
gcpGoogle Cloud"8.12.1*ç^
:
containeranalysisNotegcp:containeranalysis/note:Note¦IA Container Analysis note is a high-level piece of metadata that
describes a type of analysis that can be done for a resource.


To get more information about Note, see:

* [API documentation](https://cloud.google.com/container-analysis/api/reference/rest/)
* How-to Guides
    * [Creating Attestations (Occurrences)](https://cloud.google.com/binary-authorization/docs/making-attestations)
    * [Official Documentation](https://cloud.google.com/container-analysis/)

## Example Usage

### Container Analysis Note Basic


<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const note = new gcp.containeranalysis.Note("note", {
    name: "attestor-note",
    attestationAuthority: {
        hint: {
            humanReadableName: "Attestor Note",
        },
    },
});
```
```python
import pulumi
import pulumi_gcp as gcp

note = gcp.containeranalysis.Note("note",
    name="attestor-note",
    attestation_authority={
        "hint": {
            "human_readable_name": "Attestor Note",
        },
    })
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var note = new Gcp.ContainerAnalysis.Note("note", new()
    {
        Name = "attestor-note",
        AttestationAuthority = new Gcp.ContainerAnalysis.Inputs.NoteAttestationAuthorityArgs
        {
            Hint = new Gcp.ContainerAnalysis.Inputs.NoteAttestationAuthorityHintArgs
            {
                HumanReadableName = "Attestor Note",
            },
        },
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/containeranalysis"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		_, err := containeranalysis.NewNote(ctx, "note", &containeranalysis.NoteArgs{
			Name: pulumi.String("attestor-note"),
			AttestationAuthority: &containeranalysis.NoteAttestationAuthorityArgs{
				Hint: &containeranalysis.NoteAttestationAuthorityHintArgs{
					HumanReadableName: pulumi.String("Attestor Note"),
				},
			},
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.containeranalysis.Note;
import com.pulumi.gcp.containeranalysis.NoteArgs;
import com.pulumi.gcp.containeranalysis.inputs.NoteAttestationAuthorityArgs;
import com.pulumi.gcp.containeranalysis.inputs.NoteAttestationAuthorityHintArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        var note = new Note("note", NoteArgs.builder()
            .name("attestor-note")
            .attestationAuthority(NoteAttestationAuthorityArgs.builder()
                .hint(NoteAttestationAuthorityHintArgs.builder()
                    .humanReadableName("Attestor Note")
                    .build())
                .build())
            .build());

    }
}
```
```yaml
resources:
  note:
    type: gcp:containeranalysis:Note
    properties:
      name: attestor-note
      attestationAuthority:
        hint:
          humanReadableName: Attestor Note
```
<!--End PulumiCodeChooser -->
### Container Analysis Note Attestation Full


<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const note = new gcp.containeranalysis.Note("note", {
    name: "attestor-note",
    shortDescription: "test note",
    longDescription: "a longer description of test note",
    expirationTime: "2120-10-02T15:01:23.045123456Z",
    relatedUrls: [
        {
            url: "some.url",
            label: "foo",
        },
        {
            url: "google.com",
        },
    ],
    attestationAuthority: {
        hint: {
            humanReadableName: "Attestor Note",
        },
    },
});
```
```python
import pulumi
import pulumi_gcp as gcp

note = gcp.containeranalysis.Note("note",
    name="attestor-note",
    short_description="test note",
    long_description="a longer description of test note",
    expiration_time="2120-10-02T15:01:23.045123456Z",
    related_urls=[
        {
            "url": "some.url",
            "label": "foo",
        },
        {
            "url": "google.com",
        },
    ],
    attestation_authority={
        "hint": {
            "human_readable_name": "Attestor Note",
        },
    })
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var note = new Gcp.ContainerAnalysis.Note("note", new()
    {
        Name = "attestor-note",
        ShortDescription = "test note",
        LongDescription = "a longer description of test note",
        ExpirationTime = "2120-10-02T15:01:23.045123456Z",
        RelatedUrls = new[]
        {
            new Gcp.ContainerAnalysis.Inputs.NoteRelatedUrlArgs
            {
                Url = "some.url",
                Label = "foo",
            },
            new Gcp.ContainerAnalysis.Inputs.NoteRelatedUrlArgs
            {
                Url = "google.com",
            },
        },
        AttestationAuthority = new Gcp.ContainerAnalysis.Inputs.NoteAttestationAuthorityArgs
        {
            Hint = new Gcp.ContainerAnalysis.Inputs.NoteAttestationAuthorityHintArgs
            {
                HumanReadableName = "Attestor Note",
            },
        },
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/containeranalysis"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		_, err := containeranalysis.NewNote(ctx, "note", &containeranalysis.NoteArgs{
			Name:             pulumi.String("attestor-note"),
			ShortDescription: pulumi.String("test note"),
			LongDescription:  pulumi.String("a longer description of test note"),
			ExpirationTime:   pulumi.String("2120-10-02T15:01:23.045123456Z"),
			RelatedUrls: containeranalysis.NoteRelatedUrlArray{
				&containeranalysis.NoteRelatedUrlArgs{
					Url:   pulumi.String("some.url"),
					Label: pulumi.String("foo"),
				},
				&containeranalysis.NoteRelatedUrlArgs{
					Url: pulumi.String("google.com"),
				},
			},
			AttestationAuthority: &containeranalysis.NoteAttestationAuthorityArgs{
				Hint: &containeranalysis.NoteAttestationAuthorityHintArgs{
					HumanReadableName: pulumi.String("Attestor Note"),
				},
			},
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.containeranalysis.Note;
import com.pulumi.gcp.containeranalysis.NoteArgs;
import com.pulumi.gcp.containeranalysis.inputs.NoteRelatedUrlArgs;
import com.pulumi.gcp.containeranalysis.inputs.NoteAttestationAuthorityArgs;
import com.pulumi.gcp.containeranalysis.inputs.NoteAttestationAuthorityHintArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        var note = new Note("note", NoteArgs.builder()
            .name("attestor-note")
            .shortDescription("test note")
            .longDescription("a longer description of test note")
            .expirationTime("2120-10-02T15:01:23.045123456Z")
            .relatedUrls(            
                NoteRelatedUrlArgs.builder()
                    .url("some.url")
                    .label("foo")
                    .build(),
                NoteRelatedUrlArgs.builder()
                    .url("google.com")
                    .build())
            .attestationAuthority(NoteAttestationAuthorityArgs.builder()
                .hint(NoteAttestationAuthorityHintArgs.builder()
                    .humanReadableName("Attestor Note")
                    .build())
                .build())
            .build());

    }
}
```
```yaml
resources:
  note:
    type: gcp:containeranalysis:Note
    properties:
      name: attestor-note
      shortDescription: test note
      longDescription: a longer description of test note
      expirationTime: 2120-10-02T15:01:23.045123456Z
      relatedUrls:
        - url: some.url
          label: foo
        - url: google.com
      attestationAuthority:
        hint:
          humanReadableName: Attestor Note
```
<!--End PulumiCodeChooser -->

## Import

Note can be imported using any of these accepted formats:

* `projects/{{project}}/notes/{{name}}`

* `{{project}}/{{name}}`

* `{{name}}`

When using the `pulumi import` command, Note can be imported using one of the formats above. For example:

```sh
$ pulumi import gcp:containeranalysis/note:Note default projects/{{project}}/notes/{{name}}
```

```sh
$ pulumi import gcp:containeranalysis/note:Note default {{project}}/{{name}}
```

```sh
$ pulumi import gcp:containeranalysis/note:Note default {{name}}
```

â
attestationAuthorityz:x
v
containeranalysisNoteAttestationAuthorityGgcp:containeranalysis/NoteAttestationAuthority:NoteAttestationAuthorityÍNote kind that represents a logical attestation "role" or "authority".
For example, an organization might have one AttestationAuthority for
"QA" and one for "build". This Note is intended to act strictly as a
grouping mechanism for the attached Occurrences (Attestations). This
grouping mechanism also provides a security boundary, since IAM ACLs
gate the ability for a principle to attach an Occurrence to a given
Note. It also provides a single point of lookup to find all attached
Attestation Occurrences, even if they don't all live in the same
project.
Structure is documented below.
_
expirationTimeB" GTime of expiration for this note. Leave empty if note does not expire.
<
longDescriptionB" #A detailed description of the note
$
nameB" The name of the note.

projectB" G
relatedNoteNamesB*" +Names of other notes related to this note.
¦
relatedUrls`B^*\:Z
X
containeranalysisNoteRelatedUrl3gcp:containeranalysis/NoteRelatedUrl:NoteRelatedUrl5URLs associated with this note and related metadata.
B
shortDescriptionB" (A one sentence description of the note.
"â
attestationAuthorityz:x
v
containeranalysisNoteAttestationAuthorityGgcp:containeranalysis/NoteAttestationAuthority:NoteAttestationAuthorityÍNote kind that represents a logical attestation "role" or "authority".
For example, an organization might have one AttestationAuthority for
"QA" and one for "build". This Note is intended to act strictly as a
grouping mechanism for the attached Occurrences (Attestations). This
grouping mechanism also provides a security boundary, since IAM ACLs
gate the ability for a principle to attach an Occurrence to a given
Note. It also provides a single point of lookup to find all attached
Attestation Occurrences, even if they don't all live in the same
project.
Structure is documented below.
"2

createTime"  The time this note was created.
"_
expirationTimeB" GTime of expiration for this note. Leave empty if note does not expire.
"5
kind" )The type of analysis this note describes
"<
longDescriptionB" #A detailed description of the note
""
name" The name of the note.
"
project" "G
relatedNoteNamesB*" +Names of other notes related to this note.
"¦
relatedUrls`B^*\:Z
X
containeranalysisNoteRelatedUrl3gcp:containeranalysis/NoteRelatedUrl:NoteRelatedUrl5URLs associated with this note and related metadata.
"B
shortDescriptionB" (A one sentence description of the note.
"7

updateTime" %The time this note was last updated.
*Ø
X
containeranalysisNoteIamBinding3gcp:containeranalysis/noteIamBinding:NoteIamBindingÇ¸Three different resources help you manage your IAM policy for Container Registry Note. Each of these resources serves a different use case:

* `gcp.containeranalysis.NoteIamPolicy`: Authoritative. Sets the IAM policy for the note and replaces any existing policy already attached.
* `gcp.containeranalysis.NoteIamBinding`: Authoritative for a given role. Updates the IAM policy to grant a role to a list of members. Other roles within the IAM policy for the note are preserved.
* `gcp.containeranalysis.NoteIamMember`: Non-authoritative. Updates the IAM policy to grant a role to a new member. Other members for the role for the note are preserved.

A data source can be used to retrieve policy data in advent you do not need creation

* `gcp.containeranalysis.NoteIamPolicy`: Retrieves the IAM policy for the note

> **Note:** `gcp.containeranalysis.NoteIamPolicy` **cannot** be used in conjunction with `gcp.containeranalysis.NoteIamBinding` and `gcp.containeranalysis.NoteIamMember` or they will fight over what your policy should be.

> **Note:** `gcp.containeranalysis.NoteIamBinding` resources **can be** used in conjunction with `gcp.containeranalysis.NoteIamMember` resources **only if** they do not grant privilege to the same role.



## gcp.containeranalysis.NoteIamPolicy

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const admin = gcp.organizations.getIAMPolicy({
    bindings: [{
        role: "roles/containeranalysis.notes.occurrences.viewer",
        members: ["user:jane@example.com"],
    }],
});
const policy = new gcp.containeranalysis.NoteIamPolicy("policy", {
    project: note.project,
    note: note.name,
    policyData: admin.then(admin => admin.policyData),
});
```
```python
import pulumi
import pulumi_gcp as gcp

admin = gcp.organizations.get_iam_policy(bindings=[{
    "role": "roles/containeranalysis.notes.occurrences.viewer",
    "members": ["user:jane@example.com"],
}])
policy = gcp.containeranalysis.NoteIamPolicy("policy",
    project=note["project"],
    note=note["name"],
    policy_data=admin.policy_data)
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var admin = Gcp.Organizations.GetIAMPolicy.Invoke(new()
    {
        Bindings = new[]
        {
            new Gcp.Organizations.Inputs.GetIAMPolicyBindingInputArgs
            {
                Role = "roles/containeranalysis.notes.occurrences.viewer",
                Members = new[]
                {
                    "user:jane@example.com",
                },
            },
        },
    });

    var policy = new Gcp.ContainerAnalysis.NoteIamPolicy("policy", new()
    {
        Project = note.Project,
        Note = note.Name,
        PolicyData = admin.Apply(getIAMPolicyResult => getIAMPolicyResult.PolicyData),
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/containeranalysis"
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/organizations"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		admin, err := organizations.LookupIAMPolicy(ctx, &organizations.LookupIAMPolicyArgs{
			Bindings: []organizations.GetIAMPolicyBinding{
				{
					Role: "roles/containeranalysis.notes.occurrences.viewer",
					Members: []string{
						"user:jane@example.com",
					},
				},
			},
		}, nil)
		if err != nil {
			return err
		}
		_, err = containeranalysis.NewNoteIamPolicy(ctx, "policy", &containeranalysis.NoteIamPolicyArgs{
			Project:    pulumi.Any(note.Project),
			Note:       pulumi.Any(note.Name),
			PolicyData: pulumi.String(admin.PolicyData),
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.organizations.OrganizationsFunctions;
import com.pulumi.gcp.organizations.inputs.GetIAMPolicyArgs;
import com.pulumi.gcp.containeranalysis.NoteIamPolicy;
import com.pulumi.gcp.containeranalysis.NoteIamPolicyArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        final var admin = OrganizationsFunctions.getIAMPolicy(GetIAMPolicyArgs.builder()
            .bindings(GetIAMPolicyBindingArgs.builder()
                .role("roles/containeranalysis.notes.occurrences.viewer")
                .members("user:jane@example.com")
                .build())
            .build());

        var policy = new NoteIamPolicy("policy", NoteIamPolicyArgs.builder()
            .project(note.project())
            .note(note.name())
            .policyData(admin.applyValue(getIAMPolicyResult -> getIAMPolicyResult.policyData()))
            .build());

    }
}
```
```yaml
resources:
  policy:
    type: gcp:containeranalysis:NoteIamPolicy
    properties:
      project: ${note.project}
      note: ${note.name}
      policyData: ${admin.policyData}
variables:
  admin:
    fn::invoke:
      function: gcp:organizations:getIAMPolicy
      arguments:
        bindings:
          - role: roles/containeranalysis.notes.occurrences.viewer
            members:
              - user:jane@example.com
```
<!--End PulumiCodeChooser -->

## gcp.containeranalysis.NoteIamBinding

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const binding = new gcp.containeranalysis.NoteIamBinding("binding", {
    project: note.project,
    note: note.name,
    role: "roles/containeranalysis.notes.occurrences.viewer",
    members: ["user:jane@example.com"],
});
```
```python
import pulumi
import pulumi_gcp as gcp

binding = gcp.containeranalysis.NoteIamBinding("binding",
    project=note["project"],
    note=note["name"],
    role="roles/containeranalysis.notes.occurrences.viewer",
    members=["user:jane@example.com"])
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var binding = new Gcp.ContainerAnalysis.NoteIamBinding("binding", new()
    {
        Project = note.Project,
        Note = note.Name,
        Role = "roles/containeranalysis.notes.occurrences.viewer",
        Members = new[]
        {
            "user:jane@example.com",
        },
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/containeranalysis"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		_, err := containeranalysis.NewNoteIamBinding(ctx, "binding", &containeranalysis.NoteIamBindingArgs{
			Project: pulumi.Any(note.Project),
			Note:    pulumi.Any(note.Name),
			Role:    pulumi.String("roles/containeranalysis.notes.occurrences.viewer"),
			Members: pulumi.StringArray{
				pulumi.String("user:jane@example.com"),
			},
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.containeranalysis.NoteIamBinding;
import com.pulumi.gcp.containeranalysis.NoteIamBindingArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        var binding = new NoteIamBinding("binding", NoteIamBindingArgs.builder()
            .project(note.project())
            .note(note.name())
            .role("roles/containeranalysis.notes.occurrences.viewer")
            .members("user:jane@example.com")
            .build());

    }
}
```
```yaml
resources:
  binding:
    type: gcp:containeranalysis:NoteIamBinding
    properties:
      project: ${note.project}
      note: ${note.name}
      role: roles/containeranalysis.notes.occurrences.viewer
      members:
        - user:jane@example.com
```
<!--End PulumiCodeChooser -->

## gcp.containeranalysis.NoteIamMember

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const member = new gcp.containeranalysis.NoteIamMember("member", {
    project: note.project,
    note: note.name,
    role: "roles/containeranalysis.notes.occurrences.viewer",
    member: "user:jane@example.com",
});
```
```python
import pulumi
import pulumi_gcp as gcp

member = gcp.containeranalysis.NoteIamMember("member",
    project=note["project"],
    note=note["name"],
    role="roles/containeranalysis.notes.occurrences.viewer",
    member="user:jane@example.com")
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var member = new Gcp.ContainerAnalysis.NoteIamMember("member", new()
    {
        Project = note.Project,
        Note = note.Name,
        Role = "roles/containeranalysis.notes.occurrences.viewer",
        Member = "user:jane@example.com",
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/containeranalysis"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		_, err := containeranalysis.NewNoteIamMember(ctx, "member", &containeranalysis.NoteIamMemberArgs{
			Project: pulumi.Any(note.Project),
			Note:    pulumi.Any(note.Name),
			Role:    pulumi.String("roles/containeranalysis.notes.occurrences.viewer"),
			Member:  pulumi.String("user:jane@example.com"),
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.containeranalysis.NoteIamMember;
import com.pulumi.gcp.containeranalysis.NoteIamMemberArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        var member = new NoteIamMember("member", NoteIamMemberArgs.builder()
            .project(note.project())
            .note(note.name())
            .role("roles/containeranalysis.notes.occurrences.viewer")
            .member("user:jane@example.com")
            .build());

    }
}
```
```yaml
resources:
  member:
    type: gcp:containeranalysis:NoteIamMember
    properties:
      project: ${note.project}
      note: ${note.name}
      role: roles/containeranalysis.notes.occurrences.viewer
      member: user:jane@example.com
```
<!--End PulumiCodeChooser -->


## This resource supports User Project Overrides.

-

# IAM policy for Container Registry Note
Three different resources help you manage your IAM policy for Container Registry Note. Each of these resources serves a different use case:

* `gcp.containeranalysis.NoteIamPolicy`: Authoritative. Sets the IAM policy for the note and replaces any existing policy already attached.
* `gcp.containeranalysis.NoteIamBinding`: Authoritative for a given role. Updates the IAM policy to grant a role to a list of members. Other roles within the IAM policy for the note are preserved.
* `gcp.containeranalysis.NoteIamMember`: Non-authoritative. Updates the IAM policy to grant a role to a new member. Other members for the role for the note are preserved.

A data source can be used to retrieve policy data in advent you do not need creation

* `gcp.containeranalysis.NoteIamPolicy`: Retrieves the IAM policy for the note

> **Note:** `gcp.containeranalysis.NoteIamPolicy` **cannot** be used in conjunction with `gcp.containeranalysis.NoteIamBinding` and `gcp.containeranalysis.NoteIamMember` or they will fight over what your policy should be.

> **Note:** `gcp.containeranalysis.NoteIamBinding` resources **can be** used in conjunction with `gcp.containeranalysis.NoteIamMember` resources **only if** they do not grant privilege to the same role.



## gcp.containeranalysis.NoteIamPolicy

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const admin = gcp.organizations.getIAMPolicy({
    bindings: [{
        role: "roles/containeranalysis.notes.occurrences.viewer",
        members: ["user:jane@example.com"],
    }],
});
const policy = new gcp.containeranalysis.NoteIamPolicy("policy", {
    project: note.project,
    note: note.name,
    policyData: admin.then(admin => admin.policyData),
});
```
```python
import pulumi
import pulumi_gcp as gcp

admin = gcp.organizations.get_iam_policy(bindings=[{
    "role": "roles/containeranalysis.notes.occurrences.viewer",
    "members": ["user:jane@example.com"],
}])
policy = gcp.containeranalysis.NoteIamPolicy("policy",
    project=note["project"],
    note=note["name"],
    policy_data=admin.policy_data)
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var admin = Gcp.Organizations.GetIAMPolicy.Invoke(new()
    {
        Bindings = new[]
        {
            new Gcp.Organizations.Inputs.GetIAMPolicyBindingInputArgs
            {
                Role = "roles/containeranalysis.notes.occurrences.viewer",
                Members = new[]
                {
                    "user:jane@example.com",
                },
            },
        },
    });

    var policy = new Gcp.ContainerAnalysis.NoteIamPolicy("policy", new()
    {
        Project = note.Project,
        Note = note.Name,
        PolicyData = admin.Apply(getIAMPolicyResult => getIAMPolicyResult.PolicyData),
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/containeranalysis"
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/organizations"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		admin, err := organizations.LookupIAMPolicy(ctx, &organizations.LookupIAMPolicyArgs{
			Bindings: []organizations.GetIAMPolicyBinding{
				{
					Role: "roles/containeranalysis.notes.occurrences.viewer",
					Members: []string{
						"user:jane@example.com",
					},
				},
			},
		}, nil)
		if err != nil {
			return err
		}
		_, err = containeranalysis.NewNoteIamPolicy(ctx, "policy", &containeranalysis.NoteIamPolicyArgs{
			Project:    pulumi.Any(note.Project),
			Note:       pulumi.Any(note.Name),
			PolicyData: pulumi.String(admin.PolicyData),
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.organizations.OrganizationsFunctions;
import com.pulumi.gcp.organizations.inputs.GetIAMPolicyArgs;
import com.pulumi.gcp.containeranalysis.NoteIamPolicy;
import com.pulumi.gcp.containeranalysis.NoteIamPolicyArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        final var admin = OrganizationsFunctions.getIAMPolicy(GetIAMPolicyArgs.builder()
            .bindings(GetIAMPolicyBindingArgs.builder()
                .role("roles/containeranalysis.notes.occurrences.viewer")
                .members("user:jane@example.com")
                .build())
            .build());

        var policy = new NoteIamPolicy("policy", NoteIamPolicyArgs.builder()
            .project(note.project())
            .note(note.name())
            .policyData(admin.applyValue(getIAMPolicyResult -> getIAMPolicyResult.policyData()))
            .build());

    }
}
```
```yaml
resources:
  policy:
    type: gcp:containeranalysis:NoteIamPolicy
    properties:
      project: ${note.project}
      note: ${note.name}
      policyData: ${admin.policyData}
variables:
  admin:
    fn::invoke:
      function: gcp:organizations:getIAMPolicy
      arguments:
        bindings:
          - role: roles/containeranalysis.notes.occurrences.viewer
            members:
              - user:jane@example.com
```
<!--End PulumiCodeChooser -->

## gcp.containeranalysis.NoteIamBinding

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const binding = new gcp.containeranalysis.NoteIamBinding("binding", {
    project: note.project,
    note: note.name,
    role: "roles/containeranalysis.notes.occurrences.viewer",
    members: ["user:jane@example.com"],
});
```
```python
import pulumi
import pulumi_gcp as gcp

binding = gcp.containeranalysis.NoteIamBinding("binding",
    project=note["project"],
    note=note["name"],
    role="roles/containeranalysis.notes.occurrences.viewer",
    members=["user:jane@example.com"])
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var binding = new Gcp.ContainerAnalysis.NoteIamBinding("binding", new()
    {
        Project = note.Project,
        Note = note.Name,
        Role = "roles/containeranalysis.notes.occurrences.viewer",
        Members = new[]
        {
            "user:jane@example.com",
        },
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/containeranalysis"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		_, err := containeranalysis.NewNoteIamBinding(ctx, "binding", &containeranalysis.NoteIamBindingArgs{
			Project: pulumi.Any(note.Project),
			Note:    pulumi.Any(note.Name),
			Role:    pulumi.String("roles/containeranalysis.notes.occurrences.viewer"),
			Members: pulumi.StringArray{
				pulumi.String("user:jane@example.com"),
			},
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.containeranalysis.NoteIamBinding;
import com.pulumi.gcp.containeranalysis.NoteIamBindingArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        var binding = new NoteIamBinding("binding", NoteIamBindingArgs.builder()
            .project(note.project())
            .note(note.name())
            .role("roles/containeranalysis.notes.occurrences.viewer")
            .members("user:jane@example.com")
            .build());

    }
}
```
```yaml
resources:
  binding:
    type: gcp:containeranalysis:NoteIamBinding
    properties:
      project: ${note.project}
      note: ${note.name}
      role: roles/containeranalysis.notes.occurrences.viewer
      members:
        - user:jane@example.com
```
<!--End PulumiCodeChooser -->

## gcp.containeranalysis.NoteIamMember

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const member = new gcp.containeranalysis.NoteIamMember("member", {
    project: note.project,
    note: note.name,
    role: "roles/containeranalysis.notes.occurrences.viewer",
    member: "user:jane@example.com",
});
```
```python
import pulumi
import pulumi_gcp as gcp

member = gcp.containeranalysis.NoteIamMember("member",
    project=note["project"],
    note=note["name"],
    role="roles/containeranalysis.notes.occurrences.viewer",
    member="user:jane@example.com")
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var member = new Gcp.ContainerAnalysis.NoteIamMember("member", new()
    {
        Project = note.Project,
        Note = note.Name,
        Role = "roles/containeranalysis.notes.occurrences.viewer",
        Member = "user:jane@example.com",
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/containeranalysis"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		_, err := containeranalysis.NewNoteIamMember(ctx, "member", &containeranalysis.NoteIamMemberArgs{
			Project: pulumi.Any(note.Project),
			Note:    pulumi.Any(note.Name),
			Role:    pulumi.String("roles/containeranalysis.notes.occurrences.viewer"),
			Member:  pulumi.String("user:jane@example.com"),
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.containeranalysis.NoteIamMember;
import com.pulumi.gcp.containeranalysis.NoteIamMemberArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        var member = new NoteIamMember("member", NoteIamMemberArgs.builder()
            .project(note.project())
            .note(note.name())
            .role("roles/containeranalysis.notes.occurrences.viewer")
            .member("user:jane@example.com")
            .build());

    }
}
```
```yaml
resources:
  member:
    type: gcp:containeranalysis:NoteIamMember
    properties:
      project: ${note.project}
      note: ${note.name}
      role: roles/containeranalysis.notes.occurrences.viewer
      member: user:jane@example.com
```
<!--End PulumiCodeChooser -->

## Import

For all import syntaxes, the "resource in question" can take any of the following forms:

* projects/{{project}}/notes/{{name}}

* {{project}}/{{name}}

* {{name}}

Any variables not passed in the import command will be taken from the provider configuration.

Container Registry note IAM resources can be imported using the resource identifiers, role, and member.

IAM member imports use space-delimited identifiers: the resource in question, the role, and the member identity, e.g.

```sh
$ pulumi import gcp:containeranalysis/noteIamBinding:NoteIamBinding editor "projects/{{project}}/notes/{{note}} roles/containeranalysis.notes.occurrences.viewer user:jane@example.com"
```

IAM binding imports use space-delimited identifiers: the resource in question and the role, e.g.

```sh
$ pulumi import gcp:containeranalysis/noteIamBinding:NoteIamBinding editor "projects/{{project}}/notes/{{note}} roles/containeranalysis.notes.occurrences.viewer"
```

IAM policy imports use the identifier of the resource in question, e.g.

```sh
$ pulumi import gcp:containeranalysis/noteIamBinding:NoteIamBinding editor projects/{{project}}/notes/{{note}}
```

-> **Custom Roles** If you're importing a IAM resource with a custom role, make sure to use the

 full name of the custom role, e.g. `[projects/my-project|organizations/my-org]/roles/my-custom-role`.


	conditionyBw:u
s
containeranalysisNoteIamBindingConditionEgcp:containeranalysis/NoteIamBindingCondition:NoteIamBindingConditionÖ	
members*" Ä	Identities that will be granted the privilege in `role`.
Each entry can have one of the following values:
* **allUsers**: A special identifier that represents anyone who is on the internet; with or without a Google account.
* **allAuthenticatedUsers**: A special identifier that represents anyone who is authenticated with a Google account or a service account.
* **user:{emailid}**: An email address that represents a specific Google account. For example, alice@gmail.com or joe@example.com.
* **serviceAccount:{emailid}**: An email address that represents a service account. For example, my-other-app@appspot.gserviceaccount.com.
* **group:{emailid}**: An email address that represents a Google group. For example, admins@example.com.
* **domain:{domain}**: A G Suite domain (primary, instead of alias) name that represents all the users of that domain. For example, google.com or example.com.
* **projectOwner:projectid**: Owners of the given project. For example, "projectOwner:my-example-project"
* **projectEditor:projectid**: Editors of the given project. For example, "projectEditor:my-example-project"
* **projectViewer:projectid**: Viewers of the given project. For example, "projectViewer:my-example-project"
G
note" ;Used to find the parent resource to bind the IAM policy to

projectB" The ID of the project in which the resource belongs.
If it is not provided, the project will be parsed from the identifier of the parent resource. If no project is provided in the parent identifier and no project is specified, the provider project is used.
Ý
role" ÐThe role that should be applied. Only one
`gcp.containeranalysis.NoteIamBinding` can be used per role. Note that custom roles must be of the format
`[projects|organizations]/{parent-name}/roles/{role-name}`.
"
	conditionyBw:u
s
containeranalysisNoteIamBindingConditionEgcp:containeranalysis/NoteIamBindingCondition:NoteIamBindingCondition"3
etag" '(Computed) The etag of the IAM policy.
"Ö	
members*" Ä	Identities that will be granted the privilege in `role`.
Each entry can have one of the following values:
* **allUsers**: A special identifier that represents anyone who is on the internet; with or without a Google account.
* **allAuthenticatedUsers**: A special identifier that represents anyone who is authenticated with a Google account or a service account.
* **user:{emailid}**: An email address that represents a specific Google account. For example, alice@gmail.com or joe@example.com.
* **serviceAccount:{emailid}**: An email address that represents a service account. For example, my-other-app@appspot.gserviceaccount.com.
* **group:{emailid}**: An email address that represents a Google group. For example, admins@example.com.
* **domain:{domain}**: A G Suite domain (primary, instead of alias) name that represents all the users of that domain. For example, google.com or example.com.
* **projectOwner:projectid**: Owners of the given project. For example, "projectOwner:my-example-project"
* **projectEditor:projectid**: Editors of the given project. For example, "projectEditor:my-example-project"
* **projectViewer:projectid**: Viewers of the given project. For example, "projectViewer:my-example-project"
"G
note" ;Used to find the parent resource to bind the IAM policy to
"
project" The ID of the project in which the resource belongs.
If it is not provided, the project will be parsed from the identifier of the parent resource. If no project is provided in the parent identifier and no project is specified, the provider project is used.
"Ý
role" ÐThe role that should be applied. Only one
`gcp.containeranalysis.NoteIamBinding` can be used per role. Note that custom roles must be of the format
`[projects|organizations]/{parent-name}/roles/{role-name}`.
*Ø
U
containeranalysisNoteIamMember1gcp:containeranalysis/noteIamMember:NoteIamMemberÁ¸Three different resources help you manage your IAM policy for Container Registry Note. Each of these resources serves a different use case:

* `gcp.containeranalysis.NoteIamPolicy`: Authoritative. Sets the IAM policy for the note and replaces any existing policy already attached.
* `gcp.containeranalysis.NoteIamBinding`: Authoritative for a given role. Updates the IAM policy to grant a role to a list of members. Other roles within the IAM policy for the note are preserved.
* `gcp.containeranalysis.NoteIamMember`: Non-authoritative. Updates the IAM policy to grant a role to a new member. Other members for the role for the note are preserved.

A data source can be used to retrieve policy data in advent you do not need creation

* `gcp.containeranalysis.NoteIamPolicy`: Retrieves the IAM policy for the note

> **Note:** `gcp.containeranalysis.NoteIamPolicy` **cannot** be used in conjunction with `gcp.containeranalysis.NoteIamBinding` and `gcp.containeranalysis.NoteIamMember` or they will fight over what your policy should be.

> **Note:** `gcp.containeranalysis.NoteIamBinding` resources **can be** used in conjunction with `gcp.containeranalysis.NoteIamMember` resources **only if** they do not grant privilege to the same role.



## gcp.containeranalysis.NoteIamPolicy

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const admin = gcp.organizations.getIAMPolicy({
    bindings: [{
        role: "roles/containeranalysis.notes.occurrences.viewer",
        members: ["user:jane@example.com"],
    }],
});
const policy = new gcp.containeranalysis.NoteIamPolicy("policy", {
    project: note.project,
    note: note.name,
    policyData: admin.then(admin => admin.policyData),
});
```
```python
import pulumi
import pulumi_gcp as gcp

admin = gcp.organizations.get_iam_policy(bindings=[{
    "role": "roles/containeranalysis.notes.occurrences.viewer",
    "members": ["user:jane@example.com"],
}])
policy = gcp.containeranalysis.NoteIamPolicy("policy",
    project=note["project"],
    note=note["name"],
    policy_data=admin.policy_data)
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var admin = Gcp.Organizations.GetIAMPolicy.Invoke(new()
    {
        Bindings = new[]
        {
            new Gcp.Organizations.Inputs.GetIAMPolicyBindingInputArgs
            {
                Role = "roles/containeranalysis.notes.occurrences.viewer",
                Members = new[]
                {
                    "user:jane@example.com",
                },
            },
        },
    });

    var policy = new Gcp.ContainerAnalysis.NoteIamPolicy("policy", new()
    {
        Project = note.Project,
        Note = note.Name,
        PolicyData = admin.Apply(getIAMPolicyResult => getIAMPolicyResult.PolicyData),
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/containeranalysis"
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/organizations"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		admin, err := organizations.LookupIAMPolicy(ctx, &organizations.LookupIAMPolicyArgs{
			Bindings: []organizations.GetIAMPolicyBinding{
				{
					Role: "roles/containeranalysis.notes.occurrences.viewer",
					Members: []string{
						"user:jane@example.com",
					},
				},
			},
		}, nil)
		if err != nil {
			return err
		}
		_, err = containeranalysis.NewNoteIamPolicy(ctx, "policy", &containeranalysis.NoteIamPolicyArgs{
			Project:    pulumi.Any(note.Project),
			Note:       pulumi.Any(note.Name),
			PolicyData: pulumi.String(admin.PolicyData),
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.organizations.OrganizationsFunctions;
import com.pulumi.gcp.organizations.inputs.GetIAMPolicyArgs;
import com.pulumi.gcp.containeranalysis.NoteIamPolicy;
import com.pulumi.gcp.containeranalysis.NoteIamPolicyArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        final var admin = OrganizationsFunctions.getIAMPolicy(GetIAMPolicyArgs.builder()
            .bindings(GetIAMPolicyBindingArgs.builder()
                .role("roles/containeranalysis.notes.occurrences.viewer")
                .members("user:jane@example.com")
                .build())
            .build());

        var policy = new NoteIamPolicy("policy", NoteIamPolicyArgs.builder()
            .project(note.project())
            .note(note.name())
            .policyData(admin.applyValue(getIAMPolicyResult -> getIAMPolicyResult.policyData()))
            .build());

    }
}
```
```yaml
resources:
  policy:
    type: gcp:containeranalysis:NoteIamPolicy
    properties:
      project: ${note.project}
      note: ${note.name}
      policyData: ${admin.policyData}
variables:
  admin:
    fn::invoke:
      function: gcp:organizations:getIAMPolicy
      arguments:
        bindings:
          - role: roles/containeranalysis.notes.occurrences.viewer
            members:
              - user:jane@example.com
```
<!--End PulumiCodeChooser -->

## gcp.containeranalysis.NoteIamBinding

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const binding = new gcp.containeranalysis.NoteIamBinding("binding", {
    project: note.project,
    note: note.name,
    role: "roles/containeranalysis.notes.occurrences.viewer",
    members: ["user:jane@example.com"],
});
```
```python
import pulumi
import pulumi_gcp as gcp

binding = gcp.containeranalysis.NoteIamBinding("binding",
    project=note["project"],
    note=note["name"],
    role="roles/containeranalysis.notes.occurrences.viewer",
    members=["user:jane@example.com"])
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var binding = new Gcp.ContainerAnalysis.NoteIamBinding("binding", new()
    {
        Project = note.Project,
        Note = note.Name,
        Role = "roles/containeranalysis.notes.occurrences.viewer",
        Members = new[]
        {
            "user:jane@example.com",
        },
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/containeranalysis"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		_, err := containeranalysis.NewNoteIamBinding(ctx, "binding", &containeranalysis.NoteIamBindingArgs{
			Project: pulumi.Any(note.Project),
			Note:    pulumi.Any(note.Name),
			Role:    pulumi.String("roles/containeranalysis.notes.occurrences.viewer"),
			Members: pulumi.StringArray{
				pulumi.String("user:jane@example.com"),
			},
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.containeranalysis.NoteIamBinding;
import com.pulumi.gcp.containeranalysis.NoteIamBindingArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        var binding = new NoteIamBinding("binding", NoteIamBindingArgs.builder()
            .project(note.project())
            .note(note.name())
            .role("roles/containeranalysis.notes.occurrences.viewer")
            .members("user:jane@example.com")
            .build());

    }
}
```
```yaml
resources:
  binding:
    type: gcp:containeranalysis:NoteIamBinding
    properties:
      project: ${note.project}
      note: ${note.name}
      role: roles/containeranalysis.notes.occurrences.viewer
      members:
        - user:jane@example.com
```
<!--End PulumiCodeChooser -->

## gcp.containeranalysis.NoteIamMember

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const member = new gcp.containeranalysis.NoteIamMember("member", {
    project: note.project,
    note: note.name,
    role: "roles/containeranalysis.notes.occurrences.viewer",
    member: "user:jane@example.com",
});
```
```python
import pulumi
import pulumi_gcp as gcp

member = gcp.containeranalysis.NoteIamMember("member",
    project=note["project"],
    note=note["name"],
    role="roles/containeranalysis.notes.occurrences.viewer",
    member="user:jane@example.com")
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var member = new Gcp.ContainerAnalysis.NoteIamMember("member", new()
    {
        Project = note.Project,
        Note = note.Name,
        Role = "roles/containeranalysis.notes.occurrences.viewer",
        Member = "user:jane@example.com",
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/containeranalysis"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		_, err := containeranalysis.NewNoteIamMember(ctx, "member", &containeranalysis.NoteIamMemberArgs{
			Project: pulumi.Any(note.Project),
			Note:    pulumi.Any(note.Name),
			Role:    pulumi.String("roles/containeranalysis.notes.occurrences.viewer"),
			Member:  pulumi.String("user:jane@example.com"),
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.containeranalysis.NoteIamMember;
import com.pulumi.gcp.containeranalysis.NoteIamMemberArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        var member = new NoteIamMember("member", NoteIamMemberArgs.builder()
            .project(note.project())
            .note(note.name())
            .role("roles/containeranalysis.notes.occurrences.viewer")
            .member("user:jane@example.com")
            .build());

    }
}
```
```yaml
resources:
  member:
    type: gcp:containeranalysis:NoteIamMember
    properties:
      project: ${note.project}
      note: ${note.name}
      role: roles/containeranalysis.notes.occurrences.viewer
      member: user:jane@example.com
```
<!--End PulumiCodeChooser -->


## This resource supports User Project Overrides.

-

# IAM policy for Container Registry Note
Three different resources help you manage your IAM policy for Container Registry Note. Each of these resources serves a different use case:

* `gcp.containeranalysis.NoteIamPolicy`: Authoritative. Sets the IAM policy for the note and replaces any existing policy already attached.
* `gcp.containeranalysis.NoteIamBinding`: Authoritative for a given role. Updates the IAM policy to grant a role to a list of members. Other roles within the IAM policy for the note are preserved.
* `gcp.containeranalysis.NoteIamMember`: Non-authoritative. Updates the IAM policy to grant a role to a new member. Other members for the role for the note are preserved.

A data source can be used to retrieve policy data in advent you do not need creation

* `gcp.containeranalysis.NoteIamPolicy`: Retrieves the IAM policy for the note

> **Note:** `gcp.containeranalysis.NoteIamPolicy` **cannot** be used in conjunction with `gcp.containeranalysis.NoteIamBinding` and `gcp.containeranalysis.NoteIamMember` or they will fight over what your policy should be.

> **Note:** `gcp.containeranalysis.NoteIamBinding` resources **can be** used in conjunction with `gcp.containeranalysis.NoteIamMember` resources **only if** they do not grant privilege to the same role.



## gcp.containeranalysis.NoteIamPolicy

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const admin = gcp.organizations.getIAMPolicy({
    bindings: [{
        role: "roles/containeranalysis.notes.occurrences.viewer",
        members: ["user:jane@example.com"],
    }],
});
const policy = new gcp.containeranalysis.NoteIamPolicy("policy", {
    project: note.project,
    note: note.name,
    policyData: admin.then(admin => admin.policyData),
});
```
```python
import pulumi
import pulumi_gcp as gcp

admin = gcp.organizations.get_iam_policy(bindings=[{
    "role": "roles/containeranalysis.notes.occurrences.viewer",
    "members": ["user:jane@example.com"],
}])
policy = gcp.containeranalysis.NoteIamPolicy("policy",
    project=note["project"],
    note=note["name"],
    policy_data=admin.policy_data)
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var admin = Gcp.Organizations.GetIAMPolicy.Invoke(new()
    {
        Bindings = new[]
        {
            new Gcp.Organizations.Inputs.GetIAMPolicyBindingInputArgs
            {
                Role = "roles/containeranalysis.notes.occurrences.viewer",
                Members = new[]
                {
                    "user:jane@example.com",
                },
            },
        },
    });

    var policy = new Gcp.ContainerAnalysis.NoteIamPolicy("policy", new()
    {
        Project = note.Project,
        Note = note.Name,
        PolicyData = admin.Apply(getIAMPolicyResult => getIAMPolicyResult.PolicyData),
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/containeranalysis"
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/organizations"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		admin, err := organizations.LookupIAMPolicy(ctx, &organizations.LookupIAMPolicyArgs{
			Bindings: []organizations.GetIAMPolicyBinding{
				{
					Role: "roles/containeranalysis.notes.occurrences.viewer",
					Members: []string{
						"user:jane@example.com",
					},
				},
			},
		}, nil)
		if err != nil {
			return err
		}
		_, err = containeranalysis.NewNoteIamPolicy(ctx, "policy", &containeranalysis.NoteIamPolicyArgs{
			Project:    pulumi.Any(note.Project),
			Note:       pulumi.Any(note.Name),
			PolicyData: pulumi.String(admin.PolicyData),
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.organizations.OrganizationsFunctions;
import com.pulumi.gcp.organizations.inputs.GetIAMPolicyArgs;
import com.pulumi.gcp.containeranalysis.NoteIamPolicy;
import com.pulumi.gcp.containeranalysis.NoteIamPolicyArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        final var admin = OrganizationsFunctions.getIAMPolicy(GetIAMPolicyArgs.builder()
            .bindings(GetIAMPolicyBindingArgs.builder()
                .role("roles/containeranalysis.notes.occurrences.viewer")
                .members("user:jane@example.com")
                .build())
            .build());

        var policy = new NoteIamPolicy("policy", NoteIamPolicyArgs.builder()
            .project(note.project())
            .note(note.name())
            .policyData(admin.applyValue(getIAMPolicyResult -> getIAMPolicyResult.policyData()))
            .build());

    }
}
```
```yaml
resources:
  policy:
    type: gcp:containeranalysis:NoteIamPolicy
    properties:
      project: ${note.project}
      note: ${note.name}
      policyData: ${admin.policyData}
variables:
  admin:
    fn::invoke:
      function: gcp:organizations:getIAMPolicy
      arguments:
        bindings:
          - role: roles/containeranalysis.notes.occurrences.viewer
            members:
              - user:jane@example.com
```
<!--End PulumiCodeChooser -->

## gcp.containeranalysis.NoteIamBinding

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const binding = new gcp.containeranalysis.NoteIamBinding("binding", {
    project: note.project,
    note: note.name,
    role: "roles/containeranalysis.notes.occurrences.viewer",
    members: ["user:jane@example.com"],
});
```
```python
import pulumi
import pulumi_gcp as gcp

binding = gcp.containeranalysis.NoteIamBinding("binding",
    project=note["project"],
    note=note["name"],
    role="roles/containeranalysis.notes.occurrences.viewer",
    members=["user:jane@example.com"])
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var binding = new Gcp.ContainerAnalysis.NoteIamBinding("binding", new()
    {
        Project = note.Project,
        Note = note.Name,
        Role = "roles/containeranalysis.notes.occurrences.viewer",
        Members = new[]
        {
            "user:jane@example.com",
        },
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/containeranalysis"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		_, err := containeranalysis.NewNoteIamBinding(ctx, "binding", &containeranalysis.NoteIamBindingArgs{
			Project: pulumi.Any(note.Project),
			Note:    pulumi.Any(note.Name),
			Role:    pulumi.String("roles/containeranalysis.notes.occurrences.viewer"),
			Members: pulumi.StringArray{
				pulumi.String("user:jane@example.com"),
			},
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.containeranalysis.NoteIamBinding;
import com.pulumi.gcp.containeranalysis.NoteIamBindingArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        var binding = new NoteIamBinding("binding", NoteIamBindingArgs.builder()
            .project(note.project())
            .note(note.name())
            .role("roles/containeranalysis.notes.occurrences.viewer")
            .members("user:jane@example.com")
            .build());

    }
}
```
```yaml
resources:
  binding:
    type: gcp:containeranalysis:NoteIamBinding
    properties:
      project: ${note.project}
      note: ${note.name}
      role: roles/containeranalysis.notes.occurrences.viewer
      members:
        - user:jane@example.com
```
<!--End PulumiCodeChooser -->

## gcp.containeranalysis.NoteIamMember

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const member = new gcp.containeranalysis.NoteIamMember("member", {
    project: note.project,
    note: note.name,
    role: "roles/containeranalysis.notes.occurrences.viewer",
    member: "user:jane@example.com",
});
```
```python
import pulumi
import pulumi_gcp as gcp

member = gcp.containeranalysis.NoteIamMember("member",
    project=note["project"],
    note=note["name"],
    role="roles/containeranalysis.notes.occurrences.viewer",
    member="user:jane@example.com")
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var member = new Gcp.ContainerAnalysis.NoteIamMember("member", new()
    {
        Project = note.Project,
        Note = note.Name,
        Role = "roles/containeranalysis.notes.occurrences.viewer",
        Member = "user:jane@example.com",
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/containeranalysis"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		_, err := containeranalysis.NewNoteIamMember(ctx, "member", &containeranalysis.NoteIamMemberArgs{
			Project: pulumi.Any(note.Project),
			Note:    pulumi.Any(note.Name),
			Role:    pulumi.String("roles/containeranalysis.notes.occurrences.viewer"),
			Member:  pulumi.String("user:jane@example.com"),
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.containeranalysis.NoteIamMember;
import com.pulumi.gcp.containeranalysis.NoteIamMemberArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        var member = new NoteIamMember("member", NoteIamMemberArgs.builder()
            .project(note.project())
            .note(note.name())
            .role("roles/containeranalysis.notes.occurrences.viewer")
            .member("user:jane@example.com")
            .build());

    }
}
```
```yaml
resources:
  member:
    type: gcp:containeranalysis:NoteIamMember
    properties:
      project: ${note.project}
      note: ${note.name}
      role: roles/containeranalysis.notes.occurrences.viewer
      member: user:jane@example.com
```
<!--End PulumiCodeChooser -->

## Import

For all import syntaxes, the "resource in question" can take any of the following forms:

* projects/{{project}}/notes/{{name}}

* {{project}}/{{name}}

* {{name}}

Any variables not passed in the import command will be taken from the provider configuration.

Container Registry note IAM resources can be imported using the resource identifiers, role, and member.

IAM member imports use space-delimited identifiers: the resource in question, the role, and the member identity, e.g.

```sh
$ pulumi import gcp:containeranalysis/noteIamMember:NoteIamMember editor "projects/{{project}}/notes/{{note}} roles/containeranalysis.notes.occurrences.viewer user:jane@example.com"
```

IAM binding imports use space-delimited identifiers: the resource in question and the role, e.g.

```sh
$ pulumi import gcp:containeranalysis/noteIamMember:NoteIamMember editor "projects/{{project}}/notes/{{note}} roles/containeranalysis.notes.occurrences.viewer"
```

IAM policy imports use the identifier of the resource in question, e.g.

```sh
$ pulumi import gcp:containeranalysis/noteIamMember:NoteIamMember editor projects/{{project}}/notes/{{note}}
```

-> **Custom Roles** If you're importing a IAM resource with a custom role, make sure to use the

 full name of the custom role, e.g. `[projects/my-project|organizations/my-org]/roles/my-custom-role`.


	conditionvBt:r
p
containeranalysisNoteIamMemberConditionCgcp:containeranalysis/NoteIamMemberCondition:NoteIamMemberConditionÓ	
member" Ä	Identities that will be granted the privilege in `role`.
Each entry can have one of the following values:
* **allUsers**: A special identifier that represents anyone who is on the internet; with or without a Google account.
* **allAuthenticatedUsers**: A special identifier that represents anyone who is authenticated with a Google account or a service account.
* **user:{emailid}**: An email address that represents a specific Google account. For example, alice@gmail.com or joe@example.com.
* **serviceAccount:{emailid}**: An email address that represents a service account. For example, my-other-app@appspot.gserviceaccount.com.
* **group:{emailid}**: An email address that represents a Google group. For example, admins@example.com.
* **domain:{domain}**: A G Suite domain (primary, instead of alias) name that represents all the users of that domain. For example, google.com or example.com.
* **projectOwner:projectid**: Owners of the given project. For example, "projectOwner:my-example-project"
* **projectEditor:projectid**: Editors of the given project. For example, "projectEditor:my-example-project"
* **projectViewer:projectid**: Viewers of the given project. For example, "projectViewer:my-example-project"
G
note" ;Used to find the parent resource to bind the IAM policy to

projectB" The ID of the project in which the resource belongs.
If it is not provided, the project will be parsed from the identifier of the parent resource. If no project is provided in the parent identifier and no project is specified, the provider project is used.
Ý
role" ÐThe role that should be applied. Only one
`gcp.containeranalysis.NoteIamBinding` can be used per role. Note that custom roles must be of the format
`[projects|organizations]/{parent-name}/roles/{role-name}`.
"
	conditionvBt:r
p
containeranalysisNoteIamMemberConditionCgcp:containeranalysis/NoteIamMemberCondition:NoteIamMemberCondition"3
etag" '(Computed) The etag of the IAM policy.
"Ó	
member" Ä	Identities that will be granted the privilege in `role`.
Each entry can have one of the following values:
* **allUsers**: A special identifier that represents anyone who is on the internet; with or without a Google account.
* **allAuthenticatedUsers**: A special identifier that represents anyone who is authenticated with a Google account or a service account.
* **user:{emailid}**: An email address that represents a specific Google account. For example, alice@gmail.com or joe@example.com.
* **serviceAccount:{emailid}**: An email address that represents a service account. For example, my-other-app@appspot.gserviceaccount.com.
* **group:{emailid}**: An email address that represents a Google group. For example, admins@example.com.
* **domain:{domain}**: A G Suite domain (primary, instead of alias) name that represents all the users of that domain. For example, google.com or example.com.
* **projectOwner:projectid**: Owners of the given project. For example, "projectOwner:my-example-project"
* **projectEditor:projectid**: Editors of the given project. For example, "projectEditor:my-example-project"
* **projectViewer:projectid**: Viewers of the given project. For example, "projectViewer:my-example-project"
"G
note" ;Used to find the parent resource to bind the IAM policy to
"
project" The ID of the project in which the resource belongs.
If it is not provided, the project will be parsed from the identifier of the parent resource. If no project is provided in the parent identifier and no project is specified, the provider project is used.
"Ý
role" ÐThe role that should be applied. Only one
`gcp.containeranalysis.NoteIamBinding` can be used per role. Note that custom roles must be of the format
`[projects|organizations]/{parent-name}/roles/{role-name}`.
*ÏÀ
U
containeranalysisNoteIamPolicy1gcp:containeranalysis/noteIamPolicy:NoteIamPolicyÁ¸Three different resources help you manage your IAM policy for Container Registry Note. Each of these resources serves a different use case:

* `gcp.containeranalysis.NoteIamPolicy`: Authoritative. Sets the IAM policy for the note and replaces any existing policy already attached.
* `gcp.containeranalysis.NoteIamBinding`: Authoritative for a given role. Updates the IAM policy to grant a role to a list of members. Other roles within the IAM policy for the note are preserved.
* `gcp.containeranalysis.NoteIamMember`: Non-authoritative. Updates the IAM policy to grant a role to a new member. Other members for the role for the note are preserved.

A data source can be used to retrieve policy data in advent you do not need creation

* `gcp.containeranalysis.NoteIamPolicy`: Retrieves the IAM policy for the note

> **Note:** `gcp.containeranalysis.NoteIamPolicy` **cannot** be used in conjunction with `gcp.containeranalysis.NoteIamBinding` and `gcp.containeranalysis.NoteIamMember` or they will fight over what your policy should be.

> **Note:** `gcp.containeranalysis.NoteIamBinding` resources **can be** used in conjunction with `gcp.containeranalysis.NoteIamMember` resources **only if** they do not grant privilege to the same role.



## gcp.containeranalysis.NoteIamPolicy

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const admin = gcp.organizations.getIAMPolicy({
    bindings: [{
        role: "roles/containeranalysis.notes.occurrences.viewer",
        members: ["user:jane@example.com"],
    }],
});
const policy = new gcp.containeranalysis.NoteIamPolicy("policy", {
    project: note.project,
    note: note.name,
    policyData: admin.then(admin => admin.policyData),
});
```
```python
import pulumi
import pulumi_gcp as gcp

admin = gcp.organizations.get_iam_policy(bindings=[{
    "role": "roles/containeranalysis.notes.occurrences.viewer",
    "members": ["user:jane@example.com"],
}])
policy = gcp.containeranalysis.NoteIamPolicy("policy",
    project=note["project"],
    note=note["name"],
    policy_data=admin.policy_data)
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var admin = Gcp.Organizations.GetIAMPolicy.Invoke(new()
    {
        Bindings = new[]
        {
            new Gcp.Organizations.Inputs.GetIAMPolicyBindingInputArgs
            {
                Role = "roles/containeranalysis.notes.occurrences.viewer",
                Members = new[]
                {
                    "user:jane@example.com",
                },
            },
        },
    });

    var policy = new Gcp.ContainerAnalysis.NoteIamPolicy("policy", new()
    {
        Project = note.Project,
        Note = note.Name,
        PolicyData = admin.Apply(getIAMPolicyResult => getIAMPolicyResult.PolicyData),
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/containeranalysis"
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/organizations"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		admin, err := organizations.LookupIAMPolicy(ctx, &organizations.LookupIAMPolicyArgs{
			Bindings: []organizations.GetIAMPolicyBinding{
				{
					Role: "roles/containeranalysis.notes.occurrences.viewer",
					Members: []string{
						"user:jane@example.com",
					},
				},
			},
		}, nil)
		if err != nil {
			return err
		}
		_, err = containeranalysis.NewNoteIamPolicy(ctx, "policy", &containeranalysis.NoteIamPolicyArgs{
			Project:    pulumi.Any(note.Project),
			Note:       pulumi.Any(note.Name),
			PolicyData: pulumi.String(admin.PolicyData),
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.organizations.OrganizationsFunctions;
import com.pulumi.gcp.organizations.inputs.GetIAMPolicyArgs;
import com.pulumi.gcp.containeranalysis.NoteIamPolicy;
import com.pulumi.gcp.containeranalysis.NoteIamPolicyArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        final var admin = OrganizationsFunctions.getIAMPolicy(GetIAMPolicyArgs.builder()
            .bindings(GetIAMPolicyBindingArgs.builder()
                .role("roles/containeranalysis.notes.occurrences.viewer")
                .members("user:jane@example.com")
                .build())
            .build());

        var policy = new NoteIamPolicy("policy", NoteIamPolicyArgs.builder()
            .project(note.project())
            .note(note.name())
            .policyData(admin.applyValue(getIAMPolicyResult -> getIAMPolicyResult.policyData()))
            .build());

    }
}
```
```yaml
resources:
  policy:
    type: gcp:containeranalysis:NoteIamPolicy
    properties:
      project: ${note.project}
      note: ${note.name}
      policyData: ${admin.policyData}
variables:
  admin:
    fn::invoke:
      function: gcp:organizations:getIAMPolicy
      arguments:
        bindings:
          - role: roles/containeranalysis.notes.occurrences.viewer
            members:
              - user:jane@example.com
```
<!--End PulumiCodeChooser -->

## gcp.containeranalysis.NoteIamBinding

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const binding = new gcp.containeranalysis.NoteIamBinding("binding", {
    project: note.project,
    note: note.name,
    role: "roles/containeranalysis.notes.occurrences.viewer",
    members: ["user:jane@example.com"],
});
```
```python
import pulumi
import pulumi_gcp as gcp

binding = gcp.containeranalysis.NoteIamBinding("binding",
    project=note["project"],
    note=note["name"],
    role="roles/containeranalysis.notes.occurrences.viewer",
    members=["user:jane@example.com"])
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var binding = new Gcp.ContainerAnalysis.NoteIamBinding("binding", new()
    {
        Project = note.Project,
        Note = note.Name,
        Role = "roles/containeranalysis.notes.occurrences.viewer",
        Members = new[]
        {
            "user:jane@example.com",
        },
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/containeranalysis"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		_, err := containeranalysis.NewNoteIamBinding(ctx, "binding", &containeranalysis.NoteIamBindingArgs{
			Project: pulumi.Any(note.Project),
			Note:    pulumi.Any(note.Name),
			Role:    pulumi.String("roles/containeranalysis.notes.occurrences.viewer"),
			Members: pulumi.StringArray{
				pulumi.String("user:jane@example.com"),
			},
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.containeranalysis.NoteIamBinding;
import com.pulumi.gcp.containeranalysis.NoteIamBindingArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        var binding = new NoteIamBinding("binding", NoteIamBindingArgs.builder()
            .project(note.project())
            .note(note.name())
            .role("roles/containeranalysis.notes.occurrences.viewer")
            .members("user:jane@example.com")
            .build());

    }
}
```
```yaml
resources:
  binding:
    type: gcp:containeranalysis:NoteIamBinding
    properties:
      project: ${note.project}
      note: ${note.name}
      role: roles/containeranalysis.notes.occurrences.viewer
      members:
        - user:jane@example.com
```
<!--End PulumiCodeChooser -->

## gcp.containeranalysis.NoteIamMember

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const member = new gcp.containeranalysis.NoteIamMember("member", {
    project: note.project,
    note: note.name,
    role: "roles/containeranalysis.notes.occurrences.viewer",
    member: "user:jane@example.com",
});
```
```python
import pulumi
import pulumi_gcp as gcp

member = gcp.containeranalysis.NoteIamMember("member",
    project=note["project"],
    note=note["name"],
    role="roles/containeranalysis.notes.occurrences.viewer",
    member="user:jane@example.com")
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var member = new Gcp.ContainerAnalysis.NoteIamMember("member", new()
    {
        Project = note.Project,
        Note = note.Name,
        Role = "roles/containeranalysis.notes.occurrences.viewer",
        Member = "user:jane@example.com",
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/containeranalysis"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		_, err := containeranalysis.NewNoteIamMember(ctx, "member", &containeranalysis.NoteIamMemberArgs{
			Project: pulumi.Any(note.Project),
			Note:    pulumi.Any(note.Name),
			Role:    pulumi.String("roles/containeranalysis.notes.occurrences.viewer"),
			Member:  pulumi.String("user:jane@example.com"),
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.containeranalysis.NoteIamMember;
import com.pulumi.gcp.containeranalysis.NoteIamMemberArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        var member = new NoteIamMember("member", NoteIamMemberArgs.builder()
            .project(note.project())
            .note(note.name())
            .role("roles/containeranalysis.notes.occurrences.viewer")
            .member("user:jane@example.com")
            .build());

    }
}
```
```yaml
resources:
  member:
    type: gcp:containeranalysis:NoteIamMember
    properties:
      project: ${note.project}
      note: ${note.name}
      role: roles/containeranalysis.notes.occurrences.viewer
      member: user:jane@example.com
```
<!--End PulumiCodeChooser -->


## This resource supports User Project Overrides.

-

# IAM policy for Container Registry Note
Three different resources help you manage your IAM policy for Container Registry Note. Each of these resources serves a different use case:

* `gcp.containeranalysis.NoteIamPolicy`: Authoritative. Sets the IAM policy for the note and replaces any existing policy already attached.
* `gcp.containeranalysis.NoteIamBinding`: Authoritative for a given role. Updates the IAM policy to grant a role to a list of members. Other roles within the IAM policy for the note are preserved.
* `gcp.containeranalysis.NoteIamMember`: Non-authoritative. Updates the IAM policy to grant a role to a new member. Other members for the role for the note are preserved.

A data source can be used to retrieve policy data in advent you do not need creation

* `gcp.containeranalysis.NoteIamPolicy`: Retrieves the IAM policy for the note

> **Note:** `gcp.containeranalysis.NoteIamPolicy` **cannot** be used in conjunction with `gcp.containeranalysis.NoteIamBinding` and `gcp.containeranalysis.NoteIamMember` or they will fight over what your policy should be.

> **Note:** `gcp.containeranalysis.NoteIamBinding` resources **can be** used in conjunction with `gcp.containeranalysis.NoteIamMember` resources **only if** they do not grant privilege to the same role.



## gcp.containeranalysis.NoteIamPolicy

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const admin = gcp.organizations.getIAMPolicy({
    bindings: [{
        role: "roles/containeranalysis.notes.occurrences.viewer",
        members: ["user:jane@example.com"],
    }],
});
const policy = new gcp.containeranalysis.NoteIamPolicy("policy", {
    project: note.project,
    note: note.name,
    policyData: admin.then(admin => admin.policyData),
});
```
```python
import pulumi
import pulumi_gcp as gcp

admin = gcp.organizations.get_iam_policy(bindings=[{
    "role": "roles/containeranalysis.notes.occurrences.viewer",
    "members": ["user:jane@example.com"],
}])
policy = gcp.containeranalysis.NoteIamPolicy("policy",
    project=note["project"],
    note=note["name"],
    policy_data=admin.policy_data)
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var admin = Gcp.Organizations.GetIAMPolicy.Invoke(new()
    {
        Bindings = new[]
        {
            new Gcp.Organizations.Inputs.GetIAMPolicyBindingInputArgs
            {
                Role = "roles/containeranalysis.notes.occurrences.viewer",
                Members = new[]
                {
                    "user:jane@example.com",
                },
            },
        },
    });

    var policy = new Gcp.ContainerAnalysis.NoteIamPolicy("policy", new()
    {
        Project = note.Project,
        Note = note.Name,
        PolicyData = admin.Apply(getIAMPolicyResult => getIAMPolicyResult.PolicyData),
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/containeranalysis"
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/organizations"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		admin, err := organizations.LookupIAMPolicy(ctx, &organizations.LookupIAMPolicyArgs{
			Bindings: []organizations.GetIAMPolicyBinding{
				{
					Role: "roles/containeranalysis.notes.occurrences.viewer",
					Members: []string{
						"user:jane@example.com",
					},
				},
			},
		}, nil)
		if err != nil {
			return err
		}
		_, err = containeranalysis.NewNoteIamPolicy(ctx, "policy", &containeranalysis.NoteIamPolicyArgs{
			Project:    pulumi.Any(note.Project),
			Note:       pulumi.Any(note.Name),
			PolicyData: pulumi.String(admin.PolicyData),
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.organizations.OrganizationsFunctions;
import com.pulumi.gcp.organizations.inputs.GetIAMPolicyArgs;
import com.pulumi.gcp.containeranalysis.NoteIamPolicy;
import com.pulumi.gcp.containeranalysis.NoteIamPolicyArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        final var admin = OrganizationsFunctions.getIAMPolicy(GetIAMPolicyArgs.builder()
            .bindings(GetIAMPolicyBindingArgs.builder()
                .role("roles/containeranalysis.notes.occurrences.viewer")
                .members("user:jane@example.com")
                .build())
            .build());

        var policy = new NoteIamPolicy("policy", NoteIamPolicyArgs.builder()
            .project(note.project())
            .note(note.name())
            .policyData(admin.applyValue(getIAMPolicyResult -> getIAMPolicyResult.policyData()))
            .build());

    }
}
```
```yaml
resources:
  policy:
    type: gcp:containeranalysis:NoteIamPolicy
    properties:
      project: ${note.project}
      note: ${note.name}
      policyData: ${admin.policyData}
variables:
  admin:
    fn::invoke:
      function: gcp:organizations:getIAMPolicy
      arguments:
        bindings:
          - role: roles/containeranalysis.notes.occurrences.viewer
            members:
              - user:jane@example.com
```
<!--End PulumiCodeChooser -->

## gcp.containeranalysis.NoteIamBinding

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const binding = new gcp.containeranalysis.NoteIamBinding("binding", {
    project: note.project,
    note: note.name,
    role: "roles/containeranalysis.notes.occurrences.viewer",
    members: ["user:jane@example.com"],
});
```
```python
import pulumi
import pulumi_gcp as gcp

binding = gcp.containeranalysis.NoteIamBinding("binding",
    project=note["project"],
    note=note["name"],
    role="roles/containeranalysis.notes.occurrences.viewer",
    members=["user:jane@example.com"])
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var binding = new Gcp.ContainerAnalysis.NoteIamBinding("binding", new()
    {
        Project = note.Project,
        Note = note.Name,
        Role = "roles/containeranalysis.notes.occurrences.viewer",
        Members = new[]
        {
            "user:jane@example.com",
        },
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/containeranalysis"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		_, err := containeranalysis.NewNoteIamBinding(ctx, "binding", &containeranalysis.NoteIamBindingArgs{
			Project: pulumi.Any(note.Project),
			Note:    pulumi.Any(note.Name),
			Role:    pulumi.String("roles/containeranalysis.notes.occurrences.viewer"),
			Members: pulumi.StringArray{
				pulumi.String("user:jane@example.com"),
			},
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.containeranalysis.NoteIamBinding;
import com.pulumi.gcp.containeranalysis.NoteIamBindingArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        var binding = new NoteIamBinding("binding", NoteIamBindingArgs.builder()
            .project(note.project())
            .note(note.name())
            .role("roles/containeranalysis.notes.occurrences.viewer")
            .members("user:jane@example.com")
            .build());

    }
}
```
```yaml
resources:
  binding:
    type: gcp:containeranalysis:NoteIamBinding
    properties:
      project: ${note.project}
      note: ${note.name}
      role: roles/containeranalysis.notes.occurrences.viewer
      members:
        - user:jane@example.com
```
<!--End PulumiCodeChooser -->

## gcp.containeranalysis.NoteIamMember

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const member = new gcp.containeranalysis.NoteIamMember("member", {
    project: note.project,
    note: note.name,
    role: "roles/containeranalysis.notes.occurrences.viewer",
    member: "user:jane@example.com",
});
```
```python
import pulumi
import pulumi_gcp as gcp

member = gcp.containeranalysis.NoteIamMember("member",
    project=note["project"],
    note=note["name"],
    role="roles/containeranalysis.notes.occurrences.viewer",
    member="user:jane@example.com")
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var member = new Gcp.ContainerAnalysis.NoteIamMember("member", new()
    {
        Project = note.Project,
        Note = note.Name,
        Role = "roles/containeranalysis.notes.occurrences.viewer",
        Member = "user:jane@example.com",
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/containeranalysis"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		_, err := containeranalysis.NewNoteIamMember(ctx, "member", &containeranalysis.NoteIamMemberArgs{
			Project: pulumi.Any(note.Project),
			Note:    pulumi.Any(note.Name),
			Role:    pulumi.String("roles/containeranalysis.notes.occurrences.viewer"),
			Member:  pulumi.String("user:jane@example.com"),
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.containeranalysis.NoteIamMember;
import com.pulumi.gcp.containeranalysis.NoteIamMemberArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        var member = new NoteIamMember("member", NoteIamMemberArgs.builder()
            .project(note.project())
            .note(note.name())
            .role("roles/containeranalysis.notes.occurrences.viewer")
            .member("user:jane@example.com")
            .build());

    }
}
```
```yaml
resources:
  member:
    type: gcp:containeranalysis:NoteIamMember
    properties:
      project: ${note.project}
      note: ${note.name}
      role: roles/containeranalysis.notes.occurrences.viewer
      member: user:jane@example.com
```
<!--End PulumiCodeChooser -->

## Import

For all import syntaxes, the "resource in question" can take any of the following forms:

* projects/{{project}}/notes/{{name}}

* {{project}}/{{name}}

* {{name}}

Any variables not passed in the import command will be taken from the provider configuration.

Container Registry note IAM resources can be imported using the resource identifiers, role, and member.

IAM member imports use space-delimited identifiers: the resource in question, the role, and the member identity, e.g.

```sh
$ pulumi import gcp:containeranalysis/noteIamPolicy:NoteIamPolicy editor "projects/{{project}}/notes/{{note}} roles/containeranalysis.notes.occurrences.viewer user:jane@example.com"
```

IAM binding imports use space-delimited identifiers: the resource in question and the role, e.g.

```sh
$ pulumi import gcp:containeranalysis/noteIamPolicy:NoteIamPolicy editor "projects/{{project}}/notes/{{note}} roles/containeranalysis.notes.occurrences.viewer"
```

IAM policy imports use the identifier of the resource in question, e.g.

```sh
$ pulumi import gcp:containeranalysis/noteIamPolicy:NoteIamPolicy editor projects/{{project}}/notes/{{note}}
```

-> **Custom Roles** If you're importing a IAM resource with a custom role, make sure to use the

 full name of the custom role, e.g. `[projects/my-project|organizations/my-org]/roles/my-custom-role`.

G
note" ;Used to find the parent resource to bind the IAM policy to
_

policyData" MThe policy data generated by
a `gcp.organizations.getIAMPolicy` data source.

projectB" The ID of the project in which the resource belongs.
If it is not provided, the project will be parsed from the identifier of the parent resource. If no project is provided in the parent identifier and no project is specified, the provider project is used.
"3
etag" '(Computed) The etag of the IAM policy.
"G
note" ;Used to find the parent resource to bind the IAM policy to
"_

policyData" MThe policy data generated by
a `gcp.organizations.getIAMPolicy` data source.
"
project" The ID of the project in which the resource belongs.
If it is not provided, the project will be parsed from the identifier of the parent resource. If no project is provided in the parent identifier and no project is specified, the provider project is used.
*ãH
I
containeranalysis	Occurence)gcp:containeranalysis/occurence:OccurenceÝ3An occurrence is an instance of a Note, or type of analysis that
can be done for a resource.


To get more information about Occurrence, see:

* [API documentation](https://cloud.google.com/container-analysis/api/reference/rest/)
* How-to Guides
    * [Official Documentation](https://cloud.google.com/container-analysis/)

## Example Usage

### Container Analysis Occurrence Kms


<!--Start PulumiCodeChooser -->
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.containeranalysis.Note;
import com.pulumi.gcp.containeranalysis.NoteArgs;
import com.pulumi.gcp.containeranalysis.inputs.NoteAttestationAuthorityArgs;
import com.pulumi.gcp.containeranalysis.inputs.NoteAttestationAuthorityHintArgs;
import com.pulumi.gcp.kms.KmsFunctions;
import com.pulumi.gcp.kms.inputs.GetKMSKeyRingArgs;
import com.pulumi.gcp.kms.inputs.GetKMSCryptoKeyArgs;
import com.pulumi.gcp.kms.inputs.GetKMSCryptoKeyVersionArgs;
import com.pulumi.gcp.binaryauthorization.Attestor;
import com.pulumi.gcp.binaryauthorization.AttestorArgs;
import com.pulumi.gcp.binaryauthorization.inputs.AttestorAttestationAuthorityNoteArgs;
import com.pulumi.gcp.containeranalysis.Occurence;
import com.pulumi.gcp.containeranalysis.OccurenceArgs;
import com.pulumi.gcp.containeranalysis.inputs.OccurenceAttestationArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        var note = new Note("note", NoteArgs.builder()
            .name("attestation-note")
            .attestationAuthority(NoteAttestationAuthorityArgs.builder()
                .hint(NoteAttestationAuthorityHintArgs.builder()
                    .humanReadableName("Attestor Note")
                    .build())
                .build())
            .build());

        final var keyring = KmsFunctions.getKMSKeyRing(GetKMSKeyRingArgs.builder()
            .name("my-key-ring")
            .location("global")
            .build());

        final var crypto-key = KmsFunctions.getKMSCryptoKey(GetKMSCryptoKeyArgs.builder()
            .name("my-key")
            .keyRing(keyring.applyValue(getKMSKeyRingResult -> getKMSKeyRingResult.id()))
            .build());

        final var version = KmsFunctions.getKMSCryptoKeyVersion(GetKMSCryptoKeyVersionArgs.builder()
            .cryptoKey(crypto_key.id())
            .build());

        var attestor = new Attestor("attestor", AttestorArgs.builder()
            .name("attestor")
            .attestationAuthorityNote(AttestorAttestationAuthorityNoteArgs.builder()
                .noteReference(note.name())
                .publicKeys(AttestorAttestationAuthorityNotePublicKeyArgs.builder()
                    .id(version.applyValue(getKMSCryptoKeyVersionResult -> getKMSCryptoKeyVersionResult.id()))
                    .pkixPublicKey(AttestorAttestationAuthorityNotePublicKeyPkixPublicKeyArgs.builder()
                        .publicKeyPem(version.applyValue(getKMSCryptoKeyVersionResult -> getKMSCryptoKeyVersionResult.publicKeys()[0].pem()))
                        .signatureAlgorithm(version.applyValue(getKMSCryptoKeyVersionResult -> getKMSCryptoKeyVersionResult.publicKeys()[0].algorithm()))
                        .build())
                    .build())
                .build())
            .build());

        var occurrence = new Occurence("occurrence", OccurenceArgs.builder()
            .resourceUri("gcr.io/my-project/my-image")
            .noteName(note.id())
            .attestation(OccurenceAttestationArgs.builder()
                .serializedPayload(StdFunctions.filebase64(Filebase64Args.builder()
                    .input("path/to/my/payload.json")
                    .build()).result())
                .signatures(OccurenceAttestationSignatureArgs.builder()
                    .publicKeyId(version.applyValue(getKMSCryptoKeyVersionResult -> getKMSCryptoKeyVersionResult.id()))
                    .serializedPayload(StdFunctions.filebase64(Filebase64Args.builder()
                        .input("path/to/my/payload.json.sig")
                        .build()).result())
                    .build())
                .build())
            .build());

    }
}
```
```yaml
resources:
  attestor:
    type: gcp:binaryauthorization:Attestor
    properties:
      name: attestor
      attestationAuthorityNote:
        noteReference: ${note.name}
        publicKeys:
          - id: ${version.id}
            pkixPublicKey:
              publicKeyPem: ${version.publicKeys[0].pem}
              signatureAlgorithm: ${version.publicKeys[0].algorithm}
  note:
    type: gcp:containeranalysis:Note
    properties:
      name: attestation-note
      attestationAuthority:
        hint:
          humanReadableName: Attestor Note
  occurrence:
    type: gcp:containeranalysis:Occurence
    properties:
      resourceUri: gcr.io/my-project/my-image
      noteName: ${note.id}
      attestation:
        serializedPayload:
          fn::invoke:
            function: std:filebase64
            arguments:
              input: path/to/my/payload.json
            return: result
        signatures:
          - publicKeyId: ${version.id}
            serializedPayload:
              fn::invoke:
                function: std:filebase64
                arguments:
                  input: path/to/my/payload.json.sig
                return: result
variables:
  keyring:
    fn::invoke:
      function: gcp:kms:getKMSKeyRing
      arguments:
        name: my-key-ring
        location: global
  crypto-key:
    fn::invoke:
      function: gcp:kms:getKMSCryptoKey
      arguments:
        name: my-key
        keyRing: ${keyring.id}
  version:
    fn::invoke:
      function: gcp:kms:getKMSCryptoKeyVersion
      arguments:
        cryptoKey: ${["crypto-key"].id}
```
<!--End PulumiCodeChooser -->

## Import

Occurrence can be imported using any of these accepted formats:

* `projects/{{project}}/occurrences/{{name}}`

* `{{project}}/{{name}}`

* `{{name}}`

When using the `pulumi import` command, Occurrence can be imported using one of the formats above. For example:

```sh
$ pulumi import gcp:containeranalysis/occurence:Occurence default projects/{{project}}/occurrences/{{name}}
```

```sh
$ pulumi import gcp:containeranalysis/occurence:Occurence default {{project}}/{{name}}
```

```sh
$ pulumi import gcp:containeranalysis/occurence:Occurence default {{name}}
```

¤
attestationn:l
j
containeranalysisOccurenceAttestation?gcp:containeranalysis/OccurenceAttestation:OccurenceAttestation¤Occurrence that represents a single "attestation". The authenticity
of an attestation can be verified using the attached signature.
If the verifier trusts the public key of the signer, then verifying
the signature is sufficient to establish trust. In this circumstance,
the authority to which this attestation is attached is primarily
useful for lookup (how to find this attestation if you already
know the authority and artifact to be verified) and intent (for
which authority this attestation was intended to sign.
Structure is documented below.
¬
noteName" The analysis note associated with this occurrence, in the form of
projects/[PROJECT]/notes/[NOTE_ID]. This field can be used as a
filter in list requests.

projectB" T
remediationB" ?A description of actions that can be taken to remedy the note.
º
resourceUri" ¦Required. Immutable. A URI that represents the resource for which
the occurrence applies. For example,
https://gcr.io/project/image@sha256:123abc for a Docker image.
"¤
attestationn:l
j
containeranalysisOccurenceAttestation?gcp:containeranalysis/OccurenceAttestation:OccurenceAttestation¤Occurrence that represents a single "attestation". The authenticity
of an attestation can be verified using the attached signature.
If the verifier trusts the public key of the signer, then verifying
the signature is sufficient to establish trust. In this circumstance,
the authority to which this attestation is attached is primarily
useful for lookup (how to find this attestation if you already
know the authority and artifact to be verified) and intent (for
which authority this attestation was intended to sign.
Structure is documented below.
"<

createTime" *The time when the repository was created.
"
kind" The note kind which explicitly denotes which of the occurrence
details are specified. This field can be used as a filter in list
requests.
"(
name" The name of the occurrence.
"¬
noteName" The analysis note associated with this occurrence, in the form of
projects/[PROJECT]/notes/[NOTE_ID]. This field can be used as a
filter in list requests.
"
project" "T
remediationB" ?A description of actions that can be taken to remedy the note.
"º
resourceUri" ¦Required. Immutable. A URI that represents the resource for which
the occurrence applies. For example,
https://gcr.io/project/image@sha256:123abc for a Docker image.
"A

updateTime" /The time when the repository was last updated.
*â
o
databasemigrationserviceConnectionProfile@gcp:databasemigrationservice/connectionProfile:ConnectionProfile¥õA connection profile definition.


To get more information about ConnectionProfile, see:

* [API documentation](https://cloud.google.com/database-migration/docs/reference/rest/v1/projects.locations.connectionProfiles/create)
* How-to Guides
    * [Database Migration](https://cloud.google.com/database-migration/docs/)



## Example Usage

### Database Migration Service Connection Profile Cloudsql


<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const project = gcp.organizations.getProject({});
const cloudsqldb = new gcp.sql.DatabaseInstance("cloudsqldb", {
    name: "my-database",
    databaseVersion: "MYSQL_5_7",
    settings: {
        tier: "db-n1-standard-1",
        deletionProtectionEnabled: false,
    },
    deletionProtection: false,
});
const sqlClientCert = new gcp.sql.SslCert("sql_client_cert", {
    commonName: "my-cert",
    instance: cloudsqldb.name,
}, {
    dependsOn: [cloudsqldb],
});
const sqldbUser = new gcp.sql.User("sqldb_user", {
    name: "my-username",
    instance: cloudsqldb.name,
    password: "my-password",
}, {
    dependsOn: [sqlClientCert],
});
const cloudsqlprofile = new gcp.databasemigrationservice.ConnectionProfile("cloudsqlprofile", {
    location: "us-central1",
    connectionProfileId: "my-fromprofileid",
    displayName: "my-fromprofileid_display",
    labels: {
        foo: "bar",
    },
    mysql: {
        host: cloudsqldb.ipAddresses.apply(ipAddresses => ipAddresses[0].ipAddress),
        port: 3306,
        username: sqldbUser.name,
        password: sqldbUser.password,
        ssl: {
            clientKey: sqlClientCert.privateKey,
            clientCertificate: sqlClientCert.cert,
            caCertificate: sqlClientCert.serverCaCert,
        },
        cloudSqlId: "my-database",
    },
}, {
    dependsOn: [sqldbUser],
});
const cloudsqlprofileDestination = new gcp.databasemigrationservice.ConnectionProfile("cloudsqlprofile_destination", {
    location: "us-central1",
    connectionProfileId: "my-toprofileid",
    displayName: "my-toprofileid_displayname",
    labels: {
        foo: "bar",
    },
    cloudsql: {
        settings: {
            databaseVersion: "MYSQL_5_7",
            userLabels: {
                cloudfoo: "cloudbar",
            },
            tier: "db-n1-standard-1",
            edition: "ENTERPRISE",
            storageAutoResizeLimit: "0",
            activationPolicy: "ALWAYS",
            ipConfig: {
                enableIpv4: true,
                requireSsl: true,
            },
            autoStorageIncrease: true,
            dataDiskType: "PD_HDD",
            dataDiskSizeGb: "11",
            zone: "us-central1-b",
            sourceId: project.then(project => `projects/${project.projectId}/locations/us-central1/connectionProfiles/my-fromprofileid`),
            rootPassword: "testpasscloudsql",
        },
    },
}, {
    dependsOn: [cloudsqlprofile],
});
```
```python
import pulumi
import pulumi_gcp as gcp

project = gcp.organizations.get_project()
cloudsqldb = gcp.sql.DatabaseInstance("cloudsqldb",
    name="my-database",
    database_version="MYSQL_5_7",
    settings={
        "tier": "db-n1-standard-1",
        "deletion_protection_enabled": False,
    },
    deletion_protection=False)
sql_client_cert = gcp.sql.SslCert("sql_client_cert",
    common_name="my-cert",
    instance=cloudsqldb.name,
    opts = pulumi.ResourceOptions(depends_on=[cloudsqldb]))
sqldb_user = gcp.sql.User("sqldb_user",
    name="my-username",
    instance=cloudsqldb.name,
    password="my-password",
    opts = pulumi.ResourceOptions(depends_on=[sql_client_cert]))
cloudsqlprofile = gcp.databasemigrationservice.ConnectionProfile("cloudsqlprofile",
    location="us-central1",
    connection_profile_id="my-fromprofileid",
    display_name="my-fromprofileid_display",
    labels={
        "foo": "bar",
    },
    mysql={
        "host": cloudsqldb.ip_addresses[0].ip_address,
        "port": 3306,
        "username": sqldb_user.name,
        "password": sqldb_user.password,
        "ssl": {
            "client_key": sql_client_cert.private_key,
            "client_certificate": sql_client_cert.cert,
            "ca_certificate": sql_client_cert.server_ca_cert,
        },
        "cloud_sql_id": "my-database",
    },
    opts = pulumi.ResourceOptions(depends_on=[sqldb_user]))
cloudsqlprofile_destination = gcp.databasemigrationservice.ConnectionProfile("cloudsqlprofile_destination",
    location="us-central1",
    connection_profile_id="my-toprofileid",
    display_name="my-toprofileid_displayname",
    labels={
        "foo": "bar",
    },
    cloudsql={
        "settings": {
            "database_version": "MYSQL_5_7",
            "user_labels": {
                "cloudfoo": "cloudbar",
            },
            "tier": "db-n1-standard-1",
            "edition": "ENTERPRISE",
            "storage_auto_resize_limit": "0",
            "activation_policy": "ALWAYS",
            "ip_config": {
                "enable_ipv4": True,
                "require_ssl": True,
            },
            "auto_storage_increase": True,
            "data_disk_type": "PD_HDD",
            "data_disk_size_gb": "11",
            "zone": "us-central1-b",
            "source_id": f"projects/{project.project_id}/locations/us-central1/connectionProfiles/my-fromprofileid",
            "root_password": "testpasscloudsql",
        },
    },
    opts = pulumi.ResourceOptions(depends_on=[cloudsqlprofile]))
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var project = Gcp.Organizations.GetProject.Invoke();

    var cloudsqldb = new Gcp.Sql.DatabaseInstance("cloudsqldb", new()
    {
        Name = "my-database",
        DatabaseVersion = "MYSQL_5_7",
        Settings = new Gcp.Sql.Inputs.DatabaseInstanceSettingsArgs
        {
            Tier = "db-n1-standard-1",
            DeletionProtectionEnabled = false,
        },
        DeletionProtection = false,
    });

    var sqlClientCert = new Gcp.Sql.SslCert("sql_client_cert", new()
    {
        CommonName = "my-cert",
        Instance = cloudsqldb.Name,
    }, new CustomResourceOptions
    {
        DependsOn =
        {
            cloudsqldb,
        },
    });

    var sqldbUser = new Gcp.Sql.User("sqldb_user", new()
    {
        Name = "my-username",
        Instance = cloudsqldb.Name,
        Password = "my-password",
    }, new CustomResourceOptions
    {
        DependsOn =
        {
            sqlClientCert,
        },
    });

    var cloudsqlprofile = new Gcp.DatabaseMigrationService.ConnectionProfile("cloudsqlprofile", new()
    {
        Location = "us-central1",
        ConnectionProfileId = "my-fromprofileid",
        DisplayName = "my-fromprofileid_display",
        Labels = 
        {
            { "foo", "bar" },
        },
        Mysql = new Gcp.DatabaseMigrationService.Inputs.ConnectionProfileMysqlArgs
        {
            Host = cloudsqldb.IpAddresses.Apply(ipAddresses => ipAddresses[0].IpAddress),
            Port = 3306,
            Username = sqldbUser.Name,
            Password = sqldbUser.Password,
            Ssl = new Gcp.DatabaseMigrationService.Inputs.ConnectionProfileMysqlSslArgs
            {
                ClientKey = sqlClientCert.PrivateKey,
                ClientCertificate = sqlClientCert.Cert,
                CaCertificate = sqlClientCert.ServerCaCert,
            },
            CloudSqlId = "my-database",
        },
    }, new CustomResourceOptions
    {
        DependsOn =
        {
            sqldbUser,
        },
    });

    var cloudsqlprofileDestination = new Gcp.DatabaseMigrationService.ConnectionProfile("cloudsqlprofile_destination", new()
    {
        Location = "us-central1",
        ConnectionProfileId = "my-toprofileid",
        DisplayName = "my-toprofileid_displayname",
        Labels = 
        {
            { "foo", "bar" },
        },
        Cloudsql = new Gcp.DatabaseMigrationService.Inputs.ConnectionProfileCloudsqlArgs
        {
            Settings = new Gcp.DatabaseMigrationService.Inputs.ConnectionProfileCloudsqlSettingsArgs
            {
                DatabaseVersion = "MYSQL_5_7",
                UserLabels = 
                {
                    { "cloudfoo", "cloudbar" },
                },
                Tier = "db-n1-standard-1",
                Edition = "ENTERPRISE",
                StorageAutoResizeLimit = "0",
                ActivationPolicy = "ALWAYS",
                IpConfig = new Gcp.DatabaseMigrationService.Inputs.ConnectionProfileCloudsqlSettingsIpConfigArgs
                {
                    EnableIpv4 = true,
                    RequireSsl = true,
                },
                AutoStorageIncrease = true,
                DataDiskType = "PD_HDD",
                DataDiskSizeGb = "11",
                Zone = "us-central1-b",
                SourceId = $"projects/{project.Apply(getProjectResult => getProjectResult.ProjectId)}/locations/us-central1/connectionProfiles/my-fromprofileid",
                RootPassword = "testpasscloudsql",
            },
        },
    }, new CustomResourceOptions
    {
        DependsOn =
        {
            cloudsqlprofile,
        },
    });

});
```
```go
package main

import (
	"fmt"

	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/databasemigrationservice"
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/organizations"
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/sql"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		project, err := organizations.LookupProject(ctx, &organizations.LookupProjectArgs{}, nil)
		if err != nil {
			return err
		}
		cloudsqldb, err := sql.NewDatabaseInstance(ctx, "cloudsqldb", &sql.DatabaseInstanceArgs{
			Name:            pulumi.String("my-database"),
			DatabaseVersion: pulumi.String("MYSQL_5_7"),
			Settings: &sql.DatabaseInstanceSettingsArgs{
				Tier:                      pulumi.String("db-n1-standard-1"),
				DeletionProtectionEnabled: pulumi.Bool(false),
			},
			DeletionProtection: pulumi.Bool(false),
		})
		if err != nil {
			return err
		}
		sqlClientCert, err := sql.NewSslCert(ctx, "sql_client_cert", &sql.SslCertArgs{
			CommonName: pulumi.String("my-cert"),
			Instance:   cloudsqldb.Name,
		}, pulumi.DependsOn([]pulumi.Resource{
			cloudsqldb,
		}))
		if err != nil {
			return err
		}
		sqldbUser, err := sql.NewUser(ctx, "sqldb_user", &sql.UserArgs{
			Name:     pulumi.String("my-username"),
			Instance: cloudsqldb.Name,
			Password: pulumi.String("my-password"),
		}, pulumi.DependsOn([]pulumi.Resource{
			sqlClientCert,
		}))
		if err != nil {
			return err
		}
		cloudsqlprofile, err := databasemigrationservice.NewConnectionProfile(ctx, "cloudsqlprofile", &databasemigrationservice.ConnectionProfileArgs{
			Location:            pulumi.String("us-central1"),
			ConnectionProfileId: pulumi.String("my-fromprofileid"),
			DisplayName:         pulumi.String("my-fromprofileid_display"),
			Labels: pulumi.StringMap{
				"foo": pulumi.String("bar"),
			},
			Mysql: &databasemigrationservice.ConnectionProfileMysqlArgs{
				Host: cloudsqldb.IpAddresses.ApplyT(func(ipAddresses []sql.DatabaseInstanceIpAddress) (*string, error) {
					return &ipAddresses[0].IpAddress, nil
				}).(pulumi.StringPtrOutput),
				Port:     pulumi.Int(3306),
				Username: sqldbUser.Name,
				Password: sqldbUser.Password,
				Ssl: &databasemigrationservice.ConnectionProfileMysqlSslArgs{
					ClientKey:         sqlClientCert.PrivateKey,
					ClientCertificate: sqlClientCert.Cert,
					CaCertificate:     sqlClientCert.ServerCaCert,
				},
				CloudSqlId: pulumi.String("my-database"),
			},
		}, pulumi.DependsOn([]pulumi.Resource{
			sqldbUser,
		}))
		if err != nil {
			return err
		}
		_, err = databasemigrationservice.NewConnectionProfile(ctx, "cloudsqlprofile_destination", &databasemigrationservice.ConnectionProfileArgs{
			Location:            pulumi.String("us-central1"),
			ConnectionProfileId: pulumi.String("my-toprofileid"),
			DisplayName:         pulumi.String("my-toprofileid_displayname"),
			Labels: pulumi.StringMap{
				"foo": pulumi.String("bar"),
			},
			Cloudsql: &databasemigrationservice.ConnectionProfileCloudsqlArgs{
				Settings: &databasemigrationservice.ConnectionProfileCloudsqlSettingsArgs{
					DatabaseVersion: pulumi.String("MYSQL_5_7"),
					UserLabels: pulumi.StringMap{
						"cloudfoo": pulumi.String("cloudbar"),
					},
					Tier:                   pulumi.String("db-n1-standard-1"),
					Edition:                pulumi.String("ENTERPRISE"),
					StorageAutoResizeLimit: pulumi.String("0"),
					ActivationPolicy:       pulumi.String("ALWAYS"),
					IpConfig: &databasemigrationservice.ConnectionProfileCloudsqlSettingsIpConfigArgs{
						EnableIpv4: pulumi.Bool(true),
						RequireSsl: pulumi.Bool(true),
					},
					AutoStorageIncrease: pulumi.Bool(true),
					DataDiskType:        pulumi.String("PD_HDD"),
					DataDiskSizeGb:      pulumi.String("11"),
					Zone:                pulumi.String("us-central1-b"),
					SourceId:            pulumi.Sprintf("projects/%v/locations/us-central1/connectionProfiles/my-fromprofileid", project.ProjectId),
					RootPassword:        pulumi.String("testpasscloudsql"),
				},
			},
		}, pulumi.DependsOn([]pulumi.Resource{
			cloudsqlprofile,
		}))
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.organizations.OrganizationsFunctions;
import com.pulumi.gcp.organizations.inputs.GetProjectArgs;
import com.pulumi.gcp.sql.DatabaseInstance;
import com.pulumi.gcp.sql.DatabaseInstanceArgs;
import com.pulumi.gcp.sql.inputs.DatabaseInstanceSettingsArgs;
import com.pulumi.gcp.sql.SslCert;
import com.pulumi.gcp.sql.SslCertArgs;
import com.pulumi.gcp.sql.User;
import com.pulumi.gcp.sql.UserArgs;
import com.pulumi.gcp.databasemigrationservice.ConnectionProfile;
import com.pulumi.gcp.databasemigrationservice.ConnectionProfileArgs;
import com.pulumi.gcp.databasemigrationservice.inputs.ConnectionProfileMysqlArgs;
import com.pulumi.gcp.databasemigrationservice.inputs.ConnectionProfileMysqlSslArgs;
import com.pulumi.gcp.databasemigrationservice.inputs.ConnectionProfileCloudsqlArgs;
import com.pulumi.gcp.databasemigrationservice.inputs.ConnectionProfileCloudsqlSettingsArgs;
import com.pulumi.gcp.databasemigrationservice.inputs.ConnectionProfileCloudsqlSettingsIpConfigArgs;
import com.pulumi.resources.CustomResourceOptions;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        final var project = OrganizationsFunctions.getProject();

        var cloudsqldb = new DatabaseInstance("cloudsqldb", DatabaseInstanceArgs.builder()
            .name("my-database")
            .databaseVersion("MYSQL_5_7")
            .settings(DatabaseInstanceSettingsArgs.builder()
                .tier("db-n1-standard-1")
                .deletionProtectionEnabled(false)
                .build())
            .deletionProtection(false)
            .build());

        var sqlClientCert = new SslCert("sqlClientCert", SslCertArgs.builder()
            .commonName("my-cert")
            .instance(cloudsqldb.name())
            .build(), CustomResourceOptions.builder()
                .dependsOn(cloudsqldb)
                .build());

        var sqldbUser = new User("sqldbUser", UserArgs.builder()
            .name("my-username")
            .instance(cloudsqldb.name())
            .password("my-password")
            .build(), CustomResourceOptions.builder()
                .dependsOn(sqlClientCert)
                .build());

        var cloudsqlprofile = new ConnectionProfile("cloudsqlprofile", ConnectionProfileArgs.builder()
            .location("us-central1")
            .connectionProfileId("my-fromprofileid")
            .displayName("my-fromprofileid_display")
            .labels(Map.of("foo", "bar"))
            .mysql(ConnectionProfileMysqlArgs.builder()
                .host(cloudsqldb.ipAddresses().applyValue(ipAddresses -> ipAddresses[0].ipAddress()))
                .port(3306)
                .username(sqldbUser.name())
                .password(sqldbUser.password())
                .ssl(ConnectionProfileMysqlSslArgs.builder()
                    .clientKey(sqlClientCert.privateKey())
                    .clientCertificate(sqlClientCert.cert())
                    .caCertificate(sqlClientCert.serverCaCert())
                    .build())
                .cloudSqlId("my-database")
                .build())
            .build(), CustomResourceOptions.builder()
                .dependsOn(sqldbUser)
                .build());

        var cloudsqlprofileDestination = new ConnectionProfile("cloudsqlprofileDestination", ConnectionProfileArgs.builder()
            .location("us-central1")
            .connectionProfileId("my-toprofileid")
            .displayName("my-toprofileid_displayname")
            .labels(Map.of("foo", "bar"))
            .cloudsql(ConnectionProfileCloudsqlArgs.builder()
                .settings(ConnectionProfileCloudsqlSettingsArgs.builder()
                    .databaseVersion("MYSQL_5_7")
                    .userLabels(Map.of("cloudfoo", "cloudbar"))
                    .tier("db-n1-standard-1")
                    .edition("ENTERPRISE")
                    .storageAutoResizeLimit("0")
                    .activationPolicy("ALWAYS")
                    .ipConfig(ConnectionProfileCloudsqlSettingsIpConfigArgs.builder()
                        .enableIpv4(true)
                        .requireSsl(true)
                        .build())
                    .autoStorageIncrease(true)
                    .dataDiskType("PD_HDD")
                    .dataDiskSizeGb("11")
                    .zone("us-central1-b")
                    .sourceId(String.format("projects/%s/locations/us-central1/connectionProfiles/my-fromprofileid", project.applyValue(getProjectResult -> getProjectResult.projectId())))
                    .rootPassword("testpasscloudsql")
                    .build())
                .build())
            .build(), CustomResourceOptions.builder()
                .dependsOn(cloudsqlprofile)
                .build());

    }
}
```
```yaml
resources:
  cloudsqldb:
    type: gcp:sql:DatabaseInstance
    properties:
      name: my-database
      databaseVersion: MYSQL_5_7
      settings:
        tier: db-n1-standard-1
        deletionProtectionEnabled: false
      deletionProtection: false
  sqlClientCert:
    type: gcp:sql:SslCert
    name: sql_client_cert
    properties:
      commonName: my-cert
      instance: ${cloudsqldb.name}
    options:
      dependsOn:
        - ${cloudsqldb}
  sqldbUser:
    type: gcp:sql:User
    name: sqldb_user
    properties:
      name: my-username
      instance: ${cloudsqldb.name}
      password: my-password
    options:
      dependsOn:
        - ${sqlClientCert}
  cloudsqlprofile:
    type: gcp:databasemigrationservice:ConnectionProfile
    properties:
      location: us-central1
      connectionProfileId: my-fromprofileid
      displayName: my-fromprofileid_display
      labels:
        foo: bar
      mysql:
        host: ${cloudsqldb.ipAddresses[0].ipAddress}
        port: 3306
        username: ${sqldbUser.name}
        password: ${sqldbUser.password}
        ssl:
          clientKey: ${sqlClientCert.privateKey}
          clientCertificate: ${sqlClientCert.cert}
          caCertificate: ${sqlClientCert.serverCaCert}
        cloudSqlId: my-database
    options:
      dependsOn:
        - ${sqldbUser}
  cloudsqlprofileDestination:
    type: gcp:databasemigrationservice:ConnectionProfile
    name: cloudsqlprofile_destination
    properties:
      location: us-central1
      connectionProfileId: my-toprofileid
      displayName: my-toprofileid_displayname
      labels:
        foo: bar
      cloudsql:
        settings:
          databaseVersion: MYSQL_5_7
          userLabels:
            cloudfoo: cloudbar
          tier: db-n1-standard-1
          edition: ENTERPRISE
          storageAutoResizeLimit: '0'
          activationPolicy: ALWAYS
          ipConfig:
            enableIpv4: true
            requireSsl: true
          autoStorageIncrease: true
          dataDiskType: PD_HDD
          dataDiskSizeGb: '11'
          zone: us-central1-b
          sourceId: projects/${project.projectId}/locations/us-central1/connectionProfiles/my-fromprofileid
          rootPassword: testpasscloudsql
    options:
      dependsOn:
        - ${cloudsqlprofile}
variables:
  project:
    fn::invoke:
      function: gcp:organizations:getProject
      arguments: {}
```
<!--End PulumiCodeChooser -->
### Database Migration Service Connection Profile Postgres


<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const postgresqldb = new gcp.sql.DatabaseInstance("postgresqldb", {
    name: "my-database",
    databaseVersion: "POSTGRES_12",
    settings: {
        tier: "db-custom-2-13312",
    },
    deletionProtection: false,
});
const sqlClientCert = new gcp.sql.SslCert("sql_client_cert", {
    commonName: "my-cert",
    instance: postgresqldb.name,
}, {
    dependsOn: [postgresqldb],
});
const sqldbUser = new gcp.sql.User("sqldb_user", {
    name: "my-username",
    instance: postgresqldb.name,
    password: "my-password",
}, {
    dependsOn: [sqlClientCert],
});
const postgresprofile = new gcp.databasemigrationservice.ConnectionProfile("postgresprofile", {
    location: "us-central1",
    connectionProfileId: "my-profileid",
    displayName: "my-profileid_display",
    labels: {
        foo: "bar",
    },
    postgresql: {
        host: postgresqldb.ipAddresses.apply(ipAddresses => ipAddresses[0].ipAddress),
        port: 5432,
        username: sqldbUser.name,
        password: sqldbUser.password,
        ssl: {
            clientKey: sqlClientCert.privateKey,
            clientCertificate: sqlClientCert.cert,
            caCertificate: sqlClientCert.serverCaCert,
        },
        cloudSqlId: "my-database",
    },
}, {
    dependsOn: [sqldbUser],
});
```
```python
import pulumi
import pulumi_gcp as gcp

postgresqldb = gcp.sql.DatabaseInstance("postgresqldb",
    name="my-database",
    database_version="POSTGRES_12",
    settings={
        "tier": "db-custom-2-13312",
    },
    deletion_protection=False)
sql_client_cert = gcp.sql.SslCert("sql_client_cert",
    common_name="my-cert",
    instance=postgresqldb.name,
    opts = pulumi.ResourceOptions(depends_on=[postgresqldb]))
sqldb_user = gcp.sql.User("sqldb_user",
    name="my-username",
    instance=postgresqldb.name,
    password="my-password",
    opts = pulumi.ResourceOptions(depends_on=[sql_client_cert]))
postgresprofile = gcp.databasemigrationservice.ConnectionProfile("postgresprofile",
    location="us-central1",
    connection_profile_id="my-profileid",
    display_name="my-profileid_display",
    labels={
        "foo": "bar",
    },
    postgresql={
        "host": postgresqldb.ip_addresses[0].ip_address,
        "port": 5432,
        "username": sqldb_user.name,
        "password": sqldb_user.password,
        "ssl": {
            "client_key": sql_client_cert.private_key,
            "client_certificate": sql_client_cert.cert,
            "ca_certificate": sql_client_cert.server_ca_cert,
        },
        "cloud_sql_id": "my-database",
    },
    opts = pulumi.ResourceOptions(depends_on=[sqldb_user]))
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var postgresqldb = new Gcp.Sql.DatabaseInstance("postgresqldb", new()
    {
        Name = "my-database",
        DatabaseVersion = "POSTGRES_12",
        Settings = new Gcp.Sql.Inputs.DatabaseInstanceSettingsArgs
        {
            Tier = "db-custom-2-13312",
        },
        DeletionProtection = false,
    });

    var sqlClientCert = new Gcp.Sql.SslCert("sql_client_cert", new()
    {
        CommonName = "my-cert",
        Instance = postgresqldb.Name,
    }, new CustomResourceOptions
    {
        DependsOn =
        {
            postgresqldb,
        },
    });

    var sqldbUser = new Gcp.Sql.User("sqldb_user", new()
    {
        Name = "my-username",
        Instance = postgresqldb.Name,
        Password = "my-password",
    }, new CustomResourceOptions
    {
        DependsOn =
        {
            sqlClientCert,
        },
    });

    var postgresprofile = new Gcp.DatabaseMigrationService.ConnectionProfile("postgresprofile", new()
    {
        Location = "us-central1",
        ConnectionProfileId = "my-profileid",
        DisplayName = "my-profileid_display",
        Labels = 
        {
            { "foo", "bar" },
        },
        Postgresql = new Gcp.DatabaseMigrationService.Inputs.ConnectionProfilePostgresqlArgs
        {
            Host = postgresqldb.IpAddresses.Apply(ipAddresses => ipAddresses[0].IpAddress),
            Port = 5432,
            Username = sqldbUser.Name,
            Password = sqldbUser.Password,
            Ssl = new Gcp.DatabaseMigrationService.Inputs.ConnectionProfilePostgresqlSslArgs
            {
                ClientKey = sqlClientCert.PrivateKey,
                ClientCertificate = sqlClientCert.Cert,
                CaCertificate = sqlClientCert.ServerCaCert,
            },
            CloudSqlId = "my-database",
        },
    }, new CustomResourceOptions
    {
        DependsOn =
        {
            sqldbUser,
        },
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/databasemigrationservice"
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/sql"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		postgresqldb, err := sql.NewDatabaseInstance(ctx, "postgresqldb", &sql.DatabaseInstanceArgs{
			Name:            pulumi.String("my-database"),
			DatabaseVersion: pulumi.String("POSTGRES_12"),
			Settings: &sql.DatabaseInstanceSettingsArgs{
				Tier: pulumi.String("db-custom-2-13312"),
			},
			DeletionProtection: pulumi.Bool(false),
		})
		if err != nil {
			return err
		}
		sqlClientCert, err := sql.NewSslCert(ctx, "sql_client_cert", &sql.SslCertArgs{
			CommonName: pulumi.String("my-cert"),
			Instance:   postgresqldb.Name,
		}, pulumi.DependsOn([]pulumi.Resource{
			postgresqldb,
		}))
		if err != nil {
			return err
		}
		sqldbUser, err := sql.NewUser(ctx, "sqldb_user", &sql.UserArgs{
			Name:     pulumi.String("my-username"),
			Instance: postgresqldb.Name,
			Password: pulumi.String("my-password"),
		}, pulumi.DependsOn([]pulumi.Resource{
			sqlClientCert,
		}))
		if err != nil {
			return err
		}
		_, err = databasemigrationservice.NewConnectionProfile(ctx, "postgresprofile", &databasemigrationservice.ConnectionProfileArgs{
			Location:            pulumi.String("us-central1"),
			ConnectionProfileId: pulumi.String("my-profileid"),
			DisplayName:         pulumi.String("my-profileid_display"),
			Labels: pulumi.StringMap{
				"foo": pulumi.String("bar"),
			},
			Postgresql: &databasemigrationservice.ConnectionProfilePostgresqlArgs{
				Host: postgresqldb.IpAddresses.ApplyT(func(ipAddresses []sql.DatabaseInstanceIpAddress) (*string, error) {
					return &ipAddresses[0].IpAddress, nil
				}).(pulumi.StringPtrOutput),
				Port:     pulumi.Int(5432),
				Username: sqldbUser.Name,
				Password: sqldbUser.Password,
				Ssl: &databasemigrationservice.ConnectionProfilePostgresqlSslArgs{
					ClientKey:         sqlClientCert.PrivateKey,
					ClientCertificate: sqlClientCert.Cert,
					CaCertificate:     sqlClientCert.ServerCaCert,
				},
				CloudSqlId: pulumi.String("my-database"),
			},
		}, pulumi.DependsOn([]pulumi.Resource{
			sqldbUser,
		}))
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.sql.DatabaseInstance;
import com.pulumi.gcp.sql.DatabaseInstanceArgs;
import com.pulumi.gcp.sql.inputs.DatabaseInstanceSettingsArgs;
import com.pulumi.gcp.sql.SslCert;
import com.pulumi.gcp.sql.SslCertArgs;
import com.pulumi.gcp.sql.User;
import com.pulumi.gcp.sql.UserArgs;
import com.pulumi.gcp.databasemigrationservice.ConnectionProfile;
import com.pulumi.gcp.databasemigrationservice.ConnectionProfileArgs;
import com.pulumi.gcp.databasemigrationservice.inputs.ConnectionProfilePostgresqlArgs;
import com.pulumi.gcp.databasemigrationservice.inputs.ConnectionProfilePostgresqlSslArgs;
import com.pulumi.resources.CustomResourceOptions;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        var postgresqldb = new DatabaseInstance("postgresqldb", DatabaseInstanceArgs.builder()
            .name("my-database")
            .databaseVersion("POSTGRES_12")
            .settings(DatabaseInstanceSettingsArgs.builder()
                .tier("db-custom-2-13312")
                .build())
            .deletionProtection(false)
            .build());

        var sqlClientCert = new SslCert("sqlClientCert", SslCertArgs.builder()
            .commonName("my-cert")
            .instance(postgresqldb.name())
            .build(), CustomResourceOptions.builder()
                .dependsOn(postgresqldb)
                .build());

        var sqldbUser = new User("sqldbUser", UserArgs.builder()
            .name("my-username")
            .instance(postgresqldb.name())
            .password("my-password")
            .build(), CustomResourceOptions.builder()
                .dependsOn(sqlClientCert)
                .build());

        var postgresprofile = new ConnectionProfile("postgresprofile", ConnectionProfileArgs.builder()
            .location("us-central1")
            .connectionProfileId("my-profileid")
            .displayName("my-profileid_display")
            .labels(Map.of("foo", "bar"))
            .postgresql(ConnectionProfilePostgresqlArgs.builder()
                .host(postgresqldb.ipAddresses().applyValue(ipAddresses -> ipAddresses[0].ipAddress()))
                .port(5432)
                .username(sqldbUser.name())
                .password(sqldbUser.password())
                .ssl(ConnectionProfilePostgresqlSslArgs.builder()
                    .clientKey(sqlClientCert.privateKey())
                    .clientCertificate(sqlClientCert.cert())
                    .caCertificate(sqlClientCert.serverCaCert())
                    .build())
                .cloudSqlId("my-database")
                .build())
            .build(), CustomResourceOptions.builder()
                .dependsOn(sqldbUser)
                .build());

    }
}
```
```yaml
resources:
  postgresqldb:
    type: gcp:sql:DatabaseInstance
    properties:
      name: my-database
      databaseVersion: POSTGRES_12
      settings:
        tier: db-custom-2-13312
      deletionProtection: false
  sqlClientCert:
    type: gcp:sql:SslCert
    name: sql_client_cert
    properties:
      commonName: my-cert
      instance: ${postgresqldb.name}
    options:
      dependsOn:
        - ${postgresqldb}
  sqldbUser:
    type: gcp:sql:User
    name: sqldb_user
    properties:
      name: my-username
      instance: ${postgresqldb.name}
      password: my-password
    options:
      dependsOn:
        - ${sqlClientCert}
  postgresprofile:
    type: gcp:databasemigrationservice:ConnectionProfile
    properties:
      location: us-central1
      connectionProfileId: my-profileid
      displayName: my-profileid_display
      labels:
        foo: bar
      postgresql:
        host: ${postgresqldb.ipAddresses[0].ipAddress}
        port: 5432
        username: ${sqldbUser.name}
        password: ${sqldbUser.password}
        ssl:
          clientKey: ${sqlClientCert.privateKey}
          clientCertificate: ${sqlClientCert.cert}
          caCertificate: ${sqlClientCert.serverCaCert}
        cloudSqlId: my-database
    options:
      dependsOn:
        - ${sqldbUser}
```
<!--End PulumiCodeChooser -->
### Database Migration Service Connection Profile Oracle


<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const oracleprofile = new gcp.databasemigrationservice.ConnectionProfile("oracleprofile", {
    location: "us-central1",
    connectionProfileId: "my-profileid",
    displayName: "my-profileid_display",
    labels: {
        foo: "bar",
    },
    oracle: {
        host: "host",
        port: 1521,
        username: "username",
        password: "password",
        databaseService: "dbprovider",
        staticServiceIpConnectivity: {},
    },
});
```
```python
import pulumi
import pulumi_gcp as gcp

oracleprofile = gcp.databasemigrationservice.ConnectionProfile("oracleprofile",
    location="us-central1",
    connection_profile_id="my-profileid",
    display_name="my-profileid_display",
    labels={
        "foo": "bar",
    },
    oracle={
        "host": "host",
        "port": 1521,
        "username": "username",
        "password": "password",
        "database_service": "dbprovider",
        "static_service_ip_connectivity": {},
    })
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var oracleprofile = new Gcp.DatabaseMigrationService.ConnectionProfile("oracleprofile", new()
    {
        Location = "us-central1",
        ConnectionProfileId = "my-profileid",
        DisplayName = "my-profileid_display",
        Labels = 
        {
            { "foo", "bar" },
        },
        Oracle = new Gcp.DatabaseMigrationService.Inputs.ConnectionProfileOracleArgs
        {
            Host = "host",
            Port = 1521,
            Username = "username",
            Password = "password",
            DatabaseService = "dbprovider",
            StaticServiceIpConnectivity = null,
        },
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/databasemigrationservice"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		_, err := databasemigrationservice.NewConnectionProfile(ctx, "oracleprofile", &databasemigrationservice.ConnectionProfileArgs{
			Location:            pulumi.String("us-central1"),
			ConnectionProfileId: pulumi.String("my-profileid"),
			DisplayName:         pulumi.String("my-profileid_display"),
			Labels: pulumi.StringMap{
				"foo": pulumi.String("bar"),
			},
			Oracle: &databasemigrationservice.ConnectionProfileOracleArgs{
				Host:                        pulumi.String("host"),
				Port:                        pulumi.Int(1521),
				Username:                    pulumi.String("username"),
				Password:                    pulumi.String("password"),
				DatabaseService:             pulumi.String("dbprovider"),
				StaticServiceIpConnectivity: &databasemigrationservice.ConnectionProfileOracleStaticServiceIpConnectivityArgs{},
			},
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.databasemigrationservice.ConnectionProfile;
import com.pulumi.gcp.databasemigrationservice.ConnectionProfileArgs;
import com.pulumi.gcp.databasemigrationservice.inputs.ConnectionProfileOracleArgs;
import com.pulumi.gcp.databasemigrationservice.inputs.ConnectionProfileOracleStaticServiceIpConnectivityArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        var oracleprofile = new ConnectionProfile("oracleprofile", ConnectionProfileArgs.builder()
            .location("us-central1")
            .connectionProfileId("my-profileid")
            .displayName("my-profileid_display")
            .labels(Map.of("foo", "bar"))
            .oracle(ConnectionProfileOracleArgs.builder()
                .host("host")
                .port(1521)
                .username("username")
                .password("password")
                .databaseService("dbprovider")
                .staticServiceIpConnectivity()
                .build())
            .build());

    }
}
```
```yaml
resources:
  oracleprofile:
    type: gcp:databasemigrationservice:ConnectionProfile
    properties:
      location: us-central1
      connectionProfileId: my-profileid
      displayName: my-profileid_display
      labels:
        foo: bar
      oracle:
        host: host
        port: 1521
        username: username
        password: password
        databaseService: dbprovider
        staticServiceIpConnectivity: {}
```
<!--End PulumiCodeChooser -->
### Database Migration Service Connection Profile Alloydb


<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const project = gcp.organizations.getProject({});
const _default = new gcp.compute.Network("default", {name: "vpc-network"});
const privateIpAlloc = new gcp.compute.GlobalAddress("private_ip_alloc", {
    name: "private-ip-alloc",
    addressType: "INTERNAL",
    purpose: "VPC_PEERING",
    prefixLength: 16,
    network: _default.id,
});
const vpcConnection = new gcp.servicenetworking.Connection("vpc_connection", {
    network: _default.id,
    service: "servicenetworking.googleapis.com",
    reservedPeeringRanges: [privateIpAlloc.name],
});
const alloydbprofile = new gcp.databasemigrationservice.ConnectionProfile("alloydbprofile", {
    location: "us-central1",
    connectionProfileId: "my-profileid",
    displayName: "my-profileid_display",
    labels: {
        foo: "bar",
    },
    alloydb: {
        clusterId: "tf-test-dbmsalloycluster_52865",
        settings: {
            initialUser: {
                user: "alloyuser_85840",
                password: "alloypass_60302",
            },
            vpcNetwork: _default.id,
            labels: {
                alloyfoo: "alloybar",
            },
            primaryInstanceSettings: {
                id: "priminstid",
                machineConfig: {
                    cpuCount: 2,
                },
                databaseFlags: {},
                labels: {
                    alloysinstfoo: "allowinstbar",
                },
            },
        },
    },
}, {
    dependsOn: [vpcConnection],
});
```
```python
import pulumi
import pulumi_gcp as gcp

project = gcp.organizations.get_project()
default = gcp.compute.Network("default", name="vpc-network")
private_ip_alloc = gcp.compute.GlobalAddress("private_ip_alloc",
    name="private-ip-alloc",
    address_type="INTERNAL",
    purpose="VPC_PEERING",
    prefix_length=16,
    network=default.id)
vpc_connection = gcp.servicenetworking.Connection("vpc_connection",
    network=default.id,
    service="servicenetworking.googleapis.com",
    reserved_peering_ranges=[private_ip_alloc.name])
alloydbprofile = gcp.databasemigrationservice.ConnectionProfile("alloydbprofile",
    location="us-central1",
    connection_profile_id="my-profileid",
    display_name="my-profileid_display",
    labels={
        "foo": "bar",
    },
    alloydb={
        "cluster_id": "tf-test-dbmsalloycluster_52865",
        "settings": {
            "initial_user": {
                "user": "alloyuser_85840",
                "password": "alloypass_60302",
            },
            "vpc_network": default.id,
            "labels": {
                "alloyfoo": "alloybar",
            },
            "primary_instance_settings": {
                "id": "priminstid",
                "machine_config": {
                    "cpu_count": 2,
                },
                "database_flags": {},
                "labels": {
                    "alloysinstfoo": "allowinstbar",
                },
            },
        },
    },
    opts = pulumi.ResourceOptions(depends_on=[vpc_connection]))
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var project = Gcp.Organizations.GetProject.Invoke();

    var @default = new Gcp.Compute.Network("default", new()
    {
        Name = "vpc-network",
    });

    var privateIpAlloc = new Gcp.Compute.GlobalAddress("private_ip_alloc", new()
    {
        Name = "private-ip-alloc",
        AddressType = "INTERNAL",
        Purpose = "VPC_PEERING",
        PrefixLength = 16,
        Network = @default.Id,
    });

    var vpcConnection = new Gcp.ServiceNetworking.Connection("vpc_connection", new()
    {
        Network = @default.Id,
        Service = "servicenetworking.googleapis.com",
        ReservedPeeringRanges = new[]
        {
            privateIpAlloc.Name,
        },
    });

    var alloydbprofile = new Gcp.DatabaseMigrationService.ConnectionProfile("alloydbprofile", new()
    {
        Location = "us-central1",
        ConnectionProfileId = "my-profileid",
        DisplayName = "my-profileid_display",
        Labels = 
        {
            { "foo", "bar" },
        },
        Alloydb = new Gcp.DatabaseMigrationService.Inputs.ConnectionProfileAlloydbArgs
        {
            ClusterId = "tf-test-dbmsalloycluster_52865",
            Settings = new Gcp.DatabaseMigrationService.Inputs.ConnectionProfileAlloydbSettingsArgs
            {
                InitialUser = new Gcp.DatabaseMigrationService.Inputs.ConnectionProfileAlloydbSettingsInitialUserArgs
                {
                    User = "alloyuser_85840",
                    Password = "alloypass_60302",
                },
                VpcNetwork = @default.Id,
                Labels = 
                {
                    { "alloyfoo", "alloybar" },
                },
                PrimaryInstanceSettings = new Gcp.DatabaseMigrationService.Inputs.ConnectionProfileAlloydbSettingsPrimaryInstanceSettingsArgs
                {
                    Id = "priminstid",
                    MachineConfig = new Gcp.DatabaseMigrationService.Inputs.ConnectionProfileAlloydbSettingsPrimaryInstanceSettingsMachineConfigArgs
                    {
                        CpuCount = 2,
                    },
                    DatabaseFlags = null,
                    Labels = 
                    {
                        { "alloysinstfoo", "allowinstbar" },
                    },
                },
            },
        },
    }, new CustomResourceOptions
    {
        DependsOn =
        {
            vpcConnection,
        },
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/compute"
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/databasemigrationservice"
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/organizations"
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/servicenetworking"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		_, err := organizations.LookupProject(ctx, &organizations.LookupProjectArgs{}, nil)
		if err != nil {
			return err
		}
		_, err = compute.NewNetwork(ctx, "default", &compute.NetworkArgs{
			Name: pulumi.String("vpc-network"),
		})
		if err != nil {
			return err
		}
		privateIpAlloc, err := compute.NewGlobalAddress(ctx, "private_ip_alloc", &compute.GlobalAddressArgs{
			Name:         pulumi.String("private-ip-alloc"),
			AddressType:  pulumi.String("INTERNAL"),
			Purpose:      pulumi.String("VPC_PEERING"),
			PrefixLength: pulumi.Int(16),
			Network:      _default.ID(),
		})
		if err != nil {
			return err
		}
		vpcConnection, err := servicenetworking.NewConnection(ctx, "vpc_connection", &servicenetworking.ConnectionArgs{
			Network: _default.ID(),
			Service: pulumi.String("servicenetworking.googleapis.com"),
			ReservedPeeringRanges: pulumi.StringArray{
				privateIpAlloc.Name,
			},
		})
		if err != nil {
			return err
		}
		_, err = databasemigrationservice.NewConnectionProfile(ctx, "alloydbprofile", &databasemigrationservice.ConnectionProfileArgs{
			Location:            pulumi.String("us-central1"),
			ConnectionProfileId: pulumi.String("my-profileid"),
			DisplayName:         pulumi.String("my-profileid_display"),
			Labels: pulumi.StringMap{
				"foo": pulumi.String("bar"),
			},
			Alloydb: &databasemigrationservice.ConnectionProfileAlloydbArgs{
				ClusterId: pulumi.String("tf-test-dbmsalloycluster_52865"),
				Settings: &databasemigrationservice.ConnectionProfileAlloydbSettingsArgs{
					InitialUser: &databasemigrationservice.ConnectionProfileAlloydbSettingsInitialUserArgs{
						User:     pulumi.String("alloyuser_85840"),
						Password: pulumi.String("alloypass_60302"),
					},
					VpcNetwork: _default.ID(),
					Labels: pulumi.StringMap{
						"alloyfoo": pulumi.String("alloybar"),
					},
					PrimaryInstanceSettings: &databasemigrationservice.ConnectionProfileAlloydbSettingsPrimaryInstanceSettingsArgs{
						Id: pulumi.String("priminstid"),
						MachineConfig: &databasemigrationservice.ConnectionProfileAlloydbSettingsPrimaryInstanceSettingsMachineConfigArgs{
							CpuCount: pulumi.Int(2),
						},
						DatabaseFlags: pulumi.StringMap{},
						Labels: pulumi.StringMap{
							"alloysinstfoo": pulumi.String("allowinstbar"),
						},
					},
				},
			},
		}, pulumi.DependsOn([]pulumi.Resource{
			vpcConnection,
		}))
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.organizations.OrganizationsFunctions;
import com.pulumi.gcp.organizations.inputs.GetProjectArgs;
import com.pulumi.gcp.compute.Network;
import com.pulumi.gcp.compute.NetworkArgs;
import com.pulumi.gcp.compute.GlobalAddress;
import com.pulumi.gcp.compute.GlobalAddressArgs;
import com.pulumi.gcp.servicenetworking.Connection;
import com.pulumi.gcp.servicenetworking.ConnectionArgs;
import com.pulumi.gcp.databasemigrationservice.ConnectionProfile;
import com.pulumi.gcp.databasemigrationservice.ConnectionProfileArgs;
import com.pulumi.gcp.databasemigrationservice.inputs.ConnectionProfileAlloydbArgs;
import com.pulumi.gcp.databasemigrationservice.inputs.ConnectionProfileAlloydbSettingsArgs;
import com.pulumi.gcp.databasemigrationservice.inputs.ConnectionProfileAlloydbSettingsInitialUserArgs;
import com.pulumi.gcp.databasemigrationservice.inputs.ConnectionProfileAlloydbSettingsPrimaryInstanceSettingsArgs;
import com.pulumi.gcp.databasemigrationservice.inputs.ConnectionProfileAlloydbSettingsPrimaryInstanceSettingsMachineConfigArgs;
import com.pulumi.resources.CustomResourceOptions;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        final var project = OrganizationsFunctions.getProject();

        var default_ = new Network("default", NetworkArgs.builder()
            .name("vpc-network")
            .build());

        var privateIpAlloc = new GlobalAddress("privateIpAlloc", GlobalAddressArgs.builder()
            .name("private-ip-alloc")
            .addressType("INTERNAL")
            .purpose("VPC_PEERING")
            .prefixLength(16)
            .network(default_.id())
            .build());

        var vpcConnection = new Connection("vpcConnection", ConnectionArgs.builder()
            .network(default_.id())
            .service("servicenetworking.googleapis.com")
            .reservedPeeringRanges(privateIpAlloc.name())
            .build());

        var alloydbprofile = new ConnectionProfile("alloydbprofile", ConnectionProfileArgs.builder()
            .location("us-central1")
            .connectionProfileId("my-profileid")
            .displayName("my-profileid_display")
            .labels(Map.of("foo", "bar"))
            .alloydb(ConnectionProfileAlloydbArgs.builder()
                .clusterId("tf-test-dbmsalloycluster_52865")
                .settings(ConnectionProfileAlloydbSettingsArgs.builder()
                    .initialUser(ConnectionProfileAlloydbSettingsInitialUserArgs.builder()
                        .user("alloyuser_85840")
                        .password("alloypass_60302")
                        .build())
                    .vpcNetwork(default_.id())
                    .labels(Map.of("alloyfoo", "alloybar"))
                    .primaryInstanceSettings(ConnectionProfileAlloydbSettingsPrimaryInstanceSettingsArgs.builder()
                        .id("priminstid")
                        .machineConfig(ConnectionProfileAlloydbSettingsPrimaryInstanceSettingsMachineConfigArgs.builder()
                            .cpuCount(2)
                            .build())
                        .databaseFlags()
                        .labels(Map.of("alloysinstfoo", "allowinstbar"))
                        .build())
                    .build())
                .build())
            .build(), CustomResourceOptions.builder()
                .dependsOn(vpcConnection)
                .build());

    }
}
```
```yaml
resources:
  default:
    type: gcp:compute:Network
    properties:
      name: vpc-network
  privateIpAlloc:
    type: gcp:compute:GlobalAddress
    name: private_ip_alloc
    properties:
      name: private-ip-alloc
      addressType: INTERNAL
      purpose: VPC_PEERING
      prefixLength: 16
      network: ${default.id}
  vpcConnection:
    type: gcp:servicenetworking:Connection
    name: vpc_connection
    properties:
      network: ${default.id}
      service: servicenetworking.googleapis.com
      reservedPeeringRanges:
        - ${privateIpAlloc.name}
  alloydbprofile:
    type: gcp:databasemigrationservice:ConnectionProfile
    properties:
      location: us-central1
      connectionProfileId: my-profileid
      displayName: my-profileid_display
      labels:
        foo: bar
      alloydb:
        clusterId: tf-test-dbmsalloycluster_52865
        settings:
          initialUser:
            user: alloyuser_85840
            password: alloypass_60302
          vpcNetwork: ${default.id}
          labels:
            alloyfoo: alloybar
          primaryInstanceSettings:
            id: priminstid
            machineConfig:
              cpuCount: 2
            databaseFlags: {}
            labels:
              alloysinstfoo: allowinstbar
    options:
      dependsOn:
        - ${vpcConnection}
variables:
  project:
    fn::invoke:
      function: gcp:organizations:getProject
      arguments: {}
```
<!--End PulumiCodeChooser -->
### Database Migration Service Connection Profile Existing Mysql


<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const project = gcp.organizations.getProject({});
const destinationCsql = new gcp.sql.DatabaseInstance("destination_csql", {
    name: "destination-csql",
    databaseVersion: "MYSQL_5_7",
    settings: {
        tier: "db-n1-standard-1",
        deletionProtectionEnabled: false,
    },
    deletionProtection: false,
});
const existing_mysql = new gcp.databasemigrationservice.ConnectionProfile("existing-mysql", {
    location: "us-central1",
    connectionProfileId: "destination-cp",
    displayName: "destination-cp_display",
    labels: {
        foo: "bar",
    },
    mysql: {
        cloudSqlId: "destination-csql",
    },
}, {
    dependsOn: [destinationCsql],
});
```
```python
import pulumi
import pulumi_gcp as gcp

project = gcp.organizations.get_project()
destination_csql = gcp.sql.DatabaseInstance("destination_csql",
    name="destination-csql",
    database_version="MYSQL_5_7",
    settings={
        "tier": "db-n1-standard-1",
        "deletion_protection_enabled": False,
    },
    deletion_protection=False)
existing_mysql = gcp.databasemigrationservice.ConnectionProfile("existing-mysql",
    location="us-central1",
    connection_profile_id="destination-cp",
    display_name="destination-cp_display",
    labels={
        "foo": "bar",
    },
    mysql={
        "cloud_sql_id": "destination-csql",
    },
    opts = pulumi.ResourceOptions(depends_on=[destination_csql]))
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var project = Gcp.Organizations.GetProject.Invoke();

    var destinationCsql = new Gcp.Sql.DatabaseInstance("destination_csql", new()
    {
        Name = "destination-csql",
        DatabaseVersion = "MYSQL_5_7",
        Settings = new Gcp.Sql.Inputs.DatabaseInstanceSettingsArgs
        {
            Tier = "db-n1-standard-1",
            DeletionProtectionEnabled = false,
        },
        DeletionProtection = false,
    });

    var existing_mysql = new Gcp.DatabaseMigrationService.ConnectionProfile("existing-mysql", new()
    {
        Location = "us-central1",
        ConnectionProfileId = "destination-cp",
        DisplayName = "destination-cp_display",
        Labels = 
        {
            { "foo", "bar" },
        },
        Mysql = new Gcp.DatabaseMigrationService.Inputs.ConnectionProfileMysqlArgs
        {
            CloudSqlId = "destination-csql",
        },
    }, new CustomResourceOptions
    {
        DependsOn =
        {
            destinationCsql,
        },
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/databasemigrationservice"
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/organizations"
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/sql"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		_, err := organizations.LookupProject(ctx, &organizations.LookupProjectArgs{}, nil)
		if err != nil {
			return err
		}
		destinationCsql, err := sql.NewDatabaseInstance(ctx, "destination_csql", &sql.DatabaseInstanceArgs{
			Name:            pulumi.String("destination-csql"),
			DatabaseVersion: pulumi.String("MYSQL_5_7"),
			Settings: &sql.DatabaseInstanceSettingsArgs{
				Tier:                      pulumi.String("db-n1-standard-1"),
				DeletionProtectionEnabled: pulumi.Bool(false),
			},
			DeletionProtection: pulumi.Bool(false),
		})
		if err != nil {
			return err
		}
		_, err = databasemigrationservice.NewConnectionProfile(ctx, "existing-mysql", &databasemigrationservice.ConnectionProfileArgs{
			Location:            pulumi.String("us-central1"),
			ConnectionProfileId: pulumi.String("destination-cp"),
			DisplayName:         pulumi.String("destination-cp_display"),
			Labels: pulumi.StringMap{
				"foo": pulumi.String("bar"),
			},
			Mysql: &databasemigrationservice.ConnectionProfileMysqlArgs{
				CloudSqlId: pulumi.String("destination-csql"),
			},
		}, pulumi.DependsOn([]pulumi.Resource{
			destinationCsql,
		}))
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.organizations.OrganizationsFunctions;
import com.pulumi.gcp.organizations.inputs.GetProjectArgs;
import com.pulumi.gcp.sql.DatabaseInstance;
import com.pulumi.gcp.sql.DatabaseInstanceArgs;
import com.pulumi.gcp.sql.inputs.DatabaseInstanceSettingsArgs;
import com.pulumi.gcp.databasemigrationservice.ConnectionProfile;
import com.pulumi.gcp.databasemigrationservice.ConnectionProfileArgs;
import com.pulumi.gcp.databasemigrationservice.inputs.ConnectionProfileMysqlArgs;
import com.pulumi.resources.CustomResourceOptions;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        final var project = OrganizationsFunctions.getProject();

        var destinationCsql = new DatabaseInstance("destinationCsql", DatabaseInstanceArgs.builder()
            .name("destination-csql")
            .databaseVersion("MYSQL_5_7")
            .settings(DatabaseInstanceSettingsArgs.builder()
                .tier("db-n1-standard-1")
                .deletionProtectionEnabled(false)
                .build())
            .deletionProtection(false)
            .build());

        var existing_mysql = new ConnectionProfile("existing-mysql", ConnectionProfileArgs.builder()
            .location("us-central1")
            .connectionProfileId("destination-cp")
            .displayName("destination-cp_display")
            .labels(Map.of("foo", "bar"))
            .mysql(ConnectionProfileMysqlArgs.builder()
                .cloudSqlId("destination-csql")
                .build())
            .build(), CustomResourceOptions.builder()
                .dependsOn(destinationCsql)
                .build());

    }
}
```
```yaml
resources:
  destinationCsql:
    type: gcp:sql:DatabaseInstance
    name: destination_csql
    properties:
      name: destination-csql
      databaseVersion: MYSQL_5_7
      settings:
        tier: db-n1-standard-1
        deletionProtectionEnabled: false
      deletionProtection: false
  existing-mysql:
    type: gcp:databasemigrationservice:ConnectionProfile
    properties:
      location: us-central1
      connectionProfileId: destination-cp
      displayName: destination-cp_display
      labels:
        foo: bar
      mysql:
        cloudSqlId: destination-csql
    options:
      dependsOn:
        - ${destinationCsql}
variables:
  project:
    fn::invoke:
      function: gcp:organizations:getProject
      arguments: {}
```
<!--End PulumiCodeChooser -->
### Database Migration Service Connection Profile Existing Postgres


<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const project = gcp.organizations.getProject({});
const destinationCsql = new gcp.sql.DatabaseInstance("destination_csql", {
    name: "destination-csql",
    databaseVersion: "POSTGRES_15",
    settings: {
        tier: "db-custom-2-13312",
        deletionProtectionEnabled: false,
    },
    deletionProtection: false,
});
const existing_psql = new gcp.databasemigrationservice.ConnectionProfile("existing-psql", {
    location: "us-central1",
    connectionProfileId: "destination-cp",
    displayName: "destination-cp_display",
    labels: {
        foo: "bar",
    },
    postgresql: {
        cloudSqlId: "destination-csql",
    },
}, {
    dependsOn: [destinationCsql],
});
```
```python
import pulumi
import pulumi_gcp as gcp

project = gcp.organizations.get_project()
destination_csql = gcp.sql.DatabaseInstance("destination_csql",
    name="destination-csql",
    database_version="POSTGRES_15",
    settings={
        "tier": "db-custom-2-13312",
        "deletion_protection_enabled": False,
    },
    deletion_protection=False)
existing_psql = gcp.databasemigrationservice.ConnectionProfile("existing-psql",
    location="us-central1",
    connection_profile_id="destination-cp",
    display_name="destination-cp_display",
    labels={
        "foo": "bar",
    },
    postgresql={
        "cloud_sql_id": "destination-csql",
    },
    opts = pulumi.ResourceOptions(depends_on=[destination_csql]))
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var project = Gcp.Organizations.GetProject.Invoke();

    var destinationCsql = new Gcp.Sql.DatabaseInstance("destination_csql", new()
    {
        Name = "destination-csql",
        DatabaseVersion = "POSTGRES_15",
        Settings = new Gcp.Sql.Inputs.DatabaseInstanceSettingsArgs
        {
            Tier = "db-custom-2-13312",
            DeletionProtectionEnabled = false,
        },
        DeletionProtection = false,
    });

    var existing_psql = new Gcp.DatabaseMigrationService.ConnectionProfile("existing-psql", new()
    {
        Location = "us-central1",
        ConnectionProfileId = "destination-cp",
        DisplayName = "destination-cp_display",
        Labels = 
        {
            { "foo", "bar" },
        },
        Postgresql = new Gcp.DatabaseMigrationService.Inputs.ConnectionProfilePostgresqlArgs
        {
            CloudSqlId = "destination-csql",
        },
    }, new CustomResourceOptions
    {
        DependsOn =
        {
            destinationCsql,
        },
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/databasemigrationservice"
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/organizations"
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/sql"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		_, err := organizations.LookupProject(ctx, &organizations.LookupProjectArgs{}, nil)
		if err != nil {
			return err
		}
		destinationCsql, err := sql.NewDatabaseInstance(ctx, "destination_csql", &sql.DatabaseInstanceArgs{
			Name:            pulumi.String("destination-csql"),
			DatabaseVersion: pulumi.String("POSTGRES_15"),
			Settings: &sql.DatabaseInstanceSettingsArgs{
				Tier:                      pulumi.String("db-custom-2-13312"),
				DeletionProtectionEnabled: pulumi.Bool(false),
			},
			DeletionProtection: pulumi.Bool(false),
		})
		if err != nil {
			return err
		}
		_, err = databasemigrationservice.NewConnectionProfile(ctx, "existing-psql", &databasemigrationservice.ConnectionProfileArgs{
			Location:            pulumi.String("us-central1"),
			ConnectionProfileId: pulumi.String("destination-cp"),
			DisplayName:         pulumi.String("destination-cp_display"),
			Labels: pulumi.StringMap{
				"foo": pulumi.String("bar"),
			},
			Postgresql: &databasemigrationservice.ConnectionProfilePostgresqlArgs{
				CloudSqlId: pulumi.String("destination-csql"),
			},
		}, pulumi.DependsOn([]pulumi.Resource{
			destinationCsql,
		}))
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.organizations.OrganizationsFunctions;
import com.pulumi.gcp.organizations.inputs.GetProjectArgs;
import com.pulumi.gcp.sql.DatabaseInstance;
import com.pulumi.gcp.sql.DatabaseInstanceArgs;
import com.pulumi.gcp.sql.inputs.DatabaseInstanceSettingsArgs;
import com.pulumi.gcp.databasemigrationservice.ConnectionProfile;
import com.pulumi.gcp.databasemigrationservice.ConnectionProfileArgs;
import com.pulumi.gcp.databasemigrationservice.inputs.ConnectionProfilePostgresqlArgs;
import com.pulumi.resources.CustomResourceOptions;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        final var project = OrganizationsFunctions.getProject();

        var destinationCsql = new DatabaseInstance("destinationCsql", DatabaseInstanceArgs.builder()
            .name("destination-csql")
            .databaseVersion("POSTGRES_15")
            .settings(DatabaseInstanceSettingsArgs.builder()
                .tier("db-custom-2-13312")
                .deletionProtectionEnabled(false)
                .build())
            .deletionProtection(false)
            .build());

        var existing_psql = new ConnectionProfile("existing-psql", ConnectionProfileArgs.builder()
            .location("us-central1")
            .connectionProfileId("destination-cp")
            .displayName("destination-cp_display")
            .labels(Map.of("foo", "bar"))
            .postgresql(ConnectionProfilePostgresqlArgs.builder()
                .cloudSqlId("destination-csql")
                .build())
            .build(), CustomResourceOptions.builder()
                .dependsOn(destinationCsql)
                .build());

    }
}
```
```yaml
resources:
  destinationCsql:
    type: gcp:sql:DatabaseInstance
    name: destination_csql
    properties:
      name: destination-csql
      databaseVersion: POSTGRES_15
      settings:
        tier: db-custom-2-13312
        deletionProtectionEnabled: false
      deletionProtection: false
  existing-psql:
    type: gcp:databasemigrationservice:ConnectionProfile
    properties:
      location: us-central1
      connectionProfileId: destination-cp
      displayName: destination-cp_display
      labels:
        foo: bar
      postgresql:
        cloudSqlId: destination-csql
    options:
      dependsOn:
        - ${destinationCsql}
variables:
  project:
    fn::invoke:
      function: gcp:organizations:getProject
      arguments: {}
```
<!--End PulumiCodeChooser -->
### Database Migration Service Connection Profile Existing Alloydb


<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const project = gcp.organizations.getProject({});
const _default = new gcp.compute.Network("default", {name: "destination-alloydb"});
const destinationAlloydb = new gcp.alloydb.Cluster("destination_alloydb", {
    clusterId: "destination-alloydb",
    location: "us-central1",
    networkConfig: {
        network: _default.id,
    },
    databaseVersion: "POSTGRES_15",
    initialUser: {
        user: "destination-alloydb",
        password: "destination-alloydb",
    },
});
const privateIpAlloc = new gcp.compute.GlobalAddress("private_ip_alloc", {
    name: "destination-alloydb",
    addressType: "INTERNAL",
    purpose: "VPC_PEERING",
    prefixLength: 16,
    network: _default.id,
});
const vpcConnection = new gcp.servicenetworking.Connection("vpc_connection", {
    network: _default.id,
    service: "servicenetworking.googleapis.com",
    reservedPeeringRanges: [privateIpAlloc.name],
});
const destinationAlloydbPrimary = new gcp.alloydb.Instance("destination_alloydb_primary", {
    cluster: destinationAlloydb.name,
    instanceId: "destination-alloydb-primary",
    instanceType: "PRIMARY",
}, {
    dependsOn: [vpcConnection],
});
const existing_alloydb = new gcp.databasemigrationservice.ConnectionProfile("existing-alloydb", {
    location: "us-central1",
    connectionProfileId: "destination-cp",
    displayName: "destination-cp_display",
    labels: {
        foo: "bar",
    },
    postgresql: {
        alloydbClusterId: "destination-alloydb",
    },
}, {
    dependsOn: [
        destinationAlloydb,
        destinationAlloydbPrimary,
    ],
});
```
```python
import pulumi
import pulumi_gcp as gcp

project = gcp.organizations.get_project()
default = gcp.compute.Network("default", name="destination-alloydb")
destination_alloydb = gcp.alloydb.Cluster("destination_alloydb",
    cluster_id="destination-alloydb",
    location="us-central1",
    network_config={
        "network": default.id,
    },
    database_version="POSTGRES_15",
    initial_user={
        "user": "destination-alloydb",
        "password": "destination-alloydb",
    })
private_ip_alloc = gcp.compute.GlobalAddress("private_ip_alloc",
    name="destination-alloydb",
    address_type="INTERNAL",
    purpose="VPC_PEERING",
    prefix_length=16,
    network=default.id)
vpc_connection = gcp.servicenetworking.Connection("vpc_connection",
    network=default.id,
    service="servicenetworking.googleapis.com",
    reserved_peering_ranges=[private_ip_alloc.name])
destination_alloydb_primary = gcp.alloydb.Instance("destination_alloydb_primary",
    cluster=destination_alloydb.name,
    instance_id="destination-alloydb-primary",
    instance_type="PRIMARY",
    opts = pulumi.ResourceOptions(depends_on=[vpc_connection]))
existing_alloydb = gcp.databasemigrationservice.ConnectionProfile("existing-alloydb",
    location="us-central1",
    connection_profile_id="destination-cp",
    display_name="destination-cp_display",
    labels={
        "foo": "bar",
    },
    postgresql={
        "alloydb_cluster_id": "destination-alloydb",
    },
    opts = pulumi.ResourceOptions(depends_on=[
            destination_alloydb,
            destination_alloydb_primary,
        ]))
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var project = Gcp.Organizations.GetProject.Invoke();

    var @default = new Gcp.Compute.Network("default", new()
    {
        Name = "destination-alloydb",
    });

    var destinationAlloydb = new Gcp.Alloydb.Cluster("destination_alloydb", new()
    {
        ClusterId = "destination-alloydb",
        Location = "us-central1",
        NetworkConfig = new Gcp.Alloydb.Inputs.ClusterNetworkConfigArgs
        {
            Network = @default.Id,
        },
        DatabaseVersion = "POSTGRES_15",
        InitialUser = new Gcp.Alloydb.Inputs.ClusterInitialUserArgs
        {
            User = "destination-alloydb",
            Password = "destination-alloydb",
        },
    });

    var privateIpAlloc = new Gcp.Compute.GlobalAddress("private_ip_alloc", new()
    {
        Name = "destination-alloydb",
        AddressType = "INTERNAL",
        Purpose = "VPC_PEERING",
        PrefixLength = 16,
        Network = @default.Id,
    });

    var vpcConnection = new Gcp.ServiceNetworking.Connection("vpc_connection", new()
    {
        Network = @default.Id,
        Service = "servicenetworking.googleapis.com",
        ReservedPeeringRanges = new[]
        {
            privateIpAlloc.Name,
        },
    });

    var destinationAlloydbPrimary = new Gcp.Alloydb.Instance("destination_alloydb_primary", new()
    {
        Cluster = destinationAlloydb.Name,
        InstanceId = "destination-alloydb-primary",
        InstanceType = "PRIMARY",
    }, new CustomResourceOptions
    {
        DependsOn =
        {
            vpcConnection,
        },
    });

    var existing_alloydb = new Gcp.DatabaseMigrationService.ConnectionProfile("existing-alloydb", new()
    {
        Location = "us-central1",
        ConnectionProfileId = "destination-cp",
        DisplayName = "destination-cp_display",
        Labels = 
        {
            { "foo", "bar" },
        },
        Postgresql = new Gcp.DatabaseMigrationService.Inputs.ConnectionProfilePostgresqlArgs
        {
            AlloydbClusterId = "destination-alloydb",
        },
    }, new CustomResourceOptions
    {
        DependsOn =
        {
            destinationAlloydb,
            destinationAlloydbPrimary,
        },
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/alloydb"
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/compute"
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/databasemigrationservice"
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/organizations"
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/servicenetworking"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		_, err := organizations.LookupProject(ctx, &organizations.LookupProjectArgs{}, nil)
		if err != nil {
			return err
		}
		_, err = compute.NewNetwork(ctx, "default", &compute.NetworkArgs{
			Name: pulumi.String("destination-alloydb"),
		})
		if err != nil {
			return err
		}
		destinationAlloydb, err := alloydb.NewCluster(ctx, "destination_alloydb", &alloydb.ClusterArgs{
			ClusterId: pulumi.String("destination-alloydb"),
			Location:  pulumi.String("us-central1"),
			NetworkConfig: &alloydb.ClusterNetworkConfigArgs{
				Network: _default.ID(),
			},
			DatabaseVersion: pulumi.String("POSTGRES_15"),
			InitialUser: &alloydb.ClusterInitialUserArgs{
				User:     pulumi.String("destination-alloydb"),
				Password: pulumi.String("destination-alloydb"),
			},
		})
		if err != nil {
			return err
		}
		privateIpAlloc, err := compute.NewGlobalAddress(ctx, "private_ip_alloc", &compute.GlobalAddressArgs{
			Name:         pulumi.String("destination-alloydb"),
			AddressType:  pulumi.String("INTERNAL"),
			Purpose:      pulumi.String("VPC_PEERING"),
			PrefixLength: pulumi.Int(16),
			Network:      _default.ID(),
		})
		if err != nil {
			return err
		}
		vpcConnection, err := servicenetworking.NewConnection(ctx, "vpc_connection", &servicenetworking.ConnectionArgs{
			Network: _default.ID(),
			Service: pulumi.String("servicenetworking.googleapis.com"),
			ReservedPeeringRanges: pulumi.StringArray{
				privateIpAlloc.Name,
			},
		})
		if err != nil {
			return err
		}
		destinationAlloydbPrimary, err := alloydb.NewInstance(ctx, "destination_alloydb_primary", &alloydb.InstanceArgs{
			Cluster:      destinationAlloydb.Name,
			InstanceId:   pulumi.String("destination-alloydb-primary"),
			InstanceType: pulumi.String("PRIMARY"),
		}, pulumi.DependsOn([]pulumi.Resource{
			vpcConnection,
		}))
		if err != nil {
			return err
		}
		_, err = databasemigrationservice.NewConnectionProfile(ctx, "existing-alloydb", &databasemigrationservice.ConnectionProfileArgs{
			Location:            pulumi.String("us-central1"),
			ConnectionProfileId: pulumi.String("destination-cp"),
			DisplayName:         pulumi.String("destination-cp_display"),
			Labels: pulumi.StringMap{
				"foo": pulumi.String("bar"),
			},
			Postgresql: &databasemigrationservice.ConnectionProfilePostgresqlArgs{
				AlloydbClusterId: pulumi.String("destination-alloydb"),
			},
		}, pulumi.DependsOn([]pulumi.Resource{
			destinationAlloydb,
			destinationAlloydbPrimary,
		}))
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.organizations.OrganizationsFunctions;
import com.pulumi.gcp.organizations.inputs.GetProjectArgs;
import com.pulumi.gcp.compute.Network;
import com.pulumi.gcp.compute.NetworkArgs;
import com.pulumi.gcp.alloydb.Cluster;
import com.pulumi.gcp.alloydb.ClusterArgs;
import com.pulumi.gcp.alloydb.inputs.ClusterNetworkConfigArgs;
import com.pulumi.gcp.alloydb.inputs.ClusterInitialUserArgs;
import com.pulumi.gcp.compute.GlobalAddress;
import com.pulumi.gcp.compute.GlobalAddressArgs;
import com.pulumi.gcp.servicenetworking.Connection;
import com.pulumi.gcp.servicenetworking.ConnectionArgs;
import com.pulumi.gcp.alloydb.Instance;
import com.pulumi.gcp.alloydb.InstanceArgs;
import com.pulumi.gcp.databasemigrationservice.ConnectionProfile;
import com.pulumi.gcp.databasemigrationservice.ConnectionProfileArgs;
import com.pulumi.gcp.databasemigrationservice.inputs.ConnectionProfilePostgresqlArgs;
import com.pulumi.resources.CustomResourceOptions;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        final var project = OrganizationsFunctions.getProject();

        var default_ = new Network("default", NetworkArgs.builder()
            .name("destination-alloydb")
            .build());

        var destinationAlloydb = new Cluster("destinationAlloydb", ClusterArgs.builder()
            .clusterId("destination-alloydb")
            .location("us-central1")
            .networkConfig(ClusterNetworkConfigArgs.builder()
                .network(default_.id())
                .build())
            .databaseVersion("POSTGRES_15")
            .initialUser(ClusterInitialUserArgs.builder()
                .user("destination-alloydb")
                .password("destination-alloydb")
                .build())
            .build());

        var privateIpAlloc = new GlobalAddress("privateIpAlloc", GlobalAddressArgs.builder()
            .name("destination-alloydb")
            .addressType("INTERNAL")
            .purpose("VPC_PEERING")
            .prefixLength(16)
            .network(default_.id())
            .build());

        var vpcConnection = new Connection("vpcConnection", ConnectionArgs.builder()
            .network(default_.id())
            .service("servicenetworking.googleapis.com")
            .reservedPeeringRanges(privateIpAlloc.name())
            .build());

        var destinationAlloydbPrimary = new Instance("destinationAlloydbPrimary", InstanceArgs.builder()
            .cluster(destinationAlloydb.name())
            .instanceId("destination-alloydb-primary")
            .instanceType("PRIMARY")
            .build(), CustomResourceOptions.builder()
                .dependsOn(vpcConnection)
                .build());

        var existing_alloydb = new ConnectionProfile("existing-alloydb", ConnectionProfileArgs.builder()
            .location("us-central1")
            .connectionProfileId("destination-cp")
            .displayName("destination-cp_display")
            .labels(Map.of("foo", "bar"))
            .postgresql(ConnectionProfilePostgresqlArgs.builder()
                .alloydbClusterId("destination-alloydb")
                .build())
            .build(), CustomResourceOptions.builder()
                .dependsOn(                
                    destinationAlloydb,
                    destinationAlloydbPrimary)
                .build());

    }
}
```
```yaml
resources:
  destinationAlloydb:
    type: gcp:alloydb:Cluster
    name: destination_alloydb
    properties:
      clusterId: destination-alloydb
      location: us-central1
      networkConfig:
        network: ${default.id}
      databaseVersion: POSTGRES_15
      initialUser:
        user: destination-alloydb
        password: destination-alloydb
  destinationAlloydbPrimary:
    type: gcp:alloydb:Instance
    name: destination_alloydb_primary
    properties:
      cluster: ${destinationAlloydb.name}
      instanceId: destination-alloydb-primary
      instanceType: PRIMARY
    options:
      dependsOn:
        - ${vpcConnection}
  privateIpAlloc:
    type: gcp:compute:GlobalAddress
    name: private_ip_alloc
    properties:
      name: destination-alloydb
      addressType: INTERNAL
      purpose: VPC_PEERING
      prefixLength: 16
      network: ${default.id}
  vpcConnection:
    type: gcp:servicenetworking:Connection
    name: vpc_connection
    properties:
      network: ${default.id}
      service: servicenetworking.googleapis.com
      reservedPeeringRanges:
        - ${privateIpAlloc.name}
  default:
    type: gcp:compute:Network
    properties:
      name: destination-alloydb
  existing-alloydb:
    type: gcp:databasemigrationservice:ConnectionProfile
    properties:
      location: us-central1
      connectionProfileId: destination-cp
      displayName: destination-cp_display
      labels:
        foo: bar
      postgresql:
        alloydbClusterId: destination-alloydb
    options:
      dependsOn:
        - ${destinationAlloydb}
        - ${destinationAlloydbPrimary}
variables:
  project:
    fn::invoke:
      function: gcp:organizations:getProject
      arguments: {}
```
<!--End PulumiCodeChooser -->

## Import

ConnectionProfile can be imported using any of these accepted formats:

* `projects/{{project}}/locations/{{location}}/connectionProfiles/{{connection_profile_id}}`

* `{{project}}/{{location}}/{{connection_profile_id}}`

* `{{location}}/{{connection_profile_id}}`

When using the `pulumi import` command, ConnectionProfile can be imported using one of the formats above. For example:

```sh
$ pulumi import gcp:databasemigrationservice/connectionProfile:ConnectionProfile default projects/{{project}}/locations/{{location}}/connectionProfiles/{{connection_profile_id}}
```

```sh
$ pulumi import gcp:databasemigrationservice/connectionProfile:ConnectionProfile default {{project}}/{{location}}/{{connection_profile_id}}
```

```sh
$ pulumi import gcp:databasemigrationservice/connectionProfile:ConnectionProfile default {{location}}/{{connection_profile_id}}
```

«
alloydbB:

databasemigrationserviceConnectionProfileAlloydbNgcp:databasemigrationservice/ConnectionProfileAlloydb:ConnectionProfileAlloydbSpecifies required connection parameters, and the parameters required to create an AlloyDB destination cluster.
Structure is documented below.
Ç
cloudsqlB:

databasemigrationserviceConnectionProfileCloudsqlPgcp:databasemigrationservice/ConnectionProfileCloudsql:ConnectionProfileCloudsql§Specifies required connection parameters, and, optionally, the parameters required to create a Cloud SQL destination database instance.
Structure is documented below.
E
connectionProfileId" *The ID of the connection profile.


- - -
:
displayNameB" %The connection profile display name.
Õ
labelsB2" ÂThe resource labels for connection profile to use to annotate any related underlying resources such as Compute Engine VMs.

**Note**: This field is non-authoritative, and will only manage the labels present in your configuration.
Please refer to the field `effective_labels` for all of the labels present on the resource.
K
locationB" 9The location where the connection profile should reside.
ü
mysqlB:
~
databasemigrationserviceConnectionProfileMysqlJgcp:databasemigrationservice/ConnectionProfileMysql:ConnectionProfileMysqljSpecifies connection parameters required specifically for MySQL databases.
Structure is documented below.

oracleB:

databasemigrationserviceConnectionProfileOracleLgcp:databasemigrationservice/ConnectionProfileOracle:ConnectionProfileOraclekSpecifies connection parameters required specifically for Oracle databases.
Structure is documented below.


postgresqlB:

databasemigrationserviceConnectionProfilePostgresqlTgcp:databasemigrationservice/ConnectionProfilePostgresql:ConnectionProfilePostgresqloSpecifies connection parameters required specifically for PostgreSQL databases.
Structure is documented below.
{
projectB" jThe ID of the project in which the resource belongs.
If it is not provided, the provider project is used.
"«
alloydbB:

databasemigrationserviceConnectionProfileAlloydbNgcp:databasemigrationservice/ConnectionProfileAlloydb:ConnectionProfileAlloydbSpecifies required connection parameters, and the parameters required to create an AlloyDB destination cluster.
Structure is documented below.
"Ç
cloudsqlB:

databasemigrationserviceConnectionProfileCloudsqlPgcp:databasemigrationservice/ConnectionProfileCloudsql:ConnectionProfileCloudsql§Specifies required connection parameters, and, optionally, the parameters required to create a Cloud SQL destination database instance.
Structure is documented below.
"E
connectionProfileId" *The ID of the connection profile.


- - -
"»

createTime" ¨Output only. The timestamp when the resource was created. A timestamp in RFC3339 UTC 'Zulu' format, accurate to nanoseconds. Example: '2014-10-02T15:01:23.045123456Z'.
")

dbprovider" The database provider.
":
displayNameB" %The connection profile display name.
"¦
effectiveLabels2" All of labels (key/value pairs) present on the resource in GCP, including the labels configured through Pulumi, other clients and services.
"ê
errors*:
~
databasemigrationserviceConnectionProfileErrorJgcp:databasemigrationservice/ConnectionProfileError:ConnectionProfileErrorWOutput only. The error details in case of state FAILED.
Structure is documented below.
"Õ
labelsB2" ÂThe resource labels for connection profile to use to annotate any related underlying resources such as Compute Engine VMs.

**Note**: This field is non-authoritative, and will only manage the labels present in your configuration.
Please refer to the field `effective_labels` for all of the labels present on the resource.
"K
locationB" 9The location where the connection profile should reside.
"ü
mysqlB:
~
databasemigrationserviceConnectionProfileMysqlJgcp:databasemigrationservice/ConnectionProfileMysql:ConnectionProfileMysqljSpecifies connection parameters required specifically for MySQL databases.
Structure is documented below.
"
name" The name of this connection profile resource in the form of projects/{project}/locations/{location}/connectionProfiles/{connectionProfile}.
"
oracleB:

databasemigrationserviceConnectionProfileOracleLgcp:databasemigrationservice/ConnectionProfileOracle:ConnectionProfileOraclekSpecifies connection parameters required specifically for Oracle databases.
Structure is documented below.
"

postgresqlB:

databasemigrationserviceConnectionProfilePostgresqlTgcp:databasemigrationservice/ConnectionProfilePostgresql:ConnectionProfilePostgresqloSpecifies connection parameters required specifically for PostgreSQL databases.
Structure is documented below.
"y
project" jThe ID of the project in which the resource belongs.
If it is not provided, the provider project is used.
"
pulumiLabels2" mThe combination of labels configured directly on the resource
and default labels configured on the provider.
"3
state" &The current connection profile state.
*ôð
`
databasemigrationserviceMigrationJob6gcp:databasemigrationservice/migrationJob:MigrationJobÂºA migration job definition.


To get more information about MigrationJob, see:

* [API documentation](https://cloud.google.com/database-migration/docs/reference/rest/v1/projects.locations.migrationJobs/create)
* How-to Guides
    * [Database Migration](https://cloud.google.com/database-migration/docs/)

## Example Usage

### Database Migration Service Migration Job Mysql To Mysql


<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const project = gcp.organizations.getProject({});
const sourceCsql = new gcp.sql.DatabaseInstance("source_csql", {
    name: "source-csql",
    databaseVersion: "MYSQL_5_7",
    settings: {
        tier: "db-n1-standard-1",
        deletionProtectionEnabled: false,
    },
    deletionProtection: false,
});
const sourceSqlClientCert = new gcp.sql.SslCert("source_sql_client_cert", {
    commonName: "cert",
    instance: sourceCsql.name,
}, {
    dependsOn: [sourceCsql],
});
const sourceSqldbUser = new gcp.sql.User("source_sqldb_user", {
    name: "username",
    instance: sourceCsql.name,
    password: "password",
}, {
    dependsOn: [sourceSqlClientCert],
});
const sourceCp = new gcp.databasemigrationservice.ConnectionProfile("source_cp", {
    location: "us-central1",
    connectionProfileId: "source-cp",
    displayName: "source-cp_display",
    labels: {
        foo: "bar",
    },
    mysql: {
        host: sourceCsql.ipAddresses.apply(ipAddresses => ipAddresses[0].ipAddress),
        port: 3306,
        username: sourceSqldbUser.name,
        password: sourceSqldbUser.password,
        ssl: {
            clientKey: sourceSqlClientCert.privateKey,
            clientCertificate: sourceSqlClientCert.cert,
            caCertificate: sourceSqlClientCert.serverCaCert,
        },
        cloudSqlId: "source-csql",
    },
}, {
    dependsOn: [sourceSqldbUser],
});
const destinationCsql = new gcp.sql.DatabaseInstance("destination_csql", {
    name: "destination-csql",
    databaseVersion: "MYSQL_5_7",
    settings: {
        tier: "db-n1-standard-1",
        deletionProtectionEnabled: false,
    },
    deletionProtection: false,
});
const destinationCp = new gcp.databasemigrationservice.ConnectionProfile("destination_cp", {
    location: "us-central1",
    connectionProfileId: "destination-cp",
    displayName: "destination-cp_display",
    labels: {
        foo: "bar",
    },
    mysql: {
        cloudSqlId: "destination-csql",
    },
}, {
    dependsOn: [destinationCsql],
});
const _default = new gcp.compute.Network("default", {name: "destination-csql"});
const mysqltomysql = new gcp.databasemigrationservice.MigrationJob("mysqltomysql", {
    location: "us-central1",
    migrationJobId: "my-migrationid",
    displayName: "my-migrationid_display",
    labels: {
        foo: "bar",
    },
    performanceConfig: {
        dumpParallelLevel: "MAX",
    },
    vpcPeeringConnectivity: {
        vpc: _default.id,
    },
    dumpType: "LOGICAL",
    dumpFlags: {
        dumpFlags: [{
            name: "max-allowed-packet",
            value: "1073741824",
        }],
    },
    source: sourceCp.name,
    destination: destinationCp.name,
    type: "CONTINUOUS",
});
```
```python
import pulumi
import pulumi_gcp as gcp

project = gcp.organizations.get_project()
source_csql = gcp.sql.DatabaseInstance("source_csql",
    name="source-csql",
    database_version="MYSQL_5_7",
    settings={
        "tier": "db-n1-standard-1",
        "deletion_protection_enabled": False,
    },
    deletion_protection=False)
source_sql_client_cert = gcp.sql.SslCert("source_sql_client_cert",
    common_name="cert",
    instance=source_csql.name,
    opts = pulumi.ResourceOptions(depends_on=[source_csql]))
source_sqldb_user = gcp.sql.User("source_sqldb_user",
    name="username",
    instance=source_csql.name,
    password="password",
    opts = pulumi.ResourceOptions(depends_on=[source_sql_client_cert]))
source_cp = gcp.databasemigrationservice.ConnectionProfile("source_cp",
    location="us-central1",
    connection_profile_id="source-cp",
    display_name="source-cp_display",
    labels={
        "foo": "bar",
    },
    mysql={
        "host": source_csql.ip_addresses[0].ip_address,
        "port": 3306,
        "username": source_sqldb_user.name,
        "password": source_sqldb_user.password,
        "ssl": {
            "client_key": source_sql_client_cert.private_key,
            "client_certificate": source_sql_client_cert.cert,
            "ca_certificate": source_sql_client_cert.server_ca_cert,
        },
        "cloud_sql_id": "source-csql",
    },
    opts = pulumi.ResourceOptions(depends_on=[source_sqldb_user]))
destination_csql = gcp.sql.DatabaseInstance("destination_csql",
    name="destination-csql",
    database_version="MYSQL_5_7",
    settings={
        "tier": "db-n1-standard-1",
        "deletion_protection_enabled": False,
    },
    deletion_protection=False)
destination_cp = gcp.databasemigrationservice.ConnectionProfile("destination_cp",
    location="us-central1",
    connection_profile_id="destination-cp",
    display_name="destination-cp_display",
    labels={
        "foo": "bar",
    },
    mysql={
        "cloud_sql_id": "destination-csql",
    },
    opts = pulumi.ResourceOptions(depends_on=[destination_csql]))
default = gcp.compute.Network("default", name="destination-csql")
mysqltomysql = gcp.databasemigrationservice.MigrationJob("mysqltomysql",
    location="us-central1",
    migration_job_id="my-migrationid",
    display_name="my-migrationid_display",
    labels={
        "foo": "bar",
    },
    performance_config={
        "dump_parallel_level": "MAX",
    },
    vpc_peering_connectivity={
        "vpc": default.id,
    },
    dump_type="LOGICAL",
    dump_flags={
        "dump_flags": [{
            "name": "max-allowed-packet",
            "value": "1073741824",
        }],
    },
    source=source_cp.name,
    destination=destination_cp.name,
    type="CONTINUOUS")
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var project = Gcp.Organizations.GetProject.Invoke();

    var sourceCsql = new Gcp.Sql.DatabaseInstance("source_csql", new()
    {
        Name = "source-csql",
        DatabaseVersion = "MYSQL_5_7",
        Settings = new Gcp.Sql.Inputs.DatabaseInstanceSettingsArgs
        {
            Tier = "db-n1-standard-1",
            DeletionProtectionEnabled = false,
        },
        DeletionProtection = false,
    });

    var sourceSqlClientCert = new Gcp.Sql.SslCert("source_sql_client_cert", new()
    {
        CommonName = "cert",
        Instance = sourceCsql.Name,
    }, new CustomResourceOptions
    {
        DependsOn =
        {
            sourceCsql,
        },
    });

    var sourceSqldbUser = new Gcp.Sql.User("source_sqldb_user", new()
    {
        Name = "username",
        Instance = sourceCsql.Name,
        Password = "password",
    }, new CustomResourceOptions
    {
        DependsOn =
        {
            sourceSqlClientCert,
        },
    });

    var sourceCp = new Gcp.DatabaseMigrationService.ConnectionProfile("source_cp", new()
    {
        Location = "us-central1",
        ConnectionProfileId = "source-cp",
        DisplayName = "source-cp_display",
        Labels = 
        {
            { "foo", "bar" },
        },
        Mysql = new Gcp.DatabaseMigrationService.Inputs.ConnectionProfileMysqlArgs
        {
            Host = sourceCsql.IpAddresses.Apply(ipAddresses => ipAddresses[0].IpAddress),
            Port = 3306,
            Username = sourceSqldbUser.Name,
            Password = sourceSqldbUser.Password,
            Ssl = new Gcp.DatabaseMigrationService.Inputs.ConnectionProfileMysqlSslArgs
            {
                ClientKey = sourceSqlClientCert.PrivateKey,
                ClientCertificate = sourceSqlClientCert.Cert,
                CaCertificate = sourceSqlClientCert.ServerCaCert,
            },
            CloudSqlId = "source-csql",
        },
    }, new CustomResourceOptions
    {
        DependsOn =
        {
            sourceSqldbUser,
        },
    });

    var destinationCsql = new Gcp.Sql.DatabaseInstance("destination_csql", new()
    {
        Name = "destination-csql",
        DatabaseVersion = "MYSQL_5_7",
        Settings = new Gcp.Sql.Inputs.DatabaseInstanceSettingsArgs
        {
            Tier = "db-n1-standard-1",
            DeletionProtectionEnabled = false,
        },
        DeletionProtection = false,
    });

    var destinationCp = new Gcp.DatabaseMigrationService.ConnectionProfile("destination_cp", new()
    {
        Location = "us-central1",
        ConnectionProfileId = "destination-cp",
        DisplayName = "destination-cp_display",
        Labels = 
        {
            { "foo", "bar" },
        },
        Mysql = new Gcp.DatabaseMigrationService.Inputs.ConnectionProfileMysqlArgs
        {
            CloudSqlId = "destination-csql",
        },
    }, new CustomResourceOptions
    {
        DependsOn =
        {
            destinationCsql,
        },
    });

    var @default = new Gcp.Compute.Network("default", new()
    {
        Name = "destination-csql",
    });

    var mysqltomysql = new Gcp.DatabaseMigrationService.MigrationJob("mysqltomysql", new()
    {
        Location = "us-central1",
        MigrationJobId = "my-migrationid",
        DisplayName = "my-migrationid_display",
        Labels = 
        {
            { "foo", "bar" },
        },
        PerformanceConfig = new Gcp.DatabaseMigrationService.Inputs.MigrationJobPerformanceConfigArgs
        {
            DumpParallelLevel = "MAX",
        },
        VpcPeeringConnectivity = new Gcp.DatabaseMigrationService.Inputs.MigrationJobVpcPeeringConnectivityArgs
        {
            Vpc = @default.Id,
        },
        DumpType = "LOGICAL",
        DumpFlags = new Gcp.DatabaseMigrationService.Inputs.MigrationJobDumpFlagsArgs
        {
            DumpFlags = new[]
            {
                new Gcp.DatabaseMigrationService.Inputs.MigrationJobDumpFlagsDumpFlagArgs
                {
                    Name = "max-allowed-packet",
                    Value = "1073741824",
                },
            },
        },
        Source = sourceCp.Name,
        Destination = destinationCp.Name,
        Type = "CONTINUOUS",
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/compute"
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/databasemigrationservice"
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/organizations"
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/sql"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		_, err := organizations.LookupProject(ctx, &organizations.LookupProjectArgs{}, nil)
		if err != nil {
			return err
		}
		sourceCsql, err := sql.NewDatabaseInstance(ctx, "source_csql", &sql.DatabaseInstanceArgs{
			Name:            pulumi.String("source-csql"),
			DatabaseVersion: pulumi.String("MYSQL_5_7"),
			Settings: &sql.DatabaseInstanceSettingsArgs{
				Tier:                      pulumi.String("db-n1-standard-1"),
				DeletionProtectionEnabled: pulumi.Bool(false),
			},
			DeletionProtection: pulumi.Bool(false),
		})
		if err != nil {
			return err
		}
		sourceSqlClientCert, err := sql.NewSslCert(ctx, "source_sql_client_cert", &sql.SslCertArgs{
			CommonName: pulumi.String("cert"),
			Instance:   sourceCsql.Name,
		}, pulumi.DependsOn([]pulumi.Resource{
			sourceCsql,
		}))
		if err != nil {
			return err
		}
		sourceSqldbUser, err := sql.NewUser(ctx, "source_sqldb_user", &sql.UserArgs{
			Name:     pulumi.String("username"),
			Instance: sourceCsql.Name,
			Password: pulumi.String("password"),
		}, pulumi.DependsOn([]pulumi.Resource{
			sourceSqlClientCert,
		}))
		if err != nil {
			return err
		}
		sourceCp, err := databasemigrationservice.NewConnectionProfile(ctx, "source_cp", &databasemigrationservice.ConnectionProfileArgs{
			Location:            pulumi.String("us-central1"),
			ConnectionProfileId: pulumi.String("source-cp"),
			DisplayName:         pulumi.String("source-cp_display"),
			Labels: pulumi.StringMap{
				"foo": pulumi.String("bar"),
			},
			Mysql: &databasemigrationservice.ConnectionProfileMysqlArgs{
				Host: sourceCsql.IpAddresses.ApplyT(func(ipAddresses []sql.DatabaseInstanceIpAddress) (*string, error) {
					return &ipAddresses[0].IpAddress, nil
				}).(pulumi.StringPtrOutput),
				Port:     pulumi.Int(3306),
				Username: sourceSqldbUser.Name,
				Password: sourceSqldbUser.Password,
				Ssl: &databasemigrationservice.ConnectionProfileMysqlSslArgs{
					ClientKey:         sourceSqlClientCert.PrivateKey,
					ClientCertificate: sourceSqlClientCert.Cert,
					CaCertificate:     sourceSqlClientCert.ServerCaCert,
				},
				CloudSqlId: pulumi.String("source-csql"),
			},
		}, pulumi.DependsOn([]pulumi.Resource{
			sourceSqldbUser,
		}))
		if err != nil {
			return err
		}
		destinationCsql, err := sql.NewDatabaseInstance(ctx, "destination_csql", &sql.DatabaseInstanceArgs{
			Name:            pulumi.String("destination-csql"),
			DatabaseVersion: pulumi.String("MYSQL_5_7"),
			Settings: &sql.DatabaseInstanceSettingsArgs{
				Tier:                      pulumi.String("db-n1-standard-1"),
				DeletionProtectionEnabled: pulumi.Bool(false),
			},
			DeletionProtection: pulumi.Bool(false),
		})
		if err != nil {
			return err
		}
		destinationCp, err := databasemigrationservice.NewConnectionProfile(ctx, "destination_cp", &databasemigrationservice.ConnectionProfileArgs{
			Location:            pulumi.String("us-central1"),
			ConnectionProfileId: pulumi.String("destination-cp"),
			DisplayName:         pulumi.String("destination-cp_display"),
			Labels: pulumi.StringMap{
				"foo": pulumi.String("bar"),
			},
			Mysql: &databasemigrationservice.ConnectionProfileMysqlArgs{
				CloudSqlId: pulumi.String("destination-csql"),
			},
		}, pulumi.DependsOn([]pulumi.Resource{
			destinationCsql,
		}))
		if err != nil {
			return err
		}
		_, err = compute.NewNetwork(ctx, "default", &compute.NetworkArgs{
			Name: pulumi.String("destination-csql"),
		})
		if err != nil {
			return err
		}
		_, err = databasemigrationservice.NewMigrationJob(ctx, "mysqltomysql", &databasemigrationservice.MigrationJobArgs{
			Location:       pulumi.String("us-central1"),
			MigrationJobId: pulumi.String("my-migrationid"),
			DisplayName:    pulumi.String("my-migrationid_display"),
			Labels: pulumi.StringMap{
				"foo": pulumi.String("bar"),
			},
			PerformanceConfig: &databasemigrationservice.MigrationJobPerformanceConfigArgs{
				DumpParallelLevel: pulumi.String("MAX"),
			},
			VpcPeeringConnectivity: &databasemigrationservice.MigrationJobVpcPeeringConnectivityArgs{
				Vpc: _default.ID(),
			},
			DumpType: pulumi.String("LOGICAL"),
			DumpFlags: &databasemigrationservice.MigrationJobDumpFlagsArgs{
				DumpFlags: databasemigrationservice.MigrationJobDumpFlagsDumpFlagArray{
					&databasemigrationservice.MigrationJobDumpFlagsDumpFlagArgs{
						Name:  pulumi.String("max-allowed-packet"),
						Value: pulumi.String("1073741824"),
					},
				},
			},
			Source:      sourceCp.Name,
			Destination: destinationCp.Name,
			Type:        pulumi.String("CONTINUOUS"),
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.organizations.OrganizationsFunctions;
import com.pulumi.gcp.organizations.inputs.GetProjectArgs;
import com.pulumi.gcp.sql.DatabaseInstance;
import com.pulumi.gcp.sql.DatabaseInstanceArgs;
import com.pulumi.gcp.sql.inputs.DatabaseInstanceSettingsArgs;
import com.pulumi.gcp.sql.SslCert;
import com.pulumi.gcp.sql.SslCertArgs;
import com.pulumi.gcp.sql.User;
import com.pulumi.gcp.sql.UserArgs;
import com.pulumi.gcp.databasemigrationservice.ConnectionProfile;
import com.pulumi.gcp.databasemigrationservice.ConnectionProfileArgs;
import com.pulumi.gcp.databasemigrationservice.inputs.ConnectionProfileMysqlArgs;
import com.pulumi.gcp.databasemigrationservice.inputs.ConnectionProfileMysqlSslArgs;
import com.pulumi.gcp.compute.Network;
import com.pulumi.gcp.compute.NetworkArgs;
import com.pulumi.gcp.databasemigrationservice.MigrationJob;
import com.pulumi.gcp.databasemigrationservice.MigrationJobArgs;
import com.pulumi.gcp.databasemigrationservice.inputs.MigrationJobPerformanceConfigArgs;
import com.pulumi.gcp.databasemigrationservice.inputs.MigrationJobVpcPeeringConnectivityArgs;
import com.pulumi.gcp.databasemigrationservice.inputs.MigrationJobDumpFlagsArgs;
import com.pulumi.resources.CustomResourceOptions;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        final var project = OrganizationsFunctions.getProject();

        var sourceCsql = new DatabaseInstance("sourceCsql", DatabaseInstanceArgs.builder()
            .name("source-csql")
            .databaseVersion("MYSQL_5_7")
            .settings(DatabaseInstanceSettingsArgs.builder()
                .tier("db-n1-standard-1")
                .deletionProtectionEnabled(false)
                .build())
            .deletionProtection(false)
            .build());

        var sourceSqlClientCert = new SslCert("sourceSqlClientCert", SslCertArgs.builder()
            .commonName("cert")
            .instance(sourceCsql.name())
            .build(), CustomResourceOptions.builder()
                .dependsOn(sourceCsql)
                .build());

        var sourceSqldbUser = new User("sourceSqldbUser", UserArgs.builder()
            .name("username")
            .instance(sourceCsql.name())
            .password("password")
            .build(), CustomResourceOptions.builder()
                .dependsOn(sourceSqlClientCert)
                .build());

        var sourceCp = new ConnectionProfile("sourceCp", ConnectionProfileArgs.builder()
            .location("us-central1")
            .connectionProfileId("source-cp")
            .displayName("source-cp_display")
            .labels(Map.of("foo", "bar"))
            .mysql(ConnectionProfileMysqlArgs.builder()
                .host(sourceCsql.ipAddresses().applyValue(ipAddresses -> ipAddresses[0].ipAddress()))
                .port(3306)
                .username(sourceSqldbUser.name())
                .password(sourceSqldbUser.password())
                .ssl(ConnectionProfileMysqlSslArgs.builder()
                    .clientKey(sourceSqlClientCert.privateKey())
                    .clientCertificate(sourceSqlClientCert.cert())
                    .caCertificate(sourceSqlClientCert.serverCaCert())
                    .build())
                .cloudSqlId("source-csql")
                .build())
            .build(), CustomResourceOptions.builder()
                .dependsOn(sourceSqldbUser)
                .build());

        var destinationCsql = new DatabaseInstance("destinationCsql", DatabaseInstanceArgs.builder()
            .name("destination-csql")
            .databaseVersion("MYSQL_5_7")
            .settings(DatabaseInstanceSettingsArgs.builder()
                .tier("db-n1-standard-1")
                .deletionProtectionEnabled(false)
                .build())
            .deletionProtection(false)
            .build());

        var destinationCp = new ConnectionProfile("destinationCp", ConnectionProfileArgs.builder()
            .location("us-central1")
            .connectionProfileId("destination-cp")
            .displayName("destination-cp_display")
            .labels(Map.of("foo", "bar"))
            .mysql(ConnectionProfileMysqlArgs.builder()
                .cloudSqlId("destination-csql")
                .build())
            .build(), CustomResourceOptions.builder()
                .dependsOn(destinationCsql)
                .build());

        var default_ = new Network("default", NetworkArgs.builder()
            .name("destination-csql")
            .build());

        var mysqltomysql = new MigrationJob("mysqltomysql", MigrationJobArgs.builder()
            .location("us-central1")
            .migrationJobId("my-migrationid")
            .displayName("my-migrationid_display")
            .labels(Map.of("foo", "bar"))
            .performanceConfig(MigrationJobPerformanceConfigArgs.builder()
                .dumpParallelLevel("MAX")
                .build())
            .vpcPeeringConnectivity(MigrationJobVpcPeeringConnectivityArgs.builder()
                .vpc(default_.id())
                .build())
            .dumpType("LOGICAL")
            .dumpFlags(MigrationJobDumpFlagsArgs.builder()
                .dumpFlags(MigrationJobDumpFlagsDumpFlagArgs.builder()
                    .name("max-allowed-packet")
                    .value("1073741824")
                    .build())
                .build())
            .source(sourceCp.name())
            .destination(destinationCp.name())
            .type("CONTINUOUS")
            .build());

    }
}
```
```yaml
resources:
  sourceCsql:
    type: gcp:sql:DatabaseInstance
    name: source_csql
    properties:
      name: source-csql
      databaseVersion: MYSQL_5_7
      settings:
        tier: db-n1-standard-1
        deletionProtectionEnabled: false
      deletionProtection: false
  sourceSqlClientCert:
    type: gcp:sql:SslCert
    name: source_sql_client_cert
    properties:
      commonName: cert
      instance: ${sourceCsql.name}
    options:
      dependsOn:
        - ${sourceCsql}
  sourceSqldbUser:
    type: gcp:sql:User
    name: source_sqldb_user
    properties:
      name: username
      instance: ${sourceCsql.name}
      password: password
    options:
      dependsOn:
        - ${sourceSqlClientCert}
  sourceCp:
    type: gcp:databasemigrationservice:ConnectionProfile
    name: source_cp
    properties:
      location: us-central1
      connectionProfileId: source-cp
      displayName: source-cp_display
      labels:
        foo: bar
      mysql:
        host: ${sourceCsql.ipAddresses[0].ipAddress}
        port: 3306
        username: ${sourceSqldbUser.name}
        password: ${sourceSqldbUser.password}
        ssl:
          clientKey: ${sourceSqlClientCert.privateKey}
          clientCertificate: ${sourceSqlClientCert.cert}
          caCertificate: ${sourceSqlClientCert.serverCaCert}
        cloudSqlId: source-csql
    options:
      dependsOn:
        - ${sourceSqldbUser}
  destinationCsql:
    type: gcp:sql:DatabaseInstance
    name: destination_csql
    properties:
      name: destination-csql
      databaseVersion: MYSQL_5_7
      settings:
        tier: db-n1-standard-1
        deletionProtectionEnabled: false
      deletionProtection: false
  destinationCp:
    type: gcp:databasemigrationservice:ConnectionProfile
    name: destination_cp
    properties:
      location: us-central1
      connectionProfileId: destination-cp
      displayName: destination-cp_display
      labels:
        foo: bar
      mysql:
        cloudSqlId: destination-csql
    options:
      dependsOn:
        - ${destinationCsql}
  default:
    type: gcp:compute:Network
    properties:
      name: destination-csql
  mysqltomysql:
    type: gcp:databasemigrationservice:MigrationJob
    properties:
      location: us-central1
      migrationJobId: my-migrationid
      displayName: my-migrationid_display
      labels:
        foo: bar
      performanceConfig:
        dumpParallelLevel: MAX
      vpcPeeringConnectivity:
        vpc: ${default.id}
      dumpType: LOGICAL
      dumpFlags:
        dumpFlags:
          - name: max-allowed-packet
            value: '1073741824'
      source: ${sourceCp.name}
      destination: ${destinationCp.name}
      type: CONTINUOUS
variables:
  project:
    fn::invoke:
      function: gcp:organizations:getProject
      arguments: {}
```
<!--End PulumiCodeChooser -->
### Database Migration Service Migration Job Postgres To Postgres


<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const project = gcp.organizations.getProject({});
const sourceCsql = new gcp.sql.DatabaseInstance("source_csql", {
    name: "source-csql",
    databaseVersion: "POSTGRES_15",
    settings: {
        tier: "db-custom-2-13312",
        deletionProtectionEnabled: false,
    },
    deletionProtection: false,
});
const sourceSqlClientCert = new gcp.sql.SslCert("source_sql_client_cert", {
    commonName: "cert",
    instance: sourceCsql.name,
}, {
    dependsOn: [sourceCsql],
});
const sourceSqldbUser = new gcp.sql.User("source_sqldb_user", {
    name: "username",
    instance: sourceCsql.name,
    password: "password",
}, {
    dependsOn: [sourceSqlClientCert],
});
const sourceCp = new gcp.databasemigrationservice.ConnectionProfile("source_cp", {
    location: "us-central1",
    connectionProfileId: "source-cp",
    displayName: "source-cp_display",
    labels: {
        foo: "bar",
    },
    postgresql: {
        host: sourceCsql.ipAddresses.apply(ipAddresses => ipAddresses[0].ipAddress),
        port: 3306,
        username: sourceSqldbUser.name,
        password: sourceSqldbUser.password,
        ssl: {
            clientKey: sourceSqlClientCert.privateKey,
            clientCertificate: sourceSqlClientCert.cert,
            caCertificate: sourceSqlClientCert.serverCaCert,
        },
        cloudSqlId: "source-csql",
    },
}, {
    dependsOn: [sourceSqldbUser],
});
const destinationCsql = new gcp.sql.DatabaseInstance("destination_csql", {
    name: "destination-csql",
    databaseVersion: "POSTGRES_15",
    settings: {
        tier: "db-custom-2-13312",
        deletionProtectionEnabled: false,
    },
    deletionProtection: false,
});
const destinationCp = new gcp.databasemigrationservice.ConnectionProfile("destination_cp", {
    location: "us-central1",
    connectionProfileId: "destination-cp",
    displayName: "destination-cp_display",
    labels: {
        foo: "bar",
    },
    postgresql: {
        cloudSqlId: "destination-csql",
    },
}, {
    dependsOn: [destinationCsql],
});
const psqltopsql = new gcp.databasemigrationservice.MigrationJob("psqltopsql", {
    location: "us-central1",
    migrationJobId: "my-migrationid",
    displayName: "my-migrationid_display",
    labels: {
        foo: "bar",
    },
    staticIpConnectivity: {},
    source: sourceCp.name,
    destination: destinationCp.name,
    type: "CONTINUOUS",
});
```
```python
import pulumi
import pulumi_gcp as gcp

project = gcp.organizations.get_project()
source_csql = gcp.sql.DatabaseInstance("source_csql",
    name="source-csql",
    database_version="POSTGRES_15",
    settings={
        "tier": "db-custom-2-13312",
        "deletion_protection_enabled": False,
    },
    deletion_protection=False)
source_sql_client_cert = gcp.sql.SslCert("source_sql_client_cert",
    common_name="cert",
    instance=source_csql.name,
    opts = pulumi.ResourceOptions(depends_on=[source_csql]))
source_sqldb_user = gcp.sql.User("source_sqldb_user",
    name="username",
    instance=source_csql.name,
    password="password",
    opts = pulumi.ResourceOptions(depends_on=[source_sql_client_cert]))
source_cp = gcp.databasemigrationservice.ConnectionProfile("source_cp",
    location="us-central1",
    connection_profile_id="source-cp",
    display_name="source-cp_display",
    labels={
        "foo": "bar",
    },
    postgresql={
        "host": source_csql.ip_addresses[0].ip_address,
        "port": 3306,
        "username": source_sqldb_user.name,
        "password": source_sqldb_user.password,
        "ssl": {
            "client_key": source_sql_client_cert.private_key,
            "client_certificate": source_sql_client_cert.cert,
            "ca_certificate": source_sql_client_cert.server_ca_cert,
        },
        "cloud_sql_id": "source-csql",
    },
    opts = pulumi.ResourceOptions(depends_on=[source_sqldb_user]))
destination_csql = gcp.sql.DatabaseInstance("destination_csql",
    name="destination-csql",
    database_version="POSTGRES_15",
    settings={
        "tier": "db-custom-2-13312",
        "deletion_protection_enabled": False,
    },
    deletion_protection=False)
destination_cp = gcp.databasemigrationservice.ConnectionProfile("destination_cp",
    location="us-central1",
    connection_profile_id="destination-cp",
    display_name="destination-cp_display",
    labels={
        "foo": "bar",
    },
    postgresql={
        "cloud_sql_id": "destination-csql",
    },
    opts = pulumi.ResourceOptions(depends_on=[destination_csql]))
psqltopsql = gcp.databasemigrationservice.MigrationJob("psqltopsql",
    location="us-central1",
    migration_job_id="my-migrationid",
    display_name="my-migrationid_display",
    labels={
        "foo": "bar",
    },
    static_ip_connectivity={},
    source=source_cp.name,
    destination=destination_cp.name,
    type="CONTINUOUS")
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var project = Gcp.Organizations.GetProject.Invoke();

    var sourceCsql = new Gcp.Sql.DatabaseInstance("source_csql", new()
    {
        Name = "source-csql",
        DatabaseVersion = "POSTGRES_15",
        Settings = new Gcp.Sql.Inputs.DatabaseInstanceSettingsArgs
        {
            Tier = "db-custom-2-13312",
            DeletionProtectionEnabled = false,
        },
        DeletionProtection = false,
    });

    var sourceSqlClientCert = new Gcp.Sql.SslCert("source_sql_client_cert", new()
    {
        CommonName = "cert",
        Instance = sourceCsql.Name,
    }, new CustomResourceOptions
    {
        DependsOn =
        {
            sourceCsql,
        },
    });

    var sourceSqldbUser = new Gcp.Sql.User("source_sqldb_user", new()
    {
        Name = "username",
        Instance = sourceCsql.Name,
        Password = "password",
    }, new CustomResourceOptions
    {
        DependsOn =
        {
            sourceSqlClientCert,
        },
    });

    var sourceCp = new Gcp.DatabaseMigrationService.ConnectionProfile("source_cp", new()
    {
        Location = "us-central1",
        ConnectionProfileId = "source-cp",
        DisplayName = "source-cp_display",
        Labels = 
        {
            { "foo", "bar" },
        },
        Postgresql = new Gcp.DatabaseMigrationService.Inputs.ConnectionProfilePostgresqlArgs
        {
            Host = sourceCsql.IpAddresses.Apply(ipAddresses => ipAddresses[0].IpAddress),
            Port = 3306,
            Username = sourceSqldbUser.Name,
            Password = sourceSqldbUser.Password,
            Ssl = new Gcp.DatabaseMigrationService.Inputs.ConnectionProfilePostgresqlSslArgs
            {
                ClientKey = sourceSqlClientCert.PrivateKey,
                ClientCertificate = sourceSqlClientCert.Cert,
                CaCertificate = sourceSqlClientCert.ServerCaCert,
            },
            CloudSqlId = "source-csql",
        },
    }, new CustomResourceOptions
    {
        DependsOn =
        {
            sourceSqldbUser,
        },
    });

    var destinationCsql = new Gcp.Sql.DatabaseInstance("destination_csql", new()
    {
        Name = "destination-csql",
        DatabaseVersion = "POSTGRES_15",
        Settings = new Gcp.Sql.Inputs.DatabaseInstanceSettingsArgs
        {
            Tier = "db-custom-2-13312",
            DeletionProtectionEnabled = false,
        },
        DeletionProtection = false,
    });

    var destinationCp = new Gcp.DatabaseMigrationService.ConnectionProfile("destination_cp", new()
    {
        Location = "us-central1",
        ConnectionProfileId = "destination-cp",
        DisplayName = "destination-cp_display",
        Labels = 
        {
            { "foo", "bar" },
        },
        Postgresql = new Gcp.DatabaseMigrationService.Inputs.ConnectionProfilePostgresqlArgs
        {
            CloudSqlId = "destination-csql",
        },
    }, new CustomResourceOptions
    {
        DependsOn =
        {
            destinationCsql,
        },
    });

    var psqltopsql = new Gcp.DatabaseMigrationService.MigrationJob("psqltopsql", new()
    {
        Location = "us-central1",
        MigrationJobId = "my-migrationid",
        DisplayName = "my-migrationid_display",
        Labels = 
        {
            { "foo", "bar" },
        },
        StaticIpConnectivity = null,
        Source = sourceCp.Name,
        Destination = destinationCp.Name,
        Type = "CONTINUOUS",
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/databasemigrationservice"
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/organizations"
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/sql"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		_, err := organizations.LookupProject(ctx, &organizations.LookupProjectArgs{}, nil)
		if err != nil {
			return err
		}
		sourceCsql, err := sql.NewDatabaseInstance(ctx, "source_csql", &sql.DatabaseInstanceArgs{
			Name:            pulumi.String("source-csql"),
			DatabaseVersion: pulumi.String("POSTGRES_15"),
			Settings: &sql.DatabaseInstanceSettingsArgs{
				Tier:                      pulumi.String("db-custom-2-13312"),
				DeletionProtectionEnabled: pulumi.Bool(false),
			},
			DeletionProtection: pulumi.Bool(false),
		})
		if err != nil {
			return err
		}
		sourceSqlClientCert, err := sql.NewSslCert(ctx, "source_sql_client_cert", &sql.SslCertArgs{
			CommonName: pulumi.String("cert"),
			Instance:   sourceCsql.Name,
		}, pulumi.DependsOn([]pulumi.Resource{
			sourceCsql,
		}))
		if err != nil {
			return err
		}
		sourceSqldbUser, err := sql.NewUser(ctx, "source_sqldb_user", &sql.UserArgs{
			Name:     pulumi.String("username"),
			Instance: sourceCsql.Name,
			Password: pulumi.String("password"),
		}, pulumi.DependsOn([]pulumi.Resource{
			sourceSqlClientCert,
		}))
		if err != nil {
			return err
		}
		sourceCp, err := databasemigrationservice.NewConnectionProfile(ctx, "source_cp", &databasemigrationservice.ConnectionProfileArgs{
			Location:            pulumi.String("us-central1"),
			ConnectionProfileId: pulumi.String("source-cp"),
			DisplayName:         pulumi.String("source-cp_display"),
			Labels: pulumi.StringMap{
				"foo": pulumi.String("bar"),
			},
			Postgresql: &databasemigrationservice.ConnectionProfilePostgresqlArgs{
				Host: sourceCsql.IpAddresses.ApplyT(func(ipAddresses []sql.DatabaseInstanceIpAddress) (*string, error) {
					return &ipAddresses[0].IpAddress, nil
				}).(pulumi.StringPtrOutput),
				Port:     pulumi.Int(3306),
				Username: sourceSqldbUser.Name,
				Password: sourceSqldbUser.Password,
				Ssl: &databasemigrationservice.ConnectionProfilePostgresqlSslArgs{
					ClientKey:         sourceSqlClientCert.PrivateKey,
					ClientCertificate: sourceSqlClientCert.Cert,
					CaCertificate:     sourceSqlClientCert.ServerCaCert,
				},
				CloudSqlId: pulumi.String("source-csql"),
			},
		}, pulumi.DependsOn([]pulumi.Resource{
			sourceSqldbUser,
		}))
		if err != nil {
			return err
		}
		destinationCsql, err := sql.NewDatabaseInstance(ctx, "destination_csql", &sql.DatabaseInstanceArgs{
			Name:            pulumi.String("destination-csql"),
			DatabaseVersion: pulumi.String("POSTGRES_15"),
			Settings: &sql.DatabaseInstanceSettingsArgs{
				Tier:                      pulumi.String("db-custom-2-13312"),
				DeletionProtectionEnabled: pulumi.Bool(false),
			},
			DeletionProtection: pulumi.Bool(false),
		})
		if err != nil {
			return err
		}
		destinationCp, err := databasemigrationservice.NewConnectionProfile(ctx, "destination_cp", &databasemigrationservice.ConnectionProfileArgs{
			Location:            pulumi.String("us-central1"),
			ConnectionProfileId: pulumi.String("destination-cp"),
			DisplayName:         pulumi.String("destination-cp_display"),
			Labels: pulumi.StringMap{
				"foo": pulumi.String("bar"),
			},
			Postgresql: &databasemigrationservice.ConnectionProfilePostgresqlArgs{
				CloudSqlId: pulumi.String("destination-csql"),
			},
		}, pulumi.DependsOn([]pulumi.Resource{
			destinationCsql,
		}))
		if err != nil {
			return err
		}
		_, err = databasemigrationservice.NewMigrationJob(ctx, "psqltopsql", &databasemigrationservice.MigrationJobArgs{
			Location:       pulumi.String("us-central1"),
			MigrationJobId: pulumi.String("my-migrationid"),
			DisplayName:    pulumi.String("my-migrationid_display"),
			Labels: pulumi.StringMap{
				"foo": pulumi.String("bar"),
			},
			StaticIpConnectivity: &databasemigrationservice.MigrationJobStaticIpConnectivityArgs{},
			Source:               sourceCp.Name,
			Destination:          destinationCp.Name,
			Type:                 pulumi.String("CONTINUOUS"),
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.organizations.OrganizationsFunctions;
import com.pulumi.gcp.organizations.inputs.GetProjectArgs;
import com.pulumi.gcp.sql.DatabaseInstance;
import com.pulumi.gcp.sql.DatabaseInstanceArgs;
import com.pulumi.gcp.sql.inputs.DatabaseInstanceSettingsArgs;
import com.pulumi.gcp.sql.SslCert;
import com.pulumi.gcp.sql.SslCertArgs;
import com.pulumi.gcp.sql.User;
import com.pulumi.gcp.sql.UserArgs;
import com.pulumi.gcp.databasemigrationservice.ConnectionProfile;
import com.pulumi.gcp.databasemigrationservice.ConnectionProfileArgs;
import com.pulumi.gcp.databasemigrationservice.inputs.ConnectionProfilePostgresqlArgs;
import com.pulumi.gcp.databasemigrationservice.inputs.ConnectionProfilePostgresqlSslArgs;
import com.pulumi.gcp.databasemigrationservice.MigrationJob;
import com.pulumi.gcp.databasemigrationservice.MigrationJobArgs;
import com.pulumi.gcp.databasemigrationservice.inputs.MigrationJobStaticIpConnectivityArgs;
import com.pulumi.resources.CustomResourceOptions;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        final var project = OrganizationsFunctions.getProject();

        var sourceCsql = new DatabaseInstance("sourceCsql", DatabaseInstanceArgs.builder()
            .name("source-csql")
            .databaseVersion("POSTGRES_15")
            .settings(DatabaseInstanceSettingsArgs.builder()
                .tier("db-custom-2-13312")
                .deletionProtectionEnabled(false)
                .build())
            .deletionProtection(false)
            .build());

        var sourceSqlClientCert = new SslCert("sourceSqlClientCert", SslCertArgs.builder()
            .commonName("cert")
            .instance(sourceCsql.name())
            .build(), CustomResourceOptions.builder()
                .dependsOn(sourceCsql)
                .build());

        var sourceSqldbUser = new User("sourceSqldbUser", UserArgs.builder()
            .name("username")
            .instance(sourceCsql.name())
            .password("password")
            .build(), CustomResourceOptions.builder()
                .dependsOn(sourceSqlClientCert)
                .build());

        var sourceCp = new ConnectionProfile("sourceCp", ConnectionProfileArgs.builder()
            .location("us-central1")
            .connectionProfileId("source-cp")
            .displayName("source-cp_display")
            .labels(Map.of("foo", "bar"))
            .postgresql(ConnectionProfilePostgresqlArgs.builder()
                .host(sourceCsql.ipAddresses().applyValue(ipAddresses -> ipAddresses[0].ipAddress()))
                .port(3306)
                .username(sourceSqldbUser.name())
                .password(sourceSqldbUser.password())
                .ssl(ConnectionProfilePostgresqlSslArgs.builder()
                    .clientKey(sourceSqlClientCert.privateKey())
                    .clientCertificate(sourceSqlClientCert.cert())
                    .caCertificate(sourceSqlClientCert.serverCaCert())
                    .build())
                .cloudSqlId("source-csql")
                .build())
            .build(), CustomResourceOptions.builder()
                .dependsOn(sourceSqldbUser)
                .build());

        var destinationCsql = new DatabaseInstance("destinationCsql", DatabaseInstanceArgs.builder()
            .name("destination-csql")
            .databaseVersion("POSTGRES_15")
            .settings(DatabaseInstanceSettingsArgs.builder()
                .tier("db-custom-2-13312")
                .deletionProtectionEnabled(false)
                .build())
            .deletionProtection(false)
            .build());

        var destinationCp = new ConnectionProfile("destinationCp", ConnectionProfileArgs.builder()
            .location("us-central1")
            .connectionProfileId("destination-cp")
            .displayName("destination-cp_display")
            .labels(Map.of("foo", "bar"))
            .postgresql(ConnectionProfilePostgresqlArgs.builder()
                .cloudSqlId("destination-csql")
                .build())
            .build(), CustomResourceOptions.builder()
                .dependsOn(destinationCsql)
                .build());

        var psqltopsql = new MigrationJob("psqltopsql", MigrationJobArgs.builder()
            .location("us-central1")
            .migrationJobId("my-migrationid")
            .displayName("my-migrationid_display")
            .labels(Map.of("foo", "bar"))
            .staticIpConnectivity()
            .source(sourceCp.name())
            .destination(destinationCp.name())
            .type("CONTINUOUS")
            .build());

    }
}
```
```yaml
resources:
  sourceCsql:
    type: gcp:sql:DatabaseInstance
    name: source_csql
    properties:
      name: source-csql
      databaseVersion: POSTGRES_15
      settings:
        tier: db-custom-2-13312
        deletionProtectionEnabled: false
      deletionProtection: false
  sourceSqlClientCert:
    type: gcp:sql:SslCert
    name: source_sql_client_cert
    properties:
      commonName: cert
      instance: ${sourceCsql.name}
    options:
      dependsOn:
        - ${sourceCsql}
  sourceSqldbUser:
    type: gcp:sql:User
    name: source_sqldb_user
    properties:
      name: username
      instance: ${sourceCsql.name}
      password: password
    options:
      dependsOn:
        - ${sourceSqlClientCert}
  sourceCp:
    type: gcp:databasemigrationservice:ConnectionProfile
    name: source_cp
    properties:
      location: us-central1
      connectionProfileId: source-cp
      displayName: source-cp_display
      labels:
        foo: bar
      postgresql:
        host: ${sourceCsql.ipAddresses[0].ipAddress}
        port: 3306
        username: ${sourceSqldbUser.name}
        password: ${sourceSqldbUser.password}
        ssl:
          clientKey: ${sourceSqlClientCert.privateKey}
          clientCertificate: ${sourceSqlClientCert.cert}
          caCertificate: ${sourceSqlClientCert.serverCaCert}
        cloudSqlId: source-csql
    options:
      dependsOn:
        - ${sourceSqldbUser}
  destinationCsql:
    type: gcp:sql:DatabaseInstance
    name: destination_csql
    properties:
      name: destination-csql
      databaseVersion: POSTGRES_15
      settings:
        tier: db-custom-2-13312
        deletionProtectionEnabled: false
      deletionProtection: false
  destinationCp:
    type: gcp:databasemigrationservice:ConnectionProfile
    name: destination_cp
    properties:
      location: us-central1
      connectionProfileId: destination-cp
      displayName: destination-cp_display
      labels:
        foo: bar
      postgresql:
        cloudSqlId: destination-csql
    options:
      dependsOn:
        - ${destinationCsql}
  psqltopsql:
    type: gcp:databasemigrationservice:MigrationJob
    properties:
      location: us-central1
      migrationJobId: my-migrationid
      displayName: my-migrationid_display
      labels:
        foo: bar
      staticIpConnectivity: {}
      source: ${sourceCp.name}
      destination: ${destinationCp.name}
      type: CONTINUOUS
variables:
  project:
    fn::invoke:
      function: gcp:organizations:getProject
      arguments: {}
```
<!--End PulumiCodeChooser -->
### Database Migration Service Migration Job Postgres To Alloydb


<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const project = gcp.organizations.getProject({});
const sourceCsql = new gcp.sql.DatabaseInstance("source_csql", {
    name: "source-csql",
    databaseVersion: "POSTGRES_15",
    settings: {
        tier: "db-custom-2-13312",
        deletionProtectionEnabled: false,
    },
    deletionProtection: false,
});
const sourceSqlClientCert = new gcp.sql.SslCert("source_sql_client_cert", {
    commonName: "cert",
    instance: sourceCsql.name,
}, {
    dependsOn: [sourceCsql],
});
const sourceSqldbUser = new gcp.sql.User("source_sqldb_user", {
    name: "username",
    instance: sourceCsql.name,
    password: "password",
}, {
    dependsOn: [sourceSqlClientCert],
});
const sourceCp = new gcp.databasemigrationservice.ConnectionProfile("source_cp", {
    location: "us-central1",
    connectionProfileId: "source-cp",
    displayName: "source-cp_display",
    labels: {
        foo: "bar",
    },
    postgresql: {
        host: sourceCsql.ipAddresses.apply(ipAddresses => ipAddresses[0].ipAddress),
        port: 3306,
        username: sourceSqldbUser.name,
        password: sourceSqldbUser.password,
        ssl: {
            clientKey: sourceSqlClientCert.privateKey,
            clientCertificate: sourceSqlClientCert.cert,
            caCertificate: sourceSqlClientCert.serverCaCert,
        },
        cloudSqlId: "source-csql",
    },
}, {
    dependsOn: [sourceSqldbUser],
});
const _default = new gcp.compute.Network("default", {name: "destination-alloydb"});
const destinationAlloydb = new gcp.alloydb.Cluster("destination_alloydb", {
    clusterId: "destination-alloydb",
    location: "us-central1",
    networkConfig: {
        network: _default.id,
    },
    databaseVersion: "POSTGRES_15",
    initialUser: {
        user: "destination-alloydb",
        password: "destination-alloydb",
    },
});
const privateIpAlloc = new gcp.compute.GlobalAddress("private_ip_alloc", {
    name: "destination-alloydb",
    addressType: "INTERNAL",
    purpose: "VPC_PEERING",
    prefixLength: 16,
    network: _default.id,
});
const vpcConnection = new gcp.servicenetworking.Connection("vpc_connection", {
    network: _default.id,
    service: "servicenetworking.googleapis.com",
    reservedPeeringRanges: [privateIpAlloc.name],
});
const destinationAlloydbPrimary = new gcp.alloydb.Instance("destination_alloydb_primary", {
    cluster: destinationAlloydb.name,
    instanceId: "destination-alloydb-primary",
    instanceType: "PRIMARY",
}, {
    dependsOn: [vpcConnection],
});
const destinationCp = new gcp.databasemigrationservice.ConnectionProfile("destination_cp", {
    location: "us-central1",
    connectionProfileId: "destination-cp",
    displayName: "destination-cp_display",
    labels: {
        foo: "bar",
    },
    postgresql: {
        alloydbClusterId: "destination-alloydb",
    },
}, {
    dependsOn: [
        destinationAlloydb,
        destinationAlloydbPrimary,
    ],
});
const psqltoalloydb = new gcp.databasemigrationservice.MigrationJob("psqltoalloydb", {
    location: "us-central1",
    migrationJobId: "my-migrationid",
    displayName: "my-migrationid_display",
    labels: {
        foo: "bar",
    },
    staticIpConnectivity: {},
    source: sourceCp.name,
    destination: destinationCp.name,
    type: "CONTINUOUS",
});
```
```python
import pulumi
import pulumi_gcp as gcp

project = gcp.organizations.get_project()
source_csql = gcp.sql.DatabaseInstance("source_csql",
    name="source-csql",
    database_version="POSTGRES_15",
    settings={
        "tier": "db-custom-2-13312",
        "deletion_protection_enabled": False,
    },
    deletion_protection=False)
source_sql_client_cert = gcp.sql.SslCert("source_sql_client_cert",
    common_name="cert",
    instance=source_csql.name,
    opts = pulumi.ResourceOptions(depends_on=[source_csql]))
source_sqldb_user = gcp.sql.User("source_sqldb_user",
    name="username",
    instance=source_csql.name,
    password="password",
    opts = pulumi.ResourceOptions(depends_on=[source_sql_client_cert]))
source_cp = gcp.databasemigrationservice.ConnectionProfile("source_cp",
    location="us-central1",
    connection_profile_id="source-cp",
    display_name="source-cp_display",
    labels={
        "foo": "bar",
    },
    postgresql={
        "host": source_csql.ip_addresses[0].ip_address,
        "port": 3306,
        "username": source_sqldb_user.name,
        "password": source_sqldb_user.password,
        "ssl": {
            "client_key": source_sql_client_cert.private_key,
            "client_certificate": source_sql_client_cert.cert,
            "ca_certificate": source_sql_client_cert.server_ca_cert,
        },
        "cloud_sql_id": "source-csql",
    },
    opts = pulumi.ResourceOptions(depends_on=[source_sqldb_user]))
default = gcp.compute.Network("default", name="destination-alloydb")
destination_alloydb = gcp.alloydb.Cluster("destination_alloydb",
    cluster_id="destination-alloydb",
    location="us-central1",
    network_config={
        "network": default.id,
    },
    database_version="POSTGRES_15",
    initial_user={
        "user": "destination-alloydb",
        "password": "destination-alloydb",
    })
private_ip_alloc = gcp.compute.GlobalAddress("private_ip_alloc",
    name="destination-alloydb",
    address_type="INTERNAL",
    purpose="VPC_PEERING",
    prefix_length=16,
    network=default.id)
vpc_connection = gcp.servicenetworking.Connection("vpc_connection",
    network=default.id,
    service="servicenetworking.googleapis.com",
    reserved_peering_ranges=[private_ip_alloc.name])
destination_alloydb_primary = gcp.alloydb.Instance("destination_alloydb_primary",
    cluster=destination_alloydb.name,
    instance_id="destination-alloydb-primary",
    instance_type="PRIMARY",
    opts = pulumi.ResourceOptions(depends_on=[vpc_connection]))
destination_cp = gcp.databasemigrationservice.ConnectionProfile("destination_cp",
    location="us-central1",
    connection_profile_id="destination-cp",
    display_name="destination-cp_display",
    labels={
        "foo": "bar",
    },
    postgresql={
        "alloydb_cluster_id": "destination-alloydb",
    },
    opts = pulumi.ResourceOptions(depends_on=[
            destination_alloydb,
            destination_alloydb_primary,
        ]))
psqltoalloydb = gcp.databasemigrationservice.MigrationJob("psqltoalloydb",
    location="us-central1",
    migration_job_id="my-migrationid",
    display_name="my-migrationid_display",
    labels={
        "foo": "bar",
    },
    static_ip_connectivity={},
    source=source_cp.name,
    destination=destination_cp.name,
    type="CONTINUOUS")
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var project = Gcp.Organizations.GetProject.Invoke();

    var sourceCsql = new Gcp.Sql.DatabaseInstance("source_csql", new()
    {
        Name = "source-csql",
        DatabaseVersion = "POSTGRES_15",
        Settings = new Gcp.Sql.Inputs.DatabaseInstanceSettingsArgs
        {
            Tier = "db-custom-2-13312",
            DeletionProtectionEnabled = false,
        },
        DeletionProtection = false,
    });

    var sourceSqlClientCert = new Gcp.Sql.SslCert("source_sql_client_cert", new()
    {
        CommonName = "cert",
        Instance = sourceCsql.Name,
    }, new CustomResourceOptions
    {
        DependsOn =
        {
            sourceCsql,
        },
    });

    var sourceSqldbUser = new Gcp.Sql.User("source_sqldb_user", new()
    {
        Name = "username",
        Instance = sourceCsql.Name,
        Password = "password",
    }, new CustomResourceOptions
    {
        DependsOn =
        {
            sourceSqlClientCert,
        },
    });

    var sourceCp = new Gcp.DatabaseMigrationService.ConnectionProfile("source_cp", new()
    {
        Location = "us-central1",
        ConnectionProfileId = "source-cp",
        DisplayName = "source-cp_display",
        Labels = 
        {
            { "foo", "bar" },
        },
        Postgresql = new Gcp.DatabaseMigrationService.Inputs.ConnectionProfilePostgresqlArgs
        {
            Host = sourceCsql.IpAddresses.Apply(ipAddresses => ipAddresses[0].IpAddress),
            Port = 3306,
            Username = sourceSqldbUser.Name,
            Password = sourceSqldbUser.Password,
            Ssl = new Gcp.DatabaseMigrationService.Inputs.ConnectionProfilePostgresqlSslArgs
            {
                ClientKey = sourceSqlClientCert.PrivateKey,
                ClientCertificate = sourceSqlClientCert.Cert,
                CaCertificate = sourceSqlClientCert.ServerCaCert,
            },
            CloudSqlId = "source-csql",
        },
    }, new CustomResourceOptions
    {
        DependsOn =
        {
            sourceSqldbUser,
        },
    });

    var @default = new Gcp.Compute.Network("default", new()
    {
        Name = "destination-alloydb",
    });

    var destinationAlloydb = new Gcp.Alloydb.Cluster("destination_alloydb", new()
    {
        ClusterId = "destination-alloydb",
        Location = "us-central1",
        NetworkConfig = new Gcp.Alloydb.Inputs.ClusterNetworkConfigArgs
        {
            Network = @default.Id,
        },
        DatabaseVersion = "POSTGRES_15",
        InitialUser = new Gcp.Alloydb.Inputs.ClusterInitialUserArgs
        {
            User = "destination-alloydb",
            Password = "destination-alloydb",
        },
    });

    var privateIpAlloc = new Gcp.Compute.GlobalAddress("private_ip_alloc", new()
    {
        Name = "destination-alloydb",
        AddressType = "INTERNAL",
        Purpose = "VPC_PEERING",
        PrefixLength = 16,
        Network = @default.Id,
    });

    var vpcConnection = new Gcp.ServiceNetworking.Connection("vpc_connection", new()
    {
        Network = @default.Id,
        Service = "servicenetworking.googleapis.com",
        ReservedPeeringRanges = new[]
        {
            privateIpAlloc.Name,
        },
    });

    var destinationAlloydbPrimary = new Gcp.Alloydb.Instance("destination_alloydb_primary", new()
    {
        Cluster = destinationAlloydb.Name,
        InstanceId = "destination-alloydb-primary",
        InstanceType = "PRIMARY",
    }, new CustomResourceOptions
    {
        DependsOn =
        {
            vpcConnection,
        },
    });

    var destinationCp = new Gcp.DatabaseMigrationService.ConnectionProfile("destination_cp", new()
    {
        Location = "us-central1",
        ConnectionProfileId = "destination-cp",
        DisplayName = "destination-cp_display",
        Labels = 
        {
            { "foo", "bar" },
        },
        Postgresql = new Gcp.DatabaseMigrationService.Inputs.ConnectionProfilePostgresqlArgs
        {
            AlloydbClusterId = "destination-alloydb",
        },
    }, new CustomResourceOptions
    {
        DependsOn =
        {
            destinationAlloydb,
            destinationAlloydbPrimary,
        },
    });

    var psqltoalloydb = new Gcp.DatabaseMigrationService.MigrationJob("psqltoalloydb", new()
    {
        Location = "us-central1",
        MigrationJobId = "my-migrationid",
        DisplayName = "my-migrationid_display",
        Labels = 
        {
            { "foo", "bar" },
        },
        StaticIpConnectivity = null,
        Source = sourceCp.Name,
        Destination = destinationCp.Name,
        Type = "CONTINUOUS",
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/alloydb"
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/compute"
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/databasemigrationservice"
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/organizations"
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/servicenetworking"
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/sql"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		_, err := organizations.LookupProject(ctx, &organizations.LookupProjectArgs{}, nil)
		if err != nil {
			return err
		}
		sourceCsql, err := sql.NewDatabaseInstance(ctx, "source_csql", &sql.DatabaseInstanceArgs{
			Name:            pulumi.String("source-csql"),
			DatabaseVersion: pulumi.String("POSTGRES_15"),
			Settings: &sql.DatabaseInstanceSettingsArgs{
				Tier:                      pulumi.String("db-custom-2-13312"),
				DeletionProtectionEnabled: pulumi.Bool(false),
			},
			DeletionProtection: pulumi.Bool(false),
		})
		if err != nil {
			return err
		}
		sourceSqlClientCert, err := sql.NewSslCert(ctx, "source_sql_client_cert", &sql.SslCertArgs{
			CommonName: pulumi.String("cert"),
			Instance:   sourceCsql.Name,
		}, pulumi.DependsOn([]pulumi.Resource{
			sourceCsql,
		}))
		if err != nil {
			return err
		}
		sourceSqldbUser, err := sql.NewUser(ctx, "source_sqldb_user", &sql.UserArgs{
			Name:     pulumi.String("username"),
			Instance: sourceCsql.Name,
			Password: pulumi.String("password"),
		}, pulumi.DependsOn([]pulumi.Resource{
			sourceSqlClientCert,
		}))
		if err != nil {
			return err
		}
		sourceCp, err := databasemigrationservice.NewConnectionProfile(ctx, "source_cp", &databasemigrationservice.ConnectionProfileArgs{
			Location:            pulumi.String("us-central1"),
			ConnectionProfileId: pulumi.String("source-cp"),
			DisplayName:         pulumi.String("source-cp_display"),
			Labels: pulumi.StringMap{
				"foo": pulumi.String("bar"),
			},
			Postgresql: &databasemigrationservice.ConnectionProfilePostgresqlArgs{
				Host: sourceCsql.IpAddresses.ApplyT(func(ipAddresses []sql.DatabaseInstanceIpAddress) (*string, error) {
					return &ipAddresses[0].IpAddress, nil
				}).(pulumi.StringPtrOutput),
				Port:     pulumi.Int(3306),
				Username: sourceSqldbUser.Name,
				Password: sourceSqldbUser.Password,
				Ssl: &databasemigrationservice.ConnectionProfilePostgresqlSslArgs{
					ClientKey:         sourceSqlClientCert.PrivateKey,
					ClientCertificate: sourceSqlClientCert.Cert,
					CaCertificate:     sourceSqlClientCert.ServerCaCert,
				},
				CloudSqlId: pulumi.String("source-csql"),
			},
		}, pulumi.DependsOn([]pulumi.Resource{
			sourceSqldbUser,
		}))
		if err != nil {
			return err
		}
		_, err = compute.NewNetwork(ctx, "default", &compute.NetworkArgs{
			Name: pulumi.String("destination-alloydb"),
		})
		if err != nil {
			return err
		}
		destinationAlloydb, err := alloydb.NewCluster(ctx, "destination_alloydb", &alloydb.ClusterArgs{
			ClusterId: pulumi.String("destination-alloydb"),
			Location:  pulumi.String("us-central1"),
			NetworkConfig: &alloydb.ClusterNetworkConfigArgs{
				Network: _default.ID(),
			},
			DatabaseVersion: pulumi.String("POSTGRES_15"),
			InitialUser: &alloydb.ClusterInitialUserArgs{
				User:     pulumi.String("destination-alloydb"),
				Password: pulumi.String("destination-alloydb"),
			},
		})
		if err != nil {
			return err
		}
		privateIpAlloc, err := compute.NewGlobalAddress(ctx, "private_ip_alloc", &compute.GlobalAddressArgs{
			Name:         pulumi.String("destination-alloydb"),
			AddressType:  pulumi.String("INTERNAL"),
			Purpose:      pulumi.String("VPC_PEERING"),
			PrefixLength: pulumi.Int(16),
			Network:      _default.ID(),
		})
		if err != nil {
			return err
		}
		vpcConnection, err := servicenetworking.NewConnection(ctx, "vpc_connection", &servicenetworking.ConnectionArgs{
			Network: _default.ID(),
			Service: pulumi.String("servicenetworking.googleapis.com"),
			ReservedPeeringRanges: pulumi.StringArray{
				privateIpAlloc.Name,
			},
		})
		if err != nil {
			return err
		}
		destinationAlloydbPrimary, err := alloydb.NewInstance(ctx, "destination_alloydb_primary", &alloydb.InstanceArgs{
			Cluster:      destinationAlloydb.Name,
			InstanceId:   pulumi.String("destination-alloydb-primary"),
			InstanceType: pulumi.String("PRIMARY"),
		}, pulumi.DependsOn([]pulumi.Resource{
			vpcConnection,
		}))
		if err != nil {
			return err
		}
		destinationCp, err := databasemigrationservice.NewConnectionProfile(ctx, "destination_cp", &databasemigrationservice.ConnectionProfileArgs{
			Location:            pulumi.String("us-central1"),
			ConnectionProfileId: pulumi.String("destination-cp"),
			DisplayName:         pulumi.String("destination-cp_display"),
			Labels: pulumi.StringMap{
				"foo": pulumi.String("bar"),
			},
			Postgresql: &databasemigrationservice.ConnectionProfilePostgresqlArgs{
				AlloydbClusterId: pulumi.String("destination-alloydb"),
			},
		}, pulumi.DependsOn([]pulumi.Resource{
			destinationAlloydb,
			destinationAlloydbPrimary,
		}))
		if err != nil {
			return err
		}
		_, err = databasemigrationservice.NewMigrationJob(ctx, "psqltoalloydb", &databasemigrationservice.MigrationJobArgs{
			Location:       pulumi.String("us-central1"),
			MigrationJobId: pulumi.String("my-migrationid"),
			DisplayName:    pulumi.String("my-migrationid_display"),
			Labels: pulumi.StringMap{
				"foo": pulumi.String("bar"),
			},
			StaticIpConnectivity: &databasemigrationservice.MigrationJobStaticIpConnectivityArgs{},
			Source:               sourceCp.Name,
			Destination:          destinationCp.Name,
			Type:                 pulumi.String("CONTINUOUS"),
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.organizations.OrganizationsFunctions;
import com.pulumi.gcp.organizations.inputs.GetProjectArgs;
import com.pulumi.gcp.sql.DatabaseInstance;
import com.pulumi.gcp.sql.DatabaseInstanceArgs;
import com.pulumi.gcp.sql.inputs.DatabaseInstanceSettingsArgs;
import com.pulumi.gcp.sql.SslCert;
import com.pulumi.gcp.sql.SslCertArgs;
import com.pulumi.gcp.sql.User;
import com.pulumi.gcp.sql.UserArgs;
import com.pulumi.gcp.databasemigrationservice.ConnectionProfile;
import com.pulumi.gcp.databasemigrationservice.ConnectionProfileArgs;
import com.pulumi.gcp.databasemigrationservice.inputs.ConnectionProfilePostgresqlArgs;
import com.pulumi.gcp.databasemigrationservice.inputs.ConnectionProfilePostgresqlSslArgs;
import com.pulumi.gcp.compute.Network;
import com.pulumi.gcp.compute.NetworkArgs;
import com.pulumi.gcp.alloydb.Cluster;
import com.pulumi.gcp.alloydb.ClusterArgs;
import com.pulumi.gcp.alloydb.inputs.ClusterNetworkConfigArgs;
import com.pulumi.gcp.alloydb.inputs.ClusterInitialUserArgs;
import com.pulumi.gcp.compute.GlobalAddress;
import com.pulumi.gcp.compute.GlobalAddressArgs;
import com.pulumi.gcp.servicenetworking.Connection;
import com.pulumi.gcp.servicenetworking.ConnectionArgs;
import com.pulumi.gcp.alloydb.Instance;
import com.pulumi.gcp.alloydb.InstanceArgs;
import com.pulumi.gcp.databasemigrationservice.MigrationJob;
import com.pulumi.gcp.databasemigrationservice.MigrationJobArgs;
import com.pulumi.gcp.databasemigrationservice.inputs.MigrationJobStaticIpConnectivityArgs;
import com.pulumi.resources.CustomResourceOptions;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        final var project = OrganizationsFunctions.getProject();

        var sourceCsql = new DatabaseInstance("sourceCsql", DatabaseInstanceArgs.builder()
            .name("source-csql")
            .databaseVersion("POSTGRES_15")
            .settings(DatabaseInstanceSettingsArgs.builder()
                .tier("db-custom-2-13312")
                .deletionProtectionEnabled(false)
                .build())
            .deletionProtection(false)
            .build());

        var sourceSqlClientCert = new SslCert("sourceSqlClientCert", SslCertArgs.builder()
            .commonName("cert")
            .instance(sourceCsql.name())
            .build(), CustomResourceOptions.builder()
                .dependsOn(sourceCsql)
                .build());

        var sourceSqldbUser = new User("sourceSqldbUser", UserArgs.builder()
            .name("username")
            .instance(sourceCsql.name())
            .password("password")
            .build(), CustomResourceOptions.builder()
                .dependsOn(sourceSqlClientCert)
                .build());

        var sourceCp = new ConnectionProfile("sourceCp", ConnectionProfileArgs.builder()
            .location("us-central1")
            .connectionProfileId("source-cp")
            .displayName("source-cp_display")
            .labels(Map.of("foo", "bar"))
            .postgresql(ConnectionProfilePostgresqlArgs.builder()
                .host(sourceCsql.ipAddresses().applyValue(ipAddresses -> ipAddresses[0].ipAddress()))
                .port(3306)
                .username(sourceSqldbUser.name())
                .password(sourceSqldbUser.password())
                .ssl(ConnectionProfilePostgresqlSslArgs.builder()
                    .clientKey(sourceSqlClientCert.privateKey())
                    .clientCertificate(sourceSqlClientCert.cert())
                    .caCertificate(sourceSqlClientCert.serverCaCert())
                    .build())
                .cloudSqlId("source-csql")
                .build())
            .build(), CustomResourceOptions.builder()
                .dependsOn(sourceSqldbUser)
                .build());

        var default_ = new Network("default", NetworkArgs.builder()
            .name("destination-alloydb")
            .build());

        var destinationAlloydb = new Cluster("destinationAlloydb", ClusterArgs.builder()
            .clusterId("destination-alloydb")
            .location("us-central1")
            .networkConfig(ClusterNetworkConfigArgs.builder()
                .network(default_.id())
                .build())
            .databaseVersion("POSTGRES_15")
            .initialUser(ClusterInitialUserArgs.builder()
                .user("destination-alloydb")
                .password("destination-alloydb")
                .build())
            .build());

        var privateIpAlloc = new GlobalAddress("privateIpAlloc", GlobalAddressArgs.builder()
            .name("destination-alloydb")
            .addressType("INTERNAL")
            .purpose("VPC_PEERING")
            .prefixLength(16)
            .network(default_.id())
            .build());

        var vpcConnection = new Connection("vpcConnection", ConnectionArgs.builder()
            .network(default_.id())
            .service("servicenetworking.googleapis.com")
            .reservedPeeringRanges(privateIpAlloc.name())
            .build());

        var destinationAlloydbPrimary = new Instance("destinationAlloydbPrimary", InstanceArgs.builder()
            .cluster(destinationAlloydb.name())
            .instanceId("destination-alloydb-primary")
            .instanceType("PRIMARY")
            .build(), CustomResourceOptions.builder()
                .dependsOn(vpcConnection)
                .build());

        var destinationCp = new ConnectionProfile("destinationCp", ConnectionProfileArgs.builder()
            .location("us-central1")
            .connectionProfileId("destination-cp")
            .displayName("destination-cp_display")
            .labels(Map.of("foo", "bar"))
            .postgresql(ConnectionProfilePostgresqlArgs.builder()
                .alloydbClusterId("destination-alloydb")
                .build())
            .build(), CustomResourceOptions.builder()
                .dependsOn(                
                    destinationAlloydb,
                    destinationAlloydbPrimary)
                .build());

        var psqltoalloydb = new MigrationJob("psqltoalloydb", MigrationJobArgs.builder()
            .location("us-central1")
            .migrationJobId("my-migrationid")
            .displayName("my-migrationid_display")
            .labels(Map.of("foo", "bar"))
            .staticIpConnectivity()
            .source(sourceCp.name())
            .destination(destinationCp.name())
            .type("CONTINUOUS")
            .build());

    }
}
```
```yaml
resources:
  sourceCsql:
    type: gcp:sql:DatabaseInstance
    name: source_csql
    properties:
      name: source-csql
      databaseVersion: POSTGRES_15
      settings:
        tier: db-custom-2-13312
        deletionProtectionEnabled: false
      deletionProtection: false
  sourceSqlClientCert:
    type: gcp:sql:SslCert
    name: source_sql_client_cert
    properties:
      commonName: cert
      instance: ${sourceCsql.name}
    options:
      dependsOn:
        - ${sourceCsql}
  sourceSqldbUser:
    type: gcp:sql:User
    name: source_sqldb_user
    properties:
      name: username
      instance: ${sourceCsql.name}
      password: password
    options:
      dependsOn:
        - ${sourceSqlClientCert}
  sourceCp:
    type: gcp:databasemigrationservice:ConnectionProfile
    name: source_cp
    properties:
      location: us-central1
      connectionProfileId: source-cp
      displayName: source-cp_display
      labels:
        foo: bar
      postgresql:
        host: ${sourceCsql.ipAddresses[0].ipAddress}
        port: 3306
        username: ${sourceSqldbUser.name}
        password: ${sourceSqldbUser.password}
        ssl:
          clientKey: ${sourceSqlClientCert.privateKey}
          clientCertificate: ${sourceSqlClientCert.cert}
          caCertificate: ${sourceSqlClientCert.serverCaCert}
        cloudSqlId: source-csql
    options:
      dependsOn:
        - ${sourceSqldbUser}
  destinationAlloydb:
    type: gcp:alloydb:Cluster
    name: destination_alloydb
    properties:
      clusterId: destination-alloydb
      location: us-central1
      networkConfig:
        network: ${default.id}
      databaseVersion: POSTGRES_15
      initialUser:
        user: destination-alloydb
        password: destination-alloydb
  destinationAlloydbPrimary:
    type: gcp:alloydb:Instance
    name: destination_alloydb_primary
    properties:
      cluster: ${destinationAlloydb.name}
      instanceId: destination-alloydb-primary
      instanceType: PRIMARY
    options:
      dependsOn:
        - ${vpcConnection}
  privateIpAlloc:
    type: gcp:compute:GlobalAddress
    name: private_ip_alloc
    properties:
      name: destination-alloydb
      addressType: INTERNAL
      purpose: VPC_PEERING
      prefixLength: 16
      network: ${default.id}
  vpcConnection:
    type: gcp:servicenetworking:Connection
    name: vpc_connection
    properties:
      network: ${default.id}
      service: servicenetworking.googleapis.com
      reservedPeeringRanges:
        - ${privateIpAlloc.name}
  default:
    type: gcp:compute:Network
    properties:
      name: destination-alloydb
  destinationCp:
    type: gcp:databasemigrationservice:ConnectionProfile
    name: destination_cp
    properties:
      location: us-central1
      connectionProfileId: destination-cp
      displayName: destination-cp_display
      labels:
        foo: bar
      postgresql:
        alloydbClusterId: destination-alloydb
    options:
      dependsOn:
        - ${destinationAlloydb}
        - ${destinationAlloydbPrimary}
  psqltoalloydb:
    type: gcp:databasemigrationservice:MigrationJob
    properties:
      location: us-central1
      migrationJobId: my-migrationid
      displayName: my-migrationid_display
      labels:
        foo: bar
      staticIpConnectivity: {}
      source: ${sourceCp.name}
      destination: ${destinationCp.name}
      type: CONTINUOUS
variables:
  project:
    fn::invoke:
      function: gcp:organizations:getProject
      arguments: {}
```
<!--End PulumiCodeChooser -->

## Import

MigrationJob can be imported using any of these accepted formats:

* `projects/{{project}}/locations/{{location}}/migrationJobs/{{migration_job_id}}`

* `{{project}}/{{location}}/{{migration_job_id}}`

* `{{location}}/{{migration_job_id}}`

When using the `pulumi import` command, MigrationJob can be imported using one of the formats above. For example:

```sh
$ pulumi import gcp:databasemigrationservice/migrationJob:MigrationJob default projects/{{project}}/locations/{{location}}/migrationJobs/{{migration_job_id}}
```

```sh
$ pulumi import gcp:databasemigrationservice/migrationJob:MigrationJob default {{project}}/{{location}}/{{migration_job_id}}
```

```sh
$ pulumi import gcp:databasemigrationservice/migrationJob:MigrationJob default {{location}}/{{migration_job_id}}
```

¶
destination" ¢The name of the destination connection profile resource in the form of projects/{project}/locations/{location}/connectionProfiles/{destinationConnectionProfile}.
5
displayNameB"  The migration job display name.
È
	dumpFlagsB:}
{
databasemigrationserviceMigrationJobDumpFlagsHgcp:databasemigrationservice/MigrationJobDumpFlags:MigrationJobDumpFlags7The initial dump flags.
Structure is documented below.
·
dumpPathB" ¤The path to the dump file in Google Cloud Storage,
in the format: (gs://[BUCKET_NAME]/[OBJECT_NAME]).
This field and the "dump_flags" field are mutually exclusive.

dumpTypeB" The type of the data dump. Supported for MySQL to CloudSQL for MySQL
migrations only.
Possible values are: `LOGICAL`, `PHYSICAL`.
Ð
labelsB2" ½The resource labels for migration job to use to annotate any related underlying resources such as Compute Engine VMs.

**Note**: This field is non-authoritative, and will only manage the labels present in your configuration.
Please refer to the field `effective_labels` for all of the labels present on the resource.
F
locationB" 4The location where the migration job should reside.
;
migrationJobId" %The ID of the migration job.


- - -

performanceConfigB:

databasemigrationserviceMigrationJobPerformanceConfigXgcp:databasemigrationservice/MigrationJobPerformanceConfig:MigrationJobPerformanceConfigUData dump parallelism settings used by the migration.
Structure is documented below.
{
projectB" jThe ID of the project in which the resource belongs.
If it is not provided, the provider project is used.
®
reverseSshConnectivity«B¨:¥
¢
databasemigrationservice"MigrationJobReverseSshConnectivitybgcp:databasemigrationservice/MigrationJobReverseSshConnectivity:MigrationJobReverseSshConnectivityfThe details of the VPC network that the source database is located in.
Structure is documented below.
§
source" The name of the source connection profile resource in the form of projects/{project}/locations/{location}/connectionProfiles/{sourceConnectionProfile}.
´
staticIpConnectivity¥B¢:

databasemigrationservice MigrationJobStaticIpConnectivity^gcp:databasemigrationservice/MigrationJobStaticIpConnectivity:MigrationJobStaticIpConnectivityóIf set to an empty object (`{}`), the source database will allow incoming
connections from the public IP of the destination database.
You can retrieve the public IP of the Cloud SQL instance from the
Cloud SQL console or using Cloud SQL APIs.
Z
type" NThe type of the migration job.
Possible values are: `ONE_TIME`, `CONTINUOUS`.
®
vpcPeeringConnectivity«B¨:¥
¢
databasemigrationservice"MigrationJobVpcPeeringConnectivitybgcp:databasemigrationservice/MigrationJobVpcPeeringConnectivity:MigrationJobVpcPeeringConnectivityfThe details of the VPC network that the source database is located in.
Structure is documented below.
"»

createTime" ¨Output only. The timestamp when the resource was created. A timestamp in RFC3339 UTC 'Zulu' format, accurate to nanoseconds. Example: '2014-10-02T15:01:23.045123456Z'.
"¶
destination" ¢The name of the destination connection profile resource in the form of projects/{project}/locations/{location}/connectionProfiles/{destinationConnectionProfile}.
"5
displayNameB"  The migration job display name.
"È
	dumpFlagsB:}
{
databasemigrationserviceMigrationJobDumpFlagsHgcp:databasemigrationservice/MigrationJobDumpFlags:MigrationJobDumpFlags7The initial dump flags.
Structure is documented below.
"·
dumpPathB" ¤The path to the dump file in Google Cloud Storage,
in the format: (gs://[BUCKET_NAME]/[OBJECT_NAME]).
This field and the "dump_flags" field are mutually exclusive.
"
dumpTypeB" The type of the data dump. Supported for MySQL to CloudSQL for MySQL
migrations only.
Possible values are: `LOGICAL`, `PHYSICAL`.
"¦
effectiveLabels2" All of labels (key/value pairs) present on the resource in GCP, including the labels configured through Pulumi, other clients and services.
"Ø
errorsu*s:q
o
databasemigrationserviceMigrationJobError@gcp:databasemigrationservice/MigrationJobError:MigrationJobErrorWOutput only. The error details in case of state FAILED.
Structure is documented below.
"Ð
labelsB2" ½The resource labels for migration job to use to annotate any related underlying resources such as Compute Engine VMs.

**Note**: This field is non-authoritative, and will only manage the labels present in your configuration.
Please refer to the field `effective_labels` for all of the labels present on the resource.
"F
locationB" 4The location where the migration job should reside.
";
migrationJobId" %The ID of the migration job.


- - -
"
name" }The name of this migration job resource in the form of projects/{project}/locations/{location}/migrationJobs/{migrationJob}.
"
performanceConfigB:

databasemigrationserviceMigrationJobPerformanceConfigXgcp:databasemigrationservice/MigrationJobPerformanceConfig:MigrationJobPerformanceConfigUData dump parallelism settings used by the migration.
Structure is documented below.
".
phase" !The current migration job phase.
"y
project" jThe ID of the project in which the resource belongs.
If it is not provided, the provider project is used.
"
pulumiLabels2" mThe combination of labels configured directly on the resource
and default labels configured on the provider.
"®
reverseSshConnectivity«B¨:¥
¢
databasemigrationservice"MigrationJobReverseSshConnectivitybgcp:databasemigrationservice/MigrationJobReverseSshConnectivity:MigrationJobReverseSshConnectivityfThe details of the VPC network that the source database is located in.
Structure is documented below.
"§
source" The name of the source connection profile resource in the form of projects/{project}/locations/{location}/connectionProfiles/{sourceConnectionProfile}.
".
state" !The current migration job state.
"´
staticIpConnectivity¥B¢:

databasemigrationservice MigrationJobStaticIpConnectivity^gcp:databasemigrationservice/MigrationJobStaticIpConnectivity:MigrationJobStaticIpConnectivityóIf set to an empty object (`{}`), the source database will allow incoming
connections from the public IP of the destination database.
You can retrieve the public IP of the Cloud SQL instance from the
Cloud SQL console or using Cloud SQL APIs.
"Z
type" NThe type of the migration job.
Possible values are: `ONE_TIME`, `CONTINUOUS`.
"®
vpcPeeringConnectivity«B¨:¥
¢
databasemigrationservice"MigrationJobVpcPeeringConnectivitybgcp:databasemigrationservice/MigrationJobVpcPeeringConnectivity:MigrationJobVpcPeeringConnectivityfThe details of the VPC network that the source database is located in.
Structure is documented below.
*C
o
databasemigrationservicePrivateConnection@gcp:databasemigrationservice/privateConnection:PrivateConnection¯1The PrivateConnection resource is used to establish private connectivity between Database Migration Service and a customer's network.


To get more information about PrivateConnection, see:

* [API documentation](https://cloud.google.com/database-migration/docs/reference/rest/v1/projects.locations.privateConnections)
* How-to Guides
    * [Official Documentation](https://cloud.google.com/database-migration/docs/oracle-to-postgresql/create-private-connectivity-configuration)

## Example Usage

### Database Migration Service Private Connection


<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const _default = new gcp.databasemigrationservice.PrivateConnection("default", {
    displayName: "dbms_pc",
    location: "us-central1",
    privateConnectionId: "my-connection",
    labels: {
        key: "value",
    },
    vpcPeeringConfig: {
        vpcName: googleComputeNetwork["default"].id,
        subnet: "10.0.0.0/29",
    },
});
const defaultNetwork = new gcp.compute.Network("default", {
    name: "my-network",
    autoCreateSubnetworks: false,
});
```
```python
import pulumi
import pulumi_gcp as gcp

default = gcp.databasemigrationservice.PrivateConnection("default",
    display_name="dbms_pc",
    location="us-central1",
    private_connection_id="my-connection",
    labels={
        "key": "value",
    },
    vpc_peering_config={
        "vpc_name": google_compute_network["default"]["id"],
        "subnet": "10.0.0.0/29",
    })
default_network = gcp.compute.Network("default",
    name="my-network",
    auto_create_subnetworks=False)
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var @default = new Gcp.DatabaseMigrationService.PrivateConnection("default", new()
    {
        DisplayName = "dbms_pc",
        Location = "us-central1",
        PrivateConnectionId = "my-connection",
        Labels = 
        {
            { "key", "value" },
        },
        VpcPeeringConfig = new Gcp.DatabaseMigrationService.Inputs.PrivateConnectionVpcPeeringConfigArgs
        {
            VpcName = googleComputeNetwork.Default.Id,
            Subnet = "10.0.0.0/29",
        },
    });

    var defaultNetwork = new Gcp.Compute.Network("default", new()
    {
        Name = "my-network",
        AutoCreateSubnetworks = false,
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/compute"
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/databasemigrationservice"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		_, err := databasemigrationservice.NewPrivateConnection(ctx, "default", &databasemigrationservice.PrivateConnectionArgs{
			DisplayName:         pulumi.String("dbms_pc"),
			Location:            pulumi.String("us-central1"),
			PrivateConnectionId: pulumi.String("my-connection"),
			Labels: pulumi.StringMap{
				"key": pulumi.String("value"),
			},
			VpcPeeringConfig: &databasemigrationservice.PrivateConnectionVpcPeeringConfigArgs{
				VpcName: pulumi.Any(googleComputeNetwork.Default.Id),
				Subnet:  pulumi.String("10.0.0.0/29"),
			},
		})
		if err != nil {
			return err
		}
		_, err = compute.NewNetwork(ctx, "default", &compute.NetworkArgs{
			Name:                  pulumi.String("my-network"),
			AutoCreateSubnetworks: pulumi.Bool(false),
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.databasemigrationservice.PrivateConnection;
import com.pulumi.gcp.databasemigrationservice.PrivateConnectionArgs;
import com.pulumi.gcp.databasemigrationservice.inputs.PrivateConnectionVpcPeeringConfigArgs;
import com.pulumi.gcp.compute.Network;
import com.pulumi.gcp.compute.NetworkArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        var default_ = new PrivateConnection("default", PrivateConnectionArgs.builder()
            .displayName("dbms_pc")
            .location("us-central1")
            .privateConnectionId("my-connection")
            .labels(Map.of("key", "value"))
            .vpcPeeringConfig(PrivateConnectionVpcPeeringConfigArgs.builder()
                .vpcName(googleComputeNetwork.default().id())
                .subnet("10.0.0.0/29")
                .build())
            .build());

        var defaultNetwork = new Network("defaultNetwork", NetworkArgs.builder()
            .name("my-network")
            .autoCreateSubnetworks(false)
            .build());

    }
}
```
```yaml
resources:
  default:
    type: gcp:databasemigrationservice:PrivateConnection
    properties:
      displayName: dbms_pc
      location: us-central1
      privateConnectionId: my-connection
      labels:
        key: value
      vpcPeeringConfig:
        vpcName: ${googleComputeNetwork.default.id}
        subnet: 10.0.0.0/29
  defaultNetwork:
    type: gcp:compute:Network
    name: default
    properties:
      name: my-network
      autoCreateSubnetworks: false
```
<!--End PulumiCodeChooser -->

## Import

PrivateConnection can be imported using any of these accepted formats:

* `projects/{{project}}/locations/{{location}}/privateConnections/{{private_connection_id}}`

* `{{project}}/{{location}}/{{private_connection_id}}`

* `{{location}}/{{private_connection_id}}`

When using the `pulumi import` command, PrivateConnection can be imported using one of the formats above. For example:

```sh
$ pulumi import gcp:databasemigrationservice/privateConnection:PrivateConnection default projects/{{project}}/locations/{{location}}/privateConnections/{{private_connection_id}}
```

```sh
$ pulumi import gcp:databasemigrationservice/privateConnection:PrivateConnection default {{project}}/{{location}}/{{private_connection_id}}
```

```sh
$ pulumi import gcp:databasemigrationservice/privateConnection:PrivateConnection default {{location}}/{{private_connection_id}}
```

#
displayNameB" Display name.
á
labelsB2" ÎLabels. **Note**: This field is non-authoritative, and will only manage the labels present in your configuration. Please
refer to the field 'effective_labels' for all of the labels present on the resource.
P
location" @The name of the location this private connection is located in.
@
privateConnectionId" %The private connectivity identifier.

projectB" Ñ
vpcPeeringConfig¥:¢

databasemigrationservice!PrivateConnectionVpcPeeringConfig`gcp:databasemigrationservice/PrivateConnectionVpcPeeringConfig:PrivateConnectionVpcPeeringConfigThe VPC Peering configuration is used to create VPC peering
between databasemigrationservice and the consumer's VPC.
Structure is documented below.
"!
displayName" Display name.
"¦
effectiveLabels2" All of labels (key/value pairs) present on the resource in GCP, including the labels configured through Pulumi, other clients and services.
"â
errors*:
~
databasemigrationservicePrivateConnectionErrorJgcp:databasemigrationservice/PrivateConnectionError:PrivateConnectionErrorOThe PrivateConnection error in case of failure.
Structure is documented below.
"á
labelsB2" ÎLabels. **Note**: This field is non-authoritative, and will only manage the labels present in your configuration. Please
refer to the field 'effective_labels' for all of the labels present on the resource.
"P
location" @The name of the location this private connection is located in.
"!
name" The resource's name.
"@
privateConnectionId" %The private connectivity identifier.
"
project" "
pulumiLabels2" mThe combination of labels configured directly on the resource
and default labels configured on the provider.
"-
state"  State of the PrivateConnection.
"Ñ
vpcPeeringConfig¥:¢

databasemigrationservice!PrivateConnectionVpcPeeringConfig`gcp:databasemigrationservice/PrivateConnectionVpcPeeringConfig:PrivateConnectionVpcPeeringConfigThe VPC Peering configuration is used to create VPC peering
between databasemigrationservice and the consumer's VPC.
Structure is documented below.
*Á¸
1
datacatalogEntrygcp:datacatalog/entry:EntryEntry Metadata. A Data Catalog Entry resource represents another resource in Google Cloud Platform
(such as a BigQuery dataset or a Pub/Sub topic) or outside of Google Cloud Platform. Clients can use
the linkedResource field in the Entry resource to refer to the original resource ID of the source system.

An Entry resource contains resource details, such as its schema. An Entry can also be used to attach
flexible metadata, such as a Tag.


To get more information about Entry, see:

* [API documentation](https://cloud.google.com/data-catalog/docs/reference/rest/v1/projects.locations.entryGroups.entries)
* How-to Guides
    * [Official Documentation](https://cloud.google.com/data-catalog/docs)

## Example Usage

### Data Catalog Entry Basic


<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const entryGroup = new gcp.datacatalog.EntryGroup("entry_group", {entryGroupId: "my_group"});
const basicEntry = new gcp.datacatalog.Entry("basic_entry", {
    entryGroup: entryGroup.id,
    entryId: "my_entry",
    userSpecifiedType: "my_custom_type",
    userSpecifiedSystem: "SomethingExternal",
});
```
```python
import pulumi
import pulumi_gcp as gcp

entry_group = gcp.datacatalog.EntryGroup("entry_group", entry_group_id="my_group")
basic_entry = gcp.datacatalog.Entry("basic_entry",
    entry_group=entry_group.id,
    entry_id="my_entry",
    user_specified_type="my_custom_type",
    user_specified_system="SomethingExternal")
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var entryGroup = new Gcp.DataCatalog.EntryGroup("entry_group", new()
    {
        EntryGroupId = "my_group",
    });

    var basicEntry = new Gcp.DataCatalog.Entry("basic_entry", new()
    {
        EntryGroup = entryGroup.Id,
        EntryId = "my_entry",
        UserSpecifiedType = "my_custom_type",
        UserSpecifiedSystem = "SomethingExternal",
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/datacatalog"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		entryGroup, err := datacatalog.NewEntryGroup(ctx, "entry_group", &datacatalog.EntryGroupArgs{
			EntryGroupId: pulumi.String("my_group"),
		})
		if err != nil {
			return err
		}
		_, err = datacatalog.NewEntry(ctx, "basic_entry", &datacatalog.EntryArgs{
			EntryGroup:          entryGroup.ID(),
			EntryId:             pulumi.String("my_entry"),
			UserSpecifiedType:   pulumi.String("my_custom_type"),
			UserSpecifiedSystem: pulumi.String("SomethingExternal"),
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.datacatalog.EntryGroup;
import com.pulumi.gcp.datacatalog.EntryGroupArgs;
import com.pulumi.gcp.datacatalog.Entry;
import com.pulumi.gcp.datacatalog.EntryArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        var entryGroup = new EntryGroup("entryGroup", EntryGroupArgs.builder()
            .entryGroupId("my_group")
            .build());

        var basicEntry = new Entry("basicEntry", EntryArgs.builder()
            .entryGroup(entryGroup.id())
            .entryId("my_entry")
            .userSpecifiedType("my_custom_type")
            .userSpecifiedSystem("SomethingExternal")
            .build());

    }
}
```
```yaml
resources:
  basicEntry:
    type: gcp:datacatalog:Entry
    name: basic_entry
    properties:
      entryGroup: ${entryGroup.id}
      entryId: my_entry
      userSpecifiedType: my_custom_type
      userSpecifiedSystem: SomethingExternal
  entryGroup:
    type: gcp:datacatalog:EntryGroup
    name: entry_group
    properties:
      entryGroupId: my_group
```
<!--End PulumiCodeChooser -->
### Data Catalog Entry Fileset


<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const entryGroup = new gcp.datacatalog.EntryGroup("entry_group", {entryGroupId: "my_group"});
const basicEntry = new gcp.datacatalog.Entry("basic_entry", {
    entryGroup: entryGroup.id,
    entryId: "my_entry",
    type: "FILESET",
    gcsFilesetSpec: {
        filePatterns: ["gs://fake_bucket/dir/*"],
    },
});
```
```python
import pulumi
import pulumi_gcp as gcp

entry_group = gcp.datacatalog.EntryGroup("entry_group", entry_group_id="my_group")
basic_entry = gcp.datacatalog.Entry("basic_entry",
    entry_group=entry_group.id,
    entry_id="my_entry",
    type="FILESET",
    gcs_fileset_spec={
        "file_patterns": ["gs://fake_bucket/dir/*"],
    })
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var entryGroup = new Gcp.DataCatalog.EntryGroup("entry_group", new()
    {
        EntryGroupId = "my_group",
    });

    var basicEntry = new Gcp.DataCatalog.Entry("basic_entry", new()
    {
        EntryGroup = entryGroup.Id,
        EntryId = "my_entry",
        Type = "FILESET",
        GcsFilesetSpec = new Gcp.DataCatalog.Inputs.EntryGcsFilesetSpecArgs
        {
            FilePatterns = new[]
            {
                "gs://fake_bucket/dir/*",
            },
        },
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/datacatalog"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		entryGroup, err := datacatalog.NewEntryGroup(ctx, "entry_group", &datacatalog.EntryGroupArgs{
			EntryGroupId: pulumi.String("my_group"),
		})
		if err != nil {
			return err
		}
		_, err = datacatalog.NewEntry(ctx, "basic_entry", &datacatalog.EntryArgs{
			EntryGroup: entryGroup.ID(),
			EntryId:    pulumi.String("my_entry"),
			Type:       pulumi.String("FILESET"),
			GcsFilesetSpec: &datacatalog.EntryGcsFilesetSpecArgs{
				FilePatterns: pulumi.StringArray{
					pulumi.String("gs://fake_bucket/dir/*"),
				},
			},
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.datacatalog.EntryGroup;
import com.pulumi.gcp.datacatalog.EntryGroupArgs;
import com.pulumi.gcp.datacatalog.Entry;
import com.pulumi.gcp.datacatalog.EntryArgs;
import com.pulumi.gcp.datacatalog.inputs.EntryGcsFilesetSpecArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        var entryGroup = new EntryGroup("entryGroup", EntryGroupArgs.builder()
            .entryGroupId("my_group")
            .build());

        var basicEntry = new Entry("basicEntry", EntryArgs.builder()
            .entryGroup(entryGroup.id())
            .entryId("my_entry")
            .type("FILESET")
            .gcsFilesetSpec(EntryGcsFilesetSpecArgs.builder()
                .filePatterns("gs://fake_bucket/dir/*")
                .build())
            .build());

    }
}
```
```yaml
resources:
  basicEntry:
    type: gcp:datacatalog:Entry
    name: basic_entry
    properties:
      entryGroup: ${entryGroup.id}
      entryId: my_entry
      type: FILESET
      gcsFilesetSpec:
        filePatterns:
          - gs://fake_bucket/dir/*
  entryGroup:
    type: gcp:datacatalog:EntryGroup
    name: entry_group
    properties:
      entryGroupId: my_group
```
<!--End PulumiCodeChooser -->
### Data Catalog Entry Full


<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const entryGroup = new gcp.datacatalog.EntryGroup("entry_group", {entryGroupId: "my_group"});
const basicEntry = new gcp.datacatalog.Entry("basic_entry", {
    entryGroup: entryGroup.id,
    entryId: "my_entry",
    userSpecifiedType: "my_user_specified_type",
    userSpecifiedSystem: "Something_custom",
    linkedResource: "my/linked/resource",
    displayName: "my custom type entry",
    description: "a custom type entry for a user specified system",
    schema: `{
  "columns": [
    {
      "column": "first_name",
      "description": "First name",
      "mode": "REQUIRED",
      "type": "STRING"
    },
    {
      "column": "last_name",
      "description": "Last name",
      "mode": "REQUIRED",
      "type": "STRING"
    },
    {
      "column": "address",
      "description": "Address",
      "mode": "REPEATED",
      "subcolumns": [
        {
          "column": "city",
          "description": "City",
          "mode": "NULLABLE",
          "type": "STRING"
        },
        {
          "column": "state",
          "description": "State",
          "mode": "NULLABLE",
          "type": "STRING"
        }
      ],
      "type": "RECORD"
    }
  ]
}
`,
});
```
```python
import pulumi
import pulumi_gcp as gcp

entry_group = gcp.datacatalog.EntryGroup("entry_group", entry_group_id="my_group")
basic_entry = gcp.datacatalog.Entry("basic_entry",
    entry_group=entry_group.id,
    entry_id="my_entry",
    user_specified_type="my_user_specified_type",
    user_specified_system="Something_custom",
    linked_resource="my/linked/resource",
    display_name="my custom type entry",
    description="a custom type entry for a user specified system",
    schema="""{
  "columns": [
    {
      "column": "first_name",
      "description": "First name",
      "mode": "REQUIRED",
      "type": "STRING"
    },
    {
      "column": "last_name",
      "description": "Last name",
      "mode": "REQUIRED",
      "type": "STRING"
    },
    {
      "column": "address",
      "description": "Address",
      "mode": "REPEATED",
      "subcolumns": [
        {
          "column": "city",
          "description": "City",
          "mode": "NULLABLE",
          "type": "STRING"
        },
        {
          "column": "state",
          "description": "State",
          "mode": "NULLABLE",
          "type": "STRING"
        }
      ],
      "type": "RECORD"
    }
  ]
}
""")
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var entryGroup = new Gcp.DataCatalog.EntryGroup("entry_group", new()
    {
        EntryGroupId = "my_group",
    });

    var basicEntry = new Gcp.DataCatalog.Entry("basic_entry", new()
    {
        EntryGroup = entryGroup.Id,
        EntryId = "my_entry",
        UserSpecifiedType = "my_user_specified_type",
        UserSpecifiedSystem = "Something_custom",
        LinkedResource = "my/linked/resource",
        DisplayName = "my custom type entry",
        Description = "a custom type entry for a user specified system",
        Schema = @"{
  ""columns"": [
    {
      ""column"": ""first_name"",
      ""description"": ""First name"",
      ""mode"": ""REQUIRED"",
      ""type"": ""STRING""
    },
    {
      ""column"": ""last_name"",
      ""description"": ""Last name"",
      ""mode"": ""REQUIRED"",
      ""type"": ""STRING""
    },
    {
      ""column"": ""address"",
      ""description"": ""Address"",
      ""mode"": ""REPEATED"",
      ""subcolumns"": [
        {
          ""column"": ""city"",
          ""description"": ""City"",
          ""mode"": ""NULLABLE"",
          ""type"": ""STRING""
        },
        {
          ""column"": ""state"",
          ""description"": ""State"",
          ""mode"": ""NULLABLE"",
          ""type"": ""STRING""
        }
      ],
      ""type"": ""RECORD""
    }
  ]
}
",
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/datacatalog"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		entryGroup, err := datacatalog.NewEntryGroup(ctx, "entry_group", &datacatalog.EntryGroupArgs{
			EntryGroupId: pulumi.String("my_group"),
		})
		if err != nil {
			return err
		}
		_, err = datacatalog.NewEntry(ctx, "basic_entry", &datacatalog.EntryArgs{
			EntryGroup:          entryGroup.ID(),
			EntryId:             pulumi.String("my_entry"),
			UserSpecifiedType:   pulumi.String("my_user_specified_type"),
			UserSpecifiedSystem: pulumi.String("Something_custom"),
			LinkedResource:      pulumi.String("my/linked/resource"),
			DisplayName:         pulumi.String("my custom type entry"),
			Description:         pulumi.String("a custom type entry for a user specified system"),
			Schema: pulumi.String(`{
  "columns": [
    {
      "column": "first_name",
      "description": "First name",
      "mode": "REQUIRED",
      "type": "STRING"
    },
    {
      "column": "last_name",
      "description": "Last name",
      "mode": "REQUIRED",
      "type": "STRING"
    },
    {
      "column": "address",
      "description": "Address",
      "mode": "REPEATED",
      "subcolumns": [
        {
          "column": "city",
          "description": "City",
          "mode": "NULLABLE",
          "type": "STRING"
        },
        {
          "column": "state",
          "description": "State",
          "mode": "NULLABLE",
          "type": "STRING"
        }
      ],
      "type": "RECORD"
    }
  ]
}
`),
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.datacatalog.EntryGroup;
import com.pulumi.gcp.datacatalog.EntryGroupArgs;
import com.pulumi.gcp.datacatalog.Entry;
import com.pulumi.gcp.datacatalog.EntryArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        var entryGroup = new EntryGroup("entryGroup", EntryGroupArgs.builder()
            .entryGroupId("my_group")
            .build());

        var basicEntry = new Entry("basicEntry", EntryArgs.builder()
            .entryGroup(entryGroup.id())
            .entryId("my_entry")
            .userSpecifiedType("my_user_specified_type")
            .userSpecifiedSystem("Something_custom")
            .linkedResource("my/linked/resource")
            .displayName("my custom type entry")
            .description("a custom type entry for a user specified system")
            .schema("""
{
  "columns": [
    {
      "column": "first_name",
      "description": "First name",
      "mode": "REQUIRED",
      "type": "STRING"
    },
    {
      "column": "last_name",
      "description": "Last name",
      "mode": "REQUIRED",
      "type": "STRING"
    },
    {
      "column": "address",
      "description": "Address",
      "mode": "REPEATED",
      "subcolumns": [
        {
          "column": "city",
          "description": "City",
          "mode": "NULLABLE",
          "type": "STRING"
        },
        {
          "column": "state",
          "description": "State",
          "mode": "NULLABLE",
          "type": "STRING"
        }
      ],
      "type": "RECORD"
    }
  ]
}
            """)
            .build());

    }
}
```
```yaml
resources:
  basicEntry:
    type: gcp:datacatalog:Entry
    name: basic_entry
    properties:
      entryGroup: ${entryGroup.id}
      entryId: my_entry
      userSpecifiedType: my_user_specified_type
      userSpecifiedSystem: Something_custom
      linkedResource: my/linked/resource
      displayName: my custom type entry
      description: a custom type entry for a user specified system
      schema: |
        {
          "columns": [
            {
              "column": "first_name",
              "description": "First name",
              "mode": "REQUIRED",
              "type": "STRING"
            },
            {
              "column": "last_name",
              "description": "Last name",
              "mode": "REQUIRED",
              "type": "STRING"
            },
            {
              "column": "address",
              "description": "Address",
              "mode": "REPEATED",
              "subcolumns": [
                {
                  "column": "city",
                  "description": "City",
                  "mode": "NULLABLE",
                  "type": "STRING"
                },
                {
                  "column": "state",
                  "description": "State",
                  "mode": "NULLABLE",
                  "type": "STRING"
                }
              ],
              "type": "RECORD"
            }
          ]
        }
  entryGroup:
    type: gcp:datacatalog:EntryGroup
    name: entry_group
    properties:
      entryGroupId: my_group
```
<!--End PulumiCodeChooser -->

## Import

Entry can be imported using any of these accepted formats:

* `{{name}}`

When using the `pulumi import` command, Entry can be imported using one of the formats above. For example:

```sh
$ pulumi import gcp:datacatalog/entry:Entry default {{name}}
```

{
descriptionB" fEntry description, which can consist of several sentences or paragraphs that describe entry contents.

displayNameB" Display information such as title and description. A short name to identify the entry,
for example, "Analytics Data - Jan 2011".
@

entryGroup" .The name of the entry group this entry is in.
6
entryId" 'The id of the entry to create.


- - -
û
gcsFilesetSpecaB_:]
[
datacatalogEntryGcsFilesetSpec7gcp:datacatalog/EntryGcsFilesetSpec:EntryGcsFilesetSpecSpecification that applies to a Cloud Storage fileset. This is only valid on entries of type FILESET.
Structure is documented below.
Æ
linkedResourceB" ­The resource this metadata entry refers to.
For Google Cloud Platform resources, linkedResource is the full name of the resource.
For example, the linkedResource for a table resource from BigQuery is:
//bigquery.googleapis.com/projects/projectId/datasets/datasetId/tables/tableId
Output only when Entry is of type in the EntryType enum. For entries with userSpecifiedType,
this field is optional and defaults to an empty string.
«
schemaB" Schema of the entry (e.g. BigQuery, GoogleSQL, Avro schema), as a json string. An entry might not have any schema
attached to it. See
https://cloud.google.com/data-catalog/docs/reference/rest/v1/projects.locations.entryGroups.entries#schema
for what fields this schema can contain.
ø
typeB" éThe type of the entry. Only used for Entries with types in the EntryType enum.
Currently, only FILESET enum value is allowed. All other entries created through Data Catalog must use userSpecifiedType.
Possible values are: `FILESET`.
Æ
userSpecifiedSystemB" ¨This field indicates the entry's source system that Data Catalog does not integrate with.
userSpecifiedSystem strings must begin with a letter or underscore and can only contain letters, numbers,
and underscores; are case insensitive; must be at least 1 character and at most 64 characters long.
ð
userSpecifiedTypeB" ÔEntry type if it does not fit any of the input-allowed values listed in EntryType enum above.
When creating an entry, users should check the enum values first, if nothing matches the entry
to be created, then provide a custom value, for example "my_special_type".
userSpecifiedType strings must begin with a letter or underscore and can only contain letters,
numbers, and underscores; are case insensitive; must be at least 1 character and at most 64 characters long.
"ì
bigqueryDateShardedSpecs|*z:x
v
datacatalogEntryBigqueryDateShardedSpecIgcp:datacatalog/EntryBigqueryDateShardedSpec:EntryBigqueryDateShardedSpecÑSpecification for a group of BigQuery tables with name pattern [prefix]YYYYMMDD.
Context: https://cloud.google.com/bigquery/docs/partitioned-tables#partitioning_versus_sharding.
Structure is documented below.
"þ
bigqueryTableSpecsj*h:f
d
datacatalogEntryBigqueryTableSpec=gcp:datacatalog/EntryBigqueryTableSpec:EntryBigqueryTableSpec|Specification that applies to a BigQuery table. This is only valid on entries of type TABLE.
Structure is documented below.
"{
descriptionB" fEntry description, which can consist of several sentences or paragraphs that describe entry contents.
"
displayNameB" Display information such as title and description. A short name to identify the entry,
for example, "Analytics Data - Jan 2011".
"@

entryGroup" .The name of the entry group this entry is in.
"6
entryId" 'The id of the entry to create.


- - -
"û
gcsFilesetSpecaB_:]
[
datacatalogEntryGcsFilesetSpec7gcp:datacatalog/EntryGcsFilesetSpec:EntryGcsFilesetSpecSpecification that applies to a Cloud Storage fileset. This is only valid on entries of type FILESET.
Structure is documented below.
"
integratedSystem" oThis field indicates the entry's source system that Data Catalog integrates with, such as BigQuery or Pub/Sub.
"Ä
linkedResource" ­The resource this metadata entry refers to.
For Google Cloud Platform resources, linkedResource is the full name of the resource.
For example, the linkedResource for a table resource from BigQuery is:
//bigquery.googleapis.com/projects/projectId/datasets/datasetId/tables/tableId
Output only when Entry is of type in the EntryType enum. For entries with userSpecifiedType,
this field is optional and defaults to an empty string.
"
name" The Data Catalog resource name of the entry in URL format.
Example: projects/{project_id}/locations/{location}/entryGroups/{entryGroupId}/entries/{entryId}.
Note that this Entry and its child resources may not actually be stored in the location in this name.
"«
schemaB" Schema of the entry (e.g. BigQuery, GoogleSQL, Avro schema), as a json string. An entry might not have any schema
attached to it. See
https://cloud.google.com/data-catalog/docs/reference/rest/v1/projects.locations.entryGroups.entries#schema
for what fields this schema can contain.
"ø
typeB" éThe type of the entry. Only used for Entries with types in the EntryType enum.
Currently, only FILESET enum value is allowed. All other entries created through Data Catalog must use userSpecifiedType.
Possible values are: `FILESET`.
"Æ
userSpecifiedSystemB" ¨This field indicates the entry's source system that Data Catalog does not integrate with.
userSpecifiedSystem strings must begin with a letter or underscore and can only contain letters, numbers,
and underscores; are case insensitive; must be at least 1 character and at most 64 characters long.
"ð
userSpecifiedTypeB" ÔEntry type if it does not fit any of the input-allowed values listed in EntryType enum above.
When creating an entry, users should check the enum values first, if nothing matches the entry
to be created, then provide a custom value, for example "my_special_type".
userSpecifiedType strings must begin with a letter or underscore and can only contain letters,
numbers, and underscores; are case insensitive; must be at least 1 character and at most 64 characters long.
*ø2
@
datacatalog
EntryGroup%gcp:datacatalog/entryGroup:EntryGroupÕ'An EntryGroup resource represents a logical grouping of zero or more Data Catalog Entry resources.


To get more information about EntryGroup, see:

* [API documentation](https://cloud.google.com/data-catalog/docs/reference/rest/v1/projects.locations.entryGroups)
* How-to Guides
    * [Official Documentation](https://cloud.google.com/data-catalog/docs)

## Example Usage

### Data Catalog Entry Group Basic


<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const basicEntryGroup = new gcp.datacatalog.EntryGroup("basic_entry_group", {entryGroupId: "my_group"});
```
```python
import pulumi
import pulumi_gcp as gcp

basic_entry_group = gcp.datacatalog.EntryGroup("basic_entry_group", entry_group_id="my_group")
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var basicEntryGroup = new Gcp.DataCatalog.EntryGroup("basic_entry_group", new()
    {
        EntryGroupId = "my_group",
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/datacatalog"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		_, err := datacatalog.NewEntryGroup(ctx, "basic_entry_group", &datacatalog.EntryGroupArgs{
			EntryGroupId: pulumi.String("my_group"),
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.datacatalog.EntryGroup;
import com.pulumi.gcp.datacatalog.EntryGroupArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        var basicEntryGroup = new EntryGroup("basicEntryGroup", EntryGroupArgs.builder()
            .entryGroupId("my_group")
            .build());

    }
}
```
```yaml
resources:
  basicEntryGroup:
    type: gcp:datacatalog:EntryGroup
    name: basic_entry_group
    properties:
      entryGroupId: my_group
```
<!--End PulumiCodeChooser -->
### Data Catalog Entry Group Full


<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const basicEntryGroup = new gcp.datacatalog.EntryGroup("basic_entry_group", {
    entryGroupId: "my_group",
    displayName: "entry group",
    description: "example entry group",
});
```
```python
import pulumi
import pulumi_gcp as gcp

basic_entry_group = gcp.datacatalog.EntryGroup("basic_entry_group",
    entry_group_id="my_group",
    display_name="entry group",
    description="example entry group")
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var basicEntryGroup = new Gcp.DataCatalog.EntryGroup("basic_entry_group", new()
    {
        EntryGroupId = "my_group",
        DisplayName = "entry group",
        Description = "example entry group",
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/datacatalog"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		_, err := datacatalog.NewEntryGroup(ctx, "basic_entry_group", &datacatalog.EntryGroupArgs{
			EntryGroupId: pulumi.String("my_group"),
			DisplayName:  pulumi.String("entry group"),
			Description:  pulumi.String("example entry group"),
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.datacatalog.EntryGroup;
import com.pulumi.gcp.datacatalog.EntryGroupArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        var basicEntryGroup = new EntryGroup("basicEntryGroup", EntryGroupArgs.builder()
            .entryGroupId("my_group")
            .displayName("entry group")
            .description("example entry group")
            .build());

    }
}
```
```yaml
resources:
  basicEntryGroup:
    type: gcp:datacatalog:EntryGroup
    name: basic_entry_group
    properties:
      entryGroupId: my_group
      displayName: entry group
      description: example entry group
```
<!--End PulumiCodeChooser -->

## Import

EntryGroup can be imported using any of these accepted formats:

* `{{name}}`

When using the `pulumi import` command, EntryGroup can be imported using one of the formats above. For example:

```sh
$ pulumi import gcp:datacatalog/entryGroup:EntryGroup default {{name}}
```


descriptionB" rEntry group description, which can consist of several sentences or paragraphs that describe entry group contents.
i
displayNameB" TA short name to identify the entry group, for example, "analytics data - jan 2011".
Æ
entryGroupId" ±The id of the entry group to create. The id must begin with a letter or underscore,
contain only English letters, numbers and underscores, and be at most 64 characters.


- - -
{
projectB" jThe ID of the project in which the resource belongs.
If it is not provided, the provider project is used.
,
regionB" EntryGroup location region.
"
descriptionB" rEntry group description, which can consist of several sentences or paragraphs that describe entry group contents.
"i
displayNameB" TA short name to identify the entry group, for example, "analytics data - jan 2011".
"Æ
entryGroupId" ±The id of the entry group to create. The id must begin with a letter or underscore,
contain only English letters, numbers and underscores, and be at most 64 characters.


- - -
"
name" The resource name of the entry group in URL format. Example: projects/{project}/locations/{location}/entryGroups/{entryGroupId}
"y
project" jThe ID of the project in which the resource belongs.
If it is not provided, the provider project is used.
"*
region" EntryGroup location region.
*Ì
^
datacatalogEntryGroupIamBinding9gcp:datacatalog/entryGroupIamBinding:EntryGroupIamBindingò«Three different resources help you manage your IAM policy for Data catalog EntryGroup. Each of these resources serves a different use case:

* `gcp.datacatalog.EntryGroupIamPolicy`: Authoritative. Sets the IAM policy for the entrygroup and replaces any existing policy already attached.
* `gcp.datacatalog.EntryGroupIamBinding`: Authoritative for a given role. Updates the IAM policy to grant a role to a list of members. Other roles within the IAM policy for the entrygroup are preserved.
* `gcp.datacatalog.EntryGroupIamMember`: Non-authoritative. Updates the IAM policy to grant a role to a new member. Other members for the role for the entrygroup are preserved.

A data source can be used to retrieve policy data in advent you do not need creation

* `gcp.datacatalog.EntryGroupIamPolicy`: Retrieves the IAM policy for the entrygroup

> **Note:** `gcp.datacatalog.EntryGroupIamPolicy` **cannot** be used in conjunction with `gcp.datacatalog.EntryGroupIamBinding` and `gcp.datacatalog.EntryGroupIamMember` or they will fight over what your policy should be.

> **Note:** `gcp.datacatalog.EntryGroupIamBinding` resources **can be** used in conjunction with `gcp.datacatalog.EntryGroupIamMember` resources **only if** they do not grant privilege to the same role.



## gcp.datacatalog.EntryGroupIamPolicy

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const admin = gcp.organizations.getIAMPolicy({
    bindings: [{
        role: "roles/viewer",
        members: ["user:jane@example.com"],
    }],
});
const policy = new gcp.datacatalog.EntryGroupIamPolicy("policy", {
    entryGroup: basicEntryGroup.name,
    policyData: admin.then(admin => admin.policyData),
});
```
```python
import pulumi
import pulumi_gcp as gcp

admin = gcp.organizations.get_iam_policy(bindings=[{
    "role": "roles/viewer",
    "members": ["user:jane@example.com"],
}])
policy = gcp.datacatalog.EntryGroupIamPolicy("policy",
    entry_group=basic_entry_group["name"],
    policy_data=admin.policy_data)
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var admin = Gcp.Organizations.GetIAMPolicy.Invoke(new()
    {
        Bindings = new[]
        {
            new Gcp.Organizations.Inputs.GetIAMPolicyBindingInputArgs
            {
                Role = "roles/viewer",
                Members = new[]
                {
                    "user:jane@example.com",
                },
            },
        },
    });

    var policy = new Gcp.DataCatalog.EntryGroupIamPolicy("policy", new()
    {
        EntryGroup = basicEntryGroup.Name,
        PolicyData = admin.Apply(getIAMPolicyResult => getIAMPolicyResult.PolicyData),
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/datacatalog"
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/organizations"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		admin, err := organizations.LookupIAMPolicy(ctx, &organizations.LookupIAMPolicyArgs{
			Bindings: []organizations.GetIAMPolicyBinding{
				{
					Role: "roles/viewer",
					Members: []string{
						"user:jane@example.com",
					},
				},
			},
		}, nil)
		if err != nil {
			return err
		}
		_, err = datacatalog.NewEntryGroupIamPolicy(ctx, "policy", &datacatalog.EntryGroupIamPolicyArgs{
			EntryGroup: pulumi.Any(basicEntryGroup.Name),
			PolicyData: pulumi.String(admin.PolicyData),
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.organizations.OrganizationsFunctions;
import com.pulumi.gcp.organizations.inputs.GetIAMPolicyArgs;
import com.pulumi.gcp.datacatalog.EntryGroupIamPolicy;
import com.pulumi.gcp.datacatalog.EntryGroupIamPolicyArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        final var admin = OrganizationsFunctions.getIAMPolicy(GetIAMPolicyArgs.builder()
            .bindings(GetIAMPolicyBindingArgs.builder()
                .role("roles/viewer")
                .members("user:jane@example.com")
                .build())
            .build());

        var policy = new EntryGroupIamPolicy("policy", EntryGroupIamPolicyArgs.builder()
            .entryGroup(basicEntryGroup.name())
            .policyData(admin.applyValue(getIAMPolicyResult -> getIAMPolicyResult.policyData()))
            .build());

    }
}
```
```yaml
resources:
  policy:
    type: gcp:datacatalog:EntryGroupIamPolicy
    properties:
      entryGroup: ${basicEntryGroup.name}
      policyData: ${admin.policyData}
variables:
  admin:
    fn::invoke:
      function: gcp:organizations:getIAMPolicy
      arguments:
        bindings:
          - role: roles/viewer
            members:
              - user:jane@example.com
```
<!--End PulumiCodeChooser -->

## gcp.datacatalog.EntryGroupIamBinding

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const binding = new gcp.datacatalog.EntryGroupIamBinding("binding", {
    entryGroup: basicEntryGroup.name,
    role: "roles/viewer",
    members: ["user:jane@example.com"],
});
```
```python
import pulumi
import pulumi_gcp as gcp

binding = gcp.datacatalog.EntryGroupIamBinding("binding",
    entry_group=basic_entry_group["name"],
    role="roles/viewer",
    members=["user:jane@example.com"])
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var binding = new Gcp.DataCatalog.EntryGroupIamBinding("binding", new()
    {
        EntryGroup = basicEntryGroup.Name,
        Role = "roles/viewer",
        Members = new[]
        {
            "user:jane@example.com",
        },
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/datacatalog"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		_, err := datacatalog.NewEntryGroupIamBinding(ctx, "binding", &datacatalog.EntryGroupIamBindingArgs{
			EntryGroup: pulumi.Any(basicEntryGroup.Name),
			Role:       pulumi.String("roles/viewer"),
			Members: pulumi.StringArray{
				pulumi.String("user:jane@example.com"),
			},
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.datacatalog.EntryGroupIamBinding;
import com.pulumi.gcp.datacatalog.EntryGroupIamBindingArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        var binding = new EntryGroupIamBinding("binding", EntryGroupIamBindingArgs.builder()
            .entryGroup(basicEntryGroup.name())
            .role("roles/viewer")
            .members("user:jane@example.com")
            .build());

    }
}
```
```yaml
resources:
  binding:
    type: gcp:datacatalog:EntryGroupIamBinding
    properties:
      entryGroup: ${basicEntryGroup.name}
      role: roles/viewer
      members:
        - user:jane@example.com
```
<!--End PulumiCodeChooser -->

## gcp.datacatalog.EntryGroupIamMember

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const member = new gcp.datacatalog.EntryGroupIamMember("member", {
    entryGroup: basicEntryGroup.name,
    role: "roles/viewer",
    member: "user:jane@example.com",
});
```
```python
import pulumi
import pulumi_gcp as gcp

member = gcp.datacatalog.EntryGroupIamMember("member",
    entry_group=basic_entry_group["name"],
    role="roles/viewer",
    member="user:jane@example.com")
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var member = new Gcp.DataCatalog.EntryGroupIamMember("member", new()
    {
        EntryGroup = basicEntryGroup.Name,
        Role = "roles/viewer",
        Member = "user:jane@example.com",
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/datacatalog"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		_, err := datacatalog.NewEntryGroupIamMember(ctx, "member", &datacatalog.EntryGroupIamMemberArgs{
			EntryGroup: pulumi.Any(basicEntryGroup.Name),
			Role:       pulumi.String("roles/viewer"),
			Member:     pulumi.String("user:jane@example.com"),
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.datacatalog.EntryGroupIamMember;
import com.pulumi.gcp.datacatalog.EntryGroupIamMemberArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        var member = new EntryGroupIamMember("member", EntryGroupIamMemberArgs.builder()
            .entryGroup(basicEntryGroup.name())
            .role("roles/viewer")
            .member("user:jane@example.com")
            .build());

    }
}
```
```yaml
resources:
  member:
    type: gcp:datacatalog:EntryGroupIamMember
    properties:
      entryGroup: ${basicEntryGroup.name}
      role: roles/viewer
      member: user:jane@example.com
```
<!--End PulumiCodeChooser -->


## This resource supports User Project Overrides.

-

# IAM policy for Data catalog EntryGroup
Three different resources help you manage your IAM policy for Data catalog EntryGroup. Each of these resources serves a different use case:

* `gcp.datacatalog.EntryGroupIamPolicy`: Authoritative. Sets the IAM policy for the entrygroup and replaces any existing policy already attached.
* `gcp.datacatalog.EntryGroupIamBinding`: Authoritative for a given role. Updates the IAM policy to grant a role to a list of members. Other roles within the IAM policy for the entrygroup are preserved.
* `gcp.datacatalog.EntryGroupIamMember`: Non-authoritative. Updates the IAM policy to grant a role to a new member. Other members for the role for the entrygroup are preserved.

A data source can be used to retrieve policy data in advent you do not need creation

* `gcp.datacatalog.EntryGroupIamPolicy`: Retrieves the IAM policy for the entrygroup

> **Note:** `gcp.datacatalog.EntryGroupIamPolicy` **cannot** be used in conjunction with `gcp.datacatalog.EntryGroupIamBinding` and `gcp.datacatalog.EntryGroupIamMember` or they will fight over what your policy should be.

> **Note:** `gcp.datacatalog.EntryGroupIamBinding` resources **can be** used in conjunction with `gcp.datacatalog.EntryGroupIamMember` resources **only if** they do not grant privilege to the same role.



## gcp.datacatalog.EntryGroupIamPolicy

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const admin = gcp.organizations.getIAMPolicy({
    bindings: [{
        role: "roles/viewer",
        members: ["user:jane@example.com"],
    }],
});
const policy = new gcp.datacatalog.EntryGroupIamPolicy("policy", {
    entryGroup: basicEntryGroup.name,
    policyData: admin.then(admin => admin.policyData),
});
```
```python
import pulumi
import pulumi_gcp as gcp

admin = gcp.organizations.get_iam_policy(bindings=[{
    "role": "roles/viewer",
    "members": ["user:jane@example.com"],
}])
policy = gcp.datacatalog.EntryGroupIamPolicy("policy",
    entry_group=basic_entry_group["name"],
    policy_data=admin.policy_data)
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var admin = Gcp.Organizations.GetIAMPolicy.Invoke(new()
    {
        Bindings = new[]
        {
            new Gcp.Organizations.Inputs.GetIAMPolicyBindingInputArgs
            {
                Role = "roles/viewer",
                Members = new[]
                {
                    "user:jane@example.com",
                },
            },
        },
    });

    var policy = new Gcp.DataCatalog.EntryGroupIamPolicy("policy", new()
    {
        EntryGroup = basicEntryGroup.Name,
        PolicyData = admin.Apply(getIAMPolicyResult => getIAMPolicyResult.PolicyData),
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/datacatalog"
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/organizations"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		admin, err := organizations.LookupIAMPolicy(ctx, &organizations.LookupIAMPolicyArgs{
			Bindings: []organizations.GetIAMPolicyBinding{
				{
					Role: "roles/viewer",
					Members: []string{
						"user:jane@example.com",
					},
				},
			},
		}, nil)
		if err != nil {
			return err
		}
		_, err = datacatalog.NewEntryGroupIamPolicy(ctx, "policy", &datacatalog.EntryGroupIamPolicyArgs{
			EntryGroup: pulumi.Any(basicEntryGroup.Name),
			PolicyData: pulumi.String(admin.PolicyData),
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.organizations.OrganizationsFunctions;
import com.pulumi.gcp.organizations.inputs.GetIAMPolicyArgs;
import com.pulumi.gcp.datacatalog.EntryGroupIamPolicy;
import com.pulumi.gcp.datacatalog.EntryGroupIamPolicyArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        final var admin = OrganizationsFunctions.getIAMPolicy(GetIAMPolicyArgs.builder()
            .bindings(GetIAMPolicyBindingArgs.builder()
                .role("roles/viewer")
                .members("user:jane@example.com")
                .build())
            .build());

        var policy = new EntryGroupIamPolicy("policy", EntryGroupIamPolicyArgs.builder()
            .entryGroup(basicEntryGroup.name())
            .policyData(admin.applyValue(getIAMPolicyResult -> getIAMPolicyResult.policyData()))
            .build());

    }
}
```
```yaml
resources:
  policy:
    type: gcp:datacatalog:EntryGroupIamPolicy
    properties:
      entryGroup: ${basicEntryGroup.name}
      policyData: ${admin.policyData}
variables:
  admin:
    fn::invoke:
      function: gcp:organizations:getIAMPolicy
      arguments:
        bindings:
          - role: roles/viewer
            members:
              - user:jane@example.com
```
<!--End PulumiCodeChooser -->

## gcp.datacatalog.EntryGroupIamBinding

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const binding = new gcp.datacatalog.EntryGroupIamBinding("binding", {
    entryGroup: basicEntryGroup.name,
    role: "roles/viewer",
    members: ["user:jane@example.com"],
});
```
```python
import pulumi
import pulumi_gcp as gcp

binding = gcp.datacatalog.EntryGroupIamBinding("binding",
    entry_group=basic_entry_group["name"],
    role="roles/viewer",
    members=["user:jane@example.com"])
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var binding = new Gcp.DataCatalog.EntryGroupIamBinding("binding", new()
    {
        EntryGroup = basicEntryGroup.Name,
        Role = "roles/viewer",
        Members = new[]
        {
            "user:jane@example.com",
        },
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/datacatalog"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		_, err := datacatalog.NewEntryGroupIamBinding(ctx, "binding", &datacatalog.EntryGroupIamBindingArgs{
			EntryGroup: pulumi.Any(basicEntryGroup.Name),
			Role:       pulumi.String("roles/viewer"),
			Members: pulumi.StringArray{
				pulumi.String("user:jane@example.com"),
			},
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.datacatalog.EntryGroupIamBinding;
import com.pulumi.gcp.datacatalog.EntryGroupIamBindingArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        var binding = new EntryGroupIamBinding("binding", EntryGroupIamBindingArgs.builder()
            .entryGroup(basicEntryGroup.name())
            .role("roles/viewer")
            .members("user:jane@example.com")
            .build());

    }
}
```
```yaml
resources:
  binding:
    type: gcp:datacatalog:EntryGroupIamBinding
    properties:
      entryGroup: ${basicEntryGroup.name}
      role: roles/viewer
      members:
        - user:jane@example.com
```
<!--End PulumiCodeChooser -->

## gcp.datacatalog.EntryGroupIamMember

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const member = new gcp.datacatalog.EntryGroupIamMember("member", {
    entryGroup: basicEntryGroup.name,
    role: "roles/viewer",
    member: "user:jane@example.com",
});
```
```python
import pulumi
import pulumi_gcp as gcp

member = gcp.datacatalog.EntryGroupIamMember("member",
    entry_group=basic_entry_group["name"],
    role="roles/viewer",
    member="user:jane@example.com")
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var member = new Gcp.DataCatalog.EntryGroupIamMember("member", new()
    {
        EntryGroup = basicEntryGroup.Name,
        Role = "roles/viewer",
        Member = "user:jane@example.com",
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/datacatalog"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		_, err := datacatalog.NewEntryGroupIamMember(ctx, "member", &datacatalog.EntryGroupIamMemberArgs{
			EntryGroup: pulumi.Any(basicEntryGroup.Name),
			Role:       pulumi.String("roles/viewer"),
			Member:     pulumi.String("user:jane@example.com"),
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.datacatalog.EntryGroupIamMember;
import com.pulumi.gcp.datacatalog.EntryGroupIamMemberArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        var member = new EntryGroupIamMember("member", EntryGroupIamMemberArgs.builder()
            .entryGroup(basicEntryGroup.name())
            .role("roles/viewer")
            .member("user:jane@example.com")
            .build());

    }
}
```
```yaml
resources:
  member:
    type: gcp:datacatalog:EntryGroupIamMember
    properties:
      entryGroup: ${basicEntryGroup.name}
      role: roles/viewer
      member: user:jane@example.com
```
<!--End PulumiCodeChooser -->

## Import

For all import syntaxes, the "resource in question" can take any of the following forms:

* projects/{{project}}/locations/{{region}}/entryGroups/{{entry_group}}

* {{project}}/{{region}}/{{entry_group}}

* {{region}}/{{entry_group}}

* {{entry_group}}

Any variables not passed in the import command will be taken from the provider configuration.

Data catalog entrygroup IAM resources can be imported using the resource identifiers, role, and member.

IAM member imports use space-delimited identifiers: the resource in question, the role, and the member identity, e.g.

```sh
$ pulumi import gcp:datacatalog/entryGroupIamBinding:EntryGroupIamBinding editor "projects/{{project}}/locations/{{region}}/entryGroups/{{entry_group}} roles/viewer user:jane@example.com"
```

IAM binding imports use space-delimited identifiers: the resource in question and the role, e.g.

```sh
$ pulumi import gcp:datacatalog/entryGroupIamBinding:EntryGroupIamBinding editor "projects/{{project}}/locations/{{region}}/entryGroups/{{entry_group}} roles/viewer"
```

IAM policy imports use the identifier of the resource in question, e.g.

```sh
$ pulumi import gcp:datacatalog/entryGroupIamBinding:EntryGroupIamBinding editor projects/{{project}}/locations/{{region}}/entryGroups/{{entry_group}}
```

-> **Custom Roles** If you're importing a IAM resource with a custom role, make sure to use the

 full name of the custom role, e.g. `[projects/my-project|organizations/my-org]/roles/my-custom-role`.


	conditionB}:{
y
datacatalogEntryGroupIamBindingConditionKgcp:datacatalog/EntryGroupIamBindingCondition:EntryGroupIamBindingConditionM

entryGroup" ;Used to find the parent resource to bind the IAM policy to
Ö	
members*" Ä	Identities that will be granted the privilege in `role`.
Each entry can have one of the following values:
* **allUsers**: A special identifier that represents anyone who is on the internet; with or without a Google account.
* **allAuthenticatedUsers**: A special identifier that represents anyone who is authenticated with a Google account or a service account.
* **user:{emailid}**: An email address that represents a specific Google account. For example, alice@gmail.com or joe@example.com.
* **serviceAccount:{emailid}**: An email address that represents a service account. For example, my-other-app@appspot.gserviceaccount.com.
* **group:{emailid}**: An email address that represents a Google group. For example, admins@example.com.
* **domain:{domain}**: A G Suite domain (primary, instead of alias) name that represents all the users of that domain. For example, google.com or example.com.
* **projectOwner:projectid**: Owners of the given project. For example, "projectOwner:my-example-project"
* **projectEditor:projectid**: Editors of the given project. For example, "projectEditor:my-example-project"
* **projectViewer:projectid**: Viewers of the given project. For example, "projectViewer:my-example-project"

projectB" The ID of the project in which the resource belongs.
If it is not provided, the project will be parsed from the identifier of the parent resource. If no project is provided in the parent identifier and no project is specified, the provider project is used.

regionB" Ý
role" ÐThe role that should be applied. Only one
`gcp.datacatalog.EntryGroupIamBinding` can be used per role. Note that custom roles must be of the format
`[projects|organizations]/{parent-name}/roles/{role-name}`.
"
	conditionB}:{
y
datacatalogEntryGroupIamBindingConditionKgcp:datacatalog/EntryGroupIamBindingCondition:EntryGroupIamBindingCondition"M

entryGroup" ;Used to find the parent resource to bind the IAM policy to
"3
etag" '(Computed) The etag of the IAM policy.
"Ö	
members*" Ä	Identities that will be granted the privilege in `role`.
Each entry can have one of the following values:
* **allUsers**: A special identifier that represents anyone who is on the internet; with or without a Google account.
* **allAuthenticatedUsers**: A special identifier that represents anyone who is authenticated with a Google account or a service account.
* **user:{emailid}**: An email address that represents a specific Google account. For example, alice@gmail.com or joe@example.com.
* **serviceAccount:{emailid}**: An email address that represents a service account. For example, my-other-app@appspot.gserviceaccount.com.
* **group:{emailid}**: An email address that represents a Google group. For example, admins@example.com.
* **domain:{domain}**: A G Suite domain (primary, instead of alias) name that represents all the users of that domain. For example, google.com or example.com.
* **projectOwner:projectid**: Owners of the given project. For example, "projectOwner:my-example-project"
* **projectEditor:projectid**: Editors of the given project. For example, "projectEditor:my-example-project"
* **projectViewer:projectid**: Viewers of the given project. For example, "projectViewer:my-example-project"
"
project" The ID of the project in which the resource belongs.
If it is not provided, the project will be parsed from the identifier of the parent resource. If no project is provided in the parent identifier and no project is specified, the provider project is used.
"
region" "Ý
role" ÐThe role that should be applied. Only one
`gcp.datacatalog.EntryGroupIamBinding` can be used per role. Note that custom roles must be of the format
`[projects|organizations]/{parent-name}/roles/{role-name}`.
*ìË
[
datacatalogEntryGroupIamMember7gcp:datacatalog/entryGroupIamMember:EntryGroupIamMemberì«Three different resources help you manage your IAM policy for Data catalog EntryGroup. Each of these resources serves a different use case:

* `gcp.datacatalog.EntryGroupIamPolicy`: Authoritative. Sets the IAM policy for the entrygroup and replaces any existing policy already attached.
* `gcp.datacatalog.EntryGroupIamBinding`: Authoritative for a given role. Updates the IAM policy to grant a role to a list of members. Other roles within the IAM policy for the entrygroup are preserved.
* `gcp.datacatalog.EntryGroupIamMember`: Non-authoritative. Updates the IAM policy to grant a role to a new member. Other members for the role for the entrygroup are preserved.

A data source can be used to retrieve policy data in advent you do not need creation

* `gcp.datacatalog.EntryGroupIamPolicy`: Retrieves the IAM policy for the entrygroup

> **Note:** `gcp.datacatalog.EntryGroupIamPolicy` **cannot** be used in conjunction with `gcp.datacatalog.EntryGroupIamBinding` and `gcp.datacatalog.EntryGroupIamMember` or they will fight over what your policy should be.

> **Note:** `gcp.datacatalog.EntryGroupIamBinding` resources **can be** used in conjunction with `gcp.datacatalog.EntryGroupIamMember` resources **only if** they do not grant privilege to the same role.



## gcp.datacatalog.EntryGroupIamPolicy

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const admin = gcp.organizations.getIAMPolicy({
    bindings: [{
        role: "roles/viewer",
        members: ["user:jane@example.com"],
    }],
});
const policy = new gcp.datacatalog.EntryGroupIamPolicy("policy", {
    entryGroup: basicEntryGroup.name,
    policyData: admin.then(admin => admin.policyData),
});
```
```python
import pulumi
import pulumi_gcp as gcp

admin = gcp.organizations.get_iam_policy(bindings=[{
    "role": "roles/viewer",
    "members": ["user:jane@example.com"],
}])
policy = gcp.datacatalog.EntryGroupIamPolicy("policy",
    entry_group=basic_entry_group["name"],
    policy_data=admin.policy_data)
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var admin = Gcp.Organizations.GetIAMPolicy.Invoke(new()
    {
        Bindings = new[]
        {
            new Gcp.Organizations.Inputs.GetIAMPolicyBindingInputArgs
            {
                Role = "roles/viewer",
                Members = new[]
                {
                    "user:jane@example.com",
                },
            },
        },
    });

    var policy = new Gcp.DataCatalog.EntryGroupIamPolicy("policy", new()
    {
        EntryGroup = basicEntryGroup.Name,
        PolicyData = admin.Apply(getIAMPolicyResult => getIAMPolicyResult.PolicyData),
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/datacatalog"
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/organizations"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		admin, err := organizations.LookupIAMPolicy(ctx, &organizations.LookupIAMPolicyArgs{
			Bindings: []organizations.GetIAMPolicyBinding{
				{
					Role: "roles/viewer",
					Members: []string{
						"user:jane@example.com",
					},
				},
			},
		}, nil)
		if err != nil {
			return err
		}
		_, err = datacatalog.NewEntryGroupIamPolicy(ctx, "policy", &datacatalog.EntryGroupIamPolicyArgs{
			EntryGroup: pulumi.Any(basicEntryGroup.Name),
			PolicyData: pulumi.String(admin.PolicyData),
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.organizations.OrganizationsFunctions;
import com.pulumi.gcp.organizations.inputs.GetIAMPolicyArgs;
import com.pulumi.gcp.datacatalog.EntryGroupIamPolicy;
import com.pulumi.gcp.datacatalog.EntryGroupIamPolicyArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        final var admin = OrganizationsFunctions.getIAMPolicy(GetIAMPolicyArgs.builder()
            .bindings(GetIAMPolicyBindingArgs.builder()
                .role("roles/viewer")
                .members("user:jane@example.com")
                .build())
            .build());

        var policy = new EntryGroupIamPolicy("policy", EntryGroupIamPolicyArgs.builder()
            .entryGroup(basicEntryGroup.name())
            .policyData(admin.applyValue(getIAMPolicyResult -> getIAMPolicyResult.policyData()))
            .build());

    }
}
```
```yaml
resources:
  policy:
    type: gcp:datacatalog:EntryGroupIamPolicy
    properties:
      entryGroup: ${basicEntryGroup.name}
      policyData: ${admin.policyData}
variables:
  admin:
    fn::invoke:
      function: gcp:organizations:getIAMPolicy
      arguments:
        bindings:
          - role: roles/viewer
            members:
              - user:jane@example.com
```
<!--End PulumiCodeChooser -->

## gcp.datacatalog.EntryGroupIamBinding

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const binding = new gcp.datacatalog.EntryGroupIamBinding("binding", {
    entryGroup: basicEntryGroup.name,
    role: "roles/viewer",
    members: ["user:jane@example.com"],
});
```
```python
import pulumi
import pulumi_gcp as gcp

binding = gcp.datacatalog.EntryGroupIamBinding("binding",
    entry_group=basic_entry_group["name"],
    role="roles/viewer",
    members=["user:jane@example.com"])
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var binding = new Gcp.DataCatalog.EntryGroupIamBinding("binding", new()
    {
        EntryGroup = basicEntryGroup.Name,
        Role = "roles/viewer",
        Members = new[]
        {
            "user:jane@example.com",
        },
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/datacatalog"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		_, err := datacatalog.NewEntryGroupIamBinding(ctx, "binding", &datacatalog.EntryGroupIamBindingArgs{
			EntryGroup: pulumi.Any(basicEntryGroup.Name),
			Role:       pulumi.String("roles/viewer"),
			Members: pulumi.StringArray{
				pulumi.String("user:jane@example.com"),
			},
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.datacatalog.EntryGroupIamBinding;
import com.pulumi.gcp.datacatalog.EntryGroupIamBindingArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        var binding = new EntryGroupIamBinding("binding", EntryGroupIamBindingArgs.builder()
            .entryGroup(basicEntryGroup.name())
            .role("roles/viewer")
            .members("user:jane@example.com")
            .build());

    }
}
```
```yaml
resources:
  binding:
    type: gcp:datacatalog:EntryGroupIamBinding
    properties:
      entryGroup: ${basicEntryGroup.name}
      role: roles/viewer
      members:
        - user:jane@example.com
```
<!--End PulumiCodeChooser -->

## gcp.datacatalog.EntryGroupIamMember

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const member = new gcp.datacatalog.EntryGroupIamMember("member", {
    entryGroup: basicEntryGroup.name,
    role: "roles/viewer",
    member: "user:jane@example.com",
});
```
```python
import pulumi
import pulumi_gcp as gcp

member = gcp.datacatalog.EntryGroupIamMember("member",
    entry_group=basic_entry_group["name"],
    role="roles/viewer",
    member="user:jane@example.com")
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var member = new Gcp.DataCatalog.EntryGroupIamMember("member", new()
    {
        EntryGroup = basicEntryGroup.Name,
        Role = "roles/viewer",
        Member = "user:jane@example.com",
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/datacatalog"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		_, err := datacatalog.NewEntryGroupIamMember(ctx, "member", &datacatalog.EntryGroupIamMemberArgs{
			EntryGroup: pulumi.Any(basicEntryGroup.Name),
			Role:       pulumi.String("roles/viewer"),
			Member:     pulumi.String("user:jane@example.com"),
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.datacatalog.EntryGroupIamMember;
import com.pulumi.gcp.datacatalog.EntryGroupIamMemberArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        var member = new EntryGroupIamMember("member", EntryGroupIamMemberArgs.builder()
            .entryGroup(basicEntryGroup.name())
            .role("roles/viewer")
            .member("user:jane@example.com")
            .build());

    }
}
```
```yaml
resources:
  member:
    type: gcp:datacatalog:EntryGroupIamMember
    properties:
      entryGroup: ${basicEntryGroup.name}
      role: roles/viewer
      member: user:jane@example.com
```
<!--End PulumiCodeChooser -->


## This resource supports User Project Overrides.

-

# IAM policy for Data catalog EntryGroup
Three different resources help you manage your IAM policy for Data catalog EntryGroup. Each of these resources serves a different use case:

* `gcp.datacatalog.EntryGroupIamPolicy`: Authoritative. Sets the IAM policy for the entrygroup and replaces any existing policy already attached.
* `gcp.datacatalog.EntryGroupIamBinding`: Authoritative for a given role. Updates the IAM policy to grant a role to a list of members. Other roles within the IAM policy for the entrygroup are preserved.
* `gcp.datacatalog.EntryGroupIamMember`: Non-authoritative. Updates the IAM policy to grant a role to a new member. Other members for the role for the entrygroup are preserved.

A data source can be used to retrieve policy data in advent you do not need creation

* `gcp.datacatalog.EntryGroupIamPolicy`: Retrieves the IAM policy for the entrygroup

> **Note:** `gcp.datacatalog.EntryGroupIamPolicy` **cannot** be used in conjunction with `gcp.datacatalog.EntryGroupIamBinding` and `gcp.datacatalog.EntryGroupIamMember` or they will fight over what your policy should be.

> **Note:** `gcp.datacatalog.EntryGroupIamBinding` resources **can be** used in conjunction with `gcp.datacatalog.EntryGroupIamMember` resources **only if** they do not grant privilege to the same role.



## gcp.datacatalog.EntryGroupIamPolicy

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const admin = gcp.organizations.getIAMPolicy({
    bindings: [{
        role: "roles/viewer",
        members: ["user:jane@example.com"],
    }],
});
const policy = new gcp.datacatalog.EntryGroupIamPolicy("policy", {
    entryGroup: basicEntryGroup.name,
    policyData: admin.then(admin => admin.policyData),
});
```
```python
import pulumi
import pulumi_gcp as gcp

admin = gcp.organizations.get_iam_policy(bindings=[{
    "role": "roles/viewer",
    "members": ["user:jane@example.com"],
}])
policy = gcp.datacatalog.EntryGroupIamPolicy("policy",
    entry_group=basic_entry_group["name"],
    policy_data=admin.policy_data)
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var admin = Gcp.Organizations.GetIAMPolicy.Invoke(new()
    {
        Bindings = new[]
        {
            new Gcp.Organizations.Inputs.GetIAMPolicyBindingInputArgs
            {
                Role = "roles/viewer",
                Members = new[]
                {
                    "user:jane@example.com",
                },
            },
        },
    });

    var policy = new Gcp.DataCatalog.EntryGroupIamPolicy("policy", new()
    {
        EntryGroup = basicEntryGroup.Name,
        PolicyData = admin.Apply(getIAMPolicyResult => getIAMPolicyResult.PolicyData),
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/datacatalog"
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/organizations"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		admin, err := organizations.LookupIAMPolicy(ctx, &organizations.LookupIAMPolicyArgs{
			Bindings: []organizations.GetIAMPolicyBinding{
				{
					Role: "roles/viewer",
					Members: []string{
						"user:jane@example.com",
					},
				},
			},
		}, nil)
		if err != nil {
			return err
		}
		_, err = datacatalog.NewEntryGroupIamPolicy(ctx, "policy", &datacatalog.EntryGroupIamPolicyArgs{
			EntryGroup: pulumi.Any(basicEntryGroup.Name),
			PolicyData: pulumi.String(admin.PolicyData),
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.organizations.OrganizationsFunctions;
import com.pulumi.gcp.organizations.inputs.GetIAMPolicyArgs;
import com.pulumi.gcp.datacatalog.EntryGroupIamPolicy;
import com.pulumi.gcp.datacatalog.EntryGroupIamPolicyArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        final var admin = OrganizationsFunctions.getIAMPolicy(GetIAMPolicyArgs.builder()
            .bindings(GetIAMPolicyBindingArgs.builder()
                .role("roles/viewer")
                .members("user:jane@example.com")
                .build())
            .build());

        var policy = new EntryGroupIamPolicy("policy", EntryGroupIamPolicyArgs.builder()
            .entryGroup(basicEntryGroup.name())
            .policyData(admin.applyValue(getIAMPolicyResult -> getIAMPolicyResult.policyData()))
            .build());

    }
}
```
```yaml
resources:
  policy:
    type: gcp:datacatalog:EntryGroupIamPolicy
    properties:
      entryGroup: ${basicEntryGroup.name}
      policyData: ${admin.policyData}
variables:
  admin:
    fn::invoke:
      function: gcp:organizations:getIAMPolicy
      arguments:
        bindings:
          - role: roles/viewer
            members:
              - user:jane@example.com
```
<!--End PulumiCodeChooser -->

## gcp.datacatalog.EntryGroupIamBinding

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const binding = new gcp.datacatalog.EntryGroupIamBinding("binding", {
    entryGroup: basicEntryGroup.name,
    role: "roles/viewer",
    members: ["user:jane@example.com"],
});
```
```python
import pulumi
import pulumi_gcp as gcp

binding = gcp.datacatalog.EntryGroupIamBinding("binding",
    entry_group=basic_entry_group["name"],
    role="roles/viewer",
    members=["user:jane@example.com"])
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var binding = new Gcp.DataCatalog.EntryGroupIamBinding("binding", new()
    {
        EntryGroup = basicEntryGroup.Name,
        Role = "roles/viewer",
        Members = new[]
        {
            "user:jane@example.com",
        },
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/datacatalog"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		_, err := datacatalog.NewEntryGroupIamBinding(ctx, "binding", &datacatalog.EntryGroupIamBindingArgs{
			EntryGroup: pulumi.Any(basicEntryGroup.Name),
			Role:       pulumi.String("roles/viewer"),
			Members: pulumi.StringArray{
				pulumi.String("user:jane@example.com"),
			},
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.datacatalog.EntryGroupIamBinding;
import com.pulumi.gcp.datacatalog.EntryGroupIamBindingArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        var binding = new EntryGroupIamBinding("binding", EntryGroupIamBindingArgs.builder()
            .entryGroup(basicEntryGroup.name())
            .role("roles/viewer")
            .members("user:jane@example.com")
            .build());

    }
}
```
```yaml
resources:
  binding:
    type: gcp:datacatalog:EntryGroupIamBinding
    properties:
      entryGroup: ${basicEntryGroup.name}
      role: roles/viewer
      members:
        - user:jane@example.com
```
<!--End PulumiCodeChooser -->

## gcp.datacatalog.EntryGroupIamMember

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const member = new gcp.datacatalog.EntryGroupIamMember("member", {
    entryGroup: basicEntryGroup.name,
    role: "roles/viewer",
    member: "user:jane@example.com",
});
```
```python
import pulumi
import pulumi_gcp as gcp

member = gcp.datacatalog.EntryGroupIamMember("member",
    entry_group=basic_entry_group["name"],
    role="roles/viewer",
    member="user:jane@example.com")
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var member = new Gcp.DataCatalog.EntryGroupIamMember("member", new()
    {
        EntryGroup = basicEntryGroup.Name,
        Role = "roles/viewer",
        Member = "user:jane@example.com",
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/datacatalog"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		_, err := datacatalog.NewEntryGroupIamMember(ctx, "member", &datacatalog.EntryGroupIamMemberArgs{
			EntryGroup: pulumi.Any(basicEntryGroup.Name),
			Role:       pulumi.String("roles/viewer"),
			Member:     pulumi.String("user:jane@example.com"),
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.datacatalog.EntryGroupIamMember;
import com.pulumi.gcp.datacatalog.EntryGroupIamMemberArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        var member = new EntryGroupIamMember("member", EntryGroupIamMemberArgs.builder()
            .entryGroup(basicEntryGroup.name())
            .role("roles/viewer")
            .member("user:jane@example.com")
            .build());

    }
}
```
```yaml
resources:
  member:
    type: gcp:datacatalog:EntryGroupIamMember
    properties:
      entryGroup: ${basicEntryGroup.name}
      role: roles/viewer
      member: user:jane@example.com
```
<!--End PulumiCodeChooser -->

## Import

For all import syntaxes, the "resource in question" can take any of the following forms:

* projects/{{project}}/locations/{{region}}/entryGroups/{{entry_group}}

* {{project}}/{{region}}/{{entry_group}}

* {{region}}/{{entry_group}}

* {{entry_group}}

Any variables not passed in the import command will be taken from the provider configuration.

Data catalog entrygroup IAM resources can be imported using the resource identifiers, role, and member.

IAM member imports use space-delimited identifiers: the resource in question, the role, and the member identity, e.g.

```sh
$ pulumi import gcp:datacatalog/entryGroupIamMember:EntryGroupIamMember editor "projects/{{project}}/locations/{{region}}/entryGroups/{{entry_group}} roles/viewer user:jane@example.com"
```

IAM binding imports use space-delimited identifiers: the resource in question and the role, e.g.

```sh
$ pulumi import gcp:datacatalog/entryGroupIamMember:EntryGroupIamMember editor "projects/{{project}}/locations/{{region}}/entryGroups/{{entry_group}} roles/viewer"
```

IAM policy imports use the identifier of the resource in question, e.g.

```sh
$ pulumi import gcp:datacatalog/entryGroupIamMember:EntryGroupIamMember editor projects/{{project}}/locations/{{region}}/entryGroups/{{entry_group}}
```

-> **Custom Roles** If you're importing a IAM resource with a custom role, make sure to use the

 full name of the custom role, e.g. `[projects/my-project|organizations/my-org]/roles/my-custom-role`.


	condition|Bz:x
v
datacatalogEntryGroupIamMemberConditionIgcp:datacatalog/EntryGroupIamMemberCondition:EntryGroupIamMemberConditionM

entryGroup" ;Used to find the parent resource to bind the IAM policy to
Ó	
member" Ä	Identities that will be granted the privilege in `role`.
Each entry can have one of the following values:
* **allUsers**: A special identifier that represents anyone who is on the internet; with or without a Google account.
* **allAuthenticatedUsers**: A special identifier that represents anyone who is authenticated with a Google account or a service account.
* **user:{emailid}**: An email address that represents a specific Google account. For example, alice@gmail.com or joe@example.com.
* **serviceAccount:{emailid}**: An email address that represents a service account. For example, my-other-app@appspot.gserviceaccount.com.
* **group:{emailid}**: An email address that represents a Google group. For example, admins@example.com.
* **domain:{domain}**: A G Suite domain (primary, instead of alias) name that represents all the users of that domain. For example, google.com or example.com.
* **projectOwner:projectid**: Owners of the given project. For example, "projectOwner:my-example-project"
* **projectEditor:projectid**: Editors of the given project. For example, "projectEditor:my-example-project"
* **projectViewer:projectid**: Viewers of the given project. For example, "projectViewer:my-example-project"

projectB" The ID of the project in which the resource belongs.
If it is not provided, the project will be parsed from the identifier of the parent resource. If no project is provided in the parent identifier and no project is specified, the provider project is used.

regionB" Ý
role" ÐThe role that should be applied. Only one
`gcp.datacatalog.EntryGroupIamBinding` can be used per role. Note that custom roles must be of the format
`[projects|organizations]/{parent-name}/roles/{role-name}`.
"
	condition|Bz:x
v
datacatalogEntryGroupIamMemberConditionIgcp:datacatalog/EntryGroupIamMemberCondition:EntryGroupIamMemberCondition"M

entryGroup" ;Used to find the parent resource to bind the IAM policy to
"3
etag" '(Computed) The etag of the IAM policy.
"Ó	
member" Ä	Identities that will be granted the privilege in `role`.
Each entry can have one of the following values:
* **allUsers**: A special identifier that represents anyone who is on the internet; with or without a Google account.
* **allAuthenticatedUsers**: A special identifier that represents anyone who is authenticated with a Google account or a service account.
* **user:{emailid}**: An email address that represents a specific Google account. For example, alice@gmail.com or joe@example.com.
* **serviceAccount:{emailid}**: An email address that represents a service account. For example, my-other-app@appspot.gserviceaccount.com.
* **group:{emailid}**: An email address that represents a Google group. For example, admins@example.com.
* **domain:{domain}**: A G Suite domain (primary, instead of alias) name that represents all the users of that domain. For example, google.com or example.com.
* **projectOwner:projectid**: Owners of the given project. For example, "projectOwner:my-example-project"
* **projectEditor:projectid**: Editors of the given project. For example, "projectEditor:my-example-project"
* **projectViewer:projectid**: Viewers of the given project. For example, "projectViewer:my-example-project"
"
project" The ID of the project in which the resource belongs.
If it is not provided, the project will be parsed from the identifier of the parent resource. If no project is provided in the parent identifier and no project is specified, the provider project is used.
"
region" "Ý
role" ÐThe role that should be applied. Only one
`gcp.datacatalog.EntryGroupIamBinding` can be used per role. Note that custom roles must be of the format
`[projects|organizations]/{parent-name}/roles/{role-name}`.
*ª´
[
datacatalogEntryGroupIamPolicy7gcp:datacatalog/entryGroupIamPolicy:EntryGroupIamPolicyì«Three different resources help you manage your IAM policy for Data catalog EntryGroup. Each of these resources serves a different use case:

* `gcp.datacatalog.EntryGroupIamPolicy`: Authoritative. Sets the IAM policy for the entrygroup and replaces any existing policy already attached.
* `gcp.datacatalog.EntryGroupIamBinding`: Authoritative for a given role. Updates the IAM policy to grant a role to a list of members. Other roles within the IAM policy for the entrygroup are preserved.
* `gcp.datacatalog.EntryGroupIamMember`: Non-authoritative. Updates the IAM policy to grant a role to a new member. Other members for the role for the entrygroup are preserved.

A data source can be used to retrieve policy data in advent you do not need creation

* `gcp.datacatalog.EntryGroupIamPolicy`: Retrieves the IAM policy for the entrygroup

> **Note:** `gcp.datacatalog.EntryGroupIamPolicy` **cannot** be used in conjunction with `gcp.datacatalog.EntryGroupIamBinding` and `gcp.datacatalog.EntryGroupIamMember` or they will fight over what your policy should be.

> **Note:** `gcp.datacatalog.EntryGroupIamBinding` resources **can be** used in conjunction with `gcp.datacatalog.EntryGroupIamMember` resources **only if** they do not grant privilege to the same role.



## gcp.datacatalog.EntryGroupIamPolicy

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const admin = gcp.organizations.getIAMPolicy({
    bindings: [{
        role: "roles/viewer",
        members: ["user:jane@example.com"],
    }],
});
const policy = new gcp.datacatalog.EntryGroupIamPolicy("policy", {
    entryGroup: basicEntryGroup.name,
    policyData: admin.then(admin => admin.policyData),
});
```
```python
import pulumi
import pulumi_gcp as gcp

admin = gcp.organizations.get_iam_policy(bindings=[{
    "role": "roles/viewer",
    "members": ["user:jane@example.com"],
}])
policy = gcp.datacatalog.EntryGroupIamPolicy("policy",
    entry_group=basic_entry_group["name"],
    policy_data=admin.policy_data)
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var admin = Gcp.Organizations.GetIAMPolicy.Invoke(new()
    {
        Bindings = new[]
        {
            new Gcp.Organizations.Inputs.GetIAMPolicyBindingInputArgs
            {
                Role = "roles/viewer",
                Members = new[]
                {
                    "user:jane@example.com",
                },
            },
        },
    });

    var policy = new Gcp.DataCatalog.EntryGroupIamPolicy("policy", new()
    {
        EntryGroup = basicEntryGroup.Name,
        PolicyData = admin.Apply(getIAMPolicyResult => getIAMPolicyResult.PolicyData),
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/datacatalog"
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/organizations"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		admin, err := organizations.LookupIAMPolicy(ctx, &organizations.LookupIAMPolicyArgs{
			Bindings: []organizations.GetIAMPolicyBinding{
				{
					Role: "roles/viewer",
					Members: []string{
						"user:jane@example.com",
					},
				},
			},
		}, nil)
		if err != nil {
			return err
		}
		_, err = datacatalog.NewEntryGroupIamPolicy(ctx, "policy", &datacatalog.EntryGroupIamPolicyArgs{
			EntryGroup: pulumi.Any(basicEntryGroup.Name),
			PolicyData: pulumi.String(admin.PolicyData),
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.organizations.OrganizationsFunctions;
import com.pulumi.gcp.organizations.inputs.GetIAMPolicyArgs;
import com.pulumi.gcp.datacatalog.EntryGroupIamPolicy;
import com.pulumi.gcp.datacatalog.EntryGroupIamPolicyArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        final var admin = OrganizationsFunctions.getIAMPolicy(GetIAMPolicyArgs.builder()
            .bindings(GetIAMPolicyBindingArgs.builder()
                .role("roles/viewer")
                .members("user:jane@example.com")
                .build())
            .build());

        var policy = new EntryGroupIamPolicy("policy", EntryGroupIamPolicyArgs.builder()
            .entryGroup(basicEntryGroup.name())
            .policyData(admin.applyValue(getIAMPolicyResult -> getIAMPolicyResult.policyData()))
            .build());

    }
}
```
```yaml
resources:
  policy:
    type: gcp:datacatalog:EntryGroupIamPolicy
    properties:
      entryGroup: ${basicEntryGroup.name}
      policyData: ${admin.policyData}
variables:
  admin:
    fn::invoke:
      function: gcp:organizations:getIAMPolicy
      arguments:
        bindings:
          - role: roles/viewer
            members:
              - user:jane@example.com
```
<!--End PulumiCodeChooser -->

## gcp.datacatalog.EntryGroupIamBinding

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const binding = new gcp.datacatalog.EntryGroupIamBinding("binding", {
    entryGroup: basicEntryGroup.name,
    role: "roles/viewer",
    members: ["user:jane@example.com"],
});
```
```python
import pulumi
import pulumi_gcp as gcp

binding = gcp.datacatalog.EntryGroupIamBinding("binding",
    entry_group=basic_entry_group["name"],
    role="roles/viewer",
    members=["user:jane@example.com"])
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var binding = new Gcp.DataCatalog.EntryGroupIamBinding("binding", new()
    {
        EntryGroup = basicEntryGroup.Name,
        Role = "roles/viewer",
        Members = new[]
        {
            "user:jane@example.com",
        },
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/datacatalog"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		_, err := datacatalog.NewEntryGroupIamBinding(ctx, "binding", &datacatalog.EntryGroupIamBindingArgs{
			EntryGroup: pulumi.Any(basicEntryGroup.Name),
			Role:       pulumi.String("roles/viewer"),
			Members: pulumi.StringArray{
				pulumi.String("user:jane@example.com"),
			},
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.datacatalog.EntryGroupIamBinding;
import com.pulumi.gcp.datacatalog.EntryGroupIamBindingArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        var binding = new EntryGroupIamBinding("binding", EntryGroupIamBindingArgs.builder()
            .entryGroup(basicEntryGroup.name())
            .role("roles/viewer")
            .members("user:jane@example.com")
            .build());

    }
}
```
```yaml
resources:
  binding:
    type: gcp:datacatalog:EntryGroupIamBinding
    properties:
      entryGroup: ${basicEntryGroup.name}
      role: roles/viewer
      members:
        - user:jane@example.com
```
<!--End PulumiCodeChooser -->

## gcp.datacatalog.EntryGroupIamMember

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const member = new gcp.datacatalog.EntryGroupIamMember("member", {
    entryGroup: basicEntryGroup.name,
    role: "roles/viewer",
    member: "user:jane@example.com",
});
```
```python
import pulumi
import pulumi_gcp as gcp

member = gcp.datacatalog.EntryGroupIamMember("member",
    entry_group=basic_entry_group["name"],
    role="roles/viewer",
    member="user:jane@example.com")
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var member = new Gcp.DataCatalog.EntryGroupIamMember("member", new()
    {
        EntryGroup = basicEntryGroup.Name,
        Role = "roles/viewer",
        Member = "user:jane@example.com",
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/datacatalog"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		_, err := datacatalog.NewEntryGroupIamMember(ctx, "member", &datacatalog.EntryGroupIamMemberArgs{
			EntryGroup: pulumi.Any(basicEntryGroup.Name),
			Role:       pulumi.String("roles/viewer"),
			Member:     pulumi.String("user:jane@example.com"),
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.datacatalog.EntryGroupIamMember;
import com.pulumi.gcp.datacatalog.EntryGroupIamMemberArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        var member = new EntryGroupIamMember("member", EntryGroupIamMemberArgs.builder()
            .entryGroup(basicEntryGroup.name())
            .role("roles/viewer")
            .member("user:jane@example.com")
            .build());

    }
}
```
```yaml
resources:
  member:
    type: gcp:datacatalog:EntryGroupIamMember
    properties:
      entryGroup: ${basicEntryGroup.name}
      role: roles/viewer
      member: user:jane@example.com
```
<!--End PulumiCodeChooser -->


## This resource supports User Project Overrides.

-

# IAM policy for Data catalog EntryGroup
Three different resources help you manage your IAM policy for Data catalog EntryGroup. Each of these resources serves a different use case:

* `gcp.datacatalog.EntryGroupIamPolicy`: Authoritative. Sets the IAM policy for the entrygroup and replaces any existing policy already attached.
* `gcp.datacatalog.EntryGroupIamBinding`: Authoritative for a given role. Updates the IAM policy to grant a role to a list of members. Other roles within the IAM policy for the entrygroup are preserved.
* `gcp.datacatalog.EntryGroupIamMember`: Non-authoritative. Updates the IAM policy to grant a role to a new member. Other members for the role for the entrygroup are preserved.

A data source can be used to retrieve policy data in advent you do not need creation

* `gcp.datacatalog.EntryGroupIamPolicy`: Retrieves the IAM policy for the entrygroup

> **Note:** `gcp.datacatalog.EntryGroupIamPolicy` **cannot** be used in conjunction with `gcp.datacatalog.EntryGroupIamBinding` and `gcp.datacatalog.EntryGroupIamMember` or they will fight over what your policy should be.

> **Note:** `gcp.datacatalog.EntryGroupIamBinding` resources **can be** used in conjunction with `gcp.datacatalog.EntryGroupIamMember` resources **only if** they do not grant privilege to the same role.



## gcp.datacatalog.EntryGroupIamPolicy

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const admin = gcp.organizations.getIAMPolicy({
    bindings: [{
        role: "roles/viewer",
        members: ["user:jane@example.com"],
    }],
});
const policy = new gcp.datacatalog.EntryGroupIamPolicy("policy", {
    entryGroup: basicEntryGroup.name,
    policyData: admin.then(admin => admin.policyData),
});
```
```python
import pulumi
import pulumi_gcp as gcp

admin = gcp.organizations.get_iam_policy(bindings=[{
    "role": "roles/viewer",
    "members": ["user:jane@example.com"],
}])
policy = gcp.datacatalog.EntryGroupIamPolicy("policy",
    entry_group=basic_entry_group["name"],
    policy_data=admin.policy_data)
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var admin = Gcp.Organizations.GetIAMPolicy.Invoke(new()
    {
        Bindings = new[]
        {
            new Gcp.Organizations.Inputs.GetIAMPolicyBindingInputArgs
            {
                Role = "roles/viewer",
                Members = new[]
                {
                    "user:jane@example.com",
                },
            },
        },
    });

    var policy = new Gcp.DataCatalog.EntryGroupIamPolicy("policy", new()
    {
        EntryGroup = basicEntryGroup.Name,
        PolicyData = admin.Apply(getIAMPolicyResult => getIAMPolicyResult.PolicyData),
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/datacatalog"
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/organizations"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		admin, err := organizations.LookupIAMPolicy(ctx, &organizations.LookupIAMPolicyArgs{
			Bindings: []organizations.GetIAMPolicyBinding{
				{
					Role: "roles/viewer",
					Members: []string{
						"user:jane@example.com",
					},
				},
			},
		}, nil)
		if err != nil {
			return err
		}
		_, err = datacatalog.NewEntryGroupIamPolicy(ctx, "policy", &datacatalog.EntryGroupIamPolicyArgs{
			EntryGroup: pulumi.Any(basicEntryGroup.Name),
			PolicyData: pulumi.String(admin.PolicyData),
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.organizations.OrganizationsFunctions;
import com.pulumi.gcp.organizations.inputs.GetIAMPolicyArgs;
import com.pulumi.gcp.datacatalog.EntryGroupIamPolicy;
import com.pulumi.gcp.datacatalog.EntryGroupIamPolicyArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        final var admin = OrganizationsFunctions.getIAMPolicy(GetIAMPolicyArgs.builder()
            .bindings(GetIAMPolicyBindingArgs.builder()
                .role("roles/viewer")
                .members("user:jane@example.com")
                .build())
            .build());

        var policy = new EntryGroupIamPolicy("policy", EntryGroupIamPolicyArgs.builder()
            .entryGroup(basicEntryGroup.name())
            .policyData(admin.applyValue(getIAMPolicyResult -> getIAMPolicyResult.policyData()))
            .build());

    }
}
```
```yaml
resources:
  policy:
    type: gcp:datacatalog:EntryGroupIamPolicy
    properties:
      entryGroup: ${basicEntryGroup.name}
      policyData: ${admin.policyData}
variables:
  admin:
    fn::invoke:
      function: gcp:organizations:getIAMPolicy
      arguments:
        bindings:
          - role: roles/viewer
            members:
              - user:jane@example.com
```
<!--End PulumiCodeChooser -->

## gcp.datacatalog.EntryGroupIamBinding

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const binding = new gcp.datacatalog.EntryGroupIamBinding("binding", {
    entryGroup: basicEntryGroup.name,
    role: "roles/viewer",
    members: ["user:jane@example.com"],
});
```
```python
import pulumi
import pulumi_gcp as gcp

binding = gcp.datacatalog.EntryGroupIamBinding("binding",
    entry_group=basic_entry_group["name"],
    role="roles/viewer",
    members=["user:jane@example.com"])
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var binding = new Gcp.DataCatalog.EntryGroupIamBinding("binding", new()
    {
        EntryGroup = basicEntryGroup.Name,
        Role = "roles/viewer",
        Members = new[]
        {
            "user:jane@example.com",
        },
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/datacatalog"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		_, err := datacatalog.NewEntryGroupIamBinding(ctx, "binding", &datacatalog.EntryGroupIamBindingArgs{
			EntryGroup: pulumi.Any(basicEntryGroup.Name),
			Role:       pulumi.String("roles/viewer"),
			Members: pulumi.StringArray{
				pulumi.String("user:jane@example.com"),
			},
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.datacatalog.EntryGroupIamBinding;
import com.pulumi.gcp.datacatalog.EntryGroupIamBindingArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        var binding = new EntryGroupIamBinding("binding", EntryGroupIamBindingArgs.builder()
            .entryGroup(basicEntryGroup.name())
            .role("roles/viewer")
            .members("user:jane@example.com")
            .build());

    }
}
```
```yaml
resources:
  binding:
    type: gcp:datacatalog:EntryGroupIamBinding
    properties:
      entryGroup: ${basicEntryGroup.name}
      role: roles/viewer
      members:
        - user:jane@example.com
```
<!--End PulumiCodeChooser -->

## gcp.datacatalog.EntryGroupIamMember

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const member = new gcp.datacatalog.EntryGroupIamMember("member", {
    entryGroup: basicEntryGroup.name,
    role: "roles/viewer",
    member: "user:jane@example.com",
});
```
```python
import pulumi
import pulumi_gcp as gcp

member = gcp.datacatalog.EntryGroupIamMember("member",
    entry_group=basic_entry_group["name"],
    role="roles/viewer",
    member="user:jane@example.com")
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var member = new Gcp.DataCatalog.EntryGroupIamMember("member", new()
    {
        EntryGroup = basicEntryGroup.Name,
        Role = "roles/viewer",
        Member = "user:jane@example.com",
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/datacatalog"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		_, err := datacatalog.NewEntryGroupIamMember(ctx, "member", &datacatalog.EntryGroupIamMemberArgs{
			EntryGroup: pulumi.Any(basicEntryGroup.Name),
			Role:       pulumi.String("roles/viewer"),
			Member:     pulumi.String("user:jane@example.com"),
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.datacatalog.EntryGroupIamMember;
import com.pulumi.gcp.datacatalog.EntryGroupIamMemberArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        var member = new EntryGroupIamMember("member", EntryGroupIamMemberArgs.builder()
            .entryGroup(basicEntryGroup.name())
            .role("roles/viewer")
            .member("user:jane@example.com")
            .build());

    }
}
```
```yaml
resources:
  member:
    type: gcp:datacatalog:EntryGroupIamMember
    properties:
      entryGroup: ${basicEntryGroup.name}
      role: roles/viewer
      member: user:jane@example.com
```
<!--End PulumiCodeChooser -->

## Import

For all import syntaxes, the "resource in question" can take any of the following forms:

* projects/{{project}}/locations/{{region}}/entryGroups/{{entry_group}}

* {{project}}/{{region}}/{{entry_group}}

* {{region}}/{{entry_group}}

* {{entry_group}}

Any variables not passed in the import command will be taken from the provider configuration.

Data catalog entrygroup IAM resources can be imported using the resource identifiers, role, and member.

IAM member imports use space-delimited identifiers: the resource in question, the role, and the member identity, e.g.

```sh
$ pulumi import gcp:datacatalog/entryGroupIamPolicy:EntryGroupIamPolicy editor "projects/{{project}}/locations/{{region}}/entryGroups/{{entry_group}} roles/viewer user:jane@example.com"
```

IAM binding imports use space-delimited identifiers: the resource in question and the role, e.g.

```sh
$ pulumi import gcp:datacatalog/entryGroupIamPolicy:EntryGroupIamPolicy editor "projects/{{project}}/locations/{{region}}/entryGroups/{{entry_group}} roles/viewer"
```

IAM policy imports use the identifier of the resource in question, e.g.

```sh
$ pulumi import gcp:datacatalog/entryGroupIamPolicy:EntryGroupIamPolicy editor projects/{{project}}/locations/{{region}}/entryGroups/{{entry_group}}
```

-> **Custom Roles** If you're importing a IAM resource with a custom role, make sure to use the

 full name of the custom role, e.g. `[projects/my-project|organizations/my-org]/roles/my-custom-role`.

M

entryGroup" ;Used to find the parent resource to bind the IAM policy to
_

policyData" MThe policy data generated by
a `gcp.organizations.getIAMPolicy` data source.

projectB" The ID of the project in which the resource belongs.
If it is not provided, the project will be parsed from the identifier of the parent resource. If no project is provided in the parent identifier and no project is specified, the provider project is used.

regionB" "M

entryGroup" ;Used to find the parent resource to bind the IAM policy to
"3
etag" '(Computed) The etag of the IAM policy.
"_

policyData" MThe policy data generated by
a `gcp.organizations.getIAMPolicy` data source.
"
project" The ID of the project in which the resource belongs.
If it is not provided, the project will be parsed from the identifier of the parent resource. If no project is provided in the parent identifier and no project is specified, the provider project is used.
"
region" *q
=
datacatalog	PolicyTag#gcp:datacatalog/policyTag:PolicyTagbDenotes one policy tag in a taxonomy.


To get more information about PolicyTag, see:

* [API documentation](https://cloud.google.com/data-catalog/docs/reference/rest/v1/projects.locations.taxonomies.policyTags)
* How-to Guides
    * [Official Documentation](https://cloud.google.com/data-catalog/docs)

## Example Usage

### Data Catalog Taxonomies Policy Tag Basic


<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const myTaxonomy = new gcp.datacatalog.Taxonomy("my_taxonomy", {
    displayName: "taxonomy_display_name",
    description: "A collection of policy tags",
    activatedPolicyTypes: ["FINE_GRAINED_ACCESS_CONTROL"],
});
const basicPolicyTag = new gcp.datacatalog.PolicyTag("basic_policy_tag", {
    taxonomy: myTaxonomy.id,
    displayName: "Low security",
    description: "A policy tag normally associated with low security items",
});
```
```python
import pulumi
import pulumi_gcp as gcp

my_taxonomy = gcp.datacatalog.Taxonomy("my_taxonomy",
    display_name="taxonomy_display_name",
    description="A collection of policy tags",
    activated_policy_types=["FINE_GRAINED_ACCESS_CONTROL"])
basic_policy_tag = gcp.datacatalog.PolicyTag("basic_policy_tag",
    taxonomy=my_taxonomy.id,
    display_name="Low security",
    description="A policy tag normally associated with low security items")
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var myTaxonomy = new Gcp.DataCatalog.Taxonomy("my_taxonomy", new()
    {
        DisplayName = "taxonomy_display_name",
        Description = "A collection of policy tags",
        ActivatedPolicyTypes = new[]
        {
            "FINE_GRAINED_ACCESS_CONTROL",
        },
    });

    var basicPolicyTag = new Gcp.DataCatalog.PolicyTag("basic_policy_tag", new()
    {
        Taxonomy = myTaxonomy.Id,
        DisplayName = "Low security",
        Description = "A policy tag normally associated with low security items",
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/datacatalog"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		myTaxonomy, err := datacatalog.NewTaxonomy(ctx, "my_taxonomy", &datacatalog.TaxonomyArgs{
			DisplayName: pulumi.String("taxonomy_display_name"),
			Description: pulumi.String("A collection of policy tags"),
			ActivatedPolicyTypes: pulumi.StringArray{
				pulumi.String("FINE_GRAINED_ACCESS_CONTROL"),
			},
		})
		if err != nil {
			return err
		}
		_, err = datacatalog.NewPolicyTag(ctx, "basic_policy_tag", &datacatalog.PolicyTagArgs{
			Taxonomy:    myTaxonomy.ID(),
			DisplayName: pulumi.String("Low security"),
			Description: pulumi.String("A policy tag normally associated with low security items"),
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.datacatalog.Taxonomy;
import com.pulumi.gcp.datacatalog.TaxonomyArgs;
import com.pulumi.gcp.datacatalog.PolicyTag;
import com.pulumi.gcp.datacatalog.PolicyTagArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        var myTaxonomy = new Taxonomy("myTaxonomy", TaxonomyArgs.builder()
            .displayName("taxonomy_display_name")
            .description("A collection of policy tags")
            .activatedPolicyTypes("FINE_GRAINED_ACCESS_CONTROL")
            .build());

        var basicPolicyTag = new PolicyTag("basicPolicyTag", PolicyTagArgs.builder()
            .taxonomy(myTaxonomy.id())
            .displayName("Low security")
            .description("A policy tag normally associated with low security items")
            .build());

    }
}
```
```yaml
resources:
  basicPolicyTag:
    type: gcp:datacatalog:PolicyTag
    name: basic_policy_tag
    properties:
      taxonomy: ${myTaxonomy.id}
      displayName: Low security
      description: A policy tag normally associated with low security items
  myTaxonomy:
    type: gcp:datacatalog:Taxonomy
    name: my_taxonomy
    properties:
      displayName: taxonomy_display_name
      description: A collection of policy tags
      activatedPolicyTypes:
        - FINE_GRAINED_ACCESS_CONTROL
```
<!--End PulumiCodeChooser -->
### Data Catalog Taxonomies Policy Tag Child Policies


<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const myTaxonomy = new gcp.datacatalog.Taxonomy("my_taxonomy", {
    displayName: "taxonomy_display_name",
    description: "A collection of policy tags",
    activatedPolicyTypes: ["FINE_GRAINED_ACCESS_CONTROL"],
});
const parentPolicy = new gcp.datacatalog.PolicyTag("parent_policy", {
    taxonomy: myTaxonomy.id,
    displayName: "High",
    description: "A policy tag category used for high security access",
});
const childPolicy = new gcp.datacatalog.PolicyTag("child_policy", {
    taxonomy: myTaxonomy.id,
    displayName: "ssn",
    description: "A hash of the users ssn",
    parentPolicyTag: parentPolicy.id,
});
const childPolicy2 = new gcp.datacatalog.PolicyTag("child_policy2", {
    taxonomy: myTaxonomy.id,
    displayName: "dob",
    description: "The users date of birth",
    parentPolicyTag: parentPolicy.id,
}, {
    dependsOn: [childPolicy],
});
```
```python
import pulumi
import pulumi_gcp as gcp

my_taxonomy = gcp.datacatalog.Taxonomy("my_taxonomy",
    display_name="taxonomy_display_name",
    description="A collection of policy tags",
    activated_policy_types=["FINE_GRAINED_ACCESS_CONTROL"])
parent_policy = gcp.datacatalog.PolicyTag("parent_policy",
    taxonomy=my_taxonomy.id,
    display_name="High",
    description="A policy tag category used for high security access")
child_policy = gcp.datacatalog.PolicyTag("child_policy",
    taxonomy=my_taxonomy.id,
    display_name="ssn",
    description="A hash of the users ssn",
    parent_policy_tag=parent_policy.id)
child_policy2 = gcp.datacatalog.PolicyTag("child_policy2",
    taxonomy=my_taxonomy.id,
    display_name="dob",
    description="The users date of birth",
    parent_policy_tag=parent_policy.id,
    opts = pulumi.ResourceOptions(depends_on=[child_policy]))
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var myTaxonomy = new Gcp.DataCatalog.Taxonomy("my_taxonomy", new()
    {
        DisplayName = "taxonomy_display_name",
        Description = "A collection of policy tags",
        ActivatedPolicyTypes = new[]
        {
            "FINE_GRAINED_ACCESS_CONTROL",
        },
    });

    var parentPolicy = new Gcp.DataCatalog.PolicyTag("parent_policy", new()
    {
        Taxonomy = myTaxonomy.Id,
        DisplayName = "High",
        Description = "A policy tag category used for high security access",
    });

    var childPolicy = new Gcp.DataCatalog.PolicyTag("child_policy", new()
    {
        Taxonomy = myTaxonomy.Id,
        DisplayName = "ssn",
        Description = "A hash of the users ssn",
        ParentPolicyTag = parentPolicy.Id,
    });

    var childPolicy2 = new Gcp.DataCatalog.PolicyTag("child_policy2", new()
    {
        Taxonomy = myTaxonomy.Id,
        DisplayName = "dob",
        Description = "The users date of birth",
        ParentPolicyTag = parentPolicy.Id,
    }, new CustomResourceOptions
    {
        DependsOn =
        {
            childPolicy,
        },
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/datacatalog"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		myTaxonomy, err := datacatalog.NewTaxonomy(ctx, "my_taxonomy", &datacatalog.TaxonomyArgs{
			DisplayName: pulumi.String("taxonomy_display_name"),
			Description: pulumi.String("A collection of policy tags"),
			ActivatedPolicyTypes: pulumi.StringArray{
				pulumi.String("FINE_GRAINED_ACCESS_CONTROL"),
			},
		})
		if err != nil {
			return err
		}
		parentPolicy, err := datacatalog.NewPolicyTag(ctx, "parent_policy", &datacatalog.PolicyTagArgs{
			Taxonomy:    myTaxonomy.ID(),
			DisplayName: pulumi.String("High"),
			Description: pulumi.String("A policy tag category used for high security access"),
		})
		if err != nil {
			return err
		}
		childPolicy, err := datacatalog.NewPolicyTag(ctx, "child_policy", &datacatalog.PolicyTagArgs{
			Taxonomy:        myTaxonomy.ID(),
			DisplayName:     pulumi.String("ssn"),
			Description:     pulumi.String("A hash of the users ssn"),
			ParentPolicyTag: parentPolicy.ID(),
		})
		if err != nil {
			return err
		}
		_, err = datacatalog.NewPolicyTag(ctx, "child_policy2", &datacatalog.PolicyTagArgs{
			Taxonomy:        myTaxonomy.ID(),
			DisplayName:     pulumi.String("dob"),
			Description:     pulumi.String("The users date of birth"),
			ParentPolicyTag: parentPolicy.ID(),
		}, pulumi.DependsOn([]pulumi.Resource{
			childPolicy,
		}))
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.datacatalog.Taxonomy;
import com.pulumi.gcp.datacatalog.TaxonomyArgs;
import com.pulumi.gcp.datacatalog.PolicyTag;
import com.pulumi.gcp.datacatalog.PolicyTagArgs;
import com.pulumi.resources.CustomResourceOptions;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        var myTaxonomy = new Taxonomy("myTaxonomy", TaxonomyArgs.builder()
            .displayName("taxonomy_display_name")
            .description("A collection of policy tags")
            .activatedPolicyTypes("FINE_GRAINED_ACCESS_CONTROL")
            .build());

        var parentPolicy = new PolicyTag("parentPolicy", PolicyTagArgs.builder()
            .taxonomy(myTaxonomy.id())
            .displayName("High")
            .description("A policy tag category used for high security access")
            .build());

        var childPolicy = new PolicyTag("childPolicy", PolicyTagArgs.builder()
            .taxonomy(myTaxonomy.id())
            .displayName("ssn")
            .description("A hash of the users ssn")
            .parentPolicyTag(parentPolicy.id())
            .build());

        var childPolicy2 = new PolicyTag("childPolicy2", PolicyTagArgs.builder()
            .taxonomy(myTaxonomy.id())
            .displayName("dob")
            .description("The users date of birth")
            .parentPolicyTag(parentPolicy.id())
            .build(), CustomResourceOptions.builder()
                .dependsOn(childPolicy)
                .build());

    }
}
```
```yaml
resources:
  parentPolicy:
    type: gcp:datacatalog:PolicyTag
    name: parent_policy
    properties:
      taxonomy: ${myTaxonomy.id}
      displayName: High
      description: A policy tag category used for high security access
  childPolicy:
    type: gcp:datacatalog:PolicyTag
    name: child_policy
    properties:
      taxonomy: ${myTaxonomy.id}
      displayName: ssn
      description: A hash of the users ssn
      parentPolicyTag: ${parentPolicy.id}
  childPolicy2:
    type: gcp:datacatalog:PolicyTag
    name: child_policy2
    properties:
      taxonomy: ${myTaxonomy.id}
      displayName: dob
      description: The users date of birth
      parentPolicyTag: ${parentPolicy.id}
    options:
      dependsOn:
        - ${childPolicy}
  myTaxonomy:
    type: gcp:datacatalog:Taxonomy
    name: my_taxonomy
    properties:
      displayName: taxonomy_display_name
      description: A collection of policy tags
      activatedPolicyTypes:
        - FINE_GRAINED_ACCESS_CONTROL
```
<!--End PulumiCodeChooser -->

## Import

PolicyTag can be imported using any of these accepted formats:

* `{{name}}`

When using the `pulumi import` command, PolicyTag can be imported using one of the formats above. For example:

```sh
$ pulumi import gcp:datacatalog/policyTag:PolicyTag default {{name}}
```

¤
descriptionB" Description of this policy tag. It must: contain only unicode characters, tabs,
newlines, carriage returns and page breaks; and be at most 2000 bytes long when
encoded in UTF-8. If not set, defaults to an empty description.
If not set, defaults to an empty description.

displayName" ïUser defined name of this policy tag. It must: be unique within the parent
taxonomy; contain only unicode letters, numbers, underscores, dashes and spaces;
not start or end with spaces; and be at most 200 bytes long when encoded in UTF-8.
·
parentPolicyTagB" Resource name of this policy tag's parent policy tag.
If empty, it means this policy tag is a top level policy tag.
If not set, defaults to an empty string.
C
taxonomy" 3Taxonomy the policy tag is associated with


- - -
"Q
childPolicyTags*" 8Resource names of child policy tags of this policy tag.
"¤
descriptionB" Description of this policy tag. It must: contain only unicode characters, tabs,
newlines, carriage returns and page breaks; and be at most 2000 bytes long when
encoded in UTF-8. If not set, defaults to an empty description.
If not set, defaults to an empty description.
"
displayName" ïUser defined name of this policy tag. It must: be unique within the parent
taxonomy; contain only unicode letters, numbers, underscores, dashes and spaces;
not start or end with spaces; and be at most 200 bytes long when encoded in UTF-8.
"
name" Resource name of this policy tag, whose format is:
"projects/{project}/locations/{region}/taxonomies/{taxonomy}/policyTags/{policytag}"
"·
parentPolicyTagB" Resource name of this policy tag's parent policy tag.
If empty, it means this policy tag is a top level policy tag.
If not set, defaults to an empty string.
"C
taxonomy" 3Taxonomy the policy tag is associated with


- - -
*ÚÄ
[
datacatalogPolicyTagIamBinding7gcp:datacatalog/policyTagIamBinding:PolicyTagIamBinding ©Three different resources help you manage your IAM policy for Data catalog PolicyTag. Each of these resources serves a different use case:

* `gcp.datacatalog.PolicyTagIamPolicy`: Authoritative. Sets the IAM policy for the policytag and replaces any existing policy already attached.
* `gcp.datacatalog.PolicyTagIamBinding`: Authoritative for a given role. Updates the IAM policy to grant a role to a list of members. Other roles within the IAM policy for the policytag are preserved.
* `gcp.datacatalog.PolicyTagIamMember`: Non-authoritative. Updates the IAM policy to grant a role to a new member. Other members for the role for the policytag are preserved.

A data source can be used to retrieve policy data in advent you do not need creation

* `gcp.datacatalog.PolicyTagIamPolicy`: Retrieves the IAM policy for the policytag

> **Note:** `gcp.datacatalog.PolicyTagIamPolicy` **cannot** be used in conjunction with `gcp.datacatalog.PolicyTagIamBinding` and `gcp.datacatalog.PolicyTagIamMember` or they will fight over what your policy should be.

> **Note:** `gcp.datacatalog.PolicyTagIamBinding` resources **can be** used in conjunction with `gcp.datacatalog.PolicyTagIamMember` resources **only if** they do not grant privilege to the same role.



## gcp.datacatalog.PolicyTagIamPolicy

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const admin = gcp.organizations.getIAMPolicy({
    bindings: [{
        role: "roles/viewer",
        members: ["user:jane@example.com"],
    }],
});
const policy = new gcp.datacatalog.PolicyTagIamPolicy("policy", {
    policyTag: basicPolicyTag.name,
    policyData: admin.then(admin => admin.policyData),
});
```
```python
import pulumi
import pulumi_gcp as gcp

admin = gcp.organizations.get_iam_policy(bindings=[{
    "role": "roles/viewer",
    "members": ["user:jane@example.com"],
}])
policy = gcp.datacatalog.PolicyTagIamPolicy("policy",
    policy_tag=basic_policy_tag["name"],
    policy_data=admin.policy_data)
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var admin = Gcp.Organizations.GetIAMPolicy.Invoke(new()
    {
        Bindings = new[]
        {
            new Gcp.Organizations.Inputs.GetIAMPolicyBindingInputArgs
            {
                Role = "roles/viewer",
                Members = new[]
                {
                    "user:jane@example.com",
                },
            },
        },
    });

    var policy = new Gcp.DataCatalog.PolicyTagIamPolicy("policy", new()
    {
        PolicyTag = basicPolicyTag.Name,
        PolicyData = admin.Apply(getIAMPolicyResult => getIAMPolicyResult.PolicyData),
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/datacatalog"
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/organizations"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		admin, err := organizations.LookupIAMPolicy(ctx, &organizations.LookupIAMPolicyArgs{
			Bindings: []organizations.GetIAMPolicyBinding{
				{
					Role: "roles/viewer",
					Members: []string{
						"user:jane@example.com",
					},
				},
			},
		}, nil)
		if err != nil {
			return err
		}
		_, err = datacatalog.NewPolicyTagIamPolicy(ctx, "policy", &datacatalog.PolicyTagIamPolicyArgs{
			PolicyTag:  pulumi.Any(basicPolicyTag.Name),
			PolicyData: pulumi.String(admin.PolicyData),
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.organizations.OrganizationsFunctions;
import com.pulumi.gcp.organizations.inputs.GetIAMPolicyArgs;
import com.pulumi.gcp.datacatalog.PolicyTagIamPolicy;
import com.pulumi.gcp.datacatalog.PolicyTagIamPolicyArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        final var admin = OrganizationsFunctions.getIAMPolicy(GetIAMPolicyArgs.builder()
            .bindings(GetIAMPolicyBindingArgs.builder()
                .role("roles/viewer")
                .members("user:jane@example.com")
                .build())
            .build());

        var policy = new PolicyTagIamPolicy("policy", PolicyTagIamPolicyArgs.builder()
            .policyTag(basicPolicyTag.name())
            .policyData(admin.applyValue(getIAMPolicyResult -> getIAMPolicyResult.policyData()))
            .build());

    }
}
```
```yaml
resources:
  policy:
    type: gcp:datacatalog:PolicyTagIamPolicy
    properties:
      policyTag: ${basicPolicyTag.name}
      policyData: ${admin.policyData}
variables:
  admin:
    fn::invoke:
      function: gcp:organizations:getIAMPolicy
      arguments:
        bindings:
          - role: roles/viewer
            members:
              - user:jane@example.com
```
<!--End PulumiCodeChooser -->

## gcp.datacatalog.PolicyTagIamBinding

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const binding = new gcp.datacatalog.PolicyTagIamBinding("binding", {
    policyTag: basicPolicyTag.name,
    role: "roles/viewer",
    members: ["user:jane@example.com"],
});
```
```python
import pulumi
import pulumi_gcp as gcp

binding = gcp.datacatalog.PolicyTagIamBinding("binding",
    policy_tag=basic_policy_tag["name"],
    role="roles/viewer",
    members=["user:jane@example.com"])
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var binding = new Gcp.DataCatalog.PolicyTagIamBinding("binding", new()
    {
        PolicyTag = basicPolicyTag.Name,
        Role = "roles/viewer",
        Members = new[]
        {
            "user:jane@example.com",
        },
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/datacatalog"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		_, err := datacatalog.NewPolicyTagIamBinding(ctx, "binding", &datacatalog.PolicyTagIamBindingArgs{
			PolicyTag: pulumi.Any(basicPolicyTag.Name),
			Role:      pulumi.String("roles/viewer"),
			Members: pulumi.StringArray{
				pulumi.String("user:jane@example.com"),
			},
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.datacatalog.PolicyTagIamBinding;
import com.pulumi.gcp.datacatalog.PolicyTagIamBindingArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        var binding = new PolicyTagIamBinding("binding", PolicyTagIamBindingArgs.builder()
            .policyTag(basicPolicyTag.name())
            .role("roles/viewer")
            .members("user:jane@example.com")
            .build());

    }
}
```
```yaml
resources:
  binding:
    type: gcp:datacatalog:PolicyTagIamBinding
    properties:
      policyTag: ${basicPolicyTag.name}
      role: roles/viewer
      members:
        - user:jane@example.com
```
<!--End PulumiCodeChooser -->

## gcp.datacatalog.PolicyTagIamMember

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const member = new gcp.datacatalog.PolicyTagIamMember("member", {
    policyTag: basicPolicyTag.name,
    role: "roles/viewer",
    member: "user:jane@example.com",
});
```
```python
import pulumi
import pulumi_gcp as gcp

member = gcp.datacatalog.PolicyTagIamMember("member",
    policy_tag=basic_policy_tag["name"],
    role="roles/viewer",
    member="user:jane@example.com")
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var member = new Gcp.DataCatalog.PolicyTagIamMember("member", new()
    {
        PolicyTag = basicPolicyTag.Name,
        Role = "roles/viewer",
        Member = "user:jane@example.com",
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/datacatalog"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		_, err := datacatalog.NewPolicyTagIamMember(ctx, "member", &datacatalog.PolicyTagIamMemberArgs{
			PolicyTag: pulumi.Any(basicPolicyTag.Name),
			Role:      pulumi.String("roles/viewer"),
			Member:    pulumi.String("user:jane@example.com"),
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.datacatalog.PolicyTagIamMember;
import com.pulumi.gcp.datacatalog.PolicyTagIamMemberArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        var member = new PolicyTagIamMember("member", PolicyTagIamMemberArgs.builder()
            .policyTag(basicPolicyTag.name())
            .role("roles/viewer")
            .member("user:jane@example.com")
            .build());

    }
}
```
```yaml
resources:
  member:
    type: gcp:datacatalog:PolicyTagIamMember
    properties:
      policyTag: ${basicPolicyTag.name}
      role: roles/viewer
      member: user:jane@example.com
```
<!--End PulumiCodeChooser -->


## > **Custom Roles** If you're importing a IAM resource with a custom role, make sure to use the

 full name of the custom role, e.g. `[projects/my-project|organizations/my-org]/roles/my-custom-role`.
-

# IAM policy for Data catalog PolicyTag
Three different resources help you manage your IAM policy for Data catalog PolicyTag. Each of these resources serves a different use case:

* `gcp.datacatalog.PolicyTagIamPolicy`: Authoritative. Sets the IAM policy for the policytag and replaces any existing policy already attached.
* `gcp.datacatalog.PolicyTagIamBinding`: Authoritative for a given role. Updates the IAM policy to grant a role to a list of members. Other roles within the IAM policy for the policytag are preserved.
* `gcp.datacatalog.PolicyTagIamMember`: Non-authoritative. Updates the IAM policy to grant a role to a new member. Other members for the role for the policytag are preserved.

A data source can be used to retrieve policy data in advent you do not need creation

* `gcp.datacatalog.PolicyTagIamPolicy`: Retrieves the IAM policy for the policytag

> **Note:** `gcp.datacatalog.PolicyTagIamPolicy` **cannot** be used in conjunction with `gcp.datacatalog.PolicyTagIamBinding` and `gcp.datacatalog.PolicyTagIamMember` or they will fight over what your policy should be.

> **Note:** `gcp.datacatalog.PolicyTagIamBinding` resources **can be** used in conjunction with `gcp.datacatalog.PolicyTagIamMember` resources **only if** they do not grant privilege to the same role.



## gcp.datacatalog.PolicyTagIamPolicy

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const admin = gcp.organizations.getIAMPolicy({
    bindings: [{
        role: "roles/viewer",
        members: ["user:jane@example.com"],
    }],
});
const policy = new gcp.datacatalog.PolicyTagIamPolicy("policy", {
    policyTag: basicPolicyTag.name,
    policyData: admin.then(admin => admin.policyData),
});
```
```python
import pulumi
import pulumi_gcp as gcp

admin = gcp.organizations.get_iam_policy(bindings=[{
    "role": "roles/viewer",
    "members": ["user:jane@example.com"],
}])
policy = gcp.datacatalog.PolicyTagIamPolicy("policy",
    policy_tag=basic_policy_tag["name"],
    policy_data=admin.policy_data)
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var admin = Gcp.Organizations.GetIAMPolicy.Invoke(new()
    {
        Bindings = new[]
        {
            new Gcp.Organizations.Inputs.GetIAMPolicyBindingInputArgs
            {
                Role = "roles/viewer",
                Members = new[]
                {
                    "user:jane@example.com",
                },
            },
        },
    });

    var policy = new Gcp.DataCatalog.PolicyTagIamPolicy("policy", new()
    {
        PolicyTag = basicPolicyTag.Name,
        PolicyData = admin.Apply(getIAMPolicyResult => getIAMPolicyResult.PolicyData),
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/datacatalog"
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/organizations"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		admin, err := organizations.LookupIAMPolicy(ctx, &organizations.LookupIAMPolicyArgs{
			Bindings: []organizations.GetIAMPolicyBinding{
				{
					Role: "roles/viewer",
					Members: []string{
						"user:jane@example.com",
					},
				},
			},
		}, nil)
		if err != nil {
			return err
		}
		_, err = datacatalog.NewPolicyTagIamPolicy(ctx, "policy", &datacatalog.PolicyTagIamPolicyArgs{
			PolicyTag:  pulumi.Any(basicPolicyTag.Name),
			PolicyData: pulumi.String(admin.PolicyData),
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.organizations.OrganizationsFunctions;
import com.pulumi.gcp.organizations.inputs.GetIAMPolicyArgs;
import com.pulumi.gcp.datacatalog.PolicyTagIamPolicy;
import com.pulumi.gcp.datacatalog.PolicyTagIamPolicyArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        final var admin = OrganizationsFunctions.getIAMPolicy(GetIAMPolicyArgs.builder()
            .bindings(GetIAMPolicyBindingArgs.builder()
                .role("roles/viewer")
                .members("user:jane@example.com")
                .build())
            .build());

        var policy = new PolicyTagIamPolicy("policy", PolicyTagIamPolicyArgs.builder()
            .policyTag(basicPolicyTag.name())
            .policyData(admin.applyValue(getIAMPolicyResult -> getIAMPolicyResult.policyData()))
            .build());

    }
}
```
```yaml
resources:
  policy:
    type: gcp:datacatalog:PolicyTagIamPolicy
    properties:
      policyTag: ${basicPolicyTag.name}
      policyData: ${admin.policyData}
variables:
  admin:
    fn::invoke:
      function: gcp:organizations:getIAMPolicy
      arguments:
        bindings:
          - role: roles/viewer
            members:
              - user:jane@example.com
```
<!--End PulumiCodeChooser -->

## gcp.datacatalog.PolicyTagIamBinding

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const binding = new gcp.datacatalog.PolicyTagIamBinding("binding", {
    policyTag: basicPolicyTag.name,
    role: "roles/viewer",
    members: ["user:jane@example.com"],
});
```
```python
import pulumi
import pulumi_gcp as gcp

binding = gcp.datacatalog.PolicyTagIamBinding("binding",
    policy_tag=basic_policy_tag["name"],
    role="roles/viewer",
    members=["user:jane@example.com"])
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var binding = new Gcp.DataCatalog.PolicyTagIamBinding("binding", new()
    {
        PolicyTag = basicPolicyTag.Name,
        Role = "roles/viewer",
        Members = new[]
        {
            "user:jane@example.com",
        },
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/datacatalog"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		_, err := datacatalog.NewPolicyTagIamBinding(ctx, "binding", &datacatalog.PolicyTagIamBindingArgs{
			PolicyTag: pulumi.Any(basicPolicyTag.Name),
			Role:      pulumi.String("roles/viewer"),
			Members: pulumi.StringArray{
				pulumi.String("user:jane@example.com"),
			},
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.datacatalog.PolicyTagIamBinding;
import com.pulumi.gcp.datacatalog.PolicyTagIamBindingArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        var binding = new PolicyTagIamBinding("binding", PolicyTagIamBindingArgs.builder()
            .policyTag(basicPolicyTag.name())
            .role("roles/viewer")
            .members("user:jane@example.com")
            .build());

    }
}
```
```yaml
resources:
  binding:
    type: gcp:datacatalog:PolicyTagIamBinding
    properties:
      policyTag: ${basicPolicyTag.name}
      role: roles/viewer
      members:
        - user:jane@example.com
```
<!--End PulumiCodeChooser -->

## gcp.datacatalog.PolicyTagIamMember

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const member = new gcp.datacatalog.PolicyTagIamMember("member", {
    policyTag: basicPolicyTag.name,
    role: "roles/viewer",
    member: "user:jane@example.com",
});
```
```python
import pulumi
import pulumi_gcp as gcp

member = gcp.datacatalog.PolicyTagIamMember("member",
    policy_tag=basic_policy_tag["name"],
    role="roles/viewer",
    member="user:jane@example.com")
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var member = new Gcp.DataCatalog.PolicyTagIamMember("member", new()
    {
        PolicyTag = basicPolicyTag.Name,
        Role = "roles/viewer",
        Member = "user:jane@example.com",
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/datacatalog"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		_, err := datacatalog.NewPolicyTagIamMember(ctx, "member", &datacatalog.PolicyTagIamMemberArgs{
			PolicyTag: pulumi.Any(basicPolicyTag.Name),
			Role:      pulumi.String("roles/viewer"),
			Member:    pulumi.String("user:jane@example.com"),
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.datacatalog.PolicyTagIamMember;
import com.pulumi.gcp.datacatalog.PolicyTagIamMemberArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        var member = new PolicyTagIamMember("member", PolicyTagIamMemberArgs.builder()
            .policyTag(basicPolicyTag.name())
            .role("roles/viewer")
            .member("user:jane@example.com")
            .build());

    }
}
```
```yaml
resources:
  member:
    type: gcp:datacatalog:PolicyTagIamMember
    properties:
      policyTag: ${basicPolicyTag.name}
      role: roles/viewer
      member: user:jane@example.com
```
<!--End PulumiCodeChooser -->

## Import

For all import syntaxes, the "resource in question" can take any of the following forms:

* {{policy_tag}}

Any variables not passed in the import command will be taken from the provider configuration.

Data catalog policytag IAM resources can be imported using the resource identifiers, role, and member.

IAM member imports use space-delimited identifiers: the resource in question, the role, and the member identity, e.g.

```sh
$ pulumi import gcp:datacatalog/policyTagIamBinding:PolicyTagIamBinding editor "{{policy_tag}} roles/viewer user:jane@example.com"
```

IAM binding imports use space-delimited identifiers: the resource in question and the role, e.g.

```sh
$ pulumi import gcp:datacatalog/policyTagIamBinding:PolicyTagIamBinding editor "{{policy_tag}} roles/viewer"
```

IAM policy imports use the identifier of the resource in question, e.g.

```sh
$ pulumi import gcp:datacatalog/policyTagIamBinding:PolicyTagIamBinding editor {{policy_tag}}
```

-> **Custom Roles** If you're importing a IAM resource with a custom role, make sure to use the

 full name of the custom role, e.g. `[projects/my-project|organizations/my-org]/roles/my-custom-role`.


	condition|Bz:x
v
datacatalogPolicyTagIamBindingConditionIgcp:datacatalog/PolicyTagIamBindingCondition:PolicyTagIamBindingConditionÖ	
members*" Ä	Identities that will be granted the privilege in `role`.
Each entry can have one of the following values:
* **allUsers**: A special identifier that represents anyone who is on the internet; with or without a Google account.
* **allAuthenticatedUsers**: A special identifier that represents anyone who is authenticated with a Google account or a service account.
* **user:{emailid}**: An email address that represents a specific Google account. For example, alice@gmail.com or joe@example.com.
* **serviceAccount:{emailid}**: An email address that represents a service account. For example, my-other-app@appspot.gserviceaccount.com.
* **group:{emailid}**: An email address that represents a Google group. For example, admins@example.com.
* **domain:{domain}**: A G Suite domain (primary, instead of alias) name that represents all the users of that domain. For example, google.com or example.com.
* **projectOwner:projectid**: Owners of the given project. For example, "projectOwner:my-example-project"
* **projectEditor:projectid**: Editors of the given project. For example, "projectEditor:my-example-project"
* **projectViewer:projectid**: Viewers of the given project. For example, "projectViewer:my-example-project"
L
	policyTag" ;Used to find the parent resource to bind the IAM policy to
Ü
role" ÏThe role that should be applied. Only one
`gcp.datacatalog.PolicyTagIamBinding` can be used per role. Note that custom roles must be of the format
`[projects|organizations]/{parent-name}/roles/{role-name}`.
"
	condition|Bz:x
v
datacatalogPolicyTagIamBindingConditionIgcp:datacatalog/PolicyTagIamBindingCondition:PolicyTagIamBindingCondition"3
etag" '(Computed) The etag of the IAM policy.
"Ö	
members*" Ä	Identities that will be granted the privilege in `role`.
Each entry can have one of the following values:
* **allUsers**: A special identifier that represents anyone who is on the internet; with or without a Google account.
* **allAuthenticatedUsers**: A special identifier that represents anyone who is authenticated with a Google account or a service account.
* **user:{emailid}**: An email address that represents a specific Google account. For example, alice@gmail.com or joe@example.com.
* **serviceAccount:{emailid}**: An email address that represents a service account. For example, my-other-app@appspot.gserviceaccount.com.
* **group:{emailid}**: An email address that represents a Google group. For example, admins@example.com.
* **domain:{domain}**: A G Suite domain (primary, instead of alias) name that represents all the users of that domain. For example, google.com or example.com.
* **projectOwner:projectid**: Owners of the given project. For example, "projectOwner:my-example-project"
* **projectEditor:projectid**: Editors of the given project. For example, "projectEditor:my-example-project"
* **projectViewer:projectid**: Viewers of the given project. For example, "projectViewer:my-example-project"
"L
	policyTag" ;Used to find the parent resource to bind the IAM policy to
"Ü
role" ÏThe role that should be applied. Only one
`gcp.datacatalog.PolicyTagIamBinding` can be used per role. Note that custom roles must be of the format
`[projects|organizations]/{parent-name}/roles/{role-name}`.
*ÅÄ
X
datacatalogPolicyTagIamMember5gcp:datacatalog/policyTagIamMember:PolicyTagIamMember©Three different resources help you manage your IAM policy for Data catalog PolicyTag. Each of these resources serves a different use case:

* `gcp.datacatalog.PolicyTagIamPolicy`: Authoritative. Sets the IAM policy for the policytag and replaces any existing policy already attached.
* `gcp.datacatalog.PolicyTagIamBinding`: Authoritative for a given role. Updates the IAM policy to grant a role to a list of members. Other roles within the IAM policy for the policytag are preserved.
* `gcp.datacatalog.PolicyTagIamMember`: Non-authoritative. Updates the IAM policy to grant a role to a new member. Other members for the role for the policytag are preserved.

A data source can be used to retrieve policy data in advent you do not need creation

* `gcp.datacatalog.PolicyTagIamPolicy`: Retrieves the IAM policy for the policytag

> **Note:** `gcp.datacatalog.PolicyTagIamPolicy` **cannot** be used in conjunction with `gcp.datacatalog.PolicyTagIamBinding` and `gcp.datacatalog.PolicyTagIamMember` or they will fight over what your policy should be.

> **Note:** `gcp.datacatalog.PolicyTagIamBinding` resources **can be** used in conjunction with `gcp.datacatalog.PolicyTagIamMember` resources **only if** they do not grant privilege to the same role.



## gcp.datacatalog.PolicyTagIamPolicy

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const admin = gcp.organizations.getIAMPolicy({
    bindings: [{
        role: "roles/viewer",
        members: ["user:jane@example.com"],
    }],
});
const policy = new gcp.datacatalog.PolicyTagIamPolicy("policy", {
    policyTag: basicPolicyTag.name,
    policyData: admin.then(admin => admin.policyData),
});
```
```python
import pulumi
import pulumi_gcp as gcp

admin = gcp.organizations.get_iam_policy(bindings=[{
    "role": "roles/viewer",
    "members": ["user:jane@example.com"],
}])
policy = gcp.datacatalog.PolicyTagIamPolicy("policy",
    policy_tag=basic_policy_tag["name"],
    policy_data=admin.policy_data)
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var admin = Gcp.Organizations.GetIAMPolicy.Invoke(new()
    {
        Bindings = new[]
        {
            new Gcp.Organizations.Inputs.GetIAMPolicyBindingInputArgs
            {
                Role = "roles/viewer",
                Members = new[]
                {
                    "user:jane@example.com",
                },
            },
        },
    });

    var policy = new Gcp.DataCatalog.PolicyTagIamPolicy("policy", new()
    {
        PolicyTag = basicPolicyTag.Name,
        PolicyData = admin.Apply(getIAMPolicyResult => getIAMPolicyResult.PolicyData),
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/datacatalog"
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/organizations"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		admin, err := organizations.LookupIAMPolicy(ctx, &organizations.LookupIAMPolicyArgs{
			Bindings: []organizations.GetIAMPolicyBinding{
				{
					Role: "roles/viewer",
					Members: []string{
						"user:jane@example.com",
					},
				},
			},
		}, nil)
		if err != nil {
			return err
		}
		_, err = datacatalog.NewPolicyTagIamPolicy(ctx, "policy", &datacatalog.PolicyTagIamPolicyArgs{
			PolicyTag:  pulumi.Any(basicPolicyTag.Name),
			PolicyData: pulumi.String(admin.PolicyData),
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.organizations.OrganizationsFunctions;
import com.pulumi.gcp.organizations.inputs.GetIAMPolicyArgs;
import com.pulumi.gcp.datacatalog.PolicyTagIamPolicy;
import com.pulumi.gcp.datacatalog.PolicyTagIamPolicyArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        final var admin = OrganizationsFunctions.getIAMPolicy(GetIAMPolicyArgs.builder()
            .bindings(GetIAMPolicyBindingArgs.builder()
                .role("roles/viewer")
                .members("user:jane@example.com")
                .build())
            .build());

        var policy = new PolicyTagIamPolicy("policy", PolicyTagIamPolicyArgs.builder()
            .policyTag(basicPolicyTag.name())
            .policyData(admin.applyValue(getIAMPolicyResult -> getIAMPolicyResult.policyData()))
            .build());

    }
}
```
```yaml
resources:
  policy:
    type: gcp:datacatalog:PolicyTagIamPolicy
    properties:
      policyTag: ${basicPolicyTag.name}
      policyData: ${admin.policyData}
variables:
  admin:
    fn::invoke:
      function: gcp:organizations:getIAMPolicy
      arguments:
        bindings:
          - role: roles/viewer
            members:
              - user:jane@example.com
```
<!--End PulumiCodeChooser -->

## gcp.datacatalog.PolicyTagIamBinding

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const binding = new gcp.datacatalog.PolicyTagIamBinding("binding", {
    policyTag: basicPolicyTag.name,
    role: "roles/viewer",
    members: ["user:jane@example.com"],
});
```
```python
import pulumi
import pulumi_gcp as gcp

binding = gcp.datacatalog.PolicyTagIamBinding("binding",
    policy_tag=basic_policy_tag["name"],
    role="roles/viewer",
    members=["user:jane@example.com"])
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var binding = new Gcp.DataCatalog.PolicyTagIamBinding("binding", new()
    {
        PolicyTag = basicPolicyTag.Name,
        Role = "roles/viewer",
        Members = new[]
        {
            "user:jane@example.com",
        },
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/datacatalog"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		_, err := datacatalog.NewPolicyTagIamBinding(ctx, "binding", &datacatalog.PolicyTagIamBindingArgs{
			PolicyTag: pulumi.Any(basicPolicyTag.Name),
			Role:      pulumi.String("roles/viewer"),
			Members: pulumi.StringArray{
				pulumi.String("user:jane@example.com"),
			},
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.datacatalog.PolicyTagIamBinding;
import com.pulumi.gcp.datacatalog.PolicyTagIamBindingArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        var binding = new PolicyTagIamBinding("binding", PolicyTagIamBindingArgs.builder()
            .policyTag(basicPolicyTag.name())
            .role("roles/viewer")
            .members("user:jane@example.com")
            .build());

    }
}
```
```yaml
resources:
  binding:
    type: gcp:datacatalog:PolicyTagIamBinding
    properties:
      policyTag: ${basicPolicyTag.name}
      role: roles/viewer
      members:
        - user:jane@example.com
```
<!--End PulumiCodeChooser -->

## gcp.datacatalog.PolicyTagIamMember

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const member = new gcp.datacatalog.PolicyTagIamMember("member", {
    policyTag: basicPolicyTag.name,
    role: "roles/viewer",
    member: "user:jane@example.com",
});
```
```python
import pulumi
import pulumi_gcp as gcp

member = gcp.datacatalog.PolicyTagIamMember("member",
    policy_tag=basic_policy_tag["name"],
    role="roles/viewer",
    member="user:jane@example.com")
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var member = new Gcp.DataCatalog.PolicyTagIamMember("member", new()
    {
        PolicyTag = basicPolicyTag.Name,
        Role = "roles/viewer",
        Member = "user:jane@example.com",
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/datacatalog"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		_, err := datacatalog.NewPolicyTagIamMember(ctx, "member", &datacatalog.PolicyTagIamMemberArgs{
			PolicyTag: pulumi.Any(basicPolicyTag.Name),
			Role:      pulumi.String("roles/viewer"),
			Member:    pulumi.String("user:jane@example.com"),
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.datacatalog.PolicyTagIamMember;
import com.pulumi.gcp.datacatalog.PolicyTagIamMemberArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        var member = new PolicyTagIamMember("member", PolicyTagIamMemberArgs.builder()
            .policyTag(basicPolicyTag.name())
            .role("roles/viewer")
            .member("user:jane@example.com")
            .build());

    }
}
```
```yaml
resources:
  member:
    type: gcp:datacatalog:PolicyTagIamMember
    properties:
      policyTag: ${basicPolicyTag.name}
      role: roles/viewer
      member: user:jane@example.com
```
<!--End PulumiCodeChooser -->


## > **Custom Roles** If you're importing a IAM resource with a custom role, make sure to use the

 full name of the custom role, e.g. `[projects/my-project|organizations/my-org]/roles/my-custom-role`.
-

# IAM policy for Data catalog PolicyTag
Three different resources help you manage your IAM policy for Data catalog PolicyTag. Each of these resources serves a different use case:

* `gcp.datacatalog.PolicyTagIamPolicy`: Authoritative. Sets the IAM policy for the policytag and replaces any existing policy already attached.
* `gcp.datacatalog.PolicyTagIamBinding`: Authoritative for a given role. Updates the IAM policy to grant a role to a list of members. Other roles within the IAM policy for the policytag are preserved.
* `gcp.datacatalog.PolicyTagIamMember`: Non-authoritative. Updates the IAM policy to grant a role to a new member. Other members for the role for the policytag are preserved.

A data source can be used to retrieve policy data in advent you do not need creation

* `gcp.datacatalog.PolicyTagIamPolicy`: Retrieves the IAM policy for the policytag

> **Note:** `gcp.datacatalog.PolicyTagIamPolicy` **cannot** be used in conjunction with `gcp.datacatalog.PolicyTagIamBinding` and `gcp.datacatalog.PolicyTagIamMember` or they will fight over what your policy should be.

> **Note:** `gcp.datacatalog.PolicyTagIamBinding` resources **can be** used in conjunction with `gcp.datacatalog.PolicyTagIamMember` resources **only if** they do not grant privilege to the same role.



## gcp.datacatalog.PolicyTagIamPolicy

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const admin = gcp.organizations.getIAMPolicy({
    bindings: [{
        role: "roles/viewer",
        members: ["user:jane@example.com"],
    }],
});
const policy = new gcp.datacatalog.PolicyTagIamPolicy("policy", {
    policyTag: basicPolicyTag.name,
    policyData: admin.then(admin => admin.policyData),
});
```
```python
import pulumi
import pulumi_gcp as gcp

admin = gcp.organizations.get_iam_policy(bindings=[{
    "role": "roles/viewer",
    "members": ["user:jane@example.com"],
}])
policy = gcp.datacatalog.PolicyTagIamPolicy("policy",
    policy_tag=basic_policy_tag["name"],
    policy_data=admin.policy_data)
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var admin = Gcp.Organizations.GetIAMPolicy.Invoke(new()
    {
        Bindings = new[]
        {
            new Gcp.Organizations.Inputs.GetIAMPolicyBindingInputArgs
            {
                Role = "roles/viewer",
                Members = new[]
                {
                    "user:jane@example.com",
                },
            },
        },
    });

    var policy = new Gcp.DataCatalog.PolicyTagIamPolicy("policy", new()
    {
        PolicyTag = basicPolicyTag.Name,
        PolicyData = admin.Apply(getIAMPolicyResult => getIAMPolicyResult.PolicyData),
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/datacatalog"
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/organizations"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		admin, err := organizations.LookupIAMPolicy(ctx, &organizations.LookupIAMPolicyArgs{
			Bindings: []organizations.GetIAMPolicyBinding{
				{
					Role: "roles/viewer",
					Members: []string{
						"user:jane@example.com",
					},
				},
			},
		}, nil)
		if err != nil {
			return err
		}
		_, err = datacatalog.NewPolicyTagIamPolicy(ctx, "policy", &datacatalog.PolicyTagIamPolicyArgs{
			PolicyTag:  pulumi.Any(basicPolicyTag.Name),
			PolicyData: pulumi.String(admin.PolicyData),
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.organizations.OrganizationsFunctions;
import com.pulumi.gcp.organizations.inputs.GetIAMPolicyArgs;
import com.pulumi.gcp.datacatalog.PolicyTagIamPolicy;
import com.pulumi.gcp.datacatalog.PolicyTagIamPolicyArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        final var admin = OrganizationsFunctions.getIAMPolicy(GetIAMPolicyArgs.builder()
            .bindings(GetIAMPolicyBindingArgs.builder()
                .role("roles/viewer")
                .members("user:jane@example.com")
                .build())
            .build());

        var policy = new PolicyTagIamPolicy("policy", PolicyTagIamPolicyArgs.builder()
            .policyTag(basicPolicyTag.name())
            .policyData(admin.applyValue(getIAMPolicyResult -> getIAMPolicyResult.policyData()))
            .build());

    }
}
```
```yaml
resources:
  policy:
    type: gcp:datacatalog:PolicyTagIamPolicy
    properties:
      policyTag: ${basicPolicyTag.name}
      policyData: ${admin.policyData}
variables:
  admin:
    fn::invoke:
      function: gcp:organizations:getIAMPolicy
      arguments:
        bindings:
          - role: roles/viewer
            members:
              - user:jane@example.com
```
<!--End PulumiCodeChooser -->

## gcp.datacatalog.PolicyTagIamBinding

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const binding = new gcp.datacatalog.PolicyTagIamBinding("binding", {
    policyTag: basicPolicyTag.name,
    role: "roles/viewer",
    members: ["user:jane@example.com"],
});
```
```python
import pulumi
import pulumi_gcp as gcp

binding = gcp.datacatalog.PolicyTagIamBinding("binding",
    policy_tag=basic_policy_tag["name"],
    role="roles/viewer",
    members=["user:jane@example.com"])
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var binding = new Gcp.DataCatalog.PolicyTagIamBinding("binding", new()
    {
        PolicyTag = basicPolicyTag.Name,
        Role = "roles/viewer",
        Members = new[]
        {
            "user:jane@example.com",
        },
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/datacatalog"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		_, err := datacatalog.NewPolicyTagIamBinding(ctx, "binding", &datacatalog.PolicyTagIamBindingArgs{
			PolicyTag: pulumi.Any(basicPolicyTag.Name),
			Role:      pulumi.String("roles/viewer"),
			Members: pulumi.StringArray{
				pulumi.String("user:jane@example.com"),
			},
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.datacatalog.PolicyTagIamBinding;
import com.pulumi.gcp.datacatalog.PolicyTagIamBindingArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        var binding = new PolicyTagIamBinding("binding", PolicyTagIamBindingArgs.builder()
            .policyTag(basicPolicyTag.name())
            .role("roles/viewer")
            .members("user:jane@example.com")
            .build());

    }
}
```
```yaml
resources:
  binding:
    type: gcp:datacatalog:PolicyTagIamBinding
    properties:
      policyTag: ${basicPolicyTag.name}
      role: roles/viewer
      members:
        - user:jane@example.com
```
<!--End PulumiCodeChooser -->

## gcp.datacatalog.PolicyTagIamMember

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const member = new gcp.datacatalog.PolicyTagIamMember("member", {
    policyTag: basicPolicyTag.name,
    role: "roles/viewer",
    member: "user:jane@example.com",
});
```
```python
import pulumi
import pulumi_gcp as gcp

member = gcp.datacatalog.PolicyTagIamMember("member",
    policy_tag=basic_policy_tag["name"],
    role="roles/viewer",
    member="user:jane@example.com")
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var member = new Gcp.DataCatalog.PolicyTagIamMember("member", new()
    {
        PolicyTag = basicPolicyTag.Name,
        Role = "roles/viewer",
        Member = "user:jane@example.com",
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/datacatalog"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		_, err := datacatalog.NewPolicyTagIamMember(ctx, "member", &datacatalog.PolicyTagIamMemberArgs{
			PolicyTag: pulumi.Any(basicPolicyTag.Name),
			Role:      pulumi.String("roles/viewer"),
			Member:    pulumi.String("user:jane@example.com"),
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.datacatalog.PolicyTagIamMember;
import com.pulumi.gcp.datacatalog.PolicyTagIamMemberArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        var member = new PolicyTagIamMember("member", PolicyTagIamMemberArgs.builder()
            .policyTag(basicPolicyTag.name())
            .role("roles/viewer")
            .member("user:jane@example.com")
            .build());

    }
}
```
```yaml
resources:
  member:
    type: gcp:datacatalog:PolicyTagIamMember
    properties:
      policyTag: ${basicPolicyTag.name}
      role: roles/viewer
      member: user:jane@example.com
```
<!--End PulumiCodeChooser -->

## Import

For all import syntaxes, the "resource in question" can take any of the following forms:

* {{policy_tag}}

Any variables not passed in the import command will be taken from the provider configuration.

Data catalog policytag IAM resources can be imported using the resource identifiers, role, and member.

IAM member imports use space-delimited identifiers: the resource in question, the role, and the member identity, e.g.

```sh
$ pulumi import gcp:datacatalog/policyTagIamMember:PolicyTagIamMember editor "{{policy_tag}} roles/viewer user:jane@example.com"
```

IAM binding imports use space-delimited identifiers: the resource in question and the role, e.g.

```sh
$ pulumi import gcp:datacatalog/policyTagIamMember:PolicyTagIamMember editor "{{policy_tag}} roles/viewer"
```

IAM policy imports use the identifier of the resource in question, e.g.

```sh
$ pulumi import gcp:datacatalog/policyTagIamMember:PolicyTagIamMember editor {{policy_tag}}
```

-> **Custom Roles** If you're importing a IAM resource with a custom role, make sure to use the

 full name of the custom role, e.g. `[projects/my-project|organizations/my-org]/roles/my-custom-role`.


	conditionyBw:u
s
datacatalogPolicyTagIamMemberConditionGgcp:datacatalog/PolicyTagIamMemberCondition:PolicyTagIamMemberConditionÓ	
member" Ä	Identities that will be granted the privilege in `role`.
Each entry can have one of the following values:
* **allUsers**: A special identifier that represents anyone who is on the internet; with or without a Google account.
* **allAuthenticatedUsers**: A special identifier that represents anyone who is authenticated with a Google account or a service account.
* **user:{emailid}**: An email address that represents a specific Google account. For example, alice@gmail.com or joe@example.com.
* **serviceAccount:{emailid}**: An email address that represents a service account. For example, my-other-app@appspot.gserviceaccount.com.
* **group:{emailid}**: An email address that represents a Google group. For example, admins@example.com.
* **domain:{domain}**: A G Suite domain (primary, instead of alias) name that represents all the users of that domain. For example, google.com or example.com.
* **projectOwner:projectid**: Owners of the given project. For example, "projectOwner:my-example-project"
* **projectEditor:projectid**: Editors of the given project. For example, "projectEditor:my-example-project"
* **projectViewer:projectid**: Viewers of the given project. For example, "projectViewer:my-example-project"
L
	policyTag" ;Used to find the parent resource to bind the IAM policy to
Ü
role" ÏThe role that should be applied. Only one
`gcp.datacatalog.PolicyTagIamBinding` can be used per role. Note that custom roles must be of the format
`[projects|organizations]/{parent-name}/roles/{role-name}`.
"
	conditionyBw:u
s
datacatalogPolicyTagIamMemberConditionGgcp:datacatalog/PolicyTagIamMemberCondition:PolicyTagIamMemberCondition"3
etag" '(Computed) The etag of the IAM policy.
"Ó	
member" Ä	Identities that will be granted the privilege in `role`.
Each entry can have one of the following values:
* **allUsers**: A special identifier that represents anyone who is on the internet; with or without a Google account.
* **allAuthenticatedUsers**: A special identifier that represents anyone who is authenticated with a Google account or a service account.
* **user:{emailid}**: An email address that represents a specific Google account. For example, alice@gmail.com or joe@example.com.
* **serviceAccount:{emailid}**: An email address that represents a service account. For example, my-other-app@appspot.gserviceaccount.com.
* **group:{emailid}**: An email address that represents a Google group. For example, admins@example.com.
* **domain:{domain}**: A G Suite domain (primary, instead of alias) name that represents all the users of that domain. For example, google.com or example.com.
* **projectOwner:projectid**: Owners of the given project. For example, "projectOwner:my-example-project"
* **projectEditor:projectid**: Editors of the given project. For example, "projectEditor:my-example-project"
* **projectViewer:projectid**: Viewers of the given project. For example, "projectViewer:my-example-project"
"L
	policyTag" ;Used to find the parent resource to bind the IAM policy to
"Ü
role" ÏThe role that should be applied. Only one
`gcp.datacatalog.PolicyTagIamBinding` can be used per role. Note that custom roles must be of the format
`[projects|organizations]/{parent-name}/roles/{role-name}`.
*­
X
datacatalogPolicyTagIamPolicy5gcp:datacatalog/policyTagIamPolicy:PolicyTagIamPolicy©Three different resources help you manage your IAM policy for Data catalog PolicyTag. Each of these resources serves a different use case:

* `gcp.datacatalog.PolicyTagIamPolicy`: Authoritative. Sets the IAM policy for the policytag and replaces any existing policy already attached.
* `gcp.datacatalog.PolicyTagIamBinding`: Authoritative for a given role. Updates the IAM policy to grant a role to a list of members. Other roles within the IAM policy for the policytag are preserved.
* `gcp.datacatalog.PolicyTagIamMember`: Non-authoritative. Updates the IAM policy to grant a role to a new member. Other members for the role for the policytag are preserved.

A data source can be used to retrieve policy data in advent you do not need creation

* `gcp.datacatalog.PolicyTagIamPolicy`: Retrieves the IAM policy for the policytag

> **Note:** `gcp.datacatalog.PolicyTagIamPolicy` **cannot** be used in conjunction with `gcp.datacatalog.PolicyTagIamBinding` and `gcp.datacatalog.PolicyTagIamMember` or they will fight over what your policy should be.

> **Note:** `gcp.datacatalog.PolicyTagIamBinding` resources **can be** used in conjunction with `gcp.datacatalog.PolicyTagIamMember` resources **only if** they do not grant privilege to the same role.



## gcp.datacatalog.PolicyTagIamPolicy

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const admin = gcp.organizations.getIAMPolicy({
    bindings: [{
        role: "roles/viewer",
        members: ["user:jane@example.com"],
    }],
});
const policy = new gcp.datacatalog.PolicyTagIamPolicy("policy", {
    policyTag: basicPolicyTag.name,
    policyData: admin.then(admin => admin.policyData),
});
```
```python
import pulumi
import pulumi_gcp as gcp

admin = gcp.organizations.get_iam_policy(bindings=[{
    "role": "roles/viewer",
    "members": ["user:jane@example.com"],
}])
policy = gcp.datacatalog.PolicyTagIamPolicy("policy",
    policy_tag=basic_policy_tag["name"],
    policy_data=admin.policy_data)
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var admin = Gcp.Organizations.GetIAMPolicy.Invoke(new()
    {
        Bindings = new[]
        {
            new Gcp.Organizations.Inputs.GetIAMPolicyBindingInputArgs
            {
                Role = "roles/viewer",
                Members = new[]
                {
                    "user:jane@example.com",
                },
            },
        },
    });

    var policy = new Gcp.DataCatalog.PolicyTagIamPolicy("policy", new()
    {
        PolicyTag = basicPolicyTag.Name,
        PolicyData = admin.Apply(getIAMPolicyResult => getIAMPolicyResult.PolicyData),
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/datacatalog"
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/organizations"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		admin, err := organizations.LookupIAMPolicy(ctx, &organizations.LookupIAMPolicyArgs{
			Bindings: []organizations.GetIAMPolicyBinding{
				{
					Role: "roles/viewer",
					Members: []string{
						"user:jane@example.com",
					},
				},
			},
		}, nil)
		if err != nil {
			return err
		}
		_, err = datacatalog.NewPolicyTagIamPolicy(ctx, "policy", &datacatalog.PolicyTagIamPolicyArgs{
			PolicyTag:  pulumi.Any(basicPolicyTag.Name),
			PolicyData: pulumi.String(admin.PolicyData),
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.organizations.OrganizationsFunctions;
import com.pulumi.gcp.organizations.inputs.GetIAMPolicyArgs;
import com.pulumi.gcp.datacatalog.PolicyTagIamPolicy;
import com.pulumi.gcp.datacatalog.PolicyTagIamPolicyArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        final var admin = OrganizationsFunctions.getIAMPolicy(GetIAMPolicyArgs.builder()
            .bindings(GetIAMPolicyBindingArgs.builder()
                .role("roles/viewer")
                .members("user:jane@example.com")
                .build())
            .build());

        var policy = new PolicyTagIamPolicy("policy", PolicyTagIamPolicyArgs.builder()
            .policyTag(basicPolicyTag.name())
            .policyData(admin.applyValue(getIAMPolicyResult -> getIAMPolicyResult.policyData()))
            .build());

    }
}
```
```yaml
resources:
  policy:
    type: gcp:datacatalog:PolicyTagIamPolicy
    properties:
      policyTag: ${basicPolicyTag.name}
      policyData: ${admin.policyData}
variables:
  admin:
    fn::invoke:
      function: gcp:organizations:getIAMPolicy
      arguments:
        bindings:
          - role: roles/viewer
            members:
              - user:jane@example.com
```
<!--End PulumiCodeChooser -->

## gcp.datacatalog.PolicyTagIamBinding

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const binding = new gcp.datacatalog.PolicyTagIamBinding("binding", {
    policyTag: basicPolicyTag.name,
    role: "roles/viewer",
    members: ["user:jane@example.com"],
});
```
```python
import pulumi
import pulumi_gcp as gcp

binding = gcp.datacatalog.PolicyTagIamBinding("binding",
    policy_tag=basic_policy_tag["name"],
    role="roles/viewer",
    members=["user:jane@example.com"])
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var binding = new Gcp.DataCatalog.PolicyTagIamBinding("binding", new()
    {
        PolicyTag = basicPolicyTag.Name,
        Role = "roles/viewer",
        Members = new[]
        {
            "user:jane@example.com",
        },
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/datacatalog"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		_, err := datacatalog.NewPolicyTagIamBinding(ctx, "binding", &datacatalog.PolicyTagIamBindingArgs{
			PolicyTag: pulumi.Any(basicPolicyTag.Name),
			Role:      pulumi.String("roles/viewer"),
			Members: pulumi.StringArray{
				pulumi.String("user:jane@example.com"),
			},
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.datacatalog.PolicyTagIamBinding;
import com.pulumi.gcp.datacatalog.PolicyTagIamBindingArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        var binding = new PolicyTagIamBinding("binding", PolicyTagIamBindingArgs.builder()
            .policyTag(basicPolicyTag.name())
            .role("roles/viewer")
            .members("user:jane@example.com")
            .build());

    }
}
```
```yaml
resources:
  binding:
    type: gcp:datacatalog:PolicyTagIamBinding
    properties:
      policyTag: ${basicPolicyTag.name}
      role: roles/viewer
      members:
        - user:jane@example.com
```
<!--End PulumiCodeChooser -->

## gcp.datacatalog.PolicyTagIamMember

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const member = new gcp.datacatalog.PolicyTagIamMember("member", {
    policyTag: basicPolicyTag.name,
    role: "roles/viewer",
    member: "user:jane@example.com",
});
```
```python
import pulumi
import pulumi_gcp as gcp

member = gcp.datacatalog.PolicyTagIamMember("member",
    policy_tag=basic_policy_tag["name"],
    role="roles/viewer",
    member="user:jane@example.com")
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var member = new Gcp.DataCatalog.PolicyTagIamMember("member", new()
    {
        PolicyTag = basicPolicyTag.Name,
        Role = "roles/viewer",
        Member = "user:jane@example.com",
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/datacatalog"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		_, err := datacatalog.NewPolicyTagIamMember(ctx, "member", &datacatalog.PolicyTagIamMemberArgs{
			PolicyTag: pulumi.Any(basicPolicyTag.Name),
			Role:      pulumi.String("roles/viewer"),
			Member:    pulumi.String("user:jane@example.com"),
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.datacatalog.PolicyTagIamMember;
import com.pulumi.gcp.datacatalog.PolicyTagIamMemberArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        var member = new PolicyTagIamMember("member", PolicyTagIamMemberArgs.builder()
            .policyTag(basicPolicyTag.name())
            .role("roles/viewer")
            .member("user:jane@example.com")
            .build());

    }
}
```
```yaml
resources:
  member:
    type: gcp:datacatalog:PolicyTagIamMember
    properties:
      policyTag: ${basicPolicyTag.name}
      role: roles/viewer
      member: user:jane@example.com
```
<!--End PulumiCodeChooser -->


## > **Custom Roles** If you're importing a IAM resource with a custom role, make sure to use the

 full name of the custom role, e.g. `[projects/my-project|organizations/my-org]/roles/my-custom-role`.
-

# IAM policy for Data catalog PolicyTag
Three different resources help you manage your IAM policy for Data catalog PolicyTag. Each of these resources serves a different use case:

* `gcp.datacatalog.PolicyTagIamPolicy`: Authoritative. Sets the IAM policy for the policytag and replaces any existing policy already attached.
* `gcp.datacatalog.PolicyTagIamBinding`: Authoritative for a given role. Updates the IAM policy to grant a role to a list of members. Other roles within the IAM policy for the policytag are preserved.
* `gcp.datacatalog.PolicyTagIamMember`: Non-authoritative. Updates the IAM policy to grant a role to a new member. Other members for the role for the policytag are preserved.

A data source can be used to retrieve policy data in advent you do not need creation

* `gcp.datacatalog.PolicyTagIamPolicy`: Retrieves the IAM policy for the policytag

> **Note:** `gcp.datacatalog.PolicyTagIamPolicy` **cannot** be used in conjunction with `gcp.datacatalog.PolicyTagIamBinding` and `gcp.datacatalog.PolicyTagIamMember` or they will fight over what your policy should be.

> **Note:** `gcp.datacatalog.PolicyTagIamBinding` resources **can be** used in conjunction with `gcp.datacatalog.PolicyTagIamMember` resources **only if** they do not grant privilege to the same role.



## gcp.datacatalog.PolicyTagIamPolicy

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const admin = gcp.organizations.getIAMPolicy({
    bindings: [{
        role: "roles/viewer",
        members: ["user:jane@example.com"],
    }],
});
const policy = new gcp.datacatalog.PolicyTagIamPolicy("policy", {
    policyTag: basicPolicyTag.name,
    policyData: admin.then(admin => admin.policyData),
});
```
```python
import pulumi
import pulumi_gcp as gcp

admin = gcp.organizations.get_iam_policy(bindings=[{
    "role": "roles/viewer",
    "members": ["user:jane@example.com"],
}])
policy = gcp.datacatalog.PolicyTagIamPolicy("policy",
    policy_tag=basic_policy_tag["name"],
    policy_data=admin.policy_data)
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var admin = Gcp.Organizations.GetIAMPolicy.Invoke(new()
    {
        Bindings = new[]
        {
            new Gcp.Organizations.Inputs.GetIAMPolicyBindingInputArgs
            {
                Role = "roles/viewer",
                Members = new[]
                {
                    "user:jane@example.com",
                },
            },
        },
    });

    var policy = new Gcp.DataCatalog.PolicyTagIamPolicy("policy", new()
    {
        PolicyTag = basicPolicyTag.Name,
        PolicyData = admin.Apply(getIAMPolicyResult => getIAMPolicyResult.PolicyData),
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/datacatalog"
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/organizations"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		admin, err := organizations.LookupIAMPolicy(ctx, &organizations.LookupIAMPolicyArgs{
			Bindings: []organizations.GetIAMPolicyBinding{
				{
					Role: "roles/viewer",
					Members: []string{
						"user:jane@example.com",
					},
				},
			},
		}, nil)
		if err != nil {
			return err
		}
		_, err = datacatalog.NewPolicyTagIamPolicy(ctx, "policy", &datacatalog.PolicyTagIamPolicyArgs{
			PolicyTag:  pulumi.Any(basicPolicyTag.Name),
			PolicyData: pulumi.String(admin.PolicyData),
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.organizations.OrganizationsFunctions;
import com.pulumi.gcp.organizations.inputs.GetIAMPolicyArgs;
import com.pulumi.gcp.datacatalog.PolicyTagIamPolicy;
import com.pulumi.gcp.datacatalog.PolicyTagIamPolicyArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        final var admin = OrganizationsFunctions.getIAMPolicy(GetIAMPolicyArgs.builder()
            .bindings(GetIAMPolicyBindingArgs.builder()
                .role("roles/viewer")
                .members("user:jane@example.com")
                .build())
            .build());

        var policy = new PolicyTagIamPolicy("policy", PolicyTagIamPolicyArgs.builder()
            .policyTag(basicPolicyTag.name())
            .policyData(admin.applyValue(getIAMPolicyResult -> getIAMPolicyResult.policyData()))
            .build());

    }
}
```
```yaml
resources:
  policy:
    type: gcp:datacatalog:PolicyTagIamPolicy
    properties:
      policyTag: ${basicPolicyTag.name}
      policyData: ${admin.policyData}
variables:
  admin:
    fn::invoke:
      function: gcp:organizations:getIAMPolicy
      arguments:
        bindings:
          - role: roles/viewer
            members:
              - user:jane@example.com
```
<!--End PulumiCodeChooser -->

## gcp.datacatalog.PolicyTagIamBinding

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const binding = new gcp.datacatalog.PolicyTagIamBinding("binding", {
    policyTag: basicPolicyTag.name,
    role: "roles/viewer",
    members: ["user:jane@example.com"],
});
```
```python
import pulumi
import pulumi_gcp as gcp

binding = gcp.datacatalog.PolicyTagIamBinding("binding",
    policy_tag=basic_policy_tag["name"],
    role="roles/viewer",
    members=["user:jane@example.com"])
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var binding = new Gcp.DataCatalog.PolicyTagIamBinding("binding", new()
    {
        PolicyTag = basicPolicyTag.Name,
        Role = "roles/viewer",
        Members = new[]
        {
            "user:jane@example.com",
        },
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/datacatalog"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		_, err := datacatalog.NewPolicyTagIamBinding(ctx, "binding", &datacatalog.PolicyTagIamBindingArgs{
			PolicyTag: pulumi.Any(basicPolicyTag.Name),
			Role:      pulumi.String("roles/viewer"),
			Members: pulumi.StringArray{
				pulumi.String("user:jane@example.com"),
			},
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.datacatalog.PolicyTagIamBinding;
import com.pulumi.gcp.datacatalog.PolicyTagIamBindingArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        var binding = new PolicyTagIamBinding("binding", PolicyTagIamBindingArgs.builder()
            .policyTag(basicPolicyTag.name())
            .role("roles/viewer")
            .members("user:jane@example.com")
            .build());

    }
}
```
```yaml
resources:
  binding:
    type: gcp:datacatalog:PolicyTagIamBinding
    properties:
      policyTag: ${basicPolicyTag.name}
      role: roles/viewer
      members:
        - user:jane@example.com
```
<!--End PulumiCodeChooser -->

## gcp.datacatalog.PolicyTagIamMember

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const member = new gcp.datacatalog.PolicyTagIamMember("member", {
    policyTag: basicPolicyTag.name,
    role: "roles/viewer",
    member: "user:jane@example.com",
});
```
```python
import pulumi
import pulumi_gcp as gcp

member = gcp.datacatalog.PolicyTagIamMember("member",
    policy_tag=basic_policy_tag["name"],
    role="roles/viewer",
    member="user:jane@example.com")
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var member = new Gcp.DataCatalog.PolicyTagIamMember("member", new()
    {
        PolicyTag = basicPolicyTag.Name,
        Role = "roles/viewer",
        Member = "user:jane@example.com",
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/datacatalog"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		_, err := datacatalog.NewPolicyTagIamMember(ctx, "member", &datacatalog.PolicyTagIamMemberArgs{
			PolicyTag: pulumi.Any(basicPolicyTag.Name),
			Role:      pulumi.String("roles/viewer"),
			Member:    pulumi.String("user:jane@example.com"),
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.datacatalog.PolicyTagIamMember;
import com.pulumi.gcp.datacatalog.PolicyTagIamMemberArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        var member = new PolicyTagIamMember("member", PolicyTagIamMemberArgs.builder()
            .policyTag(basicPolicyTag.name())
            .role("roles/viewer")
            .member("user:jane@example.com")
            .build());

    }
}
```
```yaml
resources:
  member:
    type: gcp:datacatalog:PolicyTagIamMember
    properties:
      policyTag: ${basicPolicyTag.name}
      role: roles/viewer
      member: user:jane@example.com
```
<!--End PulumiCodeChooser -->

## Import

For all import syntaxes, the "resource in question" can take any of the following forms:

* {{policy_tag}}

Any variables not passed in the import command will be taken from the provider configuration.

Data catalog policytag IAM resources can be imported using the resource identifiers, role, and member.

IAM member imports use space-delimited identifiers: the resource in question, the role, and the member identity, e.g.

```sh
$ pulumi import gcp:datacatalog/policyTagIamPolicy:PolicyTagIamPolicy editor "{{policy_tag}} roles/viewer user:jane@example.com"
```

IAM binding imports use space-delimited identifiers: the resource in question and the role, e.g.

```sh
$ pulumi import gcp:datacatalog/policyTagIamPolicy:PolicyTagIamPolicy editor "{{policy_tag}} roles/viewer"
```

IAM policy imports use the identifier of the resource in question, e.g.

```sh
$ pulumi import gcp:datacatalog/policyTagIamPolicy:PolicyTagIamPolicy editor {{policy_tag}}
```

-> **Custom Roles** If you're importing a IAM resource with a custom role, make sure to use the

 full name of the custom role, e.g. `[projects/my-project|organizations/my-org]/roles/my-custom-role`.

_

policyData" MThe policy data generated by
a `gcp.organizations.getIAMPolicy` data source.
L
	policyTag" ;Used to find the parent resource to bind the IAM policy to
"3
etag" '(Computed) The etag of the IAM policy.
"_

policyData" MThe policy data generated by
a `gcp.organizations.getIAMPolicy` data source.
"L
	policyTag" ;Used to find the parent resource to bind the IAM policy to
*×¿
+
datacatalogTaggcp:datacatalog/tag:Tag¨¬Tags are used to attach custom metadata to Data Catalog resources. Tags conform to the specifications within their tag template.

See [Data Catalog IAM](https://cloud.google.com/data-catalog/docs/concepts/iam) for information on the permissions needed to create or view tags.


To get more information about Tag, see:

* [API documentation](https://cloud.google.com/data-catalog/docs/reference/rest/v1/projects.locations.entryGroups.tags)
* How-to Guides
    * [Official Documentation](https://cloud.google.com/data-catalog/docs)

## Example Usage

### Data Catalog Entry Tag Basic


<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const entryGroup = new gcp.datacatalog.EntryGroup("entry_group", {entryGroupId: "my_entry_group"});
const entry = new gcp.datacatalog.Entry("entry", {
    entryGroup: entryGroup.id,
    entryId: "my_entry",
    userSpecifiedType: "my_custom_type",
    userSpecifiedSystem: "SomethingExternal",
});
const tagTemplate = new gcp.datacatalog.TagTemplate("tag_template", {
    tagTemplateId: "my_template",
    region: "us-central1",
    displayName: "Demo Tag Template",
    fields: [
        {
            fieldId: "source",
            displayName: "Source of data asset",
            type: {
                primitiveType: "STRING",
            },
            isRequired: true,
        },
        {
            fieldId: "num_rows",
            displayName: "Number of rows in the data asset",
            type: {
                primitiveType: "DOUBLE",
            },
        },
        {
            fieldId: "pii_type",
            displayName: "PII type",
            type: {
                enumType: {
                    allowedValues: [
                        {
                            displayName: "EMAIL",
                        },
                        {
                            displayName: "SOCIAL SECURITY NUMBER",
                        },
                        {
                            displayName: "NONE",
                        },
                    ],
                },
            },
        },
    ],
    forceDelete: false,
});
const basicTag = new gcp.datacatalog.Tag("basic_tag", {
    parent: entry.id,
    template: tagTemplate.id,
    fields: [{
        fieldName: "source",
        stringValue: "my-string",
    }],
});
```
```python
import pulumi
import pulumi_gcp as gcp

entry_group = gcp.datacatalog.EntryGroup("entry_group", entry_group_id="my_entry_group")
entry = gcp.datacatalog.Entry("entry",
    entry_group=entry_group.id,
    entry_id="my_entry",
    user_specified_type="my_custom_type",
    user_specified_system="SomethingExternal")
tag_template = gcp.datacatalog.TagTemplate("tag_template",
    tag_template_id="my_template",
    region="us-central1",
    display_name="Demo Tag Template",
    fields=[
        {
            "field_id": "source",
            "display_name": "Source of data asset",
            "type": {
                "primitive_type": "STRING",
            },
            "is_required": True,
        },
        {
            "field_id": "num_rows",
            "display_name": "Number of rows in the data asset",
            "type": {
                "primitive_type": "DOUBLE",
            },
        },
        {
            "field_id": "pii_type",
            "display_name": "PII type",
            "type": {
                "enum_type": {
                    "allowed_values": [
                        {
                            "display_name": "EMAIL",
                        },
                        {
                            "display_name": "SOCIAL SECURITY NUMBER",
                        },
                        {
                            "display_name": "NONE",
                        },
                    ],
                },
            },
        },
    ],
    force_delete=False)
basic_tag = gcp.datacatalog.Tag("basic_tag",
    parent=entry.id,
    template=tag_template.id,
    fields=[{
        "field_name": "source",
        "string_value": "my-string",
    }])
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var entryGroup = new Gcp.DataCatalog.EntryGroup("entry_group", new()
    {
        EntryGroupId = "my_entry_group",
    });

    var entry = new Gcp.DataCatalog.Entry("entry", new()
    {
        EntryGroup = entryGroup.Id,
        EntryId = "my_entry",
        UserSpecifiedType = "my_custom_type",
        UserSpecifiedSystem = "SomethingExternal",
    });

    var tagTemplate = new Gcp.DataCatalog.TagTemplate("tag_template", new()
    {
        TagTemplateId = "my_template",
        Region = "us-central1",
        DisplayName = "Demo Tag Template",
        Fields = new[]
        {
            new Gcp.DataCatalog.Inputs.TagTemplateFieldArgs
            {
                FieldId = "source",
                DisplayName = "Source of data asset",
                Type = new Gcp.DataCatalog.Inputs.TagTemplateFieldTypeArgs
                {
                    PrimitiveType = "STRING",
                },
                IsRequired = true,
            },
            new Gcp.DataCatalog.Inputs.TagTemplateFieldArgs
            {
                FieldId = "num_rows",
                DisplayName = "Number of rows in the data asset",
                Type = new Gcp.DataCatalog.Inputs.TagTemplateFieldTypeArgs
                {
                    PrimitiveType = "DOUBLE",
                },
            },
            new Gcp.DataCatalog.Inputs.TagTemplateFieldArgs
            {
                FieldId = "pii_type",
                DisplayName = "PII type",
                Type = new Gcp.DataCatalog.Inputs.TagTemplateFieldTypeArgs
                {
                    EnumType = new Gcp.DataCatalog.Inputs.TagTemplateFieldTypeEnumTypeArgs
                    {
                        AllowedValues = new[]
                        {
                            new Gcp.DataCatalog.Inputs.TagTemplateFieldTypeEnumTypeAllowedValueArgs
                            {
                                DisplayName = "EMAIL",
                            },
                            new Gcp.DataCatalog.Inputs.TagTemplateFieldTypeEnumTypeAllowedValueArgs
                            {
                                DisplayName = "SOCIAL SECURITY NUMBER",
                            },
                            new Gcp.DataCatalog.Inputs.TagTemplateFieldTypeEnumTypeAllowedValueArgs
                            {
                                DisplayName = "NONE",
                            },
                        },
                    },
                },
            },
        },
        ForceDelete = false,
    });

    var basicTag = new Gcp.DataCatalog.Tag("basic_tag", new()
    {
        Parent = entry.Id,
        Template = tagTemplate.Id,
        Fields = new[]
        {
            new Gcp.DataCatalog.Inputs.TagFieldArgs
            {
                FieldName = "source",
                StringValue = "my-string",
            },
        },
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/datacatalog"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		entryGroup, err := datacatalog.NewEntryGroup(ctx, "entry_group", &datacatalog.EntryGroupArgs{
			EntryGroupId: pulumi.String("my_entry_group"),
		})
		if err != nil {
			return err
		}
		entry, err := datacatalog.NewEntry(ctx, "entry", &datacatalog.EntryArgs{
			EntryGroup:          entryGroup.ID(),
			EntryId:             pulumi.String("my_entry"),
			UserSpecifiedType:   pulumi.String("my_custom_type"),
			UserSpecifiedSystem: pulumi.String("SomethingExternal"),
		})
		if err != nil {
			return err
		}
		tagTemplate, err := datacatalog.NewTagTemplate(ctx, "tag_template", &datacatalog.TagTemplateArgs{
			TagTemplateId: pulumi.String("my_template"),
			Region:        pulumi.String("us-central1"),
			DisplayName:   pulumi.String("Demo Tag Template"),
			Fields: datacatalog.TagTemplateFieldArray{
				&datacatalog.TagTemplateFieldArgs{
					FieldId:     pulumi.String("source"),
					DisplayName: pulumi.String("Source of data asset"),
					Type: &datacatalog.TagTemplateFieldTypeArgs{
						PrimitiveType: pulumi.String("STRING"),
					},
					IsRequired: pulumi.Bool(true),
				},
				&datacatalog.TagTemplateFieldArgs{
					FieldId:     pulumi.String("num_rows"),
					DisplayName: pulumi.String("Number of rows in the data asset"),
					Type: &datacatalog.TagTemplateFieldTypeArgs{
						PrimitiveType: pulumi.String("DOUBLE"),
					},
				},
				&datacatalog.TagTemplateFieldArgs{
					FieldId:     pulumi.String("pii_type"),
					DisplayName: pulumi.String("PII type"),
					Type: &datacatalog.TagTemplateFieldTypeArgs{
						EnumType: &datacatalog.TagTemplateFieldTypeEnumTypeArgs{
							AllowedValues: datacatalog.TagTemplateFieldTypeEnumTypeAllowedValueArray{
								&datacatalog.TagTemplateFieldTypeEnumTypeAllowedValueArgs{
									DisplayName: pulumi.String("EMAIL"),
								},
								&datacatalog.TagTemplateFieldTypeEnumTypeAllowedValueArgs{
									DisplayName: pulumi.String("SOCIAL SECURITY NUMBER"),
								},
								&datacatalog.TagTemplateFieldTypeEnumTypeAllowedValueArgs{
									DisplayName: pulumi.String("NONE"),
								},
							},
						},
					},
				},
			},
			ForceDelete: pulumi.Bool(false),
		})
		if err != nil {
			return err
		}
		_, err = datacatalog.NewTag(ctx, "basic_tag", &datacatalog.TagArgs{
			Parent:   entry.ID(),
			Template: tagTemplate.ID(),
			Fields: datacatalog.TagFieldArray{
				&datacatalog.TagFieldArgs{
					FieldName:   pulumi.String("source"),
					StringValue: pulumi.String("my-string"),
				},
			},
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.datacatalog.EntryGroup;
import com.pulumi.gcp.datacatalog.EntryGroupArgs;
import com.pulumi.gcp.datacatalog.Entry;
import com.pulumi.gcp.datacatalog.EntryArgs;
import com.pulumi.gcp.datacatalog.TagTemplate;
import com.pulumi.gcp.datacatalog.TagTemplateArgs;
import com.pulumi.gcp.datacatalog.inputs.TagTemplateFieldArgs;
import com.pulumi.gcp.datacatalog.inputs.TagTemplateFieldTypeArgs;
import com.pulumi.gcp.datacatalog.inputs.TagTemplateFieldTypeEnumTypeArgs;
import com.pulumi.gcp.datacatalog.Tag;
import com.pulumi.gcp.datacatalog.TagArgs;
import com.pulumi.gcp.datacatalog.inputs.TagFieldArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        var entryGroup = new EntryGroup("entryGroup", EntryGroupArgs.builder()
            .entryGroupId("my_entry_group")
            .build());

        var entry = new Entry("entry", EntryArgs.builder()
            .entryGroup(entryGroup.id())
            .entryId("my_entry")
            .userSpecifiedType("my_custom_type")
            .userSpecifiedSystem("SomethingExternal")
            .build());

        var tagTemplate = new TagTemplate("tagTemplate", TagTemplateArgs.builder()
            .tagTemplateId("my_template")
            .region("us-central1")
            .displayName("Demo Tag Template")
            .fields(            
                TagTemplateFieldArgs.builder()
                    .fieldId("source")
                    .displayName("Source of data asset")
                    .type(TagTemplateFieldTypeArgs.builder()
                        .primitiveType("STRING")
                        .build())
                    .isRequired(true)
                    .build(),
                TagTemplateFieldArgs.builder()
                    .fieldId("num_rows")
                    .displayName("Number of rows in the data asset")
                    .type(TagTemplateFieldTypeArgs.builder()
                        .primitiveType("DOUBLE")
                        .build())
                    .build(),
                TagTemplateFieldArgs.builder()
                    .fieldId("pii_type")
                    .displayName("PII type")
                    .type(TagTemplateFieldTypeArgs.builder()
                        .enumType(TagTemplateFieldTypeEnumTypeArgs.builder()
                            .allowedValues(                            
                                TagTemplateFieldTypeEnumTypeAllowedValueArgs.builder()
                                    .displayName("EMAIL")
                                    .build(),
                                TagTemplateFieldTypeEnumTypeAllowedValueArgs.builder()
                                    .displayName("SOCIAL SECURITY NUMBER")
                                    .build(),
                                TagTemplateFieldTypeEnumTypeAllowedValueArgs.builder()
                                    .displayName("NONE")
                                    .build())
                            .build())
                        .build())
                    .build())
            .forceDelete("false")
            .build());

        var basicTag = new Tag("basicTag", TagArgs.builder()
            .parent(entry.id())
            .template(tagTemplate.id())
            .fields(TagFieldArgs.builder()
                .fieldName("source")
                .stringValue("my-string")
                .build())
            .build());

    }
}
```
```yaml
resources:
  entry:
    type: gcp:datacatalog:Entry
    properties:
      entryGroup: ${entryGroup.id}
      entryId: my_entry
      userSpecifiedType: my_custom_type
      userSpecifiedSystem: SomethingExternal
  entryGroup:
    type: gcp:datacatalog:EntryGroup
    name: entry_group
    properties:
      entryGroupId: my_entry_group
  tagTemplate:
    type: gcp:datacatalog:TagTemplate
    name: tag_template
    properties:
      tagTemplateId: my_template
      region: us-central1
      displayName: Demo Tag Template
      fields:
        - fieldId: source
          displayName: Source of data asset
          type:
            primitiveType: STRING
          isRequired: true
        - fieldId: num_rows
          displayName: Number of rows in the data asset
          type:
            primitiveType: DOUBLE
        - fieldId: pii_type
          displayName: PII type
          type:
            enumType:
              allowedValues:
                - displayName: EMAIL
                - displayName: SOCIAL SECURITY NUMBER
                - displayName: NONE
      forceDelete: 'false'
  basicTag:
    type: gcp:datacatalog:Tag
    name: basic_tag
    properties:
      parent: ${entry.id}
      template: ${tagTemplate.id}
      fields:
        - fieldName: source
          stringValue: my-string
```
<!--End PulumiCodeChooser -->
### Data Catalog Entry Group Tag


<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const entryGroup = new gcp.datacatalog.EntryGroup("entry_group", {entryGroupId: "my_entry_group"});
const firstEntry = new gcp.datacatalog.Entry("first_entry", {
    entryGroup: entryGroup.id,
    entryId: "first_entry",
    userSpecifiedType: "my_custom_type",
    userSpecifiedSystem: "SomethingExternal",
});
const secondEntry = new gcp.datacatalog.Entry("second_entry", {
    entryGroup: entryGroup.id,
    entryId: "second_entry",
    userSpecifiedType: "another_custom_type",
    userSpecifiedSystem: "SomethingElseExternal",
});
const tagTemplate = new gcp.datacatalog.TagTemplate("tag_template", {
    tagTemplateId: "my_template",
    region: "us-central1",
    displayName: "Demo Tag Template",
    fields: [
        {
            fieldId: "source",
            displayName: "Source of data asset",
            type: {
                primitiveType: "STRING",
            },
            isRequired: true,
        },
        {
            fieldId: "num_rows",
            displayName: "Number of rows in the data asset",
            type: {
                primitiveType: "DOUBLE",
            },
        },
        {
            fieldId: "pii_type",
            displayName: "PII type",
            type: {
                enumType: {
                    allowedValues: [
                        {
                            displayName: "EMAIL",
                        },
                        {
                            displayName: "SOCIAL SECURITY NUMBER",
                        },
                        {
                            displayName: "NONE",
                        },
                    ],
                },
            },
        },
    ],
    forceDelete: false,
});
const entryGroupTag = new gcp.datacatalog.Tag("entry_group_tag", {
    parent: entryGroup.id,
    template: tagTemplate.id,
    fields: [{
        fieldName: "source",
        stringValue: "my-string",
    }],
});
```
```python
import pulumi
import pulumi_gcp as gcp

entry_group = gcp.datacatalog.EntryGroup("entry_group", entry_group_id="my_entry_group")
first_entry = gcp.datacatalog.Entry("first_entry",
    entry_group=entry_group.id,
    entry_id="first_entry",
    user_specified_type="my_custom_type",
    user_specified_system="SomethingExternal")
second_entry = gcp.datacatalog.Entry("second_entry",
    entry_group=entry_group.id,
    entry_id="second_entry",
    user_specified_type="another_custom_type",
    user_specified_system="SomethingElseExternal")
tag_template = gcp.datacatalog.TagTemplate("tag_template",
    tag_template_id="my_template",
    region="us-central1",
    display_name="Demo Tag Template",
    fields=[
        {
            "field_id": "source",
            "display_name": "Source of data asset",
            "type": {
                "primitive_type": "STRING",
            },
            "is_required": True,
        },
        {
            "field_id": "num_rows",
            "display_name": "Number of rows in the data asset",
            "type": {
                "primitive_type": "DOUBLE",
            },
        },
        {
            "field_id": "pii_type",
            "display_name": "PII type",
            "type": {
                "enum_type": {
                    "allowed_values": [
                        {
                            "display_name": "EMAIL",
                        },
                        {
                            "display_name": "SOCIAL SECURITY NUMBER",
                        },
                        {
                            "display_name": "NONE",
                        },
                    ],
                },
            },
        },
    ],
    force_delete=False)
entry_group_tag = gcp.datacatalog.Tag("entry_group_tag",
    parent=entry_group.id,
    template=tag_template.id,
    fields=[{
        "field_name": "source",
        "string_value": "my-string",
    }])
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var entryGroup = new Gcp.DataCatalog.EntryGroup("entry_group", new()
    {
        EntryGroupId = "my_entry_group",
    });

    var firstEntry = new Gcp.DataCatalog.Entry("first_entry", new()
    {
        EntryGroup = entryGroup.Id,
        EntryId = "first_entry",
        UserSpecifiedType = "my_custom_type",
        UserSpecifiedSystem = "SomethingExternal",
    });

    var secondEntry = new Gcp.DataCatalog.Entry("second_entry", new()
    {
        EntryGroup = entryGroup.Id,
        EntryId = "second_entry",
        UserSpecifiedType = "another_custom_type",
        UserSpecifiedSystem = "SomethingElseExternal",
    });

    var tagTemplate = new Gcp.DataCatalog.TagTemplate("tag_template", new()
    {
        TagTemplateId = "my_template",
        Region = "us-central1",
        DisplayName = "Demo Tag Template",
        Fields = new[]
        {
            new Gcp.DataCatalog.Inputs.TagTemplateFieldArgs
            {
                FieldId = "source",
                DisplayName = "Source of data asset",
                Type = new Gcp.DataCatalog.Inputs.TagTemplateFieldTypeArgs
                {
                    PrimitiveType = "STRING",
                },
                IsRequired = true,
            },
            new Gcp.DataCatalog.Inputs.TagTemplateFieldArgs
            {
                FieldId = "num_rows",
                DisplayName = "Number of rows in the data asset",
                Type = new Gcp.DataCatalog.Inputs.TagTemplateFieldTypeArgs
                {
                    PrimitiveType = "DOUBLE",
                },
            },
            new Gcp.DataCatalog.Inputs.TagTemplateFieldArgs
            {
                FieldId = "pii_type",
                DisplayName = "PII type",
                Type = new Gcp.DataCatalog.Inputs.TagTemplateFieldTypeArgs
                {
                    EnumType = new Gcp.DataCatalog.Inputs.TagTemplateFieldTypeEnumTypeArgs
                    {
                        AllowedValues = new[]
                        {
                            new Gcp.DataCatalog.Inputs.TagTemplateFieldTypeEnumTypeAllowedValueArgs
                            {
                                DisplayName = "EMAIL",
                            },
                            new Gcp.DataCatalog.Inputs.TagTemplateFieldTypeEnumTypeAllowedValueArgs
                            {
                                DisplayName = "SOCIAL SECURITY NUMBER",
                            },
                            new Gcp.DataCatalog.Inputs.TagTemplateFieldTypeEnumTypeAllowedValueArgs
                            {
                                DisplayName = "NONE",
                            },
                        },
                    },
                },
            },
        },
        ForceDelete = false,
    });

    var entryGroupTag = new Gcp.DataCatalog.Tag("entry_group_tag", new()
    {
        Parent = entryGroup.Id,
        Template = tagTemplate.Id,
        Fields = new[]
        {
            new Gcp.DataCatalog.Inputs.TagFieldArgs
            {
                FieldName = "source",
                StringValue = "my-string",
            },
        },
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/datacatalog"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		entryGroup, err := datacatalog.NewEntryGroup(ctx, "entry_group", &datacatalog.EntryGroupArgs{
			EntryGroupId: pulumi.String("my_entry_group"),
		})
		if err != nil {
			return err
		}
		_, err = datacatalog.NewEntry(ctx, "first_entry", &datacatalog.EntryArgs{
			EntryGroup:          entryGroup.ID(),
			EntryId:             pulumi.String("first_entry"),
			UserSpecifiedType:   pulumi.String("my_custom_type"),
			UserSpecifiedSystem: pulumi.String("SomethingExternal"),
		})
		if err != nil {
			return err
		}
		_, err = datacatalog.NewEntry(ctx, "second_entry", &datacatalog.EntryArgs{
			EntryGroup:          entryGroup.ID(),
			EntryId:             pulumi.String("second_entry"),
			UserSpecifiedType:   pulumi.String("another_custom_type"),
			UserSpecifiedSystem: pulumi.String("SomethingElseExternal"),
		})
		if err != nil {
			return err
		}
		tagTemplate, err := datacatalog.NewTagTemplate(ctx, "tag_template", &datacatalog.TagTemplateArgs{
			TagTemplateId: pulumi.String("my_template"),
			Region:        pulumi.String("us-central1"),
			DisplayName:   pulumi.String("Demo Tag Template"),
			Fields: datacatalog.TagTemplateFieldArray{
				&datacatalog.TagTemplateFieldArgs{
					FieldId:     pulumi.String("source"),
					DisplayName: pulumi.String("Source of data asset"),
					Type: &datacatalog.TagTemplateFieldTypeArgs{
						PrimitiveType: pulumi.String("STRING"),
					},
					IsRequired: pulumi.Bool(true),
				},
				&datacatalog.TagTemplateFieldArgs{
					FieldId:     pulumi.String("num_rows"),
					DisplayName: pulumi.String("Number of rows in the data asset"),
					Type: &datacatalog.TagTemplateFieldTypeArgs{
						PrimitiveType: pulumi.String("DOUBLE"),
					},
				},
				&datacatalog.TagTemplateFieldArgs{
					FieldId:     pulumi.String("pii_type"),
					DisplayName: pulumi.String("PII type"),
					Type: &datacatalog.TagTemplateFieldTypeArgs{
						EnumType: &datacatalog.TagTemplateFieldTypeEnumTypeArgs{
							AllowedValues: datacatalog.TagTemplateFieldTypeEnumTypeAllowedValueArray{
								&datacatalog.TagTemplateFieldTypeEnumTypeAllowedValueArgs{
									DisplayName: pulumi.String("EMAIL"),
								},
								&datacatalog.TagTemplateFieldTypeEnumTypeAllowedValueArgs{
									DisplayName: pulumi.String("SOCIAL SECURITY NUMBER"),
								},
								&datacatalog.TagTemplateFieldTypeEnumTypeAllowedValueArgs{
									DisplayName: pulumi.String("NONE"),
								},
							},
						},
					},
				},
			},
			ForceDelete: pulumi.Bool(false),
		})
		if err != nil {
			return err
		}
		_, err = datacatalog.NewTag(ctx, "entry_group_tag", &datacatalog.TagArgs{
			Parent:   entryGroup.ID(),
			Template: tagTemplate.ID(),
			Fields: datacatalog.TagFieldArray{
				&datacatalog.TagFieldArgs{
					FieldName:   pulumi.String("source"),
					StringValue: pulumi.String("my-string"),
				},
			},
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.datacatalog.EntryGroup;
import com.pulumi.gcp.datacatalog.EntryGroupArgs;
import com.pulumi.gcp.datacatalog.Entry;
import com.pulumi.gcp.datacatalog.EntryArgs;
import com.pulumi.gcp.datacatalog.TagTemplate;
import com.pulumi.gcp.datacatalog.TagTemplateArgs;
import com.pulumi.gcp.datacatalog.inputs.TagTemplateFieldArgs;
import com.pulumi.gcp.datacatalog.inputs.TagTemplateFieldTypeArgs;
import com.pulumi.gcp.datacatalog.inputs.TagTemplateFieldTypeEnumTypeArgs;
import com.pulumi.gcp.datacatalog.Tag;
import com.pulumi.gcp.datacatalog.TagArgs;
import com.pulumi.gcp.datacatalog.inputs.TagFieldArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        var entryGroup = new EntryGroup("entryGroup", EntryGroupArgs.builder()
            .entryGroupId("my_entry_group")
            .build());

        var firstEntry = new Entry("firstEntry", EntryArgs.builder()
            .entryGroup(entryGroup.id())
            .entryId("first_entry")
            .userSpecifiedType("my_custom_type")
            .userSpecifiedSystem("SomethingExternal")
            .build());

        var secondEntry = new Entry("secondEntry", EntryArgs.builder()
            .entryGroup(entryGroup.id())
            .entryId("second_entry")
            .userSpecifiedType("another_custom_type")
            .userSpecifiedSystem("SomethingElseExternal")
            .build());

        var tagTemplate = new TagTemplate("tagTemplate", TagTemplateArgs.builder()
            .tagTemplateId("my_template")
            .region("us-central1")
            .displayName("Demo Tag Template")
            .fields(            
                TagTemplateFieldArgs.builder()
                    .fieldId("source")
                    .displayName("Source of data asset")
                    .type(TagTemplateFieldTypeArgs.builder()
                        .primitiveType("STRING")
                        .build())
                    .isRequired(true)
                    .build(),
                TagTemplateFieldArgs.builder()
                    .fieldId("num_rows")
                    .displayName("Number of rows in the data asset")
                    .type(TagTemplateFieldTypeArgs.builder()
                        .primitiveType("DOUBLE")
                        .build())
                    .build(),
                TagTemplateFieldArgs.builder()
                    .fieldId("pii_type")
                    .displayName("PII type")
                    .type(TagTemplateFieldTypeArgs.builder()
                        .enumType(TagTemplateFieldTypeEnumTypeArgs.builder()
                            .allowedValues(                            
                                TagTemplateFieldTypeEnumTypeAllowedValueArgs.builder()
                                    .displayName("EMAIL")
                                    .build(),
                                TagTemplateFieldTypeEnumTypeAllowedValueArgs.builder()
                                    .displayName("SOCIAL SECURITY NUMBER")
                                    .build(),
                                TagTemplateFieldTypeEnumTypeAllowedValueArgs.builder()
                                    .displayName("NONE")
                                    .build())
                            .build())
                        .build())
                    .build())
            .forceDelete("false")
            .build());

        var entryGroupTag = new Tag("entryGroupTag", TagArgs.builder()
            .parent(entryGroup.id())
            .template(tagTemplate.id())
            .fields(TagFieldArgs.builder()
                .fieldName("source")
                .stringValue("my-string")
                .build())
            .build());

    }
}
```
```yaml
resources:
  firstEntry:
    type: gcp:datacatalog:Entry
    name: first_entry
    properties:
      entryGroup: ${entryGroup.id}
      entryId: first_entry
      userSpecifiedType: my_custom_type
      userSpecifiedSystem: SomethingExternal
  secondEntry:
    type: gcp:datacatalog:Entry
    name: second_entry
    properties:
      entryGroup: ${entryGroup.id}
      entryId: second_entry
      userSpecifiedType: another_custom_type
      userSpecifiedSystem: SomethingElseExternal
  entryGroup:
    type: gcp:datacatalog:EntryGroup
    name: entry_group
    properties:
      entryGroupId: my_entry_group
  tagTemplate:
    type: gcp:datacatalog:TagTemplate
    name: tag_template
    properties:
      tagTemplateId: my_template
      region: us-central1
      displayName: Demo Tag Template
      fields:
        - fieldId: source
          displayName: Source of data asset
          type:
            primitiveType: STRING
          isRequired: true
        - fieldId: num_rows
          displayName: Number of rows in the data asset
          type:
            primitiveType: DOUBLE
        - fieldId: pii_type
          displayName: PII type
          type:
            enumType:
              allowedValues:
                - displayName: EMAIL
                - displayName: SOCIAL SECURITY NUMBER
                - displayName: NONE
      forceDelete: 'false'
  entryGroupTag:
    type: gcp:datacatalog:Tag
    name: entry_group_tag
    properties:
      parent: ${entryGroup.id}
      template: ${tagTemplate.id}
      fields:
        - fieldName: source
          stringValue: my-string
```
<!--End PulumiCodeChooser -->
### Data Catalog Entry Tag Full


<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const entryGroup = new gcp.datacatalog.EntryGroup("entry_group", {entryGroupId: "my_entry_group"});
const entry = new gcp.datacatalog.Entry("entry", {
    entryGroup: entryGroup.id,
    entryId: "my_entry",
    userSpecifiedType: "my_custom_type",
    userSpecifiedSystem: "SomethingExternal",
    schema: `{
  "columns": [
    {
      "column": "first_name",
      "description": "First name",
      "mode": "REQUIRED",
      "type": "STRING"
    },
    {
      "column": "last_name",
      "description": "Last name",
      "mode": "REQUIRED",
      "type": "STRING"
    },
    {
      "column": "address",
      "description": "Address",
      "mode": "REPEATED",
      "subcolumns": [
        {
          "column": "city",
          "description": "City",
          "mode": "NULLABLE",
          "type": "STRING"
        },
        {
          "column": "state",
          "description": "State",
          "mode": "NULLABLE",
          "type": "STRING"
        }
      ],
      "type": "RECORD"
    }
  ]
}
`,
});
const tagTemplate = new gcp.datacatalog.TagTemplate("tag_template", {
    tagTemplateId: "my_template",
    region: "us-central1",
    displayName: "Demo Tag Template",
    fields: [
        {
            fieldId: "source",
            displayName: "Source of data asset",
            type: {
                primitiveType: "STRING",
            },
            isRequired: true,
        },
        {
            fieldId: "num_rows",
            displayName: "Number of rows in the data asset",
            type: {
                primitiveType: "DOUBLE",
            },
        },
        {
            fieldId: "pii_type",
            displayName: "PII type",
            type: {
                enumType: {
                    allowedValues: [
                        {
                            displayName: "EMAIL",
                        },
                        {
                            displayName: "SOCIAL SECURITY NUMBER",
                        },
                        {
                            displayName: "NONE",
                        },
                    ],
                },
            },
        },
    ],
    forceDelete: false,
});
const basicTag = new gcp.datacatalog.Tag("basic_tag", {
    parent: entry.id,
    template: tagTemplate.id,
    fields: [
        {
            fieldName: "source",
            stringValue: "my-string",
        },
        {
            fieldName: "num_rows",
            doubleValue: 5,
        },
        {
            fieldName: "pii_type",
            enumValue: "EMAIL",
        },
    ],
    column: "address",
});
const second_tag = new gcp.datacatalog.Tag("second-tag", {
    parent: entry.id,
    template: tagTemplate.id,
    fields: [
        {
            fieldName: "source",
            stringValue: "my-string",
        },
        {
            fieldName: "pii_type",
            enumValue: "NONE",
        },
    ],
    column: "first_name",
});
```
```python
import pulumi
import pulumi_gcp as gcp

entry_group = gcp.datacatalog.EntryGroup("entry_group", entry_group_id="my_entry_group")
entry = gcp.datacatalog.Entry("entry",
    entry_group=entry_group.id,
    entry_id="my_entry",
    user_specified_type="my_custom_type",
    user_specified_system="SomethingExternal",
    schema="""{
  "columns": [
    {
      "column": "first_name",
      "description": "First name",
      "mode": "REQUIRED",
      "type": "STRING"
    },
    {
      "column": "last_name",
      "description": "Last name",
      "mode": "REQUIRED",
      "type": "STRING"
    },
    {
      "column": "address",
      "description": "Address",
      "mode": "REPEATED",
      "subcolumns": [
        {
          "column": "city",
          "description": "City",
          "mode": "NULLABLE",
          "type": "STRING"
        },
        {
          "column": "state",
          "description": "State",
          "mode": "NULLABLE",
          "type": "STRING"
        }
      ],
      "type": "RECORD"
    }
  ]
}
""")
tag_template = gcp.datacatalog.TagTemplate("tag_template",
    tag_template_id="my_template",
    region="us-central1",
    display_name="Demo Tag Template",
    fields=[
        {
            "field_id": "source",
            "display_name": "Source of data asset",
            "type": {
                "primitive_type": "STRING",
            },
            "is_required": True,
        },
        {
            "field_id": "num_rows",
            "display_name": "Number of rows in the data asset",
            "type": {
                "primitive_type": "DOUBLE",
            },
        },
        {
            "field_id": "pii_type",
            "display_name": "PII type",
            "type": {
                "enum_type": {
                    "allowed_values": [
                        {
                            "display_name": "EMAIL",
                        },
                        {
                            "display_name": "SOCIAL SECURITY NUMBER",
                        },
                        {
                            "display_name": "NONE",
                        },
                    ],
                },
            },
        },
    ],
    force_delete=False)
basic_tag = gcp.datacatalog.Tag("basic_tag",
    parent=entry.id,
    template=tag_template.id,
    fields=[
        {
            "field_name": "source",
            "string_value": "my-string",
        },
        {
            "field_name": "num_rows",
            "double_value": 5,
        },
        {
            "field_name": "pii_type",
            "enum_value": "EMAIL",
        },
    ],
    column="address")
second_tag = gcp.datacatalog.Tag("second-tag",
    parent=entry.id,
    template=tag_template.id,
    fields=[
        {
            "field_name": "source",
            "string_value": "my-string",
        },
        {
            "field_name": "pii_type",
            "enum_value": "NONE",
        },
    ],
    column="first_name")
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var entryGroup = new Gcp.DataCatalog.EntryGroup("entry_group", new()
    {
        EntryGroupId = "my_entry_group",
    });

    var entry = new Gcp.DataCatalog.Entry("entry", new()
    {
        EntryGroup = entryGroup.Id,
        EntryId = "my_entry",
        UserSpecifiedType = "my_custom_type",
        UserSpecifiedSystem = "SomethingExternal",
        Schema = @"{
  ""columns"": [
    {
      ""column"": ""first_name"",
      ""description"": ""First name"",
      ""mode"": ""REQUIRED"",
      ""type"": ""STRING""
    },
    {
      ""column"": ""last_name"",
      ""description"": ""Last name"",
      ""mode"": ""REQUIRED"",
      ""type"": ""STRING""
    },
    {
      ""column"": ""address"",
      ""description"": ""Address"",
      ""mode"": ""REPEATED"",
      ""subcolumns"": [
        {
          ""column"": ""city"",
          ""description"": ""City"",
          ""mode"": ""NULLABLE"",
          ""type"": ""STRING""
        },
        {
          ""column"": ""state"",
          ""description"": ""State"",
          ""mode"": ""NULLABLE"",
          ""type"": ""STRING""
        }
      ],
      ""type"": ""RECORD""
    }
  ]
}
",
    });

    var tagTemplate = new Gcp.DataCatalog.TagTemplate("tag_template", new()
    {
        TagTemplateId = "my_template",
        Region = "us-central1",
        DisplayName = "Demo Tag Template",
        Fields = new[]
        {
            new Gcp.DataCatalog.Inputs.TagTemplateFieldArgs
            {
                FieldId = "source",
                DisplayName = "Source of data asset",
                Type = new Gcp.DataCatalog.Inputs.TagTemplateFieldTypeArgs
                {
                    PrimitiveType = "STRING",
                },
                IsRequired = true,
            },
            new Gcp.DataCatalog.Inputs.TagTemplateFieldArgs
            {
                FieldId = "num_rows",
                DisplayName = "Number of rows in the data asset",
                Type = new Gcp.DataCatalog.Inputs.TagTemplateFieldTypeArgs
                {
                    PrimitiveType = "DOUBLE",
                },
            },
            new Gcp.DataCatalog.Inputs.TagTemplateFieldArgs
            {
                FieldId = "pii_type",
                DisplayName = "PII type",
                Type = new Gcp.DataCatalog.Inputs.TagTemplateFieldTypeArgs
                {
                    EnumType = new Gcp.DataCatalog.Inputs.TagTemplateFieldTypeEnumTypeArgs
                    {
                        AllowedValues = new[]
                        {
                            new Gcp.DataCatalog.Inputs.TagTemplateFieldTypeEnumTypeAllowedValueArgs
                            {
                                DisplayName = "EMAIL",
                            },
                            new Gcp.DataCatalog.Inputs.TagTemplateFieldTypeEnumTypeAllowedValueArgs
                            {
                                DisplayName = "SOCIAL SECURITY NUMBER",
                            },
                            new Gcp.DataCatalog.Inputs.TagTemplateFieldTypeEnumTypeAllowedValueArgs
                            {
                                DisplayName = "NONE",
                            },
                        },
                    },
                },
            },
        },
        ForceDelete = false,
    });

    var basicTag = new Gcp.DataCatalog.Tag("basic_tag", new()
    {
        Parent = entry.Id,
        Template = tagTemplate.Id,
        Fields = new[]
        {
            new Gcp.DataCatalog.Inputs.TagFieldArgs
            {
                FieldName = "source",
                StringValue = "my-string",
            },
            new Gcp.DataCatalog.Inputs.TagFieldArgs
            {
                FieldName = "num_rows",
                DoubleValue = 5,
            },
            new Gcp.DataCatalog.Inputs.TagFieldArgs
            {
                FieldName = "pii_type",
                EnumValue = "EMAIL",
            },
        },
        Column = "address",
    });

    var second_tag = new Gcp.DataCatalog.Tag("second-tag", new()
    {
        Parent = entry.Id,
        Template = tagTemplate.Id,
        Fields = new[]
        {
            new Gcp.DataCatalog.Inputs.TagFieldArgs
            {
                FieldName = "source",
                StringValue = "my-string",
            },
            new Gcp.DataCatalog.Inputs.TagFieldArgs
            {
                FieldName = "pii_type",
                EnumValue = "NONE",
            },
        },
        Column = "first_name",
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/datacatalog"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		entryGroup, err := datacatalog.NewEntryGroup(ctx, "entry_group", &datacatalog.EntryGroupArgs{
			EntryGroupId: pulumi.String("my_entry_group"),
		})
		if err != nil {
			return err
		}
		entry, err := datacatalog.NewEntry(ctx, "entry", &datacatalog.EntryArgs{
			EntryGroup:          entryGroup.ID(),
			EntryId:             pulumi.String("my_entry"),
			UserSpecifiedType:   pulumi.String("my_custom_type"),
			UserSpecifiedSystem: pulumi.String("SomethingExternal"),
			Schema: pulumi.String(`{
  "columns": [
    {
      "column": "first_name",
      "description": "First name",
      "mode": "REQUIRED",
      "type": "STRING"
    },
    {
      "column": "last_name",
      "description": "Last name",
      "mode": "REQUIRED",
      "type": "STRING"
    },
    {
      "column": "address",
      "description": "Address",
      "mode": "REPEATED",
      "subcolumns": [
        {
          "column": "city",
          "description": "City",
          "mode": "NULLABLE",
          "type": "STRING"
        },
        {
          "column": "state",
          "description": "State",
          "mode": "NULLABLE",
          "type": "STRING"
        }
      ],
      "type": "RECORD"
    }
  ]
}
`),
		})
		if err != nil {
			return err
		}
		tagTemplate, err := datacatalog.NewTagTemplate(ctx, "tag_template", &datacatalog.TagTemplateArgs{
			TagTemplateId: pulumi.String("my_template"),
			Region:        pulumi.String("us-central1"),
			DisplayName:   pulumi.String("Demo Tag Template"),
			Fields: datacatalog.TagTemplateFieldArray{
				&datacatalog.TagTemplateFieldArgs{
					FieldId:     pulumi.String("source"),
					DisplayName: pulumi.String("Source of data asset"),
					Type: &datacatalog.TagTemplateFieldTypeArgs{
						PrimitiveType: pulumi.String("STRING"),
					},
					IsRequired: pulumi.Bool(true),
				},
				&datacatalog.TagTemplateFieldArgs{
					FieldId:     pulumi.String("num_rows"),
					DisplayName: pulumi.String("Number of rows in the data asset"),
					Type: &datacatalog.TagTemplateFieldTypeArgs{
						PrimitiveType: pulumi.String("DOUBLE"),
					},
				},
				&datacatalog.TagTemplateFieldArgs{
					FieldId:     pulumi.String("pii_type"),
					DisplayName: pulumi.String("PII type"),
					Type: &datacatalog.TagTemplateFieldTypeArgs{
						EnumType: &datacatalog.TagTemplateFieldTypeEnumTypeArgs{
							AllowedValues: datacatalog.TagTemplateFieldTypeEnumTypeAllowedValueArray{
								&datacatalog.TagTemplateFieldTypeEnumTypeAllowedValueArgs{
									DisplayName: pulumi.String("EMAIL"),
								},
								&datacatalog.TagTemplateFieldTypeEnumTypeAllowedValueArgs{
									DisplayName: pulumi.String("SOCIAL SECURITY NUMBER"),
								},
								&datacatalog.TagTemplateFieldTypeEnumTypeAllowedValueArgs{
									DisplayName: pulumi.String("NONE"),
								},
							},
						},
					},
				},
			},
			ForceDelete: pulumi.Bool(false),
		})
		if err != nil {
			return err
		}
		_, err = datacatalog.NewTag(ctx, "basic_tag", &datacatalog.TagArgs{
			Parent:   entry.ID(),
			Template: tagTemplate.ID(),
			Fields: datacatalog.TagFieldArray{
				&datacatalog.TagFieldArgs{
					FieldName:   pulumi.String("source"),
					StringValue: pulumi.String("my-string"),
				},
				&datacatalog.TagFieldArgs{
					FieldName:   pulumi.String("num_rows"),
					DoubleValue: pulumi.Float64(5),
				},
				&datacatalog.TagFieldArgs{
					FieldName: pulumi.String("pii_type"),
					EnumValue: pulumi.String("EMAIL"),
				},
			},
			Column: pulumi.String("address"),
		})
		if err != nil {
			return err
		}
		_, err = datacatalog.NewTag(ctx, "second-tag", &datacatalog.TagArgs{
			Parent:   entry.ID(),
			Template: tagTemplate.ID(),
			Fields: datacatalog.TagFieldArray{
				&datacatalog.TagFieldArgs{
					FieldName:   pulumi.String("source"),
					StringValue: pulumi.String("my-string"),
				},
				&datacatalog.TagFieldArgs{
					FieldName: pulumi.String("pii_type"),
					EnumValue: pulumi.String("NONE"),
				},
			},
			Column: pulumi.String("first_name"),
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.datacatalog.EntryGroup;
import com.pulumi.gcp.datacatalog.EntryGroupArgs;
import com.pulumi.gcp.datacatalog.Entry;
import com.pulumi.gcp.datacatalog.EntryArgs;
import com.pulumi.gcp.datacatalog.TagTemplate;
import com.pulumi.gcp.datacatalog.TagTemplateArgs;
import com.pulumi.gcp.datacatalog.inputs.TagTemplateFieldArgs;
import com.pulumi.gcp.datacatalog.inputs.TagTemplateFieldTypeArgs;
import com.pulumi.gcp.datacatalog.inputs.TagTemplateFieldTypeEnumTypeArgs;
import com.pulumi.gcp.datacatalog.Tag;
import com.pulumi.gcp.datacatalog.TagArgs;
import com.pulumi.gcp.datacatalog.inputs.TagFieldArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        var entryGroup = new EntryGroup("entryGroup", EntryGroupArgs.builder()
            .entryGroupId("my_entry_group")
            .build());

        var entry = new Entry("entry", EntryArgs.builder()
            .entryGroup(entryGroup.id())
            .entryId("my_entry")
            .userSpecifiedType("my_custom_type")
            .userSpecifiedSystem("SomethingExternal")
            .schema("""
{
  "columns": [
    {
      "column": "first_name",
      "description": "First name",
      "mode": "REQUIRED",
      "type": "STRING"
    },
    {
      "column": "last_name",
      "description": "Last name",
      "mode": "REQUIRED",
      "type": "STRING"
    },
    {
      "column": "address",
      "description": "Address",
      "mode": "REPEATED",
      "subcolumns": [
        {
          "column": "city",
          "description": "City",
          "mode": "NULLABLE",
          "type": "STRING"
        },
        {
          "column": "state",
          "description": "State",
          "mode": "NULLABLE",
          "type": "STRING"
        }
      ],
      "type": "RECORD"
    }
  ]
}
            """)
            .build());

        var tagTemplate = new TagTemplate("tagTemplate", TagTemplateArgs.builder()
            .tagTemplateId("my_template")
            .region("us-central1")
            .displayName("Demo Tag Template")
            .fields(            
                TagTemplateFieldArgs.builder()
                    .fieldId("source")
                    .displayName("Source of data asset")
                    .type(TagTemplateFieldTypeArgs.builder()
                        .primitiveType("STRING")
                        .build())
                    .isRequired(true)
                    .build(),
                TagTemplateFieldArgs.builder()
                    .fieldId("num_rows")
                    .displayName("Number of rows in the data asset")
                    .type(TagTemplateFieldTypeArgs.builder()
                        .primitiveType("DOUBLE")
                        .build())
                    .build(),
                TagTemplateFieldArgs.builder()
                    .fieldId("pii_type")
                    .displayName("PII type")
                    .type(TagTemplateFieldTypeArgs.builder()
                        .enumType(TagTemplateFieldTypeEnumTypeArgs.builder()
                            .allowedValues(                            
                                TagTemplateFieldTypeEnumTypeAllowedValueArgs.builder()
                                    .displayName("EMAIL")
                                    .build(),
                                TagTemplateFieldTypeEnumTypeAllowedValueArgs.builder()
                                    .displayName("SOCIAL SECURITY NUMBER")
                                    .build(),
                                TagTemplateFieldTypeEnumTypeAllowedValueArgs.builder()
                                    .displayName("NONE")
                                    .build())
                            .build())
                        .build())
                    .build())
            .forceDelete("false")
            .build());

        var basicTag = new Tag("basicTag", TagArgs.builder()
            .parent(entry.id())
            .template(tagTemplate.id())
            .fields(            
                TagFieldArgs.builder()
                    .fieldName("source")
                    .stringValue("my-string")
                    .build(),
                TagFieldArgs.builder()
                    .fieldName("num_rows")
                    .doubleValue(5)
                    .build(),
                TagFieldArgs.builder()
                    .fieldName("pii_type")
                    .enumValue("EMAIL")
                    .build())
            .column("address")
            .build());

        var second_tag = new Tag("second-tag", TagArgs.builder()
            .parent(entry.id())
            .template(tagTemplate.id())
            .fields(            
                TagFieldArgs.builder()
                    .fieldName("source")
                    .stringValue("my-string")
                    .build(),
                TagFieldArgs.builder()
                    .fieldName("pii_type")
                    .enumValue("NONE")
                    .build())
            .column("first_name")
            .build());

    }
}
```
```yaml
resources:
  entry:
    type: gcp:datacatalog:Entry
    properties:
      entryGroup: ${entryGroup.id}
      entryId: my_entry
      userSpecifiedType: my_custom_type
      userSpecifiedSystem: SomethingExternal
      schema: |
        {
          "columns": [
            {
              "column": "first_name",
              "description": "First name",
              "mode": "REQUIRED",
              "type": "STRING"
            },
            {
              "column": "last_name",
              "description": "Last name",
              "mode": "REQUIRED",
              "type": "STRING"
            },
            {
              "column": "address",
              "description": "Address",
              "mode": "REPEATED",
              "subcolumns": [
                {
                  "column": "city",
                  "description": "City",
                  "mode": "NULLABLE",
                  "type": "STRING"
                },
                {
                  "column": "state",
                  "description": "State",
                  "mode": "NULLABLE",
                  "type": "STRING"
                }
              ],
              "type": "RECORD"
            }
          ]
        }
  entryGroup:
    type: gcp:datacatalog:EntryGroup
    name: entry_group
    properties:
      entryGroupId: my_entry_group
  tagTemplate:
    type: gcp:datacatalog:TagTemplate
    name: tag_template
    properties:
      tagTemplateId: my_template
      region: us-central1
      displayName: Demo Tag Template
      fields:
        - fieldId: source
          displayName: Source of data asset
          type:
            primitiveType: STRING
          isRequired: true
        - fieldId: num_rows
          displayName: Number of rows in the data asset
          type:
            primitiveType: DOUBLE
        - fieldId: pii_type
          displayName: PII type
          type:
            enumType:
              allowedValues:
                - displayName: EMAIL
                - displayName: SOCIAL SECURITY NUMBER
                - displayName: NONE
      forceDelete: 'false'
  basicTag:
    type: gcp:datacatalog:Tag
    name: basic_tag
    properties:
      parent: ${entry.id}
      template: ${tagTemplate.id}
      fields:
        - fieldName: source
          stringValue: my-string
        - fieldName: num_rows
          doubleValue: 5
        - fieldName: pii_type
          enumValue: EMAIL
      column: address
  second-tag:
    type: gcp:datacatalog:Tag
    properties:
      parent: ${entry.id}
      template: ${tagTemplate.id}
      fields:
        - fieldName: source
          stringValue: my-string
        - fieldName: pii_type
          enumValue: NONE
      column: first_name
```
<!--End PulumiCodeChooser -->

## Import

Tag can be imported using any of these accepted formats:

* `{{name}}`

When using the `pulumi import` command, Tag can be imported using one of the formats above. For example:

```sh
$ pulumi import gcp:datacatalog/tag:Tag default {{name}}
```


columnB" Resources like Entry can have schemas associated with them. This scope allows users to attach tags to an individual
column based on that schema. For attaching a tag to a nested column, use '.' to separate the column names. Example:
'outer_column.inner_column'
µ
fields@*>:<
:
datacatalogTagField!gcp:datacatalog/TagField:TagFieldèThis maps the ID of a tag field to the value of and additional information about that field.
Valid field IDs are defined by the tag's template. A tag must have at least 1 field and at most 500 fields.
Structure is documented below.
¿
parentB" ®The name of the parent this tag is attached to. This can be the name of an entry or an entry group. If an entry group,
the tag will be attached to all entries in that group.
Ê
template" ¹The resource name of the tag template that this tag uses. Example:
projects/{project_id}/locations/{location}/tagTemplates/{tagTemplateId}
This field cannot be modified after creation.
"
columnB" Resources like Entry can have schemas associated with them. This scope allows users to attach tags to an individual
column based on that schema. For attaching a tag to a nested column, use '.' to separate the column names. Example:
'outer_column.inner_column'
"µ
fields@*>:<
:
datacatalogTagField!gcp:datacatalog/TagField:TagFieldèThis maps the ID of a tag field to the value of and additional information about that field.
Valid field IDs are defined by the tag's template. A tag must have at least 1 field and at most 500 fields.
Structure is documented below.
"ú
name" íThe resource name of the tag in URL format. Example:
projects/{project_id}/locations/{location}/entrygroups/{entryGroupId}/entries/{entryId}/tags/{tag_id} or
projects/{project_id}/locations/{location}/entrygroups/{entryGroupId}/tags/{tag_id}
where tag_id is a system-generated identifier. Note that this Tag may not actually be stored in the location in this name.
"¿
parentB" ®The name of the parent this tag is attached to. This can be the name of an entry or an entry group. If an entry group,
the tag will be attached to all entries in that group.
"Ê
template" ¹The resource name of the tag template that this tag uses. Example:
projects/{project_id}/locations/{location}/tagTemplates/{tagTemplateId}
This field cannot be modified after creation.
"A
templateDisplayname" &The display name of the tag template.
*þe
C
datacatalogTagTemplate'gcp:datacatalog/tagTemplate:TagTemplateWA tag template defines a tag, which can have one or more typed fields.
The template is used to create and attach the tag to GCP resources.


To get more information about TagTemplate, see:

* [API documentation](https://cloud.google.com/data-catalog/docs/reference/rest/v1/projects.locations.tagTemplates)
* How-to Guides
    * [Official Documentation](https://cloud.google.com/data-catalog/docs)

## Example Usage

### Data Catalog Tag Template Basic


<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const basicTagTemplate = new gcp.datacatalog.TagTemplate("basic_tag_template", {
    tagTemplateId: "my_template",
    region: "us-central1",
    displayName: "Demo Tag Template",
    fields: [
        {
            fieldId: "source",
            displayName: "Source of data asset",
            type: {
                primitiveType: "STRING",
            },
            isRequired: true,
        },
        {
            fieldId: "num_rows",
            displayName: "Number of rows in the data asset",
            type: {
                primitiveType: "DOUBLE",
            },
        },
        {
            fieldId: "pii_type",
            displayName: "PII type",
            type: {
                enumType: {
                    allowedValues: [
                        {
                            displayName: "EMAIL",
                        },
                        {
                            displayName: "SOCIAL SECURITY NUMBER",
                        },
                        {
                            displayName: "NONE",
                        },
                    ],
                },
            },
        },
    ],
    forceDelete: false,
});
```
```python
import pulumi
import pulumi_gcp as gcp

basic_tag_template = gcp.datacatalog.TagTemplate("basic_tag_template",
    tag_template_id="my_template",
    region="us-central1",
    display_name="Demo Tag Template",
    fields=[
        {
            "field_id": "source",
            "display_name": "Source of data asset",
            "type": {
                "primitive_type": "STRING",
            },
            "is_required": True,
        },
        {
            "field_id": "num_rows",
            "display_name": "Number of rows in the data asset",
            "type": {
                "primitive_type": "DOUBLE",
            },
        },
        {
            "field_id": "pii_type",
            "display_name": "PII type",
            "type": {
                "enum_type": {
                    "allowed_values": [
                        {
                            "display_name": "EMAIL",
                        },
                        {
                            "display_name": "SOCIAL SECURITY NUMBER",
                        },
                        {
                            "display_name": "NONE",
                        },
                    ],
                },
            },
        },
    ],
    force_delete=False)
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var basicTagTemplate = new Gcp.DataCatalog.TagTemplate("basic_tag_template", new()
    {
        TagTemplateId = "my_template",
        Region = "us-central1",
        DisplayName = "Demo Tag Template",
        Fields = new[]
        {
            new Gcp.DataCatalog.Inputs.TagTemplateFieldArgs
            {
                FieldId = "source",
                DisplayName = "Source of data asset",
                Type = new Gcp.DataCatalog.Inputs.TagTemplateFieldTypeArgs
                {
                    PrimitiveType = "STRING",
                },
                IsRequired = true,
            },
            new Gcp.DataCatalog.Inputs.TagTemplateFieldArgs
            {
                FieldId = "num_rows",
                DisplayName = "Number of rows in the data asset",
                Type = new Gcp.DataCatalog.Inputs.TagTemplateFieldTypeArgs
                {
                    PrimitiveType = "DOUBLE",
                },
            },
            new Gcp.DataCatalog.Inputs.TagTemplateFieldArgs
            {
                FieldId = "pii_type",
                DisplayName = "PII type",
                Type = new Gcp.DataCatalog.Inputs.TagTemplateFieldTypeArgs
                {
                    EnumType = new Gcp.DataCatalog.Inputs.TagTemplateFieldTypeEnumTypeArgs
                    {
                        AllowedValues = new[]
                        {
                            new Gcp.DataCatalog.Inputs.TagTemplateFieldTypeEnumTypeAllowedValueArgs
                            {
                                DisplayName = "EMAIL",
                            },
                            new Gcp.DataCatalog.Inputs.TagTemplateFieldTypeEnumTypeAllowedValueArgs
                            {
                                DisplayName = "SOCIAL SECURITY NUMBER",
                            },
                            new Gcp.DataCatalog.Inputs.TagTemplateFieldTypeEnumTypeAllowedValueArgs
                            {
                                DisplayName = "NONE",
                            },
                        },
                    },
                },
            },
        },
        ForceDelete = false,
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/datacatalog"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		_, err := datacatalog.NewTagTemplate(ctx, "basic_tag_template", &datacatalog.TagTemplateArgs{
			TagTemplateId: pulumi.String("my_template"),
			Region:        pulumi.String("us-central1"),
			DisplayName:   pulumi.String("Demo Tag Template"),
			Fields: datacatalog.TagTemplateFieldArray{
				&datacatalog.TagTemplateFieldArgs{
					FieldId:     pulumi.String("source"),
					DisplayName: pulumi.String("Source of data asset"),
					Type: &datacatalog.TagTemplateFieldTypeArgs{
						PrimitiveType: pulumi.String("STRING"),
					},
					IsRequired: pulumi.Bool(true),
				},
				&datacatalog.TagTemplateFieldArgs{
					FieldId:     pulumi.String("num_rows"),
					DisplayName: pulumi.String("Number of rows in the data asset"),
					Type: &datacatalog.TagTemplateFieldTypeArgs{
						PrimitiveType: pulumi.String("DOUBLE"),
					},
				},
				&datacatalog.TagTemplateFieldArgs{
					FieldId:     pulumi.String("pii_type"),
					DisplayName: pulumi.String("PII type"),
					Type: &datacatalog.TagTemplateFieldTypeArgs{
						EnumType: &datacatalog.TagTemplateFieldTypeEnumTypeArgs{
							AllowedValues: datacatalog.TagTemplateFieldTypeEnumTypeAllowedValueArray{
								&datacatalog.TagTemplateFieldTypeEnumTypeAllowedValueArgs{
									DisplayName: pulumi.String("EMAIL"),
								},
								&datacatalog.TagTemplateFieldTypeEnumTypeAllowedValueArgs{
									DisplayName: pulumi.String("SOCIAL SECURITY NUMBER"),
								},
								&datacatalog.TagTemplateFieldTypeEnumTypeAllowedValueArgs{
									DisplayName: pulumi.String("NONE"),
								},
							},
						},
					},
				},
			},
			ForceDelete: pulumi.Bool(false),
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.datacatalog.TagTemplate;
import com.pulumi.gcp.datacatalog.TagTemplateArgs;
import com.pulumi.gcp.datacatalog.inputs.TagTemplateFieldArgs;
import com.pulumi.gcp.datacatalog.inputs.TagTemplateFieldTypeArgs;
import com.pulumi.gcp.datacatalog.inputs.TagTemplateFieldTypeEnumTypeArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        var basicTagTemplate = new TagTemplate("basicTagTemplate", TagTemplateArgs.builder()
            .tagTemplateId("my_template")
            .region("us-central1")
            .displayName("Demo Tag Template")
            .fields(            
                TagTemplateFieldArgs.builder()
                    .fieldId("source")
                    .displayName("Source of data asset")
                    .type(TagTemplateFieldTypeArgs.builder()
                        .primitiveType("STRING")
                        .build())
                    .isRequired(true)
                    .build(),
                TagTemplateFieldArgs.builder()
                    .fieldId("num_rows")
                    .displayName("Number of rows in the data asset")
                    .type(TagTemplateFieldTypeArgs.builder()
                        .primitiveType("DOUBLE")
                        .build())
                    .build(),
                TagTemplateFieldArgs.builder()
                    .fieldId("pii_type")
                    .displayName("PII type")
                    .type(TagTemplateFieldTypeArgs.builder()
                        .enumType(TagTemplateFieldTypeEnumTypeArgs.builder()
                            .allowedValues(                            
                                TagTemplateFieldTypeEnumTypeAllowedValueArgs.builder()
                                    .displayName("EMAIL")
                                    .build(),
                                TagTemplateFieldTypeEnumTypeAllowedValueArgs.builder()
                                    .displayName("SOCIAL SECURITY NUMBER")
                                    .build(),
                                TagTemplateFieldTypeEnumTypeAllowedValueArgs.builder()
                                    .displayName("NONE")
                                    .build())
                            .build())
                        .build())
                    .build())
            .forceDelete("false")
            .build());

    }
}
```
```yaml
resources:
  basicTagTemplate:
    type: gcp:datacatalog:TagTemplate
    name: basic_tag_template
    properties:
      tagTemplateId: my_template
      region: us-central1
      displayName: Demo Tag Template
      fields:
        - fieldId: source
          displayName: Source of data asset
          type:
            primitiveType: STRING
          isRequired: true
        - fieldId: num_rows
          displayName: Number of rows in the data asset
          type:
            primitiveType: DOUBLE
        - fieldId: pii_type
          displayName: PII type
          type:
            enumType:
              allowedValues:
                - displayName: EMAIL
                - displayName: SOCIAL SECURITY NUMBER
                - displayName: NONE
      forceDelete: 'false'
```
<!--End PulumiCodeChooser -->

## Import

TagTemplate can be imported using any of these accepted formats:

* `{{name}}`

When using the `pulumi import` command, TagTemplate can be imported using one of the formats above. For example:

```sh
$ pulumi import gcp:datacatalog/tagTemplate:TagTemplate default {{name}}
```

9
displayNameB" $The display name for this template.
ý
fieldsX*V:T
R
datacatalogTagTemplateField1gcp:datacatalog/TagTemplateField:TagTemplateFieldSet of tag template field IDs and the settings for the field. This set is an exhaustive list of the allowed fields. This set must contain at least one field and at most 500 fields. The change of field_id will be resulting in re-creating of field. The change of primitive_type will be resulting in re-creating of field, however if the field is a required, you cannot update it.
Structure is documented below.

forceDeleteB
 ~This confirms the deletion of any possible tags using this template. Must be set to true in order to delete the tag
template.

projectB" *
regionB" Template location region.
;
tagTemplateId" &The id of the tag template to create.
"9
displayNameB" $The display name for this template.
"ý
fieldsX*V:T
R
datacatalogTagTemplateField1gcp:datacatalog/TagTemplateField:TagTemplateFieldSet of tag template field IDs and the settings for the field. This set is an exhaustive list of the allowed fields. This set must contain at least one field and at most 500 fields. The change of field_id will be resulting in re-creating of field. The change of primitive_type will be resulting in re-creating of field, however if the field is a required, you cannot update it.
Structure is documented below.
"
forceDeleteB
 ~This confirms the deletion of any possible tags using this template. Must be set to true in order to delete the tag
template.
"
name" The resource name of the tag template in URL format. Example: projects/{project_id}/locations/{location}/tagTemplates/{tagTemplateId}
"
project" "(
region" Template location region.
";
tagTemplateId" &The id of the tag template to create.
*ÓÍ
a
datacatalogTagTemplateIamBinding;gcp:datacatalog/tagTemplateIamBinding:TagTemplateIamBinding³­Three different resources help you manage your IAM policy for Data catalog TagTemplate. Each of these resources serves a different use case:

* `gcp.datacatalog.TagTemplateIamPolicy`: Authoritative. Sets the IAM policy for the tagtemplate and replaces any existing policy already attached.
* `gcp.datacatalog.TagTemplateIamBinding`: Authoritative for a given role. Updates the IAM policy to grant a role to a list of members. Other roles within the IAM policy for the tagtemplate are preserved.
* `gcp.datacatalog.TagTemplateIamMember`: Non-authoritative. Updates the IAM policy to grant a role to a new member. Other members for the role for the tagtemplate are preserved.

A data source can be used to retrieve policy data in advent you do not need creation

* `gcp.datacatalog.TagTemplateIamPolicy`: Retrieves the IAM policy for the tagtemplate

> **Note:** `gcp.datacatalog.TagTemplateIamPolicy` **cannot** be used in conjunction with `gcp.datacatalog.TagTemplateIamBinding` and `gcp.datacatalog.TagTemplateIamMember` or they will fight over what your policy should be.

> **Note:** `gcp.datacatalog.TagTemplateIamBinding` resources **can be** used in conjunction with `gcp.datacatalog.TagTemplateIamMember` resources **only if** they do not grant privilege to the same role.



## gcp.datacatalog.TagTemplateIamPolicy

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const admin = gcp.organizations.getIAMPolicy({
    bindings: [{
        role: "roles/viewer",
        members: ["user:jane@example.com"],
    }],
});
const policy = new gcp.datacatalog.TagTemplateIamPolicy("policy", {
    tagTemplate: basicTagTemplate.name,
    policyData: admin.then(admin => admin.policyData),
});
```
```python
import pulumi
import pulumi_gcp as gcp

admin = gcp.organizations.get_iam_policy(bindings=[{
    "role": "roles/viewer",
    "members": ["user:jane@example.com"],
}])
policy = gcp.datacatalog.TagTemplateIamPolicy("policy",
    tag_template=basic_tag_template["name"],
    policy_data=admin.policy_data)
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var admin = Gcp.Organizations.GetIAMPolicy.Invoke(new()
    {
        Bindings = new[]
        {
            new Gcp.Organizations.Inputs.GetIAMPolicyBindingInputArgs
            {
                Role = "roles/viewer",
                Members = new[]
                {
                    "user:jane@example.com",
                },
            },
        },
    });

    var policy = new Gcp.DataCatalog.TagTemplateIamPolicy("policy", new()
    {
        TagTemplate = basicTagTemplate.Name,
        PolicyData = admin.Apply(getIAMPolicyResult => getIAMPolicyResult.PolicyData),
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/datacatalog"
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/organizations"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		admin, err := organizations.LookupIAMPolicy(ctx, &organizations.LookupIAMPolicyArgs{
			Bindings: []organizations.GetIAMPolicyBinding{
				{
					Role: "roles/viewer",
					Members: []string{
						"user:jane@example.com",
					},
				},
			},
		}, nil)
		if err != nil {
			return err
		}
		_, err = datacatalog.NewTagTemplateIamPolicy(ctx, "policy", &datacatalog.TagTemplateIamPolicyArgs{
			TagTemplate: pulumi.Any(basicTagTemplate.Name),
			PolicyData:  pulumi.String(admin.PolicyData),
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.organizations.OrganizationsFunctions;
import com.pulumi.gcp.organizations.inputs.GetIAMPolicyArgs;
import com.pulumi.gcp.datacatalog.TagTemplateIamPolicy;
import com.pulumi.gcp.datacatalog.TagTemplateIamPolicyArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        final var admin = OrganizationsFunctions.getIAMPolicy(GetIAMPolicyArgs.builder()
            .bindings(GetIAMPolicyBindingArgs.builder()
                .role("roles/viewer")
                .members("user:jane@example.com")
                .build())
            .build());

        var policy = new TagTemplateIamPolicy("policy", TagTemplateIamPolicyArgs.builder()
            .tagTemplate(basicTagTemplate.name())
            .policyData(admin.applyValue(getIAMPolicyResult -> getIAMPolicyResult.policyData()))
            .build());

    }
}
```
```yaml
resources:
  policy:
    type: gcp:datacatalog:TagTemplateIamPolicy
    properties:
      tagTemplate: ${basicTagTemplate.name}
      policyData: ${admin.policyData}
variables:
  admin:
    fn::invoke:
      function: gcp:organizations:getIAMPolicy
      arguments:
        bindings:
          - role: roles/viewer
            members:
              - user:jane@example.com
```
<!--End PulumiCodeChooser -->

## gcp.datacatalog.TagTemplateIamBinding

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const binding = new gcp.datacatalog.TagTemplateIamBinding("binding", {
    tagTemplate: basicTagTemplate.name,
    role: "roles/viewer",
    members: ["user:jane@example.com"],
});
```
```python
import pulumi
import pulumi_gcp as gcp

binding = gcp.datacatalog.TagTemplateIamBinding("binding",
    tag_template=basic_tag_template["name"],
    role="roles/viewer",
    members=["user:jane@example.com"])
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var binding = new Gcp.DataCatalog.TagTemplateIamBinding("binding", new()
    {
        TagTemplate = basicTagTemplate.Name,
        Role = "roles/viewer",
        Members = new[]
        {
            "user:jane@example.com",
        },
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/datacatalog"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		_, err := datacatalog.NewTagTemplateIamBinding(ctx, "binding", &datacatalog.TagTemplateIamBindingArgs{
			TagTemplate: pulumi.Any(basicTagTemplate.Name),
			Role:        pulumi.String("roles/viewer"),
			Members: pulumi.StringArray{
				pulumi.String("user:jane@example.com"),
			},
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.datacatalog.TagTemplateIamBinding;
import com.pulumi.gcp.datacatalog.TagTemplateIamBindingArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        var binding = new TagTemplateIamBinding("binding", TagTemplateIamBindingArgs.builder()
            .tagTemplate(basicTagTemplate.name())
            .role("roles/viewer")
            .members("user:jane@example.com")
            .build());

    }
}
```
```yaml
resources:
  binding:
    type: gcp:datacatalog:TagTemplateIamBinding
    properties:
      tagTemplate: ${basicTagTemplate.name}
      role: roles/viewer
      members:
        - user:jane@example.com
```
<!--End PulumiCodeChooser -->

## gcp.datacatalog.TagTemplateIamMember

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const member = new gcp.datacatalog.TagTemplateIamMember("member", {
    tagTemplate: basicTagTemplate.name,
    role: "roles/viewer",
    member: "user:jane@example.com",
});
```
```python
import pulumi
import pulumi_gcp as gcp

member = gcp.datacatalog.TagTemplateIamMember("member",
    tag_template=basic_tag_template["name"],
    role="roles/viewer",
    member="user:jane@example.com")
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var member = new Gcp.DataCatalog.TagTemplateIamMember("member", new()
    {
        TagTemplate = basicTagTemplate.Name,
        Role = "roles/viewer",
        Member = "user:jane@example.com",
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/datacatalog"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		_, err := datacatalog.NewTagTemplateIamMember(ctx, "member", &datacatalog.TagTemplateIamMemberArgs{
			TagTemplate: pulumi.Any(basicTagTemplate.Name),
			Role:        pulumi.String("roles/viewer"),
			Member:      pulumi.String("user:jane@example.com"),
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.datacatalog.TagTemplateIamMember;
import com.pulumi.gcp.datacatalog.TagTemplateIamMemberArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        var member = new TagTemplateIamMember("member", TagTemplateIamMemberArgs.builder()
            .tagTemplate(basicTagTemplate.name())
            .role("roles/viewer")
            .member("user:jane@example.com")
            .build());

    }
}
```
```yaml
resources:
  member:
    type: gcp:datacatalog:TagTemplateIamMember
    properties:
      tagTemplate: ${basicTagTemplate.name}
      role: roles/viewer
      member: user:jane@example.com
```
<!--End PulumiCodeChooser -->


## This resource supports User Project Overrides.

-

# IAM policy for Data catalog TagTemplate
Three different resources help you manage your IAM policy for Data catalog TagTemplate. Each of these resources serves a different use case:

* `gcp.datacatalog.TagTemplateIamPolicy`: Authoritative. Sets the IAM policy for the tagtemplate and replaces any existing policy already attached.
* `gcp.datacatalog.TagTemplateIamBinding`: Authoritative for a given role. Updates the IAM policy to grant a role to a list of members. Other roles within the IAM policy for the tagtemplate are preserved.
* `gcp.datacatalog.TagTemplateIamMember`: Non-authoritative. Updates the IAM policy to grant a role to a new member. Other members for the role for the tagtemplate are preserved.

A data source can be used to retrieve policy data in advent you do not need creation

* `gcp.datacatalog.TagTemplateIamPolicy`: Retrieves the IAM policy for the tagtemplate

> **Note:** `gcp.datacatalog.TagTemplateIamPolicy` **cannot** be used in conjunction with `gcp.datacatalog.TagTemplateIamBinding` and `gcp.datacatalog.TagTemplateIamMember` or they will fight over what your policy should be.

> **Note:** `gcp.datacatalog.TagTemplateIamBinding` resources **can be** used in conjunction with `gcp.datacatalog.TagTemplateIamMember` resources **only if** they do not grant privilege to the same role.



## gcp.datacatalog.TagTemplateIamPolicy

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const admin = gcp.organizations.getIAMPolicy({
    bindings: [{
        role: "roles/viewer",
        members: ["user:jane@example.com"],
    }],
});
const policy = new gcp.datacatalog.TagTemplateIamPolicy("policy", {
    tagTemplate: basicTagTemplate.name,
    policyData: admin.then(admin => admin.policyData),
});
```
```python
import pulumi
import pulumi_gcp as gcp

admin = gcp.organizations.get_iam_policy(bindings=[{
    "role": "roles/viewer",
    "members": ["user:jane@example.com"],
}])
policy = gcp.datacatalog.TagTemplateIamPolicy("policy",
    tag_template=basic_tag_template["name"],
    policy_data=admin.policy_data)
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var admin = Gcp.Organizations.GetIAMPolicy.Invoke(new()
    {
        Bindings = new[]
        {
            new Gcp.Organizations.Inputs.GetIAMPolicyBindingInputArgs
            {
                Role = "roles/viewer",
                Members = new[]
                {
                    "user:jane@example.com",
                },
            },
        },
    });

    var policy = new Gcp.DataCatalog.TagTemplateIamPolicy("policy", new()
    {
        TagTemplate = basicTagTemplate.Name,
        PolicyData = admin.Apply(getIAMPolicyResult => getIAMPolicyResult.PolicyData),
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/datacatalog"
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/organizations"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		admin, err := organizations.LookupIAMPolicy(ctx, &organizations.LookupIAMPolicyArgs{
			Bindings: []organizations.GetIAMPolicyBinding{
				{
					Role: "roles/viewer",
					Members: []string{
						"user:jane@example.com",
					},
				},
			},
		}, nil)
		if err != nil {
			return err
		}
		_, err = datacatalog.NewTagTemplateIamPolicy(ctx, "policy", &datacatalog.TagTemplateIamPolicyArgs{
			TagTemplate: pulumi.Any(basicTagTemplate.Name),
			PolicyData:  pulumi.String(admin.PolicyData),
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.organizations.OrganizationsFunctions;
import com.pulumi.gcp.organizations.inputs.GetIAMPolicyArgs;
import com.pulumi.gcp.datacatalog.TagTemplateIamPolicy;
import com.pulumi.gcp.datacatalog.TagTemplateIamPolicyArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        final var admin = OrganizationsFunctions.getIAMPolicy(GetIAMPolicyArgs.builder()
            .bindings(GetIAMPolicyBindingArgs.builder()
                .role("roles/viewer")
                .members("user:jane@example.com")
                .build())
            .build());

        var policy = new TagTemplateIamPolicy("policy", TagTemplateIamPolicyArgs.builder()
            .tagTemplate(basicTagTemplate.name())
            .policyData(admin.applyValue(getIAMPolicyResult -> getIAMPolicyResult.policyData()))
            .build());

    }
}
```
```yaml
resources:
  policy:
    type: gcp:datacatalog:TagTemplateIamPolicy
    properties:
      tagTemplate: ${basicTagTemplate.name}
      policyData: ${admin.policyData}
variables:
  admin:
    fn::invoke:
      function: gcp:organizations:getIAMPolicy
      arguments:
        bindings:
          - role: roles/viewer
            members:
              - user:jane@example.com
```
<!--End PulumiCodeChooser -->

## gcp.datacatalog.TagTemplateIamBinding

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const binding = new gcp.datacatalog.TagTemplateIamBinding("binding", {
    tagTemplate: basicTagTemplate.name,
    role: "roles/viewer",
    members: ["user:jane@example.com"],
});
```
```python
import pulumi
import pulumi_gcp as gcp

binding = gcp.datacatalog.TagTemplateIamBinding("binding",
    tag_template=basic_tag_template["name"],
    role="roles/viewer",
    members=["user:jane@example.com"])
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var binding = new Gcp.DataCatalog.TagTemplateIamBinding("binding", new()
    {
        TagTemplate = basicTagTemplate.Name,
        Role = "roles/viewer",
        Members = new[]
        {
            "user:jane@example.com",
        },
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/datacatalog"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		_, err := datacatalog.NewTagTemplateIamBinding(ctx, "binding", &datacatalog.TagTemplateIamBindingArgs{
			TagTemplate: pulumi.Any(basicTagTemplate.Name),
			Role:        pulumi.String("roles/viewer"),
			Members: pulumi.StringArray{
				pulumi.String("user:jane@example.com"),
			},
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.datacatalog.TagTemplateIamBinding;
import com.pulumi.gcp.datacatalog.TagTemplateIamBindingArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        var binding = new TagTemplateIamBinding("binding", TagTemplateIamBindingArgs.builder()
            .tagTemplate(basicTagTemplate.name())
            .role("roles/viewer")
            .members("user:jane@example.com")
            .build());

    }
}
```
```yaml
resources:
  binding:
    type: gcp:datacatalog:TagTemplateIamBinding
    properties:
      tagTemplate: ${basicTagTemplate.name}
      role: roles/viewer
      members:
        - user:jane@example.com
```
<!--End PulumiCodeChooser -->

## gcp.datacatalog.TagTemplateIamMember

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const member = new gcp.datacatalog.TagTemplateIamMember("member", {
    tagTemplate: basicTagTemplate.name,
    role: "roles/viewer",
    member: "user:jane@example.com",
});
```
```python
import pulumi
import pulumi_gcp as gcp

member = gcp.datacatalog.TagTemplateIamMember("member",
    tag_template=basic_tag_template["name"],
    role="roles/viewer",
    member="user:jane@example.com")
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var member = new Gcp.DataCatalog.TagTemplateIamMember("member", new()
    {
        TagTemplate = basicTagTemplate.Name,
        Role = "roles/viewer",
        Member = "user:jane@example.com",
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/datacatalog"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		_, err := datacatalog.NewTagTemplateIamMember(ctx, "member", &datacatalog.TagTemplateIamMemberArgs{
			TagTemplate: pulumi.Any(basicTagTemplate.Name),
			Role:        pulumi.String("roles/viewer"),
			Member:      pulumi.String("user:jane@example.com"),
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.datacatalog.TagTemplateIamMember;
import com.pulumi.gcp.datacatalog.TagTemplateIamMemberArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        var member = new TagTemplateIamMember("member", TagTemplateIamMemberArgs.builder()
            .tagTemplate(basicTagTemplate.name())
            .role("roles/viewer")
            .member("user:jane@example.com")
            .build());

    }
}
```
```yaml
resources:
  member:
    type: gcp:datacatalog:TagTemplateIamMember
    properties:
      tagTemplate: ${basicTagTemplate.name}
      role: roles/viewer
      member: user:jane@example.com
```
<!--End PulumiCodeChooser -->

## Import

For all import syntaxes, the "resource in question" can take any of the following forms:

* projects/{{project}}/locations/{{region}}/tagTemplates/{{tag_template}}

* {{project}}/{{region}}/{{tag_template}}

* {{region}}/{{tag_template}}

* {{tag_template}}

Any variables not passed in the import command will be taken from the provider configuration.

Data catalog tagtemplate IAM resources can be imported using the resource identifiers, role, and member.

IAM member imports use space-delimited identifiers: the resource in question, the role, and the member identity, e.g.

```sh
$ pulumi import gcp:datacatalog/tagTemplateIamBinding:TagTemplateIamBinding editor "projects/{{project}}/locations/{{region}}/tagTemplates/{{tag_template}} roles/viewer user:jane@example.com"
```

IAM binding imports use space-delimited identifiers: the resource in question and the role, e.g.

```sh
$ pulumi import gcp:datacatalog/tagTemplateIamBinding:TagTemplateIamBinding editor "projects/{{project}}/locations/{{region}}/tagTemplates/{{tag_template}} roles/viewer"
```

IAM policy imports use the identifier of the resource in question, e.g.

```sh
$ pulumi import gcp:datacatalog/tagTemplateIamBinding:TagTemplateIamBinding editor projects/{{project}}/locations/{{region}}/tagTemplates/{{tag_template}}
```

-> **Custom Roles** If you're importing a IAM resource with a custom role, make sure to use the

 full name of the custom role, e.g. `[projects/my-project|organizations/my-org]/roles/my-custom-role`.


	conditionB:~
|
datacatalogTagTemplateIamBindingConditionMgcp:datacatalog/TagTemplateIamBindingCondition:TagTemplateIamBindingConditionÖ	
members*" Ä	Identities that will be granted the privilege in `role`.
Each entry can have one of the following values:
* **allUsers**: A special identifier that represents anyone who is on the internet; with or without a Google account.
* **allAuthenticatedUsers**: A special identifier that represents anyone who is authenticated with a Google account or a service account.
* **user:{emailid}**: An email address that represents a specific Google account. For example, alice@gmail.com or joe@example.com.
* **serviceAccount:{emailid}**: An email address that represents a service account. For example, my-other-app@appspot.gserviceaccount.com.
* **group:{emailid}**: An email address that represents a Google group. For example, admins@example.com.
* **domain:{domain}**: A G Suite domain (primary, instead of alias) name that represents all the users of that domain. For example, google.com or example.com.
* **projectOwner:projectid**: Owners of the given project. For example, "projectOwner:my-example-project"
* **projectEditor:projectid**: Editors of the given project. For example, "projectEditor:my-example-project"
* **projectViewer:projectid**: Viewers of the given project. For example, "projectViewer:my-example-project"

projectB" The ID of the project in which the resource belongs.
If it is not provided, the project will be parsed from the identifier of the parent resource. If no project is provided in the parent identifier and no project is specified, the provider project is used.

regionB" Þ
role" ÑThe role that should be applied. Only one
`gcp.datacatalog.TagTemplateIamBinding` can be used per role. Note that custom roles must be of the format
`[projects|organizations]/{parent-name}/roles/{role-name}`.
N
tagTemplate" ;Used to find the parent resource to bind the IAM policy to
"
	conditionB:~
|
datacatalogTagTemplateIamBindingConditionMgcp:datacatalog/TagTemplateIamBindingCondition:TagTemplateIamBindingCondition"3
etag" '(Computed) The etag of the IAM policy.
"Ö	
members*" Ä	Identities that will be granted the privilege in `role`.
Each entry can have one of the following values:
* **allUsers**: A special identifier that represents anyone who is on the internet; with or without a Google account.
* **allAuthenticatedUsers**: A special identifier that represents anyone who is authenticated with a Google account or a service account.
* **user:{emailid}**: An email address that represents a specific Google account. For example, alice@gmail.com or joe@example.com.
* **serviceAccount:{emailid}**: An email address that represents a service account. For example, my-other-app@appspot.gserviceaccount.com.
* **group:{emailid}**: An email address that represents a Google group. For example, admins@example.com.
* **domain:{domain}**: A G Suite domain (primary, instead of alias) name that represents all the users of that domain. For example, google.com or example.com.
* **projectOwner:projectid**: Owners of the given project. For example, "projectOwner:my-example-project"
* **projectEditor:projectid**: Editors of the given project. For example, "projectEditor:my-example-project"
* **projectViewer:projectid**: Viewers of the given project. For example, "projectViewer:my-example-project"
"
project" The ID of the project in which the resource belongs.
If it is not provided, the project will be parsed from the identifier of the parent resource. If no project is provided in the parent identifier and no project is specified, the provider project is used.
"
region" "Þ
role" ÑThe role that should be applied. Only one
`gcp.datacatalog.TagTemplateIamBinding` can be used per role. Note that custom roles must be of the format
`[projects|organizations]/{parent-name}/roles/{role-name}`.
"N
tagTemplate" ;Used to find the parent resource to bind the IAM policy to
*ºÍ
^
datacatalogTagTemplateIamMember9gcp:datacatalog/tagTemplateIamMember:TagTemplateIamMember­­Three different resources help you manage your IAM policy for Data catalog TagTemplate. Each of these resources serves a different use case:

* `gcp.datacatalog.TagTemplateIamPolicy`: Authoritative. Sets the IAM policy for the tagtemplate and replaces any existing policy already attached.
* `gcp.datacatalog.TagTemplateIamBinding`: Authoritative for a given role. Updates the IAM policy to grant a role to a list of members. Other roles within the IAM policy for the tagtemplate are preserved.
* `gcp.datacatalog.TagTemplateIamMember`: Non-authoritative. Updates the IAM policy to grant a role to a new member. Other members for the role for the tagtemplate are preserved.

A data source can be used to retrieve policy data in advent you do not need creation

* `gcp.datacatalog.TagTemplateIamPolicy`: Retrieves the IAM policy for the tagtemplate

> **Note:** `gcp.datacatalog.TagTemplateIamPolicy` **cannot** be used in conjunction with `gcp.datacatalog.TagTemplateIamBinding` and `gcp.datacatalog.TagTemplateIamMember` or they will fight over what your policy should be.

> **Note:** `gcp.datacatalog.TagTemplateIamBinding` resources **can be** used in conjunction with `gcp.datacatalog.TagTemplateIamMember` resources **only if** they do not grant privilege to the same role.



## gcp.datacatalog.TagTemplateIamPolicy

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const admin = gcp.organizations.getIAMPolicy({
    bindings: [{
        role: "roles/viewer",
        members: ["user:jane@example.com"],
    }],
});
const policy = new gcp.datacatalog.TagTemplateIamPolicy("policy", {
    tagTemplate: basicTagTemplate.name,
    policyData: admin.then(admin => admin.policyData),
});
```
```python
import pulumi
import pulumi_gcp as gcp

admin = gcp.organizations.get_iam_policy(bindings=[{
    "role": "roles/viewer",
    "members": ["user:jane@example.com"],
}])
policy = gcp.datacatalog.TagTemplateIamPolicy("policy",
    tag_template=basic_tag_template["name"],
    policy_data=admin.policy_data)
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var admin = Gcp.Organizations.GetIAMPolicy.Invoke(new()
    {
        Bindings = new[]
        {
            new Gcp.Organizations.Inputs.GetIAMPolicyBindingInputArgs
            {
                Role = "roles/viewer",
                Members = new[]
                {
                    "user:jane@example.com",
                },
            },
        },
    });

    var policy = new Gcp.DataCatalog.TagTemplateIamPolicy("policy", new()
    {
        TagTemplate = basicTagTemplate.Name,
        PolicyData = admin.Apply(getIAMPolicyResult => getIAMPolicyResult.PolicyData),
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/datacatalog"
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/organizations"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		admin, err := organizations.LookupIAMPolicy(ctx, &organizations.LookupIAMPolicyArgs{
			Bindings: []organizations.GetIAMPolicyBinding{
				{
					Role: "roles/viewer",
					Members: []string{
						"user:jane@example.com",
					},
				},
			},
		}, nil)
		if err != nil {
			return err
		}
		_, err = datacatalog.NewTagTemplateIamPolicy(ctx, "policy", &datacatalog.TagTemplateIamPolicyArgs{
			TagTemplate: pulumi.Any(basicTagTemplate.Name),
			PolicyData:  pulumi.String(admin.PolicyData),
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.organizations.OrganizationsFunctions;
import com.pulumi.gcp.organizations.inputs.GetIAMPolicyArgs;
import com.pulumi.gcp.datacatalog.TagTemplateIamPolicy;
import com.pulumi.gcp.datacatalog.TagTemplateIamPolicyArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        final var admin = OrganizationsFunctions.getIAMPolicy(GetIAMPolicyArgs.builder()
            .bindings(GetIAMPolicyBindingArgs.builder()
                .role("roles/viewer")
                .members("user:jane@example.com")
                .build())
            .build());

        var policy = new TagTemplateIamPolicy("policy", TagTemplateIamPolicyArgs.builder()
            .tagTemplate(basicTagTemplate.name())
            .policyData(admin.applyValue(getIAMPolicyResult -> getIAMPolicyResult.policyData()))
            .build());

    }
}
```
```yaml
resources:
  policy:
    type: gcp:datacatalog:TagTemplateIamPolicy
    properties:
      tagTemplate: ${basicTagTemplate.name}
      policyData: ${admin.policyData}
variables:
  admin:
    fn::invoke:
      function: gcp:organizations:getIAMPolicy
      arguments:
        bindings:
          - role: roles/viewer
            members:
              - user:jane@example.com
```
<!--End PulumiCodeChooser -->

## gcp.datacatalog.TagTemplateIamBinding

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const binding = new gcp.datacatalog.TagTemplateIamBinding("binding", {
    tagTemplate: basicTagTemplate.name,
    role: "roles/viewer",
    members: ["user:jane@example.com"],
});
```
```python
import pulumi
import pulumi_gcp as gcp

binding = gcp.datacatalog.TagTemplateIamBinding("binding",
    tag_template=basic_tag_template["name"],
    role="roles/viewer",
    members=["user:jane@example.com"])
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var binding = new Gcp.DataCatalog.TagTemplateIamBinding("binding", new()
    {
        TagTemplate = basicTagTemplate.Name,
        Role = "roles/viewer",
        Members = new[]
        {
            "user:jane@example.com",
        },
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/datacatalog"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		_, err := datacatalog.NewTagTemplateIamBinding(ctx, "binding", &datacatalog.TagTemplateIamBindingArgs{
			TagTemplate: pulumi.Any(basicTagTemplate.Name),
			Role:        pulumi.String("roles/viewer"),
			Members: pulumi.StringArray{
				pulumi.String("user:jane@example.com"),
			},
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.datacatalog.TagTemplateIamBinding;
import com.pulumi.gcp.datacatalog.TagTemplateIamBindingArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        var binding = new TagTemplateIamBinding("binding", TagTemplateIamBindingArgs.builder()
            .tagTemplate(basicTagTemplate.name())
            .role("roles/viewer")
            .members("user:jane@example.com")
            .build());

    }
}
```
```yaml
resources:
  binding:
    type: gcp:datacatalog:TagTemplateIamBinding
    properties:
      tagTemplate: ${basicTagTemplate.name}
      role: roles/viewer
      members:
        - user:jane@example.com
```
<!--End PulumiCodeChooser -->

## gcp.datacatalog.TagTemplateIamMember

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const member = new gcp.datacatalog.TagTemplateIamMember("member", {
    tagTemplate: basicTagTemplate.name,
    role: "roles/viewer",
    member: "user:jane@example.com",
});
```
```python
import pulumi
import pulumi_gcp as gcp

member = gcp.datacatalog.TagTemplateIamMember("member",
    tag_template=basic_tag_template["name"],
    role="roles/viewer",
    member="user:jane@example.com")
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var member = new Gcp.DataCatalog.TagTemplateIamMember("member", new()
    {
        TagTemplate = basicTagTemplate.Name,
        Role = "roles/viewer",
        Member = "user:jane@example.com",
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/datacatalog"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		_, err := datacatalog.NewTagTemplateIamMember(ctx, "member", &datacatalog.TagTemplateIamMemberArgs{
			TagTemplate: pulumi.Any(basicTagTemplate.Name),
			Role:        pulumi.String("roles/viewer"),
			Member:      pulumi.String("user:jane@example.com"),
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.datacatalog.TagTemplateIamMember;
import com.pulumi.gcp.datacatalog.TagTemplateIamMemberArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        var member = new TagTemplateIamMember("member", TagTemplateIamMemberArgs.builder()
            .tagTemplate(basicTagTemplate.name())
            .role("roles/viewer")
            .member("user:jane@example.com")
            .build());

    }
}
```
```yaml
resources:
  member:
    type: gcp:datacatalog:TagTemplateIamMember
    properties:
      tagTemplate: ${basicTagTemplate.name}
      role: roles/viewer
      member: user:jane@example.com
```
<!--End PulumiCodeChooser -->


## This resource supports User Project Overrides.

-

# IAM policy for Data catalog TagTemplate
Three different resources help you manage your IAM policy for Data catalog TagTemplate. Each of these resources serves a different use case:

* `gcp.datacatalog.TagTemplateIamPolicy`: Authoritative. Sets the IAM policy for the tagtemplate and replaces any existing policy already attached.
* `gcp.datacatalog.TagTemplateIamBinding`: Authoritative for a given role. Updates the IAM policy to grant a role to a list of members. Other roles within the IAM policy for the tagtemplate are preserved.
* `gcp.datacatalog.TagTemplateIamMember`: Non-authoritative. Updates the IAM policy to grant a role to a new member. Other members for the role for the tagtemplate are preserved.

A data source can be used to retrieve policy data in advent you do not need creation

* `gcp.datacatalog.TagTemplateIamPolicy`: Retrieves the IAM policy for the tagtemplate

> **Note:** `gcp.datacatalog.TagTemplateIamPolicy` **cannot** be used in conjunction with `gcp.datacatalog.TagTemplateIamBinding` and `gcp.datacatalog.TagTemplateIamMember` or they will fight over what your policy should be.

> **Note:** `gcp.datacatalog.TagTemplateIamBinding` resources **can be** used in conjunction with `gcp.datacatalog.TagTemplateIamMember` resources **only if** they do not grant privilege to the same role.



## gcp.datacatalog.TagTemplateIamPolicy

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const admin = gcp.organizations.getIAMPolicy({
    bindings: [{
        role: "roles/viewer",
        members: ["user:jane@example.com"],
    }],
});
const policy = new gcp.datacatalog.TagTemplateIamPolicy("policy", {
    tagTemplate: basicTagTemplate.name,
    policyData: admin.then(admin => admin.policyData),
});
```
```python
import pulumi
import pulumi_gcp as gcp

admin = gcp.organizations.get_iam_policy(bindings=[{
    "role": "roles/viewer",
    "members": ["user:jane@example.com"],
}])
policy = gcp.datacatalog.TagTemplateIamPolicy("policy",
    tag_template=basic_tag_template["name"],
    policy_data=admin.policy_data)
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var admin = Gcp.Organizations.GetIAMPolicy.Invoke(new()
    {
        Bindings = new[]
        {
            new Gcp.Organizations.Inputs.GetIAMPolicyBindingInputArgs
            {
                Role = "roles/viewer",
                Members = new[]
                {
                    "user:jane@example.com",
                },
            },
        },
    });

    var policy = new Gcp.DataCatalog.TagTemplateIamPolicy("policy", new()
    {
        TagTemplate = basicTagTemplate.Name,
        PolicyData = admin.Apply(getIAMPolicyResult => getIAMPolicyResult.PolicyData),
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/datacatalog"
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/organizations"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		admin, err := organizations.LookupIAMPolicy(ctx, &organizations.LookupIAMPolicyArgs{
			Bindings: []organizations.GetIAMPolicyBinding{
				{
					Role: "roles/viewer",
					Members: []string{
						"user:jane@example.com",
					},
				},
			},
		}, nil)
		if err != nil {
			return err
		}
		_, err = datacatalog.NewTagTemplateIamPolicy(ctx, "policy", &datacatalog.TagTemplateIamPolicyArgs{
			TagTemplate: pulumi.Any(basicTagTemplate.Name),
			PolicyData:  pulumi.String(admin.PolicyData),
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.organizations.OrganizationsFunctions;
import com.pulumi.gcp.organizations.inputs.GetIAMPolicyArgs;
import com.pulumi.gcp.datacatalog.TagTemplateIamPolicy;
import com.pulumi.gcp.datacatalog.TagTemplateIamPolicyArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        final var admin = OrganizationsFunctions.getIAMPolicy(GetIAMPolicyArgs.builder()
            .bindings(GetIAMPolicyBindingArgs.builder()
                .role("roles/viewer")
                .members("user:jane@example.com")
                .build())
            .build());

        var policy = new TagTemplateIamPolicy("policy", TagTemplateIamPolicyArgs.builder()
            .tagTemplate(basicTagTemplate.name())
            .policyData(admin.applyValue(getIAMPolicyResult -> getIAMPolicyResult.policyData()))
            .build());

    }
}
```
```yaml
resources:
  policy:
    type: gcp:datacatalog:TagTemplateIamPolicy
    properties:
      tagTemplate: ${basicTagTemplate.name}
      policyData: ${admin.policyData}
variables:
  admin:
    fn::invoke:
      function: gcp:organizations:getIAMPolicy
      arguments:
        bindings:
          - role: roles/viewer
            members:
              - user:jane@example.com
```
<!--End PulumiCodeChooser -->

## gcp.datacatalog.TagTemplateIamBinding

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const binding = new gcp.datacatalog.TagTemplateIamBinding("binding", {
    tagTemplate: basicTagTemplate.name,
    role: "roles/viewer",
    members: ["user:jane@example.com"],
});
```
```python
import pulumi
import pulumi_gcp as gcp

binding = gcp.datacatalog.TagTemplateIamBinding("binding",
    tag_template=basic_tag_template["name"],
    role="roles/viewer",
    members=["user:jane@example.com"])
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var binding = new Gcp.DataCatalog.TagTemplateIamBinding("binding", new()
    {
        TagTemplate = basicTagTemplate.Name,
        Role = "roles/viewer",
        Members = new[]
        {
            "user:jane@example.com",
        },
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/datacatalog"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		_, err := datacatalog.NewTagTemplateIamBinding(ctx, "binding", &datacatalog.TagTemplateIamBindingArgs{
			TagTemplate: pulumi.Any(basicTagTemplate.Name),
			Role:        pulumi.String("roles/viewer"),
			Members: pulumi.StringArray{
				pulumi.String("user:jane@example.com"),
			},
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.datacatalog.TagTemplateIamBinding;
import com.pulumi.gcp.datacatalog.TagTemplateIamBindingArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        var binding = new TagTemplateIamBinding("binding", TagTemplateIamBindingArgs.builder()
            .tagTemplate(basicTagTemplate.name())
            .role("roles/viewer")
            .members("user:jane@example.com")
            .build());

    }
}
```
```yaml
resources:
  binding:
    type: gcp:datacatalog:TagTemplateIamBinding
    properties:
      tagTemplate: ${basicTagTemplate.name}
      role: roles/viewer
      members:
        - user:jane@example.com
```
<!--End PulumiCodeChooser -->

## gcp.datacatalog.TagTemplateIamMember

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const member = new gcp.datacatalog.TagTemplateIamMember("member", {
    tagTemplate: basicTagTemplate.name,
    role: "roles/viewer",
    member: "user:jane@example.com",
});
```
```python
import pulumi
import pulumi_gcp as gcp

member = gcp.datacatalog.TagTemplateIamMember("member",
    tag_template=basic_tag_template["name"],
    role="roles/viewer",
    member="user:jane@example.com")
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var member = new Gcp.DataCatalog.TagTemplateIamMember("member", new()
    {
        TagTemplate = basicTagTemplate.Name,
        Role = "roles/viewer",
        Member = "user:jane@example.com",
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/datacatalog"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		_, err := datacatalog.NewTagTemplateIamMember(ctx, "member", &datacatalog.TagTemplateIamMemberArgs{
			TagTemplate: pulumi.Any(basicTagTemplate.Name),
			Role:        pulumi.String("roles/viewer"),
			Member:      pulumi.String("user:jane@example.com"),
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.datacatalog.TagTemplateIamMember;
import com.pulumi.gcp.datacatalog.TagTemplateIamMemberArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        var member = new TagTemplateIamMember("member", TagTemplateIamMemberArgs.builder()
            .tagTemplate(basicTagTemplate.name())
            .role("roles/viewer")
            .member("user:jane@example.com")
            .build());

    }
}
```
```yaml
resources:
  member:
    type: gcp:datacatalog:TagTemplateIamMember
    properties:
      tagTemplate: ${basicTagTemplate.name}
      role: roles/viewer
      member: user:jane@example.com
```
<!--End PulumiCodeChooser -->

## Import

For all import syntaxes, the "resource in question" can take any of the following forms:

* projects/{{project}}/locations/{{region}}/tagTemplates/{{tag_template}}

* {{project}}/{{region}}/{{tag_template}}

* {{region}}/{{tag_template}}

* {{tag_template}}

Any variables not passed in the import command will be taken from the provider configuration.

Data catalog tagtemplate IAM resources can be imported using the resource identifiers, role, and member.

IAM member imports use space-delimited identifiers: the resource in question, the role, and the member identity, e.g.

```sh
$ pulumi import gcp:datacatalog/tagTemplateIamMember:TagTemplateIamMember editor "projects/{{project}}/locations/{{region}}/tagTemplates/{{tag_template}} roles/viewer user:jane@example.com"
```

IAM binding imports use space-delimited identifiers: the resource in question and the role, e.g.

```sh
$ pulumi import gcp:datacatalog/tagTemplateIamMember:TagTemplateIamMember editor "projects/{{project}}/locations/{{region}}/tagTemplates/{{tag_template}} roles/viewer"
```

IAM policy imports use the identifier of the resource in question, e.g.

```sh
$ pulumi import gcp:datacatalog/tagTemplateIamMember:TagTemplateIamMember editor projects/{{project}}/locations/{{region}}/tagTemplates/{{tag_template}}
```

-> **Custom Roles** If you're importing a IAM resource with a custom role, make sure to use the

 full name of the custom role, e.g. `[projects/my-project|organizations/my-org]/roles/my-custom-role`.


	conditionB}:{
y
datacatalogTagTemplateIamMemberConditionKgcp:datacatalog/TagTemplateIamMemberCondition:TagTemplateIamMemberConditionÓ	
member" Ä	Identities that will be granted the privilege in `role`.
Each entry can have one of the following values:
* **allUsers**: A special identifier that represents anyone who is on the internet; with or without a Google account.
* **allAuthenticatedUsers**: A special identifier that represents anyone who is authenticated with a Google account or a service account.
* **user:{emailid}**: An email address that represents a specific Google account. For example, alice@gmail.com or joe@example.com.
* **serviceAccount:{emailid}**: An email address that represents a service account. For example, my-other-app@appspot.gserviceaccount.com.
* **group:{emailid}**: An email address that represents a Google group. For example, admins@example.com.
* **domain:{domain}**: A G Suite domain (primary, instead of alias) name that represents all the users of that domain. For example, google.com or example.com.
* **projectOwner:projectid**: Owners of the given project. For example, "projectOwner:my-example-project"
* **projectEditor:projectid**: Editors of the given project. For example, "projectEditor:my-example-project"
* **projectViewer:projectid**: Viewers of the given project. For example, "projectViewer:my-example-project"

projectB" The ID of the project in which the resource belongs.
If it is not provided, the project will be parsed from the identifier of the parent resource. If no project is provided in the parent identifier and no project is specified, the provider project is used.

regionB" Þ
role" ÑThe role that should be applied. Only one
`gcp.datacatalog.TagTemplateIamBinding` can be used per role. Note that custom roles must be of the format
`[projects|organizations]/{parent-name}/roles/{role-name}`.
N
tagTemplate" ;Used to find the parent resource to bind the IAM policy to
"
	conditionB}:{
y
datacatalogTagTemplateIamMemberConditionKgcp:datacatalog/TagTemplateIamMemberCondition:TagTemplateIamMemberCondition"3
etag" '(Computed) The etag of the IAM policy.
"Ó	
member" Ä	Identities that will be granted the privilege in `role`.
Each entry can have one of the following values:
* **allUsers**: A special identifier that represents anyone who is on the internet; with or without a Google account.
* **allAuthenticatedUsers**: A special identifier that represents anyone who is authenticated with a Google account or a service account.
* **user:{emailid}**: An email address that represents a specific Google account. For example, alice@gmail.com or joe@example.com.
* **serviceAccount:{emailid}**: An email address that represents a service account. For example, my-other-app@appspot.gserviceaccount.com.
* **group:{emailid}**: An email address that represents a Google group. For example, admins@example.com.
* **domain:{domain}**: A G Suite domain (primary, instead of alias) name that represents all the users of that domain. For example, google.com or example.com.
* **projectOwner:projectid**: Owners of the given project. For example, "projectOwner:my-example-project"
* **projectEditor:projectid**: Editors of the given project. For example, "projectEditor:my-example-project"
* **projectViewer:projectid**: Viewers of the given project. For example, "projectViewer:my-example-project"
"
project" The ID of the project in which the resource belongs.
If it is not provided, the project will be parsed from the identifier of the parent resource. If no project is provided in the parent identifier and no project is specified, the provider project is used.
"
region" "Þ
role" ÑThe role that should be applied. Only one
`gcp.datacatalog.TagTemplateIamBinding` can be used per role. Note that custom roles must be of the format
`[projects|organizations]/{parent-name}/roles/{role-name}`.
"N
tagTemplate" ;Used to find the parent resource to bind the IAM policy to
*ðµ
^
datacatalogTagTemplateIamPolicy9gcp:datacatalog/tagTemplateIamPolicy:TagTemplateIamPolicy­­Three different resources help you manage your IAM policy for Data catalog TagTemplate. Each of these resources serves a different use case:

* `gcp.datacatalog.TagTemplateIamPolicy`: Authoritative. Sets the IAM policy for the tagtemplate and replaces any existing policy already attached.
* `gcp.datacatalog.TagTemplateIamBinding`: Authoritative for a given role. Updates the IAM policy to grant a role to a list of members. Other roles within the IAM policy for the tagtemplate are preserved.
* `gcp.datacatalog.TagTemplateIamMember`: Non-authoritative. Updates the IAM policy to grant a role to a new member. Other members for the role for the tagtemplate are preserved.

A data source can be used to retrieve policy data in advent you do not need creation

* `gcp.datacatalog.TagTemplateIamPolicy`: Retrieves the IAM policy for the tagtemplate

> **Note:** `gcp.datacatalog.TagTemplateIamPolicy` **cannot** be used in conjunction with `gcp.datacatalog.TagTemplateIamBinding` and `gcp.datacatalog.TagTemplateIamMember` or they will fight over what your policy should be.

> **Note:** `gcp.datacatalog.TagTemplateIamBinding` resources **can be** used in conjunction with `gcp.datacatalog.TagTemplateIamMember` resources **only if** they do not grant privilege to the same role.



## gcp.datacatalog.TagTemplateIamPolicy

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const admin = gcp.organizations.getIAMPolicy({
    bindings: [{
        role: "roles/viewer",
        members: ["user:jane@example.com"],
    }],
});
const policy = new gcp.datacatalog.TagTemplateIamPolicy("policy", {
    tagTemplate: basicTagTemplate.name,
    policyData: admin.then(admin => admin.policyData),
});
```
```python
import pulumi
import pulumi_gcp as gcp

admin = gcp.organizations.get_iam_policy(bindings=[{
    "role": "roles/viewer",
    "members": ["user:jane@example.com"],
}])
policy = gcp.datacatalog.TagTemplateIamPolicy("policy",
    tag_template=basic_tag_template["name"],
    policy_data=admin.policy_data)
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var admin = Gcp.Organizations.GetIAMPolicy.Invoke(new()
    {
        Bindings = new[]
        {
            new Gcp.Organizations.Inputs.GetIAMPolicyBindingInputArgs
            {
                Role = "roles/viewer",
                Members = new[]
                {
                    "user:jane@example.com",
                },
            },
        },
    });

    var policy = new Gcp.DataCatalog.TagTemplateIamPolicy("policy", new()
    {
        TagTemplate = basicTagTemplate.Name,
        PolicyData = admin.Apply(getIAMPolicyResult => getIAMPolicyResult.PolicyData),
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/datacatalog"
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/organizations"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		admin, err := organizations.LookupIAMPolicy(ctx, &organizations.LookupIAMPolicyArgs{
			Bindings: []organizations.GetIAMPolicyBinding{
				{
					Role: "roles/viewer",
					Members: []string{
						"user:jane@example.com",
					},
				},
			},
		}, nil)
		if err != nil {
			return err
		}
		_, err = datacatalog.NewTagTemplateIamPolicy(ctx, "policy", &datacatalog.TagTemplateIamPolicyArgs{
			TagTemplate: pulumi.Any(basicTagTemplate.Name),
			PolicyData:  pulumi.String(admin.PolicyData),
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.organizations.OrganizationsFunctions;
import com.pulumi.gcp.organizations.inputs.GetIAMPolicyArgs;
import com.pulumi.gcp.datacatalog.TagTemplateIamPolicy;
import com.pulumi.gcp.datacatalog.TagTemplateIamPolicyArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        final var admin = OrganizationsFunctions.getIAMPolicy(GetIAMPolicyArgs.builder()
            .bindings(GetIAMPolicyBindingArgs.builder()
                .role("roles/viewer")
                .members("user:jane@example.com")
                .build())
            .build());

        var policy = new TagTemplateIamPolicy("policy", TagTemplateIamPolicyArgs.builder()
            .tagTemplate(basicTagTemplate.name())
            .policyData(admin.applyValue(getIAMPolicyResult -> getIAMPolicyResult.policyData()))
            .build());

    }
}
```
```yaml
resources:
  policy:
    type: gcp:datacatalog:TagTemplateIamPolicy
    properties:
      tagTemplate: ${basicTagTemplate.name}
      policyData: ${admin.policyData}
variables:
  admin:
    fn::invoke:
      function: gcp:organizations:getIAMPolicy
      arguments:
        bindings:
          - role: roles/viewer
            members:
              - user:jane@example.com
```
<!--End PulumiCodeChooser -->

## gcp.datacatalog.TagTemplateIamBinding

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const binding = new gcp.datacatalog.TagTemplateIamBinding("binding", {
    tagTemplate: basicTagTemplate.name,
    role: "roles/viewer",
    members: ["user:jane@example.com"],
});
```
```python
import pulumi
import pulumi_gcp as gcp

binding = gcp.datacatalog.TagTemplateIamBinding("binding",
    tag_template=basic_tag_template["name"],
    role="roles/viewer",
    members=["user:jane@example.com"])
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var binding = new Gcp.DataCatalog.TagTemplateIamBinding("binding", new()
    {
        TagTemplate = basicTagTemplate.Name,
        Role = "roles/viewer",
        Members = new[]
        {
            "user:jane@example.com",
        },
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/datacatalog"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		_, err := datacatalog.NewTagTemplateIamBinding(ctx, "binding", &datacatalog.TagTemplateIamBindingArgs{
			TagTemplate: pulumi.Any(basicTagTemplate.Name),
			Role:        pulumi.String("roles/viewer"),
			Members: pulumi.StringArray{
				pulumi.String("user:jane@example.com"),
			},
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.datacatalog.TagTemplateIamBinding;
import com.pulumi.gcp.datacatalog.TagTemplateIamBindingArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        var binding = new TagTemplateIamBinding("binding", TagTemplateIamBindingArgs.builder()
            .tagTemplate(basicTagTemplate.name())
            .role("roles/viewer")
            .members("user:jane@example.com")
            .build());

    }
}
```
```yaml
resources:
  binding:
    type: gcp:datacatalog:TagTemplateIamBinding
    properties:
      tagTemplate: ${basicTagTemplate.name}
      role: roles/viewer
      members:
        - user:jane@example.com
```
<!--End PulumiCodeChooser -->

## gcp.datacatalog.TagTemplateIamMember

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const member = new gcp.datacatalog.TagTemplateIamMember("member", {
    tagTemplate: basicTagTemplate.name,
    role: "roles/viewer",
    member: "user:jane@example.com",
});
```
```python
import pulumi
import pulumi_gcp as gcp

member = gcp.datacatalog.TagTemplateIamMember("member",
    tag_template=basic_tag_template["name"],
    role="roles/viewer",
    member="user:jane@example.com")
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var member = new Gcp.DataCatalog.TagTemplateIamMember("member", new()
    {
        TagTemplate = basicTagTemplate.Name,
        Role = "roles/viewer",
        Member = "user:jane@example.com",
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/datacatalog"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		_, err := datacatalog.NewTagTemplateIamMember(ctx, "member", &datacatalog.TagTemplateIamMemberArgs{
			TagTemplate: pulumi.Any(basicTagTemplate.Name),
			Role:        pulumi.String("roles/viewer"),
			Member:      pulumi.String("user:jane@example.com"),
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.datacatalog.TagTemplateIamMember;
import com.pulumi.gcp.datacatalog.TagTemplateIamMemberArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        var member = new TagTemplateIamMember("member", TagTemplateIamMemberArgs.builder()
            .tagTemplate(basicTagTemplate.name())
            .role("roles/viewer")
            .member("user:jane@example.com")
            .build());

    }
}
```
```yaml
resources:
  member:
    type: gcp:datacatalog:TagTemplateIamMember
    properties:
      tagTemplate: ${basicTagTemplate.name}
      role: roles/viewer
      member: user:jane@example.com
```
<!--End PulumiCodeChooser -->


## This resource supports User Project Overrides.

-

# IAM policy for Data catalog TagTemplate
Three different resources help you manage your IAM policy for Data catalog TagTemplate. Each of these resources serves a different use case:

* `gcp.datacatalog.TagTemplateIamPolicy`: Authoritative. Sets the IAM policy for the tagtemplate and replaces any existing policy already attached.
* `gcp.datacatalog.TagTemplateIamBinding`: Authoritative for a given role. Updates the IAM policy to grant a role to a list of members. Other roles within the IAM policy for the tagtemplate are preserved.
* `gcp.datacatalog.TagTemplateIamMember`: Non-authoritative. Updates the IAM policy to grant a role to a new member. Other members for the role for the tagtemplate are preserved.

A data source can be used to retrieve policy data in advent you do not need creation

* `gcp.datacatalog.TagTemplateIamPolicy`: Retrieves the IAM policy for the tagtemplate

> **Note:** `gcp.datacatalog.TagTemplateIamPolicy` **cannot** be used in conjunction with `gcp.datacatalog.TagTemplateIamBinding` and `gcp.datacatalog.TagTemplateIamMember` or they will fight over what your policy should be.

> **Note:** `gcp.datacatalog.TagTemplateIamBinding` resources **can be** used in conjunction with `gcp.datacatalog.TagTemplateIamMember` resources **only if** they do not grant privilege to the same role.



## gcp.datacatalog.TagTemplateIamPolicy

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const admin = gcp.organizations.getIAMPolicy({
    bindings: [{
        role: "roles/viewer",
        members: ["user:jane@example.com"],
    }],
});
const policy = new gcp.datacatalog.TagTemplateIamPolicy("policy", {
    tagTemplate: basicTagTemplate.name,
    policyData: admin.then(admin => admin.policyData),
});
```
```python
import pulumi
import pulumi_gcp as gcp

admin = gcp.organizations.get_iam_policy(bindings=[{
    "role": "roles/viewer",
    "members": ["user:jane@example.com"],
}])
policy = gcp.datacatalog.TagTemplateIamPolicy("policy",
    tag_template=basic_tag_template["name"],
    policy_data=admin.policy_data)
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var admin = Gcp.Organizations.GetIAMPolicy.Invoke(new()
    {
        Bindings = new[]
        {
            new Gcp.Organizations.Inputs.GetIAMPolicyBindingInputArgs
            {
                Role = "roles/viewer",
                Members = new[]
                {
                    "user:jane@example.com",
                },
            },
        },
    });

    var policy = new Gcp.DataCatalog.TagTemplateIamPolicy("policy", new()
    {
        TagTemplate = basicTagTemplate.Name,
        PolicyData = admin.Apply(getIAMPolicyResult => getIAMPolicyResult.PolicyData),
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/datacatalog"
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/organizations"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		admin, err := organizations.LookupIAMPolicy(ctx, &organizations.LookupIAMPolicyArgs{
			Bindings: []organizations.GetIAMPolicyBinding{
				{
					Role: "roles/viewer",
					Members: []string{
						"user:jane@example.com",
					},
				},
			},
		}, nil)
		if err != nil {
			return err
		}
		_, err = datacatalog.NewTagTemplateIamPolicy(ctx, "policy", &datacatalog.TagTemplateIamPolicyArgs{
			TagTemplate: pulumi.Any(basicTagTemplate.Name),
			PolicyData:  pulumi.String(admin.PolicyData),
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.organizations.OrganizationsFunctions;
import com.pulumi.gcp.organizations.inputs.GetIAMPolicyArgs;
import com.pulumi.gcp.datacatalog.TagTemplateIamPolicy;
import com.pulumi.gcp.datacatalog.TagTemplateIamPolicyArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        final var admin = OrganizationsFunctions.getIAMPolicy(GetIAMPolicyArgs.builder()
            .bindings(GetIAMPolicyBindingArgs.builder()
                .role("roles/viewer")
                .members("user:jane@example.com")
                .build())
            .build());

        var policy = new TagTemplateIamPolicy("policy", TagTemplateIamPolicyArgs.builder()
            .tagTemplate(basicTagTemplate.name())
            .policyData(admin.applyValue(getIAMPolicyResult -> getIAMPolicyResult.policyData()))
            .build());

    }
}
```
```yaml
resources:
  policy:
    type: gcp:datacatalog:TagTemplateIamPolicy
    properties:
      tagTemplate: ${basicTagTemplate.name}
      policyData: ${admin.policyData}
variables:
  admin:
    fn::invoke:
      function: gcp:organizations:getIAMPolicy
      arguments:
        bindings:
          - role: roles/viewer
            members:
              - user:jane@example.com
```
<!--End PulumiCodeChooser -->

## gcp.datacatalog.TagTemplateIamBinding

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const binding = new gcp.datacatalog.TagTemplateIamBinding("binding", {
    tagTemplate: basicTagTemplate.name,
    role: "roles/viewer",
    members: ["user:jane@example.com"],
});
```
```python
import pulumi
import pulumi_gcp as gcp

binding = gcp.datacatalog.TagTemplateIamBinding("binding",
    tag_template=basic_tag_template["name"],
    role="roles/viewer",
    members=["user:jane@example.com"])
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var binding = new Gcp.DataCatalog.TagTemplateIamBinding("binding", new()
    {
        TagTemplate = basicTagTemplate.Name,
        Role = "roles/viewer",
        Members = new[]
        {
            "user:jane@example.com",
        },
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/datacatalog"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		_, err := datacatalog.NewTagTemplateIamBinding(ctx, "binding", &datacatalog.TagTemplateIamBindingArgs{
			TagTemplate: pulumi.Any(basicTagTemplate.Name),
			Role:        pulumi.String("roles/viewer"),
			Members: pulumi.StringArray{
				pulumi.String("user:jane@example.com"),
			},
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.datacatalog.TagTemplateIamBinding;
import com.pulumi.gcp.datacatalog.TagTemplateIamBindingArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        var binding = new TagTemplateIamBinding("binding", TagTemplateIamBindingArgs.builder()
            .tagTemplate(basicTagTemplate.name())
            .role("roles/viewer")
            .members("user:jane@example.com")
            .build());

    }
}
```
```yaml
resources:
  binding:
    type: gcp:datacatalog:TagTemplateIamBinding
    properties:
      tagTemplate: ${basicTagTemplate.name}
      role: roles/viewer
      members:
        - user:jane@example.com
```
<!--End PulumiCodeChooser -->

## gcp.datacatalog.TagTemplateIamMember

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const member = new gcp.datacatalog.TagTemplateIamMember("member", {
    tagTemplate: basicTagTemplate.name,
    role: "roles/viewer",
    member: "user:jane@example.com",
});
```
```python
import pulumi
import pulumi_gcp as gcp

member = gcp.datacatalog.TagTemplateIamMember("member",
    tag_template=basic_tag_template["name"],
    role="roles/viewer",
    member="user:jane@example.com")
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var member = new Gcp.DataCatalog.TagTemplateIamMember("member", new()
    {
        TagTemplate = basicTagTemplate.Name,
        Role = "roles/viewer",
        Member = "user:jane@example.com",
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/datacatalog"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		_, err := datacatalog.NewTagTemplateIamMember(ctx, "member", &datacatalog.TagTemplateIamMemberArgs{
			TagTemplate: pulumi.Any(basicTagTemplate.Name),
			Role:        pulumi.String("roles/viewer"),
			Member:      pulumi.String("user:jane@example.com"),
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.datacatalog.TagTemplateIamMember;
import com.pulumi.gcp.datacatalog.TagTemplateIamMemberArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        var member = new TagTemplateIamMember("member", TagTemplateIamMemberArgs.builder()
            .tagTemplate(basicTagTemplate.name())
            .role("roles/viewer")
            .member("user:jane@example.com")
            .build());

    }
}
```
```yaml
resources:
  member:
    type: gcp:datacatalog:TagTemplateIamMember
    properties:
      tagTemplate: ${basicTagTemplate.name}
      role: roles/viewer
      member: user:jane@example.com
```
<!--End PulumiCodeChooser -->

## Import

For all import syntaxes, the "resource in question" can take any of the following forms:

* projects/{{project}}/locations/{{region}}/tagTemplates/{{tag_template}}

* {{project}}/{{region}}/{{tag_template}}

* {{region}}/{{tag_template}}

* {{tag_template}}

Any variables not passed in the import command will be taken from the provider configuration.

Data catalog tagtemplate IAM resources can be imported using the resource identifiers, role, and member.

IAM member imports use space-delimited identifiers: the resource in question, the role, and the member identity, e.g.

```sh
$ pulumi import gcp:datacatalog/tagTemplateIamPolicy:TagTemplateIamPolicy editor "projects/{{project}}/locations/{{region}}/tagTemplates/{{tag_template}} roles/viewer user:jane@example.com"
```

IAM binding imports use space-delimited identifiers: the resource in question and the role, e.g.

```sh
$ pulumi import gcp:datacatalog/tagTemplateIamPolicy:TagTemplateIamPolicy editor "projects/{{project}}/locations/{{region}}/tagTemplates/{{tag_template}} roles/viewer"
```

IAM policy imports use the identifier of the resource in question, e.g.

```sh
$ pulumi import gcp:datacatalog/tagTemplateIamPolicy:TagTemplateIamPolicy editor projects/{{project}}/locations/{{region}}/tagTemplates/{{tag_template}}
```

-> **Custom Roles** If you're importing a IAM resource with a custom role, make sure to use the

 full name of the custom role, e.g. `[projects/my-project|organizations/my-org]/roles/my-custom-role`.

_

policyData" MThe policy data generated by
a `gcp.organizations.getIAMPolicy` data source.

projectB" The ID of the project in which the resource belongs.
If it is not provided, the project will be parsed from the identifier of the parent resource. If no project is provided in the parent identifier and no project is specified, the provider project is used.

regionB" N
tagTemplate" ;Used to find the parent resource to bind the IAM policy to
"3
etag" '(Computed) The etag of the IAM policy.
"_

policyData" MThe policy data generated by
a `gcp.organizations.getIAMPolicy` data source.
"
project" The ID of the project in which the resource belongs.
If it is not provided, the project will be parsed from the identifier of the parent resource. If no project is provided in the parent identifier and no project is specified, the provider project is used.
"
region" "N
tagTemplate" ;Used to find the parent resource to bind the IAM policy to
*ò)
:
datacatalogTaxonomy!gcp:datacatalog/taxonomy:TaxonomyóA collection of policy tags that classify data along a common axis.


To get more information about Taxonomy, see:

* [API documentation](https://cloud.google.com/data-catalog/docs/reference/rest/v1/projects.locations.taxonomies)
* How-to Guides
    * [Official Documentation](https://cloud.google.com/data-catalog/docs)

## Example Usage

### Data Catalog Taxonomy Basic


<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const basicTaxonomy = new gcp.datacatalog.Taxonomy("basic_taxonomy", {
    displayName: "my_taxonomy",
    description: "A collection of policy tags",
    activatedPolicyTypes: ["FINE_GRAINED_ACCESS_CONTROL"],
});
```
```python
import pulumi
import pulumi_gcp as gcp

basic_taxonomy = gcp.datacatalog.Taxonomy("basic_taxonomy",
    display_name="my_taxonomy",
    description="A collection of policy tags",
    activated_policy_types=["FINE_GRAINED_ACCESS_CONTROL"])
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var basicTaxonomy = new Gcp.DataCatalog.Taxonomy("basic_taxonomy", new()
    {
        DisplayName = "my_taxonomy",
        Description = "A collection of policy tags",
        ActivatedPolicyTypes = new[]
        {
            "FINE_GRAINED_ACCESS_CONTROL",
        },
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/datacatalog"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		_, err := datacatalog.NewTaxonomy(ctx, "basic_taxonomy", &datacatalog.TaxonomyArgs{
			DisplayName: pulumi.String("my_taxonomy"),
			Description: pulumi.String("A collection of policy tags"),
			ActivatedPolicyTypes: pulumi.StringArray{
				pulumi.String("FINE_GRAINED_ACCESS_CONTROL"),
			},
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.datacatalog.Taxonomy;
import com.pulumi.gcp.datacatalog.TaxonomyArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        var basicTaxonomy = new Taxonomy("basicTaxonomy", TaxonomyArgs.builder()
            .displayName("my_taxonomy")
            .description("A collection of policy tags")
            .activatedPolicyTypes("FINE_GRAINED_ACCESS_CONTROL")
            .build());

    }
}
```
```yaml
resources:
  basicTaxonomy:
    type: gcp:datacatalog:Taxonomy
    name: basic_taxonomy
    properties:
      displayName: my_taxonomy
      description: A collection of policy tags
      activatedPolicyTypes:
        - FINE_GRAINED_ACCESS_CONTROL
```
<!--End PulumiCodeChooser -->

## Import

Taxonomy can be imported using any of these accepted formats:

* `{{name}}`

When using the `pulumi import` command, Taxonomy can be imported using one of the formats above. For example:

```sh
$ pulumi import gcp:datacatalog/taxonomy:Taxonomy default {{name}}
```

Ù
activatedPolicyTypesB*" ¸A list of policy types that are activated for this taxonomy. If not set,
defaults to an empty list.
Each value may be one of: `POLICY_TYPE_UNSPECIFIED`, `FINE_GRAINED_ACCESS_CONTROL`.
ô
descriptionB" ÞDescription of this taxonomy. It must: contain only unicode characters,
tabs, newlines, carriage returns and page breaks; and be at most 2000 bytes
long when encoded in UTF-8. If not set, defaults to an empty description.
¤
displayName" User defined name of this taxonomy.
The taxonomy display name must be unique within an organization.
It must: contain only unicode letters, numbers, underscores, dashes
and spaces; not start or end with spaces; and be at most 200 bytes
long when encoded in UTF-8.


- - -
{
projectB" jThe ID of the project in which the resource belongs.
If it is not provided, the provider project is used.
*
regionB" Taxonomy location region.
"Ù
activatedPolicyTypesB*" ¸A list of policy types that are activated for this taxonomy. If not set,
defaults to an empty list.
Each value may be one of: `POLICY_TYPE_UNSPECIFIED`, `FINE_GRAINED_ACCESS_CONTROL`.
"ô
descriptionB" ÞDescription of this taxonomy. It must: contain only unicode characters,
tabs, newlines, carriage returns and page breaks; and be at most 2000 bytes
long when encoded in UTF-8. If not set, defaults to an empty description.
"¤
displayName" User defined name of this taxonomy.
The taxonomy display name must be unique within an organization.
It must: contain only unicode letters, numbers, underscores, dashes
and spaces; not start or end with spaces; and be at most 200 bytes
long when encoded in UTF-8.


- - -
"|
name" pResource name of this taxonomy, whose format is:
"projects/{project}/locations/{region}/taxonomies/{taxonomy}".
"y
project" jThe ID of the project in which the resource belongs.
If it is not provided, the provider project is used.
"(
region" Taxonomy location region.
*ÞÈ
X
datacatalogTaxonomyIamBinding5gcp:datacatalog/taxonomyIamBinding:TaxonomyIamBindingé¨Three different resources help you manage your IAM policy for Data catalog Taxonomy. Each of these resources serves a different use case:

* `gcp.datacatalog.TaxonomyIamPolicy`: Authoritative. Sets the IAM policy for the taxonomy and replaces any existing policy already attached.
* `gcp.datacatalog.TaxonomyIamBinding`: Authoritative for a given role. Updates the IAM policy to grant a role to a list of members. Other roles within the IAM policy for the taxonomy are preserved.
* `gcp.datacatalog.TaxonomyIamMember`: Non-authoritative. Updates the IAM policy to grant a role to a new member. Other members for the role for the taxonomy are preserved.

A data source can be used to retrieve policy data in advent you do not need creation

* `gcp.datacatalog.TaxonomyIamPolicy`: Retrieves the IAM policy for the taxonomy

> **Note:** `gcp.datacatalog.TaxonomyIamPolicy` **cannot** be used in conjunction with `gcp.datacatalog.TaxonomyIamBinding` and `gcp.datacatalog.TaxonomyIamMember` or they will fight over what your policy should be.

> **Note:** `gcp.datacatalog.TaxonomyIamBinding` resources **can be** used in conjunction with `gcp.datacatalog.TaxonomyIamMember` resources **only if** they do not grant privilege to the same role.



## gcp.datacatalog.TaxonomyIamPolicy

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const admin = gcp.organizations.getIAMPolicy({
    bindings: [{
        role: "roles/viewer",
        members: ["user:jane@example.com"],
    }],
});
const policy = new gcp.datacatalog.TaxonomyIamPolicy("policy", {
    taxonomy: basicTaxonomy.name,
    policyData: admin.then(admin => admin.policyData),
});
```
```python
import pulumi
import pulumi_gcp as gcp

admin = gcp.organizations.get_iam_policy(bindings=[{
    "role": "roles/viewer",
    "members": ["user:jane@example.com"],
}])
policy = gcp.datacatalog.TaxonomyIamPolicy("policy",
    taxonomy=basic_taxonomy["name"],
    policy_data=admin.policy_data)
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var admin = Gcp.Organizations.GetIAMPolicy.Invoke(new()
    {
        Bindings = new[]
        {
            new Gcp.Organizations.Inputs.GetIAMPolicyBindingInputArgs
            {
                Role = "roles/viewer",
                Members = new[]
                {
                    "user:jane@example.com",
                },
            },
        },
    });

    var policy = new Gcp.DataCatalog.TaxonomyIamPolicy("policy", new()
    {
        Taxonomy = basicTaxonomy.Name,
        PolicyData = admin.Apply(getIAMPolicyResult => getIAMPolicyResult.PolicyData),
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/datacatalog"
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/organizations"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		admin, err := organizations.LookupIAMPolicy(ctx, &organizations.LookupIAMPolicyArgs{
			Bindings: []organizations.GetIAMPolicyBinding{
				{
					Role: "roles/viewer",
					Members: []string{
						"user:jane@example.com",
					},
				},
			},
		}, nil)
		if err != nil {
			return err
		}
		_, err = datacatalog.NewTaxonomyIamPolicy(ctx, "policy", &datacatalog.TaxonomyIamPolicyArgs{
			Taxonomy:   pulumi.Any(basicTaxonomy.Name),
			PolicyData: pulumi.String(admin.PolicyData),
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.organizations.OrganizationsFunctions;
import com.pulumi.gcp.organizations.inputs.GetIAMPolicyArgs;
import com.pulumi.gcp.datacatalog.TaxonomyIamPolicy;
import com.pulumi.gcp.datacatalog.TaxonomyIamPolicyArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        final var admin = OrganizationsFunctions.getIAMPolicy(GetIAMPolicyArgs.builder()
            .bindings(GetIAMPolicyBindingArgs.builder()
                .role("roles/viewer")
                .members("user:jane@example.com")
                .build())
            .build());

        var policy = new TaxonomyIamPolicy("policy", TaxonomyIamPolicyArgs.builder()
            .taxonomy(basicTaxonomy.name())
            .policyData(admin.applyValue(getIAMPolicyResult -> getIAMPolicyResult.policyData()))
            .build());

    }
}
```
```yaml
resources:
  policy:
    type: gcp:datacatalog:TaxonomyIamPolicy
    properties:
      taxonomy: ${basicTaxonomy.name}
      policyData: ${admin.policyData}
variables:
  admin:
    fn::invoke:
      function: gcp:organizations:getIAMPolicy
      arguments:
        bindings:
          - role: roles/viewer
            members:
              - user:jane@example.com
```
<!--End PulumiCodeChooser -->

## gcp.datacatalog.TaxonomyIamBinding

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const binding = new gcp.datacatalog.TaxonomyIamBinding("binding", {
    taxonomy: basicTaxonomy.name,
    role: "roles/viewer",
    members: ["user:jane@example.com"],
});
```
```python
import pulumi
import pulumi_gcp as gcp

binding = gcp.datacatalog.TaxonomyIamBinding("binding",
    taxonomy=basic_taxonomy["name"],
    role="roles/viewer",
    members=["user:jane@example.com"])
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var binding = new Gcp.DataCatalog.TaxonomyIamBinding("binding", new()
    {
        Taxonomy = basicTaxonomy.Name,
        Role = "roles/viewer",
        Members = new[]
        {
            "user:jane@example.com",
        },
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/datacatalog"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		_, err := datacatalog.NewTaxonomyIamBinding(ctx, "binding", &datacatalog.TaxonomyIamBindingArgs{
			Taxonomy: pulumi.Any(basicTaxonomy.Name),
			Role:     pulumi.String("roles/viewer"),
			Members: pulumi.StringArray{
				pulumi.String("user:jane@example.com"),
			},
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.datacatalog.TaxonomyIamBinding;
import com.pulumi.gcp.datacatalog.TaxonomyIamBindingArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        var binding = new TaxonomyIamBinding("binding", TaxonomyIamBindingArgs.builder()
            .taxonomy(basicTaxonomy.name())
            .role("roles/viewer")
            .members("user:jane@example.com")
            .build());

    }
}
```
```yaml
resources:
  binding:
    type: gcp:datacatalog:TaxonomyIamBinding
    properties:
      taxonomy: ${basicTaxonomy.name}
      role: roles/viewer
      members:
        - user:jane@example.com
```
<!--End PulumiCodeChooser -->

## gcp.datacatalog.TaxonomyIamMember

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const member = new gcp.datacatalog.TaxonomyIamMember("member", {
    taxonomy: basicTaxonomy.name,
    role: "roles/viewer",
    member: "user:jane@example.com",
});
```
```python
import pulumi
import pulumi_gcp as gcp

member = gcp.datacatalog.TaxonomyIamMember("member",
    taxonomy=basic_taxonomy["name"],
    role="roles/viewer",
    member="user:jane@example.com")
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var member = new Gcp.DataCatalog.TaxonomyIamMember("member", new()
    {
        Taxonomy = basicTaxonomy.Name,
        Role = "roles/viewer",
        Member = "user:jane@example.com",
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/datacatalog"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		_, err := datacatalog.NewTaxonomyIamMember(ctx, "member", &datacatalog.TaxonomyIamMemberArgs{
			Taxonomy: pulumi.Any(basicTaxonomy.Name),
			Role:     pulumi.String("roles/viewer"),
			Member:   pulumi.String("user:jane@example.com"),
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.datacatalog.TaxonomyIamMember;
import com.pulumi.gcp.datacatalog.TaxonomyIamMemberArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        var member = new TaxonomyIamMember("member", TaxonomyIamMemberArgs.builder()
            .taxonomy(basicTaxonomy.name())
            .role("roles/viewer")
            .member("user:jane@example.com")
            .build());

    }
}
```
```yaml
resources:
  member:
    type: gcp:datacatalog:TaxonomyIamMember
    properties:
      taxonomy: ${basicTaxonomy.name}
      role: roles/viewer
      member: user:jane@example.com
```
<!--End PulumiCodeChooser -->


## This resource supports User Project Overrides.

-

# IAM policy for Data catalog Taxonomy
Three different resources help you manage your IAM policy for Data catalog Taxonomy. Each of these resources serves a different use case:

* `gcp.datacatalog.TaxonomyIamPolicy`: Authoritative. Sets the IAM policy for the taxonomy and replaces any existing policy already attached.
* `gcp.datacatalog.TaxonomyIamBinding`: Authoritative for a given role. Updates the IAM policy to grant a role to a list of members. Other roles within the IAM policy for the taxonomy are preserved.
* `gcp.datacatalog.TaxonomyIamMember`: Non-authoritative. Updates the IAM policy to grant a role to a new member. Other members for the role for the taxonomy are preserved.

A data source can be used to retrieve policy data in advent you do not need creation

* `gcp.datacatalog.TaxonomyIamPolicy`: Retrieves the IAM policy for the taxonomy

> **Note:** `gcp.datacatalog.TaxonomyIamPolicy` **cannot** be used in conjunction with `gcp.datacatalog.TaxonomyIamBinding` and `gcp.datacatalog.TaxonomyIamMember` or they will fight over what your policy should be.

> **Note:** `gcp.datacatalog.TaxonomyIamBinding` resources **can be** used in conjunction with `gcp.datacatalog.TaxonomyIamMember` resources **only if** they do not grant privilege to the same role.



## gcp.datacatalog.TaxonomyIamPolicy

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const admin = gcp.organizations.getIAMPolicy({
    bindings: [{
        role: "roles/viewer",
        members: ["user:jane@example.com"],
    }],
});
const policy = new gcp.datacatalog.TaxonomyIamPolicy("policy", {
    taxonomy: basicTaxonomy.name,
    policyData: admin.then(admin => admin.policyData),
});
```
```python
import pulumi
import pulumi_gcp as gcp

admin = gcp.organizations.get_iam_policy(bindings=[{
    "role": "roles/viewer",
    "members": ["user:jane@example.com"],
}])
policy = gcp.datacatalog.TaxonomyIamPolicy("policy",
    taxonomy=basic_taxonomy["name"],
    policy_data=admin.policy_data)
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var admin = Gcp.Organizations.GetIAMPolicy.Invoke(new()
    {
        Bindings = new[]
        {
            new Gcp.Organizations.Inputs.GetIAMPolicyBindingInputArgs
            {
                Role = "roles/viewer",
                Members = new[]
                {
                    "user:jane@example.com",
                },
            },
        },
    });

    var policy = new Gcp.DataCatalog.TaxonomyIamPolicy("policy", new()
    {
        Taxonomy = basicTaxonomy.Name,
        PolicyData = admin.Apply(getIAMPolicyResult => getIAMPolicyResult.PolicyData),
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/datacatalog"
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/organizations"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		admin, err := organizations.LookupIAMPolicy(ctx, &organizations.LookupIAMPolicyArgs{
			Bindings: []organizations.GetIAMPolicyBinding{
				{
					Role: "roles/viewer",
					Members: []string{
						"user:jane@example.com",
					},
				},
			},
		}, nil)
		if err != nil {
			return err
		}
		_, err = datacatalog.NewTaxonomyIamPolicy(ctx, "policy", &datacatalog.TaxonomyIamPolicyArgs{
			Taxonomy:   pulumi.Any(basicTaxonomy.Name),
			PolicyData: pulumi.String(admin.PolicyData),
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.organizations.OrganizationsFunctions;
import com.pulumi.gcp.organizations.inputs.GetIAMPolicyArgs;
import com.pulumi.gcp.datacatalog.TaxonomyIamPolicy;
import com.pulumi.gcp.datacatalog.TaxonomyIamPolicyArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        final var admin = OrganizationsFunctions.getIAMPolicy(GetIAMPolicyArgs.builder()
            .bindings(GetIAMPolicyBindingArgs.builder()
                .role("roles/viewer")
                .members("user:jane@example.com")
                .build())
            .build());

        var policy = new TaxonomyIamPolicy("policy", TaxonomyIamPolicyArgs.builder()
            .taxonomy(basicTaxonomy.name())
            .policyData(admin.applyValue(getIAMPolicyResult -> getIAMPolicyResult.policyData()))
            .build());

    }
}
```
```yaml
resources:
  policy:
    type: gcp:datacatalog:TaxonomyIamPolicy
    properties:
      taxonomy: ${basicTaxonomy.name}
      policyData: ${admin.policyData}
variables:
  admin:
    fn::invoke:
      function: gcp:organizations:getIAMPolicy
      arguments:
        bindings:
          - role: roles/viewer
            members:
              - user:jane@example.com
```
<!--End PulumiCodeChooser -->

## gcp.datacatalog.TaxonomyIamBinding

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const binding = new gcp.datacatalog.TaxonomyIamBinding("binding", {
    taxonomy: basicTaxonomy.name,
    role: "roles/viewer",
    members: ["user:jane@example.com"],
});
```
```python
import pulumi
import pulumi_gcp as gcp

binding = gcp.datacatalog.TaxonomyIamBinding("binding",
    taxonomy=basic_taxonomy["name"],
    role="roles/viewer",
    members=["user:jane@example.com"])
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var binding = new Gcp.DataCatalog.TaxonomyIamBinding("binding", new()
    {
        Taxonomy = basicTaxonomy.Name,
        Role = "roles/viewer",
        Members = new[]
        {
            "user:jane@example.com",
        },
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/datacatalog"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		_, err := datacatalog.NewTaxonomyIamBinding(ctx, "binding", &datacatalog.TaxonomyIamBindingArgs{
			Taxonomy: pulumi.Any(basicTaxonomy.Name),
			Role:     pulumi.String("roles/viewer"),
			Members: pulumi.StringArray{
				pulumi.String("user:jane@example.com"),
			},
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.datacatalog.TaxonomyIamBinding;
import com.pulumi.gcp.datacatalog.TaxonomyIamBindingArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        var binding = new TaxonomyIamBinding("binding", TaxonomyIamBindingArgs.builder()
            .taxonomy(basicTaxonomy.name())
            .role("roles/viewer")
            .members("user:jane@example.com")
            .build());

    }
}
```
```yaml
resources:
  binding:
    type: gcp:datacatalog:TaxonomyIamBinding
    properties:
      taxonomy: ${basicTaxonomy.name}
      role: roles/viewer
      members:
        - user:jane@example.com
```
<!--End PulumiCodeChooser -->

## gcp.datacatalog.TaxonomyIamMember

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const member = new gcp.datacatalog.TaxonomyIamMember("member", {
    taxonomy: basicTaxonomy.name,
    role: "roles/viewer",
    member: "user:jane@example.com",
});
```
```python
import pulumi
import pulumi_gcp as gcp

member = gcp.datacatalog.TaxonomyIamMember("member",
    taxonomy=basic_taxonomy["name"],
    role="roles/viewer",
    member="user:jane@example.com")
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var member = new Gcp.DataCatalog.TaxonomyIamMember("member", new()
    {
        Taxonomy = basicTaxonomy.Name,
        Role = "roles/viewer",
        Member = "user:jane@example.com",
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/datacatalog"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		_, err := datacatalog.NewTaxonomyIamMember(ctx, "member", &datacatalog.TaxonomyIamMemberArgs{
			Taxonomy: pulumi.Any(basicTaxonomy.Name),
			Role:     pulumi.String("roles/viewer"),
			Member:   pulumi.String("user:jane@example.com"),
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.datacatalog.TaxonomyIamMember;
import com.pulumi.gcp.datacatalog.TaxonomyIamMemberArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        var member = new TaxonomyIamMember("member", TaxonomyIamMemberArgs.builder()
            .taxonomy(basicTaxonomy.name())
            .role("roles/viewer")
            .member("user:jane@example.com")
            .build());

    }
}
```
```yaml
resources:
  member:
    type: gcp:datacatalog:TaxonomyIamMember
    properties:
      taxonomy: ${basicTaxonomy.name}
      role: roles/viewer
      member: user:jane@example.com
```
<!--End PulumiCodeChooser -->

## Import

For all import syntaxes, the "resource in question" can take any of the following forms:

* projects/{{project}}/locations/{{region}}/taxonomies/{{taxonomy}}

* {{project}}/{{region}}/{{taxonomy}}

* {{region}}/{{taxonomy}}

* {{taxonomy}}

Any variables not passed in the import command will be taken from the provider configuration.

Data catalog taxonomy IAM resources can be imported using the resource identifiers, role, and member.

IAM member imports use space-delimited identifiers: the resource in question, the role, and the member identity, e.g.

```sh
$ pulumi import gcp:datacatalog/taxonomyIamBinding:TaxonomyIamBinding editor "projects/{{project}}/locations/{{region}}/taxonomies/{{taxonomy}} roles/viewer user:jane@example.com"
```

IAM binding imports use space-delimited identifiers: the resource in question and the role, e.g.

```sh
$ pulumi import gcp:datacatalog/taxonomyIamBinding:TaxonomyIamBinding editor "projects/{{project}}/locations/{{region}}/taxonomies/{{taxonomy}} roles/viewer"
```

IAM policy imports use the identifier of the resource in question, e.g.

```sh
$ pulumi import gcp:datacatalog/taxonomyIamBinding:TaxonomyIamBinding editor projects/{{project}}/locations/{{region}}/taxonomies/{{taxonomy}}
```

-> **Custom Roles** If you're importing a IAM resource with a custom role, make sure to use the

 full name of the custom role, e.g. `[projects/my-project|organizations/my-org]/roles/my-custom-role`.


	conditionyBw:u
s
datacatalogTaxonomyIamBindingConditionGgcp:datacatalog/TaxonomyIamBindingCondition:TaxonomyIamBindingConditionÖ	
members*" Ä	Identities that will be granted the privilege in `role`.
Each entry can have one of the following values:
* **allUsers**: A special identifier that represents anyone who is on the internet; with or without a Google account.
* **allAuthenticatedUsers**: A special identifier that represents anyone who is authenticated with a Google account or a service account.
* **user:{emailid}**: An email address that represents a specific Google account. For example, alice@gmail.com or joe@example.com.
* **serviceAccount:{emailid}**: An email address that represents a service account. For example, my-other-app@appspot.gserviceaccount.com.
* **group:{emailid}**: An email address that represents a Google group. For example, admins@example.com.
* **domain:{domain}**: A G Suite domain (primary, instead of alias) name that represents all the users of that domain. For example, google.com or example.com.
* **projectOwner:projectid**: Owners of the given project. For example, "projectOwner:my-example-project"
* **projectEditor:projectid**: Editors of the given project. For example, "projectEditor:my-example-project"
* **projectViewer:projectid**: Viewers of the given project. For example, "projectViewer:my-example-project"

projectB" The ID of the project in which the resource belongs.
If it is not provided, the project will be parsed from the identifier of the parent resource. If no project is provided in the parent identifier and no project is specified, the provider project is used.

regionB" Û
role" ÎThe role that should be applied. Only one
`gcp.datacatalog.TaxonomyIamBinding` can be used per role. Note that custom roles must be of the format
`[projects|organizations]/{parent-name}/roles/{role-name}`.
K
taxonomy" ;Used to find the parent resource to bind the IAM policy to
"
	conditionyBw:u
s
datacatalogTaxonomyIamBindingConditionGgcp:datacatalog/TaxonomyIamBindingCondition:TaxonomyIamBindingCondition"3
etag" '(Computed) The etag of the IAM policy.
"Ö	
members*" Ä	Identities that will be granted the privilege in `role`.
Each entry can have one of the following values:
* **allUsers**: A special identifier that represents anyone who is on the internet; with or without a Google account.
* **allAuthenticatedUsers**: A special identifier that represents anyone who is authenticated with a Google account or a service account.
* **user:{emailid}**: An email address that represents a specific Google account. For example, alice@gmail.com or joe@example.com.
* **serviceAccount:{emailid}**: An email address that represents a service account. For example, my-other-app@appspot.gserviceaccount.com.
* **group:{emailid}**: An email address that represents a Google group. For example, admins@example.com.
* **domain:{domain}**: A G Suite domain (primary, instead of alias) name that represents all the users of that domain. For example, google.com or example.com.
* **projectOwner:projectid**: Owners of the given project. For example, "projectOwner:my-example-project"
* **projectEditor:projectid**: Editors of the given project. For example, "projectEditor:my-example-project"
* **projectViewer:projectid**: Viewers of the given project. For example, "projectViewer:my-example-project"
"
project" The ID of the project in which the resource belongs.
If it is not provided, the project will be parsed from the identifier of the parent resource. If no project is provided in the parent identifier and no project is specified, the provider project is used.
"
region" "Û
role" ÎThe role that should be applied. Only one
`gcp.datacatalog.TaxonomyIamBinding` can be used per role. Note that custom roles must be of the format
`[projects|organizations]/{parent-name}/roles/{role-name}`.
"K
taxonomy" ;Used to find the parent resource to bind the IAM policy to
*ÉÈ
U
datacatalogTaxonomyIamMember3gcp:datacatalog/taxonomyIamMember:TaxonomyIamMemberã¨Three different resources help you manage your IAM policy for Data catalog Taxonomy. Each of these resources serves a different use case:

* `gcp.datacatalog.TaxonomyIamPolicy`: Authoritative. Sets the IAM policy for the taxonomy and replaces any existing policy already attached.
* `gcp.datacatalog.TaxonomyIamBinding`: Authoritative for a given role. Updates the IAM policy to grant a role to a list of members. Other roles within the IAM policy for the taxonomy are preserved.
* `gcp.datacatalog.TaxonomyIamMember`: Non-authoritative. Updates the IAM policy to grant a role to a new member. Other members for the role for the taxonomy are preserved.

A data source can be used to retrieve policy data in advent you do not need creation

* `gcp.datacatalog.TaxonomyIamPolicy`: Retrieves the IAM policy for the taxonomy

> **Note:** `gcp.datacatalog.TaxonomyIamPolicy` **cannot** be used in conjunction with `gcp.datacatalog.TaxonomyIamBinding` and `gcp.datacatalog.TaxonomyIamMember` or they will fight over what your policy should be.

> **Note:** `gcp.datacatalog.TaxonomyIamBinding` resources **can be** used in conjunction with `gcp.datacatalog.TaxonomyIamMember` resources **only if** they do not grant privilege to the same role.



## gcp.datacatalog.TaxonomyIamPolicy

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const admin = gcp.organizations.getIAMPolicy({
    bindings: [{
        role: "roles/viewer",
        members: ["user:jane@example.com"],
    }],
});
const policy = new gcp.datacatalog.TaxonomyIamPolicy("policy", {
    taxonomy: basicTaxonomy.name,
    policyData: admin.then(admin => admin.policyData),
});
```
```python
import pulumi
import pulumi_gcp as gcp

admin = gcp.organizations.get_iam_policy(bindings=[{
    "role": "roles/viewer",
    "members": ["user:jane@example.com"],
}])
policy = gcp.datacatalog.TaxonomyIamPolicy("policy",
    taxonomy=basic_taxonomy["name"],
    policy_data=admin.policy_data)
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var admin = Gcp.Organizations.GetIAMPolicy.Invoke(new()
    {
        Bindings = new[]
        {
            new Gcp.Organizations.Inputs.GetIAMPolicyBindingInputArgs
            {
                Role = "roles/viewer",
                Members = new[]
                {
                    "user:jane@example.com",
                },
            },
        },
    });

    var policy = new Gcp.DataCatalog.TaxonomyIamPolicy("policy", new()
    {
        Taxonomy = basicTaxonomy.Name,
        PolicyData = admin.Apply(getIAMPolicyResult => getIAMPolicyResult.PolicyData),
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/datacatalog"
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/organizations"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		admin, err := organizations.LookupIAMPolicy(ctx, &organizations.LookupIAMPolicyArgs{
			Bindings: []organizations.GetIAMPolicyBinding{
				{
					Role: "roles/viewer",
					Members: []string{
						"user:jane@example.com",
					},
				},
			},
		}, nil)
		if err != nil {
			return err
		}
		_, err = datacatalog.NewTaxonomyIamPolicy(ctx, "policy", &datacatalog.TaxonomyIamPolicyArgs{
			Taxonomy:   pulumi.Any(basicTaxonomy.Name),
			PolicyData: pulumi.String(admin.PolicyData),
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.organizations.OrganizationsFunctions;
import com.pulumi.gcp.organizations.inputs.GetIAMPolicyArgs;
import com.pulumi.gcp.datacatalog.TaxonomyIamPolicy;
import com.pulumi.gcp.datacatalog.TaxonomyIamPolicyArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        final var admin = OrganizationsFunctions.getIAMPolicy(GetIAMPolicyArgs.builder()
            .bindings(GetIAMPolicyBindingArgs.builder()
                .role("roles/viewer")
                .members("user:jane@example.com")
                .build())
            .build());

        var policy = new TaxonomyIamPolicy("policy", TaxonomyIamPolicyArgs.builder()
            .taxonomy(basicTaxonomy.name())
            .policyData(admin.applyValue(getIAMPolicyResult -> getIAMPolicyResult.policyData()))
            .build());

    }
}
```
```yaml
resources:
  policy:
    type: gcp:datacatalog:TaxonomyIamPolicy
    properties:
      taxonomy: ${basicTaxonomy.name}
      policyData: ${admin.policyData}
variables:
  admin:
    fn::invoke:
      function: gcp:organizations:getIAMPolicy
      arguments:
        bindings:
          - role: roles/viewer
            members:
              - user:jane@example.com
```
<!--End PulumiCodeChooser -->

## gcp.datacatalog.TaxonomyIamBinding

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const binding = new gcp.datacatalog.TaxonomyIamBinding("binding", {
    taxonomy: basicTaxonomy.name,
    role: "roles/viewer",
    members: ["user:jane@example.com"],
});
```
```python
import pulumi
import pulumi_gcp as gcp

binding = gcp.datacatalog.TaxonomyIamBinding("binding",
    taxonomy=basic_taxonomy["name"],
    role="roles/viewer",
    members=["user:jane@example.com"])
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var binding = new Gcp.DataCatalog.TaxonomyIamBinding("binding", new()
    {
        Taxonomy = basicTaxonomy.Name,
        Role = "roles/viewer",
        Members = new[]
        {
            "user:jane@example.com",
        },
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/datacatalog"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		_, err := datacatalog.NewTaxonomyIamBinding(ctx, "binding", &datacatalog.TaxonomyIamBindingArgs{
			Taxonomy: pulumi.Any(basicTaxonomy.Name),
			Role:     pulumi.String("roles/viewer"),
			Members: pulumi.StringArray{
				pulumi.String("user:jane@example.com"),
			},
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.datacatalog.TaxonomyIamBinding;
import com.pulumi.gcp.datacatalog.TaxonomyIamBindingArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        var binding = new TaxonomyIamBinding("binding", TaxonomyIamBindingArgs.builder()
            .taxonomy(basicTaxonomy.name())
            .role("roles/viewer")
            .members("user:jane@example.com")
            .build());

    }
}
```
```yaml
resources:
  binding:
    type: gcp:datacatalog:TaxonomyIamBinding
    properties:
      taxonomy: ${basicTaxonomy.name}
      role: roles/viewer
      members:
        - user:jane@example.com
```
<!--End PulumiCodeChooser -->

## gcp.datacatalog.TaxonomyIamMember

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const member = new gcp.datacatalog.TaxonomyIamMember("member", {
    taxonomy: basicTaxonomy.name,
    role: "roles/viewer",
    member: "user:jane@example.com",
});
```
```python
import pulumi
import pulumi_gcp as gcp

member = gcp.datacatalog.TaxonomyIamMember("member",
    taxonomy=basic_taxonomy["name"],
    role="roles/viewer",
    member="user:jane@example.com")
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var member = new Gcp.DataCatalog.TaxonomyIamMember("member", new()
    {
        Taxonomy = basicTaxonomy.Name,
        Role = "roles/viewer",
        Member = "user:jane@example.com",
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/datacatalog"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		_, err := datacatalog.NewTaxonomyIamMember(ctx, "member", &datacatalog.TaxonomyIamMemberArgs{
			Taxonomy: pulumi.Any(basicTaxonomy.Name),
			Role:     pulumi.String("roles/viewer"),
			Member:   pulumi.String("user:jane@example.com"),
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.datacatalog.TaxonomyIamMember;
import com.pulumi.gcp.datacatalog.TaxonomyIamMemberArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        var member = new TaxonomyIamMember("member", TaxonomyIamMemberArgs.builder()
            .taxonomy(basicTaxonomy.name())
            .role("roles/viewer")
            .member("user:jane@example.com")
            .build());

    }
}
```
```yaml
resources:
  member:
    type: gcp:datacatalog:TaxonomyIamMember
    properties:
      taxonomy: ${basicTaxonomy.name}
      role: roles/viewer
      member: user:jane@example.com
```
<!--End PulumiCodeChooser -->


## This resource supports User Project Overrides.

-

# IAM policy for Data catalog Taxonomy
Three different resources help you manage your IAM policy for Data catalog Taxonomy. Each of these resources serves a different use case:

* `gcp.datacatalog.TaxonomyIamPolicy`: Authoritative. Sets the IAM policy for the taxonomy and replaces any existing policy already attached.
* `gcp.datacatalog.TaxonomyIamBinding`: Authoritative for a given role. Updates the IAM policy to grant a role to a list of members. Other roles within the IAM policy for the taxonomy are preserved.
* `gcp.datacatalog.TaxonomyIamMember`: Non-authoritative. Updates the IAM policy to grant a role to a new member. Other members for the role for the taxonomy are preserved.

A data source can be used to retrieve policy data in advent you do not need creation

* `gcp.datacatalog.TaxonomyIamPolicy`: Retrieves the IAM policy for the taxonomy

> **Note:** `gcp.datacatalog.TaxonomyIamPolicy` **cannot** be used in conjunction with `gcp.datacatalog.TaxonomyIamBinding` and `gcp.datacatalog.TaxonomyIamMember` or they will fight over what your policy should be.

> **Note:** `gcp.datacatalog.TaxonomyIamBinding` resources **can be** used in conjunction with `gcp.datacatalog.TaxonomyIamMember` resources **only if** they do not grant privilege to the same role.



## gcp.datacatalog.TaxonomyIamPolicy

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const admin = gcp.organizations.getIAMPolicy({
    bindings: [{
        role: "roles/viewer",
        members: ["user:jane@example.com"],
    }],
});
const policy = new gcp.datacatalog.TaxonomyIamPolicy("policy", {
    taxonomy: basicTaxonomy.name,
    policyData: admin.then(admin => admin.policyData),
});
```
```python
import pulumi
import pulumi_gcp as gcp

admin = gcp.organizations.get_iam_policy(bindings=[{
    "role": "roles/viewer",
    "members": ["user:jane@example.com"],
}])
policy = gcp.datacatalog.TaxonomyIamPolicy("policy",
    taxonomy=basic_taxonomy["name"],
    policy_data=admin.policy_data)
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var admin = Gcp.Organizations.GetIAMPolicy.Invoke(new()
    {
        Bindings = new[]
        {
            new Gcp.Organizations.Inputs.GetIAMPolicyBindingInputArgs
            {
                Role = "roles/viewer",
                Members = new[]
                {
                    "user:jane@example.com",
                },
            },
        },
    });

    var policy = new Gcp.DataCatalog.TaxonomyIamPolicy("policy", new()
    {
        Taxonomy = basicTaxonomy.Name,
        PolicyData = admin.Apply(getIAMPolicyResult => getIAMPolicyResult.PolicyData),
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/datacatalog"
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/organizations"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		admin, err := organizations.LookupIAMPolicy(ctx, &organizations.LookupIAMPolicyArgs{
			Bindings: []organizations.GetIAMPolicyBinding{
				{
					Role: "roles/viewer",
					Members: []string{
						"user:jane@example.com",
					},
				},
			},
		}, nil)
		if err != nil {
			return err
		}
		_, err = datacatalog.NewTaxonomyIamPolicy(ctx, "policy", &datacatalog.TaxonomyIamPolicyArgs{
			Taxonomy:   pulumi.Any(basicTaxonomy.Name),
			PolicyData: pulumi.String(admin.PolicyData),
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.organizations.OrganizationsFunctions;
import com.pulumi.gcp.organizations.inputs.GetIAMPolicyArgs;
import com.pulumi.gcp.datacatalog.TaxonomyIamPolicy;
import com.pulumi.gcp.datacatalog.TaxonomyIamPolicyArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        final var admin = OrganizationsFunctions.getIAMPolicy(GetIAMPolicyArgs.builder()
            .bindings(GetIAMPolicyBindingArgs.builder()
                .role("roles/viewer")
                .members("user:jane@example.com")
                .build())
            .build());

        var policy = new TaxonomyIamPolicy("policy", TaxonomyIamPolicyArgs.builder()
            .taxonomy(basicTaxonomy.name())
            .policyData(admin.applyValue(getIAMPolicyResult -> getIAMPolicyResult.policyData()))
            .build());

    }
}
```
```yaml
resources:
  policy:
    type: gcp:datacatalog:TaxonomyIamPolicy
    properties:
      taxonomy: ${basicTaxonomy.name}
      policyData: ${admin.policyData}
variables:
  admin:
    fn::invoke:
      function: gcp:organizations:getIAMPolicy
      arguments:
        bindings:
          - role: roles/viewer
            members:
              - user:jane@example.com
```
<!--End PulumiCodeChooser -->

## gcp.datacatalog.TaxonomyIamBinding

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const binding = new gcp.datacatalog.TaxonomyIamBinding("binding", {
    taxonomy: basicTaxonomy.name,
    role: "roles/viewer",
    members: ["user:jane@example.com"],
});
```
```python
import pulumi
import pulumi_gcp as gcp

binding = gcp.datacatalog.TaxonomyIamBinding("binding",
    taxonomy=basic_taxonomy["name"],
    role="roles/viewer",
    members=["user:jane@example.com"])
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var binding = new Gcp.DataCatalog.TaxonomyIamBinding("binding", new()
    {
        Taxonomy = basicTaxonomy.Name,
        Role = "roles/viewer",
        Members = new[]
        {
            "user:jane@example.com",
        },
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/datacatalog"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		_, err := datacatalog.NewTaxonomyIamBinding(ctx, "binding", &datacatalog.TaxonomyIamBindingArgs{
			Taxonomy: pulumi.Any(basicTaxonomy.Name),
			Role:     pulumi.String("roles/viewer"),
			Members: pulumi.StringArray{
				pulumi.String("user:jane@example.com"),
			},
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.datacatalog.TaxonomyIamBinding;
import com.pulumi.gcp.datacatalog.TaxonomyIamBindingArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        var binding = new TaxonomyIamBinding("binding", TaxonomyIamBindingArgs.builder()
            .taxonomy(basicTaxonomy.name())
            .role("roles/viewer")
            .members("user:jane@example.com")
            .build());

    }
}
```
```yaml
resources:
  binding:
    type: gcp:datacatalog:TaxonomyIamBinding
    properties:
      taxonomy: ${basicTaxonomy.name}
      role: roles/viewer
      members:
        - user:jane@example.com
```
<!--End PulumiCodeChooser -->

## gcp.datacatalog.TaxonomyIamMember

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const member = new gcp.datacatalog.TaxonomyIamMember("member", {
    taxonomy: basicTaxonomy.name,
    role: "roles/viewer",
    member: "user:jane@example.com",
});
```
```python
import pulumi
import pulumi_gcp as gcp

member = gcp.datacatalog.TaxonomyIamMember("member",
    taxonomy=basic_taxonomy["name"],
    role="roles/viewer",
    member="user:jane@example.com")
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var member = new Gcp.DataCatalog.TaxonomyIamMember("member", new()
    {
        Taxonomy = basicTaxonomy.Name,
        Role = "roles/viewer",
        Member = "user:jane@example.com",
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/datacatalog"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		_, err := datacatalog.NewTaxonomyIamMember(ctx, "member", &datacatalog.TaxonomyIamMemberArgs{
			Taxonomy: pulumi.Any(basicTaxonomy.Name),
			Role:     pulumi.String("roles/viewer"),
			Member:   pulumi.String("user:jane@example.com"),
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.datacatalog.TaxonomyIamMember;
import com.pulumi.gcp.datacatalog.TaxonomyIamMemberArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        var member = new TaxonomyIamMember("member", TaxonomyIamMemberArgs.builder()
            .taxonomy(basicTaxonomy.name())
            .role("roles/viewer")
            .member("user:jane@example.com")
            .build());

    }
}
```
```yaml
resources:
  member:
    type: gcp:datacatalog:TaxonomyIamMember
    properties:
      taxonomy: ${basicTaxonomy.name}
      role: roles/viewer
      member: user:jane@example.com
```
<!--End PulumiCodeChooser -->

## Import

For all import syntaxes, the "resource in question" can take any of the following forms:

* projects/{{project}}/locations/{{region}}/taxonomies/{{taxonomy}}

* {{project}}/{{region}}/{{taxonomy}}

* {{region}}/{{taxonomy}}

* {{taxonomy}}

Any variables not passed in the import command will be taken from the provider configuration.

Data catalog taxonomy IAM resources can be imported using the resource identifiers, role, and member.

IAM member imports use space-delimited identifiers: the resource in question, the role, and the member identity, e.g.

```sh
$ pulumi import gcp:datacatalog/taxonomyIamMember:TaxonomyIamMember editor "projects/{{project}}/locations/{{region}}/taxonomies/{{taxonomy}} roles/viewer user:jane@example.com"
```

IAM binding imports use space-delimited identifiers: the resource in question and the role, e.g.

```sh
$ pulumi import gcp:datacatalog/taxonomyIamMember:TaxonomyIamMember editor "projects/{{project}}/locations/{{region}}/taxonomies/{{taxonomy}} roles/viewer"
```

IAM policy imports use the identifier of the resource in question, e.g.

```sh
$ pulumi import gcp:datacatalog/taxonomyIamMember:TaxonomyIamMember editor projects/{{project}}/locations/{{region}}/taxonomies/{{taxonomy}}
```

-> **Custom Roles** If you're importing a IAM resource with a custom role, make sure to use the

 full name of the custom role, e.g. `[projects/my-project|organizations/my-org]/roles/my-custom-role`.


	conditionvBt:r
p
datacatalogTaxonomyIamMemberConditionEgcp:datacatalog/TaxonomyIamMemberCondition:TaxonomyIamMemberConditionÓ	
member" Ä	Identities that will be granted the privilege in `role`.
Each entry can have one of the following values:
* **allUsers**: A special identifier that represents anyone who is on the internet; with or without a Google account.
* **allAuthenticatedUsers**: A special identifier that represents anyone who is authenticated with a Google account or a service account.
* **user:{emailid}**: An email address that represents a specific Google account. For example, alice@gmail.com or joe@example.com.
* **serviceAccount:{emailid}**: An email address that represents a service account. For example, my-other-app@appspot.gserviceaccount.com.
* **group:{emailid}**: An email address that represents a Google group. For example, admins@example.com.
* **domain:{domain}**: A G Suite domain (primary, instead of alias) name that represents all the users of that domain. For example, google.com or example.com.
* **projectOwner:projectid**: Owners of the given project. For example, "projectOwner:my-example-project"
* **projectEditor:projectid**: Editors of the given project. For example, "projectEditor:my-example-project"
* **projectViewer:projectid**: Viewers of the given project. For example, "projectViewer:my-example-project"

projectB" The ID of the project in which the resource belongs.
If it is not provided, the project will be parsed from the identifier of the parent resource. If no project is provided in the parent identifier and no project is specified, the provider project is used.

regionB" Û
role" ÎThe role that should be applied. Only one
`gcp.datacatalog.TaxonomyIamBinding` can be used per role. Note that custom roles must be of the format
`[projects|organizations]/{parent-name}/roles/{role-name}`.
K
taxonomy" ;Used to find the parent resource to bind the IAM policy to
"
	conditionvBt:r
p
datacatalogTaxonomyIamMemberConditionEgcp:datacatalog/TaxonomyIamMemberCondition:TaxonomyIamMemberCondition"3
etag" '(Computed) The etag of the IAM policy.
"Ó	
member" Ä	Identities that will be granted the privilege in `role`.
Each entry can have one of the following values:
* **allUsers**: A special identifier that represents anyone who is on the internet; with or without a Google account.
* **allAuthenticatedUsers**: A special identifier that represents anyone who is authenticated with a Google account or a service account.
* **user:{emailid}**: An email address that represents a specific Google account. For example, alice@gmail.com or joe@example.com.
* **serviceAccount:{emailid}**: An email address that represents a service account. For example, my-other-app@appspot.gserviceaccount.com.
* **group:{emailid}**: An email address that represents a Google group. For example, admins@example.com.
* **domain:{domain}**: A G Suite domain (primary, instead of alias) name that represents all the users of that domain. For example, google.com or example.com.
* **projectOwner:projectid**: Owners of the given project. For example, "projectOwner:my-example-project"
* **projectEditor:projectid**: Editors of the given project. For example, "projectEditor:my-example-project"
* **projectViewer:projectid**: Viewers of the given project. For example, "projectViewer:my-example-project"
"
project" The ID of the project in which the resource belongs.
If it is not provided, the project will be parsed from the identifier of the parent resource. If no project is provided in the parent identifier and no project is specified, the provider project is used.
"
region" "Û
role" ÎThe role that should be applied. Only one
`gcp.datacatalog.TaxonomyIamBinding` can be used per role. Note that custom roles must be of the format
`[projects|organizations]/{parent-name}/roles/{role-name}`.
"K
taxonomy" ;Used to find the parent resource to bind the IAM policy to
*±
U
datacatalogTaxonomyIamPolicy3gcp:datacatalog/taxonomyIamPolicy:TaxonomyIamPolicyã¨Three different resources help you manage your IAM policy for Data catalog Taxonomy. Each of these resources serves a different use case:

* `gcp.datacatalog.TaxonomyIamPolicy`: Authoritative. Sets the IAM policy for the taxonomy and replaces any existing policy already attached.
* `gcp.datacatalog.TaxonomyIamBinding`: Authoritative for a given role. Updates the IAM policy to grant a role to a list of members. Other roles within the IAM policy for the taxonomy are preserved.
* `gcp.datacatalog.TaxonomyIamMember`: Non-authoritative. Updates the IAM policy to grant a role to a new member. Other members for the role for the taxonomy are preserved.

A data source can be used to retrieve policy data in advent you do not need creation

* `gcp.datacatalog.TaxonomyIamPolicy`: Retrieves the IAM policy for the taxonomy

> **Note:** `gcp.datacatalog.TaxonomyIamPolicy` **cannot** be used in conjunction with `gcp.datacatalog.TaxonomyIamBinding` and `gcp.datacatalog.TaxonomyIamMember` or they will fight over what your policy should be.

> **Note:** `gcp.datacatalog.TaxonomyIamBinding` resources **can be** used in conjunction with `gcp.datacatalog.TaxonomyIamMember` resources **only if** they do not grant privilege to the same role.



## gcp.datacatalog.TaxonomyIamPolicy

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const admin = gcp.organizations.getIAMPolicy({
    bindings: [{
        role: "roles/viewer",
        members: ["user:jane@example.com"],
    }],
});
const policy = new gcp.datacatalog.TaxonomyIamPolicy("policy", {
    taxonomy: basicTaxonomy.name,
    policyData: admin.then(admin => admin.policyData),
});
```
```python
import pulumi
import pulumi_gcp as gcp

admin = gcp.organizations.get_iam_policy(bindings=[{
    "role": "roles/viewer",
    "members": ["user:jane@example.com"],
}])
policy = gcp.datacatalog.TaxonomyIamPolicy("policy",
    taxonomy=basic_taxonomy["name"],
    policy_data=admin.policy_data)
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var admin = Gcp.Organizations.GetIAMPolicy.Invoke(new()
    {
        Bindings = new[]
        {
            new Gcp.Organizations.Inputs.GetIAMPolicyBindingInputArgs
            {
                Role = "roles/viewer",
                Members = new[]
                {
                    "user:jane@example.com",
                },
            },
        },
    });

    var policy = new Gcp.DataCatalog.TaxonomyIamPolicy("policy", new()
    {
        Taxonomy = basicTaxonomy.Name,
        PolicyData = admin.Apply(getIAMPolicyResult => getIAMPolicyResult.PolicyData),
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/datacatalog"
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/organizations"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		admin, err := organizations.LookupIAMPolicy(ctx, &organizations.LookupIAMPolicyArgs{
			Bindings: []organizations.GetIAMPolicyBinding{
				{
					Role: "roles/viewer",
					Members: []string{
						"user:jane@example.com",
					},
				},
			},
		}, nil)
		if err != nil {
			return err
		}
		_, err = datacatalog.NewTaxonomyIamPolicy(ctx, "policy", &datacatalog.TaxonomyIamPolicyArgs{
			Taxonomy:   pulumi.Any(basicTaxonomy.Name),
			PolicyData: pulumi.String(admin.PolicyData),
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.organizations.OrganizationsFunctions;
import com.pulumi.gcp.organizations.inputs.GetIAMPolicyArgs;
import com.pulumi.gcp.datacatalog.TaxonomyIamPolicy;
import com.pulumi.gcp.datacatalog.TaxonomyIamPolicyArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        final var admin = OrganizationsFunctions.getIAMPolicy(GetIAMPolicyArgs.builder()
            .bindings(GetIAMPolicyBindingArgs.builder()
                .role("roles/viewer")
                .members("user:jane@example.com")
                .build())
            .build());

        var policy = new TaxonomyIamPolicy("policy", TaxonomyIamPolicyArgs.builder()
            .taxonomy(basicTaxonomy.name())
            .policyData(admin.applyValue(getIAMPolicyResult -> getIAMPolicyResult.policyData()))
            .build());

    }
}
```
```yaml
resources:
  policy:
    type: gcp:datacatalog:TaxonomyIamPolicy
    properties:
      taxonomy: ${basicTaxonomy.name}
      policyData: ${admin.policyData}
variables:
  admin:
    fn::invoke:
      function: gcp:organizations:getIAMPolicy
      arguments:
        bindings:
          - role: roles/viewer
            members:
              - user:jane@example.com
```
<!--End PulumiCodeChooser -->

## gcp.datacatalog.TaxonomyIamBinding

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const binding = new gcp.datacatalog.TaxonomyIamBinding("binding", {
    taxonomy: basicTaxonomy.name,
    role: "roles/viewer",
    members: ["user:jane@example.com"],
});
```
```python
import pulumi
import pulumi_gcp as gcp

binding = gcp.datacatalog.TaxonomyIamBinding("binding",
    taxonomy=basic_taxonomy["name"],
    role="roles/viewer",
    members=["user:jane@example.com"])
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var binding = new Gcp.DataCatalog.TaxonomyIamBinding("binding", new()
    {
        Taxonomy = basicTaxonomy.Name,
        Role = "roles/viewer",
        Members = new[]
        {
            "user:jane@example.com",
        },
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/datacatalog"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		_, err := datacatalog.NewTaxonomyIamBinding(ctx, "binding", &datacatalog.TaxonomyIamBindingArgs{
			Taxonomy: pulumi.Any(basicTaxonomy.Name),
			Role:     pulumi.String("roles/viewer"),
			Members: pulumi.StringArray{
				pulumi.String("user:jane@example.com"),
			},
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.datacatalog.TaxonomyIamBinding;
import com.pulumi.gcp.datacatalog.TaxonomyIamBindingArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        var binding = new TaxonomyIamBinding("binding", TaxonomyIamBindingArgs.builder()
            .taxonomy(basicTaxonomy.name())
            .role("roles/viewer")
            .members("user:jane@example.com")
            .build());

    }
}
```
```yaml
resources:
  binding:
    type: gcp:datacatalog:TaxonomyIamBinding
    properties:
      taxonomy: ${basicTaxonomy.name}
      role: roles/viewer
      members:
        - user:jane@example.com
```
<!--End PulumiCodeChooser -->

## gcp.datacatalog.TaxonomyIamMember

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const member = new gcp.datacatalog.TaxonomyIamMember("member", {
    taxonomy: basicTaxonomy.name,
    role: "roles/viewer",
    member: "user:jane@example.com",
});
```
```python
import pulumi
import pulumi_gcp as gcp

member = gcp.datacatalog.TaxonomyIamMember("member",
    taxonomy=basic_taxonomy["name"],
    role="roles/viewer",
    member="user:jane@example.com")
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var member = new Gcp.DataCatalog.TaxonomyIamMember("member", new()
    {
        Taxonomy = basicTaxonomy.Name,
        Role = "roles/viewer",
        Member = "user:jane@example.com",
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/datacatalog"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		_, err := datacatalog.NewTaxonomyIamMember(ctx, "member", &datacatalog.TaxonomyIamMemberArgs{
			Taxonomy: pulumi.Any(basicTaxonomy.Name),
			Role:     pulumi.String("roles/viewer"),
			Member:   pulumi.String("user:jane@example.com"),
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.datacatalog.TaxonomyIamMember;
import com.pulumi.gcp.datacatalog.TaxonomyIamMemberArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        var member = new TaxonomyIamMember("member", TaxonomyIamMemberArgs.builder()
            .taxonomy(basicTaxonomy.name())
            .role("roles/viewer")
            .member("user:jane@example.com")
            .build());

    }
}
```
```yaml
resources:
  member:
    type: gcp:datacatalog:TaxonomyIamMember
    properties:
      taxonomy: ${basicTaxonomy.name}
      role: roles/viewer
      member: user:jane@example.com
```
<!--End PulumiCodeChooser -->


## This resource supports User Project Overrides.

-

# IAM policy for Data catalog Taxonomy
Three different resources help you manage your IAM policy for Data catalog Taxonomy. Each of these resources serves a different use case:

* `gcp.datacatalog.TaxonomyIamPolicy`: Authoritative. Sets the IAM policy for the taxonomy and replaces any existing policy already attached.
* `gcp.datacatalog.TaxonomyIamBinding`: Authoritative for a given role. Updates the IAM policy to grant a role to a list of members. Other roles within the IAM policy for the taxonomy are preserved.
* `gcp.datacatalog.TaxonomyIamMember`: Non-authoritative. Updates the IAM policy to grant a role to a new member. Other members for the role for the taxonomy are preserved.

A data source can be used to retrieve policy data in advent you do not need creation

* `gcp.datacatalog.TaxonomyIamPolicy`: Retrieves the IAM policy for the taxonomy

> **Note:** `gcp.datacatalog.TaxonomyIamPolicy` **cannot** be used in conjunction with `gcp.datacatalog.TaxonomyIamBinding` and `gcp.datacatalog.TaxonomyIamMember` or they will fight over what your policy should be.

> **Note:** `gcp.datacatalog.TaxonomyIamBinding` resources **can be** used in conjunction with `gcp.datacatalog.TaxonomyIamMember` resources **only if** they do not grant privilege to the same role.



## gcp.datacatalog.TaxonomyIamPolicy

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const admin = gcp.organizations.getIAMPolicy({
    bindings: [{
        role: "roles/viewer",
        members: ["user:jane@example.com"],
    }],
});
const policy = new gcp.datacatalog.TaxonomyIamPolicy("policy", {
    taxonomy: basicTaxonomy.name,
    policyData: admin.then(admin => admin.policyData),
});
```
```python
import pulumi
import pulumi_gcp as gcp

admin = gcp.organizations.get_iam_policy(bindings=[{
    "role": "roles/viewer",
    "members": ["user:jane@example.com"],
}])
policy = gcp.datacatalog.TaxonomyIamPolicy("policy",
    taxonomy=basic_taxonomy["name"],
    policy_data=admin.policy_data)
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var admin = Gcp.Organizations.GetIAMPolicy.Invoke(new()
    {
        Bindings = new[]
        {
            new Gcp.Organizations.Inputs.GetIAMPolicyBindingInputArgs
            {
                Role = "roles/viewer",
                Members = new[]
                {
                    "user:jane@example.com",
                },
            },
        },
    });

    var policy = new Gcp.DataCatalog.TaxonomyIamPolicy("policy", new()
    {
        Taxonomy = basicTaxonomy.Name,
        PolicyData = admin.Apply(getIAMPolicyResult => getIAMPolicyResult.PolicyData),
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/datacatalog"
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/organizations"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		admin, err := organizations.LookupIAMPolicy(ctx, &organizations.LookupIAMPolicyArgs{
			Bindings: []organizations.GetIAMPolicyBinding{
				{
					Role: "roles/viewer",
					Members: []string{
						"user:jane@example.com",
					},
				},
			},
		}, nil)
		if err != nil {
			return err
		}
		_, err = datacatalog.NewTaxonomyIamPolicy(ctx, "policy", &datacatalog.TaxonomyIamPolicyArgs{
			Taxonomy:   pulumi.Any(basicTaxonomy.Name),
			PolicyData: pulumi.String(admin.PolicyData),
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.organizations.OrganizationsFunctions;
import com.pulumi.gcp.organizations.inputs.GetIAMPolicyArgs;
import com.pulumi.gcp.datacatalog.TaxonomyIamPolicy;
import com.pulumi.gcp.datacatalog.TaxonomyIamPolicyArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        final var admin = OrganizationsFunctions.getIAMPolicy(GetIAMPolicyArgs.builder()
            .bindings(GetIAMPolicyBindingArgs.builder()
                .role("roles/viewer")
                .members("user:jane@example.com")
                .build())
            .build());

        var policy = new TaxonomyIamPolicy("policy", TaxonomyIamPolicyArgs.builder()
            .taxonomy(basicTaxonomy.name())
            .policyData(admin.applyValue(getIAMPolicyResult -> getIAMPolicyResult.policyData()))
            .build());

    }
}
```
```yaml
resources:
  policy:
    type: gcp:datacatalog:TaxonomyIamPolicy
    properties:
      taxonomy: ${basicTaxonomy.name}
      policyData: ${admin.policyData}
variables:
  admin:
    fn::invoke:
      function: gcp:organizations:getIAMPolicy
      arguments:
        bindings:
          - role: roles/viewer
            members:
              - user:jane@example.com
```
<!--End PulumiCodeChooser -->

## gcp.datacatalog.TaxonomyIamBinding

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const binding = new gcp.datacatalog.TaxonomyIamBinding("binding", {
    taxonomy: basicTaxonomy.name,
    role: "roles/viewer",
    members: ["user:jane@example.com"],
});
```
```python
import pulumi
import pulumi_gcp as gcp

binding = gcp.datacatalog.TaxonomyIamBinding("binding",
    taxonomy=basic_taxonomy["name"],
    role="roles/viewer",
    members=["user:jane@example.com"])
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var binding = new Gcp.DataCatalog.TaxonomyIamBinding("binding", new()
    {
        Taxonomy = basicTaxonomy.Name,
        Role = "roles/viewer",
        Members = new[]
        {
            "user:jane@example.com",
        },
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/datacatalog"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		_, err := datacatalog.NewTaxonomyIamBinding(ctx, "binding", &datacatalog.TaxonomyIamBindingArgs{
			Taxonomy: pulumi.Any(basicTaxonomy.Name),
			Role:     pulumi.String("roles/viewer"),
			Members: pulumi.StringArray{
				pulumi.String("user:jane@example.com"),
			},
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.datacatalog.TaxonomyIamBinding;
import com.pulumi.gcp.datacatalog.TaxonomyIamBindingArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        var binding = new TaxonomyIamBinding("binding", TaxonomyIamBindingArgs.builder()
            .taxonomy(basicTaxonomy.name())
            .role("roles/viewer")
            .members("user:jane@example.com")
            .build());

    }
}
```
```yaml
resources:
  binding:
    type: gcp:datacatalog:TaxonomyIamBinding
    properties:
      taxonomy: ${basicTaxonomy.name}
      role: roles/viewer
      members:
        - user:jane@example.com
```
<!--End PulumiCodeChooser -->

## gcp.datacatalog.TaxonomyIamMember

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const member = new gcp.datacatalog.TaxonomyIamMember("member", {
    taxonomy: basicTaxonomy.name,
    role: "roles/viewer",
    member: "user:jane@example.com",
});
```
```python
import pulumi
import pulumi_gcp as gcp

member = gcp.datacatalog.TaxonomyIamMember("member",
    taxonomy=basic_taxonomy["name"],
    role="roles/viewer",
    member="user:jane@example.com")
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var member = new Gcp.DataCatalog.TaxonomyIamMember("member", new()
    {
        Taxonomy = basicTaxonomy.Name,
        Role = "roles/viewer",
        Member = "user:jane@example.com",
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/datacatalog"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		_, err := datacatalog.NewTaxonomyIamMember(ctx, "member", &datacatalog.TaxonomyIamMemberArgs{
			Taxonomy: pulumi.Any(basicTaxonomy.Name),
			Role:     pulumi.String("roles/viewer"),
			Member:   pulumi.String("user:jane@example.com"),
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.datacatalog.TaxonomyIamMember;
import com.pulumi.gcp.datacatalog.TaxonomyIamMemberArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        var member = new TaxonomyIamMember("member", TaxonomyIamMemberArgs.builder()
            .taxonomy(basicTaxonomy.name())
            .role("roles/viewer")
            .member("user:jane@example.com")
            .build());

    }
}
```
```yaml
resources:
  member:
    type: gcp:datacatalog:TaxonomyIamMember
    properties:
      taxonomy: ${basicTaxonomy.name}
      role: roles/viewer
      member: user:jane@example.com
```
<!--End PulumiCodeChooser -->

## Import

For all import syntaxes, the "resource in question" can take any of the following forms:

* projects/{{project}}/locations/{{region}}/taxonomies/{{taxonomy}}

* {{project}}/{{region}}/{{taxonomy}}

* {{region}}/{{taxonomy}}

* {{taxonomy}}

Any variables not passed in the import command will be taken from the provider configuration.

Data catalog taxonomy IAM resources can be imported using the resource identifiers, role, and member.

IAM member imports use space-delimited identifiers: the resource in question, the role, and the member identity, e.g.

```sh
$ pulumi import gcp:datacatalog/taxonomyIamPolicy:TaxonomyIamPolicy editor "projects/{{project}}/locations/{{region}}/taxonomies/{{taxonomy}} roles/viewer user:jane@example.com"
```

IAM binding imports use space-delimited identifiers: the resource in question and the role, e.g.

```sh
$ pulumi import gcp:datacatalog/taxonomyIamPolicy:TaxonomyIamPolicy editor "projects/{{project}}/locations/{{region}}/taxonomies/{{taxonomy}} roles/viewer"
```

IAM policy imports use the identifier of the resource in question, e.g.

```sh
$ pulumi import gcp:datacatalog/taxonomyIamPolicy:TaxonomyIamPolicy editor projects/{{project}}/locations/{{region}}/taxonomies/{{taxonomy}}
```

-> **Custom Roles** If you're importing a IAM resource with a custom role, make sure to use the

 full name of the custom role, e.g. `[projects/my-project|organizations/my-org]/roles/my-custom-role`.

_

policyData" MThe policy data generated by
a `gcp.organizations.getIAMPolicy` data source.

projectB" The ID of the project in which the resource belongs.
If it is not provided, the project will be parsed from the identifier of the parent resource. If no project is provided in the parent identifier and no project is specified, the provider project is used.

regionB" K
taxonomy" ;Used to find the parent resource to bind the IAM policy to
"3
etag" '(Computed) The etag of the IAM policy.
"_

policyData" MThe policy data generated by
a `gcp.organizations.getIAMPolicy` data source.
"
project" The ID of the project in which the resource belongs.
If it is not provided, the project will be parsed from the identifier of the parent resource. If no project is provided in the parent identifier and no project is specified, the provider project is used.
"
region" "K
taxonomy" ;Used to find the parent resource to bind the IAM policy to
*÷
I
dataflowFlexTemplateJob,gcp:dataflow/flexTemplateJob:FlexTemplateJobÎU## Example Usage

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const bigDataJob = new gcp.dataflow.FlexTemplateJob("big_data_job", {
    name: "dataflow-flextemplates-job",
    containerSpecGcsPath: "gs://my-bucket/templates/template.json",
    parameters: {
        inputSubscription: "messages",
    },
});
```
```python
import pulumi
import pulumi_gcp as gcp

big_data_job = gcp.dataflow.FlexTemplateJob("big_data_job",
    name="dataflow-flextemplates-job",
    container_spec_gcs_path="gs://my-bucket/templates/template.json",
    parameters={
        "inputSubscription": "messages",
    })
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var bigDataJob = new Gcp.Dataflow.FlexTemplateJob("big_data_job", new()
    {
        Name = "dataflow-flextemplates-job",
        ContainerSpecGcsPath = "gs://my-bucket/templates/template.json",
        Parameters = 
        {
            { "inputSubscription", "messages" },
        },
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/dataflow"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		_, err := dataflow.NewFlexTemplateJob(ctx, "big_data_job", &dataflow.FlexTemplateJobArgs{
			Name:                 pulumi.String("dataflow-flextemplates-job"),
			ContainerSpecGcsPath: pulumi.String("gs://my-bucket/templates/template.json"),
			Parameters: pulumi.StringMap{
				"inputSubscription": pulumi.String("messages"),
			},
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.dataflow.FlexTemplateJob;
import com.pulumi.gcp.dataflow.FlexTemplateJobArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        var bigDataJob = new FlexTemplateJob("bigDataJob", FlexTemplateJobArgs.builder()
            .name("dataflow-flextemplates-job")
            .containerSpecGcsPath("gs://my-bucket/templates/template.json")
            .parameters(Map.of("inputSubscription", "messages"))
            .build());

    }
}
```
```yaml
resources:
  bigDataJob:
    type: gcp:dataflow:FlexTemplateJob
    name: big_data_job
    properties:
      name: dataflow-flextemplates-job
      containerSpecGcsPath: gs://my-bucket/templates/template.json
      parameters:
        inputSubscription: messages
```
<!--End PulumiCodeChooser -->

## Note on "destroy" / "apply"

There are many types of Dataflow jobs.  Some Dataflow jobs run constantly,
getting new data from (e.g.) a GCS bucket, and outputting data continuously.
Some jobs process a set amount of data then terminate. All jobs can fail while
running due to programming errors or other issues. In this way, Dataflow jobs
are different from most other provider / Google resources.

The Dataflow resource is considered 'existing' while it is in a nonterminal
state.  If it reaches a terminal state (e.g. 'FAILED', 'COMPLETE',
'CANCELLED'), it will be recreated on the next 'apply'.  This is as expected for
jobs which run continuously, but may surprise users who use this resource for
other kinds of Dataflow jobs.

A Dataflow job which is 'destroyed' may be "cancelled" or "drained".  If
"cancelled", the job terminates - any data written remains where it is, but no
new data will be processed.  If "drained", no new data will enter the pipeline,
but any data currently in the pipeline will finish being processed.  The default
is "cancelled", but if a user sets `on_delete` to `"drain"` in the
configuration, you may experience a long wait for your `pulumi destroy` to
complete.

You can potentially short-circuit the wait by setting `skip_wait_on_job_termination`
to `true`, but beware that unless you take active steps to ensure that the job
`name` parameter changes between instances, the name will conflict and the launch
of the new job will fail. One way to do this is with a
random_id
resource, for example:

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";
import * as random from "@pulumi/random";

const config = new pulumi.Config();
const bigDataJobSubscriptionId = config.get("bigDataJobSubscriptionId") || "projects/myproject/subscriptions/messages";
const bigDataJobNameSuffix = new random.RandomId("big_data_job_name_suffix", {
    byteLength: 4,
    keepers: {
        region: region,
        subscription_id: bigDataJobSubscriptionId,
    },
});
const bigDataJob = new gcp.dataflow.FlexTemplateJob("big_data_job", {
    name: pulumi.interpolate`dataflow-flextemplates-job-${bigDataJobNameSuffix.dec}`,
    region: region,
    containerSpecGcsPath: "gs://my-bucket/templates/template.json",
    skipWaitOnJobTermination: true,
    parameters: {
        inputSubscription: bigDataJobSubscriptionId,
    },
});
```
```python
import pulumi
import pulumi_gcp as gcp
import pulumi_random as random

config = pulumi.Config()
big_data_job_subscription_id = config.get("bigDataJobSubscriptionId")
if big_data_job_subscription_id is None:
    big_data_job_subscription_id = "projects/myproject/subscriptions/messages"
big_data_job_name_suffix = random.RandomId("big_data_job_name_suffix",
    byte_length=4,
    keepers={
        "region": region,
        "subscription_id": big_data_job_subscription_id,
    })
big_data_job = gcp.dataflow.FlexTemplateJob("big_data_job",
    name=big_data_job_name_suffix.dec.apply(lambda dec: f"dataflow-flextemplates-job-{dec}"),
    region=region,
    container_spec_gcs_path="gs://my-bucket/templates/template.json",
    skip_wait_on_job_termination=True,
    parameters={
        "inputSubscription": big_data_job_subscription_id,
    })
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;
using Random = Pulumi.Random;

return await Deployment.RunAsync(() => 
{
    var config = new Config();
    var bigDataJobSubscriptionId = config.Get("bigDataJobSubscriptionId") ?? "projects/myproject/subscriptions/messages";
    var bigDataJobNameSuffix = new Random.RandomId("big_data_job_name_suffix", new()
    {
        ByteLength = 4,
        Keepers = 
        {
            { "region", region },
            { "subscription_id", bigDataJobSubscriptionId },
        },
    });

    var bigDataJob = new Gcp.Dataflow.FlexTemplateJob("big_data_job", new()
    {
        Name = bigDataJobNameSuffix.Dec.Apply(dec => $"dataflow-flextemplates-job-{dec}"),
        Region = region,
        ContainerSpecGcsPath = "gs://my-bucket/templates/template.json",
        SkipWaitOnJobTermination = true,
        Parameters = 
        {
            { "inputSubscription", bigDataJobSubscriptionId },
        },
    });

});
```
```go
package main

import (
	"fmt"

	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/dataflow"
	"github.com/pulumi/pulumi-random/sdk/v4/go/random"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi/config"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		cfg := config.New(ctx, "")
		bigDataJobSubscriptionId := "projects/myproject/subscriptions/messages"
		if param := cfg.Get("bigDataJobSubscriptionId"); param != "" {
			bigDataJobSubscriptionId = param
		}
		bigDataJobNameSuffix, err := random.NewRandomId(ctx, "big_data_job_name_suffix", &random.RandomIdArgs{
			ByteLength: pulumi.Int(4),
			Keepers: pulumi.StringMap{
				"region":          pulumi.Any(region),
				"subscription_id": pulumi.String(bigDataJobSubscriptionId),
			},
		})
		if err != nil {
			return err
		}
		_, err = dataflow.NewFlexTemplateJob(ctx, "big_data_job", &dataflow.FlexTemplateJobArgs{
			Name: bigDataJobNameSuffix.Dec.ApplyT(func(dec string) (string, error) {
				return fmt.Sprintf("dataflow-flextemplates-job-%v", dec), nil
			}).(pulumi.StringOutput),
			Region:                   pulumi.Any(region),
			ContainerSpecGcsPath:     pulumi.String("gs://my-bucket/templates/template.json"),
			SkipWaitOnJobTermination: pulumi.Bool(true),
			Parameters: pulumi.StringMap{
				"inputSubscription": pulumi.String(bigDataJobSubscriptionId),
			},
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.random.RandomId;
import com.pulumi.random.RandomIdArgs;
import com.pulumi.gcp.dataflow.FlexTemplateJob;
import com.pulumi.gcp.dataflow.FlexTemplateJobArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        final var config = ctx.config();
        final var bigDataJobSubscriptionId = config.get("bigDataJobSubscriptionId").orElse("projects/myproject/subscriptions/messages");
        var bigDataJobNameSuffix = new RandomId("bigDataJobNameSuffix", RandomIdArgs.builder()
            .byteLength(4)
            .keepers(Map.ofEntries(
                Map.entry("region", region),
                Map.entry("subscription_id", bigDataJobSubscriptionId)
            ))
            .build());

        var bigDataJob = new FlexTemplateJob("bigDataJob", FlexTemplateJobArgs.builder()
            .name(bigDataJobNameSuffix.dec().applyValue(dec -> String.format("dataflow-flextemplates-job-%s", dec)))
            .region(region)
            .containerSpecGcsPath("gs://my-bucket/templates/template.json")
            .skipWaitOnJobTermination(true)
            .parameters(Map.of("inputSubscription", bigDataJobSubscriptionId))
            .build());

    }
}
```
```yaml
configuration:
  bigDataJobSubscriptionId:
    type: string
    default: projects/myproject/subscriptions/messages
resources:
  bigDataJobNameSuffix:
    type: random:RandomId
    name: big_data_job_name_suffix
    properties:
      byteLength: 4
      keepers:
        region: ${region}
        subscription_id: ${bigDataJobSubscriptionId}
  bigDataJob:
    type: gcp:dataflow:FlexTemplateJob
    name: big_data_job
    properties:
      name: dataflow-flextemplates-job-${bigDataJobNameSuffix.dec}
      region: ${region}
      containerSpecGcsPath: gs://my-bucket/templates/template.json
      skipWaitOnJobTermination: true
      parameters:
        inputSubscription: ${bigDataJobSubscriptionId}
```
<!--End PulumiCodeChooser -->

## Import

This resource does not support import.


additionalExperimentsB*" pList of experiments that should be used by the job. An example value is `["enable_stackdriver_agent_metrics"]`.
D
autoscalingAlgorithmB" &The algorithm to use for autoscaling.
S
containerSpecGcsPath" 7The GCS path to the Dataflow job Flex
Template.

- - -
h
enableStreamingEngineB
 IImmutable. Indicates if the job should use the streaming engine feature.
s
ipConfigurationB" ZThe configuration for VM IPs.  Options are `"WORKER_IP_PUBLIC"` or `"WORKER_IP_PRIVATE"`.


kmsKeyNameB" The name for the Cloud KMS key for the job. Key format is: `projects/PROJECT_ID/locations/LOCATION/keyRings/KEY_RING/cryptoKeys/KEY`

labelsB2" User labels to be specified for the job. Keys and values
should follow the restrictions specified in the [labeling restrictions](https://cloud.google.com/compute/docs/labeling-resources#restrictions)
page. **Note**: This field is marked as deprecated as the API does not currently
support adding labels.
**NOTE**: Google-provided Dataflow templates often provide default labels
that begin with `goog-dataflow-provided`. Unless explicitly set in config, these
labels will be ignored to prevent diffs on re-apply.
j
launcherMachineTypeB" MThe machine type to use for launching the job. The default is n1-standard-1.
:
machineTypeB" %The machine type to use for the job.


maxWorkersB Immutable. The maximum number of Google Compute Engine instances to be made available to your pipeline during execution, from 1 to 1000.
O
nameB" AImmutable. A unique name for the resource, required by Dataflow.
k
networkB" ZThe network to which VMs will be assigned. If it is not provided, "default" will be used.
b

numWorkersB NImmutable. The initial number of Google Compute Engine instances for the job.
w
onDeleteB" eOne of "drain" or "cancel". Specifies behavior of
deletion during `pulumi destroy`.  See above note.


parametersB2" ì**Template specific** Key/Value pairs to be forwarded to the pipeline's options; keys are
case-sensitive based on the language on which the pipeline is coded, mostly Java.
**Note**: do not configure Dataflow options here in parameters.
q
projectB" `The project in which the resource belongs. If it is not
provided, the provider project is used.
K
regionB" ;Immutable. The region in which the created job should run.
Ó
sdkContainerImageB" ·Docker registry location of container image to use for the 'worker harness. Default is the container for the version of the SDK. Note this field is only valid for portable pipelines.
Ù
serviceAccountEmailB" »Service account email to run the workers as. This should be just an email e.g. `myserviceaccount@myproject.iam.gserviceaccount.com`. Do not include any `serviceAccount:` or other prefix.
 
skipWaitOnJobTerminationB
 
stagingLocationB" jThe Cloud Storage path to use for staging files. Must be a valid Cloud Storage URL, beginning with gs://.


subnetworkB" mThe subnetwork to which VMs will be assigned. Should be of the form "regions/REGION/subnetworks/SUBNETWORK".

tempLocationB" lThe Cloud Storage path to use for temporary files. Must be a valid Cloud Storage URL, beginning with gs://.
Ð
transformNameMappingB2" ¯Only applicable when updating a pipeline. Map of transform name prefixes of the job to be replaced with the corresponding name prefixes of the new job.Only applicable when updating a pipeline. Map of transform name prefixes of the job to be replaced with the corresponding name prefixes of the new job.
"
additionalExperiments*" pList of experiments that should be used by the job. An example value is `["enable_stackdriver_agent_metrics"]`.
"B
autoscalingAlgorithm" &The algorithm to use for autoscaling.
"S
containerSpecGcsPath" 7The GCS path to the Dataflow job Flex
Template.

- - -
"
effectiveLabels2" "h
enableStreamingEngineB
 IImmutable. Indicates if the job should use the streaming engine feature.
"s
ipConfigurationB" ZThe configuration for VM IPs.  Options are `"WORKER_IP_PUBLIC"` or `"WORKER_IP_PRIVATE"`.
"(
jobId" The unique ID of this job.
"

kmsKeyName" The name for the Cloud KMS key for the job. Key format is: `projects/PROJECT_ID/locations/LOCATION/keyRings/KEY_RING/cryptoKeys/KEY`
"
labelsB2" User labels to be specified for the job. Keys and values
should follow the restrictions specified in the [labeling restrictions](https://cloud.google.com/compute/docs/labeling-resources#restrictions)
page. **Note**: This field is marked as deprecated as the API does not currently
support adding labels.
**NOTE**: Google-provided Dataflow templates often provide default labels
that begin with `goog-dataflow-provided`. Unless explicitly set in config, these
labels will be ignored to prevent diffs on re-apply.
"h
launcherMachineType" MThe machine type to use for launching the job. The default is n1-standard-1.
"8
machineType" %The machine type to use for the job.
"

maxWorkers Immutable. The maximum number of Google Compute Engine instances to be made available to your pipeline during execution, from 1 to 1000.
"M
name" AImmutable. A unique name for the resource, required by Dataflow.
"i
network" ZThe network to which VMs will be assigned. If it is not provided, "default" will be used.
"`

numWorkers NImmutable. The initial number of Google Compute Engine instances for the job.
"w
onDeleteB" eOne of "drain" or "cancel". Specifies behavior of
deletion during `pulumi destroy`.  See above note.
"

parametersB2" ì**Template specific** Key/Value pairs to be forwarded to the pipeline's options; keys are
case-sensitive based on the language on which the pipeline is coded, mostly Java.
**Note**: do not configure Dataflow options here in parameters.
"o
project" `The project in which the resource belongs. If it is not
provided, the provider project is used.
"
pulumiLabels2" mThe combination of labels configured directly on the resource and default labels configured on the provider.
"I
region" ;Immutable. The region in which the created job should run.
"Ñ
sdkContainerImage" ·Docker registry location of container image to use for the 'worker harness. Default is the container for the version of the SDK. Note this field is only valid for portable pipelines.
"×
serviceAccountEmail" »Service account email to run the workers as. This should be just an email e.g. `myserviceaccount@myproject.iam.gserviceaccount.com`. Do not include any `serviceAccount:` or other prefix.
" 
skipWaitOnJobTerminationB
 "
stagingLocation" jThe Cloud Storage path to use for staging files. Must be a valid Cloud Storage URL, beginning with gs://.
"ª
state" The current state of the resource, selected from the [JobState enum](https://cloud.google.com/dataflow/docs/reference/rest/v1b3/projects.jobs#Job.JobState)
"

subnetwork" mThe subnetwork to which VMs will be assigned. Should be of the form "regions/REGION/subnetworks/SUBNETWORK".
"
tempLocation" lThe Cloud Storage path to use for temporary files. Must be a valid Cloud Storage URL, beginning with gs://.
"Ð
transformNameMappingB2" ¯Only applicable when updating a pipeline. Map of transform name prefixes of the job to be replaced with the corresponding name prefixes of the new job.Only applicable when updating a pipeline. Map of transform name prefixes of the job to be replaced with the corresponding name prefixes of the new job.
"B
type" 6The type of this job, selected from the JobType enum.
*­Ï
%
dataflowJobgcp:dataflow/job:Job½Creates a job on Dataflow, which is an implementation of Apache Beam running on Google Compute Engine. For more information see
the official documentation for
[Beam](https://beam.apache.org) and [Dataflow](https://cloud.google.com/dataflow/).

## Example Usage

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const bigDataJob = new gcp.dataflow.Job("big_data_job", {
    name: "dataflow-job",
    templateGcsPath: "gs://my-bucket/templates/template_file",
    tempGcsLocation: "gs://my-bucket/tmp_dir",
    parameters: {
        foo: "bar",
        baz: "qux",
    },
});
```
```python
import pulumi
import pulumi_gcp as gcp

big_data_job = gcp.dataflow.Job("big_data_job",
    name="dataflow-job",
    template_gcs_path="gs://my-bucket/templates/template_file",
    temp_gcs_location="gs://my-bucket/tmp_dir",
    parameters={
        "foo": "bar",
        "baz": "qux",
    })
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var bigDataJob = new Gcp.Dataflow.Job("big_data_job", new()
    {
        Name = "dataflow-job",
        TemplateGcsPath = "gs://my-bucket/templates/template_file",
        TempGcsLocation = "gs://my-bucket/tmp_dir",
        Parameters = 
        {
            { "foo", "bar" },
            { "baz", "qux" },
        },
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/dataflow"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		_, err := dataflow.NewJob(ctx, "big_data_job", &dataflow.JobArgs{
			Name:            pulumi.String("dataflow-job"),
			TemplateGcsPath: pulumi.String("gs://my-bucket/templates/template_file"),
			TempGcsLocation: pulumi.String("gs://my-bucket/tmp_dir"),
			Parameters: pulumi.StringMap{
				"foo": pulumi.String("bar"),
				"baz": pulumi.String("qux"),
			},
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.dataflow.Job;
import com.pulumi.gcp.dataflow.JobArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        var bigDataJob = new Job("bigDataJob", JobArgs.builder()
            .name("dataflow-job")
            .templateGcsPath("gs://my-bucket/templates/template_file")
            .tempGcsLocation("gs://my-bucket/tmp_dir")
            .parameters(Map.ofEntries(
                Map.entry("foo", "bar"),
                Map.entry("baz", "qux")
            ))
            .build());

    }
}
```
```yaml
resources:
  bigDataJob:
    type: gcp:dataflow:Job
    name: big_data_job
    properties:
      name: dataflow-job
      templateGcsPath: gs://my-bucket/templates/template_file
      tempGcsLocation: gs://my-bucket/tmp_dir
      parameters:
        foo: bar
        baz: qux
```
<!--End PulumiCodeChooser -->

### Streaming Job

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const topic = new gcp.pubsub.Topic("topic", {name: "dataflow-job1"});
const bucket1 = new gcp.storage.Bucket("bucket1", {
    name: "tf-test-bucket1",
    location: "US",
    forceDestroy: true,
});
const bucket2 = new gcp.storage.Bucket("bucket2", {
    name: "tf-test-bucket2",
    location: "US",
    forceDestroy: true,
});
const pubsubStream = new gcp.dataflow.Job("pubsub_stream", {
    name: "tf-test-dataflow-job1",
    templateGcsPath: "gs://my-bucket/templates/template_file",
    tempGcsLocation: "gs://my-bucket/tmp_dir",
    enableStreamingEngine: true,
    parameters: {
        inputFilePattern: pulumi.interpolate`${bucket1.url}/*.json`,
        outputTopic: topic.id,
    },
    transformNameMapping: {
        name: "test_job",
        env: "test",
    },
    onDelete: "cancel",
});
```
```python
import pulumi
import pulumi_gcp as gcp

topic = gcp.pubsub.Topic("topic", name="dataflow-job1")
bucket1 = gcp.storage.Bucket("bucket1",
    name="tf-test-bucket1",
    location="US",
    force_destroy=True)
bucket2 = gcp.storage.Bucket("bucket2",
    name="tf-test-bucket2",
    location="US",
    force_destroy=True)
pubsub_stream = gcp.dataflow.Job("pubsub_stream",
    name="tf-test-dataflow-job1",
    template_gcs_path="gs://my-bucket/templates/template_file",
    temp_gcs_location="gs://my-bucket/tmp_dir",
    enable_streaming_engine=True,
    parameters={
        "inputFilePattern": bucket1.url.apply(lambda url: f"{url}/*.json"),
        "outputTopic": topic.id,
    },
    transform_name_mapping={
        "name": "test_job",
        "env": "test",
    },
    on_delete="cancel")
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var topic = new Gcp.PubSub.Topic("topic", new()
    {
        Name = "dataflow-job1",
    });

    var bucket1 = new Gcp.Storage.Bucket("bucket1", new()
    {
        Name = "tf-test-bucket1",
        Location = "US",
        ForceDestroy = true,
    });

    var bucket2 = new Gcp.Storage.Bucket("bucket2", new()
    {
        Name = "tf-test-bucket2",
        Location = "US",
        ForceDestroy = true,
    });

    var pubsubStream = new Gcp.Dataflow.Job("pubsub_stream", new()
    {
        Name = "tf-test-dataflow-job1",
        TemplateGcsPath = "gs://my-bucket/templates/template_file",
        TempGcsLocation = "gs://my-bucket/tmp_dir",
        EnableStreamingEngine = true,
        Parameters = 
        {
            { "inputFilePattern", bucket1.Url.Apply(url => $"{url}/*.json") },
            { "outputTopic", topic.Id },
        },
        TransformNameMapping = 
        {
            { "name", "test_job" },
            { "env", "test" },
        },
        OnDelete = "cancel",
    });

});
```
```go
package main

import (
	"fmt"

	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/dataflow"
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/pubsub"
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/storage"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		topic, err := pubsub.NewTopic(ctx, "topic", &pubsub.TopicArgs{
			Name: pulumi.String("dataflow-job1"),
		})
		if err != nil {
			return err
		}
		bucket1, err := storage.NewBucket(ctx, "bucket1", &storage.BucketArgs{
			Name:         pulumi.String("tf-test-bucket1"),
			Location:     pulumi.String("US"),
			ForceDestroy: pulumi.Bool(true),
		})
		if err != nil {
			return err
		}
		_, err = storage.NewBucket(ctx, "bucket2", &storage.BucketArgs{
			Name:         pulumi.String("tf-test-bucket2"),
			Location:     pulumi.String("US"),
			ForceDestroy: pulumi.Bool(true),
		})
		if err != nil {
			return err
		}
		_, err = dataflow.NewJob(ctx, "pubsub_stream", &dataflow.JobArgs{
			Name:                  pulumi.String("tf-test-dataflow-job1"),
			TemplateGcsPath:       pulumi.String("gs://my-bucket/templates/template_file"),
			TempGcsLocation:       pulumi.String("gs://my-bucket/tmp_dir"),
			EnableStreamingEngine: pulumi.Bool(true),
			Parameters: pulumi.StringMap{
				"inputFilePattern": bucket1.Url.ApplyT(func(url string) (string, error) {
					return fmt.Sprintf("%v/*.json", url), nil
				}).(pulumi.StringOutput),
				"outputTopic": topic.ID(),
			},
			TransformNameMapping: pulumi.StringMap{
				"name": pulumi.String("test_job"),
				"env":  pulumi.String("test"),
			},
			OnDelete: pulumi.String("cancel"),
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.pubsub.Topic;
import com.pulumi.gcp.pubsub.TopicArgs;
import com.pulumi.gcp.storage.Bucket;
import com.pulumi.gcp.storage.BucketArgs;
import com.pulumi.gcp.dataflow.Job;
import com.pulumi.gcp.dataflow.JobArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        var topic = new Topic("topic", TopicArgs.builder()
            .name("dataflow-job1")
            .build());

        var bucket1 = new Bucket("bucket1", BucketArgs.builder()
            .name("tf-test-bucket1")
            .location("US")
            .forceDestroy(true)
            .build());

        var bucket2 = new Bucket("bucket2", BucketArgs.builder()
            .name("tf-test-bucket2")
            .location("US")
            .forceDestroy(true)
            .build());

        var pubsubStream = new Job("pubsubStream", JobArgs.builder()
            .name("tf-test-dataflow-job1")
            .templateGcsPath("gs://my-bucket/templates/template_file")
            .tempGcsLocation("gs://my-bucket/tmp_dir")
            .enableStreamingEngine(true)
            .parameters(Map.ofEntries(
                Map.entry("inputFilePattern", bucket1.url().applyValue(url -> String.format("%s/*.json", url))),
                Map.entry("outputTopic", topic.id())
            ))
            .transformNameMapping(Map.ofEntries(
                Map.entry("name", "test_job"),
                Map.entry("env", "test")
            ))
            .onDelete("cancel")
            .build());

    }
}
```
```yaml
resources:
  topic:
    type: gcp:pubsub:Topic
    properties:
      name: dataflow-job1
  bucket1:
    type: gcp:storage:Bucket
    properties:
      name: tf-test-bucket1
      location: US
      forceDestroy: true
  bucket2:
    type: gcp:storage:Bucket
    properties:
      name: tf-test-bucket2
      location: US
      forceDestroy: true
  pubsubStream:
    type: gcp:dataflow:Job
    name: pubsub_stream
    properties:
      name: tf-test-dataflow-job1
      templateGcsPath: gs://my-bucket/templates/template_file
      tempGcsLocation: gs://my-bucket/tmp_dir
      enableStreamingEngine: true
      parameters:
        inputFilePattern: ${bucket1.url}/*.json
        outputTopic: ${topic.id}
      transformNameMapping:
        name: test_job
        env: test
      onDelete: cancel
```
<!--End PulumiCodeChooser -->

## Note on "destroy" / "apply"

There are many types of Dataflow jobs.  Some Dataflow jobs run constantly, getting new data from (e.g.) a GCS bucket, and outputting data continuously.  Some jobs process a set amount of data then terminate.  All jobs can fail while running due to programming errors or other issues.  In this way, Dataflow jobs are different from most other Google resources.

The Dataflow resource is considered 'existing' while it is in a nonterminal state.  If it reaches a terminal state (e.g. 'FAILED', 'COMPLETE', 'CANCELLED'), it will be recreated on the next 'apply'.  This is as expected for jobs which run continuously, but may surprise users who use this resource for other kinds of Dataflow jobs.

A Dataflow job which is 'destroyed' may be "cancelled" or "drained".  If "cancelled", the job terminates - any data written remains where it is, but no new data will be processed.  If "drained", no new data will enter the pipeline, but any data currently in the pipeline will finish being processed.  The default is "drain". When `on_delete` is set to `"drain"` in the configuration, you may experience a long wait for your `pulumi destroy` to complete.

You can potentially short-circuit the wait by setting `skip_wait_on_job_termination` to `true`, but beware that unless you take active steps to ensure that the job `name` parameter changes between instances, the name will conflict and the launch of the new job will fail. One way to do this is with a random_id resource, for example:

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";
import * as random from "@pulumi/random";

const config = new pulumi.Config();
const bigDataJobSubscriptionId = config.get("bigDataJobSubscriptionId") || "projects/myproject/subscriptions/messages";
const bigDataJobNameSuffix = new random.RandomId("big_data_job_name_suffix", {
    byteLength: 4,
    keepers: {
        region: region,
        subscription_id: bigDataJobSubscriptionId,
    },
});
const bigDataJob = new gcp.dataflow.FlexTemplateJob("big_data_job", {
    name: pulumi.interpolate`dataflow-flextemplates-job-${bigDataJobNameSuffix.dec}`,
    region: region,
    containerSpecGcsPath: "gs://my-bucket/templates/template.json",
    skipWaitOnJobTermination: true,
    parameters: {
        inputSubscription: bigDataJobSubscriptionId,
    },
});
```
```python
import pulumi
import pulumi_gcp as gcp
import pulumi_random as random

config = pulumi.Config()
big_data_job_subscription_id = config.get("bigDataJobSubscriptionId")
if big_data_job_subscription_id is None:
    big_data_job_subscription_id = "projects/myproject/subscriptions/messages"
big_data_job_name_suffix = random.RandomId("big_data_job_name_suffix",
    byte_length=4,
    keepers={
        "region": region,
        "subscription_id": big_data_job_subscription_id,
    })
big_data_job = gcp.dataflow.FlexTemplateJob("big_data_job",
    name=big_data_job_name_suffix.dec.apply(lambda dec: f"dataflow-flextemplates-job-{dec}"),
    region=region,
    container_spec_gcs_path="gs://my-bucket/templates/template.json",
    skip_wait_on_job_termination=True,
    parameters={
        "inputSubscription": big_data_job_subscription_id,
    })
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;
using Random = Pulumi.Random;

return await Deployment.RunAsync(() => 
{
    var config = new Config();
    var bigDataJobSubscriptionId = config.Get("bigDataJobSubscriptionId") ?? "projects/myproject/subscriptions/messages";
    var bigDataJobNameSuffix = new Random.RandomId("big_data_job_name_suffix", new()
    {
        ByteLength = 4,
        Keepers = 
        {
            { "region", region },
            { "subscription_id", bigDataJobSubscriptionId },
        },
    });

    var bigDataJob = new Gcp.Dataflow.FlexTemplateJob("big_data_job", new()
    {
        Name = bigDataJobNameSuffix.Dec.Apply(dec => $"dataflow-flextemplates-job-{dec}"),
        Region = region,
        ContainerSpecGcsPath = "gs://my-bucket/templates/template.json",
        SkipWaitOnJobTermination = true,
        Parameters = 
        {
            { "inputSubscription", bigDataJobSubscriptionId },
        },
    });

});
```
```go
package main

import (
	"fmt"

	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/dataflow"
	"github.com/pulumi/pulumi-random/sdk/v4/go/random"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi/config"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		cfg := config.New(ctx, "")
		bigDataJobSubscriptionId := "projects/myproject/subscriptions/messages"
		if param := cfg.Get("bigDataJobSubscriptionId"); param != "" {
			bigDataJobSubscriptionId = param
		}
		bigDataJobNameSuffix, err := random.NewRandomId(ctx, "big_data_job_name_suffix", &random.RandomIdArgs{
			ByteLength: pulumi.Int(4),
			Keepers: pulumi.StringMap{
				"region":          pulumi.Any(region),
				"subscription_id": pulumi.String(bigDataJobSubscriptionId),
			},
		})
		if err != nil {
			return err
		}
		_, err = dataflow.NewFlexTemplateJob(ctx, "big_data_job", &dataflow.FlexTemplateJobArgs{
			Name: bigDataJobNameSuffix.Dec.ApplyT(func(dec string) (string, error) {
				return fmt.Sprintf("dataflow-flextemplates-job-%v", dec), nil
			}).(pulumi.StringOutput),
			Region:                   pulumi.Any(region),
			ContainerSpecGcsPath:     pulumi.String("gs://my-bucket/templates/template.json"),
			SkipWaitOnJobTermination: pulumi.Bool(true),
			Parameters: pulumi.StringMap{
				"inputSubscription": pulumi.String(bigDataJobSubscriptionId),
			},
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.random.RandomId;
import com.pulumi.random.RandomIdArgs;
import com.pulumi.gcp.dataflow.FlexTemplateJob;
import com.pulumi.gcp.dataflow.FlexTemplateJobArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        final var config = ctx.config();
        final var bigDataJobSubscriptionId = config.get("bigDataJobSubscriptionId").orElse("projects/myproject/subscriptions/messages");
        var bigDataJobNameSuffix = new RandomId("bigDataJobNameSuffix", RandomIdArgs.builder()
            .byteLength(4)
            .keepers(Map.ofEntries(
                Map.entry("region", region),
                Map.entry("subscription_id", bigDataJobSubscriptionId)
            ))
            .build());

        var bigDataJob = new FlexTemplateJob("bigDataJob", FlexTemplateJobArgs.builder()
            .name(bigDataJobNameSuffix.dec().applyValue(dec -> String.format("dataflow-flextemplates-job-%s", dec)))
            .region(region)
            .containerSpecGcsPath("gs://my-bucket/templates/template.json")
            .skipWaitOnJobTermination(true)
            .parameters(Map.of("inputSubscription", bigDataJobSubscriptionId))
            .build());

    }
}
```
```yaml
configuration:
  bigDataJobSubscriptionId:
    type: string
    default: projects/myproject/subscriptions/messages
resources:
  bigDataJobNameSuffix:
    type: random:RandomId
    name: big_data_job_name_suffix
    properties:
      byteLength: 4
      keepers:
        region: ${region}
        subscription_id: ${bigDataJobSubscriptionId}
  bigDataJob:
    type: gcp:dataflow:FlexTemplateJob
    name: big_data_job
    properties:
      name: dataflow-flextemplates-job-${bigDataJobNameSuffix.dec}
      region: ${region}
      containerSpecGcsPath: gs://my-bucket/templates/template.json
      skipWaitOnJobTermination: true
      parameters:
        inputSubscription: ${bigDataJobSubscriptionId}
```
<!--End PulumiCodeChooser -->

## Import

Dataflow jobs can be imported using the job `id` e.g.

* `{{id}}`

When using the `pulumi import` command, dataflow jobs can be imported using one of the formats above. For example:

```sh
$ pulumi import gcp:dataflow/job:Job default {{id}}
```


additionalExperimentsB*" pList of experiments that should be used by the job. An example value is `["enable_stackdriver_agent_metrics"]`.
¾
enableStreamingEngineB
 Enable/disable the use of [Streaming Engine](https://cloud.google.com/dataflow/docs/guides/deploying-a-pipeline#streaming-engine) for the job. Note that Streaming Engine is enabled by default for pipelines developed against the Beam SDK for Python v2.21.0 or later when using Python 3.
s
ipConfigurationB" ZThe configuration for VM IPs.  Options are `"WORKER_IP_PUBLIC"` or `"WORKER_IP_PRIVATE"`.


kmsKeyNameB" The name for the Cloud KMS key for the job. Key format is: `projects/PROJECT_ID/locations/LOCATION/keyRings/KEY_RING/cryptoKeys/KEY`
§
labelsB2" User labels to be specified for the job. Keys and values should follow the restrictions
specified in the [labeling restrictions](https://cloud.google.com/compute/docs/labeling-resources#restrictions) page.
**Note**: This field is non-authoritative, and will only manage the labels present in your configuration. Please refer to the field `effective_labels` for all of the labels present on the resource.
:
machineTypeB" %The machine type to use for the job.


maxWorkersB sThe number of workers permitted to work on the job.  More workers may improve processing speed at additional cost.
D
nameB" 6A unique name for the resource, required by Dataflow.
k
networkB" ZThe network to which VMs will be assigned. If it is not provided, "default" will be used.
x
onDeleteB" fOne of "drain" or "cancel".  Specifies behavior of deletion during `pulumi destroy`.  See above note.


parametersB2" ì**Template specific** Key/Value pairs to be forwarded to the pipeline's options; keys are
case-sensitive based on the language on which the pipeline is coded, mostly Java.
**Note**: do not configure Dataflow options here in parameters.
q
projectB" `The project in which the resource belongs. If it is not provided, the provider project is used.
@
regionB" 0The region in which the created job should run.
Þ
serviceAccountEmailB" ÀThe Service Account email used to create the job. This should be just an email e.g. `myserviceaccount@myproject.iam.gserviceaccount.com`. Do not include any `serviceAccount:` or other prefix.
ß
skipWaitOnJobTerminationB
 ¼If set to `true`, Pulumi will treat `DRAINING` and `CANCELLING` as terminal states when deleting the resource, and will remove the resource from Pulumi state and move on.  See above note.


subnetworkB" óThe subnetwork to which VMs will be assigned. Should be of the form "regions/REGION/subnetworks/SUBNETWORK". If the [subnetwork is located in a Shared VPC network](https://cloud.google.com/dataflow/docs/guides/specifying-networks#shared), you must use the complete URL. For example `"googleapis.com/compute/v1/projects/PROJECT_ID/regions/REGION/subnetworks/SUBNET_NAME"`
k
tempGcsLocation" TA writeable location on GCS for the Dataflow job to dump its temporary data.

- - -
B
templateGcsPath" +The GCS path to the Dataflow job template.
ã
transformNameMappingB2" ÂOnly applicable when updating a pipeline. Map of transform name prefixes of the job to be replaced with the corresponding name prefixes of the new job. This field is not used outside of update.
n
zoneB" `The zone in which the created job should run. If it is not provided, the provider zone is used.
"
additionalExperiments*" pList of experiments that should be used by the job. An example value is `["enable_stackdriver_agent_metrics"]`.
"¦
effectiveLabels2" All of labels (key/value pairs) present on the resource in GCP, including the labels configured through Pulumi, other clients and services.
"¾
enableStreamingEngineB
 Enable/disable the use of [Streaming Engine](https://cloud.google.com/dataflow/docs/guides/deploying-a-pipeline#streaming-engine) for the job. Note that Streaming Engine is enabled by default for pipelines developed against the Beam SDK for Python v2.21.0 or later when using Python 3.
"s
ipConfigurationB" ZThe configuration for VM IPs.  Options are `"WORKER_IP_PUBLIC"` or `"WORKER_IP_PRIVATE"`.
"(
jobId" The unique ID of this job.
"

kmsKeyNameB" The name for the Cloud KMS key for the job. Key format is: `projects/PROJECT_ID/locations/LOCATION/keyRings/KEY_RING/cryptoKeys/KEY`
"§
labelsB2" User labels to be specified for the job. Keys and values should follow the restrictions
specified in the [labeling restrictions](https://cloud.google.com/compute/docs/labeling-resources#restrictions) page.
**Note**: This field is non-authoritative, and will only manage the labels present in your configuration. Please refer to the field `effective_labels` for all of the labels present on the resource.
":
machineTypeB" %The machine type to use for the job.
"

maxWorkersB sThe number of workers permitted to work on the job.  More workers may improve processing speed at additional cost.
"B
name" 6A unique name for the resource, required by Dataflow.
"k
networkB" ZThe network to which VMs will be assigned. If it is not provided, "default" will be used.
"x
onDeleteB" fOne of "drain" or "cancel".  Specifies behavior of deletion during `pulumi destroy`.  See above note.
"

parametersB2" ì**Template specific** Key/Value pairs to be forwarded to the pipeline's options; keys are
case-sensitive based on the language on which the pipeline is coded, mostly Java.
**Note**: do not configure Dataflow options here in parameters.
"o
project" `The project in which the resource belongs. If it is not provided, the provider project is used.
"
pulumiLabels2" mThe combination of labels configured directly on the resource and default labels configured on the provider.
"@
regionB" 0The region in which the created job should run.
"Þ
serviceAccountEmailB" ÀThe Service Account email used to create the job. This should be just an email e.g. `myserviceaccount@myproject.iam.gserviceaccount.com`. Do not include any `serviceAccount:` or other prefix.
"ß
skipWaitOnJobTerminationB
 ¼If set to `true`, Pulumi will treat `DRAINING` and `CANCELLING` as terminal states when deleting the resource, and will remove the resource from Pulumi state and move on.  See above note.
"ª
state" The current state of the resource, selected from the [JobState enum](https://cloud.google.com/dataflow/docs/reference/rest/v1b3/projects.jobs#Job.JobState)
"

subnetworkB" óThe subnetwork to which VMs will be assigned. Should be of the form "regions/REGION/subnetworks/SUBNETWORK". If the [subnetwork is located in a Shared VPC network](https://cloud.google.com/dataflow/docs/guides/specifying-networks#shared), you must use the complete URL. For example `"googleapis.com/compute/v1/projects/PROJECT_ID/regions/REGION/subnetworks/SUBNET_NAME"`
"k
tempGcsLocation" TA writeable location on GCS for the Dataflow job to dump its temporary data.

- - -
"B
templateGcsPath" +The GCS path to the Dataflow job template.
"ã
transformNameMappingB2" ÂOnly applicable when updating a pipeline. Map of transform name prefixes of the job to be replaced with the corresponding name prefixes of the new job. This field is not used outside of update.
"
type" The type of this job, selected from the [JobType enum](https://cloud.google.com/dataflow/docs/reference/rest/v1b3/projects.jobs#Job.JobType)
"n
zoneB" `The zone in which the created job should run. If it is not provided, the provider zone is used.
*É¢
4
dataflowPipelinegcp:dataflow/pipeline:PipelineîlThe main pipeline entity and all the necessary metadata for launching and managing linked jobs.


To get more information about Pipeline, see:

* [API documentation](https://cloud.google.com/dataflow/docs/reference/data-pipelines/rest/v1/projects.locations.pipelines)
* How-to Guides
    * [Official Documentation](https://cloud.google.com/dataflow)

## Example Usage

### Data Pipeline Pipeline


<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const serviceAccount = new gcp.serviceaccount.Account("service_account", {
    accountId: "my-account",
    displayName: "Service Account",
});
const primary = new gcp.dataflow.Pipeline("primary", {
    name: "my-pipeline",
    displayName: "my-pipeline",
    type: "PIPELINE_TYPE_BATCH",
    state: "STATE_ACTIVE",
    region: "us-central1",
    workload: {
        dataflowLaunchTemplateRequest: {
            projectId: "my-project",
            gcsPath: "gs://my-bucket/path",
            launchParameters: {
                jobName: "my-job",
                parameters: {
                    name: "wrench",
                },
                environment: {
                    numWorkers: 5,
                    maxWorkers: 5,
                    zone: "us-centra1-a",
                    serviceAccountEmail: serviceAccount.email,
                    network: "default",
                    tempLocation: "gs://my-bucket/tmp_dir",
                    bypassTempDirValidation: false,
                    machineType: "E2",
                    additionalUserLabels: {
                        context: "test",
                    },
                    workerRegion: "us-central1",
                    workerZone: "us-central1-a",
                    enableStreamingEngine: false,
                },
                update: false,
                transformNameMapping: {
                    name: "wrench",
                },
            },
            location: "us-central1",
        },
    },
    scheduleInfo: {
        schedule: "* */2 * * *",
    },
});
```
```python
import pulumi
import pulumi_gcp as gcp

service_account = gcp.serviceaccount.Account("service_account",
    account_id="my-account",
    display_name="Service Account")
primary = gcp.dataflow.Pipeline("primary",
    name="my-pipeline",
    display_name="my-pipeline",
    type="PIPELINE_TYPE_BATCH",
    state="STATE_ACTIVE",
    region="us-central1",
    workload={
        "dataflow_launch_template_request": {
            "project_id": "my-project",
            "gcs_path": "gs://my-bucket/path",
            "launch_parameters": {
                "job_name": "my-job",
                "parameters": {
                    "name": "wrench",
                },
                "environment": {
                    "num_workers": 5,
                    "max_workers": 5,
                    "zone": "us-centra1-a",
                    "service_account_email": service_account.email,
                    "network": "default",
                    "temp_location": "gs://my-bucket/tmp_dir",
                    "bypass_temp_dir_validation": False,
                    "machine_type": "E2",
                    "additional_user_labels": {
                        "context": "test",
                    },
                    "worker_region": "us-central1",
                    "worker_zone": "us-central1-a",
                    "enable_streaming_engine": False,
                },
                "update": False,
                "transform_name_mapping": {
                    "name": "wrench",
                },
            },
            "location": "us-central1",
        },
    },
    schedule_info={
        "schedule": "* */2 * * *",
    })
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var serviceAccount = new Gcp.ServiceAccount.Account("service_account", new()
    {
        AccountId = "my-account",
        DisplayName = "Service Account",
    });

    var primary = new Gcp.Dataflow.Pipeline("primary", new()
    {
        Name = "my-pipeline",
        DisplayName = "my-pipeline",
        Type = "PIPELINE_TYPE_BATCH",
        State = "STATE_ACTIVE",
        Region = "us-central1",
        Workload = new Gcp.Dataflow.Inputs.PipelineWorkloadArgs
        {
            DataflowLaunchTemplateRequest = new Gcp.Dataflow.Inputs.PipelineWorkloadDataflowLaunchTemplateRequestArgs
            {
                ProjectId = "my-project",
                GcsPath = "gs://my-bucket/path",
                LaunchParameters = new Gcp.Dataflow.Inputs.PipelineWorkloadDataflowLaunchTemplateRequestLaunchParametersArgs
                {
                    JobName = "my-job",
                    Parameters = 
                    {
                        { "name", "wrench" },
                    },
                    Environment = new Gcp.Dataflow.Inputs.PipelineWorkloadDataflowLaunchTemplateRequestLaunchParametersEnvironmentArgs
                    {
                        NumWorkers = 5,
                        MaxWorkers = 5,
                        Zone = "us-centra1-a",
                        ServiceAccountEmail = serviceAccount.Email,
                        Network = "default",
                        TempLocation = "gs://my-bucket/tmp_dir",
                        BypassTempDirValidation = false,
                        MachineType = "E2",
                        AdditionalUserLabels = 
                        {
                            { "context", "test" },
                        },
                        WorkerRegion = "us-central1",
                        WorkerZone = "us-central1-a",
                        EnableStreamingEngine = false,
                    },
                    Update = false,
                    TransformNameMapping = 
                    {
                        { "name", "wrench" },
                    },
                },
                Location = "us-central1",
            },
        },
        ScheduleInfo = new Gcp.Dataflow.Inputs.PipelineScheduleInfoArgs
        {
            Schedule = "* */2 * * *",
        },
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/dataflow"
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/serviceaccount"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		serviceAccount, err := serviceaccount.NewAccount(ctx, "service_account", &serviceaccount.AccountArgs{
			AccountId:   pulumi.String("my-account"),
			DisplayName: pulumi.String("Service Account"),
		})
		if err != nil {
			return err
		}
		_, err = dataflow.NewPipeline(ctx, "primary", &dataflow.PipelineArgs{
			Name:        pulumi.String("my-pipeline"),
			DisplayName: pulumi.String("my-pipeline"),
			Type:        pulumi.String("PIPELINE_TYPE_BATCH"),
			State:       pulumi.String("STATE_ACTIVE"),
			Region:      pulumi.String("us-central1"),
			Workload: &dataflow.PipelineWorkloadArgs{
				DataflowLaunchTemplateRequest: &dataflow.PipelineWorkloadDataflowLaunchTemplateRequestArgs{
					ProjectId: pulumi.String("my-project"),
					GcsPath:   pulumi.String("gs://my-bucket/path"),
					LaunchParameters: &dataflow.PipelineWorkloadDataflowLaunchTemplateRequestLaunchParametersArgs{
						JobName: pulumi.String("my-job"),
						Parameters: pulumi.StringMap{
							"name": pulumi.String("wrench"),
						},
						Environment: &dataflow.PipelineWorkloadDataflowLaunchTemplateRequestLaunchParametersEnvironmentArgs{
							NumWorkers:              pulumi.Int(5),
							MaxWorkers:              pulumi.Int(5),
							Zone:                    pulumi.String("us-centra1-a"),
							ServiceAccountEmail:     serviceAccount.Email,
							Network:                 pulumi.String("default"),
							TempLocation:            pulumi.String("gs://my-bucket/tmp_dir"),
							BypassTempDirValidation: pulumi.Bool(false),
							MachineType:             pulumi.String("E2"),
							AdditionalUserLabels: pulumi.StringMap{
								"context": pulumi.String("test"),
							},
							WorkerRegion:          pulumi.String("us-central1"),
							WorkerZone:            pulumi.String("us-central1-a"),
							EnableStreamingEngine: pulumi.Bool(false),
						},
						Update: pulumi.Bool(false),
						TransformNameMapping: pulumi.StringMap{
							"name": pulumi.String("wrench"),
						},
					},
					Location: pulumi.String("us-central1"),
				},
			},
			ScheduleInfo: &dataflow.PipelineScheduleInfoArgs{
				Schedule: pulumi.String("* */2 * * *"),
			},
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.serviceaccount.Account;
import com.pulumi.gcp.serviceaccount.AccountArgs;
import com.pulumi.gcp.dataflow.Pipeline;
import com.pulumi.gcp.dataflow.PipelineArgs;
import com.pulumi.gcp.dataflow.inputs.PipelineWorkloadArgs;
import com.pulumi.gcp.dataflow.inputs.PipelineWorkloadDataflowLaunchTemplateRequestArgs;
import com.pulumi.gcp.dataflow.inputs.PipelineWorkloadDataflowLaunchTemplateRequestLaunchParametersArgs;
import com.pulumi.gcp.dataflow.inputs.PipelineWorkloadDataflowLaunchTemplateRequestLaunchParametersEnvironmentArgs;
import com.pulumi.gcp.dataflow.inputs.PipelineScheduleInfoArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        var serviceAccount = new Account("serviceAccount", AccountArgs.builder()
            .accountId("my-account")
            .displayName("Service Account")
            .build());

        var primary = new Pipeline("primary", PipelineArgs.builder()
            .name("my-pipeline")
            .displayName("my-pipeline")
            .type("PIPELINE_TYPE_BATCH")
            .state("STATE_ACTIVE")
            .region("us-central1")
            .workload(PipelineWorkloadArgs.builder()
                .dataflowLaunchTemplateRequest(PipelineWorkloadDataflowLaunchTemplateRequestArgs.builder()
                    .projectId("my-project")
                    .gcsPath("gs://my-bucket/path")
                    .launchParameters(PipelineWorkloadDataflowLaunchTemplateRequestLaunchParametersArgs.builder()
                        .jobName("my-job")
                        .parameters(Map.of("name", "wrench"))
                        .environment(PipelineWorkloadDataflowLaunchTemplateRequestLaunchParametersEnvironmentArgs.builder()
                            .numWorkers(5)
                            .maxWorkers(5)
                            .zone("us-centra1-a")
                            .serviceAccountEmail(serviceAccount.email())
                            .network("default")
                            .tempLocation("gs://my-bucket/tmp_dir")
                            .bypassTempDirValidation(false)
                            .machineType("E2")
                            .additionalUserLabels(Map.of("context", "test"))
                            .workerRegion("us-central1")
                            .workerZone("us-central1-a")
                            .enableStreamingEngine("false")
                            .build())
                        .update(false)
                        .transformNameMapping(Map.of("name", "wrench"))
                        .build())
                    .location("us-central1")
                    .build())
                .build())
            .scheduleInfo(PipelineScheduleInfoArgs.builder()
                .schedule("* */2 * * *")
                .build())
            .build());

    }
}
```
```yaml
resources:
  serviceAccount:
    type: gcp:serviceaccount:Account
    name: service_account
    properties:
      accountId: my-account
      displayName: Service Account
  primary:
    type: gcp:dataflow:Pipeline
    properties:
      name: my-pipeline
      displayName: my-pipeline
      type: PIPELINE_TYPE_BATCH
      state: STATE_ACTIVE
      region: us-central1
      workload:
        dataflowLaunchTemplateRequest:
          projectId: my-project
          gcsPath: gs://my-bucket/path
          launchParameters:
            jobName: my-job
            parameters:
              name: wrench
            environment:
              numWorkers: 5
              maxWorkers: 5
              zone: us-centra1-a
              serviceAccountEmail: ${serviceAccount.email}
              network: default
              tempLocation: gs://my-bucket/tmp_dir
              bypassTempDirValidation: false
              machineType: E2
              additionalUserLabels:
                context: test
              workerRegion: us-central1
              workerZone: us-central1-a
              enableStreamingEngine: 'false'
            update: false
            transformNameMapping:
              name: wrench
          location: us-central1
      scheduleInfo:
        schedule: '* */2 * * *'
```
<!--End PulumiCodeChooser -->

## Import

Pipeline can be imported using any of these accepted formats:

* `projects/{{project}}/locations/{{region}}/pipelines/{{name}}`

* `{{project}}/{{region}}/{{name}}`

* `{{region}}/{{name}}`

* `{{name}}`

When using the `pulumi import` command, Pipeline can be imported using one of the formats above. For example:

```sh
$ pulumi import gcp:dataflow/pipeline:Pipeline default projects/{{project}}/locations/{{region}}/pipelines/{{name}}
```

```sh
$ pulumi import gcp:dataflow/pipeline:Pipeline default {{project}}/{{region}}/{{name}}
```

```sh
$ pulumi import gcp:dataflow/pipeline:Pipeline default {{region}}/{{name}}
```

```sh
$ pulumi import gcp:dataflow/pipeline:Pipeline default {{name}}
```


displayNameB" }The display name of the pipeline. It can contain only letters ([A-Za-z]), numbers ([0-9]), hyphens (-), and underscores (_).
Ä
nameB" µ"The pipeline name. For example': 'projects/PROJECT_ID/locations/LOCATION_ID/pipelines/PIPELINE_ID."
"- PROJECT_ID can contain letters ([A-Za-z]), numbers ([0-9]), hyphens (-), colons (:), and periods (.). For more information, see Identifying projects."
"LOCATION_ID is the canonical ID for the pipeline's location. The list of available locations can be obtained by calling google.cloud.location.Locations.ListLocations. Note that the Data Pipelines service is not available in all regions. It depends on Cloud Scheduler, an App Engine application, so it's only available in App Engine regions."
"PIPELINE_ID is the ID of the pipeline. Must be unique for the selected project and location."

pipelineSourcesB2" ùThe sources of the pipeline (for example, Dataplex). The keys and values are set by the corresponding sources during pipeline creation.
An object containing a list of "key": value pairs. Example: { "name": "wrench", "mass": "1.3kg", "count": "3" }.
{
projectB" jThe ID of the project in which the resource belongs.
If it is not provided, the provider project is used.
*
regionB" A reference to the region
¿
scheduleInfo^B\:Z
X
dataflowPipelineScheduleInfo6gcp:dataflow/PipelineScheduleInfo:PipelineScheduleInfoÎInternal scheduling information for a pipeline. If this information is provided, periodic jobs will be created per the schedule. If not, users are responsible for creating jobs externally.
https://cloud.google.com/dataflow/docs/reference/data-pipelines/rest/v1/projects.locations.pipelines#schedulespec
Structure is documented below.
½
schedulerServiceAccountEmailB" Optional. A service account email to be used with the Cloud Scheduler job. If not specified, the default compute engine service account will be used.

state" ôThe state of the pipeline. When the pipeline is created, the state is set to 'PIPELINE_STATE_ACTIVE' by default. State changes can be requested by setting the state to stopping, paused, or resuming. State cannot be changed through pipelines.patch requests.
https://cloud.google.com/dataflow/docs/reference/data-pipelines/rest/v1/projects.locations.pipelines#state
Possible values are: `STATE_UNSPECIFIED`, `STATE_RESUMING`, `STATE_ACTIVE`, `STATE_STOPPING`, `STATE_ARCHIVED`, `STATE_PAUSED`.


- - -
á
type" ÔThe type of the pipeline. This field affects the scheduling of the pipeline and the type of metrics to show for the pipeline.
https://cloud.google.com/dataflow/docs/reference/data-pipelines/rest/v1/projects.locations.pipelines#pipelinetype
Possible values are: `PIPELINE_TYPE_UNSPECIFIED`, `PIPELINE_TYPE_BATCH`, `PIPELINE_TYPE_STREAMING`.

workloadRBP:N
L
dataflowPipelineWorkload.gcp:dataflow/PipelineWorkload:PipelineWorkload¹Workload information for creating new jobs.
https://cloud.google.com/dataflow/docs/reference/data-pipelines/rest/v1/projects.locations.pipelines#workload
Structure is documented below.
"

createTime" The timestamp when the pipeline was initially created. Set by the Data Pipelines service.
A timestamp in RFC3339 UTC "Zulu" format, with nanosecond resolution and up to nine fractional digits. Examples: "2014-10-02T15:01:23Z" and "2014-10-02T15:01:23.045123456Z".
"
displayNameB" }The display name of the pipeline. It can contain only letters ([A-Za-z]), numbers ([0-9]), hyphens (-), and underscores (_).
" 
jobCount Number of jobs.
"
lastUpdateTime" The timestamp when the pipeline was last modified. Set by the Data Pipelines service.
A timestamp in RFC3339 UTC "Zulu" format, with nanosecond resolution and up to nine fractional digits. Examples: "2014-10-02T15:01:23Z" and "2014-10-02T15:01:23.045123456Z".
"Â
name" µ"The pipeline name. For example': 'projects/PROJECT_ID/locations/LOCATION_ID/pipelines/PIPELINE_ID."
"- PROJECT_ID can contain letters ([A-Za-z]), numbers ([0-9]), hyphens (-), colons (:), and periods (.). For more information, see Identifying projects."
"LOCATION_ID is the canonical ID for the pipeline's location. The list of available locations can be obtained by calling google.cloud.location.Locations.ListLocations. Note that the Data Pipelines service is not available in all regions. It depends on Cloud Scheduler, an App Engine application, so it's only available in App Engine regions."
"PIPELINE_ID is the ID of the pipeline. Must be unique for the selected project and location."
"
pipelineSourcesB2" ùThe sources of the pipeline (for example, Dataplex). The keys and values are set by the corresponding sources during pipeline creation.
An object containing a list of "key": value pairs. Example: { "name": "wrench", "mass": "1.3kg", "count": "3" }.
"y
project" jThe ID of the project in which the resource belongs.
If it is not provided, the provider project is used.
"*
regionB" A reference to the region
"¿
scheduleInfo^B\:Z
X
dataflowPipelineScheduleInfo6gcp:dataflow/PipelineScheduleInfo:PipelineScheduleInfoÎInternal scheduling information for a pipeline. If this information is provided, periodic jobs will be created per the schedule. If not, users are responsible for creating jobs externally.
https://cloud.google.com/dataflow/docs/reference/data-pipelines/rest/v1/projects.locations.pipelines#schedulespec
Structure is documented below.
"»
schedulerServiceAccountEmail" Optional. A service account email to be used with the Cloud Scheduler job. If not specified, the default compute engine service account will be used.
"
state" ôThe state of the pipeline. When the pipeline is created, the state is set to 'PIPELINE_STATE_ACTIVE' by default. State changes can be requested by setting the state to stopping, paused, or resuming. State cannot be changed through pipelines.patch requests.
https://cloud.google.com/dataflow/docs/reference/data-pipelines/rest/v1/projects.locations.pipelines#state
Possible values are: `STATE_UNSPECIFIED`, `STATE_RESUMING`, `STATE_ACTIVE`, `STATE_STOPPING`, `STATE_ARCHIVED`, `STATE_PAUSED`.


- - -
"á
type" ÔThe type of the pipeline. This field affects the scheduling of the pipeline and the type of metrics to show for the pipeline.
https://cloud.google.com/dataflow/docs/reference/data-pipelines/rest/v1/projects.locations.pipelines#pipelinetype
Possible values are: `PIPELINE_TYPE_UNSPECIFIED`, `PIPELINE_TYPE_BATCH`, `PIPELINE_TYPE_STREAMING`.
"
workloadRBP:N
L
dataflowPipelineWorkload.gcp:dataflow/PipelineWorkload:PipelineWorkload¹Workload information for creating new jobs.
https://cloud.google.com/dataflow/docs/reference/data-pipelines/rest/v1/projects.locations.pipelines#workload
Structure is documented below.
*Ö
:
dataform
Repository"gcp:dataform/repository:Repositoryk## Example Usage

### Dataform Repository


<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const secret = new gcp.secretmanager.Secret("secret", {
    secretId: "my-secret",
    replication: {
        auto: {},
    },
});
const secretVersion = new gcp.secretmanager.SecretVersion("secret_version", {
    secret: secret.id,
    secretData: "secret-data",
});
const keyring = new gcp.kms.KeyRing("keyring", {
    name: "example-key-ring",
    location: "us-central1",
});
const exampleKey = new gcp.kms.CryptoKey("example_key", {
    name: "example-crypto-key-name",
    keyRing: keyring.id,
});
const cryptoKeyBinding = new gcp.kms.CryptoKeyIAMBinding("crypto_key_binding", {
    cryptoKeyId: exampleKey.id,
    role: "roles/cloudkms.cryptoKeyEncrypterDecrypter",
    members: [`serviceAccount:service-${project.number}@gcp-sa-dataform.iam.gserviceaccount.com`],
});
const dataformRepository = new gcp.dataform.Repository("dataform_repository", {
    name: "dataform_repository",
    displayName: "dataform_repository",
    npmrcEnvironmentVariablesSecretVersion: secretVersion.id,
    kmsKeyName: exampleKey.id,
    labels: {
        label_foo1: "label-bar1",
    },
    gitRemoteSettings: {
        url: "https://github.com/OWNER/REPOSITORY.git",
        defaultBranch: "main",
        authenticationTokenSecretVersion: secretVersion.id,
    },
    workspaceCompilationOverrides: {
        defaultDatabase: "database",
        schemaSuffix: "_suffix",
        tablePrefix: "prefix_",
    },
}, {
    dependsOn: [cryptoKeyBinding],
});
```
```python
import pulumi
import pulumi_gcp as gcp

secret = gcp.secretmanager.Secret("secret",
    secret_id="my-secret",
    replication={
        "auto": {},
    })
secret_version = gcp.secretmanager.SecretVersion("secret_version",
    secret=secret.id,
    secret_data="secret-data")
keyring = gcp.kms.KeyRing("keyring",
    name="example-key-ring",
    location="us-central1")
example_key = gcp.kms.CryptoKey("example_key",
    name="example-crypto-key-name",
    key_ring=keyring.id)
crypto_key_binding = gcp.kms.CryptoKeyIAMBinding("crypto_key_binding",
    crypto_key_id=example_key.id,
    role="roles/cloudkms.cryptoKeyEncrypterDecrypter",
    members=[f"serviceAccount:service-{project['number']}@gcp-sa-dataform.iam.gserviceaccount.com"])
dataform_repository = gcp.dataform.Repository("dataform_repository",
    name="dataform_repository",
    display_name="dataform_repository",
    npmrc_environment_variables_secret_version=secret_version.id,
    kms_key_name=example_key.id,
    labels={
        "label_foo1": "label-bar1",
    },
    git_remote_settings={
        "url": "https://github.com/OWNER/REPOSITORY.git",
        "default_branch": "main",
        "authentication_token_secret_version": secret_version.id,
    },
    workspace_compilation_overrides={
        "default_database": "database",
        "schema_suffix": "_suffix",
        "table_prefix": "prefix_",
    },
    opts = pulumi.ResourceOptions(depends_on=[crypto_key_binding]))
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var secret = new Gcp.SecretManager.Secret("secret", new()
    {
        SecretId = "my-secret",
        Replication = new Gcp.SecretManager.Inputs.SecretReplicationArgs
        {
            Auto = null,
        },
    });

    var secretVersion = new Gcp.SecretManager.SecretVersion("secret_version", new()
    {
        Secret = secret.Id,
        SecretData = "secret-data",
    });

    var keyring = new Gcp.Kms.KeyRing("keyring", new()
    {
        Name = "example-key-ring",
        Location = "us-central1",
    });

    var exampleKey = new Gcp.Kms.CryptoKey("example_key", new()
    {
        Name = "example-crypto-key-name",
        KeyRing = keyring.Id,
    });

    var cryptoKeyBinding = new Gcp.Kms.CryptoKeyIAMBinding("crypto_key_binding", new()
    {
        CryptoKeyId = exampleKey.Id,
        Role = "roles/cloudkms.cryptoKeyEncrypterDecrypter",
        Members = new[]
        {
            $"serviceAccount:service-{project.Number}@gcp-sa-dataform.iam.gserviceaccount.com",
        },
    });

    var dataformRepository = new Gcp.Dataform.Repository("dataform_repository", new()
    {
        Name = "dataform_repository",
        DisplayName = "dataform_repository",
        NpmrcEnvironmentVariablesSecretVersion = secretVersion.Id,
        KmsKeyName = exampleKey.Id,
        Labels = 
        {
            { "label_foo1", "label-bar1" },
        },
        GitRemoteSettings = new Gcp.Dataform.Inputs.RepositoryGitRemoteSettingsArgs
        {
            Url = "https://github.com/OWNER/REPOSITORY.git",
            DefaultBranch = "main",
            AuthenticationTokenSecretVersion = secretVersion.Id,
        },
        WorkspaceCompilationOverrides = new Gcp.Dataform.Inputs.RepositoryWorkspaceCompilationOverridesArgs
        {
            DefaultDatabase = "database",
            SchemaSuffix = "_suffix",
            TablePrefix = "prefix_",
        },
    }, new CustomResourceOptions
    {
        DependsOn =
        {
            cryptoKeyBinding,
        },
    });

});
```
```go
package main

import (
	"fmt"

	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/dataform"
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/kms"
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/secretmanager"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		secret, err := secretmanager.NewSecret(ctx, "secret", &secretmanager.SecretArgs{
			SecretId: pulumi.String("my-secret"),
			Replication: &secretmanager.SecretReplicationArgs{
				Auto: &secretmanager.SecretReplicationAutoArgs{},
			},
		})
		if err != nil {
			return err
		}
		secretVersion, err := secretmanager.NewSecretVersion(ctx, "secret_version", &secretmanager.SecretVersionArgs{
			Secret:     secret.ID(),
			SecretData: pulumi.String("secret-data"),
		})
		if err != nil {
			return err
		}
		keyring, err := kms.NewKeyRing(ctx, "keyring", &kms.KeyRingArgs{
			Name:     pulumi.String("example-key-ring"),
			Location: pulumi.String("us-central1"),
		})
		if err != nil {
			return err
		}
		exampleKey, err := kms.NewCryptoKey(ctx, "example_key", &kms.CryptoKeyArgs{
			Name:    pulumi.String("example-crypto-key-name"),
			KeyRing: keyring.ID(),
		})
		if err != nil {
			return err
		}
		cryptoKeyBinding, err := kms.NewCryptoKeyIAMBinding(ctx, "crypto_key_binding", &kms.CryptoKeyIAMBindingArgs{
			CryptoKeyId: exampleKey.ID(),
			Role:        pulumi.String("roles/cloudkms.cryptoKeyEncrypterDecrypter"),
			Members: pulumi.StringArray{
				pulumi.Sprintf("serviceAccount:service-%v@gcp-sa-dataform.iam.gserviceaccount.com", project.Number),
			},
		})
		if err != nil {
			return err
		}
		_, err = dataform.NewRepository(ctx, "dataform_repository", &dataform.RepositoryArgs{
			Name:                                   pulumi.String("dataform_repository"),
			DisplayName:                            pulumi.String("dataform_repository"),
			NpmrcEnvironmentVariablesSecretVersion: secretVersion.ID(),
			KmsKeyName:                             exampleKey.ID(),
			Labels: pulumi.StringMap{
				"label_foo1": pulumi.String("label-bar1"),
			},
			GitRemoteSettings: &dataform.RepositoryGitRemoteSettingsArgs{
				Url:                              pulumi.String("https://github.com/OWNER/REPOSITORY.git"),
				DefaultBranch:                    pulumi.String("main"),
				AuthenticationTokenSecretVersion: secretVersion.ID(),
			},
			WorkspaceCompilationOverrides: &dataform.RepositoryWorkspaceCompilationOverridesArgs{
				DefaultDatabase: pulumi.String("database"),
				SchemaSuffix:    pulumi.String("_suffix"),
				TablePrefix:     pulumi.String("prefix_"),
			},
		}, pulumi.DependsOn([]pulumi.Resource{
			cryptoKeyBinding,
		}))
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.secretmanager.Secret;
import com.pulumi.gcp.secretmanager.SecretArgs;
import com.pulumi.gcp.secretmanager.inputs.SecretReplicationArgs;
import com.pulumi.gcp.secretmanager.inputs.SecretReplicationAutoArgs;
import com.pulumi.gcp.secretmanager.SecretVersion;
import com.pulumi.gcp.secretmanager.SecretVersionArgs;
import com.pulumi.gcp.kms.KeyRing;
import com.pulumi.gcp.kms.KeyRingArgs;
import com.pulumi.gcp.kms.CryptoKey;
import com.pulumi.gcp.kms.CryptoKeyArgs;
import com.pulumi.gcp.kms.CryptoKeyIAMBinding;
import com.pulumi.gcp.kms.CryptoKeyIAMBindingArgs;
import com.pulumi.gcp.dataform.Repository;
import com.pulumi.gcp.dataform.RepositoryArgs;
import com.pulumi.gcp.dataform.inputs.RepositoryGitRemoteSettingsArgs;
import com.pulumi.gcp.dataform.inputs.RepositoryWorkspaceCompilationOverridesArgs;
import com.pulumi.resources.CustomResourceOptions;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        var secret = new Secret("secret", SecretArgs.builder()
            .secretId("my-secret")
            .replication(SecretReplicationArgs.builder()
                .auto()
                .build())
            .build());

        var secretVersion = new SecretVersion("secretVersion", SecretVersionArgs.builder()
            .secret(secret.id())
            .secretData("secret-data")
            .build());

        var keyring = new KeyRing("keyring", KeyRingArgs.builder()
            .name("example-key-ring")
            .location("us-central1")
            .build());

        var exampleKey = new CryptoKey("exampleKey", CryptoKeyArgs.builder()
            .name("example-crypto-key-name")
            .keyRing(keyring.id())
            .build());

        var cryptoKeyBinding = new CryptoKeyIAMBinding("cryptoKeyBinding", CryptoKeyIAMBindingArgs.builder()
            .cryptoKeyId(exampleKey.id())
            .role("roles/cloudkms.cryptoKeyEncrypterDecrypter")
            .members(String.format("serviceAccount:service-%s@gcp-sa-dataform.iam.gserviceaccount.com", project.number()))
            .build());

        var dataformRepository = new Repository("dataformRepository", RepositoryArgs.builder()
            .name("dataform_repository")
            .displayName("dataform_repository")
            .npmrcEnvironmentVariablesSecretVersion(secretVersion.id())
            .kmsKeyName(exampleKey.id())
            .labels(Map.of("label_foo1", "label-bar1"))
            .gitRemoteSettings(RepositoryGitRemoteSettingsArgs.builder()
                .url("https://github.com/OWNER/REPOSITORY.git")
                .defaultBranch("main")
                .authenticationTokenSecretVersion(secretVersion.id())
                .build())
            .workspaceCompilationOverrides(RepositoryWorkspaceCompilationOverridesArgs.builder()
                .defaultDatabase("database")
                .schemaSuffix("_suffix")
                .tablePrefix("prefix_")
                .build())
            .build(), CustomResourceOptions.builder()
                .dependsOn(cryptoKeyBinding)
                .build());

    }
}
```
```yaml
resources:
  secret:
    type: gcp:secretmanager:Secret
    properties:
      secretId: my-secret
      replication:
        auto: {}
  secretVersion:
    type: gcp:secretmanager:SecretVersion
    name: secret_version
    properties:
      secret: ${secret.id}
      secretData: secret-data
  keyring:
    type: gcp:kms:KeyRing
    properties:
      name: example-key-ring
      location: us-central1
  exampleKey:
    type: gcp:kms:CryptoKey
    name: example_key
    properties:
      name: example-crypto-key-name
      keyRing: ${keyring.id}
  cryptoKeyBinding:
    type: gcp:kms:CryptoKeyIAMBinding
    name: crypto_key_binding
    properties:
      cryptoKeyId: ${exampleKey.id}
      role: roles/cloudkms.cryptoKeyEncrypterDecrypter
      members:
        - serviceAccount:service-${project.number}@gcp-sa-dataform.iam.gserviceaccount.com
  dataformRepository:
    type: gcp:dataform:Repository
    name: dataform_repository
    properties:
      name: dataform_repository
      displayName: dataform_repository
      npmrcEnvironmentVariablesSecretVersion: ${secretVersion.id}
      kmsKeyName: ${exampleKey.id}
      labels:
        label_foo1: label-bar1
      gitRemoteSettings:
        url: https://github.com/OWNER/REPOSITORY.git
        defaultBranch: main
        authenticationTokenSecretVersion: ${secretVersion.id}
      workspaceCompilationOverrides:
        defaultDatabase: database
        schemaSuffix: _suffix
        tablePrefix: prefix_
    options:
      dependsOn:
        - ${cryptoKeyBinding}
```
<!--End PulumiCodeChooser -->

## Import

Repository can be imported using any of these accepted formats:

* `projects/{{project}}/locations/{{region}}/repositories/{{name}}`

* `{{project}}/{{region}}/{{name}}`

* `{{region}}/{{name}}`

* `{{name}}`

When using the `pulumi import` command, Repository can be imported using one of the formats above. For example:

```sh
$ pulumi import gcp:dataform/repository:Repository default projects/{{project}}/locations/{{region}}/repositories/{{name}}
```

```sh
$ pulumi import gcp:dataform/repository:Repository default {{project}}/{{region}}/{{name}}
```

```sh
$ pulumi import gcp:dataform/repository:Repository default {{region}}/{{name}}
```

```sh
$ pulumi import gcp:dataform/repository:Repository default {{name}}
```

D
displayNameB" /Optional. The repository's user-friendly name.
ô
gitRemoteSettingssBq:o
m
dataformRepositoryGitRemoteSettingsDgcp:dataform/RepositoryGitRemoteSettings:RepositoryGitRemoteSettingsjOptional. If set, configures this repository to be linked to a Git remote.
Structure is documented below.
×

kmsKeyNameB" ÂOptional. The reference to a KMS encryption key. If provided, it will be used to encrypt user data in the repository and all child resources.
It is not possible to add or update the encryption key after the repository is created. Example projects/[kms_project_id]/locations/[region]/keyRings/[key_region]/cryptoKeys/[key]
í
labelsB2" ÚOptional. Repository user labels.
An object containing a list of "key": value pairs. Example: { "name": "wrench", "mass": "1.3kg", "count": "3" }.

**Note**: This field is non-authoritative, and will only manage the labels present in your configuration.
Please refer to the field `effective_labels` for all of the labels present on the resource.
-
nameB" The repository's name.


- - -
¨
&npmrcEnvironmentVariablesSecretVersionB" ÷Optional. The name of the Secret Manager secret version to be used to interpolate variables into the .npmrc file for package installation operations. Must be in the format projects/*/secrets/*/versions/*. The file itself must be in a JSON format.
{
projectB" jThe ID of the project in which the resource belongs.
If it is not provided, the provider project is used.
*
regionB" A reference to the region
O
serviceAccountB" 7The service account to run workflow invocations under.

workspaceCompilationOverridesB:

dataform'RepositoryWorkspaceCompilationOverrides\gcp:dataform/RepositoryWorkspaceCompilationOverrides:RepositoryWorkspaceCompilationOverridesÑIf set, fields of workspaceCompilationOverrides override the default compilation settings that are specified in dataform.json when creating workspace-scoped compilation results.
Structure is documented below.
"D
displayNameB" /Optional. The repository's user-friendly name.
"¦
effectiveLabels2" All of labels (key/value pairs) present on the resource in GCP, including the labels configured through Pulumi, other clients and services.
"ô
gitRemoteSettingssBq:o
m
dataformRepositoryGitRemoteSettingsDgcp:dataform/RepositoryGitRemoteSettings:RepositoryGitRemoteSettingsjOptional. If set, configures this repository to be linked to a Git remote.
Structure is documented below.
"×

kmsKeyNameB" ÂOptional. The reference to a KMS encryption key. If provided, it will be used to encrypt user data in the repository and all child resources.
It is not possible to add or update the encryption key after the repository is created. Example projects/[kms_project_id]/locations/[region]/keyRings/[key_region]/cryptoKeys/[key]
"í
labelsB2" ÚOptional. Repository user labels.
An object containing a list of "key": value pairs. Example: { "name": "wrench", "mass": "1.3kg", "count": "3" }.

**Note**: This field is non-authoritative, and will only manage the labels present in your configuration.
Please refer to the field `effective_labels` for all of the labels present on the resource.
"+
name" The repository's name.


- - -
"¨
&npmrcEnvironmentVariablesSecretVersionB" ÷Optional. The name of the Secret Manager secret version to be used to interpolate variables into the .npmrc file for package installation operations. Must be in the format projects/*/secrets/*/versions/*. The file itself must be in a JSON format.
"y
project" jThe ID of the project in which the resource belongs.
If it is not provided, the provider project is used.
"
pulumiLabels2" mThe combination of labels configured directly on the resource
and default labels configured on the provider.
"*
regionB" A reference to the region
"O
serviceAccountB" 7The service account to run workflow invocations under.
"
workspaceCompilationOverridesB:

dataform'RepositoryWorkspaceCompilationOverrides\gcp:dataform/RepositoryWorkspaceCompilationOverrides:RepositoryWorkspaceCompilationOverridesÑIf set, fields of workspaceCompilationOverrides override the default compilation settings that are specified in dataform.json when creating workspace-scoped compilation results.
Structure is documented below.
*
X
dataformRepositoryIamBinding6gcp:dataform/repositoryIamBinding:RepositoryIamBinding
	conditionyBw:u
s
dataformRepositoryIamBindingConditionHgcp:dataform/RepositoryIamBindingCondition:RepositoryIamBindingCondition
members*" 
projectB" 
regionB" 

repository" 

role" "
	conditionyBw:u
s
dataformRepositoryIamBindingConditionHgcp:dataform/RepositoryIamBindingCondition:RepositoryIamBindingCondition"

etag" "
members*" "
project" "
region" "

repository" "

role" *
U
dataformRepositoryIamMember4gcp:dataform/repositoryIamMember:RepositoryIamMember
	conditionvBt:r
p
dataformRepositoryIamMemberConditionFgcp:dataform/RepositoryIamMemberCondition:RepositoryIamMemberCondition
member" 
projectB" 
regionB" 

repository" 

role" "
	conditionvBt:r
p
dataformRepositoryIamMemberConditionFgcp:dataform/RepositoryIamMemberCondition:RepositoryIamMemberCondition"

etag" "
member" "
project" "
region" "

repository" "

role" *é
U
dataformRepositoryIamPolicy4gcp:dataform/repositoryIamPolicy:RepositoryIamPolicy

policyData" 
projectB" 
regionB" 

repository" "

etag" "

policyData" "
project" "
region" "

repository" *þ
a
dataformRepositoryReleaseConfig<gcp:dataform/repositoryReleaseConfig:RepositoryReleaseConfigîk## Example Usage

### Dataform Repository Release Config


<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const gitRepository = new gcp.sourcerepo.Repository("git_repository", {name: "my/repository"});
const secret = new gcp.secretmanager.Secret("secret", {
    secretId: "my_secret",
    replication: {
        auto: {},
    },
});
const secretVersion = new gcp.secretmanager.SecretVersion("secret_version", {
    secret: secret.id,
    secretData: "secret-data",
});
const repository = new gcp.dataform.Repository("repository", {
    name: "dataform_repository",
    region: "us-central1",
    gitRemoteSettings: {
        url: gitRepository.url,
        defaultBranch: "main",
        authenticationTokenSecretVersion: secretVersion.id,
    },
    workspaceCompilationOverrides: {
        defaultDatabase: "database",
        schemaSuffix: "_suffix",
        tablePrefix: "prefix_",
    },
});
const release = new gcp.dataform.RepositoryReleaseConfig("release", {
    project: repository.project,
    region: repository.region,
    repository: repository.name,
    name: "my_release",
    gitCommitish: "main",
    cronSchedule: "0 7 * * *",
    timeZone: "America/New_York",
    codeCompilationConfig: {
        defaultDatabase: "gcp-example-project",
        defaultSchema: "example-dataset",
        defaultLocation: "us-central1",
        assertionSchema: "example-assertion-dataset",
        databaseSuffix: "",
        schemaSuffix: "",
        tablePrefix: "",
        vars: {
            var1: "value",
        },
    },
});
```
```python
import pulumi
import pulumi_gcp as gcp

git_repository = gcp.sourcerepo.Repository("git_repository", name="my/repository")
secret = gcp.secretmanager.Secret("secret",
    secret_id="my_secret",
    replication={
        "auto": {},
    })
secret_version = gcp.secretmanager.SecretVersion("secret_version",
    secret=secret.id,
    secret_data="secret-data")
repository = gcp.dataform.Repository("repository",
    name="dataform_repository",
    region="us-central1",
    git_remote_settings={
        "url": git_repository.url,
        "default_branch": "main",
        "authentication_token_secret_version": secret_version.id,
    },
    workspace_compilation_overrides={
        "default_database": "database",
        "schema_suffix": "_suffix",
        "table_prefix": "prefix_",
    })
release = gcp.dataform.RepositoryReleaseConfig("release",
    project=repository.project,
    region=repository.region,
    repository=repository.name,
    name="my_release",
    git_commitish="main",
    cron_schedule="0 7 * * *",
    time_zone="America/New_York",
    code_compilation_config={
        "default_database": "gcp-example-project",
        "default_schema": "example-dataset",
        "default_location": "us-central1",
        "assertion_schema": "example-assertion-dataset",
        "database_suffix": "",
        "schema_suffix": "",
        "table_prefix": "",
        "vars": {
            "var1": "value",
        },
    })
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var gitRepository = new Gcp.SourceRepo.Repository("git_repository", new()
    {
        Name = "my/repository",
    });

    var secret = new Gcp.SecretManager.Secret("secret", new()
    {
        SecretId = "my_secret",
        Replication = new Gcp.SecretManager.Inputs.SecretReplicationArgs
        {
            Auto = null,
        },
    });

    var secretVersion = new Gcp.SecretManager.SecretVersion("secret_version", new()
    {
        Secret = secret.Id,
        SecretData = "secret-data",
    });

    var repository = new Gcp.Dataform.Repository("repository", new()
    {
        Name = "dataform_repository",
        Region = "us-central1",
        GitRemoteSettings = new Gcp.Dataform.Inputs.RepositoryGitRemoteSettingsArgs
        {
            Url = gitRepository.Url,
            DefaultBranch = "main",
            AuthenticationTokenSecretVersion = secretVersion.Id,
        },
        WorkspaceCompilationOverrides = new Gcp.Dataform.Inputs.RepositoryWorkspaceCompilationOverridesArgs
        {
            DefaultDatabase = "database",
            SchemaSuffix = "_suffix",
            TablePrefix = "prefix_",
        },
    });

    var release = new Gcp.Dataform.RepositoryReleaseConfig("release", new()
    {
        Project = repository.Project,
        Region = repository.Region,
        Repository = repository.Name,
        Name = "my_release",
        GitCommitish = "main",
        CronSchedule = "0 7 * * *",
        TimeZone = "America/New_York",
        CodeCompilationConfig = new Gcp.Dataform.Inputs.RepositoryReleaseConfigCodeCompilationConfigArgs
        {
            DefaultDatabase = "gcp-example-project",
            DefaultSchema = "example-dataset",
            DefaultLocation = "us-central1",
            AssertionSchema = "example-assertion-dataset",
            DatabaseSuffix = "",
            SchemaSuffix = "",
            TablePrefix = "",
            Vars = 
            {
                { "var1", "value" },
            },
        },
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/dataform"
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/secretmanager"
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/sourcerepo"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		gitRepository, err := sourcerepo.NewRepository(ctx, "git_repository", &sourcerepo.RepositoryArgs{
			Name: pulumi.String("my/repository"),
		})
		if err != nil {
			return err
		}
		secret, err := secretmanager.NewSecret(ctx, "secret", &secretmanager.SecretArgs{
			SecretId: pulumi.String("my_secret"),
			Replication: &secretmanager.SecretReplicationArgs{
				Auto: &secretmanager.SecretReplicationAutoArgs{},
			},
		})
		if err != nil {
			return err
		}
		secretVersion, err := secretmanager.NewSecretVersion(ctx, "secret_version", &secretmanager.SecretVersionArgs{
			Secret:     secret.ID(),
			SecretData: pulumi.String("secret-data"),
		})
		if err != nil {
			return err
		}
		repository, err := dataform.NewRepository(ctx, "repository", &dataform.RepositoryArgs{
			Name:   pulumi.String("dataform_repository"),
			Region: pulumi.String("us-central1"),
			GitRemoteSettings: &dataform.RepositoryGitRemoteSettingsArgs{
				Url:                              gitRepository.Url,
				DefaultBranch:                    pulumi.String("main"),
				AuthenticationTokenSecretVersion: secretVersion.ID(),
			},
			WorkspaceCompilationOverrides: &dataform.RepositoryWorkspaceCompilationOverridesArgs{
				DefaultDatabase: pulumi.String("database"),
				SchemaSuffix:    pulumi.String("_suffix"),
				TablePrefix:     pulumi.String("prefix_"),
			},
		})
		if err != nil {
			return err
		}
		_, err = dataform.NewRepositoryReleaseConfig(ctx, "release", &dataform.RepositoryReleaseConfigArgs{
			Project:      repository.Project,
			Region:       repository.Region,
			Repository:   repository.Name,
			Name:         pulumi.String("my_release"),
			GitCommitish: pulumi.String("main"),
			CronSchedule: pulumi.String("0 7 * * *"),
			TimeZone:     pulumi.String("America/New_York"),
			CodeCompilationConfig: &dataform.RepositoryReleaseConfigCodeCompilationConfigArgs{
				DefaultDatabase: pulumi.String("gcp-example-project"),
				DefaultSchema:   pulumi.String("example-dataset"),
				DefaultLocation: pulumi.String("us-central1"),
				AssertionSchema: pulumi.String("example-assertion-dataset"),
				DatabaseSuffix:  pulumi.String(""),
				SchemaSuffix:    pulumi.String(""),
				TablePrefix:     pulumi.String(""),
				Vars: pulumi.StringMap{
					"var1": pulumi.String("value"),
				},
			},
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.sourcerepo.Repository;
import com.pulumi.gcp.sourcerepo.RepositoryArgs;
import com.pulumi.gcp.secretmanager.Secret;
import com.pulumi.gcp.secretmanager.SecretArgs;
import com.pulumi.gcp.secretmanager.inputs.SecretReplicationArgs;
import com.pulumi.gcp.secretmanager.inputs.SecretReplicationAutoArgs;
import com.pulumi.gcp.secretmanager.SecretVersion;
import com.pulumi.gcp.secretmanager.SecretVersionArgs;
import com.pulumi.gcp.dataform.Repository;
import com.pulumi.gcp.dataform.RepositoryArgs;
import com.pulumi.gcp.dataform.inputs.RepositoryGitRemoteSettingsArgs;
import com.pulumi.gcp.dataform.inputs.RepositoryWorkspaceCompilationOverridesArgs;
import com.pulumi.gcp.dataform.RepositoryReleaseConfig;
import com.pulumi.gcp.dataform.RepositoryReleaseConfigArgs;
import com.pulumi.gcp.dataform.inputs.RepositoryReleaseConfigCodeCompilationConfigArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        var gitRepository = new Repository("gitRepository", RepositoryArgs.builder()
            .name("my/repository")
            .build());

        var secret = new Secret("secret", SecretArgs.builder()
            .secretId("my_secret")
            .replication(SecretReplicationArgs.builder()
                .auto()
                .build())
            .build());

        var secretVersion = new SecretVersion("secretVersion", SecretVersionArgs.builder()
            .secret(secret.id())
            .secretData("secret-data")
            .build());

        var repository = new Repository("repository", RepositoryArgs.builder()
            .name("dataform_repository")
            .region("us-central1")
            .gitRemoteSettings(RepositoryGitRemoteSettingsArgs.builder()
                .url(gitRepository.url())
                .defaultBranch("main")
                .authenticationTokenSecretVersion(secretVersion.id())
                .build())
            .workspaceCompilationOverrides(RepositoryWorkspaceCompilationOverridesArgs.builder()
                .defaultDatabase("database")
                .schemaSuffix("_suffix")
                .tablePrefix("prefix_")
                .build())
            .build());

        var release = new RepositoryReleaseConfig("release", RepositoryReleaseConfigArgs.builder()
            .project(repository.project())
            .region(repository.region())
            .repository(repository.name())
            .name("my_release")
            .gitCommitish("main")
            .cronSchedule("0 7 * * *")
            .timeZone("America/New_York")
            .codeCompilationConfig(RepositoryReleaseConfigCodeCompilationConfigArgs.builder()
                .defaultDatabase("gcp-example-project")
                .defaultSchema("example-dataset")
                .defaultLocation("us-central1")
                .assertionSchema("example-assertion-dataset")
                .databaseSuffix("")
                .schemaSuffix("")
                .tablePrefix("")
                .vars(Map.of("var1", "value"))
                .build())
            .build());

    }
}
```
```yaml
resources:
  gitRepository:
    type: gcp:sourcerepo:Repository
    name: git_repository
    properties:
      name: my/repository
  secret:
    type: gcp:secretmanager:Secret
    properties:
      secretId: my_secret
      replication:
        auto: {}
  secretVersion:
    type: gcp:secretmanager:SecretVersion
    name: secret_version
    properties:
      secret: ${secret.id}
      secretData: secret-data
  repository:
    type: gcp:dataform:Repository
    properties:
      name: dataform_repository
      region: us-central1
      gitRemoteSettings:
        url: ${gitRepository.url}
        defaultBranch: main
        authenticationTokenSecretVersion: ${secretVersion.id}
      workspaceCompilationOverrides:
        defaultDatabase: database
        schemaSuffix: _suffix
        tablePrefix: prefix_
  release:
    type: gcp:dataform:RepositoryReleaseConfig
    properties:
      project: ${repository.project}
      region: ${repository.region}
      repository: ${repository.name}
      name: my_release
      gitCommitish: main
      cronSchedule: 0 7 * * *
      timeZone: America/New_York
      codeCompilationConfig:
        defaultDatabase: gcp-example-project
        defaultSchema: example-dataset
        defaultLocation: us-central1
        assertionSchema: example-assertion-dataset
        databaseSuffix: ""
        schemaSuffix: ""
        tablePrefix: ""
        vars:
          var1: value
```
<!--End PulumiCodeChooser -->

## Import

RepositoryReleaseConfig can be imported using any of these accepted formats:

* `projects/{{project}}/locations/{{region}}/repositories/{{repository}}/releaseConfigs/{{name}}`

* `{{project}}/{{region}}/{{repository}}/{{name}}`

* `{{region}}/{{repository}}/{{name}}`

* `{{repository}}/{{name}}`

When using the `pulumi import` command, RepositoryReleaseConfig can be imported using one of the formats above. For example:

```sh
$ pulumi import gcp:dataform/repositoryReleaseConfig:RepositoryReleaseConfig default projects/{{project}}/locations/{{region}}/repositories/{{repository}}/releaseConfigs/{{name}}
```

```sh
$ pulumi import gcp:dataform/repositoryReleaseConfig:RepositoryReleaseConfig default {{project}}/{{region}}/{{repository}}/{{name}}
```

```sh
$ pulumi import gcp:dataform/repositoryReleaseConfig:RepositoryReleaseConfig default {{region}}/{{repository}}/{{name}}
```

```sh
$ pulumi import gcp:dataform/repositoryReleaseConfig:RepositoryReleaseConfig default {{repository}}/{{name}}
```

æ
codeCompilationConfig©B¦:£
 
dataform,RepositoryReleaseConfigCodeCompilationConfigfgcp:dataform/RepositoryReleaseConfigCodeCompilationConfig:RepositoryReleaseConfigCodeCompilationConfig Optional. If set, fields of codeCompilationConfig override the default compilation settings that are specified in dataform.json.
Structure is documented below.
r
cronScheduleB" \Optional. Optional schedule (in cron format) for automatic creation of compilation results.

gitCommitish" tGit commit/tag/branch name at which the repository should be compiled. Must exist in the remote repository.


- - -
"
nameB" The release's name.
{
projectB" jThe ID of the project in which the resource belongs.
If it is not provided, the provider project is used.
*
regionB" A reference to the region
;

repositoryB" 'A reference to the Dataform repository
þ
timeZoneB" ëOptional. Specifies the time zone to be used when interpreting cronSchedule. Must be a time zone name from the time zone database (https://en.wikipedia.org/wiki/List_of_tz_database_time_zones). If left unspecified, the default is UTC.
"æ
codeCompilationConfig©B¦:£
 
dataform,RepositoryReleaseConfigCodeCompilationConfigfgcp:dataform/RepositoryReleaseConfigCodeCompilationConfig:RepositoryReleaseConfigCodeCompilationConfig Optional. If set, fields of codeCompilationConfig override the default compilation settings that are specified in dataform.json.
Structure is documented below.
"r
cronScheduleB" \Optional. Optional schedule (in cron format) for automatic creation of compilation results.
"
gitCommitish" tGit commit/tag/branch name at which the repository should be compiled. Must exist in the remote repository.


- - -
" 
name" The release's name.
"y
project" jThe ID of the project in which the resource belongs.
If it is not provided, the provider project is used.
"Å
recentScheduledReleaseRecords¾*»:¸
µ
dataform3RepositoryReleaseConfigRecentScheduledReleaseRecordtgcp:dataform/RepositoryReleaseConfigRecentScheduledReleaseRecord:RepositoryReleaseConfigRecentScheduledReleaseRecordâRecords of the 10 most recent scheduled release attempts, ordered in in descending order of releaseTime. Updated whenever automatic creation of a compilation result is triggered by cronSchedule.
Structure is documented below.
"*
regionB" A reference to the region
";

repositoryB" 'A reference to the Dataform repository
"þ
timeZoneB" ëOptional. Specifies the time zone to be used when interpreting cronSchedule. Must be a time zone name from the time zone database (https://en.wikipedia.org/wiki/List_of_tz_database_time_zones). If left unspecified, the default is UTC.
*»Â
d
dataformRepositoryWorkflowConfig>gcp:dataform/repositoryWorkflowConfig:RepositoryWorkflowConfigË¬## Example Usage

### Dataform Repository Workflow Config


<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const gitRepository = new gcp.sourcerepo.Repository("git_repository", {name: "my/repository"});
const secret = new gcp.secretmanager.Secret("secret", {
    secretId: "my_secret",
    replication: {
        auto: {},
    },
});
const secretVersion = new gcp.secretmanager.SecretVersion("secret_version", {
    secret: secret.id,
    secretData: "secret-data",
});
const repository = new gcp.dataform.Repository("repository", {
    name: "dataform_repository",
    region: "us-central1",
    gitRemoteSettings: {
        url: gitRepository.url,
        defaultBranch: "main",
        authenticationTokenSecretVersion: secretVersion.id,
    },
    workspaceCompilationOverrides: {
        defaultDatabase: "database",
        schemaSuffix: "_suffix",
        tablePrefix: "prefix_",
    },
});
const releaseConfig = new gcp.dataform.RepositoryReleaseConfig("release_config", {
    project: repository.project,
    region: repository.region,
    repository: repository.name,
    name: "my_release",
    gitCommitish: "main",
    cronSchedule: "0 7 * * *",
    timeZone: "America/New_York",
    codeCompilationConfig: {
        defaultDatabase: "gcp-example-project",
        defaultSchema: "example-dataset",
        defaultLocation: "us-central1",
        assertionSchema: "example-assertion-dataset",
        databaseSuffix: "",
        schemaSuffix: "",
        tablePrefix: "",
        vars: {
            var1: "value",
        },
    },
});
const dataformSa = new gcp.serviceaccount.Account("dataform_sa", {
    accountId: "dataform-sa",
    displayName: "Dataform Service Account",
});
const workflow = new gcp.dataform.RepositoryWorkflowConfig("workflow", {
    project: repository.project,
    region: repository.region,
    repository: repository.name,
    name: "my_workflow",
    releaseConfig: releaseConfig.id,
    invocationConfig: {
        includedTargets: [
            {
                database: "gcp-example-project",
                schema: "example-dataset",
                name: "target_1",
            },
            {
                database: "gcp-example-project",
                schema: "example-dataset",
                name: "target_2",
            },
        ],
        includedTags: ["tag_1"],
        transitiveDependenciesIncluded: true,
        transitiveDependentsIncluded: true,
        fullyRefreshIncrementalTablesEnabled: false,
        serviceAccount: dataformSa.email,
    },
    cronSchedule: "0 7 * * *",
    timeZone: "America/New_York",
});
```
```python
import pulumi
import pulumi_gcp as gcp

git_repository = gcp.sourcerepo.Repository("git_repository", name="my/repository")
secret = gcp.secretmanager.Secret("secret",
    secret_id="my_secret",
    replication={
        "auto": {},
    })
secret_version = gcp.secretmanager.SecretVersion("secret_version",
    secret=secret.id,
    secret_data="secret-data")
repository = gcp.dataform.Repository("repository",
    name="dataform_repository",
    region="us-central1",
    git_remote_settings={
        "url": git_repository.url,
        "default_branch": "main",
        "authentication_token_secret_version": secret_version.id,
    },
    workspace_compilation_overrides={
        "default_database": "database",
        "schema_suffix": "_suffix",
        "table_prefix": "prefix_",
    })
release_config = gcp.dataform.RepositoryReleaseConfig("release_config",
    project=repository.project,
    region=repository.region,
    repository=repository.name,
    name="my_release",
    git_commitish="main",
    cron_schedule="0 7 * * *",
    time_zone="America/New_York",
    code_compilation_config={
        "default_database": "gcp-example-project",
        "default_schema": "example-dataset",
        "default_location": "us-central1",
        "assertion_schema": "example-assertion-dataset",
        "database_suffix": "",
        "schema_suffix": "",
        "table_prefix": "",
        "vars": {
            "var1": "value",
        },
    })
dataform_sa = gcp.serviceaccount.Account("dataform_sa",
    account_id="dataform-sa",
    display_name="Dataform Service Account")
workflow = gcp.dataform.RepositoryWorkflowConfig("workflow",
    project=repository.project,
    region=repository.region,
    repository=repository.name,
    name="my_workflow",
    release_config=release_config.id,
    invocation_config={
        "included_targets": [
            {
                "database": "gcp-example-project",
                "schema": "example-dataset",
                "name": "target_1",
            },
            {
                "database": "gcp-example-project",
                "schema": "example-dataset",
                "name": "target_2",
            },
        ],
        "included_tags": ["tag_1"],
        "transitive_dependencies_included": True,
        "transitive_dependents_included": True,
        "fully_refresh_incremental_tables_enabled": False,
        "service_account": dataform_sa.email,
    },
    cron_schedule="0 7 * * *",
    time_zone="America/New_York")
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var gitRepository = new Gcp.SourceRepo.Repository("git_repository", new()
    {
        Name = "my/repository",
    });

    var secret = new Gcp.SecretManager.Secret("secret", new()
    {
        SecretId = "my_secret",
        Replication = new Gcp.SecretManager.Inputs.SecretReplicationArgs
        {
            Auto = null,
        },
    });

    var secretVersion = new Gcp.SecretManager.SecretVersion("secret_version", new()
    {
        Secret = secret.Id,
        SecretData = "secret-data",
    });

    var repository = new Gcp.Dataform.Repository("repository", new()
    {
        Name = "dataform_repository",
        Region = "us-central1",
        GitRemoteSettings = new Gcp.Dataform.Inputs.RepositoryGitRemoteSettingsArgs
        {
            Url = gitRepository.Url,
            DefaultBranch = "main",
            AuthenticationTokenSecretVersion = secretVersion.Id,
        },
        WorkspaceCompilationOverrides = new Gcp.Dataform.Inputs.RepositoryWorkspaceCompilationOverridesArgs
        {
            DefaultDatabase = "database",
            SchemaSuffix = "_suffix",
            TablePrefix = "prefix_",
        },
    });

    var releaseConfig = new Gcp.Dataform.RepositoryReleaseConfig("release_config", new()
    {
        Project = repository.Project,
        Region = repository.Region,
        Repository = repository.Name,
        Name = "my_release",
        GitCommitish = "main",
        CronSchedule = "0 7 * * *",
        TimeZone = "America/New_York",
        CodeCompilationConfig = new Gcp.Dataform.Inputs.RepositoryReleaseConfigCodeCompilationConfigArgs
        {
            DefaultDatabase = "gcp-example-project",
            DefaultSchema = "example-dataset",
            DefaultLocation = "us-central1",
            AssertionSchema = "example-assertion-dataset",
            DatabaseSuffix = "",
            SchemaSuffix = "",
            TablePrefix = "",
            Vars = 
            {
                { "var1", "value" },
            },
        },
    });

    var dataformSa = new Gcp.ServiceAccount.Account("dataform_sa", new()
    {
        AccountId = "dataform-sa",
        DisplayName = "Dataform Service Account",
    });

    var workflow = new Gcp.Dataform.RepositoryWorkflowConfig("workflow", new()
    {
        Project = repository.Project,
        Region = repository.Region,
        Repository = repository.Name,
        Name = "my_workflow",
        ReleaseConfig = releaseConfig.Id,
        InvocationConfig = new Gcp.Dataform.Inputs.RepositoryWorkflowConfigInvocationConfigArgs
        {
            IncludedTargets = new[]
            {
                new Gcp.Dataform.Inputs.RepositoryWorkflowConfigInvocationConfigIncludedTargetArgs
                {
                    Database = "gcp-example-project",
                    Schema = "example-dataset",
                    Name = "target_1",
                },
                new Gcp.Dataform.Inputs.RepositoryWorkflowConfigInvocationConfigIncludedTargetArgs
                {
                    Database = "gcp-example-project",
                    Schema = "example-dataset",
                    Name = "target_2",
                },
            },
            IncludedTags = new[]
            {
                "tag_1",
            },
            TransitiveDependenciesIncluded = true,
            TransitiveDependentsIncluded = true,
            FullyRefreshIncrementalTablesEnabled = false,
            ServiceAccount = dataformSa.Email,
        },
        CronSchedule = "0 7 * * *",
        TimeZone = "America/New_York",
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/dataform"
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/secretmanager"
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/serviceaccount"
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/sourcerepo"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		gitRepository, err := sourcerepo.NewRepository(ctx, "git_repository", &sourcerepo.RepositoryArgs{
			Name: pulumi.String("my/repository"),
		})
		if err != nil {
			return err
		}
		secret, err := secretmanager.NewSecret(ctx, "secret", &secretmanager.SecretArgs{
			SecretId: pulumi.String("my_secret"),
			Replication: &secretmanager.SecretReplicationArgs{
				Auto: &secretmanager.SecretReplicationAutoArgs{},
			},
		})
		if err != nil {
			return err
		}
		secretVersion, err := secretmanager.NewSecretVersion(ctx, "secret_version", &secretmanager.SecretVersionArgs{
			Secret:     secret.ID(),
			SecretData: pulumi.String("secret-data"),
		})
		if err != nil {
			return err
		}
		repository, err := dataform.NewRepository(ctx, "repository", &dataform.RepositoryArgs{
			Name:   pulumi.String("dataform_repository"),
			Region: pulumi.String("us-central1"),
			GitRemoteSettings: &dataform.RepositoryGitRemoteSettingsArgs{
				Url:                              gitRepository.Url,
				DefaultBranch:                    pulumi.String("main"),
				AuthenticationTokenSecretVersion: secretVersion.ID(),
			},
			WorkspaceCompilationOverrides: &dataform.RepositoryWorkspaceCompilationOverridesArgs{
				DefaultDatabase: pulumi.String("database"),
				SchemaSuffix:    pulumi.String("_suffix"),
				TablePrefix:     pulumi.String("prefix_"),
			},
		})
		if err != nil {
			return err
		}
		releaseConfig, err := dataform.NewRepositoryReleaseConfig(ctx, "release_config", &dataform.RepositoryReleaseConfigArgs{
			Project:      repository.Project,
			Region:       repository.Region,
			Repository:   repository.Name,
			Name:         pulumi.String("my_release"),
			GitCommitish: pulumi.String("main"),
			CronSchedule: pulumi.String("0 7 * * *"),
			TimeZone:     pulumi.String("America/New_York"),
			CodeCompilationConfig: &dataform.RepositoryReleaseConfigCodeCompilationConfigArgs{
				DefaultDatabase: pulumi.String("gcp-example-project"),
				DefaultSchema:   pulumi.String("example-dataset"),
				DefaultLocation: pulumi.String("us-central1"),
				AssertionSchema: pulumi.String("example-assertion-dataset"),
				DatabaseSuffix:  pulumi.String(""),
				SchemaSuffix:    pulumi.String(""),
				TablePrefix:     pulumi.String(""),
				Vars: pulumi.StringMap{
					"var1": pulumi.String("value"),
				},
			},
		})
		if err != nil {
			return err
		}
		dataformSa, err := serviceaccount.NewAccount(ctx, "dataform_sa", &serviceaccount.AccountArgs{
			AccountId:   pulumi.String("dataform-sa"),
			DisplayName: pulumi.String("Dataform Service Account"),
		})
		if err != nil {
			return err
		}
		_, err = dataform.NewRepositoryWorkflowConfig(ctx, "workflow", &dataform.RepositoryWorkflowConfigArgs{
			Project:       repository.Project,
			Region:        repository.Region,
			Repository:    repository.Name,
			Name:          pulumi.String("my_workflow"),
			ReleaseConfig: releaseConfig.ID(),
			InvocationConfig: &dataform.RepositoryWorkflowConfigInvocationConfigArgs{
				IncludedTargets: dataform.RepositoryWorkflowConfigInvocationConfigIncludedTargetArray{
					&dataform.RepositoryWorkflowConfigInvocationConfigIncludedTargetArgs{
						Database: pulumi.String("gcp-example-project"),
						Schema:   pulumi.String("example-dataset"),
						Name:     pulumi.String("target_1"),
					},
					&dataform.RepositoryWorkflowConfigInvocationConfigIncludedTargetArgs{
						Database: pulumi.String("gcp-example-project"),
						Schema:   pulumi.String("example-dataset"),
						Name:     pulumi.String("target_2"),
					},
				},
				IncludedTags: pulumi.StringArray{
					pulumi.String("tag_1"),
				},
				TransitiveDependenciesIncluded:       pulumi.Bool(true),
				TransitiveDependentsIncluded:         pulumi.Bool(true),
				FullyRefreshIncrementalTablesEnabled: pulumi.Bool(false),
				ServiceAccount:                       dataformSa.Email,
			},
			CronSchedule: pulumi.String("0 7 * * *"),
			TimeZone:     pulumi.String("America/New_York"),
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.sourcerepo.Repository;
import com.pulumi.gcp.sourcerepo.RepositoryArgs;
import com.pulumi.gcp.secretmanager.Secret;
import com.pulumi.gcp.secretmanager.SecretArgs;
import com.pulumi.gcp.secretmanager.inputs.SecretReplicationArgs;
import com.pulumi.gcp.secretmanager.inputs.SecretReplicationAutoArgs;
import com.pulumi.gcp.secretmanager.SecretVersion;
import com.pulumi.gcp.secretmanager.SecretVersionArgs;
import com.pulumi.gcp.dataform.Repository;
import com.pulumi.gcp.dataform.RepositoryArgs;
import com.pulumi.gcp.dataform.inputs.RepositoryGitRemoteSettingsArgs;
import com.pulumi.gcp.dataform.inputs.RepositoryWorkspaceCompilationOverridesArgs;
import com.pulumi.gcp.dataform.RepositoryReleaseConfig;
import com.pulumi.gcp.dataform.RepositoryReleaseConfigArgs;
import com.pulumi.gcp.dataform.inputs.RepositoryReleaseConfigCodeCompilationConfigArgs;
import com.pulumi.gcp.serviceaccount.Account;
import com.pulumi.gcp.serviceaccount.AccountArgs;
import com.pulumi.gcp.dataform.RepositoryWorkflowConfig;
import com.pulumi.gcp.dataform.RepositoryWorkflowConfigArgs;
import com.pulumi.gcp.dataform.inputs.RepositoryWorkflowConfigInvocationConfigArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        var gitRepository = new Repository("gitRepository", RepositoryArgs.builder()
            .name("my/repository")
            .build());

        var secret = new Secret("secret", SecretArgs.builder()
            .secretId("my_secret")
            .replication(SecretReplicationArgs.builder()
                .auto()
                .build())
            .build());

        var secretVersion = new SecretVersion("secretVersion", SecretVersionArgs.builder()
            .secret(secret.id())
            .secretData("secret-data")
            .build());

        var repository = new Repository("repository", RepositoryArgs.builder()
            .name("dataform_repository")
            .region("us-central1")
            .gitRemoteSettings(RepositoryGitRemoteSettingsArgs.builder()
                .url(gitRepository.url())
                .defaultBranch("main")
                .authenticationTokenSecretVersion(secretVersion.id())
                .build())
            .workspaceCompilationOverrides(RepositoryWorkspaceCompilationOverridesArgs.builder()
                .defaultDatabase("database")
                .schemaSuffix("_suffix")
                .tablePrefix("prefix_")
                .build())
            .build());

        var releaseConfig = new RepositoryReleaseConfig("releaseConfig", RepositoryReleaseConfigArgs.builder()
            .project(repository.project())
            .region(repository.region())
            .repository(repository.name())
            .name("my_release")
            .gitCommitish("main")
            .cronSchedule("0 7 * * *")
            .timeZone("America/New_York")
            .codeCompilationConfig(RepositoryReleaseConfigCodeCompilationConfigArgs.builder()
                .defaultDatabase("gcp-example-project")
                .defaultSchema("example-dataset")
                .defaultLocation("us-central1")
                .assertionSchema("example-assertion-dataset")
                .databaseSuffix("")
                .schemaSuffix("")
                .tablePrefix("")
                .vars(Map.of("var1", "value"))
                .build())
            .build());

        var dataformSa = new Account("dataformSa", AccountArgs.builder()
            .accountId("dataform-sa")
            .displayName("Dataform Service Account")
            .build());

        var workflow = new RepositoryWorkflowConfig("workflow", RepositoryWorkflowConfigArgs.builder()
            .project(repository.project())
            .region(repository.region())
            .repository(repository.name())
            .name("my_workflow")
            .releaseConfig(releaseConfig.id())
            .invocationConfig(RepositoryWorkflowConfigInvocationConfigArgs.builder()
                .includedTargets(                
                    RepositoryWorkflowConfigInvocationConfigIncludedTargetArgs.builder()
                        .database("gcp-example-project")
                        .schema("example-dataset")
                        .name("target_1")
                        .build(),
                    RepositoryWorkflowConfigInvocationConfigIncludedTargetArgs.builder()
                        .database("gcp-example-project")
                        .schema("example-dataset")
                        .name("target_2")
                        .build())
                .includedTags("tag_1")
                .transitiveDependenciesIncluded(true)
                .transitiveDependentsIncluded(true)
                .fullyRefreshIncrementalTablesEnabled(false)
                .serviceAccount(dataformSa.email())
                .build())
            .cronSchedule("0 7 * * *")
            .timeZone("America/New_York")
            .build());

    }
}
```
```yaml
resources:
  gitRepository:
    type: gcp:sourcerepo:Repository
    name: git_repository
    properties:
      name: my/repository
  secret:
    type: gcp:secretmanager:Secret
    properties:
      secretId: my_secret
      replication:
        auto: {}
  secretVersion:
    type: gcp:secretmanager:SecretVersion
    name: secret_version
    properties:
      secret: ${secret.id}
      secretData: secret-data
  repository:
    type: gcp:dataform:Repository
    properties:
      name: dataform_repository
      region: us-central1
      gitRemoteSettings:
        url: ${gitRepository.url}
        defaultBranch: main
        authenticationTokenSecretVersion: ${secretVersion.id}
      workspaceCompilationOverrides:
        defaultDatabase: database
        schemaSuffix: _suffix
        tablePrefix: prefix_
  releaseConfig:
    type: gcp:dataform:RepositoryReleaseConfig
    name: release_config
    properties:
      project: ${repository.project}
      region: ${repository.region}
      repository: ${repository.name}
      name: my_release
      gitCommitish: main
      cronSchedule: 0 7 * * *
      timeZone: America/New_York
      codeCompilationConfig:
        defaultDatabase: gcp-example-project
        defaultSchema: example-dataset
        defaultLocation: us-central1
        assertionSchema: example-assertion-dataset
        databaseSuffix: ""
        schemaSuffix: ""
        tablePrefix: ""
        vars:
          var1: value
  dataformSa:
    type: gcp:serviceaccount:Account
    name: dataform_sa
    properties:
      accountId: dataform-sa
      displayName: Dataform Service Account
  workflow:
    type: gcp:dataform:RepositoryWorkflowConfig
    properties:
      project: ${repository.project}
      region: ${repository.region}
      repository: ${repository.name}
      name: my_workflow
      releaseConfig: ${releaseConfig.id}
      invocationConfig:
        includedTargets:
          - database: gcp-example-project
            schema: example-dataset
            name: target_1
          - database: gcp-example-project
            schema: example-dataset
            name: target_2
        includedTags:
          - tag_1
        transitiveDependenciesIncluded: true
        transitiveDependentsIncluded: true
        fullyRefreshIncrementalTablesEnabled: false
        serviceAccount: ${dataformSa.email}
      cronSchedule: 0 7 * * *
      timeZone: America/New_York
```
<!--End PulumiCodeChooser -->

## Import

RepositoryWorkflowConfig can be imported using any of these accepted formats:

* `projects/{{project}}/locations/{{region}}/repositories/{{repository}}/workflowConfigs/{{name}}`

* `{{project}}/{{region}}/{{repository}}/{{name}}`

* `{{region}}/{{repository}}/{{name}}`

* `{{repository}}/{{name}}`

When using the `pulumi import` command, RepositoryWorkflowConfig can be imported using one of the formats above. For example:

```sh
$ pulumi import gcp:dataform/repositoryWorkflowConfig:RepositoryWorkflowConfig default projects/{{project}}/locations/{{region}}/repositories/{{repository}}/workflowConfigs/{{name}}
```

```sh
$ pulumi import gcp:dataform/repositoryWorkflowConfig:RepositoryWorkflowConfig default {{project}}/{{region}}/{{repository}}/{{name}}
```

```sh
$ pulumi import gcp:dataform/repositoryWorkflowConfig:RepositoryWorkflowConfig default {{region}}/{{repository}}/{{name}}
```

```sh
$ pulumi import gcp:dataform/repositoryWorkflowConfig:RepositoryWorkflowConfig default {{repository}}/{{name}}
```

r
cronScheduleB" \Optional. Optional schedule (in cron format) for automatic creation of compilation results.

invocationConfigB:

dataform(RepositoryWorkflowConfigInvocationConfig^gcp:dataform/RepositoryWorkflowConfigInvocationConfig:RepositoryWorkflowConfigInvocationConfigaOptional. If left unset, a default InvocationConfig will be used.
Structure is documented below.
#
nameB" The workflow's name.
{
projectB" jThe ID of the project in which the resource belongs.
If it is not provided, the provider project is used.
*
regionB" A reference to the region
¾
releaseConfig" ¨The name of the release config whose releaseCompilationResult should be executed. Must be in the format projects/*/locations/*/repositories/*/releaseConfigs/*.


- - -
;

repositoryB" 'A reference to the Dataform repository
þ
timeZoneB" ëOptional. Specifies the time zone to be used when interpreting cronSchedule. Must be a time zone name from the time zone database (https://en.wikipedia.org/wiki/List_of_tz_database_time_zones). If left unspecified, the default is UTC.
"r
cronScheduleB" \Optional. Optional schedule (in cron format) for automatic creation of compilation results.
"
invocationConfigB:

dataform(RepositoryWorkflowConfigInvocationConfig^gcp:dataform/RepositoryWorkflowConfigInvocationConfig:RepositoryWorkflowConfigInvocationConfigaOptional. If left unset, a default InvocationConfig will be used.
Structure is documented below.
"!
name" The workflow's name.
"y
project" jThe ID of the project in which the resource belongs.
If it is not provided, the provider project is used.
"Õ
recentScheduledExecutionRecordsÇ*Ä:Á
¾
dataform6RepositoryWorkflowConfigRecentScheduledExecutionRecordzgcp:dataform/RepositoryWorkflowConfigRecentScheduledExecutionRecord:RepositoryWorkflowConfigRecentScheduledExecutionRecordçRecords of the 10 most recent scheduled execution attempts, ordered in in descending order of executionTime. Updated whenever automatic creation of a workflow invocation is triggered by cronSchedule.
Structure is documented below.
"*
regionB" A reference to the region
"¾
releaseConfig" ¨The name of the release config whose releaseCompilationResult should be executed. Must be in the format projects/*/locations/*/repositories/*/releaseConfigs/*.


- - -
";

repositoryB" 'A reference to the Dataform repository
"þ
timeZoneB" ëOptional. Specifies the time zone to be used when interpreting cronSchedule. Must be a time zone name from the time zone database (https://en.wikipedia.org/wiki/List_of_tz_database_time_zones). If left unspecified, the default is UTC.
*îò
8

datafusionInstance gcp:datafusion/instance:Instanceª­Represents a Data Fusion instance.


To get more information about Instance, see:

* [API documentation](https://cloud.google.com/data-fusion/docs/reference/rest/v1beta1/projects.locations.instances)
* How-to Guides
    * [Official Documentation](https://cloud.google.com/data-fusion/docs/)

## Example Usage

### Data Fusion Instance Basic


<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const basicInstance = new gcp.datafusion.Instance("basic_instance", {
    name: "my-instance",
    region: "us-central1",
    type: "BASIC",
});
```
```python
import pulumi
import pulumi_gcp as gcp

basic_instance = gcp.datafusion.Instance("basic_instance",
    name="my-instance",
    region="us-central1",
    type="BASIC")
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var basicInstance = new Gcp.DataFusion.Instance("basic_instance", new()
    {
        Name = "my-instance",
        Region = "us-central1",
        Type = "BASIC",
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/datafusion"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		_, err := datafusion.NewInstance(ctx, "basic_instance", &datafusion.InstanceArgs{
			Name:   pulumi.String("my-instance"),
			Region: pulumi.String("us-central1"),
			Type:   pulumi.String("BASIC"),
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.datafusion.Instance;
import com.pulumi.gcp.datafusion.InstanceArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        var basicInstance = new Instance("basicInstance", InstanceArgs.builder()
            .name("my-instance")
            .region("us-central1")
            .type("BASIC")
            .build());

    }
}
```
```yaml
resources:
  basicInstance:
    type: gcp:datafusion:Instance
    name: basic_instance
    properties:
      name: my-instance
      region: us-central1
      type: BASIC
```
<!--End PulumiCodeChooser -->
### Data Fusion Instance Full


<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const default = gcp.appengine.getDefaultServiceAccount({});
const network = new gcp.compute.Network("network", {name: "datafusion-full-network"});
const privateIpAlloc = new gcp.compute.GlobalAddress("private_ip_alloc", {
    name: "datafusion-ip-alloc",
    addressType: "INTERNAL",
    purpose: "VPC_PEERING",
    prefixLength: 22,
    network: network.id,
});
const extendedInstance = new gcp.datafusion.Instance("extended_instance", {
    name: "my-instance",
    description: "My Data Fusion instance",
    displayName: "My Data Fusion instance",
    region: "us-central1",
    type: "BASIC",
    enableStackdriverLogging: true,
    enableStackdriverMonitoring: true,
    privateInstance: true,
    dataprocServiceAccount: _default.then(_default => _default.email),
    labels: {
        example_key: "example_value",
    },
    networkConfig: {
        network: "default",
        ipAllocation: pulumi.interpolate`${privateIpAlloc.address}/${privateIpAlloc.prefixLength}`,
    },
    accelerators: [{
        acceleratorType: "CDC",
        state: "ENABLED",
    }],
});
```
```python
import pulumi
import pulumi_gcp as gcp

default = gcp.appengine.get_default_service_account()
network = gcp.compute.Network("network", name="datafusion-full-network")
private_ip_alloc = gcp.compute.GlobalAddress("private_ip_alloc",
    name="datafusion-ip-alloc",
    address_type="INTERNAL",
    purpose="VPC_PEERING",
    prefix_length=22,
    network=network.id)
extended_instance = gcp.datafusion.Instance("extended_instance",
    name="my-instance",
    description="My Data Fusion instance",
    display_name="My Data Fusion instance",
    region="us-central1",
    type="BASIC",
    enable_stackdriver_logging=True,
    enable_stackdriver_monitoring=True,
    private_instance=True,
    dataproc_service_account=default.email,
    labels={
        "example_key": "example_value",
    },
    network_config={
        "network": "default",
        "ip_allocation": pulumi.Output.all(
            address=private_ip_alloc.address,
            prefix_length=private_ip_alloc.prefix_length
).apply(lambda resolved_outputs: f"{resolved_outputs['address']}/{resolved_outputs['prefix_length']}")
,
    },
    accelerators=[{
        "accelerator_type": "CDC",
        "state": "ENABLED",
    }])
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var @default = Gcp.AppEngine.GetDefaultServiceAccount.Invoke();

    var network = new Gcp.Compute.Network("network", new()
    {
        Name = "datafusion-full-network",
    });

    var privateIpAlloc = new Gcp.Compute.GlobalAddress("private_ip_alloc", new()
    {
        Name = "datafusion-ip-alloc",
        AddressType = "INTERNAL",
        Purpose = "VPC_PEERING",
        PrefixLength = 22,
        Network = network.Id,
    });

    var extendedInstance = new Gcp.DataFusion.Instance("extended_instance", new()
    {
        Name = "my-instance",
        Description = "My Data Fusion instance",
        DisplayName = "My Data Fusion instance",
        Region = "us-central1",
        Type = "BASIC",
        EnableStackdriverLogging = true,
        EnableStackdriverMonitoring = true,
        PrivateInstance = true,
        DataprocServiceAccount = @default.Apply(@default => @default.Apply(getDefaultServiceAccountResult => getDefaultServiceAccountResult.Email)),
        Labels = 
        {
            { "example_key", "example_value" },
        },
        NetworkConfig = new Gcp.DataFusion.Inputs.InstanceNetworkConfigArgs
        {
            Network = "default",
            IpAllocation = Output.Tuple(privateIpAlloc.Address, privateIpAlloc.PrefixLength).Apply(values =>
            {
                var address = values.Item1;
                var prefixLength = values.Item2;
                return $"{address}/{prefixLength}";
            }),
        },
        Accelerators = new[]
        {
            new Gcp.DataFusion.Inputs.InstanceAcceleratorArgs
            {
                AcceleratorType = "CDC",
                State = "ENABLED",
            },
        },
    });

});
```
```go
package main

import (
	"fmt"

	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/appengine"
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/compute"
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/datafusion"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		_default, err := appengine.GetDefaultServiceAccount(ctx, &appengine.GetDefaultServiceAccountArgs{}, nil)
		if err != nil {
			return err
		}
		network, err := compute.NewNetwork(ctx, "network", &compute.NetworkArgs{
			Name: pulumi.String("datafusion-full-network"),
		})
		if err != nil {
			return err
		}
		privateIpAlloc, err := compute.NewGlobalAddress(ctx, "private_ip_alloc", &compute.GlobalAddressArgs{
			Name:         pulumi.String("datafusion-ip-alloc"),
			AddressType:  pulumi.String("INTERNAL"),
			Purpose:      pulumi.String("VPC_PEERING"),
			PrefixLength: pulumi.Int(22),
			Network:      network.ID(),
		})
		if err != nil {
			return err
		}
		_, err = datafusion.NewInstance(ctx, "extended_instance", &datafusion.InstanceArgs{
			Name:                        pulumi.String("my-instance"),
			Description:                 pulumi.String("My Data Fusion instance"),
			DisplayName:                 pulumi.String("My Data Fusion instance"),
			Region:                      pulumi.String("us-central1"),
			Type:                        pulumi.String("BASIC"),
			EnableStackdriverLogging:    pulumi.Bool(true),
			EnableStackdriverMonitoring: pulumi.Bool(true),
			PrivateInstance:             pulumi.Bool(true),
			DataprocServiceAccount:      pulumi.String(_default.Email),
			Labels: pulumi.StringMap{
				"example_key": pulumi.String("example_value"),
			},
			NetworkConfig: &datafusion.InstanceNetworkConfigArgs{
				Network: pulumi.String("default"),
				IpAllocation: pulumi.All(privateIpAlloc.Address, privateIpAlloc.PrefixLength).ApplyT(func(_args []interface{}) (string, error) {
					address := _args[0].(string)
					prefixLength := _args[1].(int)
					return fmt.Sprintf("%v/%v", address, prefixLength), nil
				}).(pulumi.StringOutput),
			},
			Accelerators: datafusion.InstanceAcceleratorArray{
				&datafusion.InstanceAcceleratorArgs{
					AcceleratorType: pulumi.String("CDC"),
					State:           pulumi.String("ENABLED"),
				},
			},
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.appengine.AppengineFunctions;
import com.pulumi.gcp.appengine.inputs.GetDefaultServiceAccountArgs;
import com.pulumi.gcp.compute.Network;
import com.pulumi.gcp.compute.NetworkArgs;
import com.pulumi.gcp.compute.GlobalAddress;
import com.pulumi.gcp.compute.GlobalAddressArgs;
import com.pulumi.gcp.datafusion.Instance;
import com.pulumi.gcp.datafusion.InstanceArgs;
import com.pulumi.gcp.datafusion.inputs.InstanceNetworkConfigArgs;
import com.pulumi.gcp.datafusion.inputs.InstanceAcceleratorArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        final var default = AppengineFunctions.getDefaultServiceAccount();

        var network = new Network("network", NetworkArgs.builder()
            .name("datafusion-full-network")
            .build());

        var privateIpAlloc = new GlobalAddress("privateIpAlloc", GlobalAddressArgs.builder()
            .name("datafusion-ip-alloc")
            .addressType("INTERNAL")
            .purpose("VPC_PEERING")
            .prefixLength(22)
            .network(network.id())
            .build());

        var extendedInstance = new Instance("extendedInstance", InstanceArgs.builder()
            .name("my-instance")
            .description("My Data Fusion instance")
            .displayName("My Data Fusion instance")
            .region("us-central1")
            .type("BASIC")
            .enableStackdriverLogging(true)
            .enableStackdriverMonitoring(true)
            .privateInstance(true)
            .dataprocServiceAccount(default_.email())
            .labels(Map.of("example_key", "example_value"))
            .networkConfig(InstanceNetworkConfigArgs.builder()
                .network("default")
                .ipAllocation(Output.tuple(privateIpAlloc.address(), privateIpAlloc.prefixLength()).applyValue(values -> {
                    var address = values.t1;
                    var prefixLength = values.t2;
                    return String.format("%s/%s", address,prefixLength);
                }))
                .build())
            .accelerators(InstanceAcceleratorArgs.builder()
                .acceleratorType("CDC")
                .state("ENABLED")
                .build())
            .build());

    }
}
```
```yaml
resources:
  extendedInstance:
    type: gcp:datafusion:Instance
    name: extended_instance
    properties:
      name: my-instance
      description: My Data Fusion instance
      displayName: My Data Fusion instance
      region: us-central1
      type: BASIC
      enableStackdriverLogging: true
      enableStackdriverMonitoring: true
      privateInstance: true
      dataprocServiceAccount: ${default.email}
      labels:
        example_key: example_value
      networkConfig:
        network: default
        ipAllocation: ${privateIpAlloc.address}/${privateIpAlloc.prefixLength}
      accelerators:
        - acceleratorType: CDC
          state: ENABLED
  network:
    type: gcp:compute:Network
    properties:
      name: datafusion-full-network
  privateIpAlloc:
    type: gcp:compute:GlobalAddress
    name: private_ip_alloc
    properties:
      name: datafusion-ip-alloc
      addressType: INTERNAL
      purpose: VPC_PEERING
      prefixLength: 22
      network: ${network.id}
variables:
  default:
    fn::invoke:
      function: gcp:appengine:getDefaultServiceAccount
      arguments: {}
```
<!--End PulumiCodeChooser -->
### Data Fusion Instance Psc


<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const psc = new gcp.compute.Network("psc", {
    name: "datafusion-psc-network",
    autoCreateSubnetworks: false,
});
const pscSubnetwork = new gcp.compute.Subnetwork("psc", {
    name: "datafusion-psc-subnet",
    region: "us-central1",
    network: psc.id,
    ipCidrRange: "10.0.0.0/16",
});
const pscNetworkAttachment = new gcp.compute.NetworkAttachment("psc", {
    name: "datafusion-psc-attachment",
    region: "us-central1",
    connectionPreference: "ACCEPT_AUTOMATIC",
    subnetworks: [pscSubnetwork.selfLink],
});
const pscInstance = new gcp.datafusion.Instance("psc_instance", {
    name: "psc-instance",
    region: "us-central1",
    type: "BASIC",
    privateInstance: true,
    networkConfig: {
        connectionType: "PRIVATE_SERVICE_CONNECT_INTERFACES",
        privateServiceConnectConfig: {
            networkAttachment: pscNetworkAttachment.id,
            unreachableCidrBlock: "192.168.0.0/25",
        },
    },
});
```
```python
import pulumi
import pulumi_gcp as gcp

psc = gcp.compute.Network("psc",
    name="datafusion-psc-network",
    auto_create_subnetworks=False)
psc_subnetwork = gcp.compute.Subnetwork("psc",
    name="datafusion-psc-subnet",
    region="us-central1",
    network=psc.id,
    ip_cidr_range="10.0.0.0/16")
psc_network_attachment = gcp.compute.NetworkAttachment("psc",
    name="datafusion-psc-attachment",
    region="us-central1",
    connection_preference="ACCEPT_AUTOMATIC",
    subnetworks=[psc_subnetwork.self_link])
psc_instance = gcp.datafusion.Instance("psc_instance",
    name="psc-instance",
    region="us-central1",
    type="BASIC",
    private_instance=True,
    network_config={
        "connection_type": "PRIVATE_SERVICE_CONNECT_INTERFACES",
        "private_service_connect_config": {
            "network_attachment": psc_network_attachment.id,
            "unreachable_cidr_block": "192.168.0.0/25",
        },
    })
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var psc = new Gcp.Compute.Network("psc", new()
    {
        Name = "datafusion-psc-network",
        AutoCreateSubnetworks = false,
    });

    var pscSubnetwork = new Gcp.Compute.Subnetwork("psc", new()
    {
        Name = "datafusion-psc-subnet",
        Region = "us-central1",
        Network = psc.Id,
        IpCidrRange = "10.0.0.0/16",
    });

    var pscNetworkAttachment = new Gcp.Compute.NetworkAttachment("psc", new()
    {
        Name = "datafusion-psc-attachment",
        Region = "us-central1",
        ConnectionPreference = "ACCEPT_AUTOMATIC",
        Subnetworks = new[]
        {
            pscSubnetwork.SelfLink,
        },
    });

    var pscInstance = new Gcp.DataFusion.Instance("psc_instance", new()
    {
        Name = "psc-instance",
        Region = "us-central1",
        Type = "BASIC",
        PrivateInstance = true,
        NetworkConfig = new Gcp.DataFusion.Inputs.InstanceNetworkConfigArgs
        {
            ConnectionType = "PRIVATE_SERVICE_CONNECT_INTERFACES",
            PrivateServiceConnectConfig = new Gcp.DataFusion.Inputs.InstanceNetworkConfigPrivateServiceConnectConfigArgs
            {
                NetworkAttachment = pscNetworkAttachment.Id,
                UnreachableCidrBlock = "192.168.0.0/25",
            },
        },
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/compute"
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/datafusion"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		psc, err := compute.NewNetwork(ctx, "psc", &compute.NetworkArgs{
			Name:                  pulumi.String("datafusion-psc-network"),
			AutoCreateSubnetworks: pulumi.Bool(false),
		})
		if err != nil {
			return err
		}
		pscSubnetwork, err := compute.NewSubnetwork(ctx, "psc", &compute.SubnetworkArgs{
			Name:        pulumi.String("datafusion-psc-subnet"),
			Region:      pulumi.String("us-central1"),
			Network:     psc.ID(),
			IpCidrRange: pulumi.String("10.0.0.0/16"),
		})
		if err != nil {
			return err
		}
		pscNetworkAttachment, err := compute.NewNetworkAttachment(ctx, "psc", &compute.NetworkAttachmentArgs{
			Name:                 pulumi.String("datafusion-psc-attachment"),
			Region:               pulumi.String("us-central1"),
			ConnectionPreference: pulumi.String("ACCEPT_AUTOMATIC"),
			Subnetworks: pulumi.StringArray{
				pscSubnetwork.SelfLink,
			},
		})
		if err != nil {
			return err
		}
		_, err = datafusion.NewInstance(ctx, "psc_instance", &datafusion.InstanceArgs{
			Name:            pulumi.String("psc-instance"),
			Region:          pulumi.String("us-central1"),
			Type:            pulumi.String("BASIC"),
			PrivateInstance: pulumi.Bool(true),
			NetworkConfig: &datafusion.InstanceNetworkConfigArgs{
				ConnectionType: pulumi.String("PRIVATE_SERVICE_CONNECT_INTERFACES"),
				PrivateServiceConnectConfig: &datafusion.InstanceNetworkConfigPrivateServiceConnectConfigArgs{
					NetworkAttachment:    pscNetworkAttachment.ID(),
					UnreachableCidrBlock: pulumi.String("192.168.0.0/25"),
				},
			},
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.compute.Network;
import com.pulumi.gcp.compute.NetworkArgs;
import com.pulumi.gcp.compute.Subnetwork;
import com.pulumi.gcp.compute.SubnetworkArgs;
import com.pulumi.gcp.compute.NetworkAttachment;
import com.pulumi.gcp.compute.NetworkAttachmentArgs;
import com.pulumi.gcp.datafusion.Instance;
import com.pulumi.gcp.datafusion.InstanceArgs;
import com.pulumi.gcp.datafusion.inputs.InstanceNetworkConfigArgs;
import com.pulumi.gcp.datafusion.inputs.InstanceNetworkConfigPrivateServiceConnectConfigArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        var psc = new Network("psc", NetworkArgs.builder()
            .name("datafusion-psc-network")
            .autoCreateSubnetworks(false)
            .build());

        var pscSubnetwork = new Subnetwork("pscSubnetwork", SubnetworkArgs.builder()
            .name("datafusion-psc-subnet")
            .region("us-central1")
            .network(psc.id())
            .ipCidrRange("10.0.0.0/16")
            .build());

        var pscNetworkAttachment = new NetworkAttachment("pscNetworkAttachment", NetworkAttachmentArgs.builder()
            .name("datafusion-psc-attachment")
            .region("us-central1")
            .connectionPreference("ACCEPT_AUTOMATIC")
            .subnetworks(pscSubnetwork.selfLink())
            .build());

        var pscInstance = new Instance("pscInstance", InstanceArgs.builder()
            .name("psc-instance")
            .region("us-central1")
            .type("BASIC")
            .privateInstance(true)
            .networkConfig(InstanceNetworkConfigArgs.builder()
                .connectionType("PRIVATE_SERVICE_CONNECT_INTERFACES")
                .privateServiceConnectConfig(InstanceNetworkConfigPrivateServiceConnectConfigArgs.builder()
                    .networkAttachment(pscNetworkAttachment.id())
                    .unreachableCidrBlock("192.168.0.0/25")
                    .build())
                .build())
            .build());

    }
}
```
```yaml
resources:
  pscInstance:
    type: gcp:datafusion:Instance
    name: psc_instance
    properties:
      name: psc-instance
      region: us-central1
      type: BASIC
      privateInstance: true
      networkConfig:
        connectionType: PRIVATE_SERVICE_CONNECT_INTERFACES
        privateServiceConnectConfig:
          networkAttachment: ${pscNetworkAttachment.id}
          unreachableCidrBlock: 192.168.0.0/25
  psc:
    type: gcp:compute:Network
    properties:
      name: datafusion-psc-network
      autoCreateSubnetworks: false
  pscSubnetwork:
    type: gcp:compute:Subnetwork
    name: psc
    properties:
      name: datafusion-psc-subnet
      region: us-central1
      network: ${psc.id}
      ipCidrRange: 10.0.0.0/16
  pscNetworkAttachment:
    type: gcp:compute:NetworkAttachment
    name: psc
    properties:
      name: datafusion-psc-attachment
      region: us-central1
      connectionPreference: ACCEPT_AUTOMATIC
      subnetworks:
        - ${pscSubnetwork.selfLink}
```
<!--End PulumiCodeChooser -->
### Data Fusion Instance Cmek


<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const keyRing = new gcp.kms.KeyRing("key_ring", {
    name: "my-instance",
    location: "us-central1",
});
const cryptoKey = new gcp.kms.CryptoKey("crypto_key", {
    name: "my-instance",
    keyRing: keyRing.id,
});
const project = gcp.organizations.getProject({});
const cryptoKeyMember = new gcp.kms.CryptoKeyIAMMember("crypto_key_member", {
    cryptoKeyId: cryptoKey.id,
    role: "roles/cloudkms.cryptoKeyEncrypterDecrypter",
    member: project.then(project => `serviceAccount:service-${project.number}@gcp-sa-datafusion.iam.gserviceaccount.com`),
});
const cmek = new gcp.datafusion.Instance("cmek", {
    name: "my-instance",
    region: "us-central1",
    type: "BASIC",
    cryptoKeyConfig: {
        keyReference: cryptoKey.id,
    },
}, {
    dependsOn: [cryptoKeyMember],
});
```
```python
import pulumi
import pulumi_gcp as gcp

key_ring = gcp.kms.KeyRing("key_ring",
    name="my-instance",
    location="us-central1")
crypto_key = gcp.kms.CryptoKey("crypto_key",
    name="my-instance",
    key_ring=key_ring.id)
project = gcp.organizations.get_project()
crypto_key_member = gcp.kms.CryptoKeyIAMMember("crypto_key_member",
    crypto_key_id=crypto_key.id,
    role="roles/cloudkms.cryptoKeyEncrypterDecrypter",
    member=f"serviceAccount:service-{project.number}@gcp-sa-datafusion.iam.gserviceaccount.com")
cmek = gcp.datafusion.Instance("cmek",
    name="my-instance",
    region="us-central1",
    type="BASIC",
    crypto_key_config={
        "key_reference": crypto_key.id,
    },
    opts = pulumi.ResourceOptions(depends_on=[crypto_key_member]))
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var keyRing = new Gcp.Kms.KeyRing("key_ring", new()
    {
        Name = "my-instance",
        Location = "us-central1",
    });

    var cryptoKey = new Gcp.Kms.CryptoKey("crypto_key", new()
    {
        Name = "my-instance",
        KeyRing = keyRing.Id,
    });

    var project = Gcp.Organizations.GetProject.Invoke();

    var cryptoKeyMember = new Gcp.Kms.CryptoKeyIAMMember("crypto_key_member", new()
    {
        CryptoKeyId = cryptoKey.Id,
        Role = "roles/cloudkms.cryptoKeyEncrypterDecrypter",
        Member = $"serviceAccount:service-{project.Apply(getProjectResult => getProjectResult.Number)}@gcp-sa-datafusion.iam.gserviceaccount.com",
    });

    var cmek = new Gcp.DataFusion.Instance("cmek", new()
    {
        Name = "my-instance",
        Region = "us-central1",
        Type = "BASIC",
        CryptoKeyConfig = new Gcp.DataFusion.Inputs.InstanceCryptoKeyConfigArgs
        {
            KeyReference = cryptoKey.Id,
        },
    }, new CustomResourceOptions
    {
        DependsOn =
        {
            cryptoKeyMember,
        },
    });

});
```
```go
package main

import (
	"fmt"

	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/datafusion"
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/kms"
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/organizations"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		keyRing, err := kms.NewKeyRing(ctx, "key_ring", &kms.KeyRingArgs{
			Name:     pulumi.String("my-instance"),
			Location: pulumi.String("us-central1"),
		})
		if err != nil {
			return err
		}
		cryptoKey, err := kms.NewCryptoKey(ctx, "crypto_key", &kms.CryptoKeyArgs{
			Name:    pulumi.String("my-instance"),
			KeyRing: keyRing.ID(),
		})
		if err != nil {
			return err
		}
		project, err := organizations.LookupProject(ctx, &organizations.LookupProjectArgs{}, nil)
		if err != nil {
			return err
		}
		cryptoKeyMember, err := kms.NewCryptoKeyIAMMember(ctx, "crypto_key_member", &kms.CryptoKeyIAMMemberArgs{
			CryptoKeyId: cryptoKey.ID(),
			Role:        pulumi.String("roles/cloudkms.cryptoKeyEncrypterDecrypter"),
			Member:      pulumi.Sprintf("serviceAccount:service-%v@gcp-sa-datafusion.iam.gserviceaccount.com", project.Number),
		})
		if err != nil {
			return err
		}
		_, err = datafusion.NewInstance(ctx, "cmek", &datafusion.InstanceArgs{
			Name:   pulumi.String("my-instance"),
			Region: pulumi.String("us-central1"),
			Type:   pulumi.String("BASIC"),
			CryptoKeyConfig: &datafusion.InstanceCryptoKeyConfigArgs{
				KeyReference: cryptoKey.ID(),
			},
		}, pulumi.DependsOn([]pulumi.Resource{
			cryptoKeyMember,
		}))
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.kms.KeyRing;
import com.pulumi.gcp.kms.KeyRingArgs;
import com.pulumi.gcp.kms.CryptoKey;
import com.pulumi.gcp.kms.CryptoKeyArgs;
import com.pulumi.gcp.organizations.OrganizationsFunctions;
import com.pulumi.gcp.organizations.inputs.GetProjectArgs;
import com.pulumi.gcp.kms.CryptoKeyIAMMember;
import com.pulumi.gcp.kms.CryptoKeyIAMMemberArgs;
import com.pulumi.gcp.datafusion.Instance;
import com.pulumi.gcp.datafusion.InstanceArgs;
import com.pulumi.gcp.datafusion.inputs.InstanceCryptoKeyConfigArgs;
import com.pulumi.resources.CustomResourceOptions;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        var keyRing = new KeyRing("keyRing", KeyRingArgs.builder()
            .name("my-instance")
            .location("us-central1")
            .build());

        var cryptoKey = new CryptoKey("cryptoKey", CryptoKeyArgs.builder()
            .name("my-instance")
            .keyRing(keyRing.id())
            .build());

        final var project = OrganizationsFunctions.getProject();

        var cryptoKeyMember = new CryptoKeyIAMMember("cryptoKeyMember", CryptoKeyIAMMemberArgs.builder()
            .cryptoKeyId(cryptoKey.id())
            .role("roles/cloudkms.cryptoKeyEncrypterDecrypter")
            .member(String.format("serviceAccount:service-%s@gcp-sa-datafusion.iam.gserviceaccount.com", project.applyValue(getProjectResult -> getProjectResult.number())))
            .build());

        var cmek = new Instance("cmek", InstanceArgs.builder()
            .name("my-instance")
            .region("us-central1")
            .type("BASIC")
            .cryptoKeyConfig(InstanceCryptoKeyConfigArgs.builder()
                .keyReference(cryptoKey.id())
                .build())
            .build(), CustomResourceOptions.builder()
                .dependsOn(cryptoKeyMember)
                .build());

    }
}
```
```yaml
resources:
  cmek:
    type: gcp:datafusion:Instance
    properties:
      name: my-instance
      region: us-central1
      type: BASIC
      cryptoKeyConfig:
        keyReference: ${cryptoKey.id}
    options:
      dependsOn:
        - ${cryptoKeyMember}
  cryptoKey:
    type: gcp:kms:CryptoKey
    name: crypto_key
    properties:
      name: my-instance
      keyRing: ${keyRing.id}
  keyRing:
    type: gcp:kms:KeyRing
    name: key_ring
    properties:
      name: my-instance
      location: us-central1
  cryptoKeyMember:
    type: gcp:kms:CryptoKeyIAMMember
    name: crypto_key_member
    properties:
      cryptoKeyId: ${cryptoKey.id}
      role: roles/cloudkms.cryptoKeyEncrypterDecrypter
      member: serviceAccount:service-${project.number}@gcp-sa-datafusion.iam.gserviceaccount.com
variables:
  project:
    fn::invoke:
      function: gcp:organizations:getProject
      arguments: {}
```
<!--End PulumiCodeChooser -->
### Data Fusion Instance Enterprise


<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const enterpriseInstance = new gcp.datafusion.Instance("enterprise_instance", {
    name: "my-instance",
    region: "us-central1",
    type: "ENTERPRISE",
    enableRbac: true,
});
```
```python
import pulumi
import pulumi_gcp as gcp

enterprise_instance = gcp.datafusion.Instance("enterprise_instance",
    name="my-instance",
    region="us-central1",
    type="ENTERPRISE",
    enable_rbac=True)
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var enterpriseInstance = new Gcp.DataFusion.Instance("enterprise_instance", new()
    {
        Name = "my-instance",
        Region = "us-central1",
        Type = "ENTERPRISE",
        EnableRbac = true,
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/datafusion"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		_, err := datafusion.NewInstance(ctx, "enterprise_instance", &datafusion.InstanceArgs{
			Name:       pulumi.String("my-instance"),
			Region:     pulumi.String("us-central1"),
			Type:       pulumi.String("ENTERPRISE"),
			EnableRbac: pulumi.Bool(true),
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.datafusion.Instance;
import com.pulumi.gcp.datafusion.InstanceArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        var enterpriseInstance = new Instance("enterpriseInstance", InstanceArgs.builder()
            .name("my-instance")
            .region("us-central1")
            .type("ENTERPRISE")
            .enableRbac(true)
            .build());

    }
}
```
```yaml
resources:
  enterpriseInstance:
    type: gcp:datafusion:Instance
    name: enterprise_instance
    properties:
      name: my-instance
      region: us-central1
      type: ENTERPRISE
      enableRbac: true
```
<!--End PulumiCodeChooser -->
### Data Fusion Instance Event


<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const eventTopic = new gcp.pubsub.Topic("event", {name: "my-instance"});
const event = new gcp.datafusion.Instance("event", {
    name: "my-instance",
    region: "us-central1",
    type: "BASIC",
    eventPublishConfig: {
        enabled: true,
        topic: eventTopic.id,
    },
});
```
```python
import pulumi
import pulumi_gcp as gcp

event_topic = gcp.pubsub.Topic("event", name="my-instance")
event = gcp.datafusion.Instance("event",
    name="my-instance",
    region="us-central1",
    type="BASIC",
    event_publish_config={
        "enabled": True,
        "topic": event_topic.id,
    })
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var eventTopic = new Gcp.PubSub.Topic("event", new()
    {
        Name = "my-instance",
    });

    var @event = new Gcp.DataFusion.Instance("event", new()
    {
        Name = "my-instance",
        Region = "us-central1",
        Type = "BASIC",
        EventPublishConfig = new Gcp.DataFusion.Inputs.InstanceEventPublishConfigArgs
        {
            Enabled = true,
            Topic = eventTopic.Id,
        },
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/datafusion"
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/pubsub"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		eventTopic, err := pubsub.NewTopic(ctx, "event", &pubsub.TopicArgs{
			Name: pulumi.String("my-instance"),
		})
		if err != nil {
			return err
		}
		_, err = datafusion.NewInstance(ctx, "event", &datafusion.InstanceArgs{
			Name:   pulumi.String("my-instance"),
			Region: pulumi.String("us-central1"),
			Type:   pulumi.String("BASIC"),
			EventPublishConfig: &datafusion.InstanceEventPublishConfigArgs{
				Enabled: pulumi.Bool(true),
				Topic:   eventTopic.ID(),
			},
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.pubsub.Topic;
import com.pulumi.gcp.pubsub.TopicArgs;
import com.pulumi.gcp.datafusion.Instance;
import com.pulumi.gcp.datafusion.InstanceArgs;
import com.pulumi.gcp.datafusion.inputs.InstanceEventPublishConfigArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        var eventTopic = new Topic("eventTopic", TopicArgs.builder()
            .name("my-instance")
            .build());

        var event = new Instance("event", InstanceArgs.builder()
            .name("my-instance")
            .region("us-central1")
            .type("BASIC")
            .eventPublishConfig(InstanceEventPublishConfigArgs.builder()
                .enabled(true)
                .topic(eventTopic.id())
                .build())
            .build());

    }
}
```
```yaml
resources:
  event:
    type: gcp:datafusion:Instance
    properties:
      name: my-instance
      region: us-central1
      type: BASIC
      eventPublishConfig:
        enabled: true
        topic: ${eventTopic.id}
  eventTopic:
    type: gcp:pubsub:Topic
    name: event
    properties:
      name: my-instance
```
<!--End PulumiCodeChooser -->
### Data Fusion Instance Zone


<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const zone = new gcp.datafusion.Instance("zone", {
    name: "my-instance",
    region: "us-central1",
    zone: "us-central1-a",
    type: "DEVELOPER",
});
```
```python
import pulumi
import pulumi_gcp as gcp

zone = gcp.datafusion.Instance("zone",
    name="my-instance",
    region="us-central1",
    zone="us-central1-a",
    type="DEVELOPER")
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var zone = new Gcp.DataFusion.Instance("zone", new()
    {
        Name = "my-instance",
        Region = "us-central1",
        Zone = "us-central1-a",
        Type = "DEVELOPER",
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/datafusion"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		_, err := datafusion.NewInstance(ctx, "zone", &datafusion.InstanceArgs{
			Name:   pulumi.String("my-instance"),
			Region: pulumi.String("us-central1"),
			Zone:   pulumi.String("us-central1-a"),
			Type:   pulumi.String("DEVELOPER"),
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.datafusion.Instance;
import com.pulumi.gcp.datafusion.InstanceArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        var zone = new Instance("zone", InstanceArgs.builder()
            .name("my-instance")
            .region("us-central1")
            .zone("us-central1-a")
            .type("DEVELOPER")
            .build());

    }
}
```
```yaml
resources:
  zone:
    type: gcp:datafusion:Instance
    properties:
      name: my-instance
      region: us-central1
      zone: us-central1-a
      type: DEVELOPER
```
<!--End PulumiCodeChooser -->

## Import

Instance can be imported using any of these accepted formats:

* `projects/{{project}}/locations/{{region}}/instances/{{name}}`

* `{{project}}/{{region}}/{{name}}`

* `{{region}}/{{name}}`

* `{{name}}`

When using the `pulumi import` command, Instance can be imported using one of the formats above. For example:

```sh
$ pulumi import gcp:datafusion/instance:Instance default projects/{{project}}/locations/{{region}}/instances/{{name}}
```

```sh
$ pulumi import gcp:datafusion/instance:Instance default {{project}}/{{region}}/{{name}}
```

```sh
$ pulumi import gcp:datafusion/instance:Instance default {{region}}/{{name}}
```

```sh
$ pulumi import gcp:datafusion/instance:Instance default {{name}}
```

¼
acceleratorsaB_*]:[
Y

datafusionInstanceAccelerator6gcp:datafusion/InstanceAccelerator:InstanceAcceleratorÈList of accelerators enabled for this CDF instance.
If accelerators are enabled it is possible a permadiff will be created with the Options field.
Users will need to either manually update their state file to include these diffed options, or include the field in a lifecycle ignore changes block.
Structure is documented below.

cryptoKeyConfigkBi:g
e

datafusionInstanceCryptoKeyConfig>gcp:datafusion/InstanceCryptoKeyConfig:InstanceCryptoKeyConfigThe crypto key configuration. This field is used by the Customer-Managed Encryption Keys (CMEK) feature.
Structure is documented below.

dataprocServiceAccountB" zUser-managed service account to set on Dataproc when Cloud Data Fusion creates Dataproc to run data processing pipelines.
>
descriptionB" )An optional description of the instance.
3
displayNameB" Display name for an instance.
I

enableRbacB
 5Option to enable granular role-based access control.
H
enableStackdriverLoggingB
 &Option to enable Stackdriver Logging.
N
enableStackdriverMonitoringB
 )Option to enable Stackdriver Monitoring.
ä
eventPublishConfigtBr:p
n

datafusionInstanceEventPublishConfigDgcp:datafusion/InstanceEventPublishConfig:InstanceEventPublishConfigXOption to enable and pass metadata for event publishing.
Structure is documented below.
Ì
labelsB2" ¹The resource labels for instance to use to annotate any related underlying resources,
such as Compute Engine VMs.

**Note**: This field is non-authoritative, and will only manage the labels present in your configuration.
Please refer to the field `effective_labels` for all of the labels present on the resource.
W
nameB" IThe ID of the instance or a fully qualified identifier for the instance.

networkConfigeBc:a
_

datafusionInstanceNetworkConfig:gcp:datafusion/InstanceNetworkConfig:InstanceNetworkConfigNetwork configuration options. These are required when a private Data Fusion instance is to be created.
Structure is documented below.
e
optionsB2" RMap of additional options used to configure the behavior of Data Fusion instance.
Ñ
privateInstanceB
 ·Specifies whether the Data Fusion instance should be private. If set to
true, all Data Fusion nodes will have private IP addresses and will not be
able to access the public internet.
{
projectB" jThe ID of the project in which the resource belongs.
If it is not provided, the provider project is used.
8
regionB" (The region of the Data Fusion instance.

type" óRepresents the type of Data Fusion instance. Each type is configured with
the default settings for processing and memory.
- BASIC: Basic Data Fusion instance. In Basic type, the user will be able to create data pipelines
using point and click UI. However, there are certain limitations, such as fewer number
of concurrent pipelines, no support for streaming pipelines, etc.
- ENTERPRISE: Enterprise Data Fusion instance. In Enterprise type, the user will have more features
available, such as support for streaming pipelines, higher number of concurrent pipelines, etc.
- DEVELOPER: Developer Data Fusion instance. In Developer type, the user will have all features available but
with restrictive capabilities. This is to help enterprises design and develop their data ingestion and integration
pipelines at low cost.
Possible values are: `BASIC`, `ENTERPRISE`, `DEVELOPER`.


- - -
5
versionB" $Current version of the Data Fusion.
{
zoneB" mName of the zone in which the Data Fusion instance will be created. Only DEVELOPER instances use this field.
"¼
acceleratorsaB_*]:[
Y

datafusionInstanceAccelerator6gcp:datafusion/InstanceAccelerator:InstanceAcceleratorÈList of accelerators enabled for this CDF instance.
If accelerators are enabled it is possible a permadiff will be created with the Options field.
Users will need to either manually update their state file to include these diffed options, or include the field in a lifecycle ignore changes block.
Structure is documented below.
"B
apiEndpoint" /Endpoint on which the REST APIs is accessible.
"k

createTime" YThe time the instance was created in RFC3339 UTC "Zulu" format, accurate to nanoseconds.
"
cryptoKeyConfigkBi:g
e

datafusionInstanceCryptoKeyConfig>gcp:datafusion/InstanceCryptoKeyConfig:InstanceCryptoKeyConfigThe crypto key configuration. This field is used by the Customer-Managed Encryption Keys (CMEK) feature.
Structure is documented below.
"
dataprocServiceAccountB" zUser-managed service account to set on Dataproc when Cloud Data Fusion creates Dataproc to run data processing pipelines.
">
descriptionB" )An optional description of the instance.
"3
displayNameB" Display name for an instance.
"¦
effectiveLabels2" All of labels (key/value pairs) present on the resource in GCP, including the labels configured through Pulumi, other clients and services.
"I

enableRbacB
 5Option to enable granular role-based access control.
"H
enableStackdriverLoggingB
 &Option to enable Stackdriver Logging.
"N
enableStackdriverMonitoringB
 )Option to enable Stackdriver Monitoring.
"ä
eventPublishConfigtBr:p
n

datafusionInstanceEventPublishConfigDgcp:datafusion/InstanceEventPublishConfig:InstanceEventPublishConfigXOption to enable and pass metadata for event publishing.
Structure is documented below.
"X
	gcsBucket" GCloud Storage bucket generated by Data Fusion in the customer project.
"Ì
labelsB2" ¹The resource labels for instance to use to annotate any related underlying resources,
such as Compute Engine VMs.

**Note**: This field is non-authoritative, and will only manage the labels present in your configuration.
Please refer to the field `effective_labels` for all of the labels present on the resource.
"U
name" IThe ID of the instance or a fully qualified identifier for the instance.
"
networkConfigeBc:a
_

datafusionInstanceNetworkConfig:gcp:datafusion/InstanceNetworkConfig:InstanceNetworkConfigNetwork configuration options. These are required when a private Data Fusion instance is to be created.
Structure is documented below.
"c
options2" RMap of additional options used to configure the behavior of Data Fusion instance.
"E
p4ServiceAccount" -P4 service account for the customer project.
"Ñ
privateInstanceB
 ·Specifies whether the Data Fusion instance should be private. If set to
true, all Data Fusion nodes will have private IP addresses and will not be
able to access the public internet.
"y
project" jThe ID of the project in which the resource belongs.
If it is not provided, the provider project is used.
"
pulumiLabels2" mThe combination of labels configured directly on the resource
and default labels configured on the provider.
"6
region" (The region of the Data Fusion instance.
"f
serviceAccount" PService account which will be used to access resources in the customer project.
"Z
serviceEndpoint" CEndpoint on which the Data Fusion UI and REST APIs are accessible.
"µ
state" §The current state of this Data Fusion instance.
- CREATING: Instance is being created
- RUNNING: Instance is running and ready for requests
- FAILED: Instance creation failed
- DELETING: Instance is being deleted
- UPGRADING: Instance is being upgraded
- RESTARTING: Instance is being restarted
"n
stateMessage" ZAdditional information about the current state of this Data Fusion instance if available.
"7
tenantProjectId"  The name of the tenant project.
"
type" óRepresents the type of Data Fusion instance. Each type is configured with
the default settings for processing and memory.
- BASIC: Basic Data Fusion instance. In Basic type, the user will be able to create data pipelines
using point and click UI. However, there are certain limitations, such as fewer number
of concurrent pipelines, no support for streaming pipelines, etc.
- ENTERPRISE: Enterprise Data Fusion instance. In Enterprise type, the user will have more features
available, such as support for streaming pipelines, higher number of concurrent pipelines, etc.
- DEVELOPER: Developer Data Fusion instance. In Developer type, the user will have all features available but
with restrictive capabilities. This is to help enterprises design and develop their data ingestion and integration
pipelines at low cost.
Possible values are: `BASIC`, `ENTERPRISE`, `DEVELOPER`.


- - -
"p

updateTime" ^The time the instance was last updated in RFC3339 UTC "Zulu" format, accurate to nanoseconds.
"3
version" $Current version of the Data Fusion.
"y
zone" mName of the zone in which the Data Fusion instance will be created. Only DEVELOPER instances use this field.
*Ùæ
p
datalossPreventionDeidentifyTemplateFgcp:dataloss/preventionDeidentifyTemplate:PreventionDeidentifyTemplateÖAllows creation of templates to de-identify content.


To get more information about DeidentifyTemplate, see:

* [API documentation](https://cloud.google.com/dlp/docs/reference/rest/v2/projects.deidentifyTemplates)
* How-to Guides
    * [Official Documentation](https://cloud.google.com/dlp/docs/concepts-templates)



## Example Usage

### Dlp Deidentify Template Basic


<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const basic = new gcp.dataloss.PreventionDeidentifyTemplate("basic", {
    parent: "projects/my-project-name",
    description: "Description",
    displayName: "Displayname",
    deidentifyConfig: {
        infoTypeTransformations: {
            transformations: [
                {
                    infoTypes: [{
                        name: "FIRST_NAME",
                    }],
                    primitiveTransformation: {
                        replaceWithInfoTypeConfig: true,
                    },
                },
                {
                    infoTypes: [
                        {
                            name: "PHONE_NUMBER",
                        },
                        {
                            name: "AGE",
                        },
                    ],
                    primitiveTransformation: {
                        replaceConfig: {
                            newValue: {
                                integerValue: 9,
                            },
                        },
                    },
                },
                {
                    infoTypes: [
                        {
                            name: "EMAIL_ADDRESS",
                        },
                        {
                            name: "LAST_NAME",
                        },
                    ],
                    primitiveTransformation: {
                        characterMaskConfig: {
                            maskingCharacter: "X",
                            numberToMask: 4,
                            reverseOrder: true,
                            charactersToIgnores: [{
                                commonCharactersToIgnore: "PUNCTUATION",
                            }],
                        },
                    },
                },
                {
                    infoTypes: [{
                        name: "DATE_OF_BIRTH",
                    }],
                    primitiveTransformation: {
                        replaceConfig: {
                            newValue: {
                                dateValue: {
                                    year: 2020,
                                    month: 1,
                                    day: 1,
                                },
                            },
                        },
                    },
                },
                {
                    infoTypes: [{
                        name: "CREDIT_CARD_NUMBER",
                    }],
                    primitiveTransformation: {
                        cryptoDeterministicConfig: {
                            context: {
                                name: "sometweak",
                            },
                            cryptoKey: {
                                transient: {
                                    name: "beep",
                                },
                            },
                            surrogateInfoType: {
                                name: "abc",
                            },
                        },
                    },
                },
            ],
        },
    },
});
```
```python
import pulumi
import pulumi_gcp as gcp

basic = gcp.dataloss.PreventionDeidentifyTemplate("basic",
    parent="projects/my-project-name",
    description="Description",
    display_name="Displayname",
    deidentify_config={
        "info_type_transformations": {
            "transformations": [
                {
                    "info_types": [{
                        "name": "FIRST_NAME",
                    }],
                    "primitive_transformation": {
                        "replace_with_info_type_config": True,
                    },
                },
                {
                    "info_types": [
                        {
                            "name": "PHONE_NUMBER",
                        },
                        {
                            "name": "AGE",
                        },
                    ],
                    "primitive_transformation": {
                        "replace_config": {
                            "new_value": {
                                "integer_value": 9,
                            },
                        },
                    },
                },
                {
                    "info_types": [
                        {
                            "name": "EMAIL_ADDRESS",
                        },
                        {
                            "name": "LAST_NAME",
                        },
                    ],
                    "primitive_transformation": {
                        "character_mask_config": {
                            "masking_character": "X",
                            "number_to_mask": 4,
                            "reverse_order": True,
                            "characters_to_ignores": [{
                                "common_characters_to_ignore": "PUNCTUATION",
                            }],
                        },
                    },
                },
                {
                    "info_types": [{
                        "name": "DATE_OF_BIRTH",
                    }],
                    "primitive_transformation": {
                        "replace_config": {
                            "new_value": {
                                "date_value": {
                                    "year": 2020,
                                    "month": 1,
                                    "day": 1,
                                },
                            },
                        },
                    },
                },
                {
                    "info_types": [{
                        "name": "CREDIT_CARD_NUMBER",
                    }],
                    "primitive_transformation": {
                        "crypto_deterministic_config": {
                            "context": {
                                "name": "sometweak",
                            },
                            "crypto_key": {
                                "transient": {
                                    "name": "beep",
                                },
                            },
                            "surrogate_info_type": {
                                "name": "abc",
                            },
                        },
                    },
                },
            ],
        },
    })
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var basic = new Gcp.DataLoss.PreventionDeidentifyTemplate("basic", new()
    {
        Parent = "projects/my-project-name",
        Description = "Description",
        DisplayName = "Displayname",
        DeidentifyConfig = new Gcp.DataLoss.Inputs.PreventionDeidentifyTemplateDeidentifyConfigArgs
        {
            InfoTypeTransformations = new Gcp.DataLoss.Inputs.PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsArgs
            {
                Transformations = new[]
                {
                    new Gcp.DataLoss.Inputs.PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationArgs
                    {
                        InfoTypes = new[]
                        {
                            new Gcp.DataLoss.Inputs.PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationInfoTypeArgs
                            {
                                Name = "FIRST_NAME",
                            },
                        },
                        PrimitiveTransformation = new Gcp.DataLoss.Inputs.PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationArgs
                        {
                            ReplaceWithInfoTypeConfig = true,
                        },
                    },
                    new Gcp.DataLoss.Inputs.PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationArgs
                    {
                        InfoTypes = new[]
                        {
                            new Gcp.DataLoss.Inputs.PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationInfoTypeArgs
                            {
                                Name = "PHONE_NUMBER",
                            },
                            new Gcp.DataLoss.Inputs.PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationInfoTypeArgs
                            {
                                Name = "AGE",
                            },
                        },
                        PrimitiveTransformation = new Gcp.DataLoss.Inputs.PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationArgs
                        {
                            ReplaceConfig = new Gcp.DataLoss.Inputs.PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationReplaceConfigArgs
                            {
                                NewValue = new Gcp.DataLoss.Inputs.PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationReplaceConfigNewValueArgs
                                {
                                    IntegerValue = 9,
                                },
                            },
                        },
                    },
                    new Gcp.DataLoss.Inputs.PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationArgs
                    {
                        InfoTypes = new[]
                        {
                            new Gcp.DataLoss.Inputs.PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationInfoTypeArgs
                            {
                                Name = "EMAIL_ADDRESS",
                            },
                            new Gcp.DataLoss.Inputs.PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationInfoTypeArgs
                            {
                                Name = "LAST_NAME",
                            },
                        },
                        PrimitiveTransformation = new Gcp.DataLoss.Inputs.PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationArgs
                        {
                            CharacterMaskConfig = new Gcp.DataLoss.Inputs.PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationCharacterMaskConfigArgs
                            {
                                MaskingCharacter = "X",
                                NumberToMask = 4,
                                ReverseOrder = true,
                                CharactersToIgnores = new[]
                                {
                                    new Gcp.DataLoss.Inputs.PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationCharacterMaskConfigCharactersToIgnoreArgs
                                    {
                                        CommonCharactersToIgnore = "PUNCTUATION",
                                    },
                                },
                            },
                        },
                    },
                    new Gcp.DataLoss.Inputs.PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationArgs
                    {
                        InfoTypes = new[]
                        {
                            new Gcp.DataLoss.Inputs.PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationInfoTypeArgs
                            {
                                Name = "DATE_OF_BIRTH",
                            },
                        },
                        PrimitiveTransformation = new Gcp.DataLoss.Inputs.PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationArgs
                        {
                            ReplaceConfig = new Gcp.DataLoss.Inputs.PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationReplaceConfigArgs
                            {
                                NewValue = new Gcp.DataLoss.Inputs.PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationReplaceConfigNewValueArgs
                                {
                                    DateValue = new Gcp.DataLoss.Inputs.PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationReplaceConfigNewValueDateValueArgs
                                    {
                                        Year = 2020,
                                        Month = 1,
                                        Day = 1,
                                    },
                                },
                            },
                        },
                    },
                    new Gcp.DataLoss.Inputs.PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationArgs
                    {
                        InfoTypes = new[]
                        {
                            new Gcp.DataLoss.Inputs.PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationInfoTypeArgs
                            {
                                Name = "CREDIT_CARD_NUMBER",
                            },
                        },
                        PrimitiveTransformation = new Gcp.DataLoss.Inputs.PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationArgs
                        {
                            CryptoDeterministicConfig = new Gcp.DataLoss.Inputs.PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationCryptoDeterministicConfigArgs
                            {
                                Context = new Gcp.DataLoss.Inputs.PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationCryptoDeterministicConfigContextArgs
                                {
                                    Name = "sometweak",
                                },
                                CryptoKey = new Gcp.DataLoss.Inputs.PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationCryptoDeterministicConfigCryptoKeyArgs
                                {
                                    Transient = new Gcp.DataLoss.Inputs.PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationCryptoDeterministicConfigCryptoKeyTransientArgs
                                    {
                                        Name = "beep",
                                    },
                                },
                                SurrogateInfoType = new Gcp.DataLoss.Inputs.PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationCryptoDeterministicConfigSurrogateInfoTypeArgs
                                {
                                    Name = "abc",
                                },
                            },
                        },
                    },
                },
            },
        },
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/dataloss"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		_, err := dataloss.NewPreventionDeidentifyTemplate(ctx, "basic", &dataloss.PreventionDeidentifyTemplateArgs{
			Parent:      pulumi.String("projects/my-project-name"),
			Description: pulumi.String("Description"),
			DisplayName: pulumi.String("Displayname"),
			DeidentifyConfig: &dataloss.PreventionDeidentifyTemplateDeidentifyConfigArgs{
				InfoTypeTransformations: &dataloss.PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsArgs{
					Transformations: dataloss.PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationArray{
						&dataloss.PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationArgs{
							InfoTypes: dataloss.PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationInfoTypeArray{
								&dataloss.PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationInfoTypeArgs{
									Name: pulumi.String("FIRST_NAME"),
								},
							},
							PrimitiveTransformation: &dataloss.PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationArgs{
								ReplaceWithInfoTypeConfig: pulumi.Bool(true),
							},
						},
						&dataloss.PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationArgs{
							InfoTypes: dataloss.PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationInfoTypeArray{
								&dataloss.PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationInfoTypeArgs{
									Name: pulumi.String("PHONE_NUMBER"),
								},
								&dataloss.PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationInfoTypeArgs{
									Name: pulumi.String("AGE"),
								},
							},
							PrimitiveTransformation: &dataloss.PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationArgs{
								ReplaceConfig: &dataloss.PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationReplaceConfigArgs{
									NewValue: &dataloss.PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationReplaceConfigNewValueArgs{
										IntegerValue: pulumi.Int(9),
									},
								},
							},
						},
						&dataloss.PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationArgs{
							InfoTypes: dataloss.PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationInfoTypeArray{
								&dataloss.PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationInfoTypeArgs{
									Name: pulumi.String("EMAIL_ADDRESS"),
								},
								&dataloss.PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationInfoTypeArgs{
									Name: pulumi.String("LAST_NAME"),
								},
							},
							PrimitiveTransformation: &dataloss.PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationArgs{
								CharacterMaskConfig: &dataloss.PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationCharacterMaskConfigArgs{
									MaskingCharacter: pulumi.String("X"),
									NumberToMask:     pulumi.Int(4),
									ReverseOrder:     pulumi.Bool(true),
									CharactersToIgnores: dataloss.PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationCharacterMaskConfigCharactersToIgnoreArray{
										&dataloss.PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationCharacterMaskConfigCharactersToIgnoreArgs{
											CommonCharactersToIgnore: pulumi.String("PUNCTUATION"),
										},
									},
								},
							},
						},
						&dataloss.PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationArgs{
							InfoTypes: dataloss.PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationInfoTypeArray{
								&dataloss.PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationInfoTypeArgs{
									Name: pulumi.String("DATE_OF_BIRTH"),
								},
							},
							PrimitiveTransformation: &dataloss.PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationArgs{
								ReplaceConfig: &dataloss.PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationReplaceConfigArgs{
									NewValue: &dataloss.PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationReplaceConfigNewValueArgs{
										DateValue: &dataloss.PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationReplaceConfigNewValueDateValueArgs{
											Year:  pulumi.Int(2020),
											Month: pulumi.Int(1),
											Day:   pulumi.Int(1),
										},
									},
								},
							},
						},
						&dataloss.PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationArgs{
							InfoTypes: dataloss.PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationInfoTypeArray{
								&dataloss.PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationInfoTypeArgs{
									Name: pulumi.String("CREDIT_CARD_NUMBER"),
								},
							},
							PrimitiveTransformation: &dataloss.PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationArgs{
								CryptoDeterministicConfig: &dataloss.PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationCryptoDeterministicConfigArgs{
									Context: &dataloss.PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationCryptoDeterministicConfigContextArgs{
										Name: pulumi.String("sometweak"),
									},
									CryptoKey: &dataloss.PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationCryptoDeterministicConfigCryptoKeyArgs{
										Transient: &dataloss.PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationCryptoDeterministicConfigCryptoKeyTransientArgs{
											Name: pulumi.String("beep"),
										},
									},
									SurrogateInfoType: &dataloss.PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationCryptoDeterministicConfigSurrogateInfoTypeArgs{
										Name: pulumi.String("abc"),
									},
								},
							},
						},
					},
				},
			},
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.dataloss.PreventionDeidentifyTemplate;
import com.pulumi.gcp.dataloss.PreventionDeidentifyTemplateArgs;
import com.pulumi.gcp.dataloss.inputs.PreventionDeidentifyTemplateDeidentifyConfigArgs;
import com.pulumi.gcp.dataloss.inputs.PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        var basic = new PreventionDeidentifyTemplate("basic", PreventionDeidentifyTemplateArgs.builder()
            .parent("projects/my-project-name")
            .description("Description")
            .displayName("Displayname")
            .deidentifyConfig(PreventionDeidentifyTemplateDeidentifyConfigArgs.builder()
                .infoTypeTransformations(PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsArgs.builder()
                    .transformations(                    
                        PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationArgs.builder()
                            .infoTypes(PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationInfoTypeArgs.builder()
                                .name("FIRST_NAME")
                                .build())
                            .primitiveTransformation(PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationArgs.builder()
                                .replaceWithInfoTypeConfig(true)
                                .build())
                            .build(),
                        PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationArgs.builder()
                            .infoTypes(                            
                                PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationInfoTypeArgs.builder()
                                    .name("PHONE_NUMBER")
                                    .build(),
                                PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationInfoTypeArgs.builder()
                                    .name("AGE")
                                    .build())
                            .primitiveTransformation(PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationArgs.builder()
                                .replaceConfig(PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationReplaceConfigArgs.builder()
                                    .newValue(PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationReplaceConfigNewValueArgs.builder()
                                        .integerValue(9)
                                        .build())
                                    .build())
                                .build())
                            .build(),
                        PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationArgs.builder()
                            .infoTypes(                            
                                PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationInfoTypeArgs.builder()
                                    .name("EMAIL_ADDRESS")
                                    .build(),
                                PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationInfoTypeArgs.builder()
                                    .name("LAST_NAME")
                                    .build())
                            .primitiveTransformation(PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationArgs.builder()
                                .characterMaskConfig(PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationCharacterMaskConfigArgs.builder()
                                    .maskingCharacter("X")
                                    .numberToMask(4)
                                    .reverseOrder(true)
                                    .charactersToIgnores(PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationCharacterMaskConfigCharactersToIgnoreArgs.builder()
                                        .commonCharactersToIgnore("PUNCTUATION")
                                        .build())
                                    .build())
                                .build())
                            .build(),
                        PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationArgs.builder()
                            .infoTypes(PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationInfoTypeArgs.builder()
                                .name("DATE_OF_BIRTH")
                                .build())
                            .primitiveTransformation(PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationArgs.builder()
                                .replaceConfig(PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationReplaceConfigArgs.builder()
                                    .newValue(PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationReplaceConfigNewValueArgs.builder()
                                        .dateValue(PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationReplaceConfigNewValueDateValueArgs.builder()
                                            .year(2020)
                                            .month(1)
                                            .day(1)
                                            .build())
                                        .build())
                                    .build())
                                .build())
                            .build(),
                        PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationArgs.builder()
                            .infoTypes(PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationInfoTypeArgs.builder()
                                .name("CREDIT_CARD_NUMBER")
                                .build())
                            .primitiveTransformation(PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationArgs.builder()
                                .cryptoDeterministicConfig(PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationCryptoDeterministicConfigArgs.builder()
                                    .context(PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationCryptoDeterministicConfigContextArgs.builder()
                                        .name("sometweak")
                                        .build())
                                    .cryptoKey(PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationCryptoDeterministicConfigCryptoKeyArgs.builder()
                                        .transient_(PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationCryptoDeterministicConfigCryptoKeyTransientArgs.builder()
                                            .name("beep")
                                            .build())
                                        .build())
                                    .surrogateInfoType(PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationCryptoDeterministicConfigSurrogateInfoTypeArgs.builder()
                                        .name("abc")
                                        .build())
                                    .build())
                                .build())
                            .build())
                    .build())
                .build())
            .build());

    }
}
```
```yaml
resources:
  basic:
    type: gcp:dataloss:PreventionDeidentifyTemplate
    properties:
      parent: projects/my-project-name
      description: Description
      displayName: Displayname
      deidentifyConfig:
        infoTypeTransformations:
          transformations:
            - infoTypes:
                - name: FIRST_NAME
              primitiveTransformation:
                replaceWithInfoTypeConfig: true
            - infoTypes:
                - name: PHONE_NUMBER
                - name: AGE
              primitiveTransformation:
                replaceConfig:
                  newValue:
                    integerValue: 9
            - infoTypes:
                - name: EMAIL_ADDRESS
                - name: LAST_NAME
              primitiveTransformation:
                characterMaskConfig:
                  maskingCharacter: X
                  numberToMask: 4
                  reverseOrder: true
                  charactersToIgnores:
                    - commonCharactersToIgnore: PUNCTUATION
            - infoTypes:
                - name: DATE_OF_BIRTH
              primitiveTransformation:
                replaceConfig:
                  newValue:
                    dateValue:
                      year: 2020
                      month: 1
                      day: 1
            - infoTypes:
                - name: CREDIT_CARD_NUMBER
              primitiveTransformation:
                cryptoDeterministicConfig:
                  context:
                    name: sometweak
                  cryptoKey:
                    transient:
                      name: beep
                  surrogateInfoType:
                    name: abc
```
<!--End PulumiCodeChooser -->
### Dlp Deidentify Template Image Transformations


<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const basic = new gcp.dataloss.PreventionDeidentifyTemplate("basic", {
    parent: "projects/my-project-name",
    description: "Description",
    displayName: "Displayname",
    deidentifyConfig: {
        imageTransformations: {
            transforms: [
                {
                    redactionColor: {
                        red: 0.5,
                        blue: 1,
                        green: 0.2,
                    },
                    selectedInfoTypes: {
                        infoTypes: [{
                            name: "COLOR_INFO",
                            version: "latest",
                        }],
                    },
                },
                {
                    allInfoTypes: {},
                },
                {
                    allText: {},
                },
            ],
        },
    },
});
```
```python
import pulumi
import pulumi_gcp as gcp

basic = gcp.dataloss.PreventionDeidentifyTemplate("basic",
    parent="projects/my-project-name",
    description="Description",
    display_name="Displayname",
    deidentify_config={
        "image_transformations": {
            "transforms": [
                {
                    "redaction_color": {
                        "red": 0.5,
                        "blue": 1,
                        "green": 0.2,
                    },
                    "selected_info_types": {
                        "info_types": [{
                            "name": "COLOR_INFO",
                            "version": "latest",
                        }],
                    },
                },
                {
                    "all_info_types": {},
                },
                {
                    "all_text": {},
                },
            ],
        },
    })
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var basic = new Gcp.DataLoss.PreventionDeidentifyTemplate("basic", new()
    {
        Parent = "projects/my-project-name",
        Description = "Description",
        DisplayName = "Displayname",
        DeidentifyConfig = new Gcp.DataLoss.Inputs.PreventionDeidentifyTemplateDeidentifyConfigArgs
        {
            ImageTransformations = new Gcp.DataLoss.Inputs.PreventionDeidentifyTemplateDeidentifyConfigImageTransformationsArgs
            {
                Transforms = new[]
                {
                    new Gcp.DataLoss.Inputs.PreventionDeidentifyTemplateDeidentifyConfigImageTransformationsTransformArgs
                    {
                        RedactionColor = new Gcp.DataLoss.Inputs.PreventionDeidentifyTemplateDeidentifyConfigImageTransformationsTransformRedactionColorArgs
                        {
                            Red = 0.5,
                            Blue = 1,
                            Green = 0.2,
                        },
                        SelectedInfoTypes = new Gcp.DataLoss.Inputs.PreventionDeidentifyTemplateDeidentifyConfigImageTransformationsTransformSelectedInfoTypesArgs
                        {
                            InfoTypes = new[]
                            {
                                new Gcp.DataLoss.Inputs.PreventionDeidentifyTemplateDeidentifyConfigImageTransformationsTransformSelectedInfoTypesInfoTypeArgs
                                {
                                    Name = "COLOR_INFO",
                                    Version = "latest",
                                },
                            },
                        },
                    },
                    new Gcp.DataLoss.Inputs.PreventionDeidentifyTemplateDeidentifyConfigImageTransformationsTransformArgs
                    {
                        AllInfoTypes = null,
                    },
                    new Gcp.DataLoss.Inputs.PreventionDeidentifyTemplateDeidentifyConfigImageTransformationsTransformArgs
                    {
                        AllText = null,
                    },
                },
            },
        },
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/dataloss"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		_, err := dataloss.NewPreventionDeidentifyTemplate(ctx, "basic", &dataloss.PreventionDeidentifyTemplateArgs{
			Parent:      pulumi.String("projects/my-project-name"),
			Description: pulumi.String("Description"),
			DisplayName: pulumi.String("Displayname"),
			DeidentifyConfig: &dataloss.PreventionDeidentifyTemplateDeidentifyConfigArgs{
				ImageTransformations: &dataloss.PreventionDeidentifyTemplateDeidentifyConfigImageTransformationsArgs{
					Transforms: dataloss.PreventionDeidentifyTemplateDeidentifyConfigImageTransformationsTransformArray{
						&dataloss.PreventionDeidentifyTemplateDeidentifyConfigImageTransformationsTransformArgs{
							RedactionColor: &dataloss.PreventionDeidentifyTemplateDeidentifyConfigImageTransformationsTransformRedactionColorArgs{
								Red:   pulumi.Float64(0.5),
								Blue:  pulumi.Float64(1),
								Green: pulumi.Float64(0.2),
							},
							SelectedInfoTypes: &dataloss.PreventionDeidentifyTemplateDeidentifyConfigImageTransformationsTransformSelectedInfoTypesArgs{
								InfoTypes: dataloss.PreventionDeidentifyTemplateDeidentifyConfigImageTransformationsTransformSelectedInfoTypesInfoTypeArray{
									&dataloss.PreventionDeidentifyTemplateDeidentifyConfigImageTransformationsTransformSelectedInfoTypesInfoTypeArgs{
										Name:    pulumi.String("COLOR_INFO"),
										Version: pulumi.String("latest"),
									},
								},
							},
						},
						&dataloss.PreventionDeidentifyTemplateDeidentifyConfigImageTransformationsTransformArgs{
							AllInfoTypes: &dataloss.PreventionDeidentifyTemplateDeidentifyConfigImageTransformationsTransformAllInfoTypesArgs{},
						},
						&dataloss.PreventionDeidentifyTemplateDeidentifyConfigImageTransformationsTransformArgs{
							AllText: &dataloss.PreventionDeidentifyTemplateDeidentifyConfigImageTransformationsTransformAllTextArgs{},
						},
					},
				},
			},
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.dataloss.PreventionDeidentifyTemplate;
import com.pulumi.gcp.dataloss.PreventionDeidentifyTemplateArgs;
import com.pulumi.gcp.dataloss.inputs.PreventionDeidentifyTemplateDeidentifyConfigArgs;
import com.pulumi.gcp.dataloss.inputs.PreventionDeidentifyTemplateDeidentifyConfigImageTransformationsArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        var basic = new PreventionDeidentifyTemplate("basic", PreventionDeidentifyTemplateArgs.builder()
            .parent("projects/my-project-name")
            .description("Description")
            .displayName("Displayname")
            .deidentifyConfig(PreventionDeidentifyTemplateDeidentifyConfigArgs.builder()
                .imageTransformations(PreventionDeidentifyTemplateDeidentifyConfigImageTransformationsArgs.builder()
                    .transforms(                    
                        PreventionDeidentifyTemplateDeidentifyConfigImageTransformationsTransformArgs.builder()
                            .redactionColor(PreventionDeidentifyTemplateDeidentifyConfigImageTransformationsTransformRedactionColorArgs.builder()
                                .red(0.5)
                                .blue(1)
                                .green(0.2)
                                .build())
                            .selectedInfoTypes(PreventionDeidentifyTemplateDeidentifyConfigImageTransformationsTransformSelectedInfoTypesArgs.builder()
                                .infoTypes(PreventionDeidentifyTemplateDeidentifyConfigImageTransformationsTransformSelectedInfoTypesInfoTypeArgs.builder()
                                    .name("COLOR_INFO")
                                    .version("latest")
                                    .build())
                                .build())
                            .build(),
                        PreventionDeidentifyTemplateDeidentifyConfigImageTransformationsTransformArgs.builder()
                            .allInfoTypes()
                            .build(),
                        PreventionDeidentifyTemplateDeidentifyConfigImageTransformationsTransformArgs.builder()
                            .allText()
                            .build())
                    .build())
                .build())
            .build());

    }
}
```
```yaml
resources:
  basic:
    type: gcp:dataloss:PreventionDeidentifyTemplate
    properties:
      parent: projects/my-project-name
      description: Description
      displayName: Displayname
      deidentifyConfig:
        imageTransformations:
          transforms:
            - redactionColor:
                red: 0.5
                blue: 1
                green: 0.2
              selectedInfoTypes:
                infoTypes:
                  - name: COLOR_INFO
                    version: latest
            - allInfoTypes: {}
            - allText: {}
```
<!--End PulumiCodeChooser -->

## Import

DeidentifyTemplate can be imported using any of these accepted formats:

* `{{parent}}/deidentifyTemplates/{{name}}`

* `{{parent}}/{{name}}`

When using the `pulumi import` command, DeidentifyTemplate can be imported using one of the formats above. For example:

```sh
$ pulumi import gcp:dataloss/preventionDeidentifyTemplate:PreventionDeidentifyTemplate default {{parent}}/deidentifyTemplates/{{name}}
```

```sh
$ pulumi import gcp:dataloss/preventionDeidentifyTemplate:PreventionDeidentifyTemplate default {{parent}}/{{name}}
```


deidentifyConfig¦:£
 
dataloss,PreventionDeidentifyTemplateDeidentifyConfigfgcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfig:PreventionDeidentifyTemplateDeidentifyConfigHConfiguration of the deidentify template
Structure is documented below.
4
descriptionB" A description of the template.
<
displayNameB" 'User set display name of the template.
÷
parent" èThe parent of the template in any of the following formats:
* `projects/{{project}}`
* `projects/{{project}}/locations/{{location}}`
* `organizations/{{organization_id}}`
* `organizations/{{organization_id}}/locations/{{location}}`
þ

templateIdB" éThe template id can contain uppercase and lowercase letters, numbers, and hyphens; that is, it must match the regular
expression: [a-zA-Z\d-_]+. The maximum length is 100 characters. Can be empty to allow the system to generate one.
"V

createTime" DThe creation timestamp of an deidentifyTemplate. Set by the server.
"
deidentifyConfig¦:£
 
dataloss,PreventionDeidentifyTemplateDeidentifyConfigfgcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfig:PreventionDeidentifyTemplateDeidentifyConfigHConfiguration of the deidentify template
Structure is documented below.
"4
descriptionB" A description of the template.
"<
displayNameB" 'User set display name of the template.
"B
name" 6The resource name of the template. Set by the server.
"÷
parent" èThe parent of the template in any of the following formats:
* `projects/{{project}}`
* `projects/{{project}}/locations/{{location}}`
* `organizations/{{organization_id}}`
* `organizations/{{organization_id}}/locations/{{location}}`
"ü

templateId" éThe template id can contain uppercase and lowercase letters, numbers, and hyphens; that is, it must match the regular
expression: [a-zA-Z\d-_]+. The maximum length is 100 characters. Can be empty to allow the system to generate one.
"Y

updateTime" GThe last update timestamp of an deidentifyTemplate. Set by the server.
*!
g
datalossPreventionDiscoveryConfig@gcp:dataloss/preventionDiscoveryConfig:PreventionDiscoveryConfigÈConfiguration for discovery to scan resources for profile generation. Only one discovery configuration may exist per organization, folder, or project.


To get more information about DiscoveryConfig, see:

* [API documentation](https://cloud.google.com/dlp/docs/reference/rest/v2/projects.locations.discoveryConfigs)
* How-to Guides
    * [Schedule inspection scan](https://cloud.google.com/dlp/docs/schedule-inspection-scan)

## Example Usage

## Import

DiscoveryConfig can be imported using any of these accepted formats:

* `{{parent}}/discoveryConfigs/{{name}}`

* `{{parent}}/{{name}}`

When using the `pulumi import` command, DiscoveryConfig can be imported using one of the formats above. For example:

```sh
$ pulumi import gcp:dataloss/preventionDiscoveryConfig:PreventionDiscoveryConfig default {{parent}}/discoveryConfigs/{{name}}
```

```sh
$ pulumi import gcp:dataloss/preventionDiscoveryConfig:PreventionDiscoveryConfig default {{parent}}/{{name}}
```

ß
actionsB*}:{
y
datalossPreventionDiscoveryConfigActionLgcp:dataloss/PreventionDiscoveryConfigAction:PreventionDiscoveryConfigActionPActions to execute at the completion of scanning
Structure is documented below.
3
displayNameB" Display Name (max 1000 Chars)
C
inspectTemplatesB*" 'Detection logic for profile generation
D
location" 4Location to create the discovery config in.


- - -
Ô
	orgConfigB:

dataloss"PreventionDiscoveryConfigOrgConfigRgcp:dataloss/PreventionDiscoveryConfigOrgConfig:PreventionDiscoveryConfigOrgConfig9A nested object resource.
Structure is documented below.
À
parent" ±The parent of the discovery config in any of the following formats:
* `projects/{{project}}/locations/{{location}}`
* `organizations/{{organization_id}}/locations/{{location}}`
d
statusB" TRequired. A status for this configuration
Possible values are: `RUNNING`, `PAUSED`.
ö
targetsB*}:{
y
datalossPreventionDiscoveryConfigTargetLgcp:dataloss/PreventionDiscoveryConfigTarget:PreventionDiscoveryConfigTargetgTarget to match against for determining what to scan and how frequently
Structure is documented below.
"ß
actionsB*}:{
y
datalossPreventionDiscoveryConfigActionLgcp:dataloss/PreventionDiscoveryConfigAction:PreventionDiscoveryConfigActionPActions to execute at the completion of scanning
Structure is documented below.
"L

createTime" :Output only. The creation timestamp of a DiscoveryConfig.
"3
displayNameB" Display Name (max 1000 Chars)
"§
errors|*z:x
v
datalossPreventionDiscoveryConfigErrorJgcp:dataloss/PreventionDiscoveryConfigError:PreventionDiscoveryConfigErrorOutput only. A stream of errors encountered when the config was activated. Repeated errors may result in the config automatically being paused. Output only field. Will return the last 100 errors. Whenever the config is modified this list will be cleared.
Structure is documented below.
"C
inspectTemplatesB*" 'Detection logic for profile generation
"X
lastRunTime" EOutput only. The timestamp of the last time this config was executed
"D
location" 4Location to create the discovery config in.


- - -
"w
name" kUnique resource name for the DiscoveryConfig, assigned by the service when the DiscoveryConfig is created.
"Ô
	orgConfigB:

dataloss"PreventionDiscoveryConfigOrgConfigRgcp:dataloss/PreventionDiscoveryConfigOrgConfig:PreventionDiscoveryConfigOrgConfig9A nested object resource.
Structure is documented below.
"À
parent" ±The parent of the discovery config in any of the following formats:
* `projects/{{project}}/locations/{{location}}`
* `organizations/{{organization_id}}/locations/{{location}}`
"d
statusB" TRequired. A status for this configuration
Possible values are: `RUNNING`, `PAUSED`.
"ö
targetsB*}:{
y
datalossPreventionDiscoveryConfigTargetLgcp:dataloss/PreventionDiscoveryConfigTarget:PreventionDiscoveryConfigTargetgTarget to match against for determining what to scan and how frequently
Structure is documented below.
"O

updateTime" =Output only. The last update timestamp of a DiscoveryConfig.
*¿º
g
datalossPreventionInspectTemplate@gcp:dataloss/preventionInspectTemplate:PreventionInspectTemplate«An inspect job template.


To get more information about InspectTemplate, see:

* [API documentation](https://cloud.google.com/dlp/docs/reference/rest/v2/projects.inspectTemplates)
* How-to Guides
    * [Official Documentation](https://cloud.google.com/dlp/docs/creating-templates-inspect)

## Example Usage

### Dlp Inspect Template Basic


<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const basic = new gcp.dataloss.PreventionInspectTemplate("basic", {
    parent: "projects/my-project-name",
    description: "My description",
    displayName: "display_name",
    inspectConfig: {
        infoTypes: [
            {
                name: "EMAIL_ADDRESS",
            },
            {
                name: "PERSON_NAME",
            },
            {
                name: "LAST_NAME",
            },
            {
                name: "DOMAIN_NAME",
            },
            {
                name: "PHONE_NUMBER",
            },
            {
                name: "FIRST_NAME",
            },
        ],
        minLikelihood: "UNLIKELY",
        ruleSets: [
            {
                infoTypes: [{
                    name: "EMAIL_ADDRESS",
                }],
                rules: [{
                    exclusionRule: {
                        regex: {
                            pattern: ".+@example.com",
                        },
                        matchingType: "MATCHING_TYPE_FULL_MATCH",
                    },
                }],
            },
            {
                infoTypes: [
                    {
                        name: "EMAIL_ADDRESS",
                    },
                    {
                        name: "DOMAIN_NAME",
                    },
                    {
                        name: "PHONE_NUMBER",
                    },
                    {
                        name: "PERSON_NAME",
                    },
                    {
                        name: "FIRST_NAME",
                    },
                ],
                rules: [{
                    exclusionRule: {
                        dictionary: {
                            wordList: {
                                words: ["TEST"],
                            },
                        },
                        matchingType: "MATCHING_TYPE_PARTIAL_MATCH",
                    },
                }],
            },
            {
                infoTypes: [{
                    name: "PERSON_NAME",
                }],
                rules: [{
                    hotwordRule: {
                        hotwordRegex: {
                            pattern: "patient",
                        },
                        proximity: {
                            windowBefore: 50,
                        },
                        likelihoodAdjustment: {
                            fixedLikelihood: "VERY_LIKELY",
                        },
                    },
                }],
            },
        ],
        limits: {
            maxFindingsPerItem: 10,
            maxFindingsPerRequest: 50,
            maxFindingsPerInfoTypes: [
                {
                    maxFindings: 75,
                    infoType: {
                        name: "PERSON_NAME",
                    },
                },
                {
                    maxFindings: 80,
                    infoType: {
                        name: "LAST_NAME",
                    },
                },
            ],
        },
    },
});
```
```python
import pulumi
import pulumi_gcp as gcp

basic = gcp.dataloss.PreventionInspectTemplate("basic",
    parent="projects/my-project-name",
    description="My description",
    display_name="display_name",
    inspect_config={
        "info_types": [
            {
                "name": "EMAIL_ADDRESS",
            },
            {
                "name": "PERSON_NAME",
            },
            {
                "name": "LAST_NAME",
            },
            {
                "name": "DOMAIN_NAME",
            },
            {
                "name": "PHONE_NUMBER",
            },
            {
                "name": "FIRST_NAME",
            },
        ],
        "min_likelihood": "UNLIKELY",
        "rule_sets": [
            {
                "info_types": [{
                    "name": "EMAIL_ADDRESS",
                }],
                "rules": [{
                    "exclusion_rule": {
                        "regex": {
                            "pattern": ".+@example.com",
                        },
                        "matching_type": "MATCHING_TYPE_FULL_MATCH",
                    },
                }],
            },
            {
                "info_types": [
                    {
                        "name": "EMAIL_ADDRESS",
                    },
                    {
                        "name": "DOMAIN_NAME",
                    },
                    {
                        "name": "PHONE_NUMBER",
                    },
                    {
                        "name": "PERSON_NAME",
                    },
                    {
                        "name": "FIRST_NAME",
                    },
                ],
                "rules": [{
                    "exclusion_rule": {
                        "dictionary": {
                            "word_list": {
                                "words": ["TEST"],
                            },
                        },
                        "matching_type": "MATCHING_TYPE_PARTIAL_MATCH",
                    },
                }],
            },
            {
                "info_types": [{
                    "name": "PERSON_NAME",
                }],
                "rules": [{
                    "hotword_rule": {
                        "hotword_regex": {
                            "pattern": "patient",
                        },
                        "proximity": {
                            "window_before": 50,
                        },
                        "likelihood_adjustment": {
                            "fixed_likelihood": "VERY_LIKELY",
                        },
                    },
                }],
            },
        ],
        "limits": {
            "max_findings_per_item": 10,
            "max_findings_per_request": 50,
            "max_findings_per_info_types": [
                {
                    "max_findings": 75,
                    "info_type": {
                        "name": "PERSON_NAME",
                    },
                },
                {
                    "max_findings": 80,
                    "info_type": {
                        "name": "LAST_NAME",
                    },
                },
            ],
        },
    })
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var basic = new Gcp.DataLoss.PreventionInspectTemplate("basic", new()
    {
        Parent = "projects/my-project-name",
        Description = "My description",
        DisplayName = "display_name",
        InspectConfig = new Gcp.DataLoss.Inputs.PreventionInspectTemplateInspectConfigArgs
        {
            InfoTypes = new[]
            {
                new Gcp.DataLoss.Inputs.PreventionInspectTemplateInspectConfigInfoTypeArgs
                {
                    Name = "EMAIL_ADDRESS",
                },
                new Gcp.DataLoss.Inputs.PreventionInspectTemplateInspectConfigInfoTypeArgs
                {
                    Name = "PERSON_NAME",
                },
                new Gcp.DataLoss.Inputs.PreventionInspectTemplateInspectConfigInfoTypeArgs
                {
                    Name = "LAST_NAME",
                },
                new Gcp.DataLoss.Inputs.PreventionInspectTemplateInspectConfigInfoTypeArgs
                {
                    Name = "DOMAIN_NAME",
                },
                new Gcp.DataLoss.Inputs.PreventionInspectTemplateInspectConfigInfoTypeArgs
                {
                    Name = "PHONE_NUMBER",
                },
                new Gcp.DataLoss.Inputs.PreventionInspectTemplateInspectConfigInfoTypeArgs
                {
                    Name = "FIRST_NAME",
                },
            },
            MinLikelihood = "UNLIKELY",
            RuleSets = new[]
            {
                new Gcp.DataLoss.Inputs.PreventionInspectTemplateInspectConfigRuleSetArgs
                {
                    InfoTypes = new[]
                    {
                        new Gcp.DataLoss.Inputs.PreventionInspectTemplateInspectConfigRuleSetInfoTypeArgs
                        {
                            Name = "EMAIL_ADDRESS",
                        },
                    },
                    Rules = new[]
                    {
                        new Gcp.DataLoss.Inputs.PreventionInspectTemplateInspectConfigRuleSetRuleArgs
                        {
                            ExclusionRule = new Gcp.DataLoss.Inputs.PreventionInspectTemplateInspectConfigRuleSetRuleExclusionRuleArgs
                            {
                                Regex = new Gcp.DataLoss.Inputs.PreventionInspectTemplateInspectConfigRuleSetRuleExclusionRuleRegexArgs
                                {
                                    Pattern = ".+@example.com",
                                },
                                MatchingType = "MATCHING_TYPE_FULL_MATCH",
                            },
                        },
                    },
                },
                new Gcp.DataLoss.Inputs.PreventionInspectTemplateInspectConfigRuleSetArgs
                {
                    InfoTypes = new[]
                    {
                        new Gcp.DataLoss.Inputs.PreventionInspectTemplateInspectConfigRuleSetInfoTypeArgs
                        {
                            Name = "EMAIL_ADDRESS",
                        },
                        new Gcp.DataLoss.Inputs.PreventionInspectTemplateInspectConfigRuleSetInfoTypeArgs
                        {
                            Name = "DOMAIN_NAME",
                        },
                        new Gcp.DataLoss.Inputs.PreventionInspectTemplateInspectConfigRuleSetInfoTypeArgs
                        {
                            Name = "PHONE_NUMBER",
                        },
                        new Gcp.DataLoss.Inputs.PreventionInspectTemplateInspectConfigRuleSetInfoTypeArgs
                        {
                            Name = "PERSON_NAME",
                        },
                        new Gcp.DataLoss.Inputs.PreventionInspectTemplateInspectConfigRuleSetInfoTypeArgs
                        {
                            Name = "FIRST_NAME",
                        },
                    },
                    Rules = new[]
                    {
                        new Gcp.DataLoss.Inputs.PreventionInspectTemplateInspectConfigRuleSetRuleArgs
                        {
                            ExclusionRule = new Gcp.DataLoss.Inputs.PreventionInspectTemplateInspectConfigRuleSetRuleExclusionRuleArgs
                            {
                                Dictionary = new Gcp.DataLoss.Inputs.PreventionInspectTemplateInspectConfigRuleSetRuleExclusionRuleDictionaryArgs
                                {
                                    WordList = new Gcp.DataLoss.Inputs.PreventionInspectTemplateInspectConfigRuleSetRuleExclusionRuleDictionaryWordListArgs
                                    {
                                        Words = new[]
                                        {
                                            "TEST",
                                        },
                                    },
                                },
                                MatchingType = "MATCHING_TYPE_PARTIAL_MATCH",
                            },
                        },
                    },
                },
                new Gcp.DataLoss.Inputs.PreventionInspectTemplateInspectConfigRuleSetArgs
                {
                    InfoTypes = new[]
                    {
                        new Gcp.DataLoss.Inputs.PreventionInspectTemplateInspectConfigRuleSetInfoTypeArgs
                        {
                            Name = "PERSON_NAME",
                        },
                    },
                    Rules = new[]
                    {
                        new Gcp.DataLoss.Inputs.PreventionInspectTemplateInspectConfigRuleSetRuleArgs
                        {
                            HotwordRule = new Gcp.DataLoss.Inputs.PreventionInspectTemplateInspectConfigRuleSetRuleHotwordRuleArgs
                            {
                                HotwordRegex = new Gcp.DataLoss.Inputs.PreventionInspectTemplateInspectConfigRuleSetRuleHotwordRuleHotwordRegexArgs
                                {
                                    Pattern = "patient",
                                },
                                Proximity = new Gcp.DataLoss.Inputs.PreventionInspectTemplateInspectConfigRuleSetRuleHotwordRuleProximityArgs
                                {
                                    WindowBefore = 50,
                                },
                                LikelihoodAdjustment = new Gcp.DataLoss.Inputs.PreventionInspectTemplateInspectConfigRuleSetRuleHotwordRuleLikelihoodAdjustmentArgs
                                {
                                    FixedLikelihood = "VERY_LIKELY",
                                },
                            },
                        },
                    },
                },
            },
            Limits = new Gcp.DataLoss.Inputs.PreventionInspectTemplateInspectConfigLimitsArgs
            {
                MaxFindingsPerItem = 10,
                MaxFindingsPerRequest = 50,
                MaxFindingsPerInfoTypes = new[]
                {
                    new Gcp.DataLoss.Inputs.PreventionInspectTemplateInspectConfigLimitsMaxFindingsPerInfoTypeArgs
                    {
                        MaxFindings = 75,
                        InfoType = new Gcp.DataLoss.Inputs.PreventionInspectTemplateInspectConfigLimitsMaxFindingsPerInfoTypeInfoTypeArgs
                        {
                            Name = "PERSON_NAME",
                        },
                    },
                    new Gcp.DataLoss.Inputs.PreventionInspectTemplateInspectConfigLimitsMaxFindingsPerInfoTypeArgs
                    {
                        MaxFindings = 80,
                        InfoType = new Gcp.DataLoss.Inputs.PreventionInspectTemplateInspectConfigLimitsMaxFindingsPerInfoTypeInfoTypeArgs
                        {
                            Name = "LAST_NAME",
                        },
                    },
                },
            },
        },
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/dataloss"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		_, err := dataloss.NewPreventionInspectTemplate(ctx, "basic", &dataloss.PreventionInspectTemplateArgs{
			Parent:      pulumi.String("projects/my-project-name"),
			Description: pulumi.String("My description"),
			DisplayName: pulumi.String("display_name"),
			InspectConfig: &dataloss.PreventionInspectTemplateInspectConfigArgs{
				InfoTypes: dataloss.PreventionInspectTemplateInspectConfigInfoTypeArray{
					&dataloss.PreventionInspectTemplateInspectConfigInfoTypeArgs{
						Name: pulumi.String("EMAIL_ADDRESS"),
					},
					&dataloss.PreventionInspectTemplateInspectConfigInfoTypeArgs{
						Name: pulumi.String("PERSON_NAME"),
					},
					&dataloss.PreventionInspectTemplateInspectConfigInfoTypeArgs{
						Name: pulumi.String("LAST_NAME"),
					},
					&dataloss.PreventionInspectTemplateInspectConfigInfoTypeArgs{
						Name: pulumi.String("DOMAIN_NAME"),
					},
					&dataloss.PreventionInspectTemplateInspectConfigInfoTypeArgs{
						Name: pulumi.String("PHONE_NUMBER"),
					},
					&dataloss.PreventionInspectTemplateInspectConfigInfoTypeArgs{
						Name: pulumi.String("FIRST_NAME"),
					},
				},
				MinLikelihood: pulumi.String("UNLIKELY"),
				RuleSets: dataloss.PreventionInspectTemplateInspectConfigRuleSetArray{
					&dataloss.PreventionInspectTemplateInspectConfigRuleSetArgs{
						InfoTypes: dataloss.PreventionInspectTemplateInspectConfigRuleSetInfoTypeArray{
							&dataloss.PreventionInspectTemplateInspectConfigRuleSetInfoTypeArgs{
								Name: pulumi.String("EMAIL_ADDRESS"),
							},
						},
						Rules: dataloss.PreventionInspectTemplateInspectConfigRuleSetRuleArray{
							&dataloss.PreventionInspectTemplateInspectConfigRuleSetRuleArgs{
								ExclusionRule: &dataloss.PreventionInspectTemplateInspectConfigRuleSetRuleExclusionRuleArgs{
									Regex: &dataloss.PreventionInspectTemplateInspectConfigRuleSetRuleExclusionRuleRegexArgs{
										Pattern: pulumi.String(".+@example.com"),
									},
									MatchingType: pulumi.String("MATCHING_TYPE_FULL_MATCH"),
								},
							},
						},
					},
					&dataloss.PreventionInspectTemplateInspectConfigRuleSetArgs{
						InfoTypes: dataloss.PreventionInspectTemplateInspectConfigRuleSetInfoTypeArray{
							&dataloss.PreventionInspectTemplateInspectConfigRuleSetInfoTypeArgs{
								Name: pulumi.String("EMAIL_ADDRESS"),
							},
							&dataloss.PreventionInspectTemplateInspectConfigRuleSetInfoTypeArgs{
								Name: pulumi.String("DOMAIN_NAME"),
							},
							&dataloss.PreventionInspectTemplateInspectConfigRuleSetInfoTypeArgs{
								Name: pulumi.String("PHONE_NUMBER"),
							},
							&dataloss.PreventionInspectTemplateInspectConfigRuleSetInfoTypeArgs{
								Name: pulumi.String("PERSON_NAME"),
							},
							&dataloss.PreventionInspectTemplateInspectConfigRuleSetInfoTypeArgs{
								Name: pulumi.String("FIRST_NAME"),
							},
						},
						Rules: dataloss.PreventionInspectTemplateInspectConfigRuleSetRuleArray{
							&dataloss.PreventionInspectTemplateInspectConfigRuleSetRuleArgs{
								ExclusionRule: &dataloss.PreventionInspectTemplateInspectConfigRuleSetRuleExclusionRuleArgs{
									Dictionary: &dataloss.PreventionInspectTemplateInspectConfigRuleSetRuleExclusionRuleDictionaryArgs{
										WordList: &dataloss.PreventionInspectTemplateInspectConfigRuleSetRuleExclusionRuleDictionaryWordListArgs{
											Words: pulumi.StringArray{
												pulumi.String("TEST"),
											},
										},
									},
									MatchingType: pulumi.String("MATCHING_TYPE_PARTIAL_MATCH"),
								},
							},
						},
					},
					&dataloss.PreventionInspectTemplateInspectConfigRuleSetArgs{
						InfoTypes: dataloss.PreventionInspectTemplateInspectConfigRuleSetInfoTypeArray{
							&dataloss.PreventionInspectTemplateInspectConfigRuleSetInfoTypeArgs{
								Name: pulumi.String("PERSON_NAME"),
							},
						},
						Rules: dataloss.PreventionInspectTemplateInspectConfigRuleSetRuleArray{
							&dataloss.PreventionInspectTemplateInspectConfigRuleSetRuleArgs{
								HotwordRule: &dataloss.PreventionInspectTemplateInspectConfigRuleSetRuleHotwordRuleArgs{
									HotwordRegex: &dataloss.PreventionInspectTemplateInspectConfigRuleSetRuleHotwordRuleHotwordRegexArgs{
										Pattern: pulumi.String("patient"),
									},
									Proximity: &dataloss.PreventionInspectTemplateInspectConfigRuleSetRuleHotwordRuleProximityArgs{
										WindowBefore: pulumi.Int(50),
									},
									LikelihoodAdjustment: &dataloss.PreventionInspectTemplateInspectConfigRuleSetRuleHotwordRuleLikelihoodAdjustmentArgs{
										FixedLikelihood: pulumi.String("VERY_LIKELY"),
									},
								},
							},
						},
					},
				},
				Limits: &dataloss.PreventionInspectTemplateInspectConfigLimitsArgs{
					MaxFindingsPerItem:    pulumi.Int(10),
					MaxFindingsPerRequest: pulumi.Int(50),
					MaxFindingsPerInfoTypes: dataloss.PreventionInspectTemplateInspectConfigLimitsMaxFindingsPerInfoTypeArray{
						&dataloss.PreventionInspectTemplateInspectConfigLimitsMaxFindingsPerInfoTypeArgs{
							MaxFindings: pulumi.Int(75),
							InfoType: &dataloss.PreventionInspectTemplateInspectConfigLimitsMaxFindingsPerInfoTypeInfoTypeArgs{
								Name: pulumi.String("PERSON_NAME"),
							},
						},
						&dataloss.PreventionInspectTemplateInspectConfigLimitsMaxFindingsPerInfoTypeArgs{
							MaxFindings: pulumi.Int(80),
							InfoType: &dataloss.PreventionInspectTemplateInspectConfigLimitsMaxFindingsPerInfoTypeInfoTypeArgs{
								Name: pulumi.String("LAST_NAME"),
							},
						},
					},
				},
			},
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.dataloss.PreventionInspectTemplate;
import com.pulumi.gcp.dataloss.PreventionInspectTemplateArgs;
import com.pulumi.gcp.dataloss.inputs.PreventionInspectTemplateInspectConfigArgs;
import com.pulumi.gcp.dataloss.inputs.PreventionInspectTemplateInspectConfigLimitsArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        var basic = new PreventionInspectTemplate("basic", PreventionInspectTemplateArgs.builder()
            .parent("projects/my-project-name")
            .description("My description")
            .displayName("display_name")
            .inspectConfig(PreventionInspectTemplateInspectConfigArgs.builder()
                .infoTypes(                
                    PreventionInspectTemplateInspectConfigInfoTypeArgs.builder()
                        .name("EMAIL_ADDRESS")
                        .build(),
                    PreventionInspectTemplateInspectConfigInfoTypeArgs.builder()
                        .name("PERSON_NAME")
                        .build(),
                    PreventionInspectTemplateInspectConfigInfoTypeArgs.builder()
                        .name("LAST_NAME")
                        .build(),
                    PreventionInspectTemplateInspectConfigInfoTypeArgs.builder()
                        .name("DOMAIN_NAME")
                        .build(),
                    PreventionInspectTemplateInspectConfigInfoTypeArgs.builder()
                        .name("PHONE_NUMBER")
                        .build(),
                    PreventionInspectTemplateInspectConfigInfoTypeArgs.builder()
                        .name("FIRST_NAME")
                        .build())
                .minLikelihood("UNLIKELY")
                .ruleSets(                
                    PreventionInspectTemplateInspectConfigRuleSetArgs.builder()
                        .infoTypes(PreventionInspectTemplateInspectConfigRuleSetInfoTypeArgs.builder()
                            .name("EMAIL_ADDRESS")
                            .build())
                        .rules(PreventionInspectTemplateInspectConfigRuleSetRuleArgs.builder()
                            .exclusionRule(PreventionInspectTemplateInspectConfigRuleSetRuleExclusionRuleArgs.builder()
                                .regex(PreventionInspectTemplateInspectConfigRuleSetRuleExclusionRuleRegexArgs.builder()
                                    .pattern(".+@example.com")
                                    .build())
                                .matchingType("MATCHING_TYPE_FULL_MATCH")
                                .build())
                            .build())
                        .build(),
                    PreventionInspectTemplateInspectConfigRuleSetArgs.builder()
                        .infoTypes(                        
                            PreventionInspectTemplateInspectConfigRuleSetInfoTypeArgs.builder()
                                .name("EMAIL_ADDRESS")
                                .build(),
                            PreventionInspectTemplateInspectConfigRuleSetInfoTypeArgs.builder()
                                .name("DOMAIN_NAME")
                                .build(),
                            PreventionInspectTemplateInspectConfigRuleSetInfoTypeArgs.builder()
                                .name("PHONE_NUMBER")
                                .build(),
                            PreventionInspectTemplateInspectConfigRuleSetInfoTypeArgs.builder()
                                .name("PERSON_NAME")
                                .build(),
                            PreventionInspectTemplateInspectConfigRuleSetInfoTypeArgs.builder()
                                .name("FIRST_NAME")
                                .build())
                        .rules(PreventionInspectTemplateInspectConfigRuleSetRuleArgs.builder()
                            .exclusionRule(PreventionInspectTemplateInspectConfigRuleSetRuleExclusionRuleArgs.builder()
                                .dictionary(PreventionInspectTemplateInspectConfigRuleSetRuleExclusionRuleDictionaryArgs.builder()
                                    .wordList(PreventionInspectTemplateInspectConfigRuleSetRuleExclusionRuleDictionaryWordListArgs.builder()
                                        .words("TEST")
                                        .build())
                                    .build())
                                .matchingType("MATCHING_TYPE_PARTIAL_MATCH")
                                .build())
                            .build())
                        .build(),
                    PreventionInspectTemplateInspectConfigRuleSetArgs.builder()
                        .infoTypes(PreventionInspectTemplateInspectConfigRuleSetInfoTypeArgs.builder()
                            .name("PERSON_NAME")
                            .build())
                        .rules(PreventionInspectTemplateInspectConfigRuleSetRuleArgs.builder()
                            .hotwordRule(PreventionInspectTemplateInspectConfigRuleSetRuleHotwordRuleArgs.builder()
                                .hotwordRegex(PreventionInspectTemplateInspectConfigRuleSetRuleHotwordRuleHotwordRegexArgs.builder()
                                    .pattern("patient")
                                    .build())
                                .proximity(PreventionInspectTemplateInspectConfigRuleSetRuleHotwordRuleProximityArgs.builder()
                                    .windowBefore(50)
                                    .build())
                                .likelihoodAdjustment(PreventionInspectTemplateInspectConfigRuleSetRuleHotwordRuleLikelihoodAdjustmentArgs.builder()
                                    .fixedLikelihood("VERY_LIKELY")
                                    .build())
                                .build())
                            .build())
                        .build())
                .limits(PreventionInspectTemplateInspectConfigLimitsArgs.builder()
                    .maxFindingsPerItem(10)
                    .maxFindingsPerRequest(50)
                    .maxFindingsPerInfoTypes(                    
                        PreventionInspectTemplateInspectConfigLimitsMaxFindingsPerInfoTypeArgs.builder()
                            .maxFindings("75")
                            .infoType(PreventionInspectTemplateInspectConfigLimitsMaxFindingsPerInfoTypeInfoTypeArgs.builder()
                                .name("PERSON_NAME")
                                .build())
                            .build(),
                        PreventionInspectTemplateInspectConfigLimitsMaxFindingsPerInfoTypeArgs.builder()
                            .maxFindings("80")
                            .infoType(PreventionInspectTemplateInspectConfigLimitsMaxFindingsPerInfoTypeInfoTypeArgs.builder()
                                .name("LAST_NAME")
                                .build())
                            .build())
                    .build())
                .build())
            .build());

    }
}
```
```yaml
resources:
  basic:
    type: gcp:dataloss:PreventionInspectTemplate
    properties:
      parent: projects/my-project-name
      description: My description
      displayName: display_name
      inspectConfig:
        infoTypes:
          - name: EMAIL_ADDRESS
          - name: PERSON_NAME
          - name: LAST_NAME
          - name: DOMAIN_NAME
          - name: PHONE_NUMBER
          - name: FIRST_NAME
        minLikelihood: UNLIKELY
        ruleSets:
          - infoTypes:
              - name: EMAIL_ADDRESS
            rules:
              - exclusionRule:
                  regex:
                    pattern: .+@example.com
                  matchingType: MATCHING_TYPE_FULL_MATCH
          - infoTypes:
              - name: EMAIL_ADDRESS
              - name: DOMAIN_NAME
              - name: PHONE_NUMBER
              - name: PERSON_NAME
              - name: FIRST_NAME
            rules:
              - exclusionRule:
                  dictionary:
                    wordList:
                      words:
                        - TEST
                  matchingType: MATCHING_TYPE_PARTIAL_MATCH
          - infoTypes:
              - name: PERSON_NAME
            rules:
              - hotwordRule:
                  hotwordRegex:
                    pattern: patient
                  proximity:
                    windowBefore: 50
                  likelihoodAdjustment:
                    fixedLikelihood: VERY_LIKELY
        limits:
          maxFindingsPerItem: 10
          maxFindingsPerRequest: 50
          maxFindingsPerInfoTypes:
            - maxFindings: '75'
              infoType:
                name: PERSON_NAME
            - maxFindings: '80'
              infoType:
                name: LAST_NAME
```
<!--End PulumiCodeChooser -->
### Dlp Inspect Template Custom Type


<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const custom = new gcp.dataloss.PreventionInspectTemplate("custom", {
    parent: "projects/my-project-name",
    description: "My description",
    displayName: "display_name",
    inspectConfig: {
        customInfoTypes: [{
            infoType: {
                name: "MY_CUSTOM_TYPE",
            },
            likelihood: "UNLIKELY",
            regex: {
                pattern: "test*",
            },
        }],
        infoTypes: [{
            name: "EMAIL_ADDRESS",
        }],
        minLikelihood: "UNLIKELY",
        ruleSets: [
            {
                infoTypes: [{
                    name: "EMAIL_ADDRESS",
                }],
                rules: [{
                    exclusionRule: {
                        regex: {
                            pattern: ".+@example.com",
                        },
                        matchingType: "MATCHING_TYPE_FULL_MATCH",
                    },
                }],
            },
            {
                infoTypes: [{
                    name: "MY_CUSTOM_TYPE",
                }],
                rules: [{
                    hotwordRule: {
                        hotwordRegex: {
                            pattern: "example*",
                        },
                        proximity: {
                            windowBefore: 50,
                        },
                        likelihoodAdjustment: {
                            fixedLikelihood: "VERY_LIKELY",
                        },
                    },
                }],
            },
        ],
        limits: {
            maxFindingsPerItem: 10,
            maxFindingsPerRequest: 50,
        },
    },
});
```
```python
import pulumi
import pulumi_gcp as gcp

custom = gcp.dataloss.PreventionInspectTemplate("custom",
    parent="projects/my-project-name",
    description="My description",
    display_name="display_name",
    inspect_config={
        "custom_info_types": [{
            "info_type": {
                "name": "MY_CUSTOM_TYPE",
            },
            "likelihood": "UNLIKELY",
            "regex": {
                "pattern": "test*",
            },
        }],
        "info_types": [{
            "name": "EMAIL_ADDRESS",
        }],
        "min_likelihood": "UNLIKELY",
        "rule_sets": [
            {
                "info_types": [{
                    "name": "EMAIL_ADDRESS",
                }],
                "rules": [{
                    "exclusion_rule": {
                        "regex": {
                            "pattern": ".+@example.com",
                        },
                        "matching_type": "MATCHING_TYPE_FULL_MATCH",
                    },
                }],
            },
            {
                "info_types": [{
                    "name": "MY_CUSTOM_TYPE",
                }],
                "rules": [{
                    "hotword_rule": {
                        "hotword_regex": {
                            "pattern": "example*",
                        },
                        "proximity": {
                            "window_before": 50,
                        },
                        "likelihood_adjustment": {
                            "fixed_likelihood": "VERY_LIKELY",
                        },
                    },
                }],
            },
        ],
        "limits": {
            "max_findings_per_item": 10,
            "max_findings_per_request": 50,
        },
    })
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var custom = new Gcp.DataLoss.PreventionInspectTemplate("custom", new()
    {
        Parent = "projects/my-project-name",
        Description = "My description",
        DisplayName = "display_name",
        InspectConfig = new Gcp.DataLoss.Inputs.PreventionInspectTemplateInspectConfigArgs
        {
            CustomInfoTypes = new[]
            {
                new Gcp.DataLoss.Inputs.PreventionInspectTemplateInspectConfigCustomInfoTypeArgs
                {
                    InfoType = new Gcp.DataLoss.Inputs.PreventionInspectTemplateInspectConfigCustomInfoTypeInfoTypeArgs
                    {
                        Name = "MY_CUSTOM_TYPE",
                    },
                    Likelihood = "UNLIKELY",
                    Regex = new Gcp.DataLoss.Inputs.PreventionInspectTemplateInspectConfigCustomInfoTypeRegexArgs
                    {
                        Pattern = "test*",
                    },
                },
            },
            InfoTypes = new[]
            {
                new Gcp.DataLoss.Inputs.PreventionInspectTemplateInspectConfigInfoTypeArgs
                {
                    Name = "EMAIL_ADDRESS",
                },
            },
            MinLikelihood = "UNLIKELY",
            RuleSets = new[]
            {
                new Gcp.DataLoss.Inputs.PreventionInspectTemplateInspectConfigRuleSetArgs
                {
                    InfoTypes = new[]
                    {
                        new Gcp.DataLoss.Inputs.PreventionInspectTemplateInspectConfigRuleSetInfoTypeArgs
                        {
                            Name = "EMAIL_ADDRESS",
                        },
                    },
                    Rules = new[]
                    {
                        new Gcp.DataLoss.Inputs.PreventionInspectTemplateInspectConfigRuleSetRuleArgs
                        {
                            ExclusionRule = new Gcp.DataLoss.Inputs.PreventionInspectTemplateInspectConfigRuleSetRuleExclusionRuleArgs
                            {
                                Regex = new Gcp.DataLoss.Inputs.PreventionInspectTemplateInspectConfigRuleSetRuleExclusionRuleRegexArgs
                                {
                                    Pattern = ".+@example.com",
                                },
                                MatchingType = "MATCHING_TYPE_FULL_MATCH",
                            },
                        },
                    },
                },
                new Gcp.DataLoss.Inputs.PreventionInspectTemplateInspectConfigRuleSetArgs
                {
                    InfoTypes = new[]
                    {
                        new Gcp.DataLoss.Inputs.PreventionInspectTemplateInspectConfigRuleSetInfoTypeArgs
                        {
                            Name = "MY_CUSTOM_TYPE",
                        },
                    },
                    Rules = new[]
                    {
                        new Gcp.DataLoss.Inputs.PreventionInspectTemplateInspectConfigRuleSetRuleArgs
                        {
                            HotwordRule = new Gcp.DataLoss.Inputs.PreventionInspectTemplateInspectConfigRuleSetRuleHotwordRuleArgs
                            {
                                HotwordRegex = new Gcp.DataLoss.Inputs.PreventionInspectTemplateInspectConfigRuleSetRuleHotwordRuleHotwordRegexArgs
                                {
                                    Pattern = "example*",
                                },
                                Proximity = new Gcp.DataLoss.Inputs.PreventionInspectTemplateInspectConfigRuleSetRuleHotwordRuleProximityArgs
                                {
                                    WindowBefore = 50,
                                },
                                LikelihoodAdjustment = new Gcp.DataLoss.Inputs.PreventionInspectTemplateInspectConfigRuleSetRuleHotwordRuleLikelihoodAdjustmentArgs
                                {
                                    FixedLikelihood = "VERY_LIKELY",
                                },
                            },
                        },
                    },
                },
            },
            Limits = new Gcp.DataLoss.Inputs.PreventionInspectTemplateInspectConfigLimitsArgs
            {
                MaxFindingsPerItem = 10,
                MaxFindingsPerRequest = 50,
            },
        },
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/dataloss"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		_, err := dataloss.NewPreventionInspectTemplate(ctx, "custom", &dataloss.PreventionInspectTemplateArgs{
			Parent:      pulumi.String("projects/my-project-name"),
			Description: pulumi.String("My description"),
			DisplayName: pulumi.String("display_name"),
			InspectConfig: &dataloss.PreventionInspectTemplateInspectConfigArgs{
				CustomInfoTypes: dataloss.PreventionInspectTemplateInspectConfigCustomInfoTypeArray{
					&dataloss.PreventionInspectTemplateInspectConfigCustomInfoTypeArgs{
						InfoType: &dataloss.PreventionInspectTemplateInspectConfigCustomInfoTypeInfoTypeArgs{
							Name: pulumi.String("MY_CUSTOM_TYPE"),
						},
						Likelihood: pulumi.String("UNLIKELY"),
						Regex: &dataloss.PreventionInspectTemplateInspectConfigCustomInfoTypeRegexArgs{
							Pattern: pulumi.String("test*"),
						},
					},
				},
				InfoTypes: dataloss.PreventionInspectTemplateInspectConfigInfoTypeArray{
					&dataloss.PreventionInspectTemplateInspectConfigInfoTypeArgs{
						Name: pulumi.String("EMAIL_ADDRESS"),
					},
				},
				MinLikelihood: pulumi.String("UNLIKELY"),
				RuleSets: dataloss.PreventionInspectTemplateInspectConfigRuleSetArray{
					&dataloss.PreventionInspectTemplateInspectConfigRuleSetArgs{
						InfoTypes: dataloss.PreventionInspectTemplateInspectConfigRuleSetInfoTypeArray{
							&dataloss.PreventionInspectTemplateInspectConfigRuleSetInfoTypeArgs{
								Name: pulumi.String("EMAIL_ADDRESS"),
							},
						},
						Rules: dataloss.PreventionInspectTemplateInspectConfigRuleSetRuleArray{
							&dataloss.PreventionInspectTemplateInspectConfigRuleSetRuleArgs{
								ExclusionRule: &dataloss.PreventionInspectTemplateInspectConfigRuleSetRuleExclusionRuleArgs{
									Regex: &dataloss.PreventionInspectTemplateInspectConfigRuleSetRuleExclusionRuleRegexArgs{
										Pattern: pulumi.String(".+@example.com"),
									},
									MatchingType: pulumi.String("MATCHING_TYPE_FULL_MATCH"),
								},
							},
						},
					},
					&dataloss.PreventionInspectTemplateInspectConfigRuleSetArgs{
						InfoTypes: dataloss.PreventionInspectTemplateInspectConfigRuleSetInfoTypeArray{
							&dataloss.PreventionInspectTemplateInspectConfigRuleSetInfoTypeArgs{
								Name: pulumi.String("MY_CUSTOM_TYPE"),
							},
						},
						Rules: dataloss.PreventionInspectTemplateInspectConfigRuleSetRuleArray{
							&dataloss.PreventionInspectTemplateInspectConfigRuleSetRuleArgs{
								HotwordRule: &dataloss.PreventionInspectTemplateInspectConfigRuleSetRuleHotwordRuleArgs{
									HotwordRegex: &dataloss.PreventionInspectTemplateInspectConfigRuleSetRuleHotwordRuleHotwordRegexArgs{
										Pattern: pulumi.String("example*"),
									},
									Proximity: &dataloss.PreventionInspectTemplateInspectConfigRuleSetRuleHotwordRuleProximityArgs{
										WindowBefore: pulumi.Int(50),
									},
									LikelihoodAdjustment: &dataloss.PreventionInspectTemplateInspectConfigRuleSetRuleHotwordRuleLikelihoodAdjustmentArgs{
										FixedLikelihood: pulumi.String("VERY_LIKELY"),
									},
								},
							},
						},
					},
				},
				Limits: &dataloss.PreventionInspectTemplateInspectConfigLimitsArgs{
					MaxFindingsPerItem:    pulumi.Int(10),
					MaxFindingsPerRequest: pulumi.Int(50),
				},
			},
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.dataloss.PreventionInspectTemplate;
import com.pulumi.gcp.dataloss.PreventionInspectTemplateArgs;
import com.pulumi.gcp.dataloss.inputs.PreventionInspectTemplateInspectConfigArgs;
import com.pulumi.gcp.dataloss.inputs.PreventionInspectTemplateInspectConfigLimitsArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        var custom = new PreventionInspectTemplate("custom", PreventionInspectTemplateArgs.builder()
            .parent("projects/my-project-name")
            .description("My description")
            .displayName("display_name")
            .inspectConfig(PreventionInspectTemplateInspectConfigArgs.builder()
                .customInfoTypes(PreventionInspectTemplateInspectConfigCustomInfoTypeArgs.builder()
                    .infoType(PreventionInspectTemplateInspectConfigCustomInfoTypeInfoTypeArgs.builder()
                        .name("MY_CUSTOM_TYPE")
                        .build())
                    .likelihood("UNLIKELY")
                    .regex(PreventionInspectTemplateInspectConfigCustomInfoTypeRegexArgs.builder()
                        .pattern("test*")
                        .build())
                    .build())
                .infoTypes(PreventionInspectTemplateInspectConfigInfoTypeArgs.builder()
                    .name("EMAIL_ADDRESS")
                    .build())
                .minLikelihood("UNLIKELY")
                .ruleSets(                
                    PreventionInspectTemplateInspectConfigRuleSetArgs.builder()
                        .infoTypes(PreventionInspectTemplateInspectConfigRuleSetInfoTypeArgs.builder()
                            .name("EMAIL_ADDRESS")
                            .build())
                        .rules(PreventionInspectTemplateInspectConfigRuleSetRuleArgs.builder()
                            .exclusionRule(PreventionInspectTemplateInspectConfigRuleSetRuleExclusionRuleArgs.builder()
                                .regex(PreventionInspectTemplateInspectConfigRuleSetRuleExclusionRuleRegexArgs.builder()
                                    .pattern(".+@example.com")
                                    .build())
                                .matchingType("MATCHING_TYPE_FULL_MATCH")
                                .build())
                            .build())
                        .build(),
                    PreventionInspectTemplateInspectConfigRuleSetArgs.builder()
                        .infoTypes(PreventionInspectTemplateInspectConfigRuleSetInfoTypeArgs.builder()
                            .name("MY_CUSTOM_TYPE")
                            .build())
                        .rules(PreventionInspectTemplateInspectConfigRuleSetRuleArgs.builder()
                            .hotwordRule(PreventionInspectTemplateInspectConfigRuleSetRuleHotwordRuleArgs.builder()
                                .hotwordRegex(PreventionInspectTemplateInspectConfigRuleSetRuleHotwordRuleHotwordRegexArgs.builder()
                                    .pattern("example*")
                                    .build())
                                .proximity(PreventionInspectTemplateInspectConfigRuleSetRuleHotwordRuleProximityArgs.builder()
                                    .windowBefore(50)
                                    .build())
                                .likelihoodAdjustment(PreventionInspectTemplateInspectConfigRuleSetRuleHotwordRuleLikelihoodAdjustmentArgs.builder()
                                    .fixedLikelihood("VERY_LIKELY")
                                    .build())
                                .build())
                            .build())
                        .build())
                .limits(PreventionInspectTemplateInspectConfigLimitsArgs.builder()
                    .maxFindingsPerItem(10)
                    .maxFindingsPerRequest(50)
                    .build())
                .build())
            .build());

    }
}
```
```yaml
resources:
  custom:
    type: gcp:dataloss:PreventionInspectTemplate
    properties:
      parent: projects/my-project-name
      description: My description
      displayName: display_name
      inspectConfig:
        customInfoTypes:
          - infoType:
              name: MY_CUSTOM_TYPE
            likelihood: UNLIKELY
            regex:
              pattern: test*
        infoTypes:
          - name: EMAIL_ADDRESS
        minLikelihood: UNLIKELY
        ruleSets:
          - infoTypes:
              - name: EMAIL_ADDRESS
            rules:
              - exclusionRule:
                  regex:
                    pattern: .+@example.com
                  matchingType: MATCHING_TYPE_FULL_MATCH
          - infoTypes:
              - name: MY_CUSTOM_TYPE
            rules:
              - hotwordRule:
                  hotwordRegex:
                    pattern: example*
                  proximity:
                    windowBefore: 50
                  likelihoodAdjustment:
                    fixedLikelihood: VERY_LIKELY
        limits:
          maxFindingsPerItem: 10
          maxFindingsPerRequest: 50
```
<!--End PulumiCodeChooser -->
### Dlp Inspect Template Custom Type Surrogate


<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const customTypeSurrogate = new gcp.dataloss.PreventionInspectTemplate("custom_type_surrogate", {
    parent: "projects/my-project-name",
    description: "My description",
    displayName: "display_name",
    inspectConfig: {
        customInfoTypes: [{
            infoType: {
                name: "MY_CUSTOM_TYPE",
            },
            likelihood: "UNLIKELY",
            surrogateType: {},
        }],
        infoTypes: [{
            name: "EMAIL_ADDRESS",
        }],
        minLikelihood: "UNLIKELY",
        ruleSets: [
            {
                infoTypes: [{
                    name: "EMAIL_ADDRESS",
                }],
                rules: [{
                    exclusionRule: {
                        regex: {
                            pattern: ".+@example.com",
                        },
                        matchingType: "MATCHING_TYPE_FULL_MATCH",
                    },
                }],
            },
            {
                infoTypes: [{
                    name: "MY_CUSTOM_TYPE",
                }],
                rules: [{
                    hotwordRule: {
                        hotwordRegex: {
                            pattern: "example*",
                        },
                        proximity: {
                            windowBefore: 50,
                        },
                        likelihoodAdjustment: {
                            fixedLikelihood: "VERY_LIKELY",
                        },
                    },
                }],
            },
        ],
        limits: {
            maxFindingsPerItem: 10,
            maxFindingsPerRequest: 50,
        },
    },
});
```
```python
import pulumi
import pulumi_gcp as gcp

custom_type_surrogate = gcp.dataloss.PreventionInspectTemplate("custom_type_surrogate",
    parent="projects/my-project-name",
    description="My description",
    display_name="display_name",
    inspect_config={
        "custom_info_types": [{
            "info_type": {
                "name": "MY_CUSTOM_TYPE",
            },
            "likelihood": "UNLIKELY",
            "surrogate_type": {},
        }],
        "info_types": [{
            "name": "EMAIL_ADDRESS",
        }],
        "min_likelihood": "UNLIKELY",
        "rule_sets": [
            {
                "info_types": [{
                    "name": "EMAIL_ADDRESS",
                }],
                "rules": [{
                    "exclusion_rule": {
                        "regex": {
                            "pattern": ".+@example.com",
                        },
                        "matching_type": "MATCHING_TYPE_FULL_MATCH",
                    },
                }],
            },
            {
                "info_types": [{
                    "name": "MY_CUSTOM_TYPE",
                }],
                "rules": [{
                    "hotword_rule": {
                        "hotword_regex": {
                            "pattern": "example*",
                        },
                        "proximity": {
                            "window_before": 50,
                        },
                        "likelihood_adjustment": {
                            "fixed_likelihood": "VERY_LIKELY",
                        },
                    },
                }],
            },
        ],
        "limits": {
            "max_findings_per_item": 10,
            "max_findings_per_request": 50,
        },
    })
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var customTypeSurrogate = new Gcp.DataLoss.PreventionInspectTemplate("custom_type_surrogate", new()
    {
        Parent = "projects/my-project-name",
        Description = "My description",
        DisplayName = "display_name",
        InspectConfig = new Gcp.DataLoss.Inputs.PreventionInspectTemplateInspectConfigArgs
        {
            CustomInfoTypes = new[]
            {
                new Gcp.DataLoss.Inputs.PreventionInspectTemplateInspectConfigCustomInfoTypeArgs
                {
                    InfoType = new Gcp.DataLoss.Inputs.PreventionInspectTemplateInspectConfigCustomInfoTypeInfoTypeArgs
                    {
                        Name = "MY_CUSTOM_TYPE",
                    },
                    Likelihood = "UNLIKELY",
                    SurrogateType = null,
                },
            },
            InfoTypes = new[]
            {
                new Gcp.DataLoss.Inputs.PreventionInspectTemplateInspectConfigInfoTypeArgs
                {
                    Name = "EMAIL_ADDRESS",
                },
            },
            MinLikelihood = "UNLIKELY",
            RuleSets = new[]
            {
                new Gcp.DataLoss.Inputs.PreventionInspectTemplateInspectConfigRuleSetArgs
                {
                    InfoTypes = new[]
                    {
                        new Gcp.DataLoss.Inputs.PreventionInspectTemplateInspectConfigRuleSetInfoTypeArgs
                        {
                            Name = "EMAIL_ADDRESS",
                        },
                    },
                    Rules = new[]
                    {
                        new Gcp.DataLoss.Inputs.PreventionInspectTemplateInspectConfigRuleSetRuleArgs
                        {
                            ExclusionRule = new Gcp.DataLoss.Inputs.PreventionInspectTemplateInspectConfigRuleSetRuleExclusionRuleArgs
                            {
                                Regex = new Gcp.DataLoss.Inputs.PreventionInspectTemplateInspectConfigRuleSetRuleExclusionRuleRegexArgs
                                {
                                    Pattern = ".+@example.com",
                                },
                                MatchingType = "MATCHING_TYPE_FULL_MATCH",
                            },
                        },
                    },
                },
                new Gcp.DataLoss.Inputs.PreventionInspectTemplateInspectConfigRuleSetArgs
                {
                    InfoTypes = new[]
                    {
                        new Gcp.DataLoss.Inputs.PreventionInspectTemplateInspectConfigRuleSetInfoTypeArgs
                        {
                            Name = "MY_CUSTOM_TYPE",
                        },
                    },
                    Rules = new[]
                    {
                        new Gcp.DataLoss.Inputs.PreventionInspectTemplateInspectConfigRuleSetRuleArgs
                        {
                            HotwordRule = new Gcp.DataLoss.Inputs.PreventionInspectTemplateInspectConfigRuleSetRuleHotwordRuleArgs
                            {
                                HotwordRegex = new Gcp.DataLoss.Inputs.PreventionInspectTemplateInspectConfigRuleSetRuleHotwordRuleHotwordRegexArgs
                                {
                                    Pattern = "example*",
                                },
                                Proximity = new Gcp.DataLoss.Inputs.PreventionInspectTemplateInspectConfigRuleSetRuleHotwordRuleProximityArgs
                                {
                                    WindowBefore = 50,
                                },
                                LikelihoodAdjustment = new Gcp.DataLoss.Inputs.PreventionInspectTemplateInspectConfigRuleSetRuleHotwordRuleLikelihoodAdjustmentArgs
                                {
                                    FixedLikelihood = "VERY_LIKELY",
                                },
                            },
                        },
                    },
                },
            },
            Limits = new Gcp.DataLoss.Inputs.PreventionInspectTemplateInspectConfigLimitsArgs
            {
                MaxFindingsPerItem = 10,
                MaxFindingsPerRequest = 50,
            },
        },
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/dataloss"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		_, err := dataloss.NewPreventionInspectTemplate(ctx, "custom_type_surrogate", &dataloss.PreventionInspectTemplateArgs{
			Parent:      pulumi.String("projects/my-project-name"),
			Description: pulumi.String("My description"),
			DisplayName: pulumi.String("display_name"),
			InspectConfig: &dataloss.PreventionInspectTemplateInspectConfigArgs{
				CustomInfoTypes: dataloss.PreventionInspectTemplateInspectConfigCustomInfoTypeArray{
					&dataloss.PreventionInspectTemplateInspectConfigCustomInfoTypeArgs{
						InfoType: &dataloss.PreventionInspectTemplateInspectConfigCustomInfoTypeInfoTypeArgs{
							Name: pulumi.String("MY_CUSTOM_TYPE"),
						},
						Likelihood:    pulumi.String("UNLIKELY"),
						SurrogateType: &dataloss.PreventionInspectTemplateInspectConfigCustomInfoTypeSurrogateTypeArgs{},
					},
				},
				InfoTypes: dataloss.PreventionInspectTemplateInspectConfigInfoTypeArray{
					&dataloss.PreventionInspectTemplateInspectConfigInfoTypeArgs{
						Name: pulumi.String("EMAIL_ADDRESS"),
					},
				},
				MinLikelihood: pulumi.String("UNLIKELY"),
				RuleSets: dataloss.PreventionInspectTemplateInspectConfigRuleSetArray{
					&dataloss.PreventionInspectTemplateInspectConfigRuleSetArgs{
						InfoTypes: dataloss.PreventionInspectTemplateInspectConfigRuleSetInfoTypeArray{
							&dataloss.PreventionInspectTemplateInspectConfigRuleSetInfoTypeArgs{
								Name: pulumi.String("EMAIL_ADDRESS"),
							},
						},
						Rules: dataloss.PreventionInspectTemplateInspectConfigRuleSetRuleArray{
							&dataloss.PreventionInspectTemplateInspectConfigRuleSetRuleArgs{
								ExclusionRule: &dataloss.PreventionInspectTemplateInspectConfigRuleSetRuleExclusionRuleArgs{
									Regex: &dataloss.PreventionInspectTemplateInspectConfigRuleSetRuleExclusionRuleRegexArgs{
										Pattern: pulumi.String(".+@example.com"),
									},
									MatchingType: pulumi.String("MATCHING_TYPE_FULL_MATCH"),
								},
							},
						},
					},
					&dataloss.PreventionInspectTemplateInspectConfigRuleSetArgs{
						InfoTypes: dataloss.PreventionInspectTemplateInspectConfigRuleSetInfoTypeArray{
							&dataloss.PreventionInspectTemplateInspectConfigRuleSetInfoTypeArgs{
								Name: pulumi.String("MY_CUSTOM_TYPE"),
							},
						},
						Rules: dataloss.PreventionInspectTemplateInspectConfigRuleSetRuleArray{
							&dataloss.PreventionInspectTemplateInspectConfigRuleSetRuleArgs{
								HotwordRule: &dataloss.PreventionInspectTemplateInspectConfigRuleSetRuleHotwordRuleArgs{
									HotwordRegex: &dataloss.PreventionInspectTemplateInspectConfigRuleSetRuleHotwordRuleHotwordRegexArgs{
										Pattern: pulumi.String("example*"),
									},
									Proximity: &dataloss.PreventionInspectTemplateInspectConfigRuleSetRuleHotwordRuleProximityArgs{
										WindowBefore: pulumi.Int(50),
									},
									LikelihoodAdjustment: &dataloss.PreventionInspectTemplateInspectConfigRuleSetRuleHotwordRuleLikelihoodAdjustmentArgs{
										FixedLikelihood: pulumi.String("VERY_LIKELY"),
									},
								},
							},
						},
					},
				},
				Limits: &dataloss.PreventionInspectTemplateInspectConfigLimitsArgs{
					MaxFindingsPerItem:    pulumi.Int(10),
					MaxFindingsPerRequest: pulumi.Int(50),
				},
			},
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.dataloss.PreventionInspectTemplate;
import com.pulumi.gcp.dataloss.PreventionInspectTemplateArgs;
import com.pulumi.gcp.dataloss.inputs.PreventionInspectTemplateInspectConfigArgs;
import com.pulumi.gcp.dataloss.inputs.PreventionInspectTemplateInspectConfigLimitsArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        var customTypeSurrogate = new PreventionInspectTemplate("customTypeSurrogate", PreventionInspectTemplateArgs.builder()
            .parent("projects/my-project-name")
            .description("My description")
            .displayName("display_name")
            .inspectConfig(PreventionInspectTemplateInspectConfigArgs.builder()
                .customInfoTypes(PreventionInspectTemplateInspectConfigCustomInfoTypeArgs.builder()
                    .infoType(PreventionInspectTemplateInspectConfigCustomInfoTypeInfoTypeArgs.builder()
                        .name("MY_CUSTOM_TYPE")
                        .build())
                    .likelihood("UNLIKELY")
                    .surrogateType()
                    .build())
                .infoTypes(PreventionInspectTemplateInspectConfigInfoTypeArgs.builder()
                    .name("EMAIL_ADDRESS")
                    .build())
                .minLikelihood("UNLIKELY")
                .ruleSets(                
                    PreventionInspectTemplateInspectConfigRuleSetArgs.builder()
                        .infoTypes(PreventionInspectTemplateInspectConfigRuleSetInfoTypeArgs.builder()
                            .name("EMAIL_ADDRESS")
                            .build())
                        .rules(PreventionInspectTemplateInspectConfigRuleSetRuleArgs.builder()
                            .exclusionRule(PreventionInspectTemplateInspectConfigRuleSetRuleExclusionRuleArgs.builder()
                                .regex(PreventionInspectTemplateInspectConfigRuleSetRuleExclusionRuleRegexArgs.builder()
                                    .pattern(".+@example.com")
                                    .build())
                                .matchingType("MATCHING_TYPE_FULL_MATCH")
                                .build())
                            .build())
                        .build(),
                    PreventionInspectTemplateInspectConfigRuleSetArgs.builder()
                        .infoTypes(PreventionInspectTemplateInspectConfigRuleSetInfoTypeArgs.builder()
                            .name("MY_CUSTOM_TYPE")
                            .build())
                        .rules(PreventionInspectTemplateInspectConfigRuleSetRuleArgs.builder()
                            .hotwordRule(PreventionInspectTemplateInspectConfigRuleSetRuleHotwordRuleArgs.builder()
                                .hotwordRegex(PreventionInspectTemplateInspectConfigRuleSetRuleHotwordRuleHotwordRegexArgs.builder()
                                    .pattern("example*")
                                    .build())
                                .proximity(PreventionInspectTemplateInspectConfigRuleSetRuleHotwordRuleProximityArgs.builder()
                                    .windowBefore(50)
                                    .build())
                                .likelihoodAdjustment(PreventionInspectTemplateInspectConfigRuleSetRuleHotwordRuleLikelihoodAdjustmentArgs.builder()
                                    .fixedLikelihood("VERY_LIKELY")
                                    .build())
                                .build())
                            .build())
                        .build())
                .limits(PreventionInspectTemplateInspectConfigLimitsArgs.builder()
                    .maxFindingsPerItem(10)
                    .maxFindingsPerRequest(50)
                    .build())
                .build())
            .build());

    }
}
```
```yaml
resources:
  customTypeSurrogate:
    type: gcp:dataloss:PreventionInspectTemplate
    name: custom_type_surrogate
    properties:
      parent: projects/my-project-name
      description: My description
      displayName: display_name
      inspectConfig:
        customInfoTypes:
          - infoType:
              name: MY_CUSTOM_TYPE
            likelihood: UNLIKELY
            surrogateType: {}
        infoTypes:
          - name: EMAIL_ADDRESS
        minLikelihood: UNLIKELY
        ruleSets:
          - infoTypes:
              - name: EMAIL_ADDRESS
            rules:
              - exclusionRule:
                  regex:
                    pattern: .+@example.com
                  matchingType: MATCHING_TYPE_FULL_MATCH
          - infoTypes:
              - name: MY_CUSTOM_TYPE
            rules:
              - hotwordRule:
                  hotwordRegex:
                    pattern: example*
                  proximity:
                    windowBefore: 50
                  likelihoodAdjustment:
                    fixedLikelihood: VERY_LIKELY
        limits:
          maxFindingsPerItem: 10
          maxFindingsPerRequest: 50
```
<!--End PulumiCodeChooser -->
### Dlp Inspect Template Max Infotype Per Finding Default


<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const maxInfotypePerFindingDefault = new gcp.dataloss.PreventionInspectTemplate("max_infotype_per_finding_default", {
    parent: "projects/my-project-name",
    inspectConfig: {
        infoTypes: [
            {
                name: "EMAIL_ADDRESS",
            },
            {
                name: "PERSON_NAME",
            },
        ],
        minLikelihood: "UNLIKELY",
        limits: {
            maxFindingsPerRequest: 333,
            maxFindingsPerItem: 222,
            maxFindingsPerInfoTypes: [{
                maxFindings: 111,
            }],
        },
    },
});
```
```python
import pulumi
import pulumi_gcp as gcp

max_infotype_per_finding_default = gcp.dataloss.PreventionInspectTemplate("max_infotype_per_finding_default",
    parent="projects/my-project-name",
    inspect_config={
        "info_types": [
            {
                "name": "EMAIL_ADDRESS",
            },
            {
                "name": "PERSON_NAME",
            },
        ],
        "min_likelihood": "UNLIKELY",
        "limits": {
            "max_findings_per_request": 333,
            "max_findings_per_item": 222,
            "max_findings_per_info_types": [{
                "max_findings": 111,
            }],
        },
    })
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var maxInfotypePerFindingDefault = new Gcp.DataLoss.PreventionInspectTemplate("max_infotype_per_finding_default", new()
    {
        Parent = "projects/my-project-name",
        InspectConfig = new Gcp.DataLoss.Inputs.PreventionInspectTemplateInspectConfigArgs
        {
            InfoTypes = new[]
            {
                new Gcp.DataLoss.Inputs.PreventionInspectTemplateInspectConfigInfoTypeArgs
                {
                    Name = "EMAIL_ADDRESS",
                },
                new Gcp.DataLoss.Inputs.PreventionInspectTemplateInspectConfigInfoTypeArgs
                {
                    Name = "PERSON_NAME",
                },
            },
            MinLikelihood = "UNLIKELY",
            Limits = new Gcp.DataLoss.Inputs.PreventionInspectTemplateInspectConfigLimitsArgs
            {
                MaxFindingsPerRequest = 333,
                MaxFindingsPerItem = 222,
                MaxFindingsPerInfoTypes = new[]
                {
                    new Gcp.DataLoss.Inputs.PreventionInspectTemplateInspectConfigLimitsMaxFindingsPerInfoTypeArgs
                    {
                        MaxFindings = 111,
                    },
                },
            },
        },
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/dataloss"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		_, err := dataloss.NewPreventionInspectTemplate(ctx, "max_infotype_per_finding_default", &dataloss.PreventionInspectTemplateArgs{
			Parent: pulumi.String("projects/my-project-name"),
			InspectConfig: &dataloss.PreventionInspectTemplateInspectConfigArgs{
				InfoTypes: dataloss.PreventionInspectTemplateInspectConfigInfoTypeArray{
					&dataloss.PreventionInspectTemplateInspectConfigInfoTypeArgs{
						Name: pulumi.String("EMAIL_ADDRESS"),
					},
					&dataloss.PreventionInspectTemplateInspectConfigInfoTypeArgs{
						Name: pulumi.String("PERSON_NAME"),
					},
				},
				MinLikelihood: pulumi.String("UNLIKELY"),
				Limits: &dataloss.PreventionInspectTemplateInspectConfigLimitsArgs{
					MaxFindingsPerRequest: pulumi.Int(333),
					MaxFindingsPerItem:    pulumi.Int(222),
					MaxFindingsPerInfoTypes: dataloss.PreventionInspectTemplateInspectConfigLimitsMaxFindingsPerInfoTypeArray{
						&dataloss.PreventionInspectTemplateInspectConfigLimitsMaxFindingsPerInfoTypeArgs{
							MaxFindings: pulumi.Int(111),
						},
					},
				},
			},
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.dataloss.PreventionInspectTemplate;
import com.pulumi.gcp.dataloss.PreventionInspectTemplateArgs;
import com.pulumi.gcp.dataloss.inputs.PreventionInspectTemplateInspectConfigArgs;
import com.pulumi.gcp.dataloss.inputs.PreventionInspectTemplateInspectConfigLimitsArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        var maxInfotypePerFindingDefault = new PreventionInspectTemplate("maxInfotypePerFindingDefault", PreventionInspectTemplateArgs.builder()
            .parent("projects/my-project-name")
            .inspectConfig(PreventionInspectTemplateInspectConfigArgs.builder()
                .infoTypes(                
                    PreventionInspectTemplateInspectConfigInfoTypeArgs.builder()
                        .name("EMAIL_ADDRESS")
                        .build(),
                    PreventionInspectTemplateInspectConfigInfoTypeArgs.builder()
                        .name("PERSON_NAME")
                        .build())
                .minLikelihood("UNLIKELY")
                .limits(PreventionInspectTemplateInspectConfigLimitsArgs.builder()
                    .maxFindingsPerRequest(333)
                    .maxFindingsPerItem(222)
                    .maxFindingsPerInfoTypes(PreventionInspectTemplateInspectConfigLimitsMaxFindingsPerInfoTypeArgs.builder()
                        .maxFindings(111)
                        .build())
                    .build())
                .build())
            .build());

    }
}
```
```yaml
resources:
  maxInfotypePerFindingDefault:
    type: gcp:dataloss:PreventionInspectTemplate
    name: max_infotype_per_finding_default
    properties:
      parent: projects/my-project-name
      inspectConfig:
        infoTypes:
          - name: EMAIL_ADDRESS
          - name: PERSON_NAME
        minLikelihood: UNLIKELY
        limits:
          maxFindingsPerRequest: 333
          maxFindingsPerItem: 222
          maxFindingsPerInfoTypes:
            - maxFindings: 111
```
<!--End PulumiCodeChooser -->

## Import

InspectTemplate can be imported using any of these accepted formats:

* `{{parent}}/inspectTemplates/{{name}}`

* `{{parent}}/{{name}}`

When using the `pulumi import` command, InspectTemplate can be imported using one of the formats above. For example:

```sh
$ pulumi import gcp:dataloss/preventionInspectTemplate:PreventionInspectTemplate default {{parent}}/inspectTemplates/{{name}}
```

```sh
$ pulumi import gcp:dataloss/preventionInspectTemplate:PreventionInspectTemplate default {{parent}}/{{name}}
```

<
descriptionB" 'A description of the inspect template.
D
displayNameB" /User set display name of the inspect template.
ì
inspectConfigB:

dataloss&PreventionInspectTemplateInspectConfigZgcp:dataloss/PreventionInspectTemplateInspectConfig:PreventionInspectTemplateInspectConfigAThe core content of the template.
Structure is documented below.

parent" øThe parent of the inspect template in any of the following formats:
* `projects/{{project}}`
* `projects/{{project}}/locations/{{location}}`
* `organizations/{{organization_id}}`
* `organizations/{{organization_id}}/locations/{{location}}`


- - -
þ

templateIdB" éThe template id can contain uppercase and lowercase letters, numbers, and hyphens;
that is, it must match the regular expression: [a-zA-Z\d-_]+. The maximum length is
100 characters. Can be empty to allow the system to generate one.
"<
descriptionB" 'A description of the inspect template.
"D
displayNameB" /User set display name of the inspect template.
"ì
inspectConfigB:

dataloss&PreventionInspectTemplateInspectConfigZgcp:dataloss/PreventionInspectTemplateInspectConfig:PreventionInspectTemplateInspectConfigAThe core content of the template.
Structure is documented below.
"J
name" >The resource name of the inspect template. Set by the server.
"
parent" øThe parent of the inspect template in any of the following formats:
* `projects/{{project}}`
* `projects/{{project}}/locations/{{location}}`
* `organizations/{{organization_id}}`
* `organizations/{{organization_id}}/locations/{{location}}`


- - -
"ü

templateId" éThe template id can contain uppercase and lowercase letters, numbers, and hyphens;
that is, it must match the regular expression: [a-zA-Z\d-_]+. The maximum length is
100 characters. Can be empty to allow the system to generate one.
*°	
X
datalossPreventionJobTrigger6gcp:dataloss/preventionJobTrigger:PreventionJobTriggerÏ÷A job trigger configuration.


To get more information about JobTrigger, see:

* [API documentation](https://cloud.google.com/dlp/docs/reference/rest/v2/projects.jobTriggers)
* How-to Guides
    * [Official Documentation](https://cloud.google.com/dlp/docs/creating-job-triggers)

## Example Usage

### Dlp Job Trigger Basic


<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const basic = new gcp.dataloss.PreventionJobTrigger("basic", {
    parent: "projects/my-project-name",
    description: "Description",
    displayName: "Displayname",
    triggers: [{
        schedule: {
            recurrencePeriodDuration: "86400s",
        },
    }],
    inspectJob: {
        inspectTemplateName: "fake",
        actions: [{
            saveFindings: {
                outputConfig: {
                    table: {
                        projectId: "project",
                        datasetId: "dataset",
                    },
                },
            },
        }],
        storageConfig: {
            cloudStorageOptions: {
                fileSet: {
                    url: "gs://mybucket/directory/",
                },
            },
        },
    },
});
```
```python
import pulumi
import pulumi_gcp as gcp

basic = gcp.dataloss.PreventionJobTrigger("basic",
    parent="projects/my-project-name",
    description="Description",
    display_name="Displayname",
    triggers=[{
        "schedule": {
            "recurrence_period_duration": "86400s",
        },
    }],
    inspect_job={
        "inspect_template_name": "fake",
        "actions": [{
            "save_findings": {
                "output_config": {
                    "table": {
                        "project_id": "project",
                        "dataset_id": "dataset",
                    },
                },
            },
        }],
        "storage_config": {
            "cloud_storage_options": {
                "file_set": {
                    "url": "gs://mybucket/directory/",
                },
            },
        },
    })
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var basic = new Gcp.DataLoss.PreventionJobTrigger("basic", new()
    {
        Parent = "projects/my-project-name",
        Description = "Description",
        DisplayName = "Displayname",
        Triggers = new[]
        {
            new Gcp.DataLoss.Inputs.PreventionJobTriggerTriggerArgs
            {
                Schedule = new Gcp.DataLoss.Inputs.PreventionJobTriggerTriggerScheduleArgs
                {
                    RecurrencePeriodDuration = "86400s",
                },
            },
        },
        InspectJob = new Gcp.DataLoss.Inputs.PreventionJobTriggerInspectJobArgs
        {
            InspectTemplateName = "fake",
            Actions = new[]
            {
                new Gcp.DataLoss.Inputs.PreventionJobTriggerInspectJobActionArgs
                {
                    SaveFindings = new Gcp.DataLoss.Inputs.PreventionJobTriggerInspectJobActionSaveFindingsArgs
                    {
                        OutputConfig = new Gcp.DataLoss.Inputs.PreventionJobTriggerInspectJobActionSaveFindingsOutputConfigArgs
                        {
                            Table = new Gcp.DataLoss.Inputs.PreventionJobTriggerInspectJobActionSaveFindingsOutputConfigTableArgs
                            {
                                ProjectId = "project",
                                DatasetId = "dataset",
                            },
                        },
                    },
                },
            },
            StorageConfig = new Gcp.DataLoss.Inputs.PreventionJobTriggerInspectJobStorageConfigArgs
            {
                CloudStorageOptions = new Gcp.DataLoss.Inputs.PreventionJobTriggerInspectJobStorageConfigCloudStorageOptionsArgs
                {
                    FileSet = new Gcp.DataLoss.Inputs.PreventionJobTriggerInspectJobStorageConfigCloudStorageOptionsFileSetArgs
                    {
                        Url = "gs://mybucket/directory/",
                    },
                },
            },
        },
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/dataloss"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		_, err := dataloss.NewPreventionJobTrigger(ctx, "basic", &dataloss.PreventionJobTriggerArgs{
			Parent:      pulumi.String("projects/my-project-name"),
			Description: pulumi.String("Description"),
			DisplayName: pulumi.String("Displayname"),
			Triggers: dataloss.PreventionJobTriggerTriggerArray{
				&dataloss.PreventionJobTriggerTriggerArgs{
					Schedule: &dataloss.PreventionJobTriggerTriggerScheduleArgs{
						RecurrencePeriodDuration: pulumi.String("86400s"),
					},
				},
			},
			InspectJob: &dataloss.PreventionJobTriggerInspectJobArgs{
				InspectTemplateName: pulumi.String("fake"),
				Actions: dataloss.PreventionJobTriggerInspectJobActionArray{
					&dataloss.PreventionJobTriggerInspectJobActionArgs{
						SaveFindings: &dataloss.PreventionJobTriggerInspectJobActionSaveFindingsArgs{
							OutputConfig: &dataloss.PreventionJobTriggerInspectJobActionSaveFindingsOutputConfigArgs{
								Table: &dataloss.PreventionJobTriggerInspectJobActionSaveFindingsOutputConfigTableArgs{
									ProjectId: pulumi.String("project"),
									DatasetId: pulumi.String("dataset"),
								},
							},
						},
					},
				},
				StorageConfig: &dataloss.PreventionJobTriggerInspectJobStorageConfigArgs{
					CloudStorageOptions: &dataloss.PreventionJobTriggerInspectJobStorageConfigCloudStorageOptionsArgs{
						FileSet: &dataloss.PreventionJobTriggerInspectJobStorageConfigCloudStorageOptionsFileSetArgs{
							Url: pulumi.String("gs://mybucket/directory/"),
						},
					},
				},
			},
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.dataloss.PreventionJobTrigger;
import com.pulumi.gcp.dataloss.PreventionJobTriggerArgs;
import com.pulumi.gcp.dataloss.inputs.PreventionJobTriggerTriggerArgs;
import com.pulumi.gcp.dataloss.inputs.PreventionJobTriggerTriggerScheduleArgs;
import com.pulumi.gcp.dataloss.inputs.PreventionJobTriggerInspectJobArgs;
import com.pulumi.gcp.dataloss.inputs.PreventionJobTriggerInspectJobStorageConfigArgs;
import com.pulumi.gcp.dataloss.inputs.PreventionJobTriggerInspectJobStorageConfigCloudStorageOptionsArgs;
import com.pulumi.gcp.dataloss.inputs.PreventionJobTriggerInspectJobStorageConfigCloudStorageOptionsFileSetArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        var basic = new PreventionJobTrigger("basic", PreventionJobTriggerArgs.builder()
            .parent("projects/my-project-name")
            .description("Description")
            .displayName("Displayname")
            .triggers(PreventionJobTriggerTriggerArgs.builder()
                .schedule(PreventionJobTriggerTriggerScheduleArgs.builder()
                    .recurrencePeriodDuration("86400s")
                    .build())
                .build())
            .inspectJob(PreventionJobTriggerInspectJobArgs.builder()
                .inspectTemplateName("fake")
                .actions(PreventionJobTriggerInspectJobActionArgs.builder()
                    .saveFindings(PreventionJobTriggerInspectJobActionSaveFindingsArgs.builder()
                        .outputConfig(PreventionJobTriggerInspectJobActionSaveFindingsOutputConfigArgs.builder()
                            .table(PreventionJobTriggerInspectJobActionSaveFindingsOutputConfigTableArgs.builder()
                                .projectId("project")
                                .datasetId("dataset")
                                .build())
                            .build())
                        .build())
                    .build())
                .storageConfig(PreventionJobTriggerInspectJobStorageConfigArgs.builder()
                    .cloudStorageOptions(PreventionJobTriggerInspectJobStorageConfigCloudStorageOptionsArgs.builder()
                        .fileSet(PreventionJobTriggerInspectJobStorageConfigCloudStorageOptionsFileSetArgs.builder()
                            .url("gs://mybucket/directory/")
                            .build())
                        .build())
                    .build())
                .build())
            .build());

    }
}
```
```yaml
resources:
  basic:
    type: gcp:dataloss:PreventionJobTrigger
    properties:
      parent: projects/my-project-name
      description: Description
      displayName: Displayname
      triggers:
        - schedule:
            recurrencePeriodDuration: 86400s
      inspectJob:
        inspectTemplateName: fake
        actions:
          - saveFindings:
              outputConfig:
                table:
                  projectId: project
                  datasetId: dataset
        storageConfig:
          cloudStorageOptions:
            fileSet:
              url: gs://mybucket/directory/
```
<!--End PulumiCodeChooser -->
### Dlp Job Trigger Bigquery Row Limit


<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const bigqueryRowLimit = new gcp.dataloss.PreventionJobTrigger("bigquery_row_limit", {
    parent: "projects/my-project-name",
    description: "Description",
    displayName: "Displayname",
    triggers: [{
        schedule: {
            recurrencePeriodDuration: "86400s",
        },
    }],
    inspectJob: {
        inspectTemplateName: "fake",
        actions: [{
            saveFindings: {
                outputConfig: {
                    table: {
                        projectId: "project",
                        datasetId: "dataset",
                    },
                },
            },
        }],
        storageConfig: {
            bigQueryOptions: {
                tableReference: {
                    projectId: "project",
                    datasetId: "dataset",
                    tableId: "table_to_scan",
                },
                rowsLimit: 1000,
                sampleMethod: "RANDOM_START",
            },
        },
    },
});
```
```python
import pulumi
import pulumi_gcp as gcp

bigquery_row_limit = gcp.dataloss.PreventionJobTrigger("bigquery_row_limit",
    parent="projects/my-project-name",
    description="Description",
    display_name="Displayname",
    triggers=[{
        "schedule": {
            "recurrence_period_duration": "86400s",
        },
    }],
    inspect_job={
        "inspect_template_name": "fake",
        "actions": [{
            "save_findings": {
                "output_config": {
                    "table": {
                        "project_id": "project",
                        "dataset_id": "dataset",
                    },
                },
            },
        }],
        "storage_config": {
            "big_query_options": {
                "table_reference": {
                    "project_id": "project",
                    "dataset_id": "dataset",
                    "table_id": "table_to_scan",
                },
                "rows_limit": 1000,
                "sample_method": "RANDOM_START",
            },
        },
    })
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var bigqueryRowLimit = new Gcp.DataLoss.PreventionJobTrigger("bigquery_row_limit", new()
    {
        Parent = "projects/my-project-name",
        Description = "Description",
        DisplayName = "Displayname",
        Triggers = new[]
        {
            new Gcp.DataLoss.Inputs.PreventionJobTriggerTriggerArgs
            {
                Schedule = new Gcp.DataLoss.Inputs.PreventionJobTriggerTriggerScheduleArgs
                {
                    RecurrencePeriodDuration = "86400s",
                },
            },
        },
        InspectJob = new Gcp.DataLoss.Inputs.PreventionJobTriggerInspectJobArgs
        {
            InspectTemplateName = "fake",
            Actions = new[]
            {
                new Gcp.DataLoss.Inputs.PreventionJobTriggerInspectJobActionArgs
                {
                    SaveFindings = new Gcp.DataLoss.Inputs.PreventionJobTriggerInspectJobActionSaveFindingsArgs
                    {
                        OutputConfig = new Gcp.DataLoss.Inputs.PreventionJobTriggerInspectJobActionSaveFindingsOutputConfigArgs
                        {
                            Table = new Gcp.DataLoss.Inputs.PreventionJobTriggerInspectJobActionSaveFindingsOutputConfigTableArgs
                            {
                                ProjectId = "project",
                                DatasetId = "dataset",
                            },
                        },
                    },
                },
            },
            StorageConfig = new Gcp.DataLoss.Inputs.PreventionJobTriggerInspectJobStorageConfigArgs
            {
                BigQueryOptions = new Gcp.DataLoss.Inputs.PreventionJobTriggerInspectJobStorageConfigBigQueryOptionsArgs
                {
                    TableReference = new Gcp.DataLoss.Inputs.PreventionJobTriggerInspectJobStorageConfigBigQueryOptionsTableReferenceArgs
                    {
                        ProjectId = "project",
                        DatasetId = "dataset",
                        TableId = "table_to_scan",
                    },
                    RowsLimit = 1000,
                    SampleMethod = "RANDOM_START",
                },
            },
        },
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/dataloss"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		_, err := dataloss.NewPreventionJobTrigger(ctx, "bigquery_row_limit", &dataloss.PreventionJobTriggerArgs{
			Parent:      pulumi.String("projects/my-project-name"),
			Description: pulumi.String("Description"),
			DisplayName: pulumi.String("Displayname"),
			Triggers: dataloss.PreventionJobTriggerTriggerArray{
				&dataloss.PreventionJobTriggerTriggerArgs{
					Schedule: &dataloss.PreventionJobTriggerTriggerScheduleArgs{
						RecurrencePeriodDuration: pulumi.String("86400s"),
					},
				},
			},
			InspectJob: &dataloss.PreventionJobTriggerInspectJobArgs{
				InspectTemplateName: pulumi.String("fake"),
				Actions: dataloss.PreventionJobTriggerInspectJobActionArray{
					&dataloss.PreventionJobTriggerInspectJobActionArgs{
						SaveFindings: &dataloss.PreventionJobTriggerInspectJobActionSaveFindingsArgs{
							OutputConfig: &dataloss.PreventionJobTriggerInspectJobActionSaveFindingsOutputConfigArgs{
								Table: &dataloss.PreventionJobTriggerInspectJobActionSaveFindingsOutputConfigTableArgs{
									ProjectId: pulumi.String("project"),
									DatasetId: pulumi.String("dataset"),
								},
							},
						},
					},
				},
				StorageConfig: &dataloss.PreventionJobTriggerInspectJobStorageConfigArgs{
					BigQueryOptions: &dataloss.PreventionJobTriggerInspectJobStorageConfigBigQueryOptionsArgs{
						TableReference: &dataloss.PreventionJobTriggerInspectJobStorageConfigBigQueryOptionsTableReferenceArgs{
							ProjectId: pulumi.String("project"),
							DatasetId: pulumi.String("dataset"),
							TableId:   pulumi.String("table_to_scan"),
						},
						RowsLimit:    pulumi.Int(1000),
						SampleMethod: pulumi.String("RANDOM_START"),
					},
				},
			},
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.dataloss.PreventionJobTrigger;
import com.pulumi.gcp.dataloss.PreventionJobTriggerArgs;
import com.pulumi.gcp.dataloss.inputs.PreventionJobTriggerTriggerArgs;
import com.pulumi.gcp.dataloss.inputs.PreventionJobTriggerTriggerScheduleArgs;
import com.pulumi.gcp.dataloss.inputs.PreventionJobTriggerInspectJobArgs;
import com.pulumi.gcp.dataloss.inputs.PreventionJobTriggerInspectJobStorageConfigArgs;
import com.pulumi.gcp.dataloss.inputs.PreventionJobTriggerInspectJobStorageConfigBigQueryOptionsArgs;
import com.pulumi.gcp.dataloss.inputs.PreventionJobTriggerInspectJobStorageConfigBigQueryOptionsTableReferenceArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        var bigqueryRowLimit = new PreventionJobTrigger("bigqueryRowLimit", PreventionJobTriggerArgs.builder()
            .parent("projects/my-project-name")
            .description("Description")
            .displayName("Displayname")
            .triggers(PreventionJobTriggerTriggerArgs.builder()
                .schedule(PreventionJobTriggerTriggerScheduleArgs.builder()
                    .recurrencePeriodDuration("86400s")
                    .build())
                .build())
            .inspectJob(PreventionJobTriggerInspectJobArgs.builder()
                .inspectTemplateName("fake")
                .actions(PreventionJobTriggerInspectJobActionArgs.builder()
                    .saveFindings(PreventionJobTriggerInspectJobActionSaveFindingsArgs.builder()
                        .outputConfig(PreventionJobTriggerInspectJobActionSaveFindingsOutputConfigArgs.builder()
                            .table(PreventionJobTriggerInspectJobActionSaveFindingsOutputConfigTableArgs.builder()
                                .projectId("project")
                                .datasetId("dataset")
                                .build())
                            .build())
                        .build())
                    .build())
                .storageConfig(PreventionJobTriggerInspectJobStorageConfigArgs.builder()
                    .bigQueryOptions(PreventionJobTriggerInspectJobStorageConfigBigQueryOptionsArgs.builder()
                        .tableReference(PreventionJobTriggerInspectJobStorageConfigBigQueryOptionsTableReferenceArgs.builder()
                            .projectId("project")
                            .datasetId("dataset")
                            .tableId("table_to_scan")
                            .build())
                        .rowsLimit(1000)
                        .sampleMethod("RANDOM_START")
                        .build())
                    .build())
                .build())
            .build());

    }
}
```
```yaml
resources:
  bigqueryRowLimit:
    type: gcp:dataloss:PreventionJobTrigger
    name: bigquery_row_limit
    properties:
      parent: projects/my-project-name
      description: Description
      displayName: Displayname
      triggers:
        - schedule:
            recurrencePeriodDuration: 86400s
      inspectJob:
        inspectTemplateName: fake
        actions:
          - saveFindings:
              outputConfig:
                table:
                  projectId: project
                  datasetId: dataset
        storageConfig:
          bigQueryOptions:
            tableReference:
              projectId: project
              datasetId: dataset
              tableId: table_to_scan
            rowsLimit: 1000
            sampleMethod: RANDOM_START
```
<!--End PulumiCodeChooser -->
### Dlp Job Trigger Bigquery Row Limit Percentage


<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const bigqueryRowLimitPercentage = new gcp.dataloss.PreventionJobTrigger("bigquery_row_limit_percentage", {
    parent: "projects/my-project-name",
    description: "Description",
    displayName: "Displayname",
    triggers: [{
        schedule: {
            recurrencePeriodDuration: "86400s",
        },
    }],
    inspectJob: {
        inspectTemplateName: "fake",
        actions: [{
            saveFindings: {
                outputConfig: {
                    table: {
                        projectId: "project",
                        datasetId: "dataset",
                    },
                },
            },
        }],
        storageConfig: {
            bigQueryOptions: {
                tableReference: {
                    projectId: "project",
                    datasetId: "dataset",
                    tableId: "table_to_scan",
                },
                rowsLimitPercent: 50,
                sampleMethod: "RANDOM_START",
            },
        },
    },
});
```
```python
import pulumi
import pulumi_gcp as gcp

bigquery_row_limit_percentage = gcp.dataloss.PreventionJobTrigger("bigquery_row_limit_percentage",
    parent="projects/my-project-name",
    description="Description",
    display_name="Displayname",
    triggers=[{
        "schedule": {
            "recurrence_period_duration": "86400s",
        },
    }],
    inspect_job={
        "inspect_template_name": "fake",
        "actions": [{
            "save_findings": {
                "output_config": {
                    "table": {
                        "project_id": "project",
                        "dataset_id": "dataset",
                    },
                },
            },
        }],
        "storage_config": {
            "big_query_options": {
                "table_reference": {
                    "project_id": "project",
                    "dataset_id": "dataset",
                    "table_id": "table_to_scan",
                },
                "rows_limit_percent": 50,
                "sample_method": "RANDOM_START",
            },
        },
    })
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var bigqueryRowLimitPercentage = new Gcp.DataLoss.PreventionJobTrigger("bigquery_row_limit_percentage", new()
    {
        Parent = "projects/my-project-name",
        Description = "Description",
        DisplayName = "Displayname",
        Triggers = new[]
        {
            new Gcp.DataLoss.Inputs.PreventionJobTriggerTriggerArgs
            {
                Schedule = new Gcp.DataLoss.Inputs.PreventionJobTriggerTriggerScheduleArgs
                {
                    RecurrencePeriodDuration = "86400s",
                },
            },
        },
        InspectJob = new Gcp.DataLoss.Inputs.PreventionJobTriggerInspectJobArgs
        {
            InspectTemplateName = "fake",
            Actions = new[]
            {
                new Gcp.DataLoss.Inputs.PreventionJobTriggerInspectJobActionArgs
                {
                    SaveFindings = new Gcp.DataLoss.Inputs.PreventionJobTriggerInspectJobActionSaveFindingsArgs
                    {
                        OutputConfig = new Gcp.DataLoss.Inputs.PreventionJobTriggerInspectJobActionSaveFindingsOutputConfigArgs
                        {
                            Table = new Gcp.DataLoss.Inputs.PreventionJobTriggerInspectJobActionSaveFindingsOutputConfigTableArgs
                            {
                                ProjectId = "project",
                                DatasetId = "dataset",
                            },
                        },
                    },
                },
            },
            StorageConfig = new Gcp.DataLoss.Inputs.PreventionJobTriggerInspectJobStorageConfigArgs
            {
                BigQueryOptions = new Gcp.DataLoss.Inputs.PreventionJobTriggerInspectJobStorageConfigBigQueryOptionsArgs
                {
                    TableReference = new Gcp.DataLoss.Inputs.PreventionJobTriggerInspectJobStorageConfigBigQueryOptionsTableReferenceArgs
                    {
                        ProjectId = "project",
                        DatasetId = "dataset",
                        TableId = "table_to_scan",
                    },
                    RowsLimitPercent = 50,
                    SampleMethod = "RANDOM_START",
                },
            },
        },
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/dataloss"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		_, err := dataloss.NewPreventionJobTrigger(ctx, "bigquery_row_limit_percentage", &dataloss.PreventionJobTriggerArgs{
			Parent:      pulumi.String("projects/my-project-name"),
			Description: pulumi.String("Description"),
			DisplayName: pulumi.String("Displayname"),
			Triggers: dataloss.PreventionJobTriggerTriggerArray{
				&dataloss.PreventionJobTriggerTriggerArgs{
					Schedule: &dataloss.PreventionJobTriggerTriggerScheduleArgs{
						RecurrencePeriodDuration: pulumi.String("86400s"),
					},
				},
			},
			InspectJob: &dataloss.PreventionJobTriggerInspectJobArgs{
				InspectTemplateName: pulumi.String("fake"),
				Actions: dataloss.PreventionJobTriggerInspectJobActionArray{
					&dataloss.PreventionJobTriggerInspectJobActionArgs{
						SaveFindings: &dataloss.PreventionJobTriggerInspectJobActionSaveFindingsArgs{
							OutputConfig: &dataloss.PreventionJobTriggerInspectJobActionSaveFindingsOutputConfigArgs{
								Table: &dataloss.PreventionJobTriggerInspectJobActionSaveFindingsOutputConfigTableArgs{
									ProjectId: pulumi.String("project"),
									DatasetId: pulumi.String("dataset"),
								},
							},
						},
					},
				},
				StorageConfig: &dataloss.PreventionJobTriggerInspectJobStorageConfigArgs{
					BigQueryOptions: &dataloss.PreventionJobTriggerInspectJobStorageConfigBigQueryOptionsArgs{
						TableReference: &dataloss.PreventionJobTriggerInspectJobStorageConfigBigQueryOptionsTableReferenceArgs{
							ProjectId: pulumi.String("project"),
							DatasetId: pulumi.String("dataset"),
							TableId:   pulumi.String("table_to_scan"),
						},
						RowsLimitPercent: pulumi.Int(50),
						SampleMethod:     pulumi.String("RANDOM_START"),
					},
				},
			},
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.dataloss.PreventionJobTrigger;
import com.pulumi.gcp.dataloss.PreventionJobTriggerArgs;
import com.pulumi.gcp.dataloss.inputs.PreventionJobTriggerTriggerArgs;
import com.pulumi.gcp.dataloss.inputs.PreventionJobTriggerTriggerScheduleArgs;
import com.pulumi.gcp.dataloss.inputs.PreventionJobTriggerInspectJobArgs;
import com.pulumi.gcp.dataloss.inputs.PreventionJobTriggerInspectJobStorageConfigArgs;
import com.pulumi.gcp.dataloss.inputs.PreventionJobTriggerInspectJobStorageConfigBigQueryOptionsArgs;
import com.pulumi.gcp.dataloss.inputs.PreventionJobTriggerInspectJobStorageConfigBigQueryOptionsTableReferenceArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        var bigqueryRowLimitPercentage = new PreventionJobTrigger("bigqueryRowLimitPercentage", PreventionJobTriggerArgs.builder()
            .parent("projects/my-project-name")
            .description("Description")
            .displayName("Displayname")
            .triggers(PreventionJobTriggerTriggerArgs.builder()
                .schedule(PreventionJobTriggerTriggerScheduleArgs.builder()
                    .recurrencePeriodDuration("86400s")
                    .build())
                .build())
            .inspectJob(PreventionJobTriggerInspectJobArgs.builder()
                .inspectTemplateName("fake")
                .actions(PreventionJobTriggerInspectJobActionArgs.builder()
                    .saveFindings(PreventionJobTriggerInspectJobActionSaveFindingsArgs.builder()
                        .outputConfig(PreventionJobTriggerInspectJobActionSaveFindingsOutputConfigArgs.builder()
                            .table(PreventionJobTriggerInspectJobActionSaveFindingsOutputConfigTableArgs.builder()
                                .projectId("project")
                                .datasetId("dataset")
                                .build())
                            .build())
                        .build())
                    .build())
                .storageConfig(PreventionJobTriggerInspectJobStorageConfigArgs.builder()
                    .bigQueryOptions(PreventionJobTriggerInspectJobStorageConfigBigQueryOptionsArgs.builder()
                        .tableReference(PreventionJobTriggerInspectJobStorageConfigBigQueryOptionsTableReferenceArgs.builder()
                            .projectId("project")
                            .datasetId("dataset")
                            .tableId("table_to_scan")
                            .build())
                        .rowsLimitPercent(50)
                        .sampleMethod("RANDOM_START")
                        .build())
                    .build())
                .build())
            .build());

    }
}
```
```yaml
resources:
  bigqueryRowLimitPercentage:
    type: gcp:dataloss:PreventionJobTrigger
    name: bigquery_row_limit_percentage
    properties:
      parent: projects/my-project-name
      description: Description
      displayName: Displayname
      triggers:
        - schedule:
            recurrencePeriodDuration: 86400s
      inspectJob:
        inspectTemplateName: fake
        actions:
          - saveFindings:
              outputConfig:
                table:
                  projectId: project
                  datasetId: dataset
        storageConfig:
          bigQueryOptions:
            tableReference:
              projectId: project
              datasetId: dataset
              tableId: table_to_scan
            rowsLimitPercent: 50
            sampleMethod: RANDOM_START
```
<!--End PulumiCodeChooser -->
### Dlp Job Trigger Job Notification Emails


<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const jobNotificationEmails = new gcp.dataloss.PreventionJobTrigger("job_notification_emails", {
    parent: "projects/my-project-name",
    description: "Description for the job_trigger created by terraform",
    displayName: "TerraformDisplayName",
    triggers: [{
        schedule: {
            recurrencePeriodDuration: "86400s",
        },
    }],
    inspectJob: {
        inspectTemplateName: "sample-inspect-template",
        actions: [{
            jobNotificationEmails: {},
        }],
        storageConfig: {
            cloudStorageOptions: {
                fileSet: {
                    url: "gs://mybucket/directory/",
                },
            },
        },
    },
});
```
```python
import pulumi
import pulumi_gcp as gcp

job_notification_emails = gcp.dataloss.PreventionJobTrigger("job_notification_emails",
    parent="projects/my-project-name",
    description="Description for the job_trigger created by terraform",
    display_name="TerraformDisplayName",
    triggers=[{
        "schedule": {
            "recurrence_period_duration": "86400s",
        },
    }],
    inspect_job={
        "inspect_template_name": "sample-inspect-template",
        "actions": [{
            "job_notification_emails": {},
        }],
        "storage_config": {
            "cloud_storage_options": {
                "file_set": {
                    "url": "gs://mybucket/directory/",
                },
            },
        },
    })
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var jobNotificationEmails = new Gcp.DataLoss.PreventionJobTrigger("job_notification_emails", new()
    {
        Parent = "projects/my-project-name",
        Description = "Description for the job_trigger created by terraform",
        DisplayName = "TerraformDisplayName",
        Triggers = new[]
        {
            new Gcp.DataLoss.Inputs.PreventionJobTriggerTriggerArgs
            {
                Schedule = new Gcp.DataLoss.Inputs.PreventionJobTriggerTriggerScheduleArgs
                {
                    RecurrencePeriodDuration = "86400s",
                },
            },
        },
        InspectJob = new Gcp.DataLoss.Inputs.PreventionJobTriggerInspectJobArgs
        {
            InspectTemplateName = "sample-inspect-template",
            Actions = new[]
            {
                new Gcp.DataLoss.Inputs.PreventionJobTriggerInspectJobActionArgs
                {
                    JobNotificationEmails = null,
                },
            },
            StorageConfig = new Gcp.DataLoss.Inputs.PreventionJobTriggerInspectJobStorageConfigArgs
            {
                CloudStorageOptions = new Gcp.DataLoss.Inputs.PreventionJobTriggerInspectJobStorageConfigCloudStorageOptionsArgs
                {
                    FileSet = new Gcp.DataLoss.Inputs.PreventionJobTriggerInspectJobStorageConfigCloudStorageOptionsFileSetArgs
                    {
                        Url = "gs://mybucket/directory/",
                    },
                },
            },
        },
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/dataloss"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		_, err := dataloss.NewPreventionJobTrigger(ctx, "job_notification_emails", &dataloss.PreventionJobTriggerArgs{
			Parent:      pulumi.String("projects/my-project-name"),
			Description: pulumi.String("Description for the job_trigger created by terraform"),
			DisplayName: pulumi.String("TerraformDisplayName"),
			Triggers: dataloss.PreventionJobTriggerTriggerArray{
				&dataloss.PreventionJobTriggerTriggerArgs{
					Schedule: &dataloss.PreventionJobTriggerTriggerScheduleArgs{
						RecurrencePeriodDuration: pulumi.String("86400s"),
					},
				},
			},
			InspectJob: &dataloss.PreventionJobTriggerInspectJobArgs{
				InspectTemplateName: pulumi.String("sample-inspect-template"),
				Actions: dataloss.PreventionJobTriggerInspectJobActionArray{
					&dataloss.PreventionJobTriggerInspectJobActionArgs{
						JobNotificationEmails: &dataloss.PreventionJobTriggerInspectJobActionJobNotificationEmailsArgs{},
					},
				},
				StorageConfig: &dataloss.PreventionJobTriggerInspectJobStorageConfigArgs{
					CloudStorageOptions: &dataloss.PreventionJobTriggerInspectJobStorageConfigCloudStorageOptionsArgs{
						FileSet: &dataloss.PreventionJobTriggerInspectJobStorageConfigCloudStorageOptionsFileSetArgs{
							Url: pulumi.String("gs://mybucket/directory/"),
						},
					},
				},
			},
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.dataloss.PreventionJobTrigger;
import com.pulumi.gcp.dataloss.PreventionJobTriggerArgs;
import com.pulumi.gcp.dataloss.inputs.PreventionJobTriggerTriggerArgs;
import com.pulumi.gcp.dataloss.inputs.PreventionJobTriggerTriggerScheduleArgs;
import com.pulumi.gcp.dataloss.inputs.PreventionJobTriggerInspectJobArgs;
import com.pulumi.gcp.dataloss.inputs.PreventionJobTriggerInspectJobStorageConfigArgs;
import com.pulumi.gcp.dataloss.inputs.PreventionJobTriggerInspectJobStorageConfigCloudStorageOptionsArgs;
import com.pulumi.gcp.dataloss.inputs.PreventionJobTriggerInspectJobStorageConfigCloudStorageOptionsFileSetArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        var jobNotificationEmails = new PreventionJobTrigger("jobNotificationEmails", PreventionJobTriggerArgs.builder()
            .parent("projects/my-project-name")
            .description("Description for the job_trigger created by terraform")
            .displayName("TerraformDisplayName")
            .triggers(PreventionJobTriggerTriggerArgs.builder()
                .schedule(PreventionJobTriggerTriggerScheduleArgs.builder()
                    .recurrencePeriodDuration("86400s")
                    .build())
                .build())
            .inspectJob(PreventionJobTriggerInspectJobArgs.builder()
                .inspectTemplateName("sample-inspect-template")
                .actions(PreventionJobTriggerInspectJobActionArgs.builder()
                    .jobNotificationEmails()
                    .build())
                .storageConfig(PreventionJobTriggerInspectJobStorageConfigArgs.builder()
                    .cloudStorageOptions(PreventionJobTriggerInspectJobStorageConfigCloudStorageOptionsArgs.builder()
                        .fileSet(PreventionJobTriggerInspectJobStorageConfigCloudStorageOptionsFileSetArgs.builder()
                            .url("gs://mybucket/directory/")
                            .build())
                        .build())
                    .build())
                .build())
            .build());

    }
}
```
```yaml
resources:
  jobNotificationEmails:
    type: gcp:dataloss:PreventionJobTrigger
    name: job_notification_emails
    properties:
      parent: projects/my-project-name
      description: Description for the job_trigger created by terraform
      displayName: TerraformDisplayName
      triggers:
        - schedule:
            recurrencePeriodDuration: 86400s
      inspectJob:
        inspectTemplateName: sample-inspect-template
        actions:
          - jobNotificationEmails: {}
        storageConfig:
          cloudStorageOptions:
            fileSet:
              url: gs://mybucket/directory/
```
<!--End PulumiCodeChooser -->
### Dlp Job Trigger Deidentify


<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const _default = new gcp.bigquery.Dataset("default", {
    datasetId: "tf_test",
    friendlyName: "terraform-test",
    description: "Description for the dataset created by terraform",
    location: "US",
    defaultTableExpirationMs: 3600000,
    labels: {
        env: "default",
    },
});
const defaultTable = new gcp.bigquery.Table("default", {
    datasetId: _default.datasetId,
    tableId: "tf_test",
    deletionProtection: false,
    timePartitioning: {
        type: "DAY",
    },
    labels: {
        env: "default",
    },
    schema: `    [
    {
      "name": "quantity",
      "type": "NUMERIC",
      "mode": "NULLABLE",
      "description": "The quantity"
    },
    {
      "name": "name",
      "type": "STRING",
      "mode": "NULLABLE",
      "description": "Name of the object"
    }
    ]
`,
});
const deidentify = new gcp.dataloss.PreventionJobTrigger("deidentify", {
    parent: "projects/my-project-name",
    description: "Description for the job_trigger created by terraform",
    displayName: "TerraformDisplayName",
    triggers: [{
        schedule: {
            recurrencePeriodDuration: "86400s",
        },
    }],
    inspectJob: {
        inspectTemplateName: "sample-inspect-template",
        actions: [{
            deidentify: {
                cloudStorageOutput: "gs://samplebucket/dir/",
                fileTypesToTransforms: [
                    "CSV",
                    "TSV",
                ],
                transformationDetailsStorageConfig: {
                    table: {
                        projectId: "my-project-name",
                        datasetId: _default.datasetId,
                        tableId: defaultTable.tableId,
                    },
                },
                transformationConfig: {
                    deidentifyTemplate: "sample-deidentify-template",
                    imageRedactTemplate: "sample-image-redact-template",
                    structuredDeidentifyTemplate: "sample-structured-deidentify-template",
                },
            },
        }],
        storageConfig: {
            cloudStorageOptions: {
                fileSet: {
                    url: "gs://mybucket/directory/",
                },
            },
        },
    },
});
```
```python
import pulumi
import pulumi_gcp as gcp

default = gcp.bigquery.Dataset("default",
    dataset_id="tf_test",
    friendly_name="terraform-test",
    description="Description for the dataset created by terraform",
    location="US",
    default_table_expiration_ms=3600000,
    labels={
        "env": "default",
    })
default_table = gcp.bigquery.Table("default",
    dataset_id=default.dataset_id,
    table_id="tf_test",
    deletion_protection=False,
    time_partitioning={
        "type": "DAY",
    },
    labels={
        "env": "default",
    },
    schema="""    [
    {
      "name": "quantity",
      "type": "NUMERIC",
      "mode": "NULLABLE",
      "description": "The quantity"
    },
    {
      "name": "name",
      "type": "STRING",
      "mode": "NULLABLE",
      "description": "Name of the object"
    }
    ]
""")
deidentify = gcp.dataloss.PreventionJobTrigger("deidentify",
    parent="projects/my-project-name",
    description="Description for the job_trigger created by terraform",
    display_name="TerraformDisplayName",
    triggers=[{
        "schedule": {
            "recurrence_period_duration": "86400s",
        },
    }],
    inspect_job={
        "inspect_template_name": "sample-inspect-template",
        "actions": [{
            "deidentify": {
                "cloud_storage_output": "gs://samplebucket/dir/",
                "file_types_to_transforms": [
                    "CSV",
                    "TSV",
                ],
                "transformation_details_storage_config": {
                    "table": {
                        "project_id": "my-project-name",
                        "dataset_id": default.dataset_id,
                        "table_id": default_table.table_id,
                    },
                },
                "transformation_config": {
                    "deidentify_template": "sample-deidentify-template",
                    "image_redact_template": "sample-image-redact-template",
                    "structured_deidentify_template": "sample-structured-deidentify-template",
                },
            },
        }],
        "storage_config": {
            "cloud_storage_options": {
                "file_set": {
                    "url": "gs://mybucket/directory/",
                },
            },
        },
    })
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var @default = new Gcp.BigQuery.Dataset("default", new()
    {
        DatasetId = "tf_test",
        FriendlyName = "terraform-test",
        Description = "Description for the dataset created by terraform",
        Location = "US",
        DefaultTableExpirationMs = 3600000,
        Labels = 
        {
            { "env", "default" },
        },
    });

    var defaultTable = new Gcp.BigQuery.Table("default", new()
    {
        DatasetId = @default.DatasetId,
        TableId = "tf_test",
        DeletionProtection = false,
        TimePartitioning = new Gcp.BigQuery.Inputs.TableTimePartitioningArgs
        {
            Type = "DAY",
        },
        Labels = 
        {
            { "env", "default" },
        },
        Schema = @"    [
    {
      ""name"": ""quantity"",
      ""type"": ""NUMERIC"",
      ""mode"": ""NULLABLE"",
      ""description"": ""The quantity""
    },
    {
      ""name"": ""name"",
      ""type"": ""STRING"",
      ""mode"": ""NULLABLE"",
      ""description"": ""Name of the object""
    }
    ]
",
    });

    var deidentify = new Gcp.DataLoss.PreventionJobTrigger("deidentify", new()
    {
        Parent = "projects/my-project-name",
        Description = "Description for the job_trigger created by terraform",
        DisplayName = "TerraformDisplayName",
        Triggers = new[]
        {
            new Gcp.DataLoss.Inputs.PreventionJobTriggerTriggerArgs
            {
                Schedule = new Gcp.DataLoss.Inputs.PreventionJobTriggerTriggerScheduleArgs
                {
                    RecurrencePeriodDuration = "86400s",
                },
            },
        },
        InspectJob = new Gcp.DataLoss.Inputs.PreventionJobTriggerInspectJobArgs
        {
            InspectTemplateName = "sample-inspect-template",
            Actions = new[]
            {
                new Gcp.DataLoss.Inputs.PreventionJobTriggerInspectJobActionArgs
                {
                    Deidentify = new Gcp.DataLoss.Inputs.PreventionJobTriggerInspectJobActionDeidentifyArgs
                    {
                        CloudStorageOutput = "gs://samplebucket/dir/",
                        FileTypesToTransforms = new[]
                        {
                            "CSV",
                            "TSV",
                        },
                        TransformationDetailsStorageConfig = new Gcp.DataLoss.Inputs.PreventionJobTriggerInspectJobActionDeidentifyTransformationDetailsStorageConfigArgs
                        {
                            Table = new Gcp.DataLoss.Inputs.PreventionJobTriggerInspectJobActionDeidentifyTransformationDetailsStorageConfigTableArgs
                            {
                                ProjectId = "my-project-name",
                                DatasetId = @default.DatasetId,
                                TableId = defaultTable.TableId,
                            },
                        },
                        TransformationConfig = new Gcp.DataLoss.Inputs.PreventionJobTriggerInspectJobActionDeidentifyTransformationConfigArgs
                        {
                            DeidentifyTemplate = "sample-deidentify-template",
                            ImageRedactTemplate = "sample-image-redact-template",
                            StructuredDeidentifyTemplate = "sample-structured-deidentify-template",
                        },
                    },
                },
            },
            StorageConfig = new Gcp.DataLoss.Inputs.PreventionJobTriggerInspectJobStorageConfigArgs
            {
                CloudStorageOptions = new Gcp.DataLoss.Inputs.PreventionJobTriggerInspectJobStorageConfigCloudStorageOptionsArgs
                {
                    FileSet = new Gcp.DataLoss.Inputs.PreventionJobTriggerInspectJobStorageConfigCloudStorageOptionsFileSetArgs
                    {
                        Url = "gs://mybucket/directory/",
                    },
                },
            },
        },
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/bigquery"
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/dataloss"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		_, err := bigquery.NewDataset(ctx, "default", &bigquery.DatasetArgs{
			DatasetId:                pulumi.String("tf_test"),
			FriendlyName:             pulumi.String("terraform-test"),
			Description:              pulumi.String("Description for the dataset created by terraform"),
			Location:                 pulumi.String("US"),
			DefaultTableExpirationMs: pulumi.Int(3600000),
			Labels: pulumi.StringMap{
				"env": pulumi.String("default"),
			},
		})
		if err != nil {
			return err
		}
		defaultTable, err := bigquery.NewTable(ctx, "default", &bigquery.TableArgs{
			DatasetId:          _default.DatasetId,
			TableId:            pulumi.String("tf_test"),
			DeletionProtection: pulumi.Bool(false),
			TimePartitioning: &bigquery.TableTimePartitioningArgs{
				Type: pulumi.String("DAY"),
			},
			Labels: pulumi.StringMap{
				"env": pulumi.String("default"),
			},
			Schema: pulumi.String(`    [
    {
      "name": "quantity",
      "type": "NUMERIC",
      "mode": "NULLABLE",
      "description": "The quantity"
    },
    {
      "name": "name",
      "type": "STRING",
      "mode": "NULLABLE",
      "description": "Name of the object"
    }
    ]
`),
		})
		if err != nil {
			return err
		}
		_, err = dataloss.NewPreventionJobTrigger(ctx, "deidentify", &dataloss.PreventionJobTriggerArgs{
			Parent:      pulumi.String("projects/my-project-name"),
			Description: pulumi.String("Description for the job_trigger created by terraform"),
			DisplayName: pulumi.String("TerraformDisplayName"),
			Triggers: dataloss.PreventionJobTriggerTriggerArray{
				&dataloss.PreventionJobTriggerTriggerArgs{
					Schedule: &dataloss.PreventionJobTriggerTriggerScheduleArgs{
						RecurrencePeriodDuration: pulumi.String("86400s"),
					},
				},
			},
			InspectJob: &dataloss.PreventionJobTriggerInspectJobArgs{
				InspectTemplateName: pulumi.String("sample-inspect-template"),
				Actions: dataloss.PreventionJobTriggerInspectJobActionArray{
					&dataloss.PreventionJobTriggerInspectJobActionArgs{
						Deidentify: &dataloss.PreventionJobTriggerInspectJobActionDeidentifyArgs{
							CloudStorageOutput: pulumi.String("gs://samplebucket/dir/"),
							FileTypesToTransforms: pulumi.StringArray{
								pulumi.String("CSV"),
								pulumi.String("TSV"),
							},
							TransformationDetailsStorageConfig: &dataloss.PreventionJobTriggerInspectJobActionDeidentifyTransformationDetailsStorageConfigArgs{
								Table: &dataloss.PreventionJobTriggerInspectJobActionDeidentifyTransformationDetailsStorageConfigTableArgs{
									ProjectId: pulumi.String("my-project-name"),
									DatasetId: _default.DatasetId,
									TableId:   defaultTable.TableId,
								},
							},
							TransformationConfig: &dataloss.PreventionJobTriggerInspectJobActionDeidentifyTransformationConfigArgs{
								DeidentifyTemplate:           pulumi.String("sample-deidentify-template"),
								ImageRedactTemplate:          pulumi.String("sample-image-redact-template"),
								StructuredDeidentifyTemplate: pulumi.String("sample-structured-deidentify-template"),
							},
						},
					},
				},
				StorageConfig: &dataloss.PreventionJobTriggerInspectJobStorageConfigArgs{
					CloudStorageOptions: &dataloss.PreventionJobTriggerInspectJobStorageConfigCloudStorageOptionsArgs{
						FileSet: &dataloss.PreventionJobTriggerInspectJobStorageConfigCloudStorageOptionsFileSetArgs{
							Url: pulumi.String("gs://mybucket/directory/"),
						},
					},
				},
			},
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.bigquery.Dataset;
import com.pulumi.gcp.bigquery.DatasetArgs;
import com.pulumi.gcp.bigquery.Table;
import com.pulumi.gcp.bigquery.TableArgs;
import com.pulumi.gcp.bigquery.inputs.TableTimePartitioningArgs;
import com.pulumi.gcp.dataloss.PreventionJobTrigger;
import com.pulumi.gcp.dataloss.PreventionJobTriggerArgs;
import com.pulumi.gcp.dataloss.inputs.PreventionJobTriggerTriggerArgs;
import com.pulumi.gcp.dataloss.inputs.PreventionJobTriggerTriggerScheduleArgs;
import com.pulumi.gcp.dataloss.inputs.PreventionJobTriggerInspectJobArgs;
import com.pulumi.gcp.dataloss.inputs.PreventionJobTriggerInspectJobStorageConfigArgs;
import com.pulumi.gcp.dataloss.inputs.PreventionJobTriggerInspectJobStorageConfigCloudStorageOptionsArgs;
import com.pulumi.gcp.dataloss.inputs.PreventionJobTriggerInspectJobStorageConfigCloudStorageOptionsFileSetArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        var default_ = new Dataset("default", DatasetArgs.builder()
            .datasetId("tf_test")
            .friendlyName("terraform-test")
            .description("Description for the dataset created by terraform")
            .location("US")
            .defaultTableExpirationMs(3600000)
            .labels(Map.of("env", "default"))
            .build());

        var defaultTable = new Table("defaultTable", TableArgs.builder()
            .datasetId(default_.datasetId())
            .tableId("tf_test")
            .deletionProtection(false)
            .timePartitioning(TableTimePartitioningArgs.builder()
                .type("DAY")
                .build())
            .labels(Map.of("env", "default"))
            .schema("""
    [
    {
      "name": "quantity",
      "type": "NUMERIC",
      "mode": "NULLABLE",
      "description": "The quantity"
    },
    {
      "name": "name",
      "type": "STRING",
      "mode": "NULLABLE",
      "description": "Name of the object"
    }
    ]
            """)
            .build());

        var deidentify = new PreventionJobTrigger("deidentify", PreventionJobTriggerArgs.builder()
            .parent("projects/my-project-name")
            .description("Description for the job_trigger created by terraform")
            .displayName("TerraformDisplayName")
            .triggers(PreventionJobTriggerTriggerArgs.builder()
                .schedule(PreventionJobTriggerTriggerScheduleArgs.builder()
                    .recurrencePeriodDuration("86400s")
                    .build())
                .build())
            .inspectJob(PreventionJobTriggerInspectJobArgs.builder()
                .inspectTemplateName("sample-inspect-template")
                .actions(PreventionJobTriggerInspectJobActionArgs.builder()
                    .deidentify(PreventionJobTriggerInspectJobActionDeidentifyArgs.builder()
                        .cloudStorageOutput("gs://samplebucket/dir/")
                        .fileTypesToTransforms(                        
                            "CSV",
                            "TSV")
                        .transformationDetailsStorageConfig(PreventionJobTriggerInspectJobActionDeidentifyTransformationDetailsStorageConfigArgs.builder()
                            .table(PreventionJobTriggerInspectJobActionDeidentifyTransformationDetailsStorageConfigTableArgs.builder()
                                .projectId("my-project-name")
                                .datasetId(default_.datasetId())
                                .tableId(defaultTable.tableId())
                                .build())
                            .build())
                        .transformationConfig(PreventionJobTriggerInspectJobActionDeidentifyTransformationConfigArgs.builder()
                            .deidentifyTemplate("sample-deidentify-template")
                            .imageRedactTemplate("sample-image-redact-template")
                            .structuredDeidentifyTemplate("sample-structured-deidentify-template")
                            .build())
                        .build())
                    .build())
                .storageConfig(PreventionJobTriggerInspectJobStorageConfigArgs.builder()
                    .cloudStorageOptions(PreventionJobTriggerInspectJobStorageConfigCloudStorageOptionsArgs.builder()
                        .fileSet(PreventionJobTriggerInspectJobStorageConfigCloudStorageOptionsFileSetArgs.builder()
                            .url("gs://mybucket/directory/")
                            .build())
                        .build())
                    .build())
                .build())
            .build());

    }
}
```
```yaml
resources:
  deidentify:
    type: gcp:dataloss:PreventionJobTrigger
    properties:
      parent: projects/my-project-name
      description: Description for the job_trigger created by terraform
      displayName: TerraformDisplayName
      triggers:
        - schedule:
            recurrencePeriodDuration: 86400s
      inspectJob:
        inspectTemplateName: sample-inspect-template
        actions:
          - deidentify:
              cloudStorageOutput: gs://samplebucket/dir/
              fileTypesToTransforms:
                - CSV
                - TSV
              transformationDetailsStorageConfig:
                table:
                  projectId: my-project-name
                  datasetId: ${default.datasetId}
                  tableId: ${defaultTable.tableId}
              transformationConfig:
                deidentifyTemplate: sample-deidentify-template
                imageRedactTemplate: sample-image-redact-template
                structuredDeidentifyTemplate: sample-structured-deidentify-template
        storageConfig:
          cloudStorageOptions:
            fileSet:
              url: gs://mybucket/directory/
  default:
    type: gcp:bigquery:Dataset
    properties:
      datasetId: tf_test
      friendlyName: terraform-test
      description: Description for the dataset created by terraform
      location: US
      defaultTableExpirationMs: 3.6e+06
      labels:
        env: default
  defaultTable:
    type: gcp:bigquery:Table
    name: default
    properties:
      datasetId: ${default.datasetId}
      tableId: tf_test
      deletionProtection: false
      timePartitioning:
        type: DAY
      labels:
        env: default
      schema: |2
            [
            {
              "name": "quantity",
              "type": "NUMERIC",
              "mode": "NULLABLE",
              "description": "The quantity"
            },
            {
              "name": "name",
              "type": "STRING",
              "mode": "NULLABLE",
              "description": "Name of the object"
            }
            ]
```
<!--End PulumiCodeChooser -->
### Dlp Job Trigger Hybrid


<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const hybridTrigger = new gcp.dataloss.PreventionJobTrigger("hybrid_trigger", {
    parent: "projects/my-project-name",
    triggers: [{
        manual: {},
    }],
    inspectJob: {
        inspectTemplateName: "fake",
        actions: [{
            saveFindings: {
                outputConfig: {
                    table: {
                        projectId: "project",
                        datasetId: "dataset",
                    },
                },
            },
        }],
        storageConfig: {
            hybridOptions: {
                description: "Hybrid job trigger for data from the comments field of a table that contains customer appointment bookings",
                requiredFindingLabelKeys: ["appointment-bookings-comments"],
                labels: {
                    env: "prod",
                },
                tableOptions: {
                    identifyingFields: [{
                        name: "booking_id",
                    }],
                },
            },
        },
    },
});
```
```python
import pulumi
import pulumi_gcp as gcp

hybrid_trigger = gcp.dataloss.PreventionJobTrigger("hybrid_trigger",
    parent="projects/my-project-name",
    triggers=[{
        "manual": {},
    }],
    inspect_job={
        "inspect_template_name": "fake",
        "actions": [{
            "save_findings": {
                "output_config": {
                    "table": {
                        "project_id": "project",
                        "dataset_id": "dataset",
                    },
                },
            },
        }],
        "storage_config": {
            "hybrid_options": {
                "description": "Hybrid job trigger for data from the comments field of a table that contains customer appointment bookings",
                "required_finding_label_keys": ["appointment-bookings-comments"],
                "labels": {
                    "env": "prod",
                },
                "table_options": {
                    "identifying_fields": [{
                        "name": "booking_id",
                    }],
                },
            },
        },
    })
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var hybridTrigger = new Gcp.DataLoss.PreventionJobTrigger("hybrid_trigger", new()
    {
        Parent = "projects/my-project-name",
        Triggers = new[]
        {
            new Gcp.DataLoss.Inputs.PreventionJobTriggerTriggerArgs
            {
                Manual = null,
            },
        },
        InspectJob = new Gcp.DataLoss.Inputs.PreventionJobTriggerInspectJobArgs
        {
            InspectTemplateName = "fake",
            Actions = new[]
            {
                new Gcp.DataLoss.Inputs.PreventionJobTriggerInspectJobActionArgs
                {
                    SaveFindings = new Gcp.DataLoss.Inputs.PreventionJobTriggerInspectJobActionSaveFindingsArgs
                    {
                        OutputConfig = new Gcp.DataLoss.Inputs.PreventionJobTriggerInspectJobActionSaveFindingsOutputConfigArgs
                        {
                            Table = new Gcp.DataLoss.Inputs.PreventionJobTriggerInspectJobActionSaveFindingsOutputConfigTableArgs
                            {
                                ProjectId = "project",
                                DatasetId = "dataset",
                            },
                        },
                    },
                },
            },
            StorageConfig = new Gcp.DataLoss.Inputs.PreventionJobTriggerInspectJobStorageConfigArgs
            {
                HybridOptions = new Gcp.DataLoss.Inputs.PreventionJobTriggerInspectJobStorageConfigHybridOptionsArgs
                {
                    Description = "Hybrid job trigger for data from the comments field of a table that contains customer appointment bookings",
                    RequiredFindingLabelKeys = new[]
                    {
                        "appointment-bookings-comments",
                    },
                    Labels = 
                    {
                        { "env", "prod" },
                    },
                    TableOptions = new Gcp.DataLoss.Inputs.PreventionJobTriggerInspectJobStorageConfigHybridOptionsTableOptionsArgs
                    {
                        IdentifyingFields = new[]
                        {
                            new Gcp.DataLoss.Inputs.PreventionJobTriggerInspectJobStorageConfigHybridOptionsTableOptionsIdentifyingFieldArgs
                            {
                                Name = "booking_id",
                            },
                        },
                    },
                },
            },
        },
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/dataloss"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		_, err := dataloss.NewPreventionJobTrigger(ctx, "hybrid_trigger", &dataloss.PreventionJobTriggerArgs{
			Parent: pulumi.String("projects/my-project-name"),
			Triggers: dataloss.PreventionJobTriggerTriggerArray{
				&dataloss.PreventionJobTriggerTriggerArgs{
					Manual: &dataloss.PreventionJobTriggerTriggerManualArgs{},
				},
			},
			InspectJob: &dataloss.PreventionJobTriggerInspectJobArgs{
				InspectTemplateName: pulumi.String("fake"),
				Actions: dataloss.PreventionJobTriggerInspectJobActionArray{
					&dataloss.PreventionJobTriggerInspectJobActionArgs{
						SaveFindings: &dataloss.PreventionJobTriggerInspectJobActionSaveFindingsArgs{
							OutputConfig: &dataloss.PreventionJobTriggerInspectJobActionSaveFindingsOutputConfigArgs{
								Table: &dataloss.PreventionJobTriggerInspectJobActionSaveFindingsOutputConfigTableArgs{
									ProjectId: pulumi.String("project"),
									DatasetId: pulumi.String("dataset"),
								},
							},
						},
					},
				},
				StorageConfig: &dataloss.PreventionJobTriggerInspectJobStorageConfigArgs{
					HybridOptions: &dataloss.PreventionJobTriggerInspectJobStorageConfigHybridOptionsArgs{
						Description: pulumi.String("Hybrid job trigger for data from the comments field of a table that contains customer appointment bookings"),
						RequiredFindingLabelKeys: pulumi.StringArray{
							pulumi.String("appointment-bookings-comments"),
						},
						Labels: pulumi.StringMap{
							"env": pulumi.String("prod"),
						},
						TableOptions: &dataloss.PreventionJobTriggerInspectJobStorageConfigHybridOptionsTableOptionsArgs{
							IdentifyingFields: dataloss.PreventionJobTriggerInspectJobStorageConfigHybridOptionsTableOptionsIdentifyingFieldArray{
								&dataloss.PreventionJobTriggerInspectJobStorageConfigHybridOptionsTableOptionsIdentifyingFieldArgs{
									Name: pulumi.String("booking_id"),
								},
							},
						},
					},
				},
			},
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.dataloss.PreventionJobTrigger;
import com.pulumi.gcp.dataloss.PreventionJobTriggerArgs;
import com.pulumi.gcp.dataloss.inputs.PreventionJobTriggerTriggerArgs;
import com.pulumi.gcp.dataloss.inputs.PreventionJobTriggerTriggerManualArgs;
import com.pulumi.gcp.dataloss.inputs.PreventionJobTriggerInspectJobArgs;
import com.pulumi.gcp.dataloss.inputs.PreventionJobTriggerInspectJobStorageConfigArgs;
import com.pulumi.gcp.dataloss.inputs.PreventionJobTriggerInspectJobStorageConfigHybridOptionsArgs;
import com.pulumi.gcp.dataloss.inputs.PreventionJobTriggerInspectJobStorageConfigHybridOptionsTableOptionsArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        var hybridTrigger = new PreventionJobTrigger("hybridTrigger", PreventionJobTriggerArgs.builder()
            .parent("projects/my-project-name")
            .triggers(PreventionJobTriggerTriggerArgs.builder()
                .manual()
                .build())
            .inspectJob(PreventionJobTriggerInspectJobArgs.builder()
                .inspectTemplateName("fake")
                .actions(PreventionJobTriggerInspectJobActionArgs.builder()
                    .saveFindings(PreventionJobTriggerInspectJobActionSaveFindingsArgs.builder()
                        .outputConfig(PreventionJobTriggerInspectJobActionSaveFindingsOutputConfigArgs.builder()
                            .table(PreventionJobTriggerInspectJobActionSaveFindingsOutputConfigTableArgs.builder()
                                .projectId("project")
                                .datasetId("dataset")
                                .build())
                            .build())
                        .build())
                    .build())
                .storageConfig(PreventionJobTriggerInspectJobStorageConfigArgs.builder()
                    .hybridOptions(PreventionJobTriggerInspectJobStorageConfigHybridOptionsArgs.builder()
                        .description("Hybrid job trigger for data from the comments field of a table that contains customer appointment bookings")
                        .requiredFindingLabelKeys("appointment-bookings-comments")
                        .labels(Map.of("env", "prod"))
                        .tableOptions(PreventionJobTriggerInspectJobStorageConfigHybridOptionsTableOptionsArgs.builder()
                            .identifyingFields(PreventionJobTriggerInspectJobStorageConfigHybridOptionsTableOptionsIdentifyingFieldArgs.builder()
                                .name("booking_id")
                                .build())
                            .build())
                        .build())
                    .build())
                .build())
            .build());

    }
}
```
```yaml
resources:
  hybridTrigger:
    type: gcp:dataloss:PreventionJobTrigger
    name: hybrid_trigger
    properties:
      parent: projects/my-project-name
      triggers:
        - manual: {}
      inspectJob:
        inspectTemplateName: fake
        actions:
          - saveFindings:
              outputConfig:
                table:
                  projectId: project
                  datasetId: dataset
        storageConfig:
          hybridOptions:
            description: Hybrid job trigger for data from the comments field of a table that contains customer appointment bookings
            requiredFindingLabelKeys:
              - appointment-bookings-comments
            labels:
              env: prod
            tableOptions:
              identifyingFields:
                - name: booking_id
```
<!--End PulumiCodeChooser -->
### Dlp Job Trigger Inspect


<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const inspect = new gcp.dataloss.PreventionJobTrigger("inspect", {
    parent: "projects/my-project-name",
    description: "Description",
    displayName: "Displayname",
    triggers: [{
        schedule: {
            recurrencePeriodDuration: "86400s",
        },
    }],
    inspectJob: {
        inspectTemplateName: "fake",
        actions: [{
            saveFindings: {
                outputConfig: {
                    table: {
                        projectId: "project",
                        datasetId: "dataset",
                    },
                },
            },
        }],
        storageConfig: {
            cloudStorageOptions: {
                fileSet: {
                    url: "gs://mybucket/directory/",
                },
            },
        },
        inspectConfig: {
            customInfoTypes: [{
                infoType: {
                    name: "MY_CUSTOM_TYPE",
                },
                likelihood: "UNLIKELY",
                regex: {
                    pattern: "test*",
                },
            }],
            infoTypes: [{
                name: "EMAIL_ADDRESS",
            }],
            minLikelihood: "UNLIKELY",
            ruleSets: [
                {
                    infoTypes: [{
                        name: "EMAIL_ADDRESS",
                    }],
                    rules: [{
                        exclusionRule: {
                            regex: {
                                pattern: ".+@example.com",
                            },
                            matchingType: "MATCHING_TYPE_FULL_MATCH",
                        },
                    }],
                },
                {
                    infoTypes: [{
                        name: "MY_CUSTOM_TYPE",
                    }],
                    rules: [{
                        hotwordRule: {
                            hotwordRegex: {
                                pattern: "example*",
                            },
                            proximity: {
                                windowBefore: 50,
                            },
                            likelihoodAdjustment: {
                                fixedLikelihood: "VERY_LIKELY",
                            },
                        },
                    }],
                },
            ],
            limits: {
                maxFindingsPerItem: 10,
                maxFindingsPerRequest: 50,
            },
        },
    },
});
```
```python
import pulumi
import pulumi_gcp as gcp

inspect = gcp.dataloss.PreventionJobTrigger("inspect",
    parent="projects/my-project-name",
    description="Description",
    display_name="Displayname",
    triggers=[{
        "schedule": {
            "recurrence_period_duration": "86400s",
        },
    }],
    inspect_job={
        "inspect_template_name": "fake",
        "actions": [{
            "save_findings": {
                "output_config": {
                    "table": {
                        "project_id": "project",
                        "dataset_id": "dataset",
                    },
                },
            },
        }],
        "storage_config": {
            "cloud_storage_options": {
                "file_set": {
                    "url": "gs://mybucket/directory/",
                },
            },
        },
        "inspect_config": {
            "custom_info_types": [{
                "info_type": {
                    "name": "MY_CUSTOM_TYPE",
                },
                "likelihood": "UNLIKELY",
                "regex": {
                    "pattern": "test*",
                },
            }],
            "info_types": [{
                "name": "EMAIL_ADDRESS",
            }],
            "min_likelihood": "UNLIKELY",
            "rule_sets": [
                {
                    "info_types": [{
                        "name": "EMAIL_ADDRESS",
                    }],
                    "rules": [{
                        "exclusion_rule": {
                            "regex": {
                                "pattern": ".+@example.com",
                            },
                            "matching_type": "MATCHING_TYPE_FULL_MATCH",
                        },
                    }],
                },
                {
                    "info_types": [{
                        "name": "MY_CUSTOM_TYPE",
                    }],
                    "rules": [{
                        "hotword_rule": {
                            "hotword_regex": {
                                "pattern": "example*",
                            },
                            "proximity": {
                                "window_before": 50,
                            },
                            "likelihood_adjustment": {
                                "fixed_likelihood": "VERY_LIKELY",
                            },
                        },
                    }],
                },
            ],
            "limits": {
                "max_findings_per_item": 10,
                "max_findings_per_request": 50,
            },
        },
    })
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var inspect = new Gcp.DataLoss.PreventionJobTrigger("inspect", new()
    {
        Parent = "projects/my-project-name",
        Description = "Description",
        DisplayName = "Displayname",
        Triggers = new[]
        {
            new Gcp.DataLoss.Inputs.PreventionJobTriggerTriggerArgs
            {
                Schedule = new Gcp.DataLoss.Inputs.PreventionJobTriggerTriggerScheduleArgs
                {
                    RecurrencePeriodDuration = "86400s",
                },
            },
        },
        InspectJob = new Gcp.DataLoss.Inputs.PreventionJobTriggerInspectJobArgs
        {
            InspectTemplateName = "fake",
            Actions = new[]
            {
                new Gcp.DataLoss.Inputs.PreventionJobTriggerInspectJobActionArgs
                {
                    SaveFindings = new Gcp.DataLoss.Inputs.PreventionJobTriggerInspectJobActionSaveFindingsArgs
                    {
                        OutputConfig = new Gcp.DataLoss.Inputs.PreventionJobTriggerInspectJobActionSaveFindingsOutputConfigArgs
                        {
                            Table = new Gcp.DataLoss.Inputs.PreventionJobTriggerInspectJobActionSaveFindingsOutputConfigTableArgs
                            {
                                ProjectId = "project",
                                DatasetId = "dataset",
                            },
                        },
                    },
                },
            },
            StorageConfig = new Gcp.DataLoss.Inputs.PreventionJobTriggerInspectJobStorageConfigArgs
            {
                CloudStorageOptions = new Gcp.DataLoss.Inputs.PreventionJobTriggerInspectJobStorageConfigCloudStorageOptionsArgs
                {
                    FileSet = new Gcp.DataLoss.Inputs.PreventionJobTriggerInspectJobStorageConfigCloudStorageOptionsFileSetArgs
                    {
                        Url = "gs://mybucket/directory/",
                    },
                },
            },
            InspectConfig = new Gcp.DataLoss.Inputs.PreventionJobTriggerInspectJobInspectConfigArgs
            {
                CustomInfoTypes = new[]
                {
                    new Gcp.DataLoss.Inputs.PreventionJobTriggerInspectJobInspectConfigCustomInfoTypeArgs
                    {
                        InfoType = new Gcp.DataLoss.Inputs.PreventionJobTriggerInspectJobInspectConfigCustomInfoTypeInfoTypeArgs
                        {
                            Name = "MY_CUSTOM_TYPE",
                        },
                        Likelihood = "UNLIKELY",
                        Regex = new Gcp.DataLoss.Inputs.PreventionJobTriggerInspectJobInspectConfigCustomInfoTypeRegexArgs
                        {
                            Pattern = "test*",
                        },
                    },
                },
                InfoTypes = new[]
                {
                    new Gcp.DataLoss.Inputs.PreventionJobTriggerInspectJobInspectConfigInfoTypeArgs
                    {
                        Name = "EMAIL_ADDRESS",
                    },
                },
                MinLikelihood = "UNLIKELY",
                RuleSets = new[]
                {
                    new Gcp.DataLoss.Inputs.PreventionJobTriggerInspectJobInspectConfigRuleSetArgs
                    {
                        InfoTypes = new[]
                        {
                            new Gcp.DataLoss.Inputs.PreventionJobTriggerInspectJobInspectConfigRuleSetInfoTypeArgs
                            {
                                Name = "EMAIL_ADDRESS",
                            },
                        },
                        Rules = new[]
                        {
                            new Gcp.DataLoss.Inputs.PreventionJobTriggerInspectJobInspectConfigRuleSetRuleArgs
                            {
                                ExclusionRule = new Gcp.DataLoss.Inputs.PreventionJobTriggerInspectJobInspectConfigRuleSetRuleExclusionRuleArgs
                                {
                                    Regex = new Gcp.DataLoss.Inputs.PreventionJobTriggerInspectJobInspectConfigRuleSetRuleExclusionRuleRegexArgs
                                    {
                                        Pattern = ".+@example.com",
                                    },
                                    MatchingType = "MATCHING_TYPE_FULL_MATCH",
                                },
                            },
                        },
                    },
                    new Gcp.DataLoss.Inputs.PreventionJobTriggerInspectJobInspectConfigRuleSetArgs
                    {
                        InfoTypes = new[]
                        {
                            new Gcp.DataLoss.Inputs.PreventionJobTriggerInspectJobInspectConfigRuleSetInfoTypeArgs
                            {
                                Name = "MY_CUSTOM_TYPE",
                            },
                        },
                        Rules = new[]
                        {
                            new Gcp.DataLoss.Inputs.PreventionJobTriggerInspectJobInspectConfigRuleSetRuleArgs
                            {
                                HotwordRule = new Gcp.DataLoss.Inputs.PreventionJobTriggerInspectJobInspectConfigRuleSetRuleHotwordRuleArgs
                                {
                                    HotwordRegex = new Gcp.DataLoss.Inputs.PreventionJobTriggerInspectJobInspectConfigRuleSetRuleHotwordRuleHotwordRegexArgs
                                    {
                                        Pattern = "example*",
                                    },
                                    Proximity = new Gcp.DataLoss.Inputs.PreventionJobTriggerInspectJobInspectConfigRuleSetRuleHotwordRuleProximityArgs
                                    {
                                        WindowBefore = 50,
                                    },
                                    LikelihoodAdjustment = new Gcp.DataLoss.Inputs.PreventionJobTriggerInspectJobInspectConfigRuleSetRuleHotwordRuleLikelihoodAdjustmentArgs
                                    {
                                        FixedLikelihood = "VERY_LIKELY",
                                    },
                                },
                            },
                        },
                    },
                },
                Limits = new Gcp.DataLoss.Inputs.PreventionJobTriggerInspectJobInspectConfigLimitsArgs
                {
                    MaxFindingsPerItem = 10,
                    MaxFindingsPerRequest = 50,
                },
            },
        },
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/dataloss"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		_, err := dataloss.NewPreventionJobTrigger(ctx, "inspect", &dataloss.PreventionJobTriggerArgs{
			Parent:      pulumi.String("projects/my-project-name"),
			Description: pulumi.String("Description"),
			DisplayName: pulumi.String("Displayname"),
			Triggers: dataloss.PreventionJobTriggerTriggerArray{
				&dataloss.PreventionJobTriggerTriggerArgs{
					Schedule: &dataloss.PreventionJobTriggerTriggerScheduleArgs{
						RecurrencePeriodDuration: pulumi.String("86400s"),
					},
				},
			},
			InspectJob: &dataloss.PreventionJobTriggerInspectJobArgs{
				InspectTemplateName: pulumi.String("fake"),
				Actions: dataloss.PreventionJobTriggerInspectJobActionArray{
					&dataloss.PreventionJobTriggerInspectJobActionArgs{
						SaveFindings: &dataloss.PreventionJobTriggerInspectJobActionSaveFindingsArgs{
							OutputConfig: &dataloss.PreventionJobTriggerInspectJobActionSaveFindingsOutputConfigArgs{
								Table: &dataloss.PreventionJobTriggerInspectJobActionSaveFindingsOutputConfigTableArgs{
									ProjectId: pulumi.String("project"),
									DatasetId: pulumi.String("dataset"),
								},
							},
						},
					},
				},
				StorageConfig: &dataloss.PreventionJobTriggerInspectJobStorageConfigArgs{
					CloudStorageOptions: &dataloss.PreventionJobTriggerInspectJobStorageConfigCloudStorageOptionsArgs{
						FileSet: &dataloss.PreventionJobTriggerInspectJobStorageConfigCloudStorageOptionsFileSetArgs{
							Url: pulumi.String("gs://mybucket/directory/"),
						},
					},
				},
				InspectConfig: &dataloss.PreventionJobTriggerInspectJobInspectConfigArgs{
					CustomInfoTypes: dataloss.PreventionJobTriggerInspectJobInspectConfigCustomInfoTypeArray{
						&dataloss.PreventionJobTriggerInspectJobInspectConfigCustomInfoTypeArgs{
							InfoType: &dataloss.PreventionJobTriggerInspectJobInspectConfigCustomInfoTypeInfoTypeArgs{
								Name: pulumi.String("MY_CUSTOM_TYPE"),
							},
							Likelihood: pulumi.String("UNLIKELY"),
							Regex: &dataloss.PreventionJobTriggerInspectJobInspectConfigCustomInfoTypeRegexArgs{
								Pattern: pulumi.String("test*"),
							},
						},
					},
					InfoTypes: dataloss.PreventionJobTriggerInspectJobInspectConfigInfoTypeArray{
						&dataloss.PreventionJobTriggerInspectJobInspectConfigInfoTypeArgs{
							Name: pulumi.String("EMAIL_ADDRESS"),
						},
					},
					MinLikelihood: pulumi.String("UNLIKELY"),
					RuleSets: dataloss.PreventionJobTriggerInspectJobInspectConfigRuleSetArray{
						&dataloss.PreventionJobTriggerInspectJobInspectConfigRuleSetArgs{
							InfoTypes: dataloss.PreventionJobTriggerInspectJobInspectConfigRuleSetInfoTypeArray{
								&dataloss.PreventionJobTriggerInspectJobInspectConfigRuleSetInfoTypeArgs{
									Name: pulumi.String("EMAIL_ADDRESS"),
								},
							},
							Rules: dataloss.PreventionJobTriggerInspectJobInspectConfigRuleSetRuleArray{
								&dataloss.PreventionJobTriggerInspectJobInspectConfigRuleSetRuleArgs{
									ExclusionRule: &dataloss.PreventionJobTriggerInspectJobInspectConfigRuleSetRuleExclusionRuleArgs{
										Regex: &dataloss.PreventionJobTriggerInspectJobInspectConfigRuleSetRuleExclusionRuleRegexArgs{
											Pattern: pulumi.String(".+@example.com"),
										},
										MatchingType: pulumi.String("MATCHING_TYPE_FULL_MATCH"),
									},
								},
							},
						},
						&dataloss.PreventionJobTriggerInspectJobInspectConfigRuleSetArgs{
							InfoTypes: dataloss.PreventionJobTriggerInspectJobInspectConfigRuleSetInfoTypeArray{
								&dataloss.PreventionJobTriggerInspectJobInspectConfigRuleSetInfoTypeArgs{
									Name: pulumi.String("MY_CUSTOM_TYPE"),
								},
							},
							Rules: dataloss.PreventionJobTriggerInspectJobInspectConfigRuleSetRuleArray{
								&dataloss.PreventionJobTriggerInspectJobInspectConfigRuleSetRuleArgs{
									HotwordRule: &dataloss.PreventionJobTriggerInspectJobInspectConfigRuleSetRuleHotwordRuleArgs{
										HotwordRegex: &dataloss.PreventionJobTriggerInspectJobInspectConfigRuleSetRuleHotwordRuleHotwordRegexArgs{
											Pattern: pulumi.String("example*"),
										},
										Proximity: &dataloss.PreventionJobTriggerInspectJobInspectConfigRuleSetRuleHotwordRuleProximityArgs{
											WindowBefore: pulumi.Int(50),
										},
										LikelihoodAdjustment: &dataloss.PreventionJobTriggerInspectJobInspectConfigRuleSetRuleHotwordRuleLikelihoodAdjustmentArgs{
											FixedLikelihood: pulumi.String("VERY_LIKELY"),
										},
									},
								},
							},
						},
					},
					Limits: &dataloss.PreventionJobTriggerInspectJobInspectConfigLimitsArgs{
						MaxFindingsPerItem:    pulumi.Int(10),
						MaxFindingsPerRequest: pulumi.Int(50),
					},
				},
			},
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.dataloss.PreventionJobTrigger;
import com.pulumi.gcp.dataloss.PreventionJobTriggerArgs;
import com.pulumi.gcp.dataloss.inputs.PreventionJobTriggerTriggerArgs;
import com.pulumi.gcp.dataloss.inputs.PreventionJobTriggerTriggerScheduleArgs;
import com.pulumi.gcp.dataloss.inputs.PreventionJobTriggerInspectJobArgs;
import com.pulumi.gcp.dataloss.inputs.PreventionJobTriggerInspectJobStorageConfigArgs;
import com.pulumi.gcp.dataloss.inputs.PreventionJobTriggerInspectJobStorageConfigCloudStorageOptionsArgs;
import com.pulumi.gcp.dataloss.inputs.PreventionJobTriggerInspectJobStorageConfigCloudStorageOptionsFileSetArgs;
import com.pulumi.gcp.dataloss.inputs.PreventionJobTriggerInspectJobInspectConfigArgs;
import com.pulumi.gcp.dataloss.inputs.PreventionJobTriggerInspectJobInspectConfigLimitsArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        var inspect = new PreventionJobTrigger("inspect", PreventionJobTriggerArgs.builder()
            .parent("projects/my-project-name")
            .description("Description")
            .displayName("Displayname")
            .triggers(PreventionJobTriggerTriggerArgs.builder()
                .schedule(PreventionJobTriggerTriggerScheduleArgs.builder()
                    .recurrencePeriodDuration("86400s")
                    .build())
                .build())
            .inspectJob(PreventionJobTriggerInspectJobArgs.builder()
                .inspectTemplateName("fake")
                .actions(PreventionJobTriggerInspectJobActionArgs.builder()
                    .saveFindings(PreventionJobTriggerInspectJobActionSaveFindingsArgs.builder()
                        .outputConfig(PreventionJobTriggerInspectJobActionSaveFindingsOutputConfigArgs.builder()
                            .table(PreventionJobTriggerInspectJobActionSaveFindingsOutputConfigTableArgs.builder()
                                .projectId("project")
                                .datasetId("dataset")
                                .build())
                            .build())
                        .build())
                    .build())
                .storageConfig(PreventionJobTriggerInspectJobStorageConfigArgs.builder()
                    .cloudStorageOptions(PreventionJobTriggerInspectJobStorageConfigCloudStorageOptionsArgs.builder()
                        .fileSet(PreventionJobTriggerInspectJobStorageConfigCloudStorageOptionsFileSetArgs.builder()
                            .url("gs://mybucket/directory/")
                            .build())
                        .build())
                    .build())
                .inspectConfig(PreventionJobTriggerInspectJobInspectConfigArgs.builder()
                    .customInfoTypes(PreventionJobTriggerInspectJobInspectConfigCustomInfoTypeArgs.builder()
                        .infoType(PreventionJobTriggerInspectJobInspectConfigCustomInfoTypeInfoTypeArgs.builder()
                            .name("MY_CUSTOM_TYPE")
                            .build())
                        .likelihood("UNLIKELY")
                        .regex(PreventionJobTriggerInspectJobInspectConfigCustomInfoTypeRegexArgs.builder()
                            .pattern("test*")
                            .build())
                        .build())
                    .infoTypes(PreventionJobTriggerInspectJobInspectConfigInfoTypeArgs.builder()
                        .name("EMAIL_ADDRESS")
                        .build())
                    .minLikelihood("UNLIKELY")
                    .ruleSets(                    
                        PreventionJobTriggerInspectJobInspectConfigRuleSetArgs.builder()
                            .infoTypes(PreventionJobTriggerInspectJobInspectConfigRuleSetInfoTypeArgs.builder()
                                .name("EMAIL_ADDRESS")
                                .build())
                            .rules(PreventionJobTriggerInspectJobInspectConfigRuleSetRuleArgs.builder()
                                .exclusionRule(PreventionJobTriggerInspectJobInspectConfigRuleSetRuleExclusionRuleArgs.builder()
                                    .regex(PreventionJobTriggerInspectJobInspectConfigRuleSetRuleExclusionRuleRegexArgs.builder()
                                        .pattern(".+@example.com")
                                        .build())
                                    .matchingType("MATCHING_TYPE_FULL_MATCH")
                                    .build())
                                .build())
                            .build(),
                        PreventionJobTriggerInspectJobInspectConfigRuleSetArgs.builder()
                            .infoTypes(PreventionJobTriggerInspectJobInspectConfigRuleSetInfoTypeArgs.builder()
                                .name("MY_CUSTOM_TYPE")
                                .build())
                            .rules(PreventionJobTriggerInspectJobInspectConfigRuleSetRuleArgs.builder()
                                .hotwordRule(PreventionJobTriggerInspectJobInspectConfigRuleSetRuleHotwordRuleArgs.builder()
                                    .hotwordRegex(PreventionJobTriggerInspectJobInspectConfigRuleSetRuleHotwordRuleHotwordRegexArgs.builder()
                                        .pattern("example*")
                                        .build())
                                    .proximity(PreventionJobTriggerInspectJobInspectConfigRuleSetRuleHotwordRuleProximityArgs.builder()
                                        .windowBefore(50)
                                        .build())
                                    .likelihoodAdjustment(PreventionJobTriggerInspectJobInspectConfigRuleSetRuleHotwordRuleLikelihoodAdjustmentArgs.builder()
                                        .fixedLikelihood("VERY_LIKELY")
                                        .build())
                                    .build())
                                .build())
                            .build())
                    .limits(PreventionJobTriggerInspectJobInspectConfigLimitsArgs.builder()
                        .maxFindingsPerItem(10)
                        .maxFindingsPerRequest(50)
                        .build())
                    .build())
                .build())
            .build());

    }
}
```
```yaml
resources:
  inspect:
    type: gcp:dataloss:PreventionJobTrigger
    properties:
      parent: projects/my-project-name
      description: Description
      displayName: Displayname
      triggers:
        - schedule:
            recurrencePeriodDuration: 86400s
      inspectJob:
        inspectTemplateName: fake
        actions:
          - saveFindings:
              outputConfig:
                table:
                  projectId: project
                  datasetId: dataset
        storageConfig:
          cloudStorageOptions:
            fileSet:
              url: gs://mybucket/directory/
        inspectConfig:
          customInfoTypes:
            - infoType:
                name: MY_CUSTOM_TYPE
              likelihood: UNLIKELY
              regex:
                pattern: test*
          infoTypes:
            - name: EMAIL_ADDRESS
          minLikelihood: UNLIKELY
          ruleSets:
            - infoTypes:
                - name: EMAIL_ADDRESS
              rules:
                - exclusionRule:
                    regex:
                      pattern: .+@example.com
                    matchingType: MATCHING_TYPE_FULL_MATCH
            - infoTypes:
                - name: MY_CUSTOM_TYPE
              rules:
                - hotwordRule:
                    hotwordRegex:
                      pattern: example*
                    proximity:
                      windowBefore: 50
                    likelihoodAdjustment:
                      fixedLikelihood: VERY_LIKELY
          limits:
            maxFindingsPerItem: 10
            maxFindingsPerRequest: 50
```
<!--End PulumiCodeChooser -->
### Dlp Job Trigger Publish To Stackdriver


<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const publishToStackdriver = new gcp.dataloss.PreventionJobTrigger("publish_to_stackdriver", {
    parent: "projects/my-project-name",
    description: "Description for the job_trigger created by terraform",
    displayName: "TerraformDisplayName",
    triggers: [{
        schedule: {
            recurrencePeriodDuration: "86400s",
        },
    }],
    inspectJob: {
        inspectTemplateName: "sample-inspect-template",
        actions: [{
            publishToStackdriver: {},
        }],
        storageConfig: {
            cloudStorageOptions: {
                fileSet: {
                    url: "gs://mybucket/directory/",
                },
            },
        },
    },
});
```
```python
import pulumi
import pulumi_gcp as gcp

publish_to_stackdriver = gcp.dataloss.PreventionJobTrigger("publish_to_stackdriver",
    parent="projects/my-project-name",
    description="Description for the job_trigger created by terraform",
    display_name="TerraformDisplayName",
    triggers=[{
        "schedule": {
            "recurrence_period_duration": "86400s",
        },
    }],
    inspect_job={
        "inspect_template_name": "sample-inspect-template",
        "actions": [{
            "publish_to_stackdriver": {},
        }],
        "storage_config": {
            "cloud_storage_options": {
                "file_set": {
                    "url": "gs://mybucket/directory/",
                },
            },
        },
    })
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var publishToStackdriver = new Gcp.DataLoss.PreventionJobTrigger("publish_to_stackdriver", new()
    {
        Parent = "projects/my-project-name",
        Description = "Description for the job_trigger created by terraform",
        DisplayName = "TerraformDisplayName",
        Triggers = new[]
        {
            new Gcp.DataLoss.Inputs.PreventionJobTriggerTriggerArgs
            {
                Schedule = new Gcp.DataLoss.Inputs.PreventionJobTriggerTriggerScheduleArgs
                {
                    RecurrencePeriodDuration = "86400s",
                },
            },
        },
        InspectJob = new Gcp.DataLoss.Inputs.PreventionJobTriggerInspectJobArgs
        {
            InspectTemplateName = "sample-inspect-template",
            Actions = new[]
            {
                new Gcp.DataLoss.Inputs.PreventionJobTriggerInspectJobActionArgs
                {
                    PublishToStackdriver = null,
                },
            },
            StorageConfig = new Gcp.DataLoss.Inputs.PreventionJobTriggerInspectJobStorageConfigArgs
            {
                CloudStorageOptions = new Gcp.DataLoss.Inputs.PreventionJobTriggerInspectJobStorageConfigCloudStorageOptionsArgs
                {
                    FileSet = new Gcp.DataLoss.Inputs.PreventionJobTriggerInspectJobStorageConfigCloudStorageOptionsFileSetArgs
                    {
                        Url = "gs://mybucket/directory/",
                    },
                },
            },
        },
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/dataloss"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		_, err := dataloss.NewPreventionJobTrigger(ctx, "publish_to_stackdriver", &dataloss.PreventionJobTriggerArgs{
			Parent:      pulumi.String("projects/my-project-name"),
			Description: pulumi.String("Description for the job_trigger created by terraform"),
			DisplayName: pulumi.String("TerraformDisplayName"),
			Triggers: dataloss.PreventionJobTriggerTriggerArray{
				&dataloss.PreventionJobTriggerTriggerArgs{
					Schedule: &dataloss.PreventionJobTriggerTriggerScheduleArgs{
						RecurrencePeriodDuration: pulumi.String("86400s"),
					},
				},
			},
			InspectJob: &dataloss.PreventionJobTriggerInspectJobArgs{
				InspectTemplateName: pulumi.String("sample-inspect-template"),
				Actions: dataloss.PreventionJobTriggerInspectJobActionArray{
					&dataloss.PreventionJobTriggerInspectJobActionArgs{
						PublishToStackdriver: &dataloss.PreventionJobTriggerInspectJobActionPublishToStackdriverArgs{},
					},
				},
				StorageConfig: &dataloss.PreventionJobTriggerInspectJobStorageConfigArgs{
					CloudStorageOptions: &dataloss.PreventionJobTriggerInspectJobStorageConfigCloudStorageOptionsArgs{
						FileSet: &dataloss.PreventionJobTriggerInspectJobStorageConfigCloudStorageOptionsFileSetArgs{
							Url: pulumi.String("gs://mybucket/directory/"),
						},
					},
				},
			},
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.dataloss.PreventionJobTrigger;
import com.pulumi.gcp.dataloss.PreventionJobTriggerArgs;
import com.pulumi.gcp.dataloss.inputs.PreventionJobTriggerTriggerArgs;
import com.pulumi.gcp.dataloss.inputs.PreventionJobTriggerTriggerScheduleArgs;
import com.pulumi.gcp.dataloss.inputs.PreventionJobTriggerInspectJobArgs;
import com.pulumi.gcp.dataloss.inputs.PreventionJobTriggerInspectJobStorageConfigArgs;
import com.pulumi.gcp.dataloss.inputs.PreventionJobTriggerInspectJobStorageConfigCloudStorageOptionsArgs;
import com.pulumi.gcp.dataloss.inputs.PreventionJobTriggerInspectJobStorageConfigCloudStorageOptionsFileSetArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        var publishToStackdriver = new PreventionJobTrigger("publishToStackdriver", PreventionJobTriggerArgs.builder()
            .parent("projects/my-project-name")
            .description("Description for the job_trigger created by terraform")
            .displayName("TerraformDisplayName")
            .triggers(PreventionJobTriggerTriggerArgs.builder()
                .schedule(PreventionJobTriggerTriggerScheduleArgs.builder()
                    .recurrencePeriodDuration("86400s")
                    .build())
                .build())
            .inspectJob(PreventionJobTriggerInspectJobArgs.builder()
                .inspectTemplateName("sample-inspect-template")
                .actions(PreventionJobTriggerInspectJobActionArgs.builder()
                    .publishToStackdriver()
                    .build())
                .storageConfig(PreventionJobTriggerInspectJobStorageConfigArgs.builder()
                    .cloudStorageOptions(PreventionJobTriggerInspectJobStorageConfigCloudStorageOptionsArgs.builder()
                        .fileSet(PreventionJobTriggerInspectJobStorageConfigCloudStorageOptionsFileSetArgs.builder()
                            .url("gs://mybucket/directory/")
                            .build())
                        .build())
                    .build())
                .build())
            .build());

    }
}
```
```yaml
resources:
  publishToStackdriver:
    type: gcp:dataloss:PreventionJobTrigger
    name: publish_to_stackdriver
    properties:
      parent: projects/my-project-name
      description: Description for the job_trigger created by terraform
      displayName: TerraformDisplayName
      triggers:
        - schedule:
            recurrencePeriodDuration: 86400s
      inspectJob:
        inspectTemplateName: sample-inspect-template
        actions:
          - publishToStackdriver: {}
        storageConfig:
          cloudStorageOptions:
            fileSet:
              url: gs://mybucket/directory/
```
<!--End PulumiCodeChooser -->
### Dlp Job Trigger With Id


<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const withTriggerId = new gcp.dataloss.PreventionJobTrigger("with_trigger_id", {
    parent: "projects/my-project-name",
    description: "Starting description",
    displayName: "display",
    triggerId: "id-",
    triggers: [{
        schedule: {
            recurrencePeriodDuration: "86400s",
        },
    }],
    inspectJob: {
        inspectTemplateName: "fake",
        actions: [{
            saveFindings: {
                outputConfig: {
                    table: {
                        projectId: "project",
                        datasetId: "dataset123",
                    },
                },
            },
        }],
        storageConfig: {
            cloudStorageOptions: {
                fileSet: {
                    url: "gs://mybucket/directory/",
                },
            },
        },
    },
});
```
```python
import pulumi
import pulumi_gcp as gcp

with_trigger_id = gcp.dataloss.PreventionJobTrigger("with_trigger_id",
    parent="projects/my-project-name",
    description="Starting description",
    display_name="display",
    trigger_id="id-",
    triggers=[{
        "schedule": {
            "recurrence_period_duration": "86400s",
        },
    }],
    inspect_job={
        "inspect_template_name": "fake",
        "actions": [{
            "save_findings": {
                "output_config": {
                    "table": {
                        "project_id": "project",
                        "dataset_id": "dataset123",
                    },
                },
            },
        }],
        "storage_config": {
            "cloud_storage_options": {
                "file_set": {
                    "url": "gs://mybucket/directory/",
                },
            },
        },
    })
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var withTriggerId = new Gcp.DataLoss.PreventionJobTrigger("with_trigger_id", new()
    {
        Parent = "projects/my-project-name",
        Description = "Starting description",
        DisplayName = "display",
        TriggerId = "id-",
        Triggers = new[]
        {
            new Gcp.DataLoss.Inputs.PreventionJobTriggerTriggerArgs
            {
                Schedule = new Gcp.DataLoss.Inputs.PreventionJobTriggerTriggerScheduleArgs
                {
                    RecurrencePeriodDuration = "86400s",
                },
            },
        },
        InspectJob = new Gcp.DataLoss.Inputs.PreventionJobTriggerInspectJobArgs
        {
            InspectTemplateName = "fake",
            Actions = new[]
            {
                new Gcp.DataLoss.Inputs.PreventionJobTriggerInspectJobActionArgs
                {
                    SaveFindings = new Gcp.DataLoss.Inputs.PreventionJobTriggerInspectJobActionSaveFindingsArgs
                    {
                        OutputConfig = new Gcp.DataLoss.Inputs.PreventionJobTriggerInspectJobActionSaveFindingsOutputConfigArgs
                        {
                            Table = new Gcp.DataLoss.Inputs.PreventionJobTriggerInspectJobActionSaveFindingsOutputConfigTableArgs
                            {
                                ProjectId = "project",
                                DatasetId = "dataset123",
                            },
                        },
                    },
                },
            },
            StorageConfig = new Gcp.DataLoss.Inputs.PreventionJobTriggerInspectJobStorageConfigArgs
            {
                CloudStorageOptions = new Gcp.DataLoss.Inputs.PreventionJobTriggerInspectJobStorageConfigCloudStorageOptionsArgs
                {
                    FileSet = new Gcp.DataLoss.Inputs.PreventionJobTriggerInspectJobStorageConfigCloudStorageOptionsFileSetArgs
                    {
                        Url = "gs://mybucket/directory/",
                    },
                },
            },
        },
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/dataloss"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		_, err := dataloss.NewPreventionJobTrigger(ctx, "with_trigger_id", &dataloss.PreventionJobTriggerArgs{
			Parent:      pulumi.String("projects/my-project-name"),
			Description: pulumi.String("Starting description"),
			DisplayName: pulumi.String("display"),
			TriggerId:   pulumi.String("id-"),
			Triggers: dataloss.PreventionJobTriggerTriggerArray{
				&dataloss.PreventionJobTriggerTriggerArgs{
					Schedule: &dataloss.PreventionJobTriggerTriggerScheduleArgs{
						RecurrencePeriodDuration: pulumi.String("86400s"),
					},
				},
			},
			InspectJob: &dataloss.PreventionJobTriggerInspectJobArgs{
				InspectTemplateName: pulumi.String("fake"),
				Actions: dataloss.PreventionJobTriggerInspectJobActionArray{
					&dataloss.PreventionJobTriggerInspectJobActionArgs{
						SaveFindings: &dataloss.PreventionJobTriggerInspectJobActionSaveFindingsArgs{
							OutputConfig: &dataloss.PreventionJobTriggerInspectJobActionSaveFindingsOutputConfigArgs{
								Table: &dataloss.PreventionJobTriggerInspectJobActionSaveFindingsOutputConfigTableArgs{
									ProjectId: pulumi.String("project"),
									DatasetId: pulumi.String("dataset123"),
								},
							},
						},
					},
				},
				StorageConfig: &dataloss.PreventionJobTriggerInspectJobStorageConfigArgs{
					CloudStorageOptions: &dataloss.PreventionJobTriggerInspectJobStorageConfigCloudStorageOptionsArgs{
						FileSet: &dataloss.PreventionJobTriggerInspectJobStorageConfigCloudStorageOptionsFileSetArgs{
							Url: pulumi.String("gs://mybucket/directory/"),
						},
					},
				},
			},
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.dataloss.PreventionJobTrigger;
import com.pulumi.gcp.dataloss.PreventionJobTriggerArgs;
import com.pulumi.gcp.dataloss.inputs.PreventionJobTriggerTriggerArgs;
import com.pulumi.gcp.dataloss.inputs.PreventionJobTriggerTriggerScheduleArgs;
import com.pulumi.gcp.dataloss.inputs.PreventionJobTriggerInspectJobArgs;
import com.pulumi.gcp.dataloss.inputs.PreventionJobTriggerInspectJobStorageConfigArgs;
import com.pulumi.gcp.dataloss.inputs.PreventionJobTriggerInspectJobStorageConfigCloudStorageOptionsArgs;
import com.pulumi.gcp.dataloss.inputs.PreventionJobTriggerInspectJobStorageConfigCloudStorageOptionsFileSetArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        var withTriggerId = new PreventionJobTrigger("withTriggerId", PreventionJobTriggerArgs.builder()
            .parent("projects/my-project-name")
            .description("Starting description")
            .displayName("display")
            .triggerId("id-")
            .triggers(PreventionJobTriggerTriggerArgs.builder()
                .schedule(PreventionJobTriggerTriggerScheduleArgs.builder()
                    .recurrencePeriodDuration("86400s")
                    .build())
                .build())
            .inspectJob(PreventionJobTriggerInspectJobArgs.builder()
                .inspectTemplateName("fake")
                .actions(PreventionJobTriggerInspectJobActionArgs.builder()
                    .saveFindings(PreventionJobTriggerInspectJobActionSaveFindingsArgs.builder()
                        .outputConfig(PreventionJobTriggerInspectJobActionSaveFindingsOutputConfigArgs.builder()
                            .table(PreventionJobTriggerInspectJobActionSaveFindingsOutputConfigTableArgs.builder()
                                .projectId("project")
                                .datasetId("dataset123")
                                .build())
                            .build())
                        .build())
                    .build())
                .storageConfig(PreventionJobTriggerInspectJobStorageConfigArgs.builder()
                    .cloudStorageOptions(PreventionJobTriggerInspectJobStorageConfigCloudStorageOptionsArgs.builder()
                        .fileSet(PreventionJobTriggerInspectJobStorageConfigCloudStorageOptionsFileSetArgs.builder()
                            .url("gs://mybucket/directory/")
                            .build())
                        .build())
                    .build())
                .build())
            .build());

    }
}
```
```yaml
resources:
  withTriggerId:
    type: gcp:dataloss:PreventionJobTrigger
    name: with_trigger_id
    properties:
      parent: projects/my-project-name
      description: Starting description
      displayName: display
      triggerId: id-
      triggers:
        - schedule:
            recurrencePeriodDuration: 86400s
      inspectJob:
        inspectTemplateName: fake
        actions:
          - saveFindings:
              outputConfig:
                table:
                  projectId: project
                  datasetId: dataset123
        storageConfig:
          cloudStorageOptions:
            fileSet:
              url: gs://mybucket/directory/
```
<!--End PulumiCodeChooser -->
### Dlp Job Trigger Multiple Actions


<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const basic = new gcp.dataloss.PreventionJobTrigger("basic", {
    parent: "projects/my-project-name",
    description: "Description",
    displayName: "Displayname",
    triggers: [{
        schedule: {
            recurrencePeriodDuration: "86400s",
        },
    }],
    inspectJob: {
        inspectTemplateName: "fake",
        actions: [
            {
                saveFindings: {
                    outputConfig: {
                        table: {
                            projectId: "project",
                            datasetId: "dataset",
                        },
                    },
                },
            },
            {
                pubSub: {
                    topic: "projects/project/topics/topic-name",
                },
            },
        ],
        storageConfig: {
            cloudStorageOptions: {
                fileSet: {
                    url: "gs://mybucket/directory/",
                },
            },
        },
    },
});
```
```python
import pulumi
import pulumi_gcp as gcp

basic = gcp.dataloss.PreventionJobTrigger("basic",
    parent="projects/my-project-name",
    description="Description",
    display_name="Displayname",
    triggers=[{
        "schedule": {
            "recurrence_period_duration": "86400s",
        },
    }],
    inspect_job={
        "inspect_template_name": "fake",
        "actions": [
            {
                "save_findings": {
                    "output_config": {
                        "table": {
                            "project_id": "project",
                            "dataset_id": "dataset",
                        },
                    },
                },
            },
            {
                "pub_sub": {
                    "topic": "projects/project/topics/topic-name",
                },
            },
        ],
        "storage_config": {
            "cloud_storage_options": {
                "file_set": {
                    "url": "gs://mybucket/directory/",
                },
            },
        },
    })
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var basic = new Gcp.DataLoss.PreventionJobTrigger("basic", new()
    {
        Parent = "projects/my-project-name",
        Description = "Description",
        DisplayName = "Displayname",
        Triggers = new[]
        {
            new Gcp.DataLoss.Inputs.PreventionJobTriggerTriggerArgs
            {
                Schedule = new Gcp.DataLoss.Inputs.PreventionJobTriggerTriggerScheduleArgs
                {
                    RecurrencePeriodDuration = "86400s",
                },
            },
        },
        InspectJob = new Gcp.DataLoss.Inputs.PreventionJobTriggerInspectJobArgs
        {
            InspectTemplateName = "fake",
            Actions = new[]
            {
                new Gcp.DataLoss.Inputs.PreventionJobTriggerInspectJobActionArgs
                {
                    SaveFindings = new Gcp.DataLoss.Inputs.PreventionJobTriggerInspectJobActionSaveFindingsArgs
                    {
                        OutputConfig = new Gcp.DataLoss.Inputs.PreventionJobTriggerInspectJobActionSaveFindingsOutputConfigArgs
                        {
                            Table = new Gcp.DataLoss.Inputs.PreventionJobTriggerInspectJobActionSaveFindingsOutputConfigTableArgs
                            {
                                ProjectId = "project",
                                DatasetId = "dataset",
                            },
                        },
                    },
                },
                new Gcp.DataLoss.Inputs.PreventionJobTriggerInspectJobActionArgs
                {
                    PubSub = new Gcp.DataLoss.Inputs.PreventionJobTriggerInspectJobActionPubSubArgs
                    {
                        Topic = "projects/project/topics/topic-name",
                    },
                },
            },
            StorageConfig = new Gcp.DataLoss.Inputs.PreventionJobTriggerInspectJobStorageConfigArgs
            {
                CloudStorageOptions = new Gcp.DataLoss.Inputs.PreventionJobTriggerInspectJobStorageConfigCloudStorageOptionsArgs
                {
                    FileSet = new Gcp.DataLoss.Inputs.PreventionJobTriggerInspectJobStorageConfigCloudStorageOptionsFileSetArgs
                    {
                        Url = "gs://mybucket/directory/",
                    },
                },
            },
        },
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/dataloss"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		_, err := dataloss.NewPreventionJobTrigger(ctx, "basic", &dataloss.PreventionJobTriggerArgs{
			Parent:      pulumi.String("projects/my-project-name"),
			Description: pulumi.String("Description"),
			DisplayName: pulumi.String("Displayname"),
			Triggers: dataloss.PreventionJobTriggerTriggerArray{
				&dataloss.PreventionJobTriggerTriggerArgs{
					Schedule: &dataloss.PreventionJobTriggerTriggerScheduleArgs{
						RecurrencePeriodDuration: pulumi.String("86400s"),
					},
				},
			},
			InspectJob: &dataloss.PreventionJobTriggerInspectJobArgs{
				InspectTemplateName: pulumi.String("fake"),
				Actions: dataloss.PreventionJobTriggerInspectJobActionArray{
					&dataloss.PreventionJobTriggerInspectJobActionArgs{
						SaveFindings: &dataloss.PreventionJobTriggerInspectJobActionSaveFindingsArgs{
							OutputConfig: &dataloss.PreventionJobTriggerInspectJobActionSaveFindingsOutputConfigArgs{
								Table: &dataloss.PreventionJobTriggerInspectJobActionSaveFindingsOutputConfigTableArgs{
									ProjectId: pulumi.String("project"),
									DatasetId: pulumi.String("dataset"),
								},
							},
						},
					},
					&dataloss.PreventionJobTriggerInspectJobActionArgs{
						PubSub: &dataloss.PreventionJobTriggerInspectJobActionPubSubArgs{
							Topic: pulumi.String("projects/project/topics/topic-name"),
						},
					},
				},
				StorageConfig: &dataloss.PreventionJobTriggerInspectJobStorageConfigArgs{
					CloudStorageOptions: &dataloss.PreventionJobTriggerInspectJobStorageConfigCloudStorageOptionsArgs{
						FileSet: &dataloss.PreventionJobTriggerInspectJobStorageConfigCloudStorageOptionsFileSetArgs{
							Url: pulumi.String("gs://mybucket/directory/"),
						},
					},
				},
			},
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.dataloss.PreventionJobTrigger;
import com.pulumi.gcp.dataloss.PreventionJobTriggerArgs;
import com.pulumi.gcp.dataloss.inputs.PreventionJobTriggerTriggerArgs;
import com.pulumi.gcp.dataloss.inputs.PreventionJobTriggerTriggerScheduleArgs;
import com.pulumi.gcp.dataloss.inputs.PreventionJobTriggerInspectJobArgs;
import com.pulumi.gcp.dataloss.inputs.PreventionJobTriggerInspectJobStorageConfigArgs;
import com.pulumi.gcp.dataloss.inputs.PreventionJobTriggerInspectJobStorageConfigCloudStorageOptionsArgs;
import com.pulumi.gcp.dataloss.inputs.PreventionJobTriggerInspectJobStorageConfigCloudStorageOptionsFileSetArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        var basic = new PreventionJobTrigger("basic", PreventionJobTriggerArgs.builder()
            .parent("projects/my-project-name")
            .description("Description")
            .displayName("Displayname")
            .triggers(PreventionJobTriggerTriggerArgs.builder()
                .schedule(PreventionJobTriggerTriggerScheduleArgs.builder()
                    .recurrencePeriodDuration("86400s")
                    .build())
                .build())
            .inspectJob(PreventionJobTriggerInspectJobArgs.builder()
                .inspectTemplateName("fake")
                .actions(                
                    PreventionJobTriggerInspectJobActionArgs.builder()
                        .saveFindings(PreventionJobTriggerInspectJobActionSaveFindingsArgs.builder()
                            .outputConfig(PreventionJobTriggerInspectJobActionSaveFindingsOutputConfigArgs.builder()
                                .table(PreventionJobTriggerInspectJobActionSaveFindingsOutputConfigTableArgs.builder()
                                    .projectId("project")
                                    .datasetId("dataset")
                                    .build())
                                .build())
                            .build())
                        .build(),
                    PreventionJobTriggerInspectJobActionArgs.builder()
                        .pubSub(PreventionJobTriggerInspectJobActionPubSubArgs.builder()
                            .topic("projects/project/topics/topic-name")
                            .build())
                        .build())
                .storageConfig(PreventionJobTriggerInspectJobStorageConfigArgs.builder()
                    .cloudStorageOptions(PreventionJobTriggerInspectJobStorageConfigCloudStorageOptionsArgs.builder()
                        .fileSet(PreventionJobTriggerInspectJobStorageConfigCloudStorageOptionsFileSetArgs.builder()
                            .url("gs://mybucket/directory/")
                            .build())
                        .build())
                    .build())
                .build())
            .build());

    }
}
```
```yaml
resources:
  basic:
    type: gcp:dataloss:PreventionJobTrigger
    properties:
      parent: projects/my-project-name
      description: Description
      displayName: Displayname
      triggers:
        - schedule:
            recurrencePeriodDuration: 86400s
      inspectJob:
        inspectTemplateName: fake
        actions:
          - saveFindings:
              outputConfig:
                table:
                  projectId: project
                  datasetId: dataset
          - pubSub:
              topic: projects/project/topics/topic-name
        storageConfig:
          cloudStorageOptions:
            fileSet:
              url: gs://mybucket/directory/
```
<!--End PulumiCodeChooser -->
### Dlp Job Trigger Cloud Storage Optional Timespan Autopopulation


<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const basic = new gcp.dataloss.PreventionJobTrigger("basic", {
    parent: "projects/my-project-name",
    description: "Description",
    displayName: "Displayname",
    triggers: [{
        schedule: {
            recurrencePeriodDuration: "86400s",
        },
    }],
    inspectJob: {
        inspectTemplateName: "fake",
        actions: [{
            saveFindings: {
                outputConfig: {
                    table: {
                        projectId: "project",
                        datasetId: "dataset",
                    },
                },
            },
        }],
        storageConfig: {
            timespanConfig: {
                enableAutoPopulationOfTimespanConfig: true,
            },
            cloudStorageOptions: {
                fileSet: {
                    url: "gs://mybucket/directory/",
                },
            },
        },
    },
});
```
```python
import pulumi
import pulumi_gcp as gcp

basic = gcp.dataloss.PreventionJobTrigger("basic",
    parent="projects/my-project-name",
    description="Description",
    display_name="Displayname",
    triggers=[{
        "schedule": {
            "recurrence_period_duration": "86400s",
        },
    }],
    inspect_job={
        "inspect_template_name": "fake",
        "actions": [{
            "save_findings": {
                "output_config": {
                    "table": {
                        "project_id": "project",
                        "dataset_id": "dataset",
                    },
                },
            },
        }],
        "storage_config": {
            "timespan_config": {
                "enable_auto_population_of_timespan_config": True,
            },
            "cloud_storage_options": {
                "file_set": {
                    "url": "gs://mybucket/directory/",
                },
            },
        },
    })
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var basic = new Gcp.DataLoss.PreventionJobTrigger("basic", new()
    {
        Parent = "projects/my-project-name",
        Description = "Description",
        DisplayName = "Displayname",
        Triggers = new[]
        {
            new Gcp.DataLoss.Inputs.PreventionJobTriggerTriggerArgs
            {
                Schedule = new Gcp.DataLoss.Inputs.PreventionJobTriggerTriggerScheduleArgs
                {
                    RecurrencePeriodDuration = "86400s",
                },
            },
        },
        InspectJob = new Gcp.DataLoss.Inputs.PreventionJobTriggerInspectJobArgs
        {
            InspectTemplateName = "fake",
            Actions = new[]
            {
                new Gcp.DataLoss.Inputs.PreventionJobTriggerInspectJobActionArgs
                {
                    SaveFindings = new Gcp.DataLoss.Inputs.PreventionJobTriggerInspectJobActionSaveFindingsArgs
                    {
                        OutputConfig = new Gcp.DataLoss.Inputs.PreventionJobTriggerInspectJobActionSaveFindingsOutputConfigArgs
                        {
                            Table = new Gcp.DataLoss.Inputs.PreventionJobTriggerInspectJobActionSaveFindingsOutputConfigTableArgs
                            {
                                ProjectId = "project",
                                DatasetId = "dataset",
                            },
                        },
                    },
                },
            },
            StorageConfig = new Gcp.DataLoss.Inputs.PreventionJobTriggerInspectJobStorageConfigArgs
            {
                TimespanConfig = new Gcp.DataLoss.Inputs.PreventionJobTriggerInspectJobStorageConfigTimespanConfigArgs
                {
                    EnableAutoPopulationOfTimespanConfig = true,
                },
                CloudStorageOptions = new Gcp.DataLoss.Inputs.PreventionJobTriggerInspectJobStorageConfigCloudStorageOptionsArgs
                {
                    FileSet = new Gcp.DataLoss.Inputs.PreventionJobTriggerInspectJobStorageConfigCloudStorageOptionsFileSetArgs
                    {
                        Url = "gs://mybucket/directory/",
                    },
                },
            },
        },
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/dataloss"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		_, err := dataloss.NewPreventionJobTrigger(ctx, "basic", &dataloss.PreventionJobTriggerArgs{
			Parent:      pulumi.String("projects/my-project-name"),
			Description: pulumi.String("Description"),
			DisplayName: pulumi.String("Displayname"),
			Triggers: dataloss.PreventionJobTriggerTriggerArray{
				&dataloss.PreventionJobTriggerTriggerArgs{
					Schedule: &dataloss.PreventionJobTriggerTriggerScheduleArgs{
						RecurrencePeriodDuration: pulumi.String("86400s"),
					},
				},
			},
			InspectJob: &dataloss.PreventionJobTriggerInspectJobArgs{
				InspectTemplateName: pulumi.String("fake"),
				Actions: dataloss.PreventionJobTriggerInspectJobActionArray{
					&dataloss.PreventionJobTriggerInspectJobActionArgs{
						SaveFindings: &dataloss.PreventionJobTriggerInspectJobActionSaveFindingsArgs{
							OutputConfig: &dataloss.PreventionJobTriggerInspectJobActionSaveFindingsOutputConfigArgs{
								Table: &dataloss.PreventionJobTriggerInspectJobActionSaveFindingsOutputConfigTableArgs{
									ProjectId: pulumi.String("project"),
									DatasetId: pulumi.String("dataset"),
								},
							},
						},
					},
				},
				StorageConfig: &dataloss.PreventionJobTriggerInspectJobStorageConfigArgs{
					TimespanConfig: &dataloss.PreventionJobTriggerInspectJobStorageConfigTimespanConfigArgs{
						EnableAutoPopulationOfTimespanConfig: pulumi.Bool(true),
					},
					CloudStorageOptions: &dataloss.PreventionJobTriggerInspectJobStorageConfigCloudStorageOptionsArgs{
						FileSet: &dataloss.PreventionJobTriggerInspectJobStorageConfigCloudStorageOptionsFileSetArgs{
							Url: pulumi.String("gs://mybucket/directory/"),
						},
					},
				},
			},
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.dataloss.PreventionJobTrigger;
import com.pulumi.gcp.dataloss.PreventionJobTriggerArgs;
import com.pulumi.gcp.dataloss.inputs.PreventionJobTriggerTriggerArgs;
import com.pulumi.gcp.dataloss.inputs.PreventionJobTriggerTriggerScheduleArgs;
import com.pulumi.gcp.dataloss.inputs.PreventionJobTriggerInspectJobArgs;
import com.pulumi.gcp.dataloss.inputs.PreventionJobTriggerInspectJobStorageConfigArgs;
import com.pulumi.gcp.dataloss.inputs.PreventionJobTriggerInspectJobStorageConfigTimespanConfigArgs;
import com.pulumi.gcp.dataloss.inputs.PreventionJobTriggerInspectJobStorageConfigCloudStorageOptionsArgs;
import com.pulumi.gcp.dataloss.inputs.PreventionJobTriggerInspectJobStorageConfigCloudStorageOptionsFileSetArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        var basic = new PreventionJobTrigger("basic", PreventionJobTriggerArgs.builder()
            .parent("projects/my-project-name")
            .description("Description")
            .displayName("Displayname")
            .triggers(PreventionJobTriggerTriggerArgs.builder()
                .schedule(PreventionJobTriggerTriggerScheduleArgs.builder()
                    .recurrencePeriodDuration("86400s")
                    .build())
                .build())
            .inspectJob(PreventionJobTriggerInspectJobArgs.builder()
                .inspectTemplateName("fake")
                .actions(PreventionJobTriggerInspectJobActionArgs.builder()
                    .saveFindings(PreventionJobTriggerInspectJobActionSaveFindingsArgs.builder()
                        .outputConfig(PreventionJobTriggerInspectJobActionSaveFindingsOutputConfigArgs.builder()
                            .table(PreventionJobTriggerInspectJobActionSaveFindingsOutputConfigTableArgs.builder()
                                .projectId("project")
                                .datasetId("dataset")
                                .build())
                            .build())
                        .build())
                    .build())
                .storageConfig(PreventionJobTriggerInspectJobStorageConfigArgs.builder()
                    .timespanConfig(PreventionJobTriggerInspectJobStorageConfigTimespanConfigArgs.builder()
                        .enableAutoPopulationOfTimespanConfig(true)
                        .build())
                    .cloudStorageOptions(PreventionJobTriggerInspectJobStorageConfigCloudStorageOptionsArgs.builder()
                        .fileSet(PreventionJobTriggerInspectJobStorageConfigCloudStorageOptionsFileSetArgs.builder()
                            .url("gs://mybucket/directory/")
                            .build())
                        .build())
                    .build())
                .build())
            .build());

    }
}
```
```yaml
resources:
  basic:
    type: gcp:dataloss:PreventionJobTrigger
    properties:
      parent: projects/my-project-name
      description: Description
      displayName: Displayname
      triggers:
        - schedule:
            recurrencePeriodDuration: 86400s
      inspectJob:
        inspectTemplateName: fake
        actions:
          - saveFindings:
              outputConfig:
                table:
                  projectId: project
                  datasetId: dataset
        storageConfig:
          timespanConfig:
            enableAutoPopulationOfTimespanConfig: true
          cloudStorageOptions:
            fileSet:
              url: gs://mybucket/directory/
```
<!--End PulumiCodeChooser -->
### Dlp Job Trigger Timespan Config Big Query


<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const timespanConfigBigQuery = new gcp.dataloss.PreventionJobTrigger("timespan_config_big_query", {
    parent: "projects/my-project-name",
    description: "BigQuery DLP Job Trigger with timespan config and row limit",
    displayName: "bigquery-dlp-job-trigger-limit-timespan",
    triggers: [{
        schedule: {
            recurrencePeriodDuration: "86400s",
        },
    }],
    inspectJob: {
        inspectTemplateName: "projects/test/locations/global/inspectTemplates/6425492983381733900",
        storageConfig: {
            bigQueryOptions: {
                tableReference: {
                    projectId: "project",
                    datasetId: "dataset",
                    tableId: "table",
                },
                sampleMethod: "",
            },
            timespanConfig: {
                startTime: "2023-01-01T00:00:23Z",
                timestampField: {
                    name: "timestamp",
                },
            },
        },
        actions: [{
            saveFindings: {
                outputConfig: {
                    table: {
                        projectId: "project",
                        datasetId: "output",
                    },
                },
            },
        }],
    },
});
```
```python
import pulumi
import pulumi_gcp as gcp

timespan_config_big_query = gcp.dataloss.PreventionJobTrigger("timespan_config_big_query",
    parent="projects/my-project-name",
    description="BigQuery DLP Job Trigger with timespan config and row limit",
    display_name="bigquery-dlp-job-trigger-limit-timespan",
    triggers=[{
        "schedule": {
            "recurrence_period_duration": "86400s",
        },
    }],
    inspect_job={
        "inspect_template_name": "projects/test/locations/global/inspectTemplates/6425492983381733900",
        "storage_config": {
            "big_query_options": {
                "table_reference": {
                    "project_id": "project",
                    "dataset_id": "dataset",
                    "table_id": "table",
                },
                "sample_method": "",
            },
            "timespan_config": {
                "start_time": "2023-01-01T00:00:23Z",
                "timestamp_field": {
                    "name": "timestamp",
                },
            },
        },
        "actions": [{
            "save_findings": {
                "output_config": {
                    "table": {
                        "project_id": "project",
                        "dataset_id": "output",
                    },
                },
            },
        }],
    })
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var timespanConfigBigQuery = new Gcp.DataLoss.PreventionJobTrigger("timespan_config_big_query", new()
    {
        Parent = "projects/my-project-name",
        Description = "BigQuery DLP Job Trigger with timespan config and row limit",
        DisplayName = "bigquery-dlp-job-trigger-limit-timespan",
        Triggers = new[]
        {
            new Gcp.DataLoss.Inputs.PreventionJobTriggerTriggerArgs
            {
                Schedule = new Gcp.DataLoss.Inputs.PreventionJobTriggerTriggerScheduleArgs
                {
                    RecurrencePeriodDuration = "86400s",
                },
            },
        },
        InspectJob = new Gcp.DataLoss.Inputs.PreventionJobTriggerInspectJobArgs
        {
            InspectTemplateName = "projects/test/locations/global/inspectTemplates/6425492983381733900",
            StorageConfig = new Gcp.DataLoss.Inputs.PreventionJobTriggerInspectJobStorageConfigArgs
            {
                BigQueryOptions = new Gcp.DataLoss.Inputs.PreventionJobTriggerInspectJobStorageConfigBigQueryOptionsArgs
                {
                    TableReference = new Gcp.DataLoss.Inputs.PreventionJobTriggerInspectJobStorageConfigBigQueryOptionsTableReferenceArgs
                    {
                        ProjectId = "project",
                        DatasetId = "dataset",
                        TableId = "table",
                    },
                    SampleMethod = "",
                },
                TimespanConfig = new Gcp.DataLoss.Inputs.PreventionJobTriggerInspectJobStorageConfigTimespanConfigArgs
                {
                    StartTime = "2023-01-01T00:00:23Z",
                    TimestampField = new Gcp.DataLoss.Inputs.PreventionJobTriggerInspectJobStorageConfigTimespanConfigTimestampFieldArgs
                    {
                        Name = "timestamp",
                    },
                },
            },
            Actions = new[]
            {
                new Gcp.DataLoss.Inputs.PreventionJobTriggerInspectJobActionArgs
                {
                    SaveFindings = new Gcp.DataLoss.Inputs.PreventionJobTriggerInspectJobActionSaveFindingsArgs
                    {
                        OutputConfig = new Gcp.DataLoss.Inputs.PreventionJobTriggerInspectJobActionSaveFindingsOutputConfigArgs
                        {
                            Table = new Gcp.DataLoss.Inputs.PreventionJobTriggerInspectJobActionSaveFindingsOutputConfigTableArgs
                            {
                                ProjectId = "project",
                                DatasetId = "output",
                            },
                        },
                    },
                },
            },
        },
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/dataloss"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		_, err := dataloss.NewPreventionJobTrigger(ctx, "timespan_config_big_query", &dataloss.PreventionJobTriggerArgs{
			Parent:      pulumi.String("projects/my-project-name"),
			Description: pulumi.String("BigQuery DLP Job Trigger with timespan config and row limit"),
			DisplayName: pulumi.String("bigquery-dlp-job-trigger-limit-timespan"),
			Triggers: dataloss.PreventionJobTriggerTriggerArray{
				&dataloss.PreventionJobTriggerTriggerArgs{
					Schedule: &dataloss.PreventionJobTriggerTriggerScheduleArgs{
						RecurrencePeriodDuration: pulumi.String("86400s"),
					},
				},
			},
			InspectJob: &dataloss.PreventionJobTriggerInspectJobArgs{
				InspectTemplateName: pulumi.String("projects/test/locations/global/inspectTemplates/6425492983381733900"),
				StorageConfig: &dataloss.PreventionJobTriggerInspectJobStorageConfigArgs{
					BigQueryOptions: &dataloss.PreventionJobTriggerInspectJobStorageConfigBigQueryOptionsArgs{
						TableReference: &dataloss.PreventionJobTriggerInspectJobStorageConfigBigQueryOptionsTableReferenceArgs{
							ProjectId: pulumi.String("project"),
							DatasetId: pulumi.String("dataset"),
							TableId:   pulumi.String("table"),
						},
						SampleMethod: pulumi.String(""),
					},
					TimespanConfig: &dataloss.PreventionJobTriggerInspectJobStorageConfigTimespanConfigArgs{
						StartTime: pulumi.String("2023-01-01T00:00:23Z"),
						TimestampField: &dataloss.PreventionJobTriggerInspectJobStorageConfigTimespanConfigTimestampFieldArgs{
							Name: pulumi.String("timestamp"),
						},
					},
				},
				Actions: dataloss.PreventionJobTriggerInspectJobActionArray{
					&dataloss.PreventionJobTriggerInspectJobActionArgs{
						SaveFindings: &dataloss.PreventionJobTriggerInspectJobActionSaveFindingsArgs{
							OutputConfig: &dataloss.PreventionJobTriggerInspectJobActionSaveFindingsOutputConfigArgs{
								Table: &dataloss.PreventionJobTriggerInspectJobActionSaveFindingsOutputConfigTableArgs{
									ProjectId: pulumi.String("project"),
									DatasetId: pulumi.String("output"),
								},
							},
						},
					},
				},
			},
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.dataloss.PreventionJobTrigger;
import com.pulumi.gcp.dataloss.PreventionJobTriggerArgs;
import com.pulumi.gcp.dataloss.inputs.PreventionJobTriggerTriggerArgs;
import com.pulumi.gcp.dataloss.inputs.PreventionJobTriggerTriggerScheduleArgs;
import com.pulumi.gcp.dataloss.inputs.PreventionJobTriggerInspectJobArgs;
import com.pulumi.gcp.dataloss.inputs.PreventionJobTriggerInspectJobStorageConfigArgs;
import com.pulumi.gcp.dataloss.inputs.PreventionJobTriggerInspectJobStorageConfigBigQueryOptionsArgs;
import com.pulumi.gcp.dataloss.inputs.PreventionJobTriggerInspectJobStorageConfigBigQueryOptionsTableReferenceArgs;
import com.pulumi.gcp.dataloss.inputs.PreventionJobTriggerInspectJobStorageConfigTimespanConfigArgs;
import com.pulumi.gcp.dataloss.inputs.PreventionJobTriggerInspectJobStorageConfigTimespanConfigTimestampFieldArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        var timespanConfigBigQuery = new PreventionJobTrigger("timespanConfigBigQuery", PreventionJobTriggerArgs.builder()
            .parent("projects/my-project-name")
            .description("BigQuery DLP Job Trigger with timespan config and row limit")
            .displayName("bigquery-dlp-job-trigger-limit-timespan")
            .triggers(PreventionJobTriggerTriggerArgs.builder()
                .schedule(PreventionJobTriggerTriggerScheduleArgs.builder()
                    .recurrencePeriodDuration("86400s")
                    .build())
                .build())
            .inspectJob(PreventionJobTriggerInspectJobArgs.builder()
                .inspectTemplateName("projects/test/locations/global/inspectTemplates/6425492983381733900")
                .storageConfig(PreventionJobTriggerInspectJobStorageConfigArgs.builder()
                    .bigQueryOptions(PreventionJobTriggerInspectJobStorageConfigBigQueryOptionsArgs.builder()
                        .tableReference(PreventionJobTriggerInspectJobStorageConfigBigQueryOptionsTableReferenceArgs.builder()
                            .projectId("project")
                            .datasetId("dataset")
                            .tableId("table")
                            .build())
                        .sampleMethod("")
                        .build())
                    .timespanConfig(PreventionJobTriggerInspectJobStorageConfigTimespanConfigArgs.builder()
                        .startTime("2023-01-01T00:00:23Z")
                        .timestampField(PreventionJobTriggerInspectJobStorageConfigTimespanConfigTimestampFieldArgs.builder()
                            .name("timestamp")
                            .build())
                        .build())
                    .build())
                .actions(PreventionJobTriggerInspectJobActionArgs.builder()
                    .saveFindings(PreventionJobTriggerInspectJobActionSaveFindingsArgs.builder()
                        .outputConfig(PreventionJobTriggerInspectJobActionSaveFindingsOutputConfigArgs.builder()
                            .table(PreventionJobTriggerInspectJobActionSaveFindingsOutputConfigTableArgs.builder()
                                .projectId("project")
                                .datasetId("output")
                                .build())
                            .build())
                        .build())
                    .build())
                .build())
            .build());

    }
}
```
```yaml
resources:
  timespanConfigBigQuery:
    type: gcp:dataloss:PreventionJobTrigger
    name: timespan_config_big_query
    properties:
      parent: projects/my-project-name
      description: BigQuery DLP Job Trigger with timespan config and row limit
      displayName: bigquery-dlp-job-trigger-limit-timespan
      triggers:
        - schedule:
            recurrencePeriodDuration: 86400s
      inspectJob:
        inspectTemplateName: projects/test/locations/global/inspectTemplates/6425492983381733900
        storageConfig:
          bigQueryOptions:
            tableReference:
              projectId: project
              datasetId: dataset
              tableId: table
            sampleMethod: ""
          timespanConfig:
            startTime: 2023-01-01T00:00:23Z
            timestampField:
              name: timestamp
        actions:
          - saveFindings:
              outputConfig:
                table:
                  projectId: project
                  datasetId: output
```
<!--End PulumiCodeChooser -->

## Import

JobTrigger can be imported using any of these accepted formats:

* `{{parent}}/jobTriggers/{{name}}`

* `{{parent}}/{{name}}`

When using the `pulumi import` command, JobTrigger can be imported using one of the formats above. For example:

```sh
$ pulumi import gcp:dataloss/preventionJobTrigger:PreventionJobTrigger default {{parent}}/jobTriggers/{{name}}
```

```sh
$ pulumi import gcp:dataloss/preventionJobTrigger:PreventionJobTrigger default {{parent}}/{{name}}
```

7
descriptionB" "A description of the job trigger.
?
displayNameB" *User set display name of the job trigger.
»

inspectJob|Bz:x
v
datalossPreventionJobTriggerInspectJobJgcp:dataloss/PreventionJobTriggerInspectJob:PreventionJobTriggerInspectJob/Controls what and how to inspect for findings.

parent" xThe parent of the trigger, either in the format `projects/{{project}}`
or `projects/{{project}}/locations/{{location}}`

statusB" vWhether the trigger is currently active. Default value: "HEALTHY" Possible values: ["PAUSED", "HEALTHY", "CANCELLED"]
ü
	triggerIdB" èThe trigger id can contain uppercase and lowercase letters, numbers, and hyphens; that is, it must match the regular
expression: [a-zA-Z\d-_]+. The maximum length is 100 characters. Can be empty to allow the system to generate one.
×
triggerss*q:o
m
datalossPreventionJobTriggerTriggerDgcp:dataloss/PreventionJobTriggerTrigger:PreventionJobTriggerTriggerVWhat event needs to occur for a new job to be started.
Structure is documented below.
"S

createTime" AThe creation timestamp of an inspectTemplate. Set by the server.
"7
descriptionB" "A description of the job trigger.
"?
displayNameB" *User set display name of the job trigger.
"»

inspectJob|Bz:x
v
datalossPreventionJobTriggerInspectJobJgcp:dataloss/PreventionJobTriggerInspectJob:PreventionJobTriggerInspectJob/Controls what and how to inspect for findings.
"I
lastRunTime" 6The timestamp of the last time this trigger executed.
"E
name" 9The resource name of the job trigger. Set by the server.
"
parent" xThe parent of the trigger, either in the format `projects/{{project}}`
or `projects/{{project}}/locations/{{location}}`
"
statusB" vWhether the trigger is currently active. Default value: "HEALTHY" Possible values: ["PAUSED", "HEALTHY", "CANCELLED"]
"ú
	triggerId" èThe trigger id can contain uppercase and lowercase letters, numbers, and hyphens; that is, it must match the regular
expression: [a-zA-Z\d-_]+. The maximum length is 100 characters. Can be empty to allow the system to generate one.
"×
triggerss*q:o
m
datalossPreventionJobTriggerTriggerDgcp:dataloss/PreventionJobTriggerTrigger:PreventionJobTriggerTriggerVWhat event needs to occur for a new job to be started.
Structure is documented below.
"V

updateTime" DThe last update timestamp of an inspectTemplate. Set by the server.
*ò³
d
datalossPreventionStoredInfoType>gcp:dataloss/preventionStoredInfoType:PreventionStoredInfoType»Allows creation of custom info types.


To get more information about StoredInfoType, see:

* [API documentation](https://cloud.google.com/dlp/docs/reference/rest/v2/projects.storedInfoTypes)
* How-to Guides
    * [Official Documentation](https://cloud.google.com/dlp/docs/creating-stored-infotypes)

## Example Usage

### Dlp Stored Info Type Basic


<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const basic = new gcp.dataloss.PreventionStoredInfoType("basic", {
    parent: "projects/my-project-name",
    description: "Description",
    displayName: "Displayname",
    regex: {
        pattern: "patient",
        groupIndexes: [2],
    },
});
```
```python
import pulumi
import pulumi_gcp as gcp

basic = gcp.dataloss.PreventionStoredInfoType("basic",
    parent="projects/my-project-name",
    description="Description",
    display_name="Displayname",
    regex={
        "pattern": "patient",
        "group_indexes": [2],
    })
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var basic = new Gcp.DataLoss.PreventionStoredInfoType("basic", new()
    {
        Parent = "projects/my-project-name",
        Description = "Description",
        DisplayName = "Displayname",
        Regex = new Gcp.DataLoss.Inputs.PreventionStoredInfoTypeRegexArgs
        {
            Pattern = "patient",
            GroupIndexes = new[]
            {
                2,
            },
        },
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/dataloss"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		_, err := dataloss.NewPreventionStoredInfoType(ctx, "basic", &dataloss.PreventionStoredInfoTypeArgs{
			Parent:      pulumi.String("projects/my-project-name"),
			Description: pulumi.String("Description"),
			DisplayName: pulumi.String("Displayname"),
			Regex: &dataloss.PreventionStoredInfoTypeRegexArgs{
				Pattern: pulumi.String("patient"),
				GroupIndexes: pulumi.IntArray{
					pulumi.Int(2),
				},
			},
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.dataloss.PreventionStoredInfoType;
import com.pulumi.gcp.dataloss.PreventionStoredInfoTypeArgs;
import com.pulumi.gcp.dataloss.inputs.PreventionStoredInfoTypeRegexArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        var basic = new PreventionStoredInfoType("basic", PreventionStoredInfoTypeArgs.builder()
            .parent("projects/my-project-name")
            .description("Description")
            .displayName("Displayname")
            .regex(PreventionStoredInfoTypeRegexArgs.builder()
                .pattern("patient")
                .groupIndexes(2)
                .build())
            .build());

    }
}
```
```yaml
resources:
  basic:
    type: gcp:dataloss:PreventionStoredInfoType
    properties:
      parent: projects/my-project-name
      description: Description
      displayName: Displayname
      regex:
        pattern: patient
        groupIndexes:
          - 2
```
<!--End PulumiCodeChooser -->
### Dlp Stored Info Type Dictionary


<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const dictionary = new gcp.dataloss.PreventionStoredInfoType("dictionary", {
    parent: "projects/my-project-name",
    description: "Description",
    displayName: "Displayname",
    dictionary: {
        wordList: {
            words: [
                "word",
                "word2",
            ],
        },
    },
});
```
```python
import pulumi
import pulumi_gcp as gcp

dictionary = gcp.dataloss.PreventionStoredInfoType("dictionary",
    parent="projects/my-project-name",
    description="Description",
    display_name="Displayname",
    dictionary={
        "word_list": {
            "words": [
                "word",
                "word2",
            ],
        },
    })
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var dictionary = new Gcp.DataLoss.PreventionStoredInfoType("dictionary", new()
    {
        Parent = "projects/my-project-name",
        Description = "Description",
        DisplayName = "Displayname",
        Dictionary = new Gcp.DataLoss.Inputs.PreventionStoredInfoTypeDictionaryArgs
        {
            WordList = new Gcp.DataLoss.Inputs.PreventionStoredInfoTypeDictionaryWordListArgs
            {
                Words = new[]
                {
                    "word",
                    "word2",
                },
            },
        },
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/dataloss"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		_, err := dataloss.NewPreventionStoredInfoType(ctx, "dictionary", &dataloss.PreventionStoredInfoTypeArgs{
			Parent:      pulumi.String("projects/my-project-name"),
			Description: pulumi.String("Description"),
			DisplayName: pulumi.String("Displayname"),
			Dictionary: &dataloss.PreventionStoredInfoTypeDictionaryArgs{
				WordList: &dataloss.PreventionStoredInfoTypeDictionaryWordListArgs{
					Words: pulumi.StringArray{
						pulumi.String("word"),
						pulumi.String("word2"),
					},
				},
			},
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.dataloss.PreventionStoredInfoType;
import com.pulumi.gcp.dataloss.PreventionStoredInfoTypeArgs;
import com.pulumi.gcp.dataloss.inputs.PreventionStoredInfoTypeDictionaryArgs;
import com.pulumi.gcp.dataloss.inputs.PreventionStoredInfoTypeDictionaryWordListArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        var dictionary = new PreventionStoredInfoType("dictionary", PreventionStoredInfoTypeArgs.builder()
            .parent("projects/my-project-name")
            .description("Description")
            .displayName("Displayname")
            .dictionary(PreventionStoredInfoTypeDictionaryArgs.builder()
                .wordList(PreventionStoredInfoTypeDictionaryWordListArgs.builder()
                    .words(                    
                        "word",
                        "word2")
                    .build())
                .build())
            .build());

    }
}
```
```yaml
resources:
  dictionary:
    type: gcp:dataloss:PreventionStoredInfoType
    properties:
      parent: projects/my-project-name
      description: Description
      displayName: Displayname
      dictionary:
        wordList:
          words:
            - word
            - word2
```
<!--End PulumiCodeChooser -->
### Dlp Stored Info Type Large Custom Dictionary


<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const bucket = new gcp.storage.Bucket("bucket", {
    name: "tf-test-bucket",
    location: "US",
    forceDestroy: true,
});
const object = new gcp.storage.BucketObject("object", {
    name: "tf-test-object",
    bucket: bucket.name,
    source: new pulumi.asset.FileAsset("./test-fixtures/words.txt"),
});
const large = new gcp.dataloss.PreventionStoredInfoType("large", {
    parent: "projects/my-project-name",
    description: "Description",
    displayName: "Displayname",
    largeCustomDictionary: {
        cloudStorageFileSet: {
            url: pulumi.interpolate`gs://${bucket.name}/${object.name}`,
        },
        outputPath: {
            path: pulumi.interpolate`gs://${bucket.name}/output/dictionary.txt`,
        },
    },
});
```
```python
import pulumi
import pulumi_gcp as gcp

bucket = gcp.storage.Bucket("bucket",
    name="tf-test-bucket",
    location="US",
    force_destroy=True)
object = gcp.storage.BucketObject("object",
    name="tf-test-object",
    bucket=bucket.name,
    source=pulumi.FileAsset("./test-fixtures/words.txt"))
large = gcp.dataloss.PreventionStoredInfoType("large",
    parent="projects/my-project-name",
    description="Description",
    display_name="Displayname",
    large_custom_dictionary={
        "cloud_storage_file_set": {
            "url": pulumi.Output.all(
                bucketName=bucket.name,
                objectName=object.name
).apply(lambda resolved_outputs: f"gs://{resolved_outputs['bucketName']}/{resolved_outputs['objectName']}")
,
        },
        "output_path": {
            "path": bucket.name.apply(lambda name: f"gs://{name}/output/dictionary.txt"),
        },
    })
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var bucket = new Gcp.Storage.Bucket("bucket", new()
    {
        Name = "tf-test-bucket",
        Location = "US",
        ForceDestroy = true,
    });

    var @object = new Gcp.Storage.BucketObject("object", new()
    {
        Name = "tf-test-object",
        Bucket = bucket.Name,
        Source = new FileAsset("./test-fixtures/words.txt"),
    });

    var large = new Gcp.DataLoss.PreventionStoredInfoType("large", new()
    {
        Parent = "projects/my-project-name",
        Description = "Description",
        DisplayName = "Displayname",
        LargeCustomDictionary = new Gcp.DataLoss.Inputs.PreventionStoredInfoTypeLargeCustomDictionaryArgs
        {
            CloudStorageFileSet = new Gcp.DataLoss.Inputs.PreventionStoredInfoTypeLargeCustomDictionaryCloudStorageFileSetArgs
            {
                Url = Output.Tuple(bucket.Name, @object.Name).Apply(values =>
                {
                    var bucketName = values.Item1;
                    var objectName = values.Item2;
                    return $"gs://{bucketName}/{objectName}";
                }),
            },
            OutputPath = new Gcp.DataLoss.Inputs.PreventionStoredInfoTypeLargeCustomDictionaryOutputPathArgs
            {
                Path = bucket.Name.Apply(name => $"gs://{name}/output/dictionary.txt"),
            },
        },
    });

});
```
```go
package main

import (
	"fmt"

	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/dataloss"
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/storage"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		bucket, err := storage.NewBucket(ctx, "bucket", &storage.BucketArgs{
			Name:         pulumi.String("tf-test-bucket"),
			Location:     pulumi.String("US"),
			ForceDestroy: pulumi.Bool(true),
		})
		if err != nil {
			return err
		}
		object, err := storage.NewBucketObject(ctx, "object", &storage.BucketObjectArgs{
			Name:   pulumi.String("tf-test-object"),
			Bucket: bucket.Name,
			Source: pulumi.NewFileAsset("./test-fixtures/words.txt"),
		})
		if err != nil {
			return err
		}
		_, err = dataloss.NewPreventionStoredInfoType(ctx, "large", &dataloss.PreventionStoredInfoTypeArgs{
			Parent:      pulumi.String("projects/my-project-name"),
			Description: pulumi.String("Description"),
			DisplayName: pulumi.String("Displayname"),
			LargeCustomDictionary: &dataloss.PreventionStoredInfoTypeLargeCustomDictionaryArgs{
				CloudStorageFileSet: &dataloss.PreventionStoredInfoTypeLargeCustomDictionaryCloudStorageFileSetArgs{
					Url: pulumi.All(bucket.Name, object.Name).ApplyT(func(_args []interface{}) (string, error) {
						bucketName := _args[0].(string)
						objectName := _args[1].(string)
						return fmt.Sprintf("gs://%v/%v", bucketName, objectName), nil
					}).(pulumi.StringOutput),
				},
				OutputPath: &dataloss.PreventionStoredInfoTypeLargeCustomDictionaryOutputPathArgs{
					Path: bucket.Name.ApplyT(func(name string) (string, error) {
						return fmt.Sprintf("gs://%v/output/dictionary.txt", name), nil
					}).(pulumi.StringOutput),
				},
			},
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.storage.Bucket;
import com.pulumi.gcp.storage.BucketArgs;
import com.pulumi.gcp.storage.BucketObject;
import com.pulumi.gcp.storage.BucketObjectArgs;
import com.pulumi.gcp.dataloss.PreventionStoredInfoType;
import com.pulumi.gcp.dataloss.PreventionStoredInfoTypeArgs;
import com.pulumi.gcp.dataloss.inputs.PreventionStoredInfoTypeLargeCustomDictionaryArgs;
import com.pulumi.gcp.dataloss.inputs.PreventionStoredInfoTypeLargeCustomDictionaryCloudStorageFileSetArgs;
import com.pulumi.gcp.dataloss.inputs.PreventionStoredInfoTypeLargeCustomDictionaryOutputPathArgs;
import com.pulumi.asset.FileAsset;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        var bucket = new Bucket("bucket", BucketArgs.builder()
            .name("tf-test-bucket")
            .location("US")
            .forceDestroy(true)
            .build());

        var object = new BucketObject("object", BucketObjectArgs.builder()
            .name("tf-test-object")
            .bucket(bucket.name())
            .source(new FileAsset("./test-fixtures/words.txt"))
            .build());

        var large = new PreventionStoredInfoType("large", PreventionStoredInfoTypeArgs.builder()
            .parent("projects/my-project-name")
            .description("Description")
            .displayName("Displayname")
            .largeCustomDictionary(PreventionStoredInfoTypeLargeCustomDictionaryArgs.builder()
                .cloudStorageFileSet(PreventionStoredInfoTypeLargeCustomDictionaryCloudStorageFileSetArgs.builder()
                    .url(Output.tuple(bucket.name(), object.name()).applyValue(values -> {
                        var bucketName = values.t1;
                        var objectName = values.t2;
                        return String.format("gs://%s/%s", bucketName,objectName);
                    }))
                    .build())
                .outputPath(PreventionStoredInfoTypeLargeCustomDictionaryOutputPathArgs.builder()
                    .path(bucket.name().applyValue(name -> String.format("gs://%s/output/dictionary.txt", name)))
                    .build())
                .build())
            .build());

    }
}
```
```yaml
resources:
  large:
    type: gcp:dataloss:PreventionStoredInfoType
    properties:
      parent: projects/my-project-name
      description: Description
      displayName: Displayname
      largeCustomDictionary:
        cloudStorageFileSet:
          url: gs://${bucket.name}/${object.name}
        outputPath:
          path: gs://${bucket.name}/output/dictionary.txt
  bucket:
    type: gcp:storage:Bucket
    properties:
      name: tf-test-bucket
      location: US
      forceDestroy: true
  object:
    type: gcp:storage:BucketObject
    properties:
      name: tf-test-object
      bucket: ${bucket.name}
      source:
        fn::FileAsset: ./test-fixtures/words.txt
```
<!--End PulumiCodeChooser -->
### Dlp Stored Info Type With Id


<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const withStoredInfoTypeId = new gcp.dataloss.PreventionStoredInfoType("with_stored_info_type_id", {
    parent: "projects/my-project-name",
    description: "Description",
    displayName: "Displayname",
    storedInfoTypeId: "id-",
    regex: {
        pattern: "patient",
        groupIndexes: [2],
    },
});
```
```python
import pulumi
import pulumi_gcp as gcp

with_stored_info_type_id = gcp.dataloss.PreventionStoredInfoType("with_stored_info_type_id",
    parent="projects/my-project-name",
    description="Description",
    display_name="Displayname",
    stored_info_type_id="id-",
    regex={
        "pattern": "patient",
        "group_indexes": [2],
    })
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var withStoredInfoTypeId = new Gcp.DataLoss.PreventionStoredInfoType("with_stored_info_type_id", new()
    {
        Parent = "projects/my-project-name",
        Description = "Description",
        DisplayName = "Displayname",
        StoredInfoTypeId = "id-",
        Regex = new Gcp.DataLoss.Inputs.PreventionStoredInfoTypeRegexArgs
        {
            Pattern = "patient",
            GroupIndexes = new[]
            {
                2,
            },
        },
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/dataloss"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		_, err := dataloss.NewPreventionStoredInfoType(ctx, "with_stored_info_type_id", &dataloss.PreventionStoredInfoTypeArgs{
			Parent:           pulumi.String("projects/my-project-name"),
			Description:      pulumi.String("Description"),
			DisplayName:      pulumi.String("Displayname"),
			StoredInfoTypeId: pulumi.String("id-"),
			Regex: &dataloss.PreventionStoredInfoTypeRegexArgs{
				Pattern: pulumi.String("patient"),
				GroupIndexes: pulumi.IntArray{
					pulumi.Int(2),
				},
			},
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.dataloss.PreventionStoredInfoType;
import com.pulumi.gcp.dataloss.PreventionStoredInfoTypeArgs;
import com.pulumi.gcp.dataloss.inputs.PreventionStoredInfoTypeRegexArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        var withStoredInfoTypeId = new PreventionStoredInfoType("withStoredInfoTypeId", PreventionStoredInfoTypeArgs.builder()
            .parent("projects/my-project-name")
            .description("Description")
            .displayName("Displayname")
            .storedInfoTypeId("id-")
            .regex(PreventionStoredInfoTypeRegexArgs.builder()
                .pattern("patient")
                .groupIndexes(2)
                .build())
            .build());

    }
}
```
```yaml
resources:
  withStoredInfoTypeId:
    type: gcp:dataloss:PreventionStoredInfoType
    name: with_stored_info_type_id
    properties:
      parent: projects/my-project-name
      description: Description
      displayName: Displayname
      storedInfoTypeId: id-
      regex:
        pattern: patient
        groupIndexes:
          - 2
```
<!--End PulumiCodeChooser -->

## Import

StoredInfoType can be imported using any of these accepted formats:

* `{{parent}}/storedInfoTypes/{{name}}`

* `{{parent}}/{{name}}`

When using the `pulumi import` command, StoredInfoType can be imported using one of the formats above. For example:

```sh
$ pulumi import gcp:dataloss/preventionStoredInfoType:PreventionStoredInfoType default {{parent}}/storedInfoTypes/{{name}}
```

```sh
$ pulumi import gcp:dataloss/preventionStoredInfoType:PreventionStoredInfoType default {{parent}}/{{name}}
```

5
descriptionB"  A description of the info type.
Þ

dictionaryB:

dataloss"PreventionStoredInfoTypeDictionaryRgcp:dataloss/PreventionStoredInfoTypeDictionary:PreventionStoredInfoTypeDictionaryBDictionary which defines the rule.
Structure is documented below.
=
displayNameB" (User set display name of the info type.

largeCustomDictionary¬B©:¦
£
dataloss-PreventionStoredInfoTypeLargeCustomDictionaryhgcp:dataloss/PreventionStoredInfoTypeLargeCustomDictionary:PreventionStoredInfoTypeLargeCustomDictionaryBDictionary which defines the rule.
Structure is documented below.

parent" ñThe parent of the info type in any of the following formats:
* `projects/{{project}}`
* `projects/{{project}}/locations/{{location}}`
* `organizations/{{organization_id}}`
* `organizations/{{organization_id}}/locations/{{location}}`


- - -
Î
regexyBw:u
s
datalossPreventionStoredInfoTypeRegexHgcp:dataloss/PreventionStoredInfoTypeRegex:PreventionStoredInfoTypeRegexJRegular expression which defines the rule.
Structure is documented below.

storedInfoTypeIdB" ïThe storedInfoType ID can contain uppercase and lowercase letters, numbers, and hyphens;
that is, it must match the regular expression: [a-zA-Z\d-_]+. The maximum length is 100
characters. Can be empty to allow the system to generate one.
"5
descriptionB"  A description of the info type.
"Þ

dictionaryB:

dataloss"PreventionStoredInfoTypeDictionaryRgcp:dataloss/PreventionStoredInfoTypeDictionary:PreventionStoredInfoTypeDictionaryBDictionary which defines the rule.
Structure is documented below.
"=
displayNameB" (User set display name of the info type.
"
largeCustomDictionary¬B©:¦
£
dataloss-PreventionStoredInfoTypeLargeCustomDictionaryhgcp:dataloss/PreventionStoredInfoTypeLargeCustomDictionary:PreventionStoredInfoTypeLargeCustomDictionaryBDictionary which defines the rule.
Structure is documented below.
"C
name" 7The resource name of the info type. Set by the server.
"
parent" ñThe parent of the info type in any of the following formats:
* `projects/{{project}}`
* `projects/{{project}}/locations/{{location}}`
* `organizations/{{organization_id}}`
* `organizations/{{organization_id}}/locations/{{location}}`


- - -
"Î
regexyBw:u
s
datalossPreventionStoredInfoTypeRegexHgcp:dataloss/PreventionStoredInfoTypeRegex:PreventionStoredInfoTypeRegexJRegular expression which defines the rule.
Structure is documented below.
"
storedInfoTypeId" ïThe storedInfoType ID can contain uppercase and lowercase letters, numbers, and hyphens;
that is, it must match the regular expression: [a-zA-Z\d-_]+. The maximum length is 100
characters. Can be empty to allow the system to generate one.
*ìï
:
dataplex
AspectType"gcp:dataplex/aspectType:AspectTypeãÝAn Aspect Type is a template for creating Aspects.



## Example Usage

### Dataplex Aspect Type Basic


<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const testAspectTypeBasic = new gcp.dataplex.AspectType("test_aspect_type_basic", {
    aspectTypeId: "aspect-type-basic",
    project: "my-project-name",
    location: "us-central1",
    metadataTemplate: `{
  "name": "tf-test-template",
  "type": "record",
  "recordFields": [
    {
      "name": "type",
      "type": "enum",
      "annotations": {
        "displayName": "Type",
        "description": "Specifies the type of view represented by the entry."
      },
      "index": 1,
      "constraints": {
        "required": true
      },
      "enumValues": [
        {
          "name": "VIEW",
          "index": 1
        }
      ]
    }
  ]
}
`,
});
```
```python
import pulumi
import pulumi_gcp as gcp

test_aspect_type_basic = gcp.dataplex.AspectType("test_aspect_type_basic",
    aspect_type_id="aspect-type-basic",
    project="my-project-name",
    location="us-central1",
    metadata_template="""{
  "name": "tf-test-template",
  "type": "record",
  "recordFields": [
    {
      "name": "type",
      "type": "enum",
      "annotations": {
        "displayName": "Type",
        "description": "Specifies the type of view represented by the entry."
      },
      "index": 1,
      "constraints": {
        "required": true
      },
      "enumValues": [
        {
          "name": "VIEW",
          "index": 1
        }
      ]
    }
  ]
}
""")
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var testAspectTypeBasic = new Gcp.DataPlex.AspectType("test_aspect_type_basic", new()
    {
        AspectTypeId = "aspect-type-basic",
        Project = "my-project-name",
        Location = "us-central1",
        MetadataTemplate = @"{
  ""name"": ""tf-test-template"",
  ""type"": ""record"",
  ""recordFields"": [
    {
      ""name"": ""type"",
      ""type"": ""enum"",
      ""annotations"": {
        ""displayName"": ""Type"",
        ""description"": ""Specifies the type of view represented by the entry.""
      },
      ""index"": 1,
      ""constraints"": {
        ""required"": true
      },
      ""enumValues"": [
        {
          ""name"": ""VIEW"",
          ""index"": 1
        }
      ]
    }
  ]
}
",
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/dataplex"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		_, err := dataplex.NewAspectType(ctx, "test_aspect_type_basic", &dataplex.AspectTypeArgs{
			AspectTypeId: pulumi.String("aspect-type-basic"),
			Project:      pulumi.String("my-project-name"),
			Location:     pulumi.String("us-central1"),
			MetadataTemplate: pulumi.String(`{
  "name": "tf-test-template",
  "type": "record",
  "recordFields": [
    {
      "name": "type",
      "type": "enum",
      "annotations": {
        "displayName": "Type",
        "description": "Specifies the type of view represented by the entry."
      },
      "index": 1,
      "constraints": {
        "required": true
      },
      "enumValues": [
        {
          "name": "VIEW",
          "index": 1
        }
      ]
    }
  ]
}
`),
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.dataplex.AspectType;
import com.pulumi.gcp.dataplex.AspectTypeArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        var testAspectTypeBasic = new AspectType("testAspectTypeBasic", AspectTypeArgs.builder()
            .aspectTypeId("aspect-type-basic")
            .project("my-project-name")
            .location("us-central1")
            .metadataTemplate("""
{
  "name": "tf-test-template",
  "type": "record",
  "recordFields": [
    {
      "name": "type",
      "type": "enum",
      "annotations": {
        "displayName": "Type",
        "description": "Specifies the type of view represented by the entry."
      },
      "index": 1,
      "constraints": {
        "required": true
      },
      "enumValues": [
        {
          "name": "VIEW",
          "index": 1
        }
      ]
    }
  ]
}
            """)
            .build());

    }
}
```
```yaml
resources:
  testAspectTypeBasic:
    type: gcp:dataplex:AspectType
    name: test_aspect_type_basic
    properties:
      aspectTypeId: aspect-type-basic
      project: my-project-name
      location: us-central1
      metadataTemplate: |
        {
          "name": "tf-test-template",
          "type": "record",
          "recordFields": [
            {
              "name": "type",
              "type": "enum",
              "annotations": {
                "displayName": "Type",
                "description": "Specifies the type of view represented by the entry."
              },
              "index": 1,
              "constraints": {
                "required": true
              },
              "enumValues": [
                {
                  "name": "VIEW",
                  "index": 1
                }
              ]
            }
          ]
        }
```
<!--End PulumiCodeChooser -->
### Dataplex Aspect Type Full


<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const testAspectTypeFull = new gcp.dataplex.AspectType("test_aspect_type_full", {
    aspectTypeId: "aspect-type-full",
    project: "my-project-name",
    location: "us-central1",
    labels: {
        tag: "test-tf",
    },
    displayName: "terraform aspect type",
    description: "aspect type created by Terraform",
    metadataTemplate: `{
  "type": "record",
  "name": "Schema",
  "recordFields": [
    {
      "name": "fields",
      "type": "array",
      "index": 1,
      "arrayItems": {
        "name": "field",
        "type": "record",
        "typeId": "field",
        "recordFields": [
          {
            "name": "name",
            "type": "string",
            "index": 1,
            "constraints": {
              "required": true
            }
          },
          {
            "name": "description",
            "type": "string",
            "index": 2
          },
          {
            "name": "dataType",
            "type": "string",
            "index": 3,
            "constraints": {
              "required": true
            }
          },
          {
            "name": "metadataType",
            "type": "enum",
            "index": 4,
            "constraints": {
              "required": true
            },
            "enumValues": [
              {
                "name": "BOOLEAN",
                "index": 1
              },
              {
                "name": "NUMBER",
                "index": 2
              },
              {
                "name": "STRING",
                "index": 3
              },
              {
                "name": "BYTES",
                "index": 4
              },
              {
                "name": "DATETIME",
                "index": 5
              },
              {
                "name": "TIMESTAMP",
                "index": 6
              },
              {
                "name": "GEOSPATIAL",
                "index": 7
              },
              {
                "name": "STRUCT",
                "index": 8
              },
              {
                "name": "OTHER",
                "index": 100
              }
            ]
          },
          {
            "name": "mode",
            "type": "enum",
            "index": 5,
            "enumValues": [
              {
                "name": "NULLABLE",
                "index": 1
              },
              {
                "name": "REPEATED",
                "index": 2
              },
              {
                "name": "REQUIRED",
                "index": 3
              }
            ]
          },
          {
            "name": "defaultValue",
            "type": "string",
            "index": 6
          },
          {
            "name": "annotations",
            "type": "map",
            "index": 7,
            "mapItems": {
              "name": "label",
              "type": "string"
            }
          },
          {
            "name": "fields",
            "type": "array",
            "index": 20,
            "arrayItems": {
              "name": "field",
              "type": "record",
              "typeRef": "field"
            }
          }
        ]
      }
    }
  ]
}
`,
});
```
```python
import pulumi
import pulumi_gcp as gcp

test_aspect_type_full = gcp.dataplex.AspectType("test_aspect_type_full",
    aspect_type_id="aspect-type-full",
    project="my-project-name",
    location="us-central1",
    labels={
        "tag": "test-tf",
    },
    display_name="terraform aspect type",
    description="aspect type created by Terraform",
    metadata_template="""{
  "type": "record",
  "name": "Schema",
  "recordFields": [
    {
      "name": "fields",
      "type": "array",
      "index": 1,
      "arrayItems": {
        "name": "field",
        "type": "record",
        "typeId": "field",
        "recordFields": [
          {
            "name": "name",
            "type": "string",
            "index": 1,
            "constraints": {
              "required": true
            }
          },
          {
            "name": "description",
            "type": "string",
            "index": 2
          },
          {
            "name": "dataType",
            "type": "string",
            "index": 3,
            "constraints": {
              "required": true
            }
          },
          {
            "name": "metadataType",
            "type": "enum",
            "index": 4,
            "constraints": {
              "required": true
            },
            "enumValues": [
              {
                "name": "BOOLEAN",
                "index": 1
              },
              {
                "name": "NUMBER",
                "index": 2
              },
              {
                "name": "STRING",
                "index": 3
              },
              {
                "name": "BYTES",
                "index": 4
              },
              {
                "name": "DATETIME",
                "index": 5
              },
              {
                "name": "TIMESTAMP",
                "index": 6
              },
              {
                "name": "GEOSPATIAL",
                "index": 7
              },
              {
                "name": "STRUCT",
                "index": 8
              },
              {
                "name": "OTHER",
                "index": 100
              }
            ]
          },
          {
            "name": "mode",
            "type": "enum",
            "index": 5,
            "enumValues": [
              {
                "name": "NULLABLE",
                "index": 1
              },
              {
                "name": "REPEATED",
                "index": 2
              },
              {
                "name": "REQUIRED",
                "index": 3
              }
            ]
          },
          {
            "name": "defaultValue",
            "type": "string",
            "index": 6
          },
          {
            "name": "annotations",
            "type": "map",
            "index": 7,
            "mapItems": {
              "name": "label",
              "type": "string"
            }
          },
          {
            "name": "fields",
            "type": "array",
            "index": 20,
            "arrayItems": {
              "name": "field",
              "type": "record",
              "typeRef": "field"
            }
          }
        ]
      }
    }
  ]
}
""")
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var testAspectTypeFull = new Gcp.DataPlex.AspectType("test_aspect_type_full", new()
    {
        AspectTypeId = "aspect-type-full",
        Project = "my-project-name",
        Location = "us-central1",
        Labels = 
        {
            { "tag", "test-tf" },
        },
        DisplayName = "terraform aspect type",
        Description = "aspect type created by Terraform",
        MetadataTemplate = @"{
  ""type"": ""record"",
  ""name"": ""Schema"",
  ""recordFields"": [
    {
      ""name"": ""fields"",
      ""type"": ""array"",
      ""index"": 1,
      ""arrayItems"": {
        ""name"": ""field"",
        ""type"": ""record"",
        ""typeId"": ""field"",
        ""recordFields"": [
          {
            ""name"": ""name"",
            ""type"": ""string"",
            ""index"": 1,
            ""constraints"": {
              ""required"": true
            }
          },
          {
            ""name"": ""description"",
            ""type"": ""string"",
            ""index"": 2
          },
          {
            ""name"": ""dataType"",
            ""type"": ""string"",
            ""index"": 3,
            ""constraints"": {
              ""required"": true
            }
          },
          {
            ""name"": ""metadataType"",
            ""type"": ""enum"",
            ""index"": 4,
            ""constraints"": {
              ""required"": true
            },
            ""enumValues"": [
              {
                ""name"": ""BOOLEAN"",
                ""index"": 1
              },
              {
                ""name"": ""NUMBER"",
                ""index"": 2
              },
              {
                ""name"": ""STRING"",
                ""index"": 3
              },
              {
                ""name"": ""BYTES"",
                ""index"": 4
              },
              {
                ""name"": ""DATETIME"",
                ""index"": 5
              },
              {
                ""name"": ""TIMESTAMP"",
                ""index"": 6
              },
              {
                ""name"": ""GEOSPATIAL"",
                ""index"": 7
              },
              {
                ""name"": ""STRUCT"",
                ""index"": 8
              },
              {
                ""name"": ""OTHER"",
                ""index"": 100
              }
            ]
          },
          {
            ""name"": ""mode"",
            ""type"": ""enum"",
            ""index"": 5,
            ""enumValues"": [
              {
                ""name"": ""NULLABLE"",
                ""index"": 1
              },
              {
                ""name"": ""REPEATED"",
                ""index"": 2
              },
              {
                ""name"": ""REQUIRED"",
                ""index"": 3
              }
            ]
          },
          {
            ""name"": ""defaultValue"",
            ""type"": ""string"",
            ""index"": 6
          },
          {
            ""name"": ""annotations"",
            ""type"": ""map"",
            ""index"": 7,
            ""mapItems"": {
              ""name"": ""label"",
              ""type"": ""string""
            }
          },
          {
            ""name"": ""fields"",
            ""type"": ""array"",
            ""index"": 20,
            ""arrayItems"": {
              ""name"": ""field"",
              ""type"": ""record"",
              ""typeRef"": ""field""
            }
          }
        ]
      }
    }
  ]
}
",
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/dataplex"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		_, err := dataplex.NewAspectType(ctx, "test_aspect_type_full", &dataplex.AspectTypeArgs{
			AspectTypeId: pulumi.String("aspect-type-full"),
			Project:      pulumi.String("my-project-name"),
			Location:     pulumi.String("us-central1"),
			Labels: pulumi.StringMap{
				"tag": pulumi.String("test-tf"),
			},
			DisplayName: pulumi.String("terraform aspect type"),
			Description: pulumi.String("aspect type created by Terraform"),
			MetadataTemplate: pulumi.String(`{
  "type": "record",
  "name": "Schema",
  "recordFields": [
    {
      "name": "fields",
      "type": "array",
      "index": 1,
      "arrayItems": {
        "name": "field",
        "type": "record",
        "typeId": "field",
        "recordFields": [
          {
            "name": "name",
            "type": "string",
            "index": 1,
            "constraints": {
              "required": true
            }
          },
          {
            "name": "description",
            "type": "string",
            "index": 2
          },
          {
            "name": "dataType",
            "type": "string",
            "index": 3,
            "constraints": {
              "required": true
            }
          },
          {
            "name": "metadataType",
            "type": "enum",
            "index": 4,
            "constraints": {
              "required": true
            },
            "enumValues": [
              {
                "name": "BOOLEAN",
                "index": 1
              },
              {
                "name": "NUMBER",
                "index": 2
              },
              {
                "name": "STRING",
                "index": 3
              },
              {
                "name": "BYTES",
                "index": 4
              },
              {
                "name": "DATETIME",
                "index": 5
              },
              {
                "name": "TIMESTAMP",
                "index": 6
              },
              {
                "name": "GEOSPATIAL",
                "index": 7
              },
              {
                "name": "STRUCT",
                "index": 8
              },
              {
                "name": "OTHER",
                "index": 100
              }
            ]
          },
          {
            "name": "mode",
            "type": "enum",
            "index": 5,
            "enumValues": [
              {
                "name": "NULLABLE",
                "index": 1
              },
              {
                "name": "REPEATED",
                "index": 2
              },
              {
                "name": "REQUIRED",
                "index": 3
              }
            ]
          },
          {
            "name": "defaultValue",
            "type": "string",
            "index": 6
          },
          {
            "name": "annotations",
            "type": "map",
            "index": 7,
            "mapItems": {
              "name": "label",
              "type": "string"
            }
          },
          {
            "name": "fields",
            "type": "array",
            "index": 20,
            "arrayItems": {
              "name": "field",
              "type": "record",
              "typeRef": "field"
            }
          }
        ]
      }
    }
  ]
}
`),
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.dataplex.AspectType;
import com.pulumi.gcp.dataplex.AspectTypeArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        var testAspectTypeFull = new AspectType("testAspectTypeFull", AspectTypeArgs.builder()
            .aspectTypeId("aspect-type-full")
            .project("my-project-name")
            .location("us-central1")
            .labels(Map.of("tag", "test-tf"))
            .displayName("terraform aspect type")
            .description("aspect type created by Terraform")
            .metadataTemplate("""
{
  "type": "record",
  "name": "Schema",
  "recordFields": [
    {
      "name": "fields",
      "type": "array",
      "index": 1,
      "arrayItems": {
        "name": "field",
        "type": "record",
        "typeId": "field",
        "recordFields": [
          {
            "name": "name",
            "type": "string",
            "index": 1,
            "constraints": {
              "required": true
            }
          },
          {
            "name": "description",
            "type": "string",
            "index": 2
          },
          {
            "name": "dataType",
            "type": "string",
            "index": 3,
            "constraints": {
              "required": true
            }
          },
          {
            "name": "metadataType",
            "type": "enum",
            "index": 4,
            "constraints": {
              "required": true
            },
            "enumValues": [
              {
                "name": "BOOLEAN",
                "index": 1
              },
              {
                "name": "NUMBER",
                "index": 2
              },
              {
                "name": "STRING",
                "index": 3
              },
              {
                "name": "BYTES",
                "index": 4
              },
              {
                "name": "DATETIME",
                "index": 5
              },
              {
                "name": "TIMESTAMP",
                "index": 6
              },
              {
                "name": "GEOSPATIAL",
                "index": 7
              },
              {
                "name": "STRUCT",
                "index": 8
              },
              {
                "name": "OTHER",
                "index": 100
              }
            ]
          },
          {
            "name": "mode",
            "type": "enum",
            "index": 5,
            "enumValues": [
              {
                "name": "NULLABLE",
                "index": 1
              },
              {
                "name": "REPEATED",
                "index": 2
              },
              {
                "name": "REQUIRED",
                "index": 3
              }
            ]
          },
          {
            "name": "defaultValue",
            "type": "string",
            "index": 6
          },
          {
            "name": "annotations",
            "type": "map",
            "index": 7,
            "mapItems": {
              "name": "label",
              "type": "string"
            }
          },
          {
            "name": "fields",
            "type": "array",
            "index": 20,
            "arrayItems": {
              "name": "field",
              "type": "record",
              "typeRef": "field"
            }
          }
        ]
      }
    }
  ]
}
            """)
            .build());

    }
}
```
```yaml
resources:
  testAspectTypeFull:
    type: gcp:dataplex:AspectType
    name: test_aspect_type_full
    properties:
      aspectTypeId: aspect-type-full
      project: my-project-name
      location: us-central1
      labels:
        tag: test-tf
      displayName: terraform aspect type
      description: aspect type created by Terraform
      metadataTemplate: |
        {
          "type": "record",
          "name": "Schema",
          "recordFields": [
            {
              "name": "fields",
              "type": "array",
              "index": 1,
              "arrayItems": {
                "name": "field",
                "type": "record",
                "typeId": "field",
                "recordFields": [
                  {
                    "name": "name",
                    "type": "string",
                    "index": 1,
                    "constraints": {
                      "required": true
                    }
                  },
                  {
                    "name": "description",
                    "type": "string",
                    "index": 2
                  },
                  {
                    "name": "dataType",
                    "type": "string",
                    "index": 3,
                    "constraints": {
                      "required": true
                    }
                  },
                  {
                    "name": "metadataType",
                    "type": "enum",
                    "index": 4,
                    "constraints": {
                      "required": true
                    },
                    "enumValues": [
                      {
                        "name": "BOOLEAN",
                        "index": 1
                      },
                      {
                        "name": "NUMBER",
                        "index": 2
                      },
                      {
                        "name": "STRING",
                        "index": 3
                      },
                      {
                        "name": "BYTES",
                        "index": 4
                      },
                      {
                        "name": "DATETIME",
                        "index": 5
                      },
                      {
                        "name": "TIMESTAMP",
                        "index": 6
                      },
                      {
                        "name": "GEOSPATIAL",
                        "index": 7
                      },
                      {
                        "name": "STRUCT",
                        "index": 8
                      },
                      {
                        "name": "OTHER",
                        "index": 100
                      }
                    ]
                  },
                  {
                    "name": "mode",
                    "type": "enum",
                    "index": 5,
                    "enumValues": [
                      {
                        "name": "NULLABLE",
                        "index": 1
                      },
                      {
                        "name": "REPEATED",
                        "index": 2
                      },
                      {
                        "name": "REQUIRED",
                        "index": 3
                      }
                    ]
                  },
                  {
                    "name": "defaultValue",
                    "type": "string",
                    "index": 6
                  },
                  {
                    "name": "annotations",
                    "type": "map",
                    "index": 7,
                    "mapItems": {
                      "name": "label",
                      "type": "string"
                    }
                  },
                  {
                    "name": "fields",
                    "type": "array",
                    "index": 20,
                    "arrayItems": {
                      "name": "field",
                      "type": "record",
                      "typeRef": "field"
                    }
                  }
                ]
              }
            }
          ]
        }
```
<!--End PulumiCodeChooser -->

## Import

AspectType can be imported using any of these accepted formats:

* `projects/{{project}}/locations/{{location}}/aspectTypes/{{aspect_type_id}}`

* `{{project}}/{{location}}/{{aspect_type_id}}`

* `{{location}}/{{aspect_type_id}}`

When using the `pulumi import` command, AspectType can be imported using one of the formats above. For example:

```sh
$ pulumi import gcp:dataplex/aspectType:AspectType default projects/{{project}}/locations/{{location}}/aspectTypes/{{aspect_type_id}}
```

```sh
$ pulumi import gcp:dataplex/aspectType:AspectType default {{project}}/{{location}}/{{aspect_type_id}}
```

```sh
$ pulumi import gcp:dataplex/aspectType:AspectType default {{location}}/{{aspect_type_id}}
```

=
aspectTypeIdB" 'The aspect type id of the aspect type.
4
descriptionB" Description of the AspectType.
1
displayNameB" User friendly display name.

labelsB2" ïUser-defined labels for the AspectType.

**Note**: This field is non-authoritative, and will only manage the labels present in your configuration.
Please refer to the field `effective_labels` for all of the labels present on the resource.
E
locationB" 3The location where aspect type will be created in.
:
metadataTemplateB"  MetadataTemplate of the Aspect.
{
projectB" jThe ID of the project in which the resource belongs.
If it is not provided, the provider project is used.
"=
aspectTypeIdB" 'The aspect type id of the aspect type.
"<

createTime" *The time when the AspectType was created.
"4
descriptionB" Description of the AspectType.
"1
displayNameB" User friendly display name.
"¦
effectiveLabels2" All of labels (key/value pairs) present on the resource in GCP, including the labels configured through Pulumi, other clients and services.
"
labelsB2" ïUser-defined labels for the AspectType.

**Note**: This field is non-authoritative, and will only manage the labels present in your configuration.
Please refer to the field `effective_labels` for all of the labels present on the resource.
"E
locationB" 3The location where aspect type will be created in.
":
metadataTemplateB"  MetadataTemplate of the Aspect.
"
name" The relative resource name of the AspectType, of the form: projects/{project_number}/locations/{location_id}/aspectTypes/{aspect_type_id}
"y
project" jThe ID of the project in which the resource belongs.
If it is not provided, the provider project is used.
"
pulumiLabels2" mThe combination of labels configured directly on the resource
and default labels configured on the provider.
"
transferStatus" mDenotes the transfer status of the Aspect Type. It is unspecified
for Aspect Type created from Dataplex API.
"
uid" System generated globally unique ID for the AspectType. This ID will be different if the AspectType is deleted and re-created with the same name.
"A

updateTime" /The time when the AspectType was last updated.
*­î
X
dataplexAspectTypeIamBinding6gcp:dataplex/aspectTypeIamBinding:AspectTypeIamBindingÊThree different resources help you manage your IAM policy for Dataplex AspectType. Each of these resources serves a different use case:

* `gcp.dataplex.AspectTypeIamPolicy`: Authoritative. Sets the IAM policy for the aspecttype and replaces any existing policy already attached.
* `gcp.dataplex.AspectTypeIamBinding`: Authoritative for a given role. Updates the IAM policy to grant a role to a list of members. Other roles within the IAM policy for the aspecttype are preserved.
* `gcp.dataplex.AspectTypeIamMember`: Non-authoritative. Updates the IAM policy to grant a role to a new member. Other members for the role for the aspecttype are preserved.

A data source can be used to retrieve policy data in advent you do not need creation

* `gcp.dataplex.AspectTypeIamPolicy`: Retrieves the IAM policy for the aspecttype

> **Note:** `gcp.dataplex.AspectTypeIamPolicy` **cannot** be used in conjunction with `gcp.dataplex.AspectTypeIamBinding` and `gcp.dataplex.AspectTypeIamMember` or they will fight over what your policy should be.

> **Note:** `gcp.dataplex.AspectTypeIamBinding` resources **can be** used in conjunction with `gcp.dataplex.AspectTypeIamMember` resources **only if** they do not grant privilege to the same role.



## gcp.dataplex.AspectTypeIamPolicy

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const admin = gcp.organizations.getIAMPolicy({
    bindings: [{
        role: "roles/viewer",
        members: ["user:jane@example.com"],
    }],
});
const policy = new gcp.dataplex.AspectTypeIamPolicy("policy", {
    project: testAspectTypeBasic.project,
    location: testAspectTypeBasic.location,
    aspectTypeId: testAspectTypeBasic.aspectTypeId,
    policyData: admin.then(admin => admin.policyData),
});
```
```python
import pulumi
import pulumi_gcp as gcp

admin = gcp.organizations.get_iam_policy(bindings=[{
    "role": "roles/viewer",
    "members": ["user:jane@example.com"],
}])
policy = gcp.dataplex.AspectTypeIamPolicy("policy",
    project=test_aspect_type_basic["project"],
    location=test_aspect_type_basic["location"],
    aspect_type_id=test_aspect_type_basic["aspectTypeId"],
    policy_data=admin.policy_data)
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var admin = Gcp.Organizations.GetIAMPolicy.Invoke(new()
    {
        Bindings = new[]
        {
            new Gcp.Organizations.Inputs.GetIAMPolicyBindingInputArgs
            {
                Role = "roles/viewer",
                Members = new[]
                {
                    "user:jane@example.com",
                },
            },
        },
    });

    var policy = new Gcp.DataPlex.AspectTypeIamPolicy("policy", new()
    {
        Project = testAspectTypeBasic.Project,
        Location = testAspectTypeBasic.Location,
        AspectTypeId = testAspectTypeBasic.AspectTypeId,
        PolicyData = admin.Apply(getIAMPolicyResult => getIAMPolicyResult.PolicyData),
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/dataplex"
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/organizations"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		admin, err := organizations.LookupIAMPolicy(ctx, &organizations.LookupIAMPolicyArgs{
			Bindings: []organizations.GetIAMPolicyBinding{
				{
					Role: "roles/viewer",
					Members: []string{
						"user:jane@example.com",
					},
				},
			},
		}, nil)
		if err != nil {
			return err
		}
		_, err = dataplex.NewAspectTypeIamPolicy(ctx, "policy", &dataplex.AspectTypeIamPolicyArgs{
			Project:      pulumi.Any(testAspectTypeBasic.Project),
			Location:     pulumi.Any(testAspectTypeBasic.Location),
			AspectTypeId: pulumi.Any(testAspectTypeBasic.AspectTypeId),
			PolicyData:   pulumi.String(admin.PolicyData),
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.organizations.OrganizationsFunctions;
import com.pulumi.gcp.organizations.inputs.GetIAMPolicyArgs;
import com.pulumi.gcp.dataplex.AspectTypeIamPolicy;
import com.pulumi.gcp.dataplex.AspectTypeIamPolicyArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        final var admin = OrganizationsFunctions.getIAMPolicy(GetIAMPolicyArgs.builder()
            .bindings(GetIAMPolicyBindingArgs.builder()
                .role("roles/viewer")
                .members("user:jane@example.com")
                .build())
            .build());

        var policy = new AspectTypeIamPolicy("policy", AspectTypeIamPolicyArgs.builder()
            .project(testAspectTypeBasic.project())
            .location(testAspectTypeBasic.location())
            .aspectTypeId(testAspectTypeBasic.aspectTypeId())
            .policyData(admin.applyValue(getIAMPolicyResult -> getIAMPolicyResult.policyData()))
            .build());

    }
}
```
```yaml
resources:
  policy:
    type: gcp:dataplex:AspectTypeIamPolicy
    properties:
      project: ${testAspectTypeBasic.project}
      location: ${testAspectTypeBasic.location}
      aspectTypeId: ${testAspectTypeBasic.aspectTypeId}
      policyData: ${admin.policyData}
variables:
  admin:
    fn::invoke:
      function: gcp:organizations:getIAMPolicy
      arguments:
        bindings:
          - role: roles/viewer
            members:
              - user:jane@example.com
```
<!--End PulumiCodeChooser -->

## gcp.dataplex.AspectTypeIamBinding

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const binding = new gcp.dataplex.AspectTypeIamBinding("binding", {
    project: testAspectTypeBasic.project,
    location: testAspectTypeBasic.location,
    aspectTypeId: testAspectTypeBasic.aspectTypeId,
    role: "roles/viewer",
    members: ["user:jane@example.com"],
});
```
```python
import pulumi
import pulumi_gcp as gcp

binding = gcp.dataplex.AspectTypeIamBinding("binding",
    project=test_aspect_type_basic["project"],
    location=test_aspect_type_basic["location"],
    aspect_type_id=test_aspect_type_basic["aspectTypeId"],
    role="roles/viewer",
    members=["user:jane@example.com"])
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var binding = new Gcp.DataPlex.AspectTypeIamBinding("binding", new()
    {
        Project = testAspectTypeBasic.Project,
        Location = testAspectTypeBasic.Location,
        AspectTypeId = testAspectTypeBasic.AspectTypeId,
        Role = "roles/viewer",
        Members = new[]
        {
            "user:jane@example.com",
        },
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/dataplex"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		_, err := dataplex.NewAspectTypeIamBinding(ctx, "binding", &dataplex.AspectTypeIamBindingArgs{
			Project:      pulumi.Any(testAspectTypeBasic.Project),
			Location:     pulumi.Any(testAspectTypeBasic.Location),
			AspectTypeId: pulumi.Any(testAspectTypeBasic.AspectTypeId),
			Role:         pulumi.String("roles/viewer"),
			Members: pulumi.StringArray{
				pulumi.String("user:jane@example.com"),
			},
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.dataplex.AspectTypeIamBinding;
import com.pulumi.gcp.dataplex.AspectTypeIamBindingArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        var binding = new AspectTypeIamBinding("binding", AspectTypeIamBindingArgs.builder()
            .project(testAspectTypeBasic.project())
            .location(testAspectTypeBasic.location())
            .aspectTypeId(testAspectTypeBasic.aspectTypeId())
            .role("roles/viewer")
            .members("user:jane@example.com")
            .build());

    }
}
```
```yaml
resources:
  binding:
    type: gcp:dataplex:AspectTypeIamBinding
    properties:
      project: ${testAspectTypeBasic.project}
      location: ${testAspectTypeBasic.location}
      aspectTypeId: ${testAspectTypeBasic.aspectTypeId}
      role: roles/viewer
      members:
        - user:jane@example.com
```
<!--End PulumiCodeChooser -->

## gcp.dataplex.AspectTypeIamMember

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const member = new gcp.dataplex.AspectTypeIamMember("member", {
    project: testAspectTypeBasic.project,
    location: testAspectTypeBasic.location,
    aspectTypeId: testAspectTypeBasic.aspectTypeId,
    role: "roles/viewer",
    member: "user:jane@example.com",
});
```
```python
import pulumi
import pulumi_gcp as gcp

member = gcp.dataplex.AspectTypeIamMember("member",
    project=test_aspect_type_basic["project"],
    location=test_aspect_type_basic["location"],
    aspect_type_id=test_aspect_type_basic["aspectTypeId"],
    role="roles/viewer",
    member="user:jane@example.com")
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var member = new Gcp.DataPlex.AspectTypeIamMember("member", new()
    {
        Project = testAspectTypeBasic.Project,
        Location = testAspectTypeBasic.Location,
        AspectTypeId = testAspectTypeBasic.AspectTypeId,
        Role = "roles/viewer",
        Member = "user:jane@example.com",
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/dataplex"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		_, err := dataplex.NewAspectTypeIamMember(ctx, "member", &dataplex.AspectTypeIamMemberArgs{
			Project:      pulumi.Any(testAspectTypeBasic.Project),
			Location:     pulumi.Any(testAspectTypeBasic.Location),
			AspectTypeId: pulumi.Any(testAspectTypeBasic.AspectTypeId),
			Role:         pulumi.String("roles/viewer"),
			Member:       pulumi.String("user:jane@example.com"),
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.dataplex.AspectTypeIamMember;
import com.pulumi.gcp.dataplex.AspectTypeIamMemberArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        var member = new AspectTypeIamMember("member", AspectTypeIamMemberArgs.builder()
            .project(testAspectTypeBasic.project())
            .location(testAspectTypeBasic.location())
            .aspectTypeId(testAspectTypeBasic.aspectTypeId())
            .role("roles/viewer")
            .member("user:jane@example.com")
            .build());

    }
}
```
```yaml
resources:
  member:
    type: gcp:dataplex:AspectTypeIamMember
    properties:
      project: ${testAspectTypeBasic.project}
      location: ${testAspectTypeBasic.location}
      aspectTypeId: ${testAspectTypeBasic.aspectTypeId}
      role: roles/viewer
      member: user:jane@example.com
```
<!--End PulumiCodeChooser -->


## This resource supports User Project Overrides.

-

# IAM policy for Dataplex AspectType
Three different resources help you manage your IAM policy for Dataplex AspectType. Each of these resources serves a different use case:

* `gcp.dataplex.AspectTypeIamPolicy`: Authoritative. Sets the IAM policy for the aspecttype and replaces any existing policy already attached.
* `gcp.dataplex.AspectTypeIamBinding`: Authoritative for a given role. Updates the IAM policy to grant a role to a list of members. Other roles within the IAM policy for the aspecttype are preserved.
* `gcp.dataplex.AspectTypeIamMember`: Non-authoritative. Updates the IAM policy to grant a role to a new member. Other members for the role for the aspecttype are preserved.

A data source can be used to retrieve policy data in advent you do not need creation

* `gcp.dataplex.AspectTypeIamPolicy`: Retrieves the IAM policy for the aspecttype

> **Note:** `gcp.dataplex.AspectTypeIamPolicy` **cannot** be used in conjunction with `gcp.dataplex.AspectTypeIamBinding` and `gcp.dataplex.AspectTypeIamMember` or they will fight over what your policy should be.

> **Note:** `gcp.dataplex.AspectTypeIamBinding` resources **can be** used in conjunction with `gcp.dataplex.AspectTypeIamMember` resources **only if** they do not grant privilege to the same role.



## gcp.dataplex.AspectTypeIamPolicy

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const admin = gcp.organizations.getIAMPolicy({
    bindings: [{
        role: "roles/viewer",
        members: ["user:jane@example.com"],
    }],
});
const policy = new gcp.dataplex.AspectTypeIamPolicy("policy", {
    project: testAspectTypeBasic.project,
    location: testAspectTypeBasic.location,
    aspectTypeId: testAspectTypeBasic.aspectTypeId,
    policyData: admin.then(admin => admin.policyData),
});
```
```python
import pulumi
import pulumi_gcp as gcp

admin = gcp.organizations.get_iam_policy(bindings=[{
    "role": "roles/viewer",
    "members": ["user:jane@example.com"],
}])
policy = gcp.dataplex.AspectTypeIamPolicy("policy",
    project=test_aspect_type_basic["project"],
    location=test_aspect_type_basic["location"],
    aspect_type_id=test_aspect_type_basic["aspectTypeId"],
    policy_data=admin.policy_data)
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var admin = Gcp.Organizations.GetIAMPolicy.Invoke(new()
    {
        Bindings = new[]
        {
            new Gcp.Organizations.Inputs.GetIAMPolicyBindingInputArgs
            {
                Role = "roles/viewer",
                Members = new[]
                {
                    "user:jane@example.com",
                },
            },
        },
    });

    var policy = new Gcp.DataPlex.AspectTypeIamPolicy("policy", new()
    {
        Project = testAspectTypeBasic.Project,
        Location = testAspectTypeBasic.Location,
        AspectTypeId = testAspectTypeBasic.AspectTypeId,
        PolicyData = admin.Apply(getIAMPolicyResult => getIAMPolicyResult.PolicyData),
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/dataplex"
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/organizations"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		admin, err := organizations.LookupIAMPolicy(ctx, &organizations.LookupIAMPolicyArgs{
			Bindings: []organizations.GetIAMPolicyBinding{
				{
					Role: "roles/viewer",
					Members: []string{
						"user:jane@example.com",
					},
				},
			},
		}, nil)
		if err != nil {
			return err
		}
		_, err = dataplex.NewAspectTypeIamPolicy(ctx, "policy", &dataplex.AspectTypeIamPolicyArgs{
			Project:      pulumi.Any(testAspectTypeBasic.Project),
			Location:     pulumi.Any(testAspectTypeBasic.Location),
			AspectTypeId: pulumi.Any(testAspectTypeBasic.AspectTypeId),
			PolicyData:   pulumi.String(admin.PolicyData),
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.organizations.OrganizationsFunctions;
import com.pulumi.gcp.organizations.inputs.GetIAMPolicyArgs;
import com.pulumi.gcp.dataplex.AspectTypeIamPolicy;
import com.pulumi.gcp.dataplex.AspectTypeIamPolicyArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        final var admin = OrganizationsFunctions.getIAMPolicy(GetIAMPolicyArgs.builder()
            .bindings(GetIAMPolicyBindingArgs.builder()
                .role("roles/viewer")
                .members("user:jane@example.com")
                .build())
            .build());

        var policy = new AspectTypeIamPolicy("policy", AspectTypeIamPolicyArgs.builder()
            .project(testAspectTypeBasic.project())
            .location(testAspectTypeBasic.location())
            .aspectTypeId(testAspectTypeBasic.aspectTypeId())
            .policyData(admin.applyValue(getIAMPolicyResult -> getIAMPolicyResult.policyData()))
            .build());

    }
}
```
```yaml
resources:
  policy:
    type: gcp:dataplex:AspectTypeIamPolicy
    properties:
      project: ${testAspectTypeBasic.project}
      location: ${testAspectTypeBasic.location}
      aspectTypeId: ${testAspectTypeBasic.aspectTypeId}
      policyData: ${admin.policyData}
variables:
  admin:
    fn::invoke:
      function: gcp:organizations:getIAMPolicy
      arguments:
        bindings:
          - role: roles/viewer
            members:
              - user:jane@example.com
```
<!--End PulumiCodeChooser -->

## gcp.dataplex.AspectTypeIamBinding

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const binding = new gcp.dataplex.AspectTypeIamBinding("binding", {
    project: testAspectTypeBasic.project,
    location: testAspectTypeBasic.location,
    aspectTypeId: testAspectTypeBasic.aspectTypeId,
    role: "roles/viewer",
    members: ["user:jane@example.com"],
});
```
```python
import pulumi
import pulumi_gcp as gcp

binding = gcp.dataplex.AspectTypeIamBinding("binding",
    project=test_aspect_type_basic["project"],
    location=test_aspect_type_basic["location"],
    aspect_type_id=test_aspect_type_basic["aspectTypeId"],
    role="roles/viewer",
    members=["user:jane@example.com"])
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var binding = new Gcp.DataPlex.AspectTypeIamBinding("binding", new()
    {
        Project = testAspectTypeBasic.Project,
        Location = testAspectTypeBasic.Location,
        AspectTypeId = testAspectTypeBasic.AspectTypeId,
        Role = "roles/viewer",
        Members = new[]
        {
            "user:jane@example.com",
        },
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/dataplex"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		_, err := dataplex.NewAspectTypeIamBinding(ctx, "binding", &dataplex.AspectTypeIamBindingArgs{
			Project:      pulumi.Any(testAspectTypeBasic.Project),
			Location:     pulumi.Any(testAspectTypeBasic.Location),
			AspectTypeId: pulumi.Any(testAspectTypeBasic.AspectTypeId),
			Role:         pulumi.String("roles/viewer"),
			Members: pulumi.StringArray{
				pulumi.String("user:jane@example.com"),
			},
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.dataplex.AspectTypeIamBinding;
import com.pulumi.gcp.dataplex.AspectTypeIamBindingArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        var binding = new AspectTypeIamBinding("binding", AspectTypeIamBindingArgs.builder()
            .project(testAspectTypeBasic.project())
            .location(testAspectTypeBasic.location())
            .aspectTypeId(testAspectTypeBasic.aspectTypeId())
            .role("roles/viewer")
            .members("user:jane@example.com")
            .build());

    }
}
```
```yaml
resources:
  binding:
    type: gcp:dataplex:AspectTypeIamBinding
    properties:
      project: ${testAspectTypeBasic.project}
      location: ${testAspectTypeBasic.location}
      aspectTypeId: ${testAspectTypeBasic.aspectTypeId}
      role: roles/viewer
      members:
        - user:jane@example.com
```
<!--End PulumiCodeChooser -->

## gcp.dataplex.AspectTypeIamMember

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const member = new gcp.dataplex.AspectTypeIamMember("member", {
    project: testAspectTypeBasic.project,
    location: testAspectTypeBasic.location,
    aspectTypeId: testAspectTypeBasic.aspectTypeId,
    role: "roles/viewer",
    member: "user:jane@example.com",
});
```
```python
import pulumi
import pulumi_gcp as gcp

member = gcp.dataplex.AspectTypeIamMember("member",
    project=test_aspect_type_basic["project"],
    location=test_aspect_type_basic["location"],
    aspect_type_id=test_aspect_type_basic["aspectTypeId"],
    role="roles/viewer",
    member="user:jane@example.com")
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var member = new Gcp.DataPlex.AspectTypeIamMember("member", new()
    {
        Project = testAspectTypeBasic.Project,
        Location = testAspectTypeBasic.Location,
        AspectTypeId = testAspectTypeBasic.AspectTypeId,
        Role = "roles/viewer",
        Member = "user:jane@example.com",
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/dataplex"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		_, err := dataplex.NewAspectTypeIamMember(ctx, "member", &dataplex.AspectTypeIamMemberArgs{
			Project:      pulumi.Any(testAspectTypeBasic.Project),
			Location:     pulumi.Any(testAspectTypeBasic.Location),
			AspectTypeId: pulumi.Any(testAspectTypeBasic.AspectTypeId),
			Role:         pulumi.String("roles/viewer"),
			Member:       pulumi.String("user:jane@example.com"),
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.dataplex.AspectTypeIamMember;
import com.pulumi.gcp.dataplex.AspectTypeIamMemberArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        var member = new AspectTypeIamMember("member", AspectTypeIamMemberArgs.builder()
            .project(testAspectTypeBasic.project())
            .location(testAspectTypeBasic.location())
            .aspectTypeId(testAspectTypeBasic.aspectTypeId())
            .role("roles/viewer")
            .member("user:jane@example.com")
            .build());

    }
}
```
```yaml
resources:
  member:
    type: gcp:dataplex:AspectTypeIamMember
    properties:
      project: ${testAspectTypeBasic.project}
      location: ${testAspectTypeBasic.location}
      aspectTypeId: ${testAspectTypeBasic.aspectTypeId}
      role: roles/viewer
      member: user:jane@example.com
```
<!--End PulumiCodeChooser -->

## Import

For all import syntaxes, the "resource in question" can take any of the following forms:

* projects/{{project}}/locations/{{location}}/aspectTypes/{{aspect_type_id}}

* {{project}}/{{location}}/{{aspect_type_id}}

* {{location}}/{{aspect_type_id}}

* {{aspect_type_id}}

Any variables not passed in the import command will be taken from the provider configuration.

Dataplex aspecttype IAM resources can be imported using the resource identifiers, role, and member.

IAM member imports use space-delimited identifiers: the resource in question, the role, and the member identity, e.g.

```sh
$ pulumi import gcp:dataplex/aspectTypeIamBinding:AspectTypeIamBinding editor "projects/{{project}}/locations/{{location}}/aspectTypes/{{aspect_type_id}} roles/viewer user:jane@example.com"
```

IAM binding imports use space-delimited identifiers: the resource in question and the role, e.g.

```sh
$ pulumi import gcp:dataplex/aspectTypeIamBinding:AspectTypeIamBinding editor "projects/{{project}}/locations/{{location}}/aspectTypes/{{aspect_type_id}} roles/viewer"
```

IAM policy imports use the identifier of the resource in question, e.g.

```sh
$ pulumi import gcp:dataplex/aspectTypeIamBinding:AspectTypeIamBinding editor projects/{{project}}/locations/{{location}}/aspectTypes/{{aspect_type_id}}
```

-> **Custom Roles** If you're importing a IAM resource with a custom role, make sure to use the

 full name of the custom role, e.g. `[projects/my-project|organizations/my-org]/roles/my-custom-role`.


aspectTypeId" 
	conditionyBw:u
s
dataplexAspectTypeIamBindingConditionHgcp:dataplex/AspectTypeIamBindingCondition:AspectTypeIamBindingConditionØ
locationB" ÅThe location where aspect type will be created in.
Used to find the parent resource to bind the IAM policy to. If not specified,
the value will be parsed from the identifier of the parent resource. If no location is provided in the parent identifier and no
location is specified, it is taken from the provider configuration.
Ö	
members*" Ä	Identities that will be granted the privilege in `role`.
Each entry can have one of the following values:
* **allUsers**: A special identifier that represents anyone who is on the internet; with or without a Google account.
* **allAuthenticatedUsers**: A special identifier that represents anyone who is authenticated with a Google account or a service account.
* **user:{emailid}**: An email address that represents a specific Google account. For example, alice@gmail.com or joe@example.com.
* **serviceAccount:{emailid}**: An email address that represents a service account. For example, my-other-app@appspot.gserviceaccount.com.
* **group:{emailid}**: An email address that represents a Google group. For example, admins@example.com.
* **domain:{domain}**: A G Suite domain (primary, instead of alias) name that represents all the users of that domain. For example, google.com or example.com.
* **projectOwner:projectid**: Owners of the given project. For example, "projectOwner:my-example-project"
* **projectEditor:projectid**: Editors of the given project. For example, "projectEditor:my-example-project"
* **projectViewer:projectid**: Viewers of the given project. For example, "projectViewer:my-example-project"

projectB" The ID of the project in which the resource belongs.
If it is not provided, the project will be parsed from the identifier of the parent resource. If no project is provided in the parent identifier and no project is specified, the provider project is used.
Ú
role" ÍThe role that should be applied. Only one
`gcp.dataplex.AspectTypeIamBinding` can be used per role. Note that custom roles must be of the format
`[projects|organizations]/{parent-name}/roles/{role-name}`.
"
aspectTypeId" "
	conditionyBw:u
s
dataplexAspectTypeIamBindingConditionHgcp:dataplex/AspectTypeIamBindingCondition:AspectTypeIamBindingCondition"3
etag" '(Computed) The etag of the IAM policy.
"Ö
location" ÅThe location where aspect type will be created in.
Used to find the parent resource to bind the IAM policy to. If not specified,
the value will be parsed from the identifier of the parent resource. If no location is provided in the parent identifier and no
location is specified, it is taken from the provider configuration.
"Ö	
members*" Ä	Identities that will be granted the privilege in `role`.
Each entry can have one of the following values:
* **allUsers**: A special identifier that represents anyone who is on the internet; with or without a Google account.
* **allAuthenticatedUsers**: A special identifier that represents anyone who is authenticated with a Google account or a service account.
* **user:{emailid}**: An email address that represents a specific Google account. For example, alice@gmail.com or joe@example.com.
* **serviceAccount:{emailid}**: An email address that represents a service account. For example, my-other-app@appspot.gserviceaccount.com.
* **group:{emailid}**: An email address that represents a Google group. For example, admins@example.com.
* **domain:{domain}**: A G Suite domain (primary, instead of alias) name that represents all the users of that domain. For example, google.com or example.com.
* **projectOwner:projectid**: Owners of the given project. For example, "projectOwner:my-example-project"
* **projectEditor:projectid**: Editors of the given project. For example, "projectEditor:my-example-project"
* **projectViewer:projectid**: Viewers of the given project. For example, "projectViewer:my-example-project"
"
project" The ID of the project in which the resource belongs.
If it is not provided, the project will be parsed from the identifier of the parent resource. If no project is provided in the parent identifier and no project is specified, the provider project is used.
"Ú
role" ÍThe role that should be applied. Only one
`gcp.dataplex.AspectTypeIamBinding` can be used per role. Note that custom roles must be of the format
`[projects|organizations]/{parent-name}/roles/{role-name}`.
*î
U
dataplexAspectTypeIamMember4gcp:dataplex/aspectTypeIamMember:AspectTypeIamMemberÊThree different resources help you manage your IAM policy for Dataplex AspectType. Each of these resources serves a different use case:

* `gcp.dataplex.AspectTypeIamPolicy`: Authoritative. Sets the IAM policy for the aspecttype and replaces any existing policy already attached.
* `gcp.dataplex.AspectTypeIamBinding`: Authoritative for a given role. Updates the IAM policy to grant a role to a list of members. Other roles within the IAM policy for the aspecttype are preserved.
* `gcp.dataplex.AspectTypeIamMember`: Non-authoritative. Updates the IAM policy to grant a role to a new member. Other members for the role for the aspecttype are preserved.

A data source can be used to retrieve policy data in advent you do not need creation

* `gcp.dataplex.AspectTypeIamPolicy`: Retrieves the IAM policy for the aspecttype

> **Note:** `gcp.dataplex.AspectTypeIamPolicy` **cannot** be used in conjunction with `gcp.dataplex.AspectTypeIamBinding` and `gcp.dataplex.AspectTypeIamMember` or they will fight over what your policy should be.

> **Note:** `gcp.dataplex.AspectTypeIamBinding` resources **can be** used in conjunction with `gcp.dataplex.AspectTypeIamMember` resources **only if** they do not grant privilege to the same role.



## gcp.dataplex.AspectTypeIamPolicy

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const admin = gcp.organizations.getIAMPolicy({
    bindings: [{
        role: "roles/viewer",
        members: ["user:jane@example.com"],
    }],
});
const policy = new gcp.dataplex.AspectTypeIamPolicy("policy", {
    project: testAspectTypeBasic.project,
    location: testAspectTypeBasic.location,
    aspectTypeId: testAspectTypeBasic.aspectTypeId,
    policyData: admin.then(admin => admin.policyData),
});
```
```python
import pulumi
import pulumi_gcp as gcp

admin = gcp.organizations.get_iam_policy(bindings=[{
    "role": "roles/viewer",
    "members": ["user:jane@example.com"],
}])
policy = gcp.dataplex.AspectTypeIamPolicy("policy",
    project=test_aspect_type_basic["project"],
    location=test_aspect_type_basic["location"],
    aspect_type_id=test_aspect_type_basic["aspectTypeId"],
    policy_data=admin.policy_data)
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var admin = Gcp.Organizations.GetIAMPolicy.Invoke(new()
    {
        Bindings = new[]
        {
            new Gcp.Organizations.Inputs.GetIAMPolicyBindingInputArgs
            {
                Role = "roles/viewer",
                Members = new[]
                {
                    "user:jane@example.com",
                },
            },
        },
    });

    var policy = new Gcp.DataPlex.AspectTypeIamPolicy("policy", new()
    {
        Project = testAspectTypeBasic.Project,
        Location = testAspectTypeBasic.Location,
        AspectTypeId = testAspectTypeBasic.AspectTypeId,
        PolicyData = admin.Apply(getIAMPolicyResult => getIAMPolicyResult.PolicyData),
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/dataplex"
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/organizations"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		admin, err := organizations.LookupIAMPolicy(ctx, &organizations.LookupIAMPolicyArgs{
			Bindings: []organizations.GetIAMPolicyBinding{
				{
					Role: "roles/viewer",
					Members: []string{
						"user:jane@example.com",
					},
				},
			},
		}, nil)
		if err != nil {
			return err
		}
		_, err = dataplex.NewAspectTypeIamPolicy(ctx, "policy", &dataplex.AspectTypeIamPolicyArgs{
			Project:      pulumi.Any(testAspectTypeBasic.Project),
			Location:     pulumi.Any(testAspectTypeBasic.Location),
			AspectTypeId: pulumi.Any(testAspectTypeBasic.AspectTypeId),
			PolicyData:   pulumi.String(admin.PolicyData),
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.organizations.OrganizationsFunctions;
import com.pulumi.gcp.organizations.inputs.GetIAMPolicyArgs;
import com.pulumi.gcp.dataplex.AspectTypeIamPolicy;
import com.pulumi.gcp.dataplex.AspectTypeIamPolicyArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        final var admin = OrganizationsFunctions.getIAMPolicy(GetIAMPolicyArgs.builder()
            .bindings(GetIAMPolicyBindingArgs.builder()
                .role("roles/viewer")
                .members("user:jane@example.com")
                .build())
            .build());

        var policy = new AspectTypeIamPolicy("policy", AspectTypeIamPolicyArgs.builder()
            .project(testAspectTypeBasic.project())
            .location(testAspectTypeBasic.location())
            .aspectTypeId(testAspectTypeBasic.aspectTypeId())
            .policyData(admin.applyValue(getIAMPolicyResult -> getIAMPolicyResult.policyData()))
            .build());

    }
}
```
```yaml
resources:
  policy:
    type: gcp:dataplex:AspectTypeIamPolicy
    properties:
      project: ${testAspectTypeBasic.project}
      location: ${testAspectTypeBasic.location}
      aspectTypeId: ${testAspectTypeBasic.aspectTypeId}
      policyData: ${admin.policyData}
variables:
  admin:
    fn::invoke:
      function: gcp:organizations:getIAMPolicy
      arguments:
        bindings:
          - role: roles/viewer
            members:
              - user:jane@example.com
```
<!--End PulumiCodeChooser -->

## gcp.dataplex.AspectTypeIamBinding

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const binding = new gcp.dataplex.AspectTypeIamBinding("binding", {
    project: testAspectTypeBasic.project,
    location: testAspectTypeBasic.location,
    aspectTypeId: testAspectTypeBasic.aspectTypeId,
    role: "roles/viewer",
    members: ["user:jane@example.com"],
});
```
```python
import pulumi
import pulumi_gcp as gcp

binding = gcp.dataplex.AspectTypeIamBinding("binding",
    project=test_aspect_type_basic["project"],
    location=test_aspect_type_basic["location"],
    aspect_type_id=test_aspect_type_basic["aspectTypeId"],
    role="roles/viewer",
    members=["user:jane@example.com"])
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var binding = new Gcp.DataPlex.AspectTypeIamBinding("binding", new()
    {
        Project = testAspectTypeBasic.Project,
        Location = testAspectTypeBasic.Location,
        AspectTypeId = testAspectTypeBasic.AspectTypeId,
        Role = "roles/viewer",
        Members = new[]
        {
            "user:jane@example.com",
        },
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/dataplex"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		_, err := dataplex.NewAspectTypeIamBinding(ctx, "binding", &dataplex.AspectTypeIamBindingArgs{
			Project:      pulumi.Any(testAspectTypeBasic.Project),
			Location:     pulumi.Any(testAspectTypeBasic.Location),
			AspectTypeId: pulumi.Any(testAspectTypeBasic.AspectTypeId),
			Role:         pulumi.String("roles/viewer"),
			Members: pulumi.StringArray{
				pulumi.String("user:jane@example.com"),
			},
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.dataplex.AspectTypeIamBinding;
import com.pulumi.gcp.dataplex.AspectTypeIamBindingArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        var binding = new AspectTypeIamBinding("binding", AspectTypeIamBindingArgs.builder()
            .project(testAspectTypeBasic.project())
            .location(testAspectTypeBasic.location())
            .aspectTypeId(testAspectTypeBasic.aspectTypeId())
            .role("roles/viewer")
            .members("user:jane@example.com")
            .build());

    }
}
```
```yaml
resources:
  binding:
    type: gcp:dataplex:AspectTypeIamBinding
    properties:
      project: ${testAspectTypeBasic.project}
      location: ${testAspectTypeBasic.location}
      aspectTypeId: ${testAspectTypeBasic.aspectTypeId}
      role: roles/viewer
      members:
        - user:jane@example.com
```
<!--End PulumiCodeChooser -->

## gcp.dataplex.AspectTypeIamMember

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const member = new gcp.dataplex.AspectTypeIamMember("member", {
    project: testAspectTypeBasic.project,
    location: testAspectTypeBasic.location,
    aspectTypeId: testAspectTypeBasic.aspectTypeId,
    role: "roles/viewer",
    member: "user:jane@example.com",
});
```
```python
import pulumi
import pulumi_gcp as gcp

member = gcp.dataplex.AspectTypeIamMember("member",
    project=test_aspect_type_basic["project"],
    location=test_aspect_type_basic["location"],
    aspect_type_id=test_aspect_type_basic["aspectTypeId"],
    role="roles/viewer",
    member="user:jane@example.com")
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var member = new Gcp.DataPlex.AspectTypeIamMember("member", new()
    {
        Project = testAspectTypeBasic.Project,
        Location = testAspectTypeBasic.Location,
        AspectTypeId = testAspectTypeBasic.AspectTypeId,
        Role = "roles/viewer",
        Member = "user:jane@example.com",
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/dataplex"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		_, err := dataplex.NewAspectTypeIamMember(ctx, "member", &dataplex.AspectTypeIamMemberArgs{
			Project:      pulumi.Any(testAspectTypeBasic.Project),
			Location:     pulumi.Any(testAspectTypeBasic.Location),
			AspectTypeId: pulumi.Any(testAspectTypeBasic.AspectTypeId),
			Role:         pulumi.String("roles/viewer"),
			Member:       pulumi.String("user:jane@example.com"),
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.dataplex.AspectTypeIamMember;
import com.pulumi.gcp.dataplex.AspectTypeIamMemberArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        var member = new AspectTypeIamMember("member", AspectTypeIamMemberArgs.builder()
            .project(testAspectTypeBasic.project())
            .location(testAspectTypeBasic.location())
            .aspectTypeId(testAspectTypeBasic.aspectTypeId())
            .role("roles/viewer")
            .member("user:jane@example.com")
            .build());

    }
}
```
```yaml
resources:
  member:
    type: gcp:dataplex:AspectTypeIamMember
    properties:
      project: ${testAspectTypeBasic.project}
      location: ${testAspectTypeBasic.location}
      aspectTypeId: ${testAspectTypeBasic.aspectTypeId}
      role: roles/viewer
      member: user:jane@example.com
```
<!--End PulumiCodeChooser -->


## This resource supports User Project Overrides.

-

# IAM policy for Dataplex AspectType
Three different resources help you manage your IAM policy for Dataplex AspectType. Each of these resources serves a different use case:

* `gcp.dataplex.AspectTypeIamPolicy`: Authoritative. Sets the IAM policy for the aspecttype and replaces any existing policy already attached.
* `gcp.dataplex.AspectTypeIamBinding`: Authoritative for a given role. Updates the IAM policy to grant a role to a list of members. Other roles within the IAM policy for the aspecttype are preserved.
* `gcp.dataplex.AspectTypeIamMember`: Non-authoritative. Updates the IAM policy to grant a role to a new member. Other members for the role for the aspecttype are preserved.

A data source can be used to retrieve policy data in advent you do not need creation

* `gcp.dataplex.AspectTypeIamPolicy`: Retrieves the IAM policy for the aspecttype

> **Note:** `gcp.dataplex.AspectTypeIamPolicy` **cannot** be used in conjunction with `gcp.dataplex.AspectTypeIamBinding` and `gcp.dataplex.AspectTypeIamMember` or they will fight over what your policy should be.

> **Note:** `gcp.dataplex.AspectTypeIamBinding` resources **can be** used in conjunction with `gcp.dataplex.AspectTypeIamMember` resources **only if** they do not grant privilege to the same role.



## gcp.dataplex.AspectTypeIamPolicy

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const admin = gcp.organizations.getIAMPolicy({
    bindings: [{
        role: "roles/viewer",
        members: ["user:jane@example.com"],
    }],
});
const policy = new gcp.dataplex.AspectTypeIamPolicy("policy", {
    project: testAspectTypeBasic.project,
    location: testAspectTypeBasic.location,
    aspectTypeId: testAspectTypeBasic.aspectTypeId,
    policyData: admin.then(admin => admin.policyData),
});
```
```python
import pulumi
import pulumi_gcp as gcp

admin = gcp.organizations.get_iam_policy(bindings=[{
    "role": "roles/viewer",
    "members": ["user:jane@example.com"],
}])
policy = gcp.dataplex.AspectTypeIamPolicy("policy",
    project=test_aspect_type_basic["project"],
    location=test_aspect_type_basic["location"],
    aspect_type_id=test_aspect_type_basic["aspectTypeId"],
    policy_data=admin.policy_data)
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var admin = Gcp.Organizations.GetIAMPolicy.Invoke(new()
    {
        Bindings = new[]
        {
            new Gcp.Organizations.Inputs.GetIAMPolicyBindingInputArgs
            {
                Role = "roles/viewer",
                Members = new[]
                {
                    "user:jane@example.com",
                },
            },
        },
    });

    var policy = new Gcp.DataPlex.AspectTypeIamPolicy("policy", new()
    {
        Project = testAspectTypeBasic.Project,
        Location = testAspectTypeBasic.Location,
        AspectTypeId = testAspectTypeBasic.AspectTypeId,
        PolicyData = admin.Apply(getIAMPolicyResult => getIAMPolicyResult.PolicyData),
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/dataplex"
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/organizations"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		admin, err := organizations.LookupIAMPolicy(ctx, &organizations.LookupIAMPolicyArgs{
			Bindings: []organizations.GetIAMPolicyBinding{
				{
					Role: "roles/viewer",
					Members: []string{
						"user:jane@example.com",
					},
				},
			},
		}, nil)
		if err != nil {
			return err
		}
		_, err = dataplex.NewAspectTypeIamPolicy(ctx, "policy", &dataplex.AspectTypeIamPolicyArgs{
			Project:      pulumi.Any(testAspectTypeBasic.Project),
			Location:     pulumi.Any(testAspectTypeBasic.Location),
			AspectTypeId: pulumi.Any(testAspectTypeBasic.AspectTypeId),
			PolicyData:   pulumi.String(admin.PolicyData),
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.organizations.OrganizationsFunctions;
import com.pulumi.gcp.organizations.inputs.GetIAMPolicyArgs;
import com.pulumi.gcp.dataplex.AspectTypeIamPolicy;
import com.pulumi.gcp.dataplex.AspectTypeIamPolicyArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        final var admin = OrganizationsFunctions.getIAMPolicy(GetIAMPolicyArgs.builder()
            .bindings(GetIAMPolicyBindingArgs.builder()
                .role("roles/viewer")
                .members("user:jane@example.com")
                .build())
            .build());

        var policy = new AspectTypeIamPolicy("policy", AspectTypeIamPolicyArgs.builder()
            .project(testAspectTypeBasic.project())
            .location(testAspectTypeBasic.location())
            .aspectTypeId(testAspectTypeBasic.aspectTypeId())
            .policyData(admin.applyValue(getIAMPolicyResult -> getIAMPolicyResult.policyData()))
            .build());

    }
}
```
```yaml
resources:
  policy:
    type: gcp:dataplex:AspectTypeIamPolicy
    properties:
      project: ${testAspectTypeBasic.project}
      location: ${testAspectTypeBasic.location}
      aspectTypeId: ${testAspectTypeBasic.aspectTypeId}
      policyData: ${admin.policyData}
variables:
  admin:
    fn::invoke:
      function: gcp:organizations:getIAMPolicy
      arguments:
        bindings:
          - role: roles/viewer
            members:
              - user:jane@example.com
```
<!--End PulumiCodeChooser -->

## gcp.dataplex.AspectTypeIamBinding

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const binding = new gcp.dataplex.AspectTypeIamBinding("binding", {
    project: testAspectTypeBasic.project,
    location: testAspectTypeBasic.location,
    aspectTypeId: testAspectTypeBasic.aspectTypeId,
    role: "roles/viewer",
    members: ["user:jane@example.com"],
});
```
```python
import pulumi
import pulumi_gcp as gcp

binding = gcp.dataplex.AspectTypeIamBinding("binding",
    project=test_aspect_type_basic["project"],
    location=test_aspect_type_basic["location"],
    aspect_type_id=test_aspect_type_basic["aspectTypeId"],
    role="roles/viewer",
    members=["user:jane@example.com"])
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var binding = new Gcp.DataPlex.AspectTypeIamBinding("binding", new()
    {
        Project = testAspectTypeBasic.Project,
        Location = testAspectTypeBasic.Location,
        AspectTypeId = testAspectTypeBasic.AspectTypeId,
        Role = "roles/viewer",
        Members = new[]
        {
            "user:jane@example.com",
        },
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/dataplex"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		_, err := dataplex.NewAspectTypeIamBinding(ctx, "binding", &dataplex.AspectTypeIamBindingArgs{
			Project:      pulumi.Any(testAspectTypeBasic.Project),
			Location:     pulumi.Any(testAspectTypeBasic.Location),
			AspectTypeId: pulumi.Any(testAspectTypeBasic.AspectTypeId),
			Role:         pulumi.String("roles/viewer"),
			Members: pulumi.StringArray{
				pulumi.String("user:jane@example.com"),
			},
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.dataplex.AspectTypeIamBinding;
import com.pulumi.gcp.dataplex.AspectTypeIamBindingArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        var binding = new AspectTypeIamBinding("binding", AspectTypeIamBindingArgs.builder()
            .project(testAspectTypeBasic.project())
            .location(testAspectTypeBasic.location())
            .aspectTypeId(testAspectTypeBasic.aspectTypeId())
            .role("roles/viewer")
            .members("user:jane@example.com")
            .build());

    }
}
```
```yaml
resources:
  binding:
    type: gcp:dataplex:AspectTypeIamBinding
    properties:
      project: ${testAspectTypeBasic.project}
      location: ${testAspectTypeBasic.location}
      aspectTypeId: ${testAspectTypeBasic.aspectTypeId}
      role: roles/viewer
      members:
        - user:jane@example.com
```
<!--End PulumiCodeChooser -->

## gcp.dataplex.AspectTypeIamMember

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const member = new gcp.dataplex.AspectTypeIamMember("member", {
    project: testAspectTypeBasic.project,
    location: testAspectTypeBasic.location,
    aspectTypeId: testAspectTypeBasic.aspectTypeId,
    role: "roles/viewer",
    member: "user:jane@example.com",
});
```
```python
import pulumi
import pulumi_gcp as gcp

member = gcp.dataplex.AspectTypeIamMember("member",
    project=test_aspect_type_basic["project"],
    location=test_aspect_type_basic["location"],
    aspect_type_id=test_aspect_type_basic["aspectTypeId"],
    role="roles/viewer",
    member="user:jane@example.com")
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var member = new Gcp.DataPlex.AspectTypeIamMember("member", new()
    {
        Project = testAspectTypeBasic.Project,
        Location = testAspectTypeBasic.Location,
        AspectTypeId = testAspectTypeBasic.AspectTypeId,
        Role = "roles/viewer",
        Member = "user:jane@example.com",
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/dataplex"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		_, err := dataplex.NewAspectTypeIamMember(ctx, "member", &dataplex.AspectTypeIamMemberArgs{
			Project:      pulumi.Any(testAspectTypeBasic.Project),
			Location:     pulumi.Any(testAspectTypeBasic.Location),
			AspectTypeId: pulumi.Any(testAspectTypeBasic.AspectTypeId),
			Role:         pulumi.String("roles/viewer"),
			Member:       pulumi.String("user:jane@example.com"),
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.dataplex.AspectTypeIamMember;
import com.pulumi.gcp.dataplex.AspectTypeIamMemberArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        var member = new AspectTypeIamMember("member", AspectTypeIamMemberArgs.builder()
            .project(testAspectTypeBasic.project())
            .location(testAspectTypeBasic.location())
            .aspectTypeId(testAspectTypeBasic.aspectTypeId())
            .role("roles/viewer")
            .member("user:jane@example.com")
            .build());

    }
}
```
```yaml
resources:
  member:
    type: gcp:dataplex:AspectTypeIamMember
    properties:
      project: ${testAspectTypeBasic.project}
      location: ${testAspectTypeBasic.location}
      aspectTypeId: ${testAspectTypeBasic.aspectTypeId}
      role: roles/viewer
      member: user:jane@example.com
```
<!--End PulumiCodeChooser -->

## Import

For all import syntaxes, the "resource in question" can take any of the following forms:

* projects/{{project}}/locations/{{location}}/aspectTypes/{{aspect_type_id}}

* {{project}}/{{location}}/{{aspect_type_id}}

* {{location}}/{{aspect_type_id}}

* {{aspect_type_id}}

Any variables not passed in the import command will be taken from the provider configuration.

Dataplex aspecttype IAM resources can be imported using the resource identifiers, role, and member.

IAM member imports use space-delimited identifiers: the resource in question, the role, and the member identity, e.g.

```sh
$ pulumi import gcp:dataplex/aspectTypeIamMember:AspectTypeIamMember editor "projects/{{project}}/locations/{{location}}/aspectTypes/{{aspect_type_id}} roles/viewer user:jane@example.com"
```

IAM binding imports use space-delimited identifiers: the resource in question and the role, e.g.

```sh
$ pulumi import gcp:dataplex/aspectTypeIamMember:AspectTypeIamMember editor "projects/{{project}}/locations/{{location}}/aspectTypes/{{aspect_type_id}} roles/viewer"
```

IAM policy imports use the identifier of the resource in question, e.g.

```sh
$ pulumi import gcp:dataplex/aspectTypeIamMember:AspectTypeIamMember editor projects/{{project}}/locations/{{location}}/aspectTypes/{{aspect_type_id}}
```

-> **Custom Roles** If you're importing a IAM resource with a custom role, make sure to use the

 full name of the custom role, e.g. `[projects/my-project|organizations/my-org]/roles/my-custom-role`.


aspectTypeId" 
	conditionvBt:r
p
dataplexAspectTypeIamMemberConditionFgcp:dataplex/AspectTypeIamMemberCondition:AspectTypeIamMemberConditionØ
locationB" ÅThe location where aspect type will be created in.
Used to find the parent resource to bind the IAM policy to. If not specified,
the value will be parsed from the identifier of the parent resource. If no location is provided in the parent identifier and no
location is specified, it is taken from the provider configuration.
Ó	
member" Ä	Identities that will be granted the privilege in `role`.
Each entry can have one of the following values:
* **allUsers**: A special identifier that represents anyone who is on the internet; with or without a Google account.
* **allAuthenticatedUsers**: A special identifier that represents anyone who is authenticated with a Google account or a service account.
* **user:{emailid}**: An email address that represents a specific Google account. For example, alice@gmail.com or joe@example.com.
* **serviceAccount:{emailid}**: An email address that represents a service account. For example, my-other-app@appspot.gserviceaccount.com.
* **group:{emailid}**: An email address that represents a Google group. For example, admins@example.com.
* **domain:{domain}**: A G Suite domain (primary, instead of alias) name that represents all the users of that domain. For example, google.com or example.com.
* **projectOwner:projectid**: Owners of the given project. For example, "projectOwner:my-example-project"
* **projectEditor:projectid**: Editors of the given project. For example, "projectEditor:my-example-project"
* **projectViewer:projectid**: Viewers of the given project. For example, "projectViewer:my-example-project"

projectB" The ID of the project in which the resource belongs.
If it is not provided, the project will be parsed from the identifier of the parent resource. If no project is provided in the parent identifier and no project is specified, the provider project is used.
Ú
role" ÍThe role that should be applied. Only one
`gcp.dataplex.AspectTypeIamBinding` can be used per role. Note that custom roles must be of the format
`[projects|organizations]/{parent-name}/roles/{role-name}`.
"
aspectTypeId" "
	conditionvBt:r
p
dataplexAspectTypeIamMemberConditionFgcp:dataplex/AspectTypeIamMemberCondition:AspectTypeIamMemberCondition"3
etag" '(Computed) The etag of the IAM policy.
"Ö
location" ÅThe location where aspect type will be created in.
Used to find the parent resource to bind the IAM policy to. If not specified,
the value will be parsed from the identifier of the parent resource. If no location is provided in the parent identifier and no
location is specified, it is taken from the provider configuration.
"Ó	
member" Ä	Identities that will be granted the privilege in `role`.
Each entry can have one of the following values:
* **allUsers**: A special identifier that represents anyone who is on the internet; with or without a Google account.
* **allAuthenticatedUsers**: A special identifier that represents anyone who is authenticated with a Google account or a service account.
* **user:{emailid}**: An email address that represents a specific Google account. For example, alice@gmail.com or joe@example.com.
* **serviceAccount:{emailid}**: An email address that represents a service account. For example, my-other-app@appspot.gserviceaccount.com.
* **group:{emailid}**: An email address that represents a Google group. For example, admins@example.com.
* **domain:{domain}**: A G Suite domain (primary, instead of alias) name that represents all the users of that domain. For example, google.com or example.com.
* **projectOwner:projectid**: Owners of the given project. For example, "projectOwner:my-example-project"
* **projectEditor:projectid**: Editors of the given project. For example, "projectEditor:my-example-project"
* **projectViewer:projectid**: Viewers of the given project. For example, "projectViewer:my-example-project"
"
project" The ID of the project in which the resource belongs.
If it is not provided, the project will be parsed from the identifier of the parent resource. If no project is provided in the parent identifier and no project is specified, the provider project is used.
"Ú
role" ÍThe role that should be applied. Only one
`gcp.dataplex.AspectTypeIamBinding` can be used per role. Note that custom roles must be of the format
`[projects|organizations]/{parent-name}/roles/{role-name}`.
*èÖ
U
dataplexAspectTypeIamPolicy4gcp:dataplex/aspectTypeIamPolicy:AspectTypeIamPolicyÊThree different resources help you manage your IAM policy for Dataplex AspectType. Each of these resources serves a different use case:

* `gcp.dataplex.AspectTypeIamPolicy`: Authoritative. Sets the IAM policy for the aspecttype and replaces any existing policy already attached.
* `gcp.dataplex.AspectTypeIamBinding`: Authoritative for a given role. Updates the IAM policy to grant a role to a list of members. Other roles within the IAM policy for the aspecttype are preserved.
* `gcp.dataplex.AspectTypeIamMember`: Non-authoritative. Updates the IAM policy to grant a role to a new member. Other members for the role for the aspecttype are preserved.

A data source can be used to retrieve policy data in advent you do not need creation

* `gcp.dataplex.AspectTypeIamPolicy`: Retrieves the IAM policy for the aspecttype

> **Note:** `gcp.dataplex.AspectTypeIamPolicy` **cannot** be used in conjunction with `gcp.dataplex.AspectTypeIamBinding` and `gcp.dataplex.AspectTypeIamMember` or they will fight over what your policy should be.

> **Note:** `gcp.dataplex.AspectTypeIamBinding` resources **can be** used in conjunction with `gcp.dataplex.AspectTypeIamMember` resources **only if** they do not grant privilege to the same role.



## gcp.dataplex.AspectTypeIamPolicy

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const admin = gcp.organizations.getIAMPolicy({
    bindings: [{
        role: "roles/viewer",
        members: ["user:jane@example.com"],
    }],
});
const policy = new gcp.dataplex.AspectTypeIamPolicy("policy", {
    project: testAspectTypeBasic.project,
    location: testAspectTypeBasic.location,
    aspectTypeId: testAspectTypeBasic.aspectTypeId,
    policyData: admin.then(admin => admin.policyData),
});
```
```python
import pulumi
import pulumi_gcp as gcp

admin = gcp.organizations.get_iam_policy(bindings=[{
    "role": "roles/viewer",
    "members": ["user:jane@example.com"],
}])
policy = gcp.dataplex.AspectTypeIamPolicy("policy",
    project=test_aspect_type_basic["project"],
    location=test_aspect_type_basic["location"],
    aspect_type_id=test_aspect_type_basic["aspectTypeId"],
    policy_data=admin.policy_data)
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var admin = Gcp.Organizations.GetIAMPolicy.Invoke(new()
    {
        Bindings = new[]
        {
            new Gcp.Organizations.Inputs.GetIAMPolicyBindingInputArgs
            {
                Role = "roles/viewer",
                Members = new[]
                {
                    "user:jane@example.com",
                },
            },
        },
    });

    var policy = new Gcp.DataPlex.AspectTypeIamPolicy("policy", new()
    {
        Project = testAspectTypeBasic.Project,
        Location = testAspectTypeBasic.Location,
        AspectTypeId = testAspectTypeBasic.AspectTypeId,
        PolicyData = admin.Apply(getIAMPolicyResult => getIAMPolicyResult.PolicyData),
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/dataplex"
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/organizations"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		admin, err := organizations.LookupIAMPolicy(ctx, &organizations.LookupIAMPolicyArgs{
			Bindings: []organizations.GetIAMPolicyBinding{
				{
					Role: "roles/viewer",
					Members: []string{
						"user:jane@example.com",
					},
				},
			},
		}, nil)
		if err != nil {
			return err
		}
		_, err = dataplex.NewAspectTypeIamPolicy(ctx, "policy", &dataplex.AspectTypeIamPolicyArgs{
			Project:      pulumi.Any(testAspectTypeBasic.Project),
			Location:     pulumi.Any(testAspectTypeBasic.Location),
			AspectTypeId: pulumi.Any(testAspectTypeBasic.AspectTypeId),
			PolicyData:   pulumi.String(admin.PolicyData),
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.organizations.OrganizationsFunctions;
import com.pulumi.gcp.organizations.inputs.GetIAMPolicyArgs;
import com.pulumi.gcp.dataplex.AspectTypeIamPolicy;
import com.pulumi.gcp.dataplex.AspectTypeIamPolicyArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        final var admin = OrganizationsFunctions.getIAMPolicy(GetIAMPolicyArgs.builder()
            .bindings(GetIAMPolicyBindingArgs.builder()
                .role("roles/viewer")
                .members("user:jane@example.com")
                .build())
            .build());

        var policy = new AspectTypeIamPolicy("policy", AspectTypeIamPolicyArgs.builder()
            .project(testAspectTypeBasic.project())
            .location(testAspectTypeBasic.location())
            .aspectTypeId(testAspectTypeBasic.aspectTypeId())
            .policyData(admin.applyValue(getIAMPolicyResult -> getIAMPolicyResult.policyData()))
            .build());

    }
}
```
```yaml
resources:
  policy:
    type: gcp:dataplex:AspectTypeIamPolicy
    properties:
      project: ${testAspectTypeBasic.project}
      location: ${testAspectTypeBasic.location}
      aspectTypeId: ${testAspectTypeBasic.aspectTypeId}
      policyData: ${admin.policyData}
variables:
  admin:
    fn::invoke:
      function: gcp:organizations:getIAMPolicy
      arguments:
        bindings:
          - role: roles/viewer
            members:
              - user:jane@example.com
```
<!--End PulumiCodeChooser -->

## gcp.dataplex.AspectTypeIamBinding

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const binding = new gcp.dataplex.AspectTypeIamBinding("binding", {
    project: testAspectTypeBasic.project,
    location: testAspectTypeBasic.location,
    aspectTypeId: testAspectTypeBasic.aspectTypeId,
    role: "roles/viewer",
    members: ["user:jane@example.com"],
});
```
```python
import pulumi
import pulumi_gcp as gcp

binding = gcp.dataplex.AspectTypeIamBinding("binding",
    project=test_aspect_type_basic["project"],
    location=test_aspect_type_basic["location"],
    aspect_type_id=test_aspect_type_basic["aspectTypeId"],
    role="roles/viewer",
    members=["user:jane@example.com"])
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var binding = new Gcp.DataPlex.AspectTypeIamBinding("binding", new()
    {
        Project = testAspectTypeBasic.Project,
        Location = testAspectTypeBasic.Location,
        AspectTypeId = testAspectTypeBasic.AspectTypeId,
        Role = "roles/viewer",
        Members = new[]
        {
            "user:jane@example.com",
        },
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/dataplex"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		_, err := dataplex.NewAspectTypeIamBinding(ctx, "binding", &dataplex.AspectTypeIamBindingArgs{
			Project:      pulumi.Any(testAspectTypeBasic.Project),
			Location:     pulumi.Any(testAspectTypeBasic.Location),
			AspectTypeId: pulumi.Any(testAspectTypeBasic.AspectTypeId),
			Role:         pulumi.String("roles/viewer"),
			Members: pulumi.StringArray{
				pulumi.String("user:jane@example.com"),
			},
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.dataplex.AspectTypeIamBinding;
import com.pulumi.gcp.dataplex.AspectTypeIamBindingArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        var binding = new AspectTypeIamBinding("binding", AspectTypeIamBindingArgs.builder()
            .project(testAspectTypeBasic.project())
            .location(testAspectTypeBasic.location())
            .aspectTypeId(testAspectTypeBasic.aspectTypeId())
            .role("roles/viewer")
            .members("user:jane@example.com")
            .build());

    }
}
```
```yaml
resources:
  binding:
    type: gcp:dataplex:AspectTypeIamBinding
    properties:
      project: ${testAspectTypeBasic.project}
      location: ${testAspectTypeBasic.location}
      aspectTypeId: ${testAspectTypeBasic.aspectTypeId}
      role: roles/viewer
      members:
        - user:jane@example.com
```
<!--End PulumiCodeChooser -->

## gcp.dataplex.AspectTypeIamMember

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const member = new gcp.dataplex.AspectTypeIamMember("member", {
    project: testAspectTypeBasic.project,
    location: testAspectTypeBasic.location,
    aspectTypeId: testAspectTypeBasic.aspectTypeId,
    role: "roles/viewer",
    member: "user:jane@example.com",
});
```
```python
import pulumi
import pulumi_gcp as gcp

member = gcp.dataplex.AspectTypeIamMember("member",
    project=test_aspect_type_basic["project"],
    location=test_aspect_type_basic["location"],
    aspect_type_id=test_aspect_type_basic["aspectTypeId"],
    role="roles/viewer",
    member="user:jane@example.com")
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var member = new Gcp.DataPlex.AspectTypeIamMember("member", new()
    {
        Project = testAspectTypeBasic.Project,
        Location = testAspectTypeBasic.Location,
        AspectTypeId = testAspectTypeBasic.AspectTypeId,
        Role = "roles/viewer",
        Member = "user:jane@example.com",
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/dataplex"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		_, err := dataplex.NewAspectTypeIamMember(ctx, "member", &dataplex.AspectTypeIamMemberArgs{
			Project:      pulumi.Any(testAspectTypeBasic.Project),
			Location:     pulumi.Any(testAspectTypeBasic.Location),
			AspectTypeId: pulumi.Any(testAspectTypeBasic.AspectTypeId),
			Role:         pulumi.String("roles/viewer"),
			Member:       pulumi.String("user:jane@example.com"),
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.dataplex.AspectTypeIamMember;
import com.pulumi.gcp.dataplex.AspectTypeIamMemberArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        var member = new AspectTypeIamMember("member", AspectTypeIamMemberArgs.builder()
            .project(testAspectTypeBasic.project())
            .location(testAspectTypeBasic.location())
            .aspectTypeId(testAspectTypeBasic.aspectTypeId())
            .role("roles/viewer")
            .member("user:jane@example.com")
            .build());

    }
}
```
```yaml
resources:
  member:
    type: gcp:dataplex:AspectTypeIamMember
    properties:
      project: ${testAspectTypeBasic.project}
      location: ${testAspectTypeBasic.location}
      aspectTypeId: ${testAspectTypeBasic.aspectTypeId}
      role: roles/viewer
      member: user:jane@example.com
```
<!--End PulumiCodeChooser -->


## This resource supports User Project Overrides.

-

# IAM policy for Dataplex AspectType
Three different resources help you manage your IAM policy for Dataplex AspectType. Each of these resources serves a different use case:

* `gcp.dataplex.AspectTypeIamPolicy`: Authoritative. Sets the IAM policy for the aspecttype and replaces any existing policy already attached.
* `gcp.dataplex.AspectTypeIamBinding`: Authoritative for a given role. Updates the IAM policy to grant a role to a list of members. Other roles within the IAM policy for the aspecttype are preserved.
* `gcp.dataplex.AspectTypeIamMember`: Non-authoritative. Updates the IAM policy to grant a role to a new member. Other members for the role for the aspecttype are preserved.

A data source can be used to retrieve policy data in advent you do not need creation

* `gcp.dataplex.AspectTypeIamPolicy`: Retrieves the IAM policy for the aspecttype

> **Note:** `gcp.dataplex.AspectTypeIamPolicy` **cannot** be used in conjunction with `gcp.dataplex.AspectTypeIamBinding` and `gcp.dataplex.AspectTypeIamMember` or they will fight over what your policy should be.

> **Note:** `gcp.dataplex.AspectTypeIamBinding` resources **can be** used in conjunction with `gcp.dataplex.AspectTypeIamMember` resources **only if** they do not grant privilege to the same role.



## gcp.dataplex.AspectTypeIamPolicy

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const admin = gcp.organizations.getIAMPolicy({
    bindings: [{
        role: "roles/viewer",
        members: ["user:jane@example.com"],
    }],
});
const policy = new gcp.dataplex.AspectTypeIamPolicy("policy", {
    project: testAspectTypeBasic.project,
    location: testAspectTypeBasic.location,
    aspectTypeId: testAspectTypeBasic.aspectTypeId,
    policyData: admin.then(admin => admin.policyData),
});
```
```python
import pulumi
import pulumi_gcp as gcp

admin = gcp.organizations.get_iam_policy(bindings=[{
    "role": "roles/viewer",
    "members": ["user:jane@example.com"],
}])
policy = gcp.dataplex.AspectTypeIamPolicy("policy",
    project=test_aspect_type_basic["project"],
    location=test_aspect_type_basic["location"],
    aspect_type_id=test_aspect_type_basic["aspectTypeId"],
    policy_data=admin.policy_data)
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var admin = Gcp.Organizations.GetIAMPolicy.Invoke(new()
    {
        Bindings = new[]
        {
            new Gcp.Organizations.Inputs.GetIAMPolicyBindingInputArgs
            {
                Role = "roles/viewer",
                Members = new[]
                {
                    "user:jane@example.com",
                },
            },
        },
    });

    var policy = new Gcp.DataPlex.AspectTypeIamPolicy("policy", new()
    {
        Project = testAspectTypeBasic.Project,
        Location = testAspectTypeBasic.Location,
        AspectTypeId = testAspectTypeBasic.AspectTypeId,
        PolicyData = admin.Apply(getIAMPolicyResult => getIAMPolicyResult.PolicyData),
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/dataplex"
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/organizations"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		admin, err := organizations.LookupIAMPolicy(ctx, &organizations.LookupIAMPolicyArgs{
			Bindings: []organizations.GetIAMPolicyBinding{
				{
					Role: "roles/viewer",
					Members: []string{
						"user:jane@example.com",
					},
				},
			},
		}, nil)
		if err != nil {
			return err
		}
		_, err = dataplex.NewAspectTypeIamPolicy(ctx, "policy", &dataplex.AspectTypeIamPolicyArgs{
			Project:      pulumi.Any(testAspectTypeBasic.Project),
			Location:     pulumi.Any(testAspectTypeBasic.Location),
			AspectTypeId: pulumi.Any(testAspectTypeBasic.AspectTypeId),
			PolicyData:   pulumi.String(admin.PolicyData),
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.organizations.OrganizationsFunctions;
import com.pulumi.gcp.organizations.inputs.GetIAMPolicyArgs;
import com.pulumi.gcp.dataplex.AspectTypeIamPolicy;
import com.pulumi.gcp.dataplex.AspectTypeIamPolicyArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        final var admin = OrganizationsFunctions.getIAMPolicy(GetIAMPolicyArgs.builder()
            .bindings(GetIAMPolicyBindingArgs.builder()
                .role("roles/viewer")
                .members("user:jane@example.com")
                .build())
            .build());

        var policy = new AspectTypeIamPolicy("policy", AspectTypeIamPolicyArgs.builder()
            .project(testAspectTypeBasic.project())
            .location(testAspectTypeBasic.location())
            .aspectTypeId(testAspectTypeBasic.aspectTypeId())
            .policyData(admin.applyValue(getIAMPolicyResult -> getIAMPolicyResult.policyData()))
            .build());

    }
}
```
```yaml
resources:
  policy:
    type: gcp:dataplex:AspectTypeIamPolicy
    properties:
      project: ${testAspectTypeBasic.project}
      location: ${testAspectTypeBasic.location}
      aspectTypeId: ${testAspectTypeBasic.aspectTypeId}
      policyData: ${admin.policyData}
variables:
  admin:
    fn::invoke:
      function: gcp:organizations:getIAMPolicy
      arguments:
        bindings:
          - role: roles/viewer
            members:
              - user:jane@example.com
```
<!--End PulumiCodeChooser -->

## gcp.dataplex.AspectTypeIamBinding

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const binding = new gcp.dataplex.AspectTypeIamBinding("binding", {
    project: testAspectTypeBasic.project,
    location: testAspectTypeBasic.location,
    aspectTypeId: testAspectTypeBasic.aspectTypeId,
    role: "roles/viewer",
    members: ["user:jane@example.com"],
});
```
```python
import pulumi
import pulumi_gcp as gcp

binding = gcp.dataplex.AspectTypeIamBinding("binding",
    project=test_aspect_type_basic["project"],
    location=test_aspect_type_basic["location"],
    aspect_type_id=test_aspect_type_basic["aspectTypeId"],
    role="roles/viewer",
    members=["user:jane@example.com"])
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var binding = new Gcp.DataPlex.AspectTypeIamBinding("binding", new()
    {
        Project = testAspectTypeBasic.Project,
        Location = testAspectTypeBasic.Location,
        AspectTypeId = testAspectTypeBasic.AspectTypeId,
        Role = "roles/viewer",
        Members = new[]
        {
            "user:jane@example.com",
        },
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/dataplex"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		_, err := dataplex.NewAspectTypeIamBinding(ctx, "binding", &dataplex.AspectTypeIamBindingArgs{
			Project:      pulumi.Any(testAspectTypeBasic.Project),
			Location:     pulumi.Any(testAspectTypeBasic.Location),
			AspectTypeId: pulumi.Any(testAspectTypeBasic.AspectTypeId),
			Role:         pulumi.String("roles/viewer"),
			Members: pulumi.StringArray{
				pulumi.String("user:jane@example.com"),
			},
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.dataplex.AspectTypeIamBinding;
import com.pulumi.gcp.dataplex.AspectTypeIamBindingArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        var binding = new AspectTypeIamBinding("binding", AspectTypeIamBindingArgs.builder()
            .project(testAspectTypeBasic.project())
            .location(testAspectTypeBasic.location())
            .aspectTypeId(testAspectTypeBasic.aspectTypeId())
            .role("roles/viewer")
            .members("user:jane@example.com")
            .build());

    }
}
```
```yaml
resources:
  binding:
    type: gcp:dataplex:AspectTypeIamBinding
    properties:
      project: ${testAspectTypeBasic.project}
      location: ${testAspectTypeBasic.location}
      aspectTypeId: ${testAspectTypeBasic.aspectTypeId}
      role: roles/viewer
      members:
        - user:jane@example.com
```
<!--End PulumiCodeChooser -->

## gcp.dataplex.AspectTypeIamMember

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const member = new gcp.dataplex.AspectTypeIamMember("member", {
    project: testAspectTypeBasic.project,
    location: testAspectTypeBasic.location,
    aspectTypeId: testAspectTypeBasic.aspectTypeId,
    role: "roles/viewer",
    member: "user:jane@example.com",
});
```
```python
import pulumi
import pulumi_gcp as gcp

member = gcp.dataplex.AspectTypeIamMember("member",
    project=test_aspect_type_basic["project"],
    location=test_aspect_type_basic["location"],
    aspect_type_id=test_aspect_type_basic["aspectTypeId"],
    role="roles/viewer",
    member="user:jane@example.com")
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var member = new Gcp.DataPlex.AspectTypeIamMember("member", new()
    {
        Project = testAspectTypeBasic.Project,
        Location = testAspectTypeBasic.Location,
        AspectTypeId = testAspectTypeBasic.AspectTypeId,
        Role = "roles/viewer",
        Member = "user:jane@example.com",
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/dataplex"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		_, err := dataplex.NewAspectTypeIamMember(ctx, "member", &dataplex.AspectTypeIamMemberArgs{
			Project:      pulumi.Any(testAspectTypeBasic.Project),
			Location:     pulumi.Any(testAspectTypeBasic.Location),
			AspectTypeId: pulumi.Any(testAspectTypeBasic.AspectTypeId),
			Role:         pulumi.String("roles/viewer"),
			Member:       pulumi.String("user:jane@example.com"),
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.dataplex.AspectTypeIamMember;
import com.pulumi.gcp.dataplex.AspectTypeIamMemberArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        var member = new AspectTypeIamMember("member", AspectTypeIamMemberArgs.builder()
            .project(testAspectTypeBasic.project())
            .location(testAspectTypeBasic.location())
            .aspectTypeId(testAspectTypeBasic.aspectTypeId())
            .role("roles/viewer")
            .member("user:jane@example.com")
            .build());

    }
}
```
```yaml
resources:
  member:
    type: gcp:dataplex:AspectTypeIamMember
    properties:
      project: ${testAspectTypeBasic.project}
      location: ${testAspectTypeBasic.location}
      aspectTypeId: ${testAspectTypeBasic.aspectTypeId}
      role: roles/viewer
      member: user:jane@example.com
```
<!--End PulumiCodeChooser -->

## Import

For all import syntaxes, the "resource in question" can take any of the following forms:

* projects/{{project}}/locations/{{location}}/aspectTypes/{{aspect_type_id}}

* {{project}}/{{location}}/{{aspect_type_id}}

* {{location}}/{{aspect_type_id}}

* {{aspect_type_id}}

Any variables not passed in the import command will be taken from the provider configuration.

Dataplex aspecttype IAM resources can be imported using the resource identifiers, role, and member.

IAM member imports use space-delimited identifiers: the resource in question, the role, and the member identity, e.g.

```sh
$ pulumi import gcp:dataplex/aspectTypeIamPolicy:AspectTypeIamPolicy editor "projects/{{project}}/locations/{{location}}/aspectTypes/{{aspect_type_id}} roles/viewer user:jane@example.com"
```

IAM binding imports use space-delimited identifiers: the resource in question and the role, e.g.

```sh
$ pulumi import gcp:dataplex/aspectTypeIamPolicy:AspectTypeIamPolicy editor "projects/{{project}}/locations/{{location}}/aspectTypes/{{aspect_type_id}} roles/viewer"
```

IAM policy imports use the identifier of the resource in question, e.g.

```sh
$ pulumi import gcp:dataplex/aspectTypeIamPolicy:AspectTypeIamPolicy editor projects/{{project}}/locations/{{location}}/aspectTypes/{{aspect_type_id}}
```

-> **Custom Roles** If you're importing a IAM resource with a custom role, make sure to use the

 full name of the custom role, e.g. `[projects/my-project|organizations/my-org]/roles/my-custom-role`.


aspectTypeId" Ø
locationB" ÅThe location where aspect type will be created in.
Used to find the parent resource to bind the IAM policy to. If not specified,
the value will be parsed from the identifier of the parent resource. If no location is provided in the parent identifier and no
location is specified, it is taken from the provider configuration.
_

policyData" MThe policy data generated by
a `gcp.organizations.getIAMPolicy` data source.

projectB" The ID of the project in which the resource belongs.
If it is not provided, the project will be parsed from the identifier of the parent resource. If no project is provided in the parent identifier and no project is specified, the provider project is used.
"
aspectTypeId" "3
etag" '(Computed) The etag of the IAM policy.
"Ö
location" ÅThe location where aspect type will be created in.
Used to find the parent resource to bind the IAM policy to. If not specified,
the value will be parsed from the identifier of the parent resource. If no location is provided in the parent identifier and no
location is specified, it is taken from the provider configuration.
"_

policyData" MThe policy data generated by
a `gcp.organizations.getIAMPolicy` data source.
"
project" The ID of the project in which the resource belongs.
If it is not provided, the project will be parsed from the identifier of the parent resource. If no project is provided in the parent identifier and no project is specified, the provider project is used.
*q
+
dataplexAssetgcp:dataplex/asset:AssetÇUThe Dataplex Asset resource

## Example Usage

### Basic_asset
<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const basicBucket = new gcp.storage.Bucket("basic_bucket", {
    name: "bucket",
    location: "us-west1",
    uniformBucketLevelAccess: true,
    project: "my-project-name",
});
const basicLake = new gcp.dataplex.Lake("basic_lake", {
    name: "lake",
    location: "us-west1",
    project: "my-project-name",
});
const basicZone = new gcp.dataplex.Zone("basic_zone", {
    name: "zone",
    location: "us-west1",
    lake: basicLake.name,
    type: "RAW",
    discoverySpec: {
        enabled: false,
    },
    resourceSpec: {
        locationType: "SINGLE_REGION",
    },
    project: "my-project-name",
});
const primary = new gcp.dataplex.Asset("primary", {
    name: "asset",
    location: "us-west1",
    lake: basicLake.name,
    dataplexZone: basicZone.name,
    discoverySpec: {
        enabled: false,
    },
    resourceSpec: {
        name: "projects/my-project-name/buckets/bucket",
        type: "STORAGE_BUCKET",
    },
    labels: {
        env: "foo",
        "my-asset": "exists",
    },
    project: "my-project-name",
}, {
    dependsOn: [basicBucket],
});
```
```python
import pulumi
import pulumi_gcp as gcp

basic_bucket = gcp.storage.Bucket("basic_bucket",
    name="bucket",
    location="us-west1",
    uniform_bucket_level_access=True,
    project="my-project-name")
basic_lake = gcp.dataplex.Lake("basic_lake",
    name="lake",
    location="us-west1",
    project="my-project-name")
basic_zone = gcp.dataplex.Zone("basic_zone",
    name="zone",
    location="us-west1",
    lake=basic_lake.name,
    type="RAW",
    discovery_spec={
        "enabled": False,
    },
    resource_spec={
        "location_type": "SINGLE_REGION",
    },
    project="my-project-name")
primary = gcp.dataplex.Asset("primary",
    name="asset",
    location="us-west1",
    lake=basic_lake.name,
    dataplex_zone=basic_zone.name,
    discovery_spec={
        "enabled": False,
    },
    resource_spec={
        "name": "projects/my-project-name/buckets/bucket",
        "type": "STORAGE_BUCKET",
    },
    labels={
        "env": "foo",
        "my-asset": "exists",
    },
    project="my-project-name",
    opts = pulumi.ResourceOptions(depends_on=[basic_bucket]))
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var basicBucket = new Gcp.Storage.Bucket("basic_bucket", new()
    {
        Name = "bucket",
        Location = "us-west1",
        UniformBucketLevelAccess = true,
        Project = "my-project-name",
    });

    var basicLake = new Gcp.DataPlex.Lake("basic_lake", new()
    {
        Name = "lake",
        Location = "us-west1",
        Project = "my-project-name",
    });

    var basicZone = new Gcp.DataPlex.Zone("basic_zone", new()
    {
        Name = "zone",
        Location = "us-west1",
        Lake = basicLake.Name,
        Type = "RAW",
        DiscoverySpec = new Gcp.DataPlex.Inputs.ZoneDiscoverySpecArgs
        {
            Enabled = false,
        },
        ResourceSpec = new Gcp.DataPlex.Inputs.ZoneResourceSpecArgs
        {
            LocationType = "SINGLE_REGION",
        },
        Project = "my-project-name",
    });

    var primary = new Gcp.DataPlex.Asset("primary", new()
    {
        Name = "asset",
        Location = "us-west1",
        Lake = basicLake.Name,
        DataplexZone = basicZone.Name,
        DiscoverySpec = new Gcp.DataPlex.Inputs.AssetDiscoverySpecArgs
        {
            Enabled = false,
        },
        ResourceSpec = new Gcp.DataPlex.Inputs.AssetResourceSpecArgs
        {
            Name = "projects/my-project-name/buckets/bucket",
            Type = "STORAGE_BUCKET",
        },
        Labels = 
        {
            { "env", "foo" },
            { "my-asset", "exists" },
        },
        Project = "my-project-name",
    }, new CustomResourceOptions
    {
        DependsOn =
        {
            basicBucket,
        },
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/dataplex"
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/storage"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		basicBucket, err := storage.NewBucket(ctx, "basic_bucket", &storage.BucketArgs{
			Name:                     pulumi.String("bucket"),
			Location:                 pulumi.String("us-west1"),
			UniformBucketLevelAccess: pulumi.Bool(true),
			Project:                  pulumi.String("my-project-name"),
		})
		if err != nil {
			return err
		}
		basicLake, err := dataplex.NewLake(ctx, "basic_lake", &dataplex.LakeArgs{
			Name:     pulumi.String("lake"),
			Location: pulumi.String("us-west1"),
			Project:  pulumi.String("my-project-name"),
		})
		if err != nil {
			return err
		}
		basicZone, err := dataplex.NewZone(ctx, "basic_zone", &dataplex.ZoneArgs{
			Name:     pulumi.String("zone"),
			Location: pulumi.String("us-west1"),
			Lake:     basicLake.Name,
			Type:     pulumi.String("RAW"),
			DiscoverySpec: &dataplex.ZoneDiscoverySpecArgs{
				Enabled: pulumi.Bool(false),
			},
			ResourceSpec: &dataplex.ZoneResourceSpecArgs{
				LocationType: pulumi.String("SINGLE_REGION"),
			},
			Project: pulumi.String("my-project-name"),
		})
		if err != nil {
			return err
		}
		_, err = dataplex.NewAsset(ctx, "primary", &dataplex.AssetArgs{
			Name:         pulumi.String("asset"),
			Location:     pulumi.String("us-west1"),
			Lake:         basicLake.Name,
			DataplexZone: basicZone.Name,
			DiscoverySpec: &dataplex.AssetDiscoverySpecArgs{
				Enabled: pulumi.Bool(false),
			},
			ResourceSpec: &dataplex.AssetResourceSpecArgs{
				Name: pulumi.String("projects/my-project-name/buckets/bucket"),
				Type: pulumi.String("STORAGE_BUCKET"),
			},
			Labels: pulumi.StringMap{
				"env":      pulumi.String("foo"),
				"my-asset": pulumi.String("exists"),
			},
			Project: pulumi.String("my-project-name"),
		}, pulumi.DependsOn([]pulumi.Resource{
			basicBucket,
		}))
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.storage.Bucket;
import com.pulumi.gcp.storage.BucketArgs;
import com.pulumi.gcp.dataplex.Lake;
import com.pulumi.gcp.dataplex.LakeArgs;
import com.pulumi.gcp.dataplex.Zone;
import com.pulumi.gcp.dataplex.ZoneArgs;
import com.pulumi.gcp.dataplex.inputs.ZoneDiscoverySpecArgs;
import com.pulumi.gcp.dataplex.inputs.ZoneResourceSpecArgs;
import com.pulumi.gcp.dataplex.Asset;
import com.pulumi.gcp.dataplex.AssetArgs;
import com.pulumi.gcp.dataplex.inputs.AssetDiscoverySpecArgs;
import com.pulumi.gcp.dataplex.inputs.AssetResourceSpecArgs;
import com.pulumi.resources.CustomResourceOptions;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        var basicBucket = new Bucket("basicBucket", BucketArgs.builder()
            .name("bucket")
            .location("us-west1")
            .uniformBucketLevelAccess(true)
            .project("my-project-name")
            .build());

        var basicLake = new Lake("basicLake", LakeArgs.builder()
            .name("lake")
            .location("us-west1")
            .project("my-project-name")
            .build());

        var basicZone = new Zone("basicZone", ZoneArgs.builder()
            .name("zone")
            .location("us-west1")
            .lake(basicLake.name())
            .type("RAW")
            .discoverySpec(ZoneDiscoverySpecArgs.builder()
                .enabled(false)
                .build())
            .resourceSpec(ZoneResourceSpecArgs.builder()
                .locationType("SINGLE_REGION")
                .build())
            .project("my-project-name")
            .build());

        var primary = new Asset("primary", AssetArgs.builder()
            .name("asset")
            .location("us-west1")
            .lake(basicLake.name())
            .dataplexZone(basicZone.name())
            .discoverySpec(AssetDiscoverySpecArgs.builder()
                .enabled(false)
                .build())
            .resourceSpec(AssetResourceSpecArgs.builder()
                .name("projects/my-project-name/buckets/bucket")
                .type("STORAGE_BUCKET")
                .build())
            .labels(Map.ofEntries(
                Map.entry("env", "foo"),
                Map.entry("my-asset", "exists")
            ))
            .project("my-project-name")
            .build(), CustomResourceOptions.builder()
                .dependsOn(basicBucket)
                .build());

    }
}
```
```yaml
resources:
  basicBucket:
    type: gcp:storage:Bucket
    name: basic_bucket
    properties:
      name: bucket
      location: us-west1
      uniformBucketLevelAccess: true
      project: my-project-name
  basicLake:
    type: gcp:dataplex:Lake
    name: basic_lake
    properties:
      name: lake
      location: us-west1
      project: my-project-name
  basicZone:
    type: gcp:dataplex:Zone
    name: basic_zone
    properties:
      name: zone
      location: us-west1
      lake: ${basicLake.name}
      type: RAW
      discoverySpec:
        enabled: false
      resourceSpec:
        locationType: SINGLE_REGION
      project: my-project-name
  primary:
    type: gcp:dataplex:Asset
    properties:
      name: asset
      location: us-west1
      lake: ${basicLake.name}
      dataplexZone: ${basicZone.name}
      discoverySpec:
        enabled: false
      resourceSpec:
        name: projects/my-project-name/buckets/bucket
        type: STORAGE_BUCKET
      labels:
        env: foo
        my-asset: exists
      project: my-project-name
    options:
      dependsOn:
        - ${basicBucket}
```
<!--End PulumiCodeChooser -->

## Import

Asset can be imported using any of these accepted formats:

* `projects/{{project}}/locations/{{location}}/lakes/{{lake}}/zones/{{dataplex_zone}}/assets/{{name}}`

* `{{project}}/{{location}}/{{lake}}/{{dataplex_zone}}/{{name}}`

* `{{location}}/{{lake}}/{{dataplex_zone}}/{{name}}`

When using the `pulumi import` command, Asset can be imported using one of the formats above. For example:

```sh
$ pulumi import gcp:dataplex/asset:Asset default projects/{{project}}/locations/{{location}}/lakes/{{lake}}/zones/{{dataplex_zone}}/assets/{{name}}
```

```sh
$ pulumi import gcp:dataplex/asset:Asset default {{project}}/{{location}}/{{lake}}/{{dataplex_zone}}/{{name}}
```

```sh
$ pulumi import gcp:dataplex/asset:Asset default {{location}}/{{lake}}/{{dataplex_zone}}/{{name}}
```

.
dataplexZone" The zone for the resource
9
descriptionB" $Optional. Description of the asset.

discoverySpecV:T
R
dataplexAssetDiscoverySpec2gcp:dataplex/AssetDiscoverySpec:AssetDiscoverySpec­Required. Specification of the discovery feature applied to data referenced by this asset. When this spec is left unset, the asset will use the spec set on the parent zone.
;
displayNameB" &Optional. User friendly display name.

labelsB2" óOptional. User defined labels for the asset. **Note**: This field is non-authoritative, and will only manage the labels
present in your configuration. Please refer to the field `effective_labels` for all of the labels present on the
resource.
&
lake" The lake for the resource
.
location" The location for the resource
%
nameB" The name of the asset.
.
projectB" The project for the resource
º
resourceSpecS:Q
O
dataplexAssetResourceSpec0gcp:dataplex/AssetResourceSpec:AssetResourceSpecURequired. Immutable. Specification of the resource that is referenced by this asset.
"D

createTime" 2Output only. The time when the asset was created.
".
dataplexZone" The zone for the resource
"9
descriptionB" $Optional. Description of the asset.
"
discoverySpecV:T
R
dataplexAssetDiscoverySpec2gcp:dataplex/AssetDiscoverySpec:AssetDiscoverySpec­Required. Specification of the discovery feature applied to data referenced by this asset. When this spec is left unset, the asset will use the spec set on the parent zone.
"Ì
discoveryStatuses^*\:Z
X
dataplexAssetDiscoveryStatus6gcp:dataplex/AssetDiscoveryStatus:AssetDiscoveryStatusWOutput only. Status of the discovery feature applied to data referenced by this asset.
";
displayNameB" &Optional. User friendly display name.
"¦
effectiveLabels2" All of labels (key/value pairs) present on the resource in GCP, including the labels configured through Pulumi, other clients and services.
"
labelsB2" óOptional. User defined labels for the asset. **Note**: This field is non-authoritative, and will only manage the labels
present in your configuration. Please refer to the field `effective_labels` for all of the labels present on the
resource.
"&
lake" The lake for the resource
".
location" The location for the resource
"#
name" The name of the asset.
",
project" The project for the resource
"
pulumiLabels2" mThe combination of labels configured directly on the resource and default labels configured on the provider.
"º
resourceSpecS:Q
O
dataplexAssetResourceSpec0gcp:dataplex/AssetResourceSpec:AssetResourceSpecURequired. Immutable. Specification of the resource that is referenced by this asset.
"¯
resourceStatuses[*Y:W
U
dataplexAssetResourceStatus4gcp:dataplex/AssetResourceStatus:AssetResourceStatus>Output only. Status of the resource referenced by this asset.
"Ê
securityStatuses[*Y:W
U
dataplexAssetSecurityStatus4gcp:dataplex/AssetSecurityStatus:AssetSecurityStatusYOutput only. Status of the security policy applied to resource referenced by this asset.
"
state" yOutput only. Current state of the asset. Possible values: STATE_UNSPECIFIED, ACTIVE, CREATING, DELETING, ACTION_REQUIRED
"¡
uid" Output only. System generated globally unique ID for the asset. This ID will be different if the asset is deleted and re-created with the same name.
"I

updateTime" 7Output only. The time when the asset was last updated.
*ýí
I
dataplexAssetIamBinding,gcp:dataplex/assetIamBinding:AssetIamBindingÎThree different resources help you manage your IAM policy for Dataplex Asset. Each of these resources serves a different use case:

* `gcp.dataplex.AssetIamPolicy`: Authoritative. Sets the IAM policy for the asset and replaces any existing policy already attached.
* `gcp.dataplex.AssetIamBinding`: Authoritative for a given role. Updates the IAM policy to grant a role to a list of members. Other roles within the IAM policy for the asset are preserved.
* `gcp.dataplex.AssetIamMember`: Non-authoritative. Updates the IAM policy to grant a role to a new member. Other members for the role for the asset are preserved.

A data source can be used to retrieve policy data in advent you do not need creation

* `gcp.dataplex.AssetIamPolicy`: Retrieves the IAM policy for the asset

> **Note:** `gcp.dataplex.AssetIamPolicy` **cannot** be used in conjunction with `gcp.dataplex.AssetIamBinding` and `gcp.dataplex.AssetIamMember` or they will fight over what your policy should be.

> **Note:** `gcp.dataplex.AssetIamBinding` resources **can be** used in conjunction with `gcp.dataplex.AssetIamMember` resources **only if** they do not grant privilege to the same role.



## gcp.dataplex.AssetIamPolicy

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const admin = gcp.organizations.getIAMPolicy({
    bindings: [{
        role: "roles/viewer",
        members: ["user:jane@example.com"],
    }],
});
const policy = new gcp.dataplex.AssetIamPolicy("policy", {
    project: example.project,
    location: example.location,
    lake: example.lake,
    dataplexZone: example.dataplexZone,
    asset: example.name,
    policyData: admin.then(admin => admin.policyData),
});
```
```python
import pulumi
import pulumi_gcp as gcp

admin = gcp.organizations.get_iam_policy(bindings=[{
    "role": "roles/viewer",
    "members": ["user:jane@example.com"],
}])
policy = gcp.dataplex.AssetIamPolicy("policy",
    project=example["project"],
    location=example["location"],
    lake=example["lake"],
    dataplex_zone=example["dataplexZone"],
    asset=example["name"],
    policy_data=admin.policy_data)
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var admin = Gcp.Organizations.GetIAMPolicy.Invoke(new()
    {
        Bindings = new[]
        {
            new Gcp.Organizations.Inputs.GetIAMPolicyBindingInputArgs
            {
                Role = "roles/viewer",
                Members = new[]
                {
                    "user:jane@example.com",
                },
            },
        },
    });

    var policy = new Gcp.DataPlex.AssetIamPolicy("policy", new()
    {
        Project = example.Project,
        Location = example.Location,
        Lake = example.Lake,
        DataplexZone = example.DataplexZone,
        Asset = example.Name,
        PolicyData = admin.Apply(getIAMPolicyResult => getIAMPolicyResult.PolicyData),
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/dataplex"
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/organizations"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		admin, err := organizations.LookupIAMPolicy(ctx, &organizations.LookupIAMPolicyArgs{
			Bindings: []organizations.GetIAMPolicyBinding{
				{
					Role: "roles/viewer",
					Members: []string{
						"user:jane@example.com",
					},
				},
			},
		}, nil)
		if err != nil {
			return err
		}
		_, err = dataplex.NewAssetIamPolicy(ctx, "policy", &dataplex.AssetIamPolicyArgs{
			Project:      pulumi.Any(example.Project),
			Location:     pulumi.Any(example.Location),
			Lake:         pulumi.Any(example.Lake),
			DataplexZone: pulumi.Any(example.DataplexZone),
			Asset:        pulumi.Any(example.Name),
			PolicyData:   pulumi.String(admin.PolicyData),
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.organizations.OrganizationsFunctions;
import com.pulumi.gcp.organizations.inputs.GetIAMPolicyArgs;
import com.pulumi.gcp.dataplex.AssetIamPolicy;
import com.pulumi.gcp.dataplex.AssetIamPolicyArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        final var admin = OrganizationsFunctions.getIAMPolicy(GetIAMPolicyArgs.builder()
            .bindings(GetIAMPolicyBindingArgs.builder()
                .role("roles/viewer")
                .members("user:jane@example.com")
                .build())
            .build());

        var policy = new AssetIamPolicy("policy", AssetIamPolicyArgs.builder()
            .project(example.project())
            .location(example.location())
            .lake(example.lake())
            .dataplexZone(example.dataplexZone())
            .asset(example.name())
            .policyData(admin.applyValue(getIAMPolicyResult -> getIAMPolicyResult.policyData()))
            .build());

    }
}
```
```yaml
resources:
  policy:
    type: gcp:dataplex:AssetIamPolicy
    properties:
      project: ${example.project}
      location: ${example.location}
      lake: ${example.lake}
      dataplexZone: ${example.dataplexZone}
      asset: ${example.name}
      policyData: ${admin.policyData}
variables:
  admin:
    fn::invoke:
      function: gcp:organizations:getIAMPolicy
      arguments:
        bindings:
          - role: roles/viewer
            members:
              - user:jane@example.com
```
<!--End PulumiCodeChooser -->

## gcp.dataplex.AssetIamBinding

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const binding = new gcp.dataplex.AssetIamBinding("binding", {
    project: example.project,
    location: example.location,
    lake: example.lake,
    dataplexZone: example.dataplexZone,
    asset: example.name,
    role: "roles/viewer",
    members: ["user:jane@example.com"],
});
```
```python
import pulumi
import pulumi_gcp as gcp

binding = gcp.dataplex.AssetIamBinding("binding",
    project=example["project"],
    location=example["location"],
    lake=example["lake"],
    dataplex_zone=example["dataplexZone"],
    asset=example["name"],
    role="roles/viewer",
    members=["user:jane@example.com"])
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var binding = new Gcp.DataPlex.AssetIamBinding("binding", new()
    {
        Project = example.Project,
        Location = example.Location,
        Lake = example.Lake,
        DataplexZone = example.DataplexZone,
        Asset = example.Name,
        Role = "roles/viewer",
        Members = new[]
        {
            "user:jane@example.com",
        },
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/dataplex"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		_, err := dataplex.NewAssetIamBinding(ctx, "binding", &dataplex.AssetIamBindingArgs{
			Project:      pulumi.Any(example.Project),
			Location:     pulumi.Any(example.Location),
			Lake:         pulumi.Any(example.Lake),
			DataplexZone: pulumi.Any(example.DataplexZone),
			Asset:        pulumi.Any(example.Name),
			Role:         pulumi.String("roles/viewer"),
			Members: pulumi.StringArray{
				pulumi.String("user:jane@example.com"),
			},
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.dataplex.AssetIamBinding;
import com.pulumi.gcp.dataplex.AssetIamBindingArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        var binding = new AssetIamBinding("binding", AssetIamBindingArgs.builder()
            .project(example.project())
            .location(example.location())
            .lake(example.lake())
            .dataplexZone(example.dataplexZone())
            .asset(example.name())
            .role("roles/viewer")
            .members("user:jane@example.com")
            .build());

    }
}
```
```yaml
resources:
  binding:
    type: gcp:dataplex:AssetIamBinding
    properties:
      project: ${example.project}
      location: ${example.location}
      lake: ${example.lake}
      dataplexZone: ${example.dataplexZone}
      asset: ${example.name}
      role: roles/viewer
      members:
        - user:jane@example.com
```
<!--End PulumiCodeChooser -->

## gcp.dataplex.AssetIamMember

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const member = new gcp.dataplex.AssetIamMember("member", {
    project: example.project,
    location: example.location,
    lake: example.lake,
    dataplexZone: example.dataplexZone,
    asset: example.name,
    role: "roles/viewer",
    member: "user:jane@example.com",
});
```
```python
import pulumi
import pulumi_gcp as gcp

member = gcp.dataplex.AssetIamMember("member",
    project=example["project"],
    location=example["location"],
    lake=example["lake"],
    dataplex_zone=example["dataplexZone"],
    asset=example["name"],
    role="roles/viewer",
    member="user:jane@example.com")
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var member = new Gcp.DataPlex.AssetIamMember("member", new()
    {
        Project = example.Project,
        Location = example.Location,
        Lake = example.Lake,
        DataplexZone = example.DataplexZone,
        Asset = example.Name,
        Role = "roles/viewer",
        Member = "user:jane@example.com",
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/dataplex"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		_, err := dataplex.NewAssetIamMember(ctx, "member", &dataplex.AssetIamMemberArgs{
			Project:      pulumi.Any(example.Project),
			Location:     pulumi.Any(example.Location),
			Lake:         pulumi.Any(example.Lake),
			DataplexZone: pulumi.Any(example.DataplexZone),
			Asset:        pulumi.Any(example.Name),
			Role:         pulumi.String("roles/viewer"),
			Member:       pulumi.String("user:jane@example.com"),
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.dataplex.AssetIamMember;
import com.pulumi.gcp.dataplex.AssetIamMemberArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        var member = new AssetIamMember("member", AssetIamMemberArgs.builder()
            .project(example.project())
            .location(example.location())
            .lake(example.lake())
            .dataplexZone(example.dataplexZone())
            .asset(example.name())
            .role("roles/viewer")
            .member("user:jane@example.com")
            .build());

    }
}
```
```yaml
resources:
  member:
    type: gcp:dataplex:AssetIamMember
    properties:
      project: ${example.project}
      location: ${example.location}
      lake: ${example.lake}
      dataplexZone: ${example.dataplexZone}
      asset: ${example.name}
      role: roles/viewer
      member: user:jane@example.com
```
<!--End PulumiCodeChooser -->


## This resource supports User Project Overrides.

-

# IAM policy for Dataplex Asset
Three different resources help you manage your IAM policy for Dataplex Asset. Each of these resources serves a different use case:

* `gcp.dataplex.AssetIamPolicy`: Authoritative. Sets the IAM policy for the asset and replaces any existing policy already attached.
* `gcp.dataplex.AssetIamBinding`: Authoritative for a given role. Updates the IAM policy to grant a role to a list of members. Other roles within the IAM policy for the asset are preserved.
* `gcp.dataplex.AssetIamMember`: Non-authoritative. Updates the IAM policy to grant a role to a new member. Other members for the role for the asset are preserved.

A data source can be used to retrieve policy data in advent you do not need creation

* `gcp.dataplex.AssetIamPolicy`: Retrieves the IAM policy for the asset

> **Note:** `gcp.dataplex.AssetIamPolicy` **cannot** be used in conjunction with `gcp.dataplex.AssetIamBinding` and `gcp.dataplex.AssetIamMember` or they will fight over what your policy should be.

> **Note:** `gcp.dataplex.AssetIamBinding` resources **can be** used in conjunction with `gcp.dataplex.AssetIamMember` resources **only if** they do not grant privilege to the same role.



## gcp.dataplex.AssetIamPolicy

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const admin = gcp.organizations.getIAMPolicy({
    bindings: [{
        role: "roles/viewer",
        members: ["user:jane@example.com"],
    }],
});
const policy = new gcp.dataplex.AssetIamPolicy("policy", {
    project: example.project,
    location: example.location,
    lake: example.lake,
    dataplexZone: example.dataplexZone,
    asset: example.name,
    policyData: admin.then(admin => admin.policyData),
});
```
```python
import pulumi
import pulumi_gcp as gcp

admin = gcp.organizations.get_iam_policy(bindings=[{
    "role": "roles/viewer",
    "members": ["user:jane@example.com"],
}])
policy = gcp.dataplex.AssetIamPolicy("policy",
    project=example["project"],
    location=example["location"],
    lake=example["lake"],
    dataplex_zone=example["dataplexZone"],
    asset=example["name"],
    policy_data=admin.policy_data)
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var admin = Gcp.Organizations.GetIAMPolicy.Invoke(new()
    {
        Bindings = new[]
        {
            new Gcp.Organizations.Inputs.GetIAMPolicyBindingInputArgs
            {
                Role = "roles/viewer",
                Members = new[]
                {
                    "user:jane@example.com",
                },
            },
        },
    });

    var policy = new Gcp.DataPlex.AssetIamPolicy("policy", new()
    {
        Project = example.Project,
        Location = example.Location,
        Lake = example.Lake,
        DataplexZone = example.DataplexZone,
        Asset = example.Name,
        PolicyData = admin.Apply(getIAMPolicyResult => getIAMPolicyResult.PolicyData),
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/dataplex"
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/organizations"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		admin, err := organizations.LookupIAMPolicy(ctx, &organizations.LookupIAMPolicyArgs{
			Bindings: []organizations.GetIAMPolicyBinding{
				{
					Role: "roles/viewer",
					Members: []string{
						"user:jane@example.com",
					},
				},
			},
		}, nil)
		if err != nil {
			return err
		}
		_, err = dataplex.NewAssetIamPolicy(ctx, "policy", &dataplex.AssetIamPolicyArgs{
			Project:      pulumi.Any(example.Project),
			Location:     pulumi.Any(example.Location),
			Lake:         pulumi.Any(example.Lake),
			DataplexZone: pulumi.Any(example.DataplexZone),
			Asset:        pulumi.Any(example.Name),
			PolicyData:   pulumi.String(admin.PolicyData),
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.organizations.OrganizationsFunctions;
import com.pulumi.gcp.organizations.inputs.GetIAMPolicyArgs;
import com.pulumi.gcp.dataplex.AssetIamPolicy;
import com.pulumi.gcp.dataplex.AssetIamPolicyArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        final var admin = OrganizationsFunctions.getIAMPolicy(GetIAMPolicyArgs.builder()
            .bindings(GetIAMPolicyBindingArgs.builder()
                .role("roles/viewer")
                .members("user:jane@example.com")
                .build())
            .build());

        var policy = new AssetIamPolicy("policy", AssetIamPolicyArgs.builder()
            .project(example.project())
            .location(example.location())
            .lake(example.lake())
            .dataplexZone(example.dataplexZone())
            .asset(example.name())
            .policyData(admin.applyValue(getIAMPolicyResult -> getIAMPolicyResult.policyData()))
            .build());

    }
}
```
```yaml
resources:
  policy:
    type: gcp:dataplex:AssetIamPolicy
    properties:
      project: ${example.project}
      location: ${example.location}
      lake: ${example.lake}
      dataplexZone: ${example.dataplexZone}
      asset: ${example.name}
      policyData: ${admin.policyData}
variables:
  admin:
    fn::invoke:
      function: gcp:organizations:getIAMPolicy
      arguments:
        bindings:
          - role: roles/viewer
            members:
              - user:jane@example.com
```
<!--End PulumiCodeChooser -->

## gcp.dataplex.AssetIamBinding

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const binding = new gcp.dataplex.AssetIamBinding("binding", {
    project: example.project,
    location: example.location,
    lake: example.lake,
    dataplexZone: example.dataplexZone,
    asset: example.name,
    role: "roles/viewer",
    members: ["user:jane@example.com"],
});
```
```python
import pulumi
import pulumi_gcp as gcp

binding = gcp.dataplex.AssetIamBinding("binding",
    project=example["project"],
    location=example["location"],
    lake=example["lake"],
    dataplex_zone=example["dataplexZone"],
    asset=example["name"],
    role="roles/viewer",
    members=["user:jane@example.com"])
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var binding = new Gcp.DataPlex.AssetIamBinding("binding", new()
    {
        Project = example.Project,
        Location = example.Location,
        Lake = example.Lake,
        DataplexZone = example.DataplexZone,
        Asset = example.Name,
        Role = "roles/viewer",
        Members = new[]
        {
            "user:jane@example.com",
        },
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/dataplex"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		_, err := dataplex.NewAssetIamBinding(ctx, "binding", &dataplex.AssetIamBindingArgs{
			Project:      pulumi.Any(example.Project),
			Location:     pulumi.Any(example.Location),
			Lake:         pulumi.Any(example.Lake),
			DataplexZone: pulumi.Any(example.DataplexZone),
			Asset:        pulumi.Any(example.Name),
			Role:         pulumi.String("roles/viewer"),
			Members: pulumi.StringArray{
				pulumi.String("user:jane@example.com"),
			},
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.dataplex.AssetIamBinding;
import com.pulumi.gcp.dataplex.AssetIamBindingArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        var binding = new AssetIamBinding("binding", AssetIamBindingArgs.builder()
            .project(example.project())
            .location(example.location())
            .lake(example.lake())
            .dataplexZone(example.dataplexZone())
            .asset(example.name())
            .role("roles/viewer")
            .members("user:jane@example.com")
            .build());

    }
}
```
```yaml
resources:
  binding:
    type: gcp:dataplex:AssetIamBinding
    properties:
      project: ${example.project}
      location: ${example.location}
      lake: ${example.lake}
      dataplexZone: ${example.dataplexZone}
      asset: ${example.name}
      role: roles/viewer
      members:
        - user:jane@example.com
```
<!--End PulumiCodeChooser -->

## gcp.dataplex.AssetIamMember

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const member = new gcp.dataplex.AssetIamMember("member", {
    project: example.project,
    location: example.location,
    lake: example.lake,
    dataplexZone: example.dataplexZone,
    asset: example.name,
    role: "roles/viewer",
    member: "user:jane@example.com",
});
```
```python
import pulumi
import pulumi_gcp as gcp

member = gcp.dataplex.AssetIamMember("member",
    project=example["project"],
    location=example["location"],
    lake=example["lake"],
    dataplex_zone=example["dataplexZone"],
    asset=example["name"],
    role="roles/viewer",
    member="user:jane@example.com")
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var member = new Gcp.DataPlex.AssetIamMember("member", new()
    {
        Project = example.Project,
        Location = example.Location,
        Lake = example.Lake,
        DataplexZone = example.DataplexZone,
        Asset = example.Name,
        Role = "roles/viewer",
        Member = "user:jane@example.com",
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/dataplex"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		_, err := dataplex.NewAssetIamMember(ctx, "member", &dataplex.AssetIamMemberArgs{
			Project:      pulumi.Any(example.Project),
			Location:     pulumi.Any(example.Location),
			Lake:         pulumi.Any(example.Lake),
			DataplexZone: pulumi.Any(example.DataplexZone),
			Asset:        pulumi.Any(example.Name),
			Role:         pulumi.String("roles/viewer"),
			Member:       pulumi.String("user:jane@example.com"),
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.dataplex.AssetIamMember;
import com.pulumi.gcp.dataplex.AssetIamMemberArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        var member = new AssetIamMember("member", AssetIamMemberArgs.builder()
            .project(example.project())
            .location(example.location())
            .lake(example.lake())
            .dataplexZone(example.dataplexZone())
            .asset(example.name())
            .role("roles/viewer")
            .member("user:jane@example.com")
            .build());

    }
}
```
```yaml
resources:
  member:
    type: gcp:dataplex:AssetIamMember
    properties:
      project: ${example.project}
      location: ${example.location}
      lake: ${example.lake}
      dataplexZone: ${example.dataplexZone}
      asset: ${example.name}
      role: roles/viewer
      member: user:jane@example.com
```
<!--End PulumiCodeChooser -->

## Import

For all import syntaxes, the "resource in question" can take any of the following forms:

* projects/{{project}}/locations/{{location}}/lakes/{{lake}}/zones/{{dataplex_zone}}/assets/{{name}}

* {{project}}/{{location}}/{{lake}}/{{dataplex_zone}}/{{name}}

* {{location}}/{{lake}}/{{dataplex_zone}}/{{name}}

* {{name}}

Any variables not passed in the import command will be taken from the provider configuration.

Dataplex asset IAM resources can be imported using the resource identifiers, role, and member.

IAM member imports use space-delimited identifiers: the resource in question, the role, and the member identity, e.g.

```sh
$ pulumi import gcp:dataplex/assetIamBinding:AssetIamBinding editor "projects/{{project}}/locations/{{location}}/lakes/{{lake}}/zones/{{dataplex_zone}}/assets/{{asset}} roles/viewer user:jane@example.com"
```

IAM binding imports use space-delimited identifiers: the resource in question and the role, e.g.

```sh
$ pulumi import gcp:dataplex/assetIamBinding:AssetIamBinding editor "projects/{{project}}/locations/{{location}}/lakes/{{lake}}/zones/{{dataplex_zone}}/assets/{{asset}} roles/viewer"
```

IAM policy imports use the identifier of the resource in question, e.g.

```sh
$ pulumi import gcp:dataplex/assetIamBinding:AssetIamBinding editor projects/{{project}}/locations/{{location}}/lakes/{{lake}}/zones/{{dataplex_zone}}/assets/{{asset}}
```

-> **Custom Roles** If you're importing a IAM resource with a custom role, make sure to use the

 full name of the custom role, e.g. `[projects/my-project|organizations/my-org]/roles/my-custom-role`.

H
asset" ;Used to find the parent resource to bind the IAM policy to
w
	conditionjBh:f
d
dataplexAssetIamBindingCondition>gcp:dataplex/AssetIamBindingCondition:AssetIamBindingCondition
dataplexZone" 

lake" 
locationB" Ö	
members*" Ä	Identities that will be granted the privilege in `role`.
Each entry can have one of the following values:
* **allUsers**: A special identifier that represents anyone who is on the internet; with or without a Google account.
* **allAuthenticatedUsers**: A special identifier that represents anyone who is authenticated with a Google account or a service account.
* **user:{emailid}**: An email address that represents a specific Google account. For example, alice@gmail.com or joe@example.com.
* **serviceAccount:{emailid}**: An email address that represents a service account. For example, my-other-app@appspot.gserviceaccount.com.
* **group:{emailid}**: An email address that represents a Google group. For example, admins@example.com.
* **domain:{domain}**: A G Suite domain (primary, instead of alias) name that represents all the users of that domain. For example, google.com or example.com.
* **projectOwner:projectid**: Owners of the given project. For example, "projectOwner:my-example-project"
* **projectEditor:projectid**: Editors of the given project. For example, "projectEditor:my-example-project"
* **projectViewer:projectid**: Viewers of the given project. For example, "projectViewer:my-example-project"

projectB" The ID of the project in which the resource belongs.
If it is not provided, the project will be parsed from the identifier of the parent resource. If no project is provided in the parent identifier and no project is specified, the provider project is used.
Õ
role" ÈThe role that should be applied. Only one
`gcp.dataplex.AssetIamBinding` can be used per role. Note that custom roles must be of the format
`[projects|organizations]/{parent-name}/roles/{role-name}`.
"H
asset" ;Used to find the parent resource to bind the IAM policy to
"w
	conditionjBh:f
d
dataplexAssetIamBindingCondition>gcp:dataplex/AssetIamBindingCondition:AssetIamBindingCondition"
dataplexZone" "3
etag" '(Computed) The etag of the IAM policy.
"

lake" "
location" "Ö	
members*" Ä	Identities that will be granted the privilege in `role`.
Each entry can have one of the following values:
* **allUsers**: A special identifier that represents anyone who is on the internet; with or without a Google account.
* **allAuthenticatedUsers**: A special identifier that represents anyone who is authenticated with a Google account or a service account.
* **user:{emailid}**: An email address that represents a specific Google account. For example, alice@gmail.com or joe@example.com.
* **serviceAccount:{emailid}**: An email address that represents a service account. For example, my-other-app@appspot.gserviceaccount.com.
* **group:{emailid}**: An email address that represents a Google group. For example, admins@example.com.
* **domain:{domain}**: A G Suite domain (primary, instead of alias) name that represents all the users of that domain. For example, google.com or example.com.
* **projectOwner:projectid**: Owners of the given project. For example, "projectOwner:my-example-project"
* **projectEditor:projectid**: Editors of the given project. For example, "projectEditor:my-example-project"
* **projectViewer:projectid**: Viewers of the given project. For example, "projectViewer:my-example-project"
"
project" The ID of the project in which the resource belongs.
If it is not provided, the project will be parsed from the identifier of the parent resource. If no project is provided in the parent identifier and no project is specified, the provider project is used.
"Õ
role" ÈThe role that should be applied. Only one
`gcp.dataplex.AssetIamBinding` can be used per role. Note that custom roles must be of the format
`[projects|organizations]/{parent-name}/roles/{role-name}`.
*èí
F
dataplexAssetIamMember*gcp:dataplex/assetIamMember:AssetIamMemberÿÍThree different resources help you manage your IAM policy for Dataplex Asset. Each of these resources serves a different use case:

* `gcp.dataplex.AssetIamPolicy`: Authoritative. Sets the IAM policy for the asset and replaces any existing policy already attached.
* `gcp.dataplex.AssetIamBinding`: Authoritative for a given role. Updates the IAM policy to grant a role to a list of members. Other roles within the IAM policy for the asset are preserved.
* `gcp.dataplex.AssetIamMember`: Non-authoritative. Updates the IAM policy to grant a role to a new member. Other members for the role for the asset are preserved.

A data source can be used to retrieve policy data in advent you do not need creation

* `gcp.dataplex.AssetIamPolicy`: Retrieves the IAM policy for the asset

> **Note:** `gcp.dataplex.AssetIamPolicy` **cannot** be used in conjunction with `gcp.dataplex.AssetIamBinding` and `gcp.dataplex.AssetIamMember` or they will fight over what your policy should be.

> **Note:** `gcp.dataplex.AssetIamBinding` resources **can be** used in conjunction with `gcp.dataplex.AssetIamMember` resources **only if** they do not grant privilege to the same role.



## gcp.dataplex.AssetIamPolicy

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const admin = gcp.organizations.getIAMPolicy({
    bindings: [{
        role: "roles/viewer",
        members: ["user:jane@example.com"],
    }],
});
const policy = new gcp.dataplex.AssetIamPolicy("policy", {
    project: example.project,
    location: example.location,
    lake: example.lake,
    dataplexZone: example.dataplexZone,
    asset: example.name,
    policyData: admin.then(admin => admin.policyData),
});
```
```python
import pulumi
import pulumi_gcp as gcp

admin = gcp.organizations.get_iam_policy(bindings=[{
    "role": "roles/viewer",
    "members": ["user:jane@example.com"],
}])
policy = gcp.dataplex.AssetIamPolicy("policy",
    project=example["project"],
    location=example["location"],
    lake=example["lake"],
    dataplex_zone=example["dataplexZone"],
    asset=example["name"],
    policy_data=admin.policy_data)
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var admin = Gcp.Organizations.GetIAMPolicy.Invoke(new()
    {
        Bindings = new[]
        {
            new Gcp.Organizations.Inputs.GetIAMPolicyBindingInputArgs
            {
                Role = "roles/viewer",
                Members = new[]
                {
                    "user:jane@example.com",
                },
            },
        },
    });

    var policy = new Gcp.DataPlex.AssetIamPolicy("policy", new()
    {
        Project = example.Project,
        Location = example.Location,
        Lake = example.Lake,
        DataplexZone = example.DataplexZone,
        Asset = example.Name,
        PolicyData = admin.Apply(getIAMPolicyResult => getIAMPolicyResult.PolicyData),
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/dataplex"
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/organizations"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		admin, err := organizations.LookupIAMPolicy(ctx, &organizations.LookupIAMPolicyArgs{
			Bindings: []organizations.GetIAMPolicyBinding{
				{
					Role: "roles/viewer",
					Members: []string{
						"user:jane@example.com",
					},
				},
			},
		}, nil)
		if err != nil {
			return err
		}
		_, err = dataplex.NewAssetIamPolicy(ctx, "policy", &dataplex.AssetIamPolicyArgs{
			Project:      pulumi.Any(example.Project),
			Location:     pulumi.Any(example.Location),
			Lake:         pulumi.Any(example.Lake),
			DataplexZone: pulumi.Any(example.DataplexZone),
			Asset:        pulumi.Any(example.Name),
			PolicyData:   pulumi.String(admin.PolicyData),
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.organizations.OrganizationsFunctions;
import com.pulumi.gcp.organizations.inputs.GetIAMPolicyArgs;
import com.pulumi.gcp.dataplex.AssetIamPolicy;
import com.pulumi.gcp.dataplex.AssetIamPolicyArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        final var admin = OrganizationsFunctions.getIAMPolicy(GetIAMPolicyArgs.builder()
            .bindings(GetIAMPolicyBindingArgs.builder()
                .role("roles/viewer")
                .members("user:jane@example.com")
                .build())
            .build());

        var policy = new AssetIamPolicy("policy", AssetIamPolicyArgs.builder()
            .project(example.project())
            .location(example.location())
            .lake(example.lake())
            .dataplexZone(example.dataplexZone())
            .asset(example.name())
            .policyData(admin.applyValue(getIAMPolicyResult -> getIAMPolicyResult.policyData()))
            .build());

    }
}
```
```yaml
resources:
  policy:
    type: gcp:dataplex:AssetIamPolicy
    properties:
      project: ${example.project}
      location: ${example.location}
      lake: ${example.lake}
      dataplexZone: ${example.dataplexZone}
      asset: ${example.name}
      policyData: ${admin.policyData}
variables:
  admin:
    fn::invoke:
      function: gcp:organizations:getIAMPolicy
      arguments:
        bindings:
          - role: roles/viewer
            members:
              - user:jane@example.com
```
<!--End PulumiCodeChooser -->

## gcp.dataplex.AssetIamBinding

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const binding = new gcp.dataplex.AssetIamBinding("binding", {
    project: example.project,
    location: example.location,
    lake: example.lake,
    dataplexZone: example.dataplexZone,
    asset: example.name,
    role: "roles/viewer",
    members: ["user:jane@example.com"],
});
```
```python
import pulumi
import pulumi_gcp as gcp

binding = gcp.dataplex.AssetIamBinding("binding",
    project=example["project"],
    location=example["location"],
    lake=example["lake"],
    dataplex_zone=example["dataplexZone"],
    asset=example["name"],
    role="roles/viewer",
    members=["user:jane@example.com"])
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var binding = new Gcp.DataPlex.AssetIamBinding("binding", new()
    {
        Project = example.Project,
        Location = example.Location,
        Lake = example.Lake,
        DataplexZone = example.DataplexZone,
        Asset = example.Name,
        Role = "roles/viewer",
        Members = new[]
        {
            "user:jane@example.com",
        },
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/dataplex"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		_, err := dataplex.NewAssetIamBinding(ctx, "binding", &dataplex.AssetIamBindingArgs{
			Project:      pulumi.Any(example.Project),
			Location:     pulumi.Any(example.Location),
			Lake:         pulumi.Any(example.Lake),
			DataplexZone: pulumi.Any(example.DataplexZone),
			Asset:        pulumi.Any(example.Name),
			Role:         pulumi.String("roles/viewer"),
			Members: pulumi.StringArray{
				pulumi.String("user:jane@example.com"),
			},
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.dataplex.AssetIamBinding;
import com.pulumi.gcp.dataplex.AssetIamBindingArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        var binding = new AssetIamBinding("binding", AssetIamBindingArgs.builder()
            .project(example.project())
            .location(example.location())
            .lake(example.lake())
            .dataplexZone(example.dataplexZone())
            .asset(example.name())
            .role("roles/viewer")
            .members("user:jane@example.com")
            .build());

    }
}
```
```yaml
resources:
  binding:
    type: gcp:dataplex:AssetIamBinding
    properties:
      project: ${example.project}
      location: ${example.location}
      lake: ${example.lake}
      dataplexZone: ${example.dataplexZone}
      asset: ${example.name}
      role: roles/viewer
      members:
        - user:jane@example.com
```
<!--End PulumiCodeChooser -->

## gcp.dataplex.AssetIamMember

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const member = new gcp.dataplex.AssetIamMember("member", {
    project: example.project,
    location: example.location,
    lake: example.lake,
    dataplexZone: example.dataplexZone,
    asset: example.name,
    role: "roles/viewer",
    member: "user:jane@example.com",
});
```
```python
import pulumi
import pulumi_gcp as gcp

member = gcp.dataplex.AssetIamMember("member",
    project=example["project"],
    location=example["location"],
    lake=example["lake"],
    dataplex_zone=example["dataplexZone"],
    asset=example["name"],
    role="roles/viewer",
    member="user:jane@example.com")
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var member = new Gcp.DataPlex.AssetIamMember("member", new()
    {
        Project = example.Project,
        Location = example.Location,
        Lake = example.Lake,
        DataplexZone = example.DataplexZone,
        Asset = example.Name,
        Role = "roles/viewer",
        Member = "user:jane@example.com",
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/dataplex"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		_, err := dataplex.NewAssetIamMember(ctx, "member", &dataplex.AssetIamMemberArgs{
			Project:      pulumi.Any(example.Project),
			Location:     pulumi.Any(example.Location),
			Lake:         pulumi.Any(example.Lake),
			DataplexZone: pulumi.Any(example.DataplexZone),
			Asset:        pulumi.Any(example.Name),
			Role:         pulumi.String("roles/viewer"),
			Member:       pulumi.String("user:jane@example.com"),
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.dataplex.AssetIamMember;
import com.pulumi.gcp.dataplex.AssetIamMemberArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        var member = new AssetIamMember("member", AssetIamMemberArgs.builder()
            .project(example.project())
            .location(example.location())
            .lake(example.lake())
            .dataplexZone(example.dataplexZone())
            .asset(example.name())
            .role("roles/viewer")
            .member("user:jane@example.com")
            .build());

    }
}
```
```yaml
resources:
  member:
    type: gcp:dataplex:AssetIamMember
    properties:
      project: ${example.project}
      location: ${example.location}
      lake: ${example.lake}
      dataplexZone: ${example.dataplexZone}
      asset: ${example.name}
      role: roles/viewer
      member: user:jane@example.com
```
<!--End PulumiCodeChooser -->


## This resource supports User Project Overrides.

-

# IAM policy for Dataplex Asset
Three different resources help you manage your IAM policy for Dataplex Asset. Each of these resources serves a different use case:

* `gcp.dataplex.AssetIamPolicy`: Authoritative. Sets the IAM policy for the asset and replaces any existing policy already attached.
* `gcp.dataplex.AssetIamBinding`: Authoritative for a given role. Updates the IAM policy to grant a role to a list of members. Other roles within the IAM policy for the asset are preserved.
* `gcp.dataplex.AssetIamMember`: Non-authoritative. Updates the IAM policy to grant a role to a new member. Other members for the role for the asset are preserved.

A data source can be used to retrieve policy data in advent you do not need creation

* `gcp.dataplex.AssetIamPolicy`: Retrieves the IAM policy for the asset

> **Note:** `gcp.dataplex.AssetIamPolicy` **cannot** be used in conjunction with `gcp.dataplex.AssetIamBinding` and `gcp.dataplex.AssetIamMember` or they will fight over what your policy should be.

> **Note:** `gcp.dataplex.AssetIamBinding` resources **can be** used in conjunction with `gcp.dataplex.AssetIamMember` resources **only if** they do not grant privilege to the same role.



## gcp.dataplex.AssetIamPolicy

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const admin = gcp.organizations.getIAMPolicy({
    bindings: [{
        role: "roles/viewer",
        members: ["user:jane@example.com"],
    }],
});
const policy = new gcp.dataplex.AssetIamPolicy("policy", {
    project: example.project,
    location: example.location,
    lake: example.lake,
    dataplexZone: example.dataplexZone,
    asset: example.name,
    policyData: admin.then(admin => admin.policyData),
});
```
```python
import pulumi
import pulumi_gcp as gcp

admin = gcp.organizations.get_iam_policy(bindings=[{
    "role": "roles/viewer",
    "members": ["user:jane@example.com"],
}])
policy = gcp.dataplex.AssetIamPolicy("policy",
    project=example["project"],
    location=example["location"],
    lake=example["lake"],
    dataplex_zone=example["dataplexZone"],
    asset=example["name"],
    policy_data=admin.policy_data)
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var admin = Gcp.Organizations.GetIAMPolicy.Invoke(new()
    {
        Bindings = new[]
        {
            new Gcp.Organizations.Inputs.GetIAMPolicyBindingInputArgs
            {
                Role = "roles/viewer",
                Members = new[]
                {
                    "user:jane@example.com",
                },
            },
        },
    });

    var policy = new Gcp.DataPlex.AssetIamPolicy("policy", new()
    {
        Project = example.Project,
        Location = example.Location,
        Lake = example.Lake,
        DataplexZone = example.DataplexZone,
        Asset = example.Name,
        PolicyData = admin.Apply(getIAMPolicyResult => getIAMPolicyResult.PolicyData),
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/dataplex"
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/organizations"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		admin, err := organizations.LookupIAMPolicy(ctx, &organizations.LookupIAMPolicyArgs{
			Bindings: []organizations.GetIAMPolicyBinding{
				{
					Role: "roles/viewer",
					Members: []string{
						"user:jane@example.com",
					},
				},
			},
		}, nil)
		if err != nil {
			return err
		}
		_, err = dataplex.NewAssetIamPolicy(ctx, "policy", &dataplex.AssetIamPolicyArgs{
			Project:      pulumi.Any(example.Project),
			Location:     pulumi.Any(example.Location),
			Lake:         pulumi.Any(example.Lake),
			DataplexZone: pulumi.Any(example.DataplexZone),
			Asset:        pulumi.Any(example.Name),
			PolicyData:   pulumi.String(admin.PolicyData),
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.organizations.OrganizationsFunctions;
import com.pulumi.gcp.organizations.inputs.GetIAMPolicyArgs;
import com.pulumi.gcp.dataplex.AssetIamPolicy;
import com.pulumi.gcp.dataplex.AssetIamPolicyArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        final var admin = OrganizationsFunctions.getIAMPolicy(GetIAMPolicyArgs.builder()
            .bindings(GetIAMPolicyBindingArgs.builder()
                .role("roles/viewer")
                .members("user:jane@example.com")
                .build())
            .build());

        var policy = new AssetIamPolicy("policy", AssetIamPolicyArgs.builder()
            .project(example.project())
            .location(example.location())
            .lake(example.lake())
            .dataplexZone(example.dataplexZone())
            .asset(example.name())
            .policyData(admin.applyValue(getIAMPolicyResult -> getIAMPolicyResult.policyData()))
            .build());

    }
}
```
```yaml
resources:
  policy:
    type: gcp:dataplex:AssetIamPolicy
    properties:
      project: ${example.project}
      location: ${example.location}
      lake: ${example.lake}
      dataplexZone: ${example.dataplexZone}
      asset: ${example.name}
      policyData: ${admin.policyData}
variables:
  admin:
    fn::invoke:
      function: gcp:organizations:getIAMPolicy
      arguments:
        bindings:
          - role: roles/viewer
            members:
              - user:jane@example.com
```
<!--End PulumiCodeChooser -->

## gcp.dataplex.AssetIamBinding

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const binding = new gcp.dataplex.AssetIamBinding("binding", {
    project: example.project,
    location: example.location,
    lake: example.lake,
    dataplexZone: example.dataplexZone,
    asset: example.name,
    role: "roles/viewer",
    members: ["user:jane@example.com"],
});
```
```python
import pulumi
import pulumi_gcp as gcp

binding = gcp.dataplex.AssetIamBinding("binding",
    project=example["project"],
    location=example["location"],
    lake=example["lake"],
    dataplex_zone=example["dataplexZone"],
    asset=example["name"],
    role="roles/viewer",
    members=["user:jane@example.com"])
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var binding = new Gcp.DataPlex.AssetIamBinding("binding", new()
    {
        Project = example.Project,
        Location = example.Location,
        Lake = example.Lake,
        DataplexZone = example.DataplexZone,
        Asset = example.Name,
        Role = "roles/viewer",
        Members = new[]
        {
            "user:jane@example.com",
        },
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/dataplex"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		_, err := dataplex.NewAssetIamBinding(ctx, "binding", &dataplex.AssetIamBindingArgs{
			Project:      pulumi.Any(example.Project),
			Location:     pulumi.Any(example.Location),
			Lake:         pulumi.Any(example.Lake),
			DataplexZone: pulumi.Any(example.DataplexZone),
			Asset:        pulumi.Any(example.Name),
			Role:         pulumi.String("roles/viewer"),
			Members: pulumi.StringArray{
				pulumi.String("user:jane@example.com"),
			},
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.dataplex.AssetIamBinding;
import com.pulumi.gcp.dataplex.AssetIamBindingArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        var binding = new AssetIamBinding("binding", AssetIamBindingArgs.builder()
            .project(example.project())
            .location(example.location())
            .lake(example.lake())
            .dataplexZone(example.dataplexZone())
            .asset(example.name())
            .role("roles/viewer")
            .members("user:jane@example.com")
            .build());

    }
}
```
```yaml
resources:
  binding:
    type: gcp:dataplex:AssetIamBinding
    properties:
      project: ${example.project}
      location: ${example.location}
      lake: ${example.lake}
      dataplexZone: ${example.dataplexZone}
      asset: ${example.name}
      role: roles/viewer
      members:
        - user:jane@example.com
```
<!--End PulumiCodeChooser -->

## gcp.dataplex.AssetIamMember

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const member = new gcp.dataplex.AssetIamMember("member", {
    project: example.project,
    location: example.location,
    lake: example.lake,
    dataplexZone: example.dataplexZone,
    asset: example.name,
    role: "roles/viewer",
    member: "user:jane@example.com",
});
```
```python
import pulumi
import pulumi_gcp as gcp

member = gcp.dataplex.AssetIamMember("member",
    project=example["project"],
    location=example["location"],
    lake=example["lake"],
    dataplex_zone=example["dataplexZone"],
    asset=example["name"],
    role="roles/viewer",
    member="user:jane@example.com")
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var member = new Gcp.DataPlex.AssetIamMember("member", new()
    {
        Project = example.Project,
        Location = example.Location,
        Lake = example.Lake,
        DataplexZone = example.DataplexZone,
        Asset = example.Name,
        Role = "roles/viewer",
        Member = "user:jane@example.com",
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/dataplex"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		_, err := dataplex.NewAssetIamMember(ctx, "member", &dataplex.AssetIamMemberArgs{
			Project:      pulumi.Any(example.Project),
			Location:     pulumi.Any(example.Location),
			Lake:         pulumi.Any(example.Lake),
			DataplexZone: pulumi.Any(example.DataplexZone),
			Asset:        pulumi.Any(example.Name),
			Role:         pulumi.String("roles/viewer"),
			Member:       pulumi.String("user:jane@example.com"),
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.dataplex.AssetIamMember;
import com.pulumi.gcp.dataplex.AssetIamMemberArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        var member = new AssetIamMember("member", AssetIamMemberArgs.builder()
            .project(example.project())
            .location(example.location())
            .lake(example.lake())
            .dataplexZone(example.dataplexZone())
            .asset(example.name())
            .role("roles/viewer")
            .member("user:jane@example.com")
            .build());

    }
}
```
```yaml
resources:
  member:
    type: gcp:dataplex:AssetIamMember
    properties:
      project: ${example.project}
      location: ${example.location}
      lake: ${example.lake}
      dataplexZone: ${example.dataplexZone}
      asset: ${example.name}
      role: roles/viewer
      member: user:jane@example.com
```
<!--End PulumiCodeChooser -->

## Import

For all import syntaxes, the "resource in question" can take any of the following forms:

* projects/{{project}}/locations/{{location}}/lakes/{{lake}}/zones/{{dataplex_zone}}/assets/{{name}}

* {{project}}/{{location}}/{{lake}}/{{dataplex_zone}}/{{name}}

* {{location}}/{{lake}}/{{dataplex_zone}}/{{name}}

* {{name}}

Any variables not passed in the import command will be taken from the provider configuration.

Dataplex asset IAM resources can be imported using the resource identifiers, role, and member.

IAM member imports use space-delimited identifiers: the resource in question, the role, and the member identity, e.g.

```sh
$ pulumi import gcp:dataplex/assetIamMember:AssetIamMember editor "projects/{{project}}/locations/{{location}}/lakes/{{lake}}/zones/{{dataplex_zone}}/assets/{{asset}} roles/viewer user:jane@example.com"
```

IAM binding imports use space-delimited identifiers: the resource in question and the role, e.g.

```sh
$ pulumi import gcp:dataplex/assetIamMember:AssetIamMember editor "projects/{{project}}/locations/{{location}}/lakes/{{lake}}/zones/{{dataplex_zone}}/assets/{{asset}} roles/viewer"
```

IAM policy imports use the identifier of the resource in question, e.g.

```sh
$ pulumi import gcp:dataplex/assetIamMember:AssetIamMember editor projects/{{project}}/locations/{{location}}/lakes/{{lake}}/zones/{{dataplex_zone}}/assets/{{asset}}
```

-> **Custom Roles** If you're importing a IAM resource with a custom role, make sure to use the

 full name of the custom role, e.g. `[projects/my-project|organizations/my-org]/roles/my-custom-role`.

H
asset" ;Used to find the parent resource to bind the IAM policy to
t
	conditiongBe:c
a
dataplexAssetIamMemberCondition<gcp:dataplex/AssetIamMemberCondition:AssetIamMemberCondition
dataplexZone" 

lake" 
locationB" Ó	
member" Ä	Identities that will be granted the privilege in `role`.
Each entry can have one of the following values:
* **allUsers**: A special identifier that represents anyone who is on the internet; with or without a Google account.
* **allAuthenticatedUsers**: A special identifier that represents anyone who is authenticated with a Google account or a service account.
* **user:{emailid}**: An email address that represents a specific Google account. For example, alice@gmail.com or joe@example.com.
* **serviceAccount:{emailid}**: An email address that represents a service account. For example, my-other-app@appspot.gserviceaccount.com.
* **group:{emailid}**: An email address that represents a Google group. For example, admins@example.com.
* **domain:{domain}**: A G Suite domain (primary, instead of alias) name that represents all the users of that domain. For example, google.com or example.com.
* **projectOwner:projectid**: Owners of the given project. For example, "projectOwner:my-example-project"
* **projectEditor:projectid**: Editors of the given project. For example, "projectEditor:my-example-project"
* **projectViewer:projectid**: Viewers of the given project. For example, "projectViewer:my-example-project"

projectB" The ID of the project in which the resource belongs.
If it is not provided, the project will be parsed from the identifier of the parent resource. If no project is provided in the parent identifier and no project is specified, the provider project is used.
Õ
role" ÈThe role that should be applied. Only one
`gcp.dataplex.AssetIamBinding` can be used per role. Note that custom roles must be of the format
`[projects|organizations]/{parent-name}/roles/{role-name}`.
"H
asset" ;Used to find the parent resource to bind the IAM policy to
"t
	conditiongBe:c
a
dataplexAssetIamMemberCondition<gcp:dataplex/AssetIamMemberCondition:AssetIamMemberCondition"
dataplexZone" "3
etag" '(Computed) The etag of the IAM policy.
"

lake" "
location" "Ó	
member" Ä	Identities that will be granted the privilege in `role`.
Each entry can have one of the following values:
* **allUsers**: A special identifier that represents anyone who is on the internet; with or without a Google account.
* **allAuthenticatedUsers**: A special identifier that represents anyone who is authenticated with a Google account or a service account.
* **user:{emailid}**: An email address that represents a specific Google account. For example, alice@gmail.com or joe@example.com.
* **serviceAccount:{emailid}**: An email address that represents a service account. For example, my-other-app@appspot.gserviceaccount.com.
* **group:{emailid}**: An email address that represents a Google group. For example, admins@example.com.
* **domain:{domain}**: A G Suite domain (primary, instead of alias) name that represents all the users of that domain. For example, google.com or example.com.
* **projectOwner:projectid**: Owners of the given project. For example, "projectOwner:my-example-project"
* **projectEditor:projectid**: Editors of the given project. For example, "projectEditor:my-example-project"
* **projectViewer:projectid**: Viewers of the given project. For example, "projectViewer:my-example-project"
"
project" The ID of the project in which the resource belongs.
If it is not provided, the project will be parsed from the identifier of the parent resource. If no project is provided in the parent identifier and no project is specified, the provider project is used.
"Õ
role" ÈThe role that should be applied. Only one
`gcp.dataplex.AssetIamBinding` can be used per role. Note that custom roles must be of the format
`[projects|organizations]/{parent-name}/roles/{role-name}`.
*âÖ
F
dataplexAssetIamPolicy*gcp:dataplex/assetIamPolicy:AssetIamPolicyÿÍThree different resources help you manage your IAM policy for Dataplex Asset. Each of these resources serves a different use case:

* `gcp.dataplex.AssetIamPolicy`: Authoritative. Sets the IAM policy for the asset and replaces any existing policy already attached.
* `gcp.dataplex.AssetIamBinding`: Authoritative for a given role. Updates the IAM policy to grant a role to a list of members. Other roles within the IAM policy for the asset are preserved.
* `gcp.dataplex.AssetIamMember`: Non-authoritative. Updates the IAM policy to grant a role to a new member. Other members for the role for the asset are preserved.

A data source can be used to retrieve policy data in advent you do not need creation

* `gcp.dataplex.AssetIamPolicy`: Retrieves the IAM policy for the asset

> **Note:** `gcp.dataplex.AssetIamPolicy` **cannot** be used in conjunction with `gcp.dataplex.AssetIamBinding` and `gcp.dataplex.AssetIamMember` or they will fight over what your policy should be.

> **Note:** `gcp.dataplex.AssetIamBinding` resources **can be** used in conjunction with `gcp.dataplex.AssetIamMember` resources **only if** they do not grant privilege to the same role.



## gcp.dataplex.AssetIamPolicy

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const admin = gcp.organizations.getIAMPolicy({
    bindings: [{
        role: "roles/viewer",
        members: ["user:jane@example.com"],
    }],
});
const policy = new gcp.dataplex.AssetIamPolicy("policy", {
    project: example.project,
    location: example.location,
    lake: example.lake,
    dataplexZone: example.dataplexZone,
    asset: example.name,
    policyData: admin.then(admin => admin.policyData),
});
```
```python
import pulumi
import pulumi_gcp as gcp

admin = gcp.organizations.get_iam_policy(bindings=[{
    "role": "roles/viewer",
    "members": ["user:jane@example.com"],
}])
policy = gcp.dataplex.AssetIamPolicy("policy",
    project=example["project"],
    location=example["location"],
    lake=example["lake"],
    dataplex_zone=example["dataplexZone"],
    asset=example["name"],
    policy_data=admin.policy_data)
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var admin = Gcp.Organizations.GetIAMPolicy.Invoke(new()
    {
        Bindings = new[]
        {
            new Gcp.Organizations.Inputs.GetIAMPolicyBindingInputArgs
            {
                Role = "roles/viewer",
                Members = new[]
                {
                    "user:jane@example.com",
                },
            },
        },
    });

    var policy = new Gcp.DataPlex.AssetIamPolicy("policy", new()
    {
        Project = example.Project,
        Location = example.Location,
        Lake = example.Lake,
        DataplexZone = example.DataplexZone,
        Asset = example.Name,
        PolicyData = admin.Apply(getIAMPolicyResult => getIAMPolicyResult.PolicyData),
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/dataplex"
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/organizations"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		admin, err := organizations.LookupIAMPolicy(ctx, &organizations.LookupIAMPolicyArgs{
			Bindings: []organizations.GetIAMPolicyBinding{
				{
					Role: "roles/viewer",
					Members: []string{
						"user:jane@example.com",
					},
				},
			},
		}, nil)
		if err != nil {
			return err
		}
		_, err = dataplex.NewAssetIamPolicy(ctx, "policy", &dataplex.AssetIamPolicyArgs{
			Project:      pulumi.Any(example.Project),
			Location:     pulumi.Any(example.Location),
			Lake:         pulumi.Any(example.Lake),
			DataplexZone: pulumi.Any(example.DataplexZone),
			Asset:        pulumi.Any(example.Name),
			PolicyData:   pulumi.String(admin.PolicyData),
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.organizations.OrganizationsFunctions;
import com.pulumi.gcp.organizations.inputs.GetIAMPolicyArgs;
import com.pulumi.gcp.dataplex.AssetIamPolicy;
import com.pulumi.gcp.dataplex.AssetIamPolicyArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        final var admin = OrganizationsFunctions.getIAMPolicy(GetIAMPolicyArgs.builder()
            .bindings(GetIAMPolicyBindingArgs.builder()
                .role("roles/viewer")
                .members("user:jane@example.com")
                .build())
            .build());

        var policy = new AssetIamPolicy("policy", AssetIamPolicyArgs.builder()
            .project(example.project())
            .location(example.location())
            .lake(example.lake())
            .dataplexZone(example.dataplexZone())
            .asset(example.name())
            .policyData(admin.applyValue(getIAMPolicyResult -> getIAMPolicyResult.policyData()))
            .build());

    }
}
```
```yaml
resources:
  policy:
    type: gcp:dataplex:AssetIamPolicy
    properties:
      project: ${example.project}
      location: ${example.location}
      lake: ${example.lake}
      dataplexZone: ${example.dataplexZone}
      asset: ${example.name}
      policyData: ${admin.policyData}
variables:
  admin:
    fn::invoke:
      function: gcp:organizations:getIAMPolicy
      arguments:
        bindings:
          - role: roles/viewer
            members:
              - user:jane@example.com
```
<!--End PulumiCodeChooser -->

## gcp.dataplex.AssetIamBinding

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const binding = new gcp.dataplex.AssetIamBinding("binding", {
    project: example.project,
    location: example.location,
    lake: example.lake,
    dataplexZone: example.dataplexZone,
    asset: example.name,
    role: "roles/viewer",
    members: ["user:jane@example.com"],
});
```
```python
import pulumi
import pulumi_gcp as gcp

binding = gcp.dataplex.AssetIamBinding("binding",
    project=example["project"],
    location=example["location"],
    lake=example["lake"],
    dataplex_zone=example["dataplexZone"],
    asset=example["name"],
    role="roles/viewer",
    members=["user:jane@example.com"])
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var binding = new Gcp.DataPlex.AssetIamBinding("binding", new()
    {
        Project = example.Project,
        Location = example.Location,
        Lake = example.Lake,
        DataplexZone = example.DataplexZone,
        Asset = example.Name,
        Role = "roles/viewer",
        Members = new[]
        {
            "user:jane@example.com",
        },
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/dataplex"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		_, err := dataplex.NewAssetIamBinding(ctx, "binding", &dataplex.AssetIamBindingArgs{
			Project:      pulumi.Any(example.Project),
			Location:     pulumi.Any(example.Location),
			Lake:         pulumi.Any(example.Lake),
			DataplexZone: pulumi.Any(example.DataplexZone),
			Asset:        pulumi.Any(example.Name),
			Role:         pulumi.String("roles/viewer"),
			Members: pulumi.StringArray{
				pulumi.String("user:jane@example.com"),
			},
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.dataplex.AssetIamBinding;
import com.pulumi.gcp.dataplex.AssetIamBindingArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        var binding = new AssetIamBinding("binding", AssetIamBindingArgs.builder()
            .project(example.project())
            .location(example.location())
            .lake(example.lake())
            .dataplexZone(example.dataplexZone())
            .asset(example.name())
            .role("roles/viewer")
            .members("user:jane@example.com")
            .build());

    }
}
```
```yaml
resources:
  binding:
    type: gcp:dataplex:AssetIamBinding
    properties:
      project: ${example.project}
      location: ${example.location}
      lake: ${example.lake}
      dataplexZone: ${example.dataplexZone}
      asset: ${example.name}
      role: roles/viewer
      members:
        - user:jane@example.com
```
<!--End PulumiCodeChooser -->

## gcp.dataplex.AssetIamMember

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const member = new gcp.dataplex.AssetIamMember("member", {
    project: example.project,
    location: example.location,
    lake: example.lake,
    dataplexZone: example.dataplexZone,
    asset: example.name,
    role: "roles/viewer",
    member: "user:jane@example.com",
});
```
```python
import pulumi
import pulumi_gcp as gcp

member = gcp.dataplex.AssetIamMember("member",
    project=example["project"],
    location=example["location"],
    lake=example["lake"],
    dataplex_zone=example["dataplexZone"],
    asset=example["name"],
    role="roles/viewer",
    member="user:jane@example.com")
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var member = new Gcp.DataPlex.AssetIamMember("member", new()
    {
        Project = example.Project,
        Location = example.Location,
        Lake = example.Lake,
        DataplexZone = example.DataplexZone,
        Asset = example.Name,
        Role = "roles/viewer",
        Member = "user:jane@example.com",
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/dataplex"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		_, err := dataplex.NewAssetIamMember(ctx, "member", &dataplex.AssetIamMemberArgs{
			Project:      pulumi.Any(example.Project),
			Location:     pulumi.Any(example.Location),
			Lake:         pulumi.Any(example.Lake),
			DataplexZone: pulumi.Any(example.DataplexZone),
			Asset:        pulumi.Any(example.Name),
			Role:         pulumi.String("roles/viewer"),
			Member:       pulumi.String("user:jane@example.com"),
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.dataplex.AssetIamMember;
import com.pulumi.gcp.dataplex.AssetIamMemberArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        var member = new AssetIamMember("member", AssetIamMemberArgs.builder()
            .project(example.project())
            .location(example.location())
            .lake(example.lake())
            .dataplexZone(example.dataplexZone())
            .asset(example.name())
            .role("roles/viewer")
            .member("user:jane@example.com")
            .build());

    }
}
```
```yaml
resources:
  member:
    type: gcp:dataplex:AssetIamMember
    properties:
      project: ${example.project}
      location: ${example.location}
      lake: ${example.lake}
      dataplexZone: ${example.dataplexZone}
      asset: ${example.name}
      role: roles/viewer
      member: user:jane@example.com
```
<!--End PulumiCodeChooser -->


## This resource supports User Project Overrides.

-

# IAM policy for Dataplex Asset
Three different resources help you manage your IAM policy for Dataplex Asset. Each of these resources serves a different use case:

* `gcp.dataplex.AssetIamPolicy`: Authoritative. Sets the IAM policy for the asset and replaces any existing policy already attached.
* `gcp.dataplex.AssetIamBinding`: Authoritative for a given role. Updates the IAM policy to grant a role to a list of members. Other roles within the IAM policy for the asset are preserved.
* `gcp.dataplex.AssetIamMember`: Non-authoritative. Updates the IAM policy to grant a role to a new member. Other members for the role for the asset are preserved.

A data source can be used to retrieve policy data in advent you do not need creation

* `gcp.dataplex.AssetIamPolicy`: Retrieves the IAM policy for the asset

> **Note:** `gcp.dataplex.AssetIamPolicy` **cannot** be used in conjunction with `gcp.dataplex.AssetIamBinding` and `gcp.dataplex.AssetIamMember` or they will fight over what your policy should be.

> **Note:** `gcp.dataplex.AssetIamBinding` resources **can be** used in conjunction with `gcp.dataplex.AssetIamMember` resources **only if** they do not grant privilege to the same role.



## gcp.dataplex.AssetIamPolicy

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const admin = gcp.organizations.getIAMPolicy({
    bindings: [{
        role: "roles/viewer",
        members: ["user:jane@example.com"],
    }],
});
const policy = new gcp.dataplex.AssetIamPolicy("policy", {
    project: example.project,
    location: example.location,
    lake: example.lake,
    dataplexZone: example.dataplexZone,
    asset: example.name,
    policyData: admin.then(admin => admin.policyData),
});
```
```python
import pulumi
import pulumi_gcp as gcp

admin = gcp.organizations.get_iam_policy(bindings=[{
    "role": "roles/viewer",
    "members": ["user:jane@example.com"],
}])
policy = gcp.dataplex.AssetIamPolicy("policy",
    project=example["project"],
    location=example["location"],
    lake=example["lake"],
    dataplex_zone=example["dataplexZone"],
    asset=example["name"],
    policy_data=admin.policy_data)
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var admin = Gcp.Organizations.GetIAMPolicy.Invoke(new()
    {
        Bindings = new[]
        {
            new Gcp.Organizations.Inputs.GetIAMPolicyBindingInputArgs
            {
                Role = "roles/viewer",
                Members = new[]
                {
                    "user:jane@example.com",
                },
            },
        },
    });

    var policy = new Gcp.DataPlex.AssetIamPolicy("policy", new()
    {
        Project = example.Project,
        Location = example.Location,
        Lake = example.Lake,
        DataplexZone = example.DataplexZone,
        Asset = example.Name,
        PolicyData = admin.Apply(getIAMPolicyResult => getIAMPolicyResult.PolicyData),
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/dataplex"
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/organizations"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		admin, err := organizations.LookupIAMPolicy(ctx, &organizations.LookupIAMPolicyArgs{
			Bindings: []organizations.GetIAMPolicyBinding{
				{
					Role: "roles/viewer",
					Members: []string{
						"user:jane@example.com",
					},
				},
			},
		}, nil)
		if err != nil {
			return err
		}
		_, err = dataplex.NewAssetIamPolicy(ctx, "policy", &dataplex.AssetIamPolicyArgs{
			Project:      pulumi.Any(example.Project),
			Location:     pulumi.Any(example.Location),
			Lake:         pulumi.Any(example.Lake),
			DataplexZone: pulumi.Any(example.DataplexZone),
			Asset:        pulumi.Any(example.Name),
			PolicyData:   pulumi.String(admin.PolicyData),
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.organizations.OrganizationsFunctions;
import com.pulumi.gcp.organizations.inputs.GetIAMPolicyArgs;
import com.pulumi.gcp.dataplex.AssetIamPolicy;
import com.pulumi.gcp.dataplex.AssetIamPolicyArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        final var admin = OrganizationsFunctions.getIAMPolicy(GetIAMPolicyArgs.builder()
            .bindings(GetIAMPolicyBindingArgs.builder()
                .role("roles/viewer")
                .members("user:jane@example.com")
                .build())
            .build());

        var policy = new AssetIamPolicy("policy", AssetIamPolicyArgs.builder()
            .project(example.project())
            .location(example.location())
            .lake(example.lake())
            .dataplexZone(example.dataplexZone())
            .asset(example.name())
            .policyData(admin.applyValue(getIAMPolicyResult -> getIAMPolicyResult.policyData()))
            .build());

    }
}
```
```yaml
resources:
  policy:
    type: gcp:dataplex:AssetIamPolicy
    properties:
      project: ${example.project}
      location: ${example.location}
      lake: ${example.lake}
      dataplexZone: ${example.dataplexZone}
      asset: ${example.name}
      policyData: ${admin.policyData}
variables:
  admin:
    fn::invoke:
      function: gcp:organizations:getIAMPolicy
      arguments:
        bindings:
          - role: roles/viewer
            members:
              - user:jane@example.com
```
<!--End PulumiCodeChooser -->

## gcp.dataplex.AssetIamBinding

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const binding = new gcp.dataplex.AssetIamBinding("binding", {
    project: example.project,
    location: example.location,
    lake: example.lake,
    dataplexZone: example.dataplexZone,
    asset: example.name,
    role: "roles/viewer",
    members: ["user:jane@example.com"],
});
```
```python
import pulumi
import pulumi_gcp as gcp

binding = gcp.dataplex.AssetIamBinding("binding",
    project=example["project"],
    location=example["location"],
    lake=example["lake"],
    dataplex_zone=example["dataplexZone"],
    asset=example["name"],
    role="roles/viewer",
    members=["user:jane@example.com"])
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var binding = new Gcp.DataPlex.AssetIamBinding("binding", new()
    {
        Project = example.Project,
        Location = example.Location,
        Lake = example.Lake,
        DataplexZone = example.DataplexZone,
        Asset = example.Name,
        Role = "roles/viewer",
        Members = new[]
        {
            "user:jane@example.com",
        },
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/dataplex"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		_, err := dataplex.NewAssetIamBinding(ctx, "binding", &dataplex.AssetIamBindingArgs{
			Project:      pulumi.Any(example.Project),
			Location:     pulumi.Any(example.Location),
			Lake:         pulumi.Any(example.Lake),
			DataplexZone: pulumi.Any(example.DataplexZone),
			Asset:        pulumi.Any(example.Name),
			Role:         pulumi.String("roles/viewer"),
			Members: pulumi.StringArray{
				pulumi.String("user:jane@example.com"),
			},
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.dataplex.AssetIamBinding;
import com.pulumi.gcp.dataplex.AssetIamBindingArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        var binding = new AssetIamBinding("binding", AssetIamBindingArgs.builder()
            .project(example.project())
            .location(example.location())
            .lake(example.lake())
            .dataplexZone(example.dataplexZone())
            .asset(example.name())
            .role("roles/viewer")
            .members("user:jane@example.com")
            .build());

    }
}
```
```yaml
resources:
  binding:
    type: gcp:dataplex:AssetIamBinding
    properties:
      project: ${example.project}
      location: ${example.location}
      lake: ${example.lake}
      dataplexZone: ${example.dataplexZone}
      asset: ${example.name}
      role: roles/viewer
      members:
        - user:jane@example.com
```
<!--End PulumiCodeChooser -->

## gcp.dataplex.AssetIamMember

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const member = new gcp.dataplex.AssetIamMember("member", {
    project: example.project,
    location: example.location,
    lake: example.lake,
    dataplexZone: example.dataplexZone,
    asset: example.name,
    role: "roles/viewer",
    member: "user:jane@example.com",
});
```
```python
import pulumi
import pulumi_gcp as gcp

member = gcp.dataplex.AssetIamMember("member",
    project=example["project"],
    location=example["location"],
    lake=example["lake"],
    dataplex_zone=example["dataplexZone"],
    asset=example["name"],
    role="roles/viewer",
    member="user:jane@example.com")
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var member = new Gcp.DataPlex.AssetIamMember("member", new()
    {
        Project = example.Project,
        Location = example.Location,
        Lake = example.Lake,
        DataplexZone = example.DataplexZone,
        Asset = example.Name,
        Role = "roles/viewer",
        Member = "user:jane@example.com",
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/dataplex"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		_, err := dataplex.NewAssetIamMember(ctx, "member", &dataplex.AssetIamMemberArgs{
			Project:      pulumi.Any(example.Project),
			Location:     pulumi.Any(example.Location),
			Lake:         pulumi.Any(example.Lake),
			DataplexZone: pulumi.Any(example.DataplexZone),
			Asset:        pulumi.Any(example.Name),
			Role:         pulumi.String("roles/viewer"),
			Member:       pulumi.String("user:jane@example.com"),
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.dataplex.AssetIamMember;
import com.pulumi.gcp.dataplex.AssetIamMemberArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        var member = new AssetIamMember("member", AssetIamMemberArgs.builder()
            .project(example.project())
            .location(example.location())
            .lake(example.lake())
            .dataplexZone(example.dataplexZone())
            .asset(example.name())
            .role("roles/viewer")
            .member("user:jane@example.com")
            .build());

    }
}
```
```yaml
resources:
  member:
    type: gcp:dataplex:AssetIamMember
    properties:
      project: ${example.project}
      location: ${example.location}
      lake: ${example.lake}
      dataplexZone: ${example.dataplexZone}
      asset: ${example.name}
      role: roles/viewer
      member: user:jane@example.com
```
<!--End PulumiCodeChooser -->

## Import

For all import syntaxes, the "resource in question" can take any of the following forms:

* projects/{{project}}/locations/{{location}}/lakes/{{lake}}/zones/{{dataplex_zone}}/assets/{{name}}

* {{project}}/{{location}}/{{lake}}/{{dataplex_zone}}/{{name}}

* {{location}}/{{lake}}/{{dataplex_zone}}/{{name}}

* {{name}}

Any variables not passed in the import command will be taken from the provider configuration.

Dataplex asset IAM resources can be imported using the resource identifiers, role, and member.

IAM member imports use space-delimited identifiers: the resource in question, the role, and the member identity, e.g.

```sh
$ pulumi import gcp:dataplex/assetIamPolicy:AssetIamPolicy editor "projects/{{project}}/locations/{{location}}/lakes/{{lake}}/zones/{{dataplex_zone}}/assets/{{asset}} roles/viewer user:jane@example.com"
```

IAM binding imports use space-delimited identifiers: the resource in question and the role, e.g.

```sh
$ pulumi import gcp:dataplex/assetIamPolicy:AssetIamPolicy editor "projects/{{project}}/locations/{{location}}/lakes/{{lake}}/zones/{{dataplex_zone}}/assets/{{asset}} roles/viewer"
```

IAM policy imports use the identifier of the resource in question, e.g.

```sh
$ pulumi import gcp:dataplex/assetIamPolicy:AssetIamPolicy editor projects/{{project}}/locations/{{location}}/lakes/{{lake}}/zones/{{dataplex_zone}}/assets/{{asset}}
```

-> **Custom Roles** If you're importing a IAM resource with a custom role, make sure to use the

 full name of the custom role, e.g. `[projects/my-project|organizations/my-org]/roles/my-custom-role`.

H
asset" ;Used to find the parent resource to bind the IAM policy to

dataplexZone" 

lake" 
locationB" _

policyData" MThe policy data generated by
a `gcp.organizations.getIAMPolicy` data source.

projectB" The ID of the project in which the resource belongs.
If it is not provided, the project will be parsed from the identifier of the parent resource. If no project is provided in the parent identifier and no project is specified, the provider project is used.
"H
asset" ;Used to find the parent resource to bind the IAM policy to
"
dataplexZone" "3
etag" '(Computed) The etag of the IAM policy.
"

lake" "
location" "_

policyData" MThe policy data generated by
a `gcp.organizations.getIAMPolicy` data source.
"
project" The ID of the project in which the resource belongs.
If it is not provided, the project will be parsed from the identifier of the parent resource. If no project is provided in the parent identifier and no project is specified, the provider project is used.
*õ¥
4
dataplexDatascangcp:dataplex/datascan:Datascan¥Represents a user-visible job which provides the insights for the related data source.


To get more information about Datascan, see:

* [API documentation](https://cloud.google.com/dataplex/docs/reference/rest)
* How-to Guides
    * [Official Documentation](https://cloud.google.com/dataplex/docs)

## Example Usage

### Dataplex Datascan Basic Profile


<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const basicProfile = new gcp.dataplex.Datascan("basic_profile", {
    location: "us-central1",
    dataScanId: "dataprofile-basic",
    data: {
        resource: "//bigquery.googleapis.com/projects/bigquery-public-data/datasets/samples/tables/shakespeare",
    },
    executionSpec: {
        trigger: {
            onDemand: {},
        },
    },
    dataProfileSpec: {},
    project: "my-project-name",
});
```
```python
import pulumi
import pulumi_gcp as gcp

basic_profile = gcp.dataplex.Datascan("basic_profile",
    location="us-central1",
    data_scan_id="dataprofile-basic",
    data={
        "resource": "//bigquery.googleapis.com/projects/bigquery-public-data/datasets/samples/tables/shakespeare",
    },
    execution_spec={
        "trigger": {
            "on_demand": {},
        },
    },
    data_profile_spec={},
    project="my-project-name")
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var basicProfile = new Gcp.DataPlex.Datascan("basic_profile", new()
    {
        Location = "us-central1",
        DataScanId = "dataprofile-basic",
        Data = new Gcp.DataPlex.Inputs.DatascanDataArgs
        {
            Resource = "//bigquery.googleapis.com/projects/bigquery-public-data/datasets/samples/tables/shakespeare",
        },
        ExecutionSpec = new Gcp.DataPlex.Inputs.DatascanExecutionSpecArgs
        {
            Trigger = new Gcp.DataPlex.Inputs.DatascanExecutionSpecTriggerArgs
            {
                OnDemand = null,
            },
        },
        DataProfileSpec = null,
        Project = "my-project-name",
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/dataplex"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		_, err := dataplex.NewDatascan(ctx, "basic_profile", &dataplex.DatascanArgs{
			Location:   pulumi.String("us-central1"),
			DataScanId: pulumi.String("dataprofile-basic"),
			Data: &dataplex.DatascanDataArgs{
				Resource: pulumi.String("//bigquery.googleapis.com/projects/bigquery-public-data/datasets/samples/tables/shakespeare"),
			},
			ExecutionSpec: &dataplex.DatascanExecutionSpecArgs{
				Trigger: &dataplex.DatascanExecutionSpecTriggerArgs{
					OnDemand: &dataplex.DatascanExecutionSpecTriggerOnDemandArgs{},
				},
			},
			DataProfileSpec: &dataplex.DatascanDataProfileSpecArgs{},
			Project:         pulumi.String("my-project-name"),
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.dataplex.Datascan;
import com.pulumi.gcp.dataplex.DatascanArgs;
import com.pulumi.gcp.dataplex.inputs.DatascanDataArgs;
import com.pulumi.gcp.dataplex.inputs.DatascanExecutionSpecArgs;
import com.pulumi.gcp.dataplex.inputs.DatascanExecutionSpecTriggerArgs;
import com.pulumi.gcp.dataplex.inputs.DatascanExecutionSpecTriggerOnDemandArgs;
import com.pulumi.gcp.dataplex.inputs.DatascanDataProfileSpecArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        var basicProfile = new Datascan("basicProfile", DatascanArgs.builder()
            .location("us-central1")
            .dataScanId("dataprofile-basic")
            .data(DatascanDataArgs.builder()
                .resource("//bigquery.googleapis.com/projects/bigquery-public-data/datasets/samples/tables/shakespeare")
                .build())
            .executionSpec(DatascanExecutionSpecArgs.builder()
                .trigger(DatascanExecutionSpecTriggerArgs.builder()
                    .onDemand()
                    .build())
                .build())
            .dataProfileSpec()
            .project("my-project-name")
            .build());

    }
}
```
```yaml
resources:
  basicProfile:
    type: gcp:dataplex:Datascan
    name: basic_profile
    properties:
      location: us-central1
      dataScanId: dataprofile-basic
      data:
        resource: //bigquery.googleapis.com/projects/bigquery-public-data/datasets/samples/tables/shakespeare
      executionSpec:
        trigger:
          onDemand: {}
      dataProfileSpec: {}
      project: my-project-name
```
<!--End PulumiCodeChooser -->
### Dataplex Datascan Full Profile


<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const source = new gcp.bigquery.Dataset("source", {
    datasetId: "dataplex_dataset",
    friendlyName: "test",
    description: "This is a test description",
    location: "US",
    deleteContentsOnDestroy: true,
});
const fullProfile = new gcp.dataplex.Datascan("full_profile", {
    location: "us-central1",
    displayName: "Full Datascan Profile",
    dataScanId: "dataprofile-full",
    description: "Example resource - Full Datascan Profile",
    labels: {
        author: "billing",
    },
    data: {
        resource: "//bigquery.googleapis.com/projects/bigquery-public-data/datasets/samples/tables/shakespeare",
    },
    executionSpec: {
        trigger: {
            schedule: {
                cron: "TZ=America/New_York 1 1 * * *",
            },
        },
    },
    dataProfileSpec: {
        samplingPercent: 80,
        rowFilter: "word_count > 10",
        includeFields: {
            fieldNames: ["word_count"],
        },
        excludeFields: {
            fieldNames: ["property_type"],
        },
        postScanActions: {
            bigqueryExport: {
                resultsTable: "//bigquery.googleapis.com/projects/my-project-name/datasets/dataplex_dataset/tables/profile_export",
            },
        },
    },
    project: "my-project-name",
}, {
    dependsOn: [source],
});
```
```python
import pulumi
import pulumi_gcp as gcp

source = gcp.bigquery.Dataset("source",
    dataset_id="dataplex_dataset",
    friendly_name="test",
    description="This is a test description",
    location="US",
    delete_contents_on_destroy=True)
full_profile = gcp.dataplex.Datascan("full_profile",
    location="us-central1",
    display_name="Full Datascan Profile",
    data_scan_id="dataprofile-full",
    description="Example resource - Full Datascan Profile",
    labels={
        "author": "billing",
    },
    data={
        "resource": "//bigquery.googleapis.com/projects/bigquery-public-data/datasets/samples/tables/shakespeare",
    },
    execution_spec={
        "trigger": {
            "schedule": {
                "cron": "TZ=America/New_York 1 1 * * *",
            },
        },
    },
    data_profile_spec={
        "sampling_percent": 80,
        "row_filter": "word_count > 10",
        "include_fields": {
            "field_names": ["word_count"],
        },
        "exclude_fields": {
            "field_names": ["property_type"],
        },
        "post_scan_actions": {
            "bigquery_export": {
                "results_table": "//bigquery.googleapis.com/projects/my-project-name/datasets/dataplex_dataset/tables/profile_export",
            },
        },
    },
    project="my-project-name",
    opts = pulumi.ResourceOptions(depends_on=[source]))
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var source = new Gcp.BigQuery.Dataset("source", new()
    {
        DatasetId = "dataplex_dataset",
        FriendlyName = "test",
        Description = "This is a test description",
        Location = "US",
        DeleteContentsOnDestroy = true,
    });

    var fullProfile = new Gcp.DataPlex.Datascan("full_profile", new()
    {
        Location = "us-central1",
        DisplayName = "Full Datascan Profile",
        DataScanId = "dataprofile-full",
        Description = "Example resource - Full Datascan Profile",
        Labels = 
        {
            { "author", "billing" },
        },
        Data = new Gcp.DataPlex.Inputs.DatascanDataArgs
        {
            Resource = "//bigquery.googleapis.com/projects/bigquery-public-data/datasets/samples/tables/shakespeare",
        },
        ExecutionSpec = new Gcp.DataPlex.Inputs.DatascanExecutionSpecArgs
        {
            Trigger = new Gcp.DataPlex.Inputs.DatascanExecutionSpecTriggerArgs
            {
                Schedule = new Gcp.DataPlex.Inputs.DatascanExecutionSpecTriggerScheduleArgs
                {
                    Cron = "TZ=America/New_York 1 1 * * *",
                },
            },
        },
        DataProfileSpec = new Gcp.DataPlex.Inputs.DatascanDataProfileSpecArgs
        {
            SamplingPercent = 80,
            RowFilter = "word_count > 10",
            IncludeFields = new Gcp.DataPlex.Inputs.DatascanDataProfileSpecIncludeFieldsArgs
            {
                FieldNames = new[]
                {
                    "word_count",
                },
            },
            ExcludeFields = new Gcp.DataPlex.Inputs.DatascanDataProfileSpecExcludeFieldsArgs
            {
                FieldNames = new[]
                {
                    "property_type",
                },
            },
            PostScanActions = new Gcp.DataPlex.Inputs.DatascanDataProfileSpecPostScanActionsArgs
            {
                BigqueryExport = new Gcp.DataPlex.Inputs.DatascanDataProfileSpecPostScanActionsBigqueryExportArgs
                {
                    ResultsTable = "//bigquery.googleapis.com/projects/my-project-name/datasets/dataplex_dataset/tables/profile_export",
                },
            },
        },
        Project = "my-project-name",
    }, new CustomResourceOptions
    {
        DependsOn =
        {
            source,
        },
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/bigquery"
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/dataplex"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		source, err := bigquery.NewDataset(ctx, "source", &bigquery.DatasetArgs{
			DatasetId:               pulumi.String("dataplex_dataset"),
			FriendlyName:            pulumi.String("test"),
			Description:             pulumi.String("This is a test description"),
			Location:                pulumi.String("US"),
			DeleteContentsOnDestroy: pulumi.Bool(true),
		})
		if err != nil {
			return err
		}
		_, err = dataplex.NewDatascan(ctx, "full_profile", &dataplex.DatascanArgs{
			Location:    pulumi.String("us-central1"),
			DisplayName: pulumi.String("Full Datascan Profile"),
			DataScanId:  pulumi.String("dataprofile-full"),
			Description: pulumi.String("Example resource - Full Datascan Profile"),
			Labels: pulumi.StringMap{
				"author": pulumi.String("billing"),
			},
			Data: &dataplex.DatascanDataArgs{
				Resource: pulumi.String("//bigquery.googleapis.com/projects/bigquery-public-data/datasets/samples/tables/shakespeare"),
			},
			ExecutionSpec: &dataplex.DatascanExecutionSpecArgs{
				Trigger: &dataplex.DatascanExecutionSpecTriggerArgs{
					Schedule: &dataplex.DatascanExecutionSpecTriggerScheduleArgs{
						Cron: pulumi.String("TZ=America/New_York 1 1 * * *"),
					},
				},
			},
			DataProfileSpec: &dataplex.DatascanDataProfileSpecArgs{
				SamplingPercent: pulumi.Float64(80),
				RowFilter:       pulumi.String("word_count > 10"),
				IncludeFields: &dataplex.DatascanDataProfileSpecIncludeFieldsArgs{
					FieldNames: pulumi.StringArray{
						pulumi.String("word_count"),
					},
				},
				ExcludeFields: &dataplex.DatascanDataProfileSpecExcludeFieldsArgs{
					FieldNames: pulumi.StringArray{
						pulumi.String("property_type"),
					},
				},
				PostScanActions: &dataplex.DatascanDataProfileSpecPostScanActionsArgs{
					BigqueryExport: &dataplex.DatascanDataProfileSpecPostScanActionsBigqueryExportArgs{
						ResultsTable: pulumi.String("//bigquery.googleapis.com/projects/my-project-name/datasets/dataplex_dataset/tables/profile_export"),
					},
				},
			},
			Project: pulumi.String("my-project-name"),
		}, pulumi.DependsOn([]pulumi.Resource{
			source,
		}))
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.bigquery.Dataset;
import com.pulumi.gcp.bigquery.DatasetArgs;
import com.pulumi.gcp.dataplex.Datascan;
import com.pulumi.gcp.dataplex.DatascanArgs;
import com.pulumi.gcp.dataplex.inputs.DatascanDataArgs;
import com.pulumi.gcp.dataplex.inputs.DatascanExecutionSpecArgs;
import com.pulumi.gcp.dataplex.inputs.DatascanExecutionSpecTriggerArgs;
import com.pulumi.gcp.dataplex.inputs.DatascanExecutionSpecTriggerScheduleArgs;
import com.pulumi.gcp.dataplex.inputs.DatascanDataProfileSpecArgs;
import com.pulumi.gcp.dataplex.inputs.DatascanDataProfileSpecIncludeFieldsArgs;
import com.pulumi.gcp.dataplex.inputs.DatascanDataProfileSpecExcludeFieldsArgs;
import com.pulumi.gcp.dataplex.inputs.DatascanDataProfileSpecPostScanActionsArgs;
import com.pulumi.gcp.dataplex.inputs.DatascanDataProfileSpecPostScanActionsBigqueryExportArgs;
import com.pulumi.resources.CustomResourceOptions;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        var source = new Dataset("source", DatasetArgs.builder()
            .datasetId("dataplex_dataset")
            .friendlyName("test")
            .description("This is a test description")
            .location("US")
            .deleteContentsOnDestroy(true)
            .build());

        var fullProfile = new Datascan("fullProfile", DatascanArgs.builder()
            .location("us-central1")
            .displayName("Full Datascan Profile")
            .dataScanId("dataprofile-full")
            .description("Example resource - Full Datascan Profile")
            .labels(Map.of("author", "billing"))
            .data(DatascanDataArgs.builder()
                .resource("//bigquery.googleapis.com/projects/bigquery-public-data/datasets/samples/tables/shakespeare")
                .build())
            .executionSpec(DatascanExecutionSpecArgs.builder()
                .trigger(DatascanExecutionSpecTriggerArgs.builder()
                    .schedule(DatascanExecutionSpecTriggerScheduleArgs.builder()
                        .cron("TZ=America/New_York 1 1 * * *")
                        .build())
                    .build())
                .build())
            .dataProfileSpec(DatascanDataProfileSpecArgs.builder()
                .samplingPercent(80)
                .rowFilter("word_count > 10")
                .includeFields(DatascanDataProfileSpecIncludeFieldsArgs.builder()
                    .fieldNames("word_count")
                    .build())
                .excludeFields(DatascanDataProfileSpecExcludeFieldsArgs.builder()
                    .fieldNames("property_type")
                    .build())
                .postScanActions(DatascanDataProfileSpecPostScanActionsArgs.builder()
                    .bigqueryExport(DatascanDataProfileSpecPostScanActionsBigqueryExportArgs.builder()
                        .resultsTable("//bigquery.googleapis.com/projects/my-project-name/datasets/dataplex_dataset/tables/profile_export")
                        .build())
                    .build())
                .build())
            .project("my-project-name")
            .build(), CustomResourceOptions.builder()
                .dependsOn(source)
                .build());

    }
}
```
```yaml
resources:
  fullProfile:
    type: gcp:dataplex:Datascan
    name: full_profile
    properties:
      location: us-central1
      displayName: Full Datascan Profile
      dataScanId: dataprofile-full
      description: Example resource - Full Datascan Profile
      labels:
        author: billing
      data:
        resource: //bigquery.googleapis.com/projects/bigquery-public-data/datasets/samples/tables/shakespeare
      executionSpec:
        trigger:
          schedule:
            cron: TZ=America/New_York 1 1 * * *
      dataProfileSpec:
        samplingPercent: 80
        rowFilter: word_count > 10
        includeFields:
          fieldNames:
            - word_count
        excludeFields:
          fieldNames:
            - property_type
        postScanActions:
          bigqueryExport:
            resultsTable: //bigquery.googleapis.com/projects/my-project-name/datasets/dataplex_dataset/tables/profile_export
      project: my-project-name
    options:
      dependsOn:
        - ${source}
  source:
    type: gcp:bigquery:Dataset
    properties:
      datasetId: dataplex_dataset
      friendlyName: test
      description: This is a test description
      location: US
      deleteContentsOnDestroy: true
```
<!--End PulumiCodeChooser -->
### Dataplex Datascan Basic Quality


<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const basicQuality = new gcp.dataplex.Datascan("basic_quality", {
    location: "us-central1",
    dataScanId: "dataquality-basic",
    data: {
        resource: "//bigquery.googleapis.com/projects/bigquery-public-data/datasets/samples/tables/shakespeare",
    },
    executionSpec: {
        trigger: {
            onDemand: {},
        },
    },
    dataQualitySpec: {
        rules: [{
            dimension: "VALIDITY",
            name: "rule1",
            description: "rule 1 for validity dimension",
            tableConditionExpectation: {
                sqlExpression: "COUNT(*) > 0",
            },
        }],
    },
    project: "my-project-name",
});
```
```python
import pulumi
import pulumi_gcp as gcp

basic_quality = gcp.dataplex.Datascan("basic_quality",
    location="us-central1",
    data_scan_id="dataquality-basic",
    data={
        "resource": "//bigquery.googleapis.com/projects/bigquery-public-data/datasets/samples/tables/shakespeare",
    },
    execution_spec={
        "trigger": {
            "on_demand": {},
        },
    },
    data_quality_spec={
        "rules": [{
            "dimension": "VALIDITY",
            "name": "rule1",
            "description": "rule 1 for validity dimension",
            "table_condition_expectation": {
                "sql_expression": "COUNT(*) > 0",
            },
        }],
    },
    project="my-project-name")
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var basicQuality = new Gcp.DataPlex.Datascan("basic_quality", new()
    {
        Location = "us-central1",
        DataScanId = "dataquality-basic",
        Data = new Gcp.DataPlex.Inputs.DatascanDataArgs
        {
            Resource = "//bigquery.googleapis.com/projects/bigquery-public-data/datasets/samples/tables/shakespeare",
        },
        ExecutionSpec = new Gcp.DataPlex.Inputs.DatascanExecutionSpecArgs
        {
            Trigger = new Gcp.DataPlex.Inputs.DatascanExecutionSpecTriggerArgs
            {
                OnDemand = null,
            },
        },
        DataQualitySpec = new Gcp.DataPlex.Inputs.DatascanDataQualitySpecArgs
        {
            Rules = new[]
            {
                new Gcp.DataPlex.Inputs.DatascanDataQualitySpecRuleArgs
                {
                    Dimension = "VALIDITY",
                    Name = "rule1",
                    Description = "rule 1 for validity dimension",
                    TableConditionExpectation = new Gcp.DataPlex.Inputs.DatascanDataQualitySpecRuleTableConditionExpectationArgs
                    {
                        SqlExpression = "COUNT(*) > 0",
                    },
                },
            },
        },
        Project = "my-project-name",
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/dataplex"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		_, err := dataplex.NewDatascan(ctx, "basic_quality", &dataplex.DatascanArgs{
			Location:   pulumi.String("us-central1"),
			DataScanId: pulumi.String("dataquality-basic"),
			Data: &dataplex.DatascanDataArgs{
				Resource: pulumi.String("//bigquery.googleapis.com/projects/bigquery-public-data/datasets/samples/tables/shakespeare"),
			},
			ExecutionSpec: &dataplex.DatascanExecutionSpecArgs{
				Trigger: &dataplex.DatascanExecutionSpecTriggerArgs{
					OnDemand: &dataplex.DatascanExecutionSpecTriggerOnDemandArgs{},
				},
			},
			DataQualitySpec: &dataplex.DatascanDataQualitySpecArgs{
				Rules: dataplex.DatascanDataQualitySpecRuleArray{
					&dataplex.DatascanDataQualitySpecRuleArgs{
						Dimension:   pulumi.String("VALIDITY"),
						Name:        pulumi.String("rule1"),
						Description: pulumi.String("rule 1 for validity dimension"),
						TableConditionExpectation: &dataplex.DatascanDataQualitySpecRuleTableConditionExpectationArgs{
							SqlExpression: pulumi.String("COUNT(*) > 0"),
						},
					},
				},
			},
			Project: pulumi.String("my-project-name"),
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.dataplex.Datascan;
import com.pulumi.gcp.dataplex.DatascanArgs;
import com.pulumi.gcp.dataplex.inputs.DatascanDataArgs;
import com.pulumi.gcp.dataplex.inputs.DatascanExecutionSpecArgs;
import com.pulumi.gcp.dataplex.inputs.DatascanExecutionSpecTriggerArgs;
import com.pulumi.gcp.dataplex.inputs.DatascanExecutionSpecTriggerOnDemandArgs;
import com.pulumi.gcp.dataplex.inputs.DatascanDataQualitySpecArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        var basicQuality = new Datascan("basicQuality", DatascanArgs.builder()
            .location("us-central1")
            .dataScanId("dataquality-basic")
            .data(DatascanDataArgs.builder()
                .resource("//bigquery.googleapis.com/projects/bigquery-public-data/datasets/samples/tables/shakespeare")
                .build())
            .executionSpec(DatascanExecutionSpecArgs.builder()
                .trigger(DatascanExecutionSpecTriggerArgs.builder()
                    .onDemand()
                    .build())
                .build())
            .dataQualitySpec(DatascanDataQualitySpecArgs.builder()
                .rules(DatascanDataQualitySpecRuleArgs.builder()
                    .dimension("VALIDITY")
                    .name("rule1")
                    .description("rule 1 for validity dimension")
                    .tableConditionExpectation(DatascanDataQualitySpecRuleTableConditionExpectationArgs.builder()
                        .sqlExpression("COUNT(*) > 0")
                        .build())
                    .build())
                .build())
            .project("my-project-name")
            .build());

    }
}
```
```yaml
resources:
  basicQuality:
    type: gcp:dataplex:Datascan
    name: basic_quality
    properties:
      location: us-central1
      dataScanId: dataquality-basic
      data:
        resource: //bigquery.googleapis.com/projects/bigquery-public-data/datasets/samples/tables/shakespeare
      executionSpec:
        trigger:
          onDemand: {}
      dataQualitySpec:
        rules:
          - dimension: VALIDITY
            name: rule1
            description: rule 1 for validity dimension
            tableConditionExpectation:
              sqlExpression: COUNT(*) > 0
      project: my-project-name
```
<!--End PulumiCodeChooser -->
### Dataplex Datascan Full Quality


<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const fullQuality = new gcp.dataplex.Datascan("full_quality", {
    location: "us-central1",
    displayName: "Full Datascan Quality",
    dataScanId: "dataquality-full",
    description: "Example resource - Full Datascan Quality",
    labels: {
        author: "billing",
    },
    data: {
        resource: "//bigquery.googleapis.com/projects/bigquery-public-data/datasets/austin_bikeshare/tables/bikeshare_stations",
    },
    executionSpec: {
        trigger: {
            schedule: {
                cron: "TZ=America/New_York 1 1 * * *",
            },
        },
        field: "modified_date",
    },
    dataQualitySpec: {
        samplingPercent: 5,
        rowFilter: "station_id > 1000",
        rules: [
            {
                column: "address",
                dimension: "VALIDITY",
                threshold: 0.99,
                nonNullExpectation: {},
            },
            {
                column: "council_district",
                dimension: "VALIDITY",
                ignoreNull: true,
                threshold: 0.9,
                rangeExpectation: {
                    minValue: "1",
                    maxValue: "10",
                    strictMinEnabled: true,
                    strictMaxEnabled: false,
                },
            },
            {
                column: "power_type",
                dimension: "VALIDITY",
                ignoreNull: false,
                regexExpectation: {
                    regex: ".*solar.*",
                },
            },
            {
                column: "property_type",
                dimension: "VALIDITY",
                ignoreNull: false,
                setExpectation: {
                    values: [
                        "sidewalk",
                        "parkland",
                    ],
                },
            },
            {
                column: "address",
                dimension: "UNIQUENESS",
                uniquenessExpectation: {},
            },
            {
                column: "number_of_docks",
                dimension: "VALIDITY",
                statisticRangeExpectation: {
                    statistic: "MEAN",
                    minValue: "5",
                    maxValue: "15",
                    strictMinEnabled: true,
                    strictMaxEnabled: true,
                },
            },
            {
                column: "footprint_length",
                dimension: "VALIDITY",
                rowConditionExpectation: {
                    sqlExpression: "footprint_length > 0 AND footprint_length <= 10",
                },
            },
            {
                dimension: "VALIDITY",
                tableConditionExpectation: {
                    sqlExpression: "COUNT(*) > 0",
                },
            },
            {
                dimension: "VALIDITY",
                sqlAssertion: {
                    sqlStatement: "select * from bigquery-public-data.austin_bikeshare.bikeshare_stations where station_id is null",
                },
            },
        ],
    },
    project: "my-project-name",
});
```
```python
import pulumi
import pulumi_gcp as gcp

full_quality = gcp.dataplex.Datascan("full_quality",
    location="us-central1",
    display_name="Full Datascan Quality",
    data_scan_id="dataquality-full",
    description="Example resource - Full Datascan Quality",
    labels={
        "author": "billing",
    },
    data={
        "resource": "//bigquery.googleapis.com/projects/bigquery-public-data/datasets/austin_bikeshare/tables/bikeshare_stations",
    },
    execution_spec={
        "trigger": {
            "schedule": {
                "cron": "TZ=America/New_York 1 1 * * *",
            },
        },
        "field": "modified_date",
    },
    data_quality_spec={
        "sampling_percent": 5,
        "row_filter": "station_id > 1000",
        "rules": [
            {
                "column": "address",
                "dimension": "VALIDITY",
                "threshold": 0.99,
                "non_null_expectation": {},
            },
            {
                "column": "council_district",
                "dimension": "VALIDITY",
                "ignore_null": True,
                "threshold": 0.9,
                "range_expectation": {
                    "min_value": "1",
                    "max_value": "10",
                    "strict_min_enabled": True,
                    "strict_max_enabled": False,
                },
            },
            {
                "column": "power_type",
                "dimension": "VALIDITY",
                "ignore_null": False,
                "regex_expectation": {
                    "regex": ".*solar.*",
                },
            },
            {
                "column": "property_type",
                "dimension": "VALIDITY",
                "ignore_null": False,
                "set_expectation": {
                    "values": [
                        "sidewalk",
                        "parkland",
                    ],
                },
            },
            {
                "column": "address",
                "dimension": "UNIQUENESS",
                "uniqueness_expectation": {},
            },
            {
                "column": "number_of_docks",
                "dimension": "VALIDITY",
                "statistic_range_expectation": {
                    "statistic": "MEAN",
                    "min_value": "5",
                    "max_value": "15",
                    "strict_min_enabled": True,
                    "strict_max_enabled": True,
                },
            },
            {
                "column": "footprint_length",
                "dimension": "VALIDITY",
                "row_condition_expectation": {
                    "sql_expression": "footprint_length > 0 AND footprint_length <= 10",
                },
            },
            {
                "dimension": "VALIDITY",
                "table_condition_expectation": {
                    "sql_expression": "COUNT(*) > 0",
                },
            },
            {
                "dimension": "VALIDITY",
                "sql_assertion": {
                    "sql_statement": "select * from bigquery-public-data.austin_bikeshare.bikeshare_stations where station_id is null",
                },
            },
        ],
    },
    project="my-project-name")
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var fullQuality = new Gcp.DataPlex.Datascan("full_quality", new()
    {
        Location = "us-central1",
        DisplayName = "Full Datascan Quality",
        DataScanId = "dataquality-full",
        Description = "Example resource - Full Datascan Quality",
        Labels = 
        {
            { "author", "billing" },
        },
        Data = new Gcp.DataPlex.Inputs.DatascanDataArgs
        {
            Resource = "//bigquery.googleapis.com/projects/bigquery-public-data/datasets/austin_bikeshare/tables/bikeshare_stations",
        },
        ExecutionSpec = new Gcp.DataPlex.Inputs.DatascanExecutionSpecArgs
        {
            Trigger = new Gcp.DataPlex.Inputs.DatascanExecutionSpecTriggerArgs
            {
                Schedule = new Gcp.DataPlex.Inputs.DatascanExecutionSpecTriggerScheduleArgs
                {
                    Cron = "TZ=America/New_York 1 1 * * *",
                },
            },
            Field = "modified_date",
        },
        DataQualitySpec = new Gcp.DataPlex.Inputs.DatascanDataQualitySpecArgs
        {
            SamplingPercent = 5,
            RowFilter = "station_id > 1000",
            Rules = new[]
            {
                new Gcp.DataPlex.Inputs.DatascanDataQualitySpecRuleArgs
                {
                    Column = "address",
                    Dimension = "VALIDITY",
                    Threshold = 0.99,
                    NonNullExpectation = null,
                },
                new Gcp.DataPlex.Inputs.DatascanDataQualitySpecRuleArgs
                {
                    Column = "council_district",
                    Dimension = "VALIDITY",
                    IgnoreNull = true,
                    Threshold = 0.9,
                    RangeExpectation = new Gcp.DataPlex.Inputs.DatascanDataQualitySpecRuleRangeExpectationArgs
                    {
                        MinValue = "1",
                        MaxValue = "10",
                        StrictMinEnabled = true,
                        StrictMaxEnabled = false,
                    },
                },
                new Gcp.DataPlex.Inputs.DatascanDataQualitySpecRuleArgs
                {
                    Column = "power_type",
                    Dimension = "VALIDITY",
                    IgnoreNull = false,
                    RegexExpectation = new Gcp.DataPlex.Inputs.DatascanDataQualitySpecRuleRegexExpectationArgs
                    {
                        Regex = ".*solar.*",
                    },
                },
                new Gcp.DataPlex.Inputs.DatascanDataQualitySpecRuleArgs
                {
                    Column = "property_type",
                    Dimension = "VALIDITY",
                    IgnoreNull = false,
                    SetExpectation = new Gcp.DataPlex.Inputs.DatascanDataQualitySpecRuleSetExpectationArgs
                    {
                        Values = new[]
                        {
                            "sidewalk",
                            "parkland",
                        },
                    },
                },
                new Gcp.DataPlex.Inputs.DatascanDataQualitySpecRuleArgs
                {
                    Column = "address",
                    Dimension = "UNIQUENESS",
                    UniquenessExpectation = null,
                },
                new Gcp.DataPlex.Inputs.DatascanDataQualitySpecRuleArgs
                {
                    Column = "number_of_docks",
                    Dimension = "VALIDITY",
                    StatisticRangeExpectation = new Gcp.DataPlex.Inputs.DatascanDataQualitySpecRuleStatisticRangeExpectationArgs
                    {
                        Statistic = "MEAN",
                        MinValue = "5",
                        MaxValue = "15",
                        StrictMinEnabled = true,
                        StrictMaxEnabled = true,
                    },
                },
                new Gcp.DataPlex.Inputs.DatascanDataQualitySpecRuleArgs
                {
                    Column = "footprint_length",
                    Dimension = "VALIDITY",
                    RowConditionExpectation = new Gcp.DataPlex.Inputs.DatascanDataQualitySpecRuleRowConditionExpectationArgs
                    {
                        SqlExpression = "footprint_length > 0 AND footprint_length <= 10",
                    },
                },
                new Gcp.DataPlex.Inputs.DatascanDataQualitySpecRuleArgs
                {
                    Dimension = "VALIDITY",
                    TableConditionExpectation = new Gcp.DataPlex.Inputs.DatascanDataQualitySpecRuleTableConditionExpectationArgs
                    {
                        SqlExpression = "COUNT(*) > 0",
                    },
                },
                new Gcp.DataPlex.Inputs.DatascanDataQualitySpecRuleArgs
                {
                    Dimension = "VALIDITY",
                    SqlAssertion = new Gcp.DataPlex.Inputs.DatascanDataQualitySpecRuleSqlAssertionArgs
                    {
                        SqlStatement = "select * from bigquery-public-data.austin_bikeshare.bikeshare_stations where station_id is null",
                    },
                },
            },
        },
        Project = "my-project-name",
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/dataplex"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		_, err := dataplex.NewDatascan(ctx, "full_quality", &dataplex.DatascanArgs{
			Location:    pulumi.String("us-central1"),
			DisplayName: pulumi.String("Full Datascan Quality"),
			DataScanId:  pulumi.String("dataquality-full"),
			Description: pulumi.String("Example resource - Full Datascan Quality"),
			Labels: pulumi.StringMap{
				"author": pulumi.String("billing"),
			},
			Data: &dataplex.DatascanDataArgs{
				Resource: pulumi.String("//bigquery.googleapis.com/projects/bigquery-public-data/datasets/austin_bikeshare/tables/bikeshare_stations"),
			},
			ExecutionSpec: &dataplex.DatascanExecutionSpecArgs{
				Trigger: &dataplex.DatascanExecutionSpecTriggerArgs{
					Schedule: &dataplex.DatascanExecutionSpecTriggerScheduleArgs{
						Cron: pulumi.String("TZ=America/New_York 1 1 * * *"),
					},
				},
				Field: pulumi.String("modified_date"),
			},
			DataQualitySpec: &dataplex.DatascanDataQualitySpecArgs{
				SamplingPercent: pulumi.Float64(5),
				RowFilter:       pulumi.String("station_id > 1000"),
				Rules: dataplex.DatascanDataQualitySpecRuleArray{
					&dataplex.DatascanDataQualitySpecRuleArgs{
						Column:             pulumi.String("address"),
						Dimension:          pulumi.String("VALIDITY"),
						Threshold:          pulumi.Float64(0.99),
						NonNullExpectation: &dataplex.DatascanDataQualitySpecRuleNonNullExpectationArgs{},
					},
					&dataplex.DatascanDataQualitySpecRuleArgs{
						Column:     pulumi.String("council_district"),
						Dimension:  pulumi.String("VALIDITY"),
						IgnoreNull: pulumi.Bool(true),
						Threshold:  pulumi.Float64(0.9),
						RangeExpectation: &dataplex.DatascanDataQualitySpecRuleRangeExpectationArgs{
							MinValue:         pulumi.String("1"),
							MaxValue:         pulumi.String("10"),
							StrictMinEnabled: pulumi.Bool(true),
							StrictMaxEnabled: pulumi.Bool(false),
						},
					},
					&dataplex.DatascanDataQualitySpecRuleArgs{
						Column:     pulumi.String("power_type"),
						Dimension:  pulumi.String("VALIDITY"),
						IgnoreNull: pulumi.Bool(false),
						RegexExpectation: &dataplex.DatascanDataQualitySpecRuleRegexExpectationArgs{
							Regex: pulumi.String(".*solar.*"),
						},
					},
					&dataplex.DatascanDataQualitySpecRuleArgs{
						Column:     pulumi.String("property_type"),
						Dimension:  pulumi.String("VALIDITY"),
						IgnoreNull: pulumi.Bool(false),
						SetExpectation: &dataplex.DatascanDataQualitySpecRuleSetExpectationArgs{
							Values: pulumi.StringArray{
								pulumi.String("sidewalk"),
								pulumi.String("parkland"),
							},
						},
					},
					&dataplex.DatascanDataQualitySpecRuleArgs{
						Column:                pulumi.String("address"),
						Dimension:             pulumi.String("UNIQUENESS"),
						UniquenessExpectation: &dataplex.DatascanDataQualitySpecRuleUniquenessExpectationArgs{},
					},
					&dataplex.DatascanDataQualitySpecRuleArgs{
						Column:    pulumi.String("number_of_docks"),
						Dimension: pulumi.String("VALIDITY"),
						StatisticRangeExpectation: &dataplex.DatascanDataQualitySpecRuleStatisticRangeExpectationArgs{
							Statistic:        pulumi.String("MEAN"),
							MinValue:         pulumi.String("5"),
							MaxValue:         pulumi.String("15"),
							StrictMinEnabled: pulumi.Bool(true),
							StrictMaxEnabled: pulumi.Bool(true),
						},
					},
					&dataplex.DatascanDataQualitySpecRuleArgs{
						Column:    pulumi.String("footprint_length"),
						Dimension: pulumi.String("VALIDITY"),
						RowConditionExpectation: &dataplex.DatascanDataQualitySpecRuleRowConditionExpectationArgs{
							SqlExpression: pulumi.String("footprint_length > 0 AND footprint_length <= 10"),
						},
					},
					&dataplex.DatascanDataQualitySpecRuleArgs{
						Dimension: pulumi.String("VALIDITY"),
						TableConditionExpectation: &dataplex.DatascanDataQualitySpecRuleTableConditionExpectationArgs{
							SqlExpression: pulumi.String("COUNT(*) > 0"),
						},
					},
					&dataplex.DatascanDataQualitySpecRuleArgs{
						Dimension: pulumi.String("VALIDITY"),
						SqlAssertion: &dataplex.DatascanDataQualitySpecRuleSqlAssertionArgs{
							SqlStatement: pulumi.String("select * from bigquery-public-data.austin_bikeshare.bikeshare_stations where station_id is null"),
						},
					},
				},
			},
			Project: pulumi.String("my-project-name"),
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.dataplex.Datascan;
import com.pulumi.gcp.dataplex.DatascanArgs;
import com.pulumi.gcp.dataplex.inputs.DatascanDataArgs;
import com.pulumi.gcp.dataplex.inputs.DatascanExecutionSpecArgs;
import com.pulumi.gcp.dataplex.inputs.DatascanExecutionSpecTriggerArgs;
import com.pulumi.gcp.dataplex.inputs.DatascanExecutionSpecTriggerScheduleArgs;
import com.pulumi.gcp.dataplex.inputs.DatascanDataQualitySpecArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        var fullQuality = new Datascan("fullQuality", DatascanArgs.builder()
            .location("us-central1")
            .displayName("Full Datascan Quality")
            .dataScanId("dataquality-full")
            .description("Example resource - Full Datascan Quality")
            .labels(Map.of("author", "billing"))
            .data(DatascanDataArgs.builder()
                .resource("//bigquery.googleapis.com/projects/bigquery-public-data/datasets/austin_bikeshare/tables/bikeshare_stations")
                .build())
            .executionSpec(DatascanExecutionSpecArgs.builder()
                .trigger(DatascanExecutionSpecTriggerArgs.builder()
                    .schedule(DatascanExecutionSpecTriggerScheduleArgs.builder()
                        .cron("TZ=America/New_York 1 1 * * *")
                        .build())
                    .build())
                .field("modified_date")
                .build())
            .dataQualitySpec(DatascanDataQualitySpecArgs.builder()
                .samplingPercent(5)
                .rowFilter("station_id > 1000")
                .rules(                
                    DatascanDataQualitySpecRuleArgs.builder()
                        .column("address")
                        .dimension("VALIDITY")
                        .threshold(0.99)
                        .nonNullExpectation()
                        .build(),
                    DatascanDataQualitySpecRuleArgs.builder()
                        .column("council_district")
                        .dimension("VALIDITY")
                        .ignoreNull(true)
                        .threshold(0.9)
                        .rangeExpectation(DatascanDataQualitySpecRuleRangeExpectationArgs.builder()
                            .minValue(1)
                            .maxValue(10)
                            .strictMinEnabled(true)
                            .strictMaxEnabled(false)
                            .build())
                        .build(),
                    DatascanDataQualitySpecRuleArgs.builder()
                        .column("power_type")
                        .dimension("VALIDITY")
                        .ignoreNull(false)
                        .regexExpectation(DatascanDataQualitySpecRuleRegexExpectationArgs.builder()
                            .regex(".*solar.*")
                            .build())
                        .build(),
                    DatascanDataQualitySpecRuleArgs.builder()
                        .column("property_type")
                        .dimension("VALIDITY")
                        .ignoreNull(false)
                        .setExpectation(DatascanDataQualitySpecRuleSetExpectationArgs.builder()
                            .values(                            
                                "sidewalk",
                                "parkland")
                            .build())
                        .build(),
                    DatascanDataQualitySpecRuleArgs.builder()
                        .column("address")
                        .dimension("UNIQUENESS")
                        .uniquenessExpectation()
                        .build(),
                    DatascanDataQualitySpecRuleArgs.builder()
                        .column("number_of_docks")
                        .dimension("VALIDITY")
                        .statisticRangeExpectation(DatascanDataQualitySpecRuleStatisticRangeExpectationArgs.builder()
                            .statistic("MEAN")
                            .minValue(5)
                            .maxValue(15)
                            .strictMinEnabled(true)
                            .strictMaxEnabled(true)
                            .build())
                        .build(),
                    DatascanDataQualitySpecRuleArgs.builder()
                        .column("footprint_length")
                        .dimension("VALIDITY")
                        .rowConditionExpectation(DatascanDataQualitySpecRuleRowConditionExpectationArgs.builder()
                            .sqlExpression("footprint_length > 0 AND footprint_length <= 10")
                            .build())
                        .build(),
                    DatascanDataQualitySpecRuleArgs.builder()
                        .dimension("VALIDITY")
                        .tableConditionExpectation(DatascanDataQualitySpecRuleTableConditionExpectationArgs.builder()
                            .sqlExpression("COUNT(*) > 0")
                            .build())
                        .build(),
                    DatascanDataQualitySpecRuleArgs.builder()
                        .dimension("VALIDITY")
                        .sqlAssertion(DatascanDataQualitySpecRuleSqlAssertionArgs.builder()
                            .sqlStatement("select * from bigquery-public-data.austin_bikeshare.bikeshare_stations where station_id is null")
                            .build())
                        .build())
                .build())
            .project("my-project-name")
            .build());

    }
}
```
```yaml
resources:
  fullQuality:
    type: gcp:dataplex:Datascan
    name: full_quality
    properties:
      location: us-central1
      displayName: Full Datascan Quality
      dataScanId: dataquality-full
      description: Example resource - Full Datascan Quality
      labels:
        author: billing
      data:
        resource: //bigquery.googleapis.com/projects/bigquery-public-data/datasets/austin_bikeshare/tables/bikeshare_stations
      executionSpec:
        trigger:
          schedule:
            cron: TZ=America/New_York 1 1 * * *
        field: modified_date
      dataQualitySpec:
        samplingPercent: 5
        rowFilter: station_id > 1000
        rules:
          - column: address
            dimension: VALIDITY
            threshold: 0.99
            nonNullExpectation: {}
          - column: council_district
            dimension: VALIDITY
            ignoreNull: true
            threshold: 0.9
            rangeExpectation:
              minValue: 1
              maxValue: 10
              strictMinEnabled: true
              strictMaxEnabled: false
          - column: power_type
            dimension: VALIDITY
            ignoreNull: false
            regexExpectation:
              regex: .*solar.*
          - column: property_type
            dimension: VALIDITY
            ignoreNull: false
            setExpectation:
              values:
                - sidewalk
                - parkland
          - column: address
            dimension: UNIQUENESS
            uniquenessExpectation: {}
          - column: number_of_docks
            dimension: VALIDITY
            statisticRangeExpectation:
              statistic: MEAN
              minValue: 5
              maxValue: 15
              strictMinEnabled: true
              strictMaxEnabled: true
          - column: footprint_length
            dimension: VALIDITY
            rowConditionExpectation:
              sqlExpression: footprint_length > 0 AND footprint_length <= 10
          - dimension: VALIDITY
            tableConditionExpectation:
              sqlExpression: COUNT(*) > 0
          - dimension: VALIDITY
            sqlAssertion:
              sqlStatement: select * from bigquery-public-data.austin_bikeshare.bikeshare_stations where station_id is null
      project: my-project-name
```
<!--End PulumiCodeChooser -->

## Import

Datascan can be imported using any of these accepted formats:

* `projects/{{project}}/locations/{{location}}/dataScans/{{data_scan_id}}`

* `{{project}}/{{location}}/{{data_scan_id}}`

* `{{location}}/{{data_scan_id}}`

* `{{data_scan_id}}`

When using the `pulumi import` command, Datascan can be imported using one of the formats above. For example:

```sh
$ pulumi import gcp:dataplex/datascan:Datascan default projects/{{project}}/locations/{{location}}/dataScans/{{data_scan_id}}
```

```sh
$ pulumi import gcp:dataplex/datascan:Datascan default {{project}}/{{location}}/{{data_scan_id}}
```

```sh
$ pulumi import gcp:dataplex/datascan:Datascan default {{location}}/{{data_scan_id}}
```

```sh
$ pulumi import gcp:dataplex/datascan:Datascan default {{data_scan_id}}
```


dataD:B
@
dataplexDatascanData&gcp:dataplex/DatascanData:DatascanData=The data source for DataScan.
Structure is documented below.

dataProfileSpecgBe:c
a
dataplexDatascanDataProfileSpec<gcp:dataplex/DatascanDataProfileSpec:DatascanDataProfileSpec!DataProfileScan related setting.

dataQualitySpecgBe:c
a
dataplexDatascanDataQualitySpec<gcp:dataplex/DatascanDataQualitySpec:DatascanDataQualitySpec!DataQualityScan related setting.
 

dataScanId" DataScan identifier. Must contain only lowercase letters, numbers and hyphens. Must start with a letter. Must end with a number or a letter.
.
descriptionB" Description of the scan.
1
displayNameB" User friendly display name.
®
executionSpec_:]
[
dataplexDatascanExecutionSpec8gcp:dataplex/DatascanExecutionSpec:DatascanExecutionSpec<DataScan execution settings.
Structure is documented below.

labelsB2" User-defined labels for the scan. A list of key->value pairs. **Note**: This field is non-authoritative, and will only
manage the labels present in your configuration. Please refer to the field 'effective_labels' for all of the labels
present on the resource.
@
location" 0The location where the data scan should reside.

projectB" "6

createTime" $The time when the scan was created.
"
dataD:B
@
dataplexDatascanData&gcp:dataplex/DatascanData:DatascanData=The data source for DataScan.
Structure is documented below.
"
dataProfileSpecgBe:c
a
dataplexDatascanDataProfileSpec<gcp:dataplex/DatascanDataProfileSpec:DatascanDataProfileSpec!DataProfileScan related setting.
"
dataQualitySpecgBe:c
a
dataplexDatascanDataQualitySpec<gcp:dataplex/DatascanDataQualitySpec:DatascanDataQualitySpec!DataQualityScan related setting.
" 

dataScanId" DataScan identifier. Must contain only lowercase letters, numbers and hyphens. Must start with a letter. Must end with a number or a letter.
".
descriptionB" Description of the scan.
"1
displayNameB" User friendly display name.
"¦
effectiveLabels2" All of labels (key/value pairs) present on the resource in GCP, including the labels configured through Pulumi, other clients and services.
"®
executionSpec_:]
[
dataplexDatascanExecutionSpec8gcp:dataplex/DatascanExecutionSpec:DatascanExecutionSpec<DataScan execution settings.
Structure is documented below.
"À
executionStatusesg*e:c
a
dataplexDatascanExecutionStatus<gcp:dataplex/DatascanExecutionStatus:DatascanExecutionStatusBStatus of the data scan execution.
Structure is documented below.
"
labelsB2" User-defined labels for the scan. A list of key->value pairs. **Note**: This field is non-authoritative, and will only
manage the labels present in your configuration. Please refer to the field 'effective_labels' for all of the labels
present on the resource.
"@
location" 0The location where the data scan should reside.
"ã
name" ÖThe relative resource name of the scan, of the form: projects/{project}/locations/{locationId}/dataScans/{datascan_id}, where project refers to a project_id or project_number and locationId refers to a GCP region.
"
project" "
pulumiLabels2" mThe combination of labels configured directly on the resource
and default labels configured on the provider.
",
state" Current state of the DataScan.
""
type" The type of DataScan.
"
uid" System generated globally unique ID for the scan. This ID will be different if the scan is deleted and re-created with the same name.
";

updateTime" )The time when the scan was last updated.
*Ûä
R
dataplexDatascanIamBinding2gcp:dataplex/datascanIamBinding:DatascanIamBindingäÀThree different resources help you manage your IAM policy for Dataplex Datascan. Each of these resources serves a different use case:

* `gcp.dataplex.DatascanIamPolicy`: Authoritative. Sets the IAM policy for the datascan and replaces any existing policy already attached.
* `gcp.dataplex.DatascanIamBinding`: Authoritative for a given role. Updates the IAM policy to grant a role to a list of members. Other roles within the IAM policy for the datascan are preserved.
* `gcp.dataplex.DatascanIamMember`: Non-authoritative. Updates the IAM policy to grant a role to a new member. Other members for the role for the datascan are preserved.

A data source can be used to retrieve policy data in advent you do not need creation

* `gcp.dataplex.DatascanIamPolicy`: Retrieves the IAM policy for the datascan

> **Note:** `gcp.dataplex.DatascanIamPolicy` **cannot** be used in conjunction with `gcp.dataplex.DatascanIamBinding` and `gcp.dataplex.DatascanIamMember` or they will fight over what your policy should be.

> **Note:** `gcp.dataplex.DatascanIamBinding` resources **can be** used in conjunction with `gcp.dataplex.DatascanIamMember` resources **only if** they do not grant privilege to the same role.



## gcp.dataplex.DatascanIamPolicy

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const admin = gcp.organizations.getIAMPolicy({
    bindings: [{
        role: "roles/viewer",
        members: ["user:jane@example.com"],
    }],
});
const policy = new gcp.dataplex.DatascanIamPolicy("policy", {
    project: basicProfile.project,
    location: basicProfile.location,
    dataScanId: basicProfile.dataScanId,
    policyData: admin.then(admin => admin.policyData),
});
```
```python
import pulumi
import pulumi_gcp as gcp

admin = gcp.organizations.get_iam_policy(bindings=[{
    "role": "roles/viewer",
    "members": ["user:jane@example.com"],
}])
policy = gcp.dataplex.DatascanIamPolicy("policy",
    project=basic_profile["project"],
    location=basic_profile["location"],
    data_scan_id=basic_profile["dataScanId"],
    policy_data=admin.policy_data)
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var admin = Gcp.Organizations.GetIAMPolicy.Invoke(new()
    {
        Bindings = new[]
        {
            new Gcp.Organizations.Inputs.GetIAMPolicyBindingInputArgs
            {
                Role = "roles/viewer",
                Members = new[]
                {
                    "user:jane@example.com",
                },
            },
        },
    });

    var policy = new Gcp.DataPlex.DatascanIamPolicy("policy", new()
    {
        Project = basicProfile.Project,
        Location = basicProfile.Location,
        DataScanId = basicProfile.DataScanId,
        PolicyData = admin.Apply(getIAMPolicyResult => getIAMPolicyResult.PolicyData),
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/dataplex"
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/organizations"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		admin, err := organizations.LookupIAMPolicy(ctx, &organizations.LookupIAMPolicyArgs{
			Bindings: []organizations.GetIAMPolicyBinding{
				{
					Role: "roles/viewer",
					Members: []string{
						"user:jane@example.com",
					},
				},
			},
		}, nil)
		if err != nil {
			return err
		}
		_, err = dataplex.NewDatascanIamPolicy(ctx, "policy", &dataplex.DatascanIamPolicyArgs{
			Project:    pulumi.Any(basicProfile.Project),
			Location:   pulumi.Any(basicProfile.Location),
			DataScanId: pulumi.Any(basicProfile.DataScanId),
			PolicyData: pulumi.String(admin.PolicyData),
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.organizations.OrganizationsFunctions;
import com.pulumi.gcp.organizations.inputs.GetIAMPolicyArgs;
import com.pulumi.gcp.dataplex.DatascanIamPolicy;
import com.pulumi.gcp.dataplex.DatascanIamPolicyArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        final var admin = OrganizationsFunctions.getIAMPolicy(GetIAMPolicyArgs.builder()
            .bindings(GetIAMPolicyBindingArgs.builder()
                .role("roles/viewer")
                .members("user:jane@example.com")
                .build())
            .build());

        var policy = new DatascanIamPolicy("policy", DatascanIamPolicyArgs.builder()
            .project(basicProfile.project())
            .location(basicProfile.location())
            .dataScanId(basicProfile.dataScanId())
            .policyData(admin.applyValue(getIAMPolicyResult -> getIAMPolicyResult.policyData()))
            .build());

    }
}
```
```yaml
resources:
  policy:
    type: gcp:dataplex:DatascanIamPolicy
    properties:
      project: ${basicProfile.project}
      location: ${basicProfile.location}
      dataScanId: ${basicProfile.dataScanId}
      policyData: ${admin.policyData}
variables:
  admin:
    fn::invoke:
      function: gcp:organizations:getIAMPolicy
      arguments:
        bindings:
          - role: roles/viewer
            members:
              - user:jane@example.com
```
<!--End PulumiCodeChooser -->

## gcp.dataplex.DatascanIamBinding

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const binding = new gcp.dataplex.DatascanIamBinding("binding", {
    project: basicProfile.project,
    location: basicProfile.location,
    dataScanId: basicProfile.dataScanId,
    role: "roles/viewer",
    members: ["user:jane@example.com"],
});
```
```python
import pulumi
import pulumi_gcp as gcp

binding = gcp.dataplex.DatascanIamBinding("binding",
    project=basic_profile["project"],
    location=basic_profile["location"],
    data_scan_id=basic_profile["dataScanId"],
    role="roles/viewer",
    members=["user:jane@example.com"])
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var binding = new Gcp.DataPlex.DatascanIamBinding("binding", new()
    {
        Project = basicProfile.Project,
        Location = basicProfile.Location,
        DataScanId = basicProfile.DataScanId,
        Role = "roles/viewer",
        Members = new[]
        {
            "user:jane@example.com",
        },
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/dataplex"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		_, err := dataplex.NewDatascanIamBinding(ctx, "binding", &dataplex.DatascanIamBindingArgs{
			Project:    pulumi.Any(basicProfile.Project),
			Location:   pulumi.Any(basicProfile.Location),
			DataScanId: pulumi.Any(basicProfile.DataScanId),
			Role:       pulumi.String("roles/viewer"),
			Members: pulumi.StringArray{
				pulumi.String("user:jane@example.com"),
			},
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.dataplex.DatascanIamBinding;
import com.pulumi.gcp.dataplex.DatascanIamBindingArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        var binding = new DatascanIamBinding("binding", DatascanIamBindingArgs.builder()
            .project(basicProfile.project())
            .location(basicProfile.location())
            .dataScanId(basicProfile.dataScanId())
            .role("roles/viewer")
            .members("user:jane@example.com")
            .build());

    }
}
```
```yaml
resources:
  binding:
    type: gcp:dataplex:DatascanIamBinding
    properties:
      project: ${basicProfile.project}
      location: ${basicProfile.location}
      dataScanId: ${basicProfile.dataScanId}
      role: roles/viewer
      members:
        - user:jane@example.com
```
<!--End PulumiCodeChooser -->

## gcp.dataplex.DatascanIamMember

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const member = new gcp.dataplex.DatascanIamMember("member", {
    project: basicProfile.project,
    location: basicProfile.location,
    dataScanId: basicProfile.dataScanId,
    role: "roles/viewer",
    member: "user:jane@example.com",
});
```
```python
import pulumi
import pulumi_gcp as gcp

member = gcp.dataplex.DatascanIamMember("member",
    project=basic_profile["project"],
    location=basic_profile["location"],
    data_scan_id=basic_profile["dataScanId"],
    role="roles/viewer",
    member="user:jane@example.com")
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var member = new Gcp.DataPlex.DatascanIamMember("member", new()
    {
        Project = basicProfile.Project,
        Location = basicProfile.Location,
        DataScanId = basicProfile.DataScanId,
        Role = "roles/viewer",
        Member = "user:jane@example.com",
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/dataplex"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		_, err := dataplex.NewDatascanIamMember(ctx, "member", &dataplex.DatascanIamMemberArgs{
			Project:    pulumi.Any(basicProfile.Project),
			Location:   pulumi.Any(basicProfile.Location),
			DataScanId: pulumi.Any(basicProfile.DataScanId),
			Role:       pulumi.String("roles/viewer"),
			Member:     pulumi.String("user:jane@example.com"),
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.dataplex.DatascanIamMember;
import com.pulumi.gcp.dataplex.DatascanIamMemberArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        var member = new DatascanIamMember("member", DatascanIamMemberArgs.builder()
            .project(basicProfile.project())
            .location(basicProfile.location())
            .dataScanId(basicProfile.dataScanId())
            .role("roles/viewer")
            .member("user:jane@example.com")
            .build());

    }
}
```
```yaml
resources:
  member:
    type: gcp:dataplex:DatascanIamMember
    properties:
      project: ${basicProfile.project}
      location: ${basicProfile.location}
      dataScanId: ${basicProfile.dataScanId}
      role: roles/viewer
      member: user:jane@example.com
```
<!--End PulumiCodeChooser -->


## This resource supports User Project Overrides.

-

# IAM policy for Dataplex Datascan
Three different resources help you manage your IAM policy for Dataplex Datascan. Each of these resources serves a different use case:

* `gcp.dataplex.DatascanIamPolicy`: Authoritative. Sets the IAM policy for the datascan and replaces any existing policy already attached.
* `gcp.dataplex.DatascanIamBinding`: Authoritative for a given role. Updates the IAM policy to grant a role to a list of members. Other roles within the IAM policy for the datascan are preserved.
* `gcp.dataplex.DatascanIamMember`: Non-authoritative. Updates the IAM policy to grant a role to a new member. Other members for the role for the datascan are preserved.

A data source can be used to retrieve policy data in advent you do not need creation

* `gcp.dataplex.DatascanIamPolicy`: Retrieves the IAM policy for the datascan

> **Note:** `gcp.dataplex.DatascanIamPolicy` **cannot** be used in conjunction with `gcp.dataplex.DatascanIamBinding` and `gcp.dataplex.DatascanIamMember` or they will fight over what your policy should be.

> **Note:** `gcp.dataplex.DatascanIamBinding` resources **can be** used in conjunction with `gcp.dataplex.DatascanIamMember` resources **only if** they do not grant privilege to the same role.



## gcp.dataplex.DatascanIamPolicy

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const admin = gcp.organizations.getIAMPolicy({
    bindings: [{
        role: "roles/viewer",
        members: ["user:jane@example.com"],
    }],
});
const policy = new gcp.dataplex.DatascanIamPolicy("policy", {
    project: basicProfile.project,
    location: basicProfile.location,
    dataScanId: basicProfile.dataScanId,
    policyData: admin.then(admin => admin.policyData),
});
```
```python
import pulumi
import pulumi_gcp as gcp

admin = gcp.organizations.get_iam_policy(bindings=[{
    "role": "roles/viewer",
    "members": ["user:jane@example.com"],
}])
policy = gcp.dataplex.DatascanIamPolicy("policy",
    project=basic_profile["project"],
    location=basic_profile["location"],
    data_scan_id=basic_profile["dataScanId"],
    policy_data=admin.policy_data)
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var admin = Gcp.Organizations.GetIAMPolicy.Invoke(new()
    {
        Bindings = new[]
        {
            new Gcp.Organizations.Inputs.GetIAMPolicyBindingInputArgs
            {
                Role = "roles/viewer",
                Members = new[]
                {
                    "user:jane@example.com",
                },
            },
        },
    });

    var policy = new Gcp.DataPlex.DatascanIamPolicy("policy", new()
    {
        Project = basicProfile.Project,
        Location = basicProfile.Location,
        DataScanId = basicProfile.DataScanId,
        PolicyData = admin.Apply(getIAMPolicyResult => getIAMPolicyResult.PolicyData),
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/dataplex"
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/organizations"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		admin, err := organizations.LookupIAMPolicy(ctx, &organizations.LookupIAMPolicyArgs{
			Bindings: []organizations.GetIAMPolicyBinding{
				{
					Role: "roles/viewer",
					Members: []string{
						"user:jane@example.com",
					},
				},
			},
		}, nil)
		if err != nil {
			return err
		}
		_, err = dataplex.NewDatascanIamPolicy(ctx, "policy", &dataplex.DatascanIamPolicyArgs{
			Project:    pulumi.Any(basicProfile.Project),
			Location:   pulumi.Any(basicProfile.Location),
			DataScanId: pulumi.Any(basicProfile.DataScanId),
			PolicyData: pulumi.String(admin.PolicyData),
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.organizations.OrganizationsFunctions;
import com.pulumi.gcp.organizations.inputs.GetIAMPolicyArgs;
import com.pulumi.gcp.dataplex.DatascanIamPolicy;
import com.pulumi.gcp.dataplex.DatascanIamPolicyArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        final var admin = OrganizationsFunctions.getIAMPolicy(GetIAMPolicyArgs.builder()
            .bindings(GetIAMPolicyBindingArgs.builder()
                .role("roles/viewer")
                .members("user:jane@example.com")
                .build())
            .build());

        var policy = new DatascanIamPolicy("policy", DatascanIamPolicyArgs.builder()
            .project(basicProfile.project())
            .location(basicProfile.location())
            .dataScanId(basicProfile.dataScanId())
            .policyData(admin.applyValue(getIAMPolicyResult -> getIAMPolicyResult.policyData()))
            .build());

    }
}
```
```yaml
resources:
  policy:
    type: gcp:dataplex:DatascanIamPolicy
    properties:
      project: ${basicProfile.project}
      location: ${basicProfile.location}
      dataScanId: ${basicProfile.dataScanId}
      policyData: ${admin.policyData}
variables:
  admin:
    fn::invoke:
      function: gcp:organizations:getIAMPolicy
      arguments:
        bindings:
          - role: roles/viewer
            members:
              - user:jane@example.com
```
<!--End PulumiCodeChooser -->

## gcp.dataplex.DatascanIamBinding

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const binding = new gcp.dataplex.DatascanIamBinding("binding", {
    project: basicProfile.project,
    location: basicProfile.location,
    dataScanId: basicProfile.dataScanId,
    role: "roles/viewer",
    members: ["user:jane@example.com"],
});
```
```python
import pulumi
import pulumi_gcp as gcp

binding = gcp.dataplex.DatascanIamBinding("binding",
    project=basic_profile["project"],
    location=basic_profile["location"],
    data_scan_id=basic_profile["dataScanId"],
    role="roles/viewer",
    members=["user:jane@example.com"])
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var binding = new Gcp.DataPlex.DatascanIamBinding("binding", new()
    {
        Project = basicProfile.Project,
        Location = basicProfile.Location,
        DataScanId = basicProfile.DataScanId,
        Role = "roles/viewer",
        Members = new[]
        {
            "user:jane@example.com",
        },
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/dataplex"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		_, err := dataplex.NewDatascanIamBinding(ctx, "binding", &dataplex.DatascanIamBindingArgs{
			Project:    pulumi.Any(basicProfile.Project),
			Location:   pulumi.Any(basicProfile.Location),
			DataScanId: pulumi.Any(basicProfile.DataScanId),
			Role:       pulumi.String("roles/viewer"),
			Members: pulumi.StringArray{
				pulumi.String("user:jane@example.com"),
			},
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.dataplex.DatascanIamBinding;
import com.pulumi.gcp.dataplex.DatascanIamBindingArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        var binding = new DatascanIamBinding("binding", DatascanIamBindingArgs.builder()
            .project(basicProfile.project())
            .location(basicProfile.location())
            .dataScanId(basicProfile.dataScanId())
            .role("roles/viewer")
            .members("user:jane@example.com")
            .build());

    }
}
```
```yaml
resources:
  binding:
    type: gcp:dataplex:DatascanIamBinding
    properties:
      project: ${basicProfile.project}
      location: ${basicProfile.location}
      dataScanId: ${basicProfile.dataScanId}
      role: roles/viewer
      members:
        - user:jane@example.com
```
<!--End PulumiCodeChooser -->

## gcp.dataplex.DatascanIamMember

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const member = new gcp.dataplex.DatascanIamMember("member", {
    project: basicProfile.project,
    location: basicProfile.location,
    dataScanId: basicProfile.dataScanId,
    role: "roles/viewer",
    member: "user:jane@example.com",
});
```
```python
import pulumi
import pulumi_gcp as gcp

member = gcp.dataplex.DatascanIamMember("member",
    project=basic_profile["project"],
    location=basic_profile["location"],
    data_scan_id=basic_profile["dataScanId"],
    role="roles/viewer",
    member="user:jane@example.com")
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var member = new Gcp.DataPlex.DatascanIamMember("member", new()
    {
        Project = basicProfile.Project,
        Location = basicProfile.Location,
        DataScanId = basicProfile.DataScanId,
        Role = "roles/viewer",
        Member = "user:jane@example.com",
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/dataplex"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		_, err := dataplex.NewDatascanIamMember(ctx, "member", &dataplex.DatascanIamMemberArgs{
			Project:    pulumi.Any(basicProfile.Project),
			Location:   pulumi.Any(basicProfile.Location),
			DataScanId: pulumi.Any(basicProfile.DataScanId),
			Role:       pulumi.String("roles/viewer"),
			Member:     pulumi.String("user:jane@example.com"),
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.dataplex.DatascanIamMember;
import com.pulumi.gcp.dataplex.DatascanIamMemberArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        var member = new DatascanIamMember("member", DatascanIamMemberArgs.builder()
            .project(basicProfile.project())
            .location(basicProfile.location())
            .dataScanId(basicProfile.dataScanId())
            .role("roles/viewer")
            .member("user:jane@example.com")
            .build());

    }
}
```
```yaml
resources:
  member:
    type: gcp:dataplex:DatascanIamMember
    properties:
      project: ${basicProfile.project}
      location: ${basicProfile.location}
      dataScanId: ${basicProfile.dataScanId}
      role: roles/viewer
      member: user:jane@example.com
```
<!--End PulumiCodeChooser -->

## Import

For all import syntaxes, the "resource in question" can take any of the following forms:

* projects/{{project}}/locations/{{location}}/dataScans/{{data_scan_id}}

* {{project}}/{{location}}/{{data_scan_id}}

* {{location}}/{{data_scan_id}}

* {{data_scan_id}}

Any variables not passed in the import command will be taken from the provider configuration.

Dataplex datascan IAM resources can be imported using the resource identifiers, role, and member.

IAM member imports use space-delimited identifiers: the resource in question, the role, and the member identity, e.g.

```sh
$ pulumi import gcp:dataplex/datascanIamBinding:DatascanIamBinding editor "projects/{{project}}/locations/{{location}}/dataScans/{{data_scan_id}} roles/viewer user:jane@example.com"
```

IAM binding imports use space-delimited identifiers: the resource in question and the role, e.g.

```sh
$ pulumi import gcp:dataplex/datascanIamBinding:DatascanIamBinding editor "projects/{{project}}/locations/{{location}}/dataScans/{{data_scan_id}} roles/viewer"
```

IAM policy imports use the identifier of the resource in question, e.g.

```sh
$ pulumi import gcp:dataplex/datascanIamBinding:DatascanIamBinding editor projects/{{project}}/locations/{{location}}/dataScans/{{data_scan_id}}
```

-> **Custom Roles** If you're importing a IAM resource with a custom role, make sure to use the

 full name of the custom role, e.g. `[projects/my-project|organizations/my-org]/roles/my-custom-role`.


	conditionsBq:o
m
dataplexDatascanIamBindingConditionDgcp:dataplex/DatascanIamBindingCondition:DatascanIamBindingCondition

dataScanId" Õ
locationB" ÂThe location where the data scan should reside.
Used to find the parent resource to bind the IAM policy to. If not specified,
the value will be parsed from the identifier of the parent resource. If no location is provided in the parent identifier and no
location is specified, it is taken from the provider configuration.
Ö	
members*" Ä	Identities that will be granted the privilege in `role`.
Each entry can have one of the following values:
* **allUsers**: A special identifier that represents anyone who is on the internet; with or without a Google account.
* **allAuthenticatedUsers**: A special identifier that represents anyone who is authenticated with a Google account or a service account.
* **user:{emailid}**: An email address that represents a specific Google account. For example, alice@gmail.com or joe@example.com.
* **serviceAccount:{emailid}**: An email address that represents a service account. For example, my-other-app@appspot.gserviceaccount.com.
* **group:{emailid}**: An email address that represents a Google group. For example, admins@example.com.
* **domain:{domain}**: A G Suite domain (primary, instead of alias) name that represents all the users of that domain. For example, google.com or example.com.
* **projectOwner:projectid**: Owners of the given project. For example, "projectOwner:my-example-project"
* **projectEditor:projectid**: Editors of the given project. For example, "projectEditor:my-example-project"
* **projectViewer:projectid**: Viewers of the given project. For example, "projectViewer:my-example-project"

projectB" The ID of the project in which the resource belongs.
If it is not provided, the project will be parsed from the identifier of the parent resource. If no project is provided in the parent identifier and no project is specified, the provider project is used.
Ø
role" ËThe role that should be applied. Only one
`gcp.dataplex.DatascanIamBinding` can be used per role. Note that custom roles must be of the format
`[projects|organizations]/{parent-name}/roles/{role-name}`.
"
	conditionsBq:o
m
dataplexDatascanIamBindingConditionDgcp:dataplex/DatascanIamBindingCondition:DatascanIamBindingCondition"

dataScanId" "3
etag" '(Computed) The etag of the IAM policy.
"Ó
location" ÂThe location where the data scan should reside.
Used to find the parent resource to bind the IAM policy to. If not specified,
the value will be parsed from the identifier of the parent resource. If no location is provided in the parent identifier and no
location is specified, it is taken from the provider configuration.
"Ö	
members*" Ä	Identities that will be granted the privilege in `role`.
Each entry can have one of the following values:
* **allUsers**: A special identifier that represents anyone who is on the internet; with or without a Google account.
* **allAuthenticatedUsers**: A special identifier that represents anyone who is authenticated with a Google account or a service account.
* **user:{emailid}**: An email address that represents a specific Google account. For example, alice@gmail.com or joe@example.com.
* **serviceAccount:{emailid}**: An email address that represents a service account. For example, my-other-app@appspot.gserviceaccount.com.
* **group:{emailid}**: An email address that represents a Google group. For example, admins@example.com.
* **domain:{domain}**: A G Suite domain (primary, instead of alias) name that represents all the users of that domain. For example, google.com or example.com.
* **projectOwner:projectid**: Owners of the given project. For example, "projectOwner:my-example-project"
* **projectEditor:projectid**: Editors of the given project. For example, "projectEditor:my-example-project"
* **projectViewer:projectid**: Viewers of the given project. For example, "projectViewer:my-example-project"
"
project" The ID of the project in which the resource belongs.
If it is not provided, the project will be parsed from the identifier of the parent resource. If no project is provided in the parent identifier and no project is specified, the provider project is used.
"Ø
role" ËThe role that should be applied. Only one
`gcp.dataplex.DatascanIamBinding` can be used per role. Note that custom roles must be of the format
`[projects|organizations]/{parent-name}/roles/{role-name}`.
*Ää
O
dataplexDatascanIamMember0gcp:dataplex/datascanIamMember:DatascanIamMemberÞÀThree different resources help you manage your IAM policy for Dataplex Datascan. Each of these resources serves a different use case:

* `gcp.dataplex.DatascanIamPolicy`: Authoritative. Sets the IAM policy for the datascan and replaces any existing policy already attached.
* `gcp.dataplex.DatascanIamBinding`: Authoritative for a given role. Updates the IAM policy to grant a role to a list of members. Other roles within the IAM policy for the datascan are preserved.
* `gcp.dataplex.DatascanIamMember`: Non-authoritative. Updates the IAM policy to grant a role to a new member. Other members for the role for the datascan are preserved.

A data source can be used to retrieve policy data in advent you do not need creation

* `gcp.dataplex.DatascanIamPolicy`: Retrieves the IAM policy for the datascan

> **Note:** `gcp.dataplex.DatascanIamPolicy` **cannot** be used in conjunction with `gcp.dataplex.DatascanIamBinding` and `gcp.dataplex.DatascanIamMember` or they will fight over what your policy should be.

> **Note:** `gcp.dataplex.DatascanIamBinding` resources **can be** used in conjunction with `gcp.dataplex.DatascanIamMember` resources **only if** they do not grant privilege to the same role.



## gcp.dataplex.DatascanIamPolicy

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const admin = gcp.organizations.getIAMPolicy({
    bindings: [{
        role: "roles/viewer",
        members: ["user:jane@example.com"],
    }],
});
const policy = new gcp.dataplex.DatascanIamPolicy("policy", {
    project: basicProfile.project,
    location: basicProfile.location,
    dataScanId: basicProfile.dataScanId,
    policyData: admin.then(admin => admin.policyData),
});
```
```python
import pulumi
import pulumi_gcp as gcp

admin = gcp.organizations.get_iam_policy(bindings=[{
    "role": "roles/viewer",
    "members": ["user:jane@example.com"],
}])
policy = gcp.dataplex.DatascanIamPolicy("policy",
    project=basic_profile["project"],
    location=basic_profile["location"],
    data_scan_id=basic_profile["dataScanId"],
    policy_data=admin.policy_data)
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var admin = Gcp.Organizations.GetIAMPolicy.Invoke(new()
    {
        Bindings = new[]
        {
            new Gcp.Organizations.Inputs.GetIAMPolicyBindingInputArgs
            {
                Role = "roles/viewer",
                Members = new[]
                {
                    "user:jane@example.com",
                },
            },
        },
    });

    var policy = new Gcp.DataPlex.DatascanIamPolicy("policy", new()
    {
        Project = basicProfile.Project,
        Location = basicProfile.Location,
        DataScanId = basicProfile.DataScanId,
        PolicyData = admin.Apply(getIAMPolicyResult => getIAMPolicyResult.PolicyData),
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/dataplex"
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/organizations"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		admin, err := organizations.LookupIAMPolicy(ctx, &organizations.LookupIAMPolicyArgs{
			Bindings: []organizations.GetIAMPolicyBinding{
				{
					Role: "roles/viewer",
					Members: []string{
						"user:jane@example.com",
					},
				},
			},
		}, nil)
		if err != nil {
			return err
		}
		_, err = dataplex.NewDatascanIamPolicy(ctx, "policy", &dataplex.DatascanIamPolicyArgs{
			Project:    pulumi.Any(basicProfile.Project),
			Location:   pulumi.Any(basicProfile.Location),
			DataScanId: pulumi.Any(basicProfile.DataScanId),
			PolicyData: pulumi.String(admin.PolicyData),
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.organizations.OrganizationsFunctions;
import com.pulumi.gcp.organizations.inputs.GetIAMPolicyArgs;
import com.pulumi.gcp.dataplex.DatascanIamPolicy;
import com.pulumi.gcp.dataplex.DatascanIamPolicyArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        final var admin = OrganizationsFunctions.getIAMPolicy(GetIAMPolicyArgs.builder()
            .bindings(GetIAMPolicyBindingArgs.builder()
                .role("roles/viewer")
                .members("user:jane@example.com")
                .build())
            .build());

        var policy = new DatascanIamPolicy("policy", DatascanIamPolicyArgs.builder()
            .project(basicProfile.project())
            .location(basicProfile.location())
            .dataScanId(basicProfile.dataScanId())
            .policyData(admin.applyValue(getIAMPolicyResult -> getIAMPolicyResult.policyData()))
            .build());

    }
}
```
```yaml
resources:
  policy:
    type: gcp:dataplex:DatascanIamPolicy
    properties:
      project: ${basicProfile.project}
      location: ${basicProfile.location}
      dataScanId: ${basicProfile.dataScanId}
      policyData: ${admin.policyData}
variables:
  admin:
    fn::invoke:
      function: gcp:organizations:getIAMPolicy
      arguments:
        bindings:
          - role: roles/viewer
            members:
              - user:jane@example.com
```
<!--End PulumiCodeChooser -->

## gcp.dataplex.DatascanIamBinding

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const binding = new gcp.dataplex.DatascanIamBinding("binding", {
    project: basicProfile.project,
    location: basicProfile.location,
    dataScanId: basicProfile.dataScanId,
    role: "roles/viewer",
    members: ["user:jane@example.com"],
});
```
```python
import pulumi
import pulumi_gcp as gcp

binding = gcp.dataplex.DatascanIamBinding("binding",
    project=basic_profile["project"],
    location=basic_profile["location"],
    data_scan_id=basic_profile["dataScanId"],
    role="roles/viewer",
    members=["user:jane@example.com"])
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var binding = new Gcp.DataPlex.DatascanIamBinding("binding", new()
    {
        Project = basicProfile.Project,
        Location = basicProfile.Location,
        DataScanId = basicProfile.DataScanId,
        Role = "roles/viewer",
        Members = new[]
        {
            "user:jane@example.com",
        },
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/dataplex"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		_, err := dataplex.NewDatascanIamBinding(ctx, "binding", &dataplex.DatascanIamBindingArgs{
			Project:    pulumi.Any(basicProfile.Project),
			Location:   pulumi.Any(basicProfile.Location),
			DataScanId: pulumi.Any(basicProfile.DataScanId),
			Role:       pulumi.String("roles/viewer"),
			Members: pulumi.StringArray{
				pulumi.String("user:jane@example.com"),
			},
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.dataplex.DatascanIamBinding;
import com.pulumi.gcp.dataplex.DatascanIamBindingArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        var binding = new DatascanIamBinding("binding", DatascanIamBindingArgs.builder()
            .project(basicProfile.project())
            .location(basicProfile.location())
            .dataScanId(basicProfile.dataScanId())
            .role("roles/viewer")
            .members("user:jane@example.com")
            .build());

    }
}
```
```yaml
resources:
  binding:
    type: gcp:dataplex:DatascanIamBinding
    properties:
      project: ${basicProfile.project}
      location: ${basicProfile.location}
      dataScanId: ${basicProfile.dataScanId}
      role: roles/viewer
      members:
        - user:jane@example.com
```
<!--End PulumiCodeChooser -->

## gcp.dataplex.DatascanIamMember

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const member = new gcp.dataplex.DatascanIamMember("member", {
    project: basicProfile.project,
    location: basicProfile.location,
    dataScanId: basicProfile.dataScanId,
    role: "roles/viewer",
    member: "user:jane@example.com",
});
```
```python
import pulumi
import pulumi_gcp as gcp

member = gcp.dataplex.DatascanIamMember("member",
    project=basic_profile["project"],
    location=basic_profile["location"],
    data_scan_id=basic_profile["dataScanId"],
    role="roles/viewer",
    member="user:jane@example.com")
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var member = new Gcp.DataPlex.DatascanIamMember("member", new()
    {
        Project = basicProfile.Project,
        Location = basicProfile.Location,
        DataScanId = basicProfile.DataScanId,
        Role = "roles/viewer",
        Member = "user:jane@example.com",
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/dataplex"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		_, err := dataplex.NewDatascanIamMember(ctx, "member", &dataplex.DatascanIamMemberArgs{
			Project:    pulumi.Any(basicProfile.Project),
			Location:   pulumi.Any(basicProfile.Location),
			DataScanId: pulumi.Any(basicProfile.DataScanId),
			Role:       pulumi.String("roles/viewer"),
			Member:     pulumi.String("user:jane@example.com"),
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.dataplex.DatascanIamMember;
import com.pulumi.gcp.dataplex.DatascanIamMemberArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        var member = new DatascanIamMember("member", DatascanIamMemberArgs.builder()
            .project(basicProfile.project())
            .location(basicProfile.location())
            .dataScanId(basicProfile.dataScanId())
            .role("roles/viewer")
            .member("user:jane@example.com")
            .build());

    }
}
```
```yaml
resources:
  member:
    type: gcp:dataplex:DatascanIamMember
    properties:
      project: ${basicProfile.project}
      location: ${basicProfile.location}
      dataScanId: ${basicProfile.dataScanId}
      role: roles/viewer
      member: user:jane@example.com
```
<!--End PulumiCodeChooser -->


## This resource supports User Project Overrides.

-

# IAM policy for Dataplex Datascan
Three different resources help you manage your IAM policy for Dataplex Datascan. Each of these resources serves a different use case:

* `gcp.dataplex.DatascanIamPolicy`: Authoritative. Sets the IAM policy for the datascan and replaces any existing policy already attached.
* `gcp.dataplex.DatascanIamBinding`: Authoritative for a given role. Updates the IAM policy to grant a role to a list of members. Other roles within the IAM policy for the datascan are preserved.
* `gcp.dataplex.DatascanIamMember`: Non-authoritative. Updates the IAM policy to grant a role to a new member. Other members for the role for the datascan are preserved.

A data source can be used to retrieve policy data in advent you do not need creation

* `gcp.dataplex.DatascanIamPolicy`: Retrieves the IAM policy for the datascan

> **Note:** `gcp.dataplex.DatascanIamPolicy` **cannot** be used in conjunction with `gcp.dataplex.DatascanIamBinding` and `gcp.dataplex.DatascanIamMember` or they will fight over what your policy should be.

> **Note:** `gcp.dataplex.DatascanIamBinding` resources **can be** used in conjunction with `gcp.dataplex.DatascanIamMember` resources **only if** they do not grant privilege to the same role.



## gcp.dataplex.DatascanIamPolicy

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const admin = gcp.organizations.getIAMPolicy({
    bindings: [{
        role: "roles/viewer",
        members: ["user:jane@example.com"],
    }],
});
const policy = new gcp.dataplex.DatascanIamPolicy("policy", {
    project: basicProfile.project,
    location: basicProfile.location,
    dataScanId: basicProfile.dataScanId,
    policyData: admin.then(admin => admin.policyData),
});
```
```python
import pulumi
import pulumi_gcp as gcp

admin = gcp.organizations.get_iam_policy(bindings=[{
    "role": "roles/viewer",
    "members": ["user:jane@example.com"],
}])
policy = gcp.dataplex.DatascanIamPolicy("policy",
    project=basic_profile["project"],
    location=basic_profile["location"],
    data_scan_id=basic_profile["dataScanId"],
    policy_data=admin.policy_data)
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var admin = Gcp.Organizations.GetIAMPolicy.Invoke(new()
    {
        Bindings = new[]
        {
            new Gcp.Organizations.Inputs.GetIAMPolicyBindingInputArgs
            {
                Role = "roles/viewer",
                Members = new[]
                {
                    "user:jane@example.com",
                },
            },
        },
    });

    var policy = new Gcp.DataPlex.DatascanIamPolicy("policy", new()
    {
        Project = basicProfile.Project,
        Location = basicProfile.Location,
        DataScanId = basicProfile.DataScanId,
        PolicyData = admin.Apply(getIAMPolicyResult => getIAMPolicyResult.PolicyData),
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/dataplex"
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/organizations"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		admin, err := organizations.LookupIAMPolicy(ctx, &organizations.LookupIAMPolicyArgs{
			Bindings: []organizations.GetIAMPolicyBinding{
				{
					Role: "roles/viewer",
					Members: []string{
						"user:jane@example.com",
					},
				},
			},
		}, nil)
		if err != nil {
			return err
		}
		_, err = dataplex.NewDatascanIamPolicy(ctx, "policy", &dataplex.DatascanIamPolicyArgs{
			Project:    pulumi.Any(basicProfile.Project),
			Location:   pulumi.Any(basicProfile.Location),
			DataScanId: pulumi.Any(basicProfile.DataScanId),
			PolicyData: pulumi.String(admin.PolicyData),
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.organizations.OrganizationsFunctions;
import com.pulumi.gcp.organizations.inputs.GetIAMPolicyArgs;
import com.pulumi.gcp.dataplex.DatascanIamPolicy;
import com.pulumi.gcp.dataplex.DatascanIamPolicyArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        final var admin = OrganizationsFunctions.getIAMPolicy(GetIAMPolicyArgs.builder()
            .bindings(GetIAMPolicyBindingArgs.builder()
                .role("roles/viewer")
                .members("user:jane@example.com")
                .build())
            .build());

        var policy = new DatascanIamPolicy("policy", DatascanIamPolicyArgs.builder()
            .project(basicProfile.project())
            .location(basicProfile.location())
            .dataScanId(basicProfile.dataScanId())
            .policyData(admin.applyValue(getIAMPolicyResult -> getIAMPolicyResult.policyData()))
            .build());

    }
}
```
```yaml
resources:
  policy:
    type: gcp:dataplex:DatascanIamPolicy
    properties:
      project: ${basicProfile.project}
      location: ${basicProfile.location}
      dataScanId: ${basicProfile.dataScanId}
      policyData: ${admin.policyData}
variables:
  admin:
    fn::invoke:
      function: gcp:organizations:getIAMPolicy
      arguments:
        bindings:
          - role: roles/viewer
            members:
              - user:jane@example.com
```
<!--End PulumiCodeChooser -->

## gcp.dataplex.DatascanIamBinding

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const binding = new gcp.dataplex.DatascanIamBinding("binding", {
    project: basicProfile.project,
    location: basicProfile.location,
    dataScanId: basicProfile.dataScanId,
    role: "roles/viewer",
    members: ["user:jane@example.com"],
});
```
```python
import pulumi
import pulumi_gcp as gcp

binding = gcp.dataplex.DatascanIamBinding("binding",
    project=basic_profile["project"],
    location=basic_profile["location"],
    data_scan_id=basic_profile["dataScanId"],
    role="roles/viewer",
    members=["user:jane@example.com"])
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var binding = new Gcp.DataPlex.DatascanIamBinding("binding", new()
    {
        Project = basicProfile.Project,
        Location = basicProfile.Location,
        DataScanId = basicProfile.DataScanId,
        Role = "roles/viewer",
        Members = new[]
        {
            "user:jane@example.com",
        },
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/dataplex"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		_, err := dataplex.NewDatascanIamBinding(ctx, "binding", &dataplex.DatascanIamBindingArgs{
			Project:    pulumi.Any(basicProfile.Project),
			Location:   pulumi.Any(basicProfile.Location),
			DataScanId: pulumi.Any(basicProfile.DataScanId),
			Role:       pulumi.String("roles/viewer"),
			Members: pulumi.StringArray{
				pulumi.String("user:jane@example.com"),
			},
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.dataplex.DatascanIamBinding;
import com.pulumi.gcp.dataplex.DatascanIamBindingArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        var binding = new DatascanIamBinding("binding", DatascanIamBindingArgs.builder()
            .project(basicProfile.project())
            .location(basicProfile.location())
            .dataScanId(basicProfile.dataScanId())
            .role("roles/viewer")
            .members("user:jane@example.com")
            .build());

    }
}
```
```yaml
resources:
  binding:
    type: gcp:dataplex:DatascanIamBinding
    properties:
      project: ${basicProfile.project}
      location: ${basicProfile.location}
      dataScanId: ${basicProfile.dataScanId}
      role: roles/viewer
      members:
        - user:jane@example.com
```
<!--End PulumiCodeChooser -->

## gcp.dataplex.DatascanIamMember

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const member = new gcp.dataplex.DatascanIamMember("member", {
    project: basicProfile.project,
    location: basicProfile.location,
    dataScanId: basicProfile.dataScanId,
    role: "roles/viewer",
    member: "user:jane@example.com",
});
```
```python
import pulumi
import pulumi_gcp as gcp

member = gcp.dataplex.DatascanIamMember("member",
    project=basic_profile["project"],
    location=basic_profile["location"],
    data_scan_id=basic_profile["dataScanId"],
    role="roles/viewer",
    member="user:jane@example.com")
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var member = new Gcp.DataPlex.DatascanIamMember("member", new()
    {
        Project = basicProfile.Project,
        Location = basicProfile.Location,
        DataScanId = basicProfile.DataScanId,
        Role = "roles/viewer",
        Member = "user:jane@example.com",
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/dataplex"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		_, err := dataplex.NewDatascanIamMember(ctx, "member", &dataplex.DatascanIamMemberArgs{
			Project:    pulumi.Any(basicProfile.Project),
			Location:   pulumi.Any(basicProfile.Location),
			DataScanId: pulumi.Any(basicProfile.DataScanId),
			Role:       pulumi.String("roles/viewer"),
			Member:     pulumi.String("user:jane@example.com"),
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.dataplex.DatascanIamMember;
import com.pulumi.gcp.dataplex.DatascanIamMemberArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        var member = new DatascanIamMember("member", DatascanIamMemberArgs.builder()
            .project(basicProfile.project())
            .location(basicProfile.location())
            .dataScanId(basicProfile.dataScanId())
            .role("roles/viewer")
            .member("user:jane@example.com")
            .build());

    }
}
```
```yaml
resources:
  member:
    type: gcp:dataplex:DatascanIamMember
    properties:
      project: ${basicProfile.project}
      location: ${basicProfile.location}
      dataScanId: ${basicProfile.dataScanId}
      role: roles/viewer
      member: user:jane@example.com
```
<!--End PulumiCodeChooser -->

## Import

For all import syntaxes, the "resource in question" can take any of the following forms:

* projects/{{project}}/locations/{{location}}/dataScans/{{data_scan_id}}

* {{project}}/{{location}}/{{data_scan_id}}

* {{location}}/{{data_scan_id}}

* {{data_scan_id}}

Any variables not passed in the import command will be taken from the provider configuration.

Dataplex datascan IAM resources can be imported using the resource identifiers, role, and member.

IAM member imports use space-delimited identifiers: the resource in question, the role, and the member identity, e.g.

```sh
$ pulumi import gcp:dataplex/datascanIamMember:DatascanIamMember editor "projects/{{project}}/locations/{{location}}/dataScans/{{data_scan_id}} roles/viewer user:jane@example.com"
```

IAM binding imports use space-delimited identifiers: the resource in question and the role, e.g.

```sh
$ pulumi import gcp:dataplex/datascanIamMember:DatascanIamMember editor "projects/{{project}}/locations/{{location}}/dataScans/{{data_scan_id}} roles/viewer"
```

IAM policy imports use the identifier of the resource in question, e.g.

```sh
$ pulumi import gcp:dataplex/datascanIamMember:DatascanIamMember editor projects/{{project}}/locations/{{location}}/dataScans/{{data_scan_id}}
```

-> **Custom Roles** If you're importing a IAM resource with a custom role, make sure to use the

 full name of the custom role, e.g. `[projects/my-project|organizations/my-org]/roles/my-custom-role`.

}
	conditionpBn:l
j
dataplexDatascanIamMemberConditionBgcp:dataplex/DatascanIamMemberCondition:DatascanIamMemberCondition

dataScanId" Õ
locationB" ÂThe location where the data scan should reside.
Used to find the parent resource to bind the IAM policy to. If not specified,
the value will be parsed from the identifier of the parent resource. If no location is provided in the parent identifier and no
location is specified, it is taken from the provider configuration.
Ó	
member" Ä	Identities that will be granted the privilege in `role`.
Each entry can have one of the following values:
* **allUsers**: A special identifier that represents anyone who is on the internet; with or without a Google account.
* **allAuthenticatedUsers**: A special identifier that represents anyone who is authenticated with a Google account or a service account.
* **user:{emailid}**: An email address that represents a specific Google account. For example, alice@gmail.com or joe@example.com.
* **serviceAccount:{emailid}**: An email address that represents a service account. For example, my-other-app@appspot.gserviceaccount.com.
* **group:{emailid}**: An email address that represents a Google group. For example, admins@example.com.
* **domain:{domain}**: A G Suite domain (primary, instead of alias) name that represents all the users of that domain. For example, google.com or example.com.
* **projectOwner:projectid**: Owners of the given project. For example, "projectOwner:my-example-project"
* **projectEditor:projectid**: Editors of the given project. For example, "projectEditor:my-example-project"
* **projectViewer:projectid**: Viewers of the given project. For example, "projectViewer:my-example-project"

projectB" The ID of the project in which the resource belongs.
If it is not provided, the project will be parsed from the identifier of the parent resource. If no project is provided in the parent identifier and no project is specified, the provider project is used.
Ø
role" ËThe role that should be applied. Only one
`gcp.dataplex.DatascanIamBinding` can be used per role. Note that custom roles must be of the format
`[projects|organizations]/{parent-name}/roles/{role-name}`.
"}
	conditionpBn:l
j
dataplexDatascanIamMemberConditionBgcp:dataplex/DatascanIamMemberCondition:DatascanIamMemberCondition"

dataScanId" "3
etag" '(Computed) The etag of the IAM policy.
"Ó
location" ÂThe location where the data scan should reside.
Used to find the parent resource to bind the IAM policy to. If not specified,
the value will be parsed from the identifier of the parent resource. If no location is provided in the parent identifier and no
location is specified, it is taken from the provider configuration.
"Ó	
member" Ä	Identities that will be granted the privilege in `role`.
Each entry can have one of the following values:
* **allUsers**: A special identifier that represents anyone who is on the internet; with or without a Google account.
* **allAuthenticatedUsers**: A special identifier that represents anyone who is authenticated with a Google account or a service account.
* **user:{emailid}**: An email address that represents a specific Google account. For example, alice@gmail.com or joe@example.com.
* **serviceAccount:{emailid}**: An email address that represents a service account. For example, my-other-app@appspot.gserviceaccount.com.
* **group:{emailid}**: An email address that represents a Google group. For example, admins@example.com.
* **domain:{domain}**: A G Suite domain (primary, instead of alias) name that represents all the users of that domain. For example, google.com or example.com.
* **projectOwner:projectid**: Owners of the given project. For example, "projectOwner:my-example-project"
* **projectEditor:projectid**: Editors of the given project. For example, "projectEditor:my-example-project"
* **projectViewer:projectid**: Viewers of the given project. For example, "projectViewer:my-example-project"
"
project" The ID of the project in which the resource belongs.
If it is not provided, the project will be parsed from the identifier of the parent resource. If no project is provided in the parent identifier and no project is specified, the provider project is used.
"Ø
role" ËThe role that should be applied. Only one
`gcp.dataplex.DatascanIamBinding` can be used per role. Note that custom roles must be of the format
`[projects|organizations]/{parent-name}/roles/{role-name}`.
*¦Í
O
dataplexDatascanIamPolicy0gcp:dataplex/datascanIamPolicy:DatascanIamPolicyÞÀThree different resources help you manage your IAM policy for Dataplex Datascan. Each of these resources serves a different use case:

* `gcp.dataplex.DatascanIamPolicy`: Authoritative. Sets the IAM policy for the datascan and replaces any existing policy already attached.
* `gcp.dataplex.DatascanIamBinding`: Authoritative for a given role. Updates the IAM policy to grant a role to a list of members. Other roles within the IAM policy for the datascan are preserved.
* `gcp.dataplex.DatascanIamMember`: Non-authoritative. Updates the IAM policy to grant a role to a new member. Other members for the role for the datascan are preserved.

A data source can be used to retrieve policy data in advent you do not need creation

* `gcp.dataplex.DatascanIamPolicy`: Retrieves the IAM policy for the datascan

> **Note:** `gcp.dataplex.DatascanIamPolicy` **cannot** be used in conjunction with `gcp.dataplex.DatascanIamBinding` and `gcp.dataplex.DatascanIamMember` or they will fight over what your policy should be.

> **Note:** `gcp.dataplex.DatascanIamBinding` resources **can be** used in conjunction with `gcp.dataplex.DatascanIamMember` resources **only if** they do not grant privilege to the same role.



## gcp.dataplex.DatascanIamPolicy

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const admin = gcp.organizations.getIAMPolicy({
    bindings: [{
        role: "roles/viewer",
        members: ["user:jane@example.com"],
    }],
});
const policy = new gcp.dataplex.DatascanIamPolicy("policy", {
    project: basicProfile.project,
    location: basicProfile.location,
    dataScanId: basicProfile.dataScanId,
    policyData: admin.then(admin => admin.policyData),
});
```
```python
import pulumi
import pulumi_gcp as gcp

admin = gcp.organizations.get_iam_policy(bindings=[{
    "role": "roles/viewer",
    "members": ["user:jane@example.com"],
}])
policy = gcp.dataplex.DatascanIamPolicy("policy",
    project=basic_profile["project"],
    location=basic_profile["location"],
    data_scan_id=basic_profile["dataScanId"],
    policy_data=admin.policy_data)
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var admin = Gcp.Organizations.GetIAMPolicy.Invoke(new()
    {
        Bindings = new[]
        {
            new Gcp.Organizations.Inputs.GetIAMPolicyBindingInputArgs
            {
                Role = "roles/viewer",
                Members = new[]
                {
                    "user:jane@example.com",
                },
            },
        },
    });

    var policy = new Gcp.DataPlex.DatascanIamPolicy("policy", new()
    {
        Project = basicProfile.Project,
        Location = basicProfile.Location,
        DataScanId = basicProfile.DataScanId,
        PolicyData = admin.Apply(getIAMPolicyResult => getIAMPolicyResult.PolicyData),
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/dataplex"
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/organizations"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		admin, err := organizations.LookupIAMPolicy(ctx, &organizations.LookupIAMPolicyArgs{
			Bindings: []organizations.GetIAMPolicyBinding{
				{
					Role: "roles/viewer",
					Members: []string{
						"user:jane@example.com",
					},
				},
			},
		}, nil)
		if err != nil {
			return err
		}
		_, err = dataplex.NewDatascanIamPolicy(ctx, "policy", &dataplex.DatascanIamPolicyArgs{
			Project:    pulumi.Any(basicProfile.Project),
			Location:   pulumi.Any(basicProfile.Location),
			DataScanId: pulumi.Any(basicProfile.DataScanId),
			PolicyData: pulumi.String(admin.PolicyData),
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.organizations.OrganizationsFunctions;
import com.pulumi.gcp.organizations.inputs.GetIAMPolicyArgs;
import com.pulumi.gcp.dataplex.DatascanIamPolicy;
import com.pulumi.gcp.dataplex.DatascanIamPolicyArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        final var admin = OrganizationsFunctions.getIAMPolicy(GetIAMPolicyArgs.builder()
            .bindings(GetIAMPolicyBindingArgs.builder()
                .role("roles/viewer")
                .members("user:jane@example.com")
                .build())
            .build());

        var policy = new DatascanIamPolicy("policy", DatascanIamPolicyArgs.builder()
            .project(basicProfile.project())
            .location(basicProfile.location())
            .dataScanId(basicProfile.dataScanId())
            .policyData(admin.applyValue(getIAMPolicyResult -> getIAMPolicyResult.policyData()))
            .build());

    }
}
```
```yaml
resources:
  policy:
    type: gcp:dataplex:DatascanIamPolicy
    properties:
      project: ${basicProfile.project}
      location: ${basicProfile.location}
      dataScanId: ${basicProfile.dataScanId}
      policyData: ${admin.policyData}
variables:
  admin:
    fn::invoke:
      function: gcp:organizations:getIAMPolicy
      arguments:
        bindings:
          - role: roles/viewer
            members:
              - user:jane@example.com
```
<!--End PulumiCodeChooser -->

## gcp.dataplex.DatascanIamBinding

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const binding = new gcp.dataplex.DatascanIamBinding("binding", {
    project: basicProfile.project,
    location: basicProfile.location,
    dataScanId: basicProfile.dataScanId,
    role: "roles/viewer",
    members: ["user:jane@example.com"],
});
```
```python
import pulumi
import pulumi_gcp as gcp

binding = gcp.dataplex.DatascanIamBinding("binding",
    project=basic_profile["project"],
    location=basic_profile["location"],
    data_scan_id=basic_profile["dataScanId"],
    role="roles/viewer",
    members=["user:jane@example.com"])
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var binding = new Gcp.DataPlex.DatascanIamBinding("binding", new()
    {
        Project = basicProfile.Project,
        Location = basicProfile.Location,
        DataScanId = basicProfile.DataScanId,
        Role = "roles/viewer",
        Members = new[]
        {
            "user:jane@example.com",
        },
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/dataplex"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		_, err := dataplex.NewDatascanIamBinding(ctx, "binding", &dataplex.DatascanIamBindingArgs{
			Project:    pulumi.Any(basicProfile.Project),
			Location:   pulumi.Any(basicProfile.Location),
			DataScanId: pulumi.Any(basicProfile.DataScanId),
			Role:       pulumi.String("roles/viewer"),
			Members: pulumi.StringArray{
				pulumi.String("user:jane@example.com"),
			},
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.dataplex.DatascanIamBinding;
import com.pulumi.gcp.dataplex.DatascanIamBindingArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        var binding = new DatascanIamBinding("binding", DatascanIamBindingArgs.builder()
            .project(basicProfile.project())
            .location(basicProfile.location())
            .dataScanId(basicProfile.dataScanId())
            .role("roles/viewer")
            .members("user:jane@example.com")
            .build());

    }
}
```
```yaml
resources:
  binding:
    type: gcp:dataplex:DatascanIamBinding
    properties:
      project: ${basicProfile.project}
      location: ${basicProfile.location}
      dataScanId: ${basicProfile.dataScanId}
      role: roles/viewer
      members:
        - user:jane@example.com
```
<!--End PulumiCodeChooser -->

## gcp.dataplex.DatascanIamMember

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const member = new gcp.dataplex.DatascanIamMember("member", {
    project: basicProfile.project,
    location: basicProfile.location,
    dataScanId: basicProfile.dataScanId,
    role: "roles/viewer",
    member: "user:jane@example.com",
});
```
```python
import pulumi
import pulumi_gcp as gcp

member = gcp.dataplex.DatascanIamMember("member",
    project=basic_profile["project"],
    location=basic_profile["location"],
    data_scan_id=basic_profile["dataScanId"],
    role="roles/viewer",
    member="user:jane@example.com")
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var member = new Gcp.DataPlex.DatascanIamMember("member", new()
    {
        Project = basicProfile.Project,
        Location = basicProfile.Location,
        DataScanId = basicProfile.DataScanId,
        Role = "roles/viewer",
        Member = "user:jane@example.com",
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/dataplex"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		_, err := dataplex.NewDatascanIamMember(ctx, "member", &dataplex.DatascanIamMemberArgs{
			Project:    pulumi.Any(basicProfile.Project),
			Location:   pulumi.Any(basicProfile.Location),
			DataScanId: pulumi.Any(basicProfile.DataScanId),
			Role:       pulumi.String("roles/viewer"),
			Member:     pulumi.String("user:jane@example.com"),
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.dataplex.DatascanIamMember;
import com.pulumi.gcp.dataplex.DatascanIamMemberArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        var member = new DatascanIamMember("member", DatascanIamMemberArgs.builder()
            .project(basicProfile.project())
            .location(basicProfile.location())
            .dataScanId(basicProfile.dataScanId())
            .role("roles/viewer")
            .member("user:jane@example.com")
            .build());

    }
}
```
```yaml
resources:
  member:
    type: gcp:dataplex:DatascanIamMember
    properties:
      project: ${basicProfile.project}
      location: ${basicProfile.location}
      dataScanId: ${basicProfile.dataScanId}
      role: roles/viewer
      member: user:jane@example.com
```
<!--End PulumiCodeChooser -->


## This resource supports User Project Overrides.

-

# IAM policy for Dataplex Datascan
Three different resources help you manage your IAM policy for Dataplex Datascan. Each of these resources serves a different use case:

* `gcp.dataplex.DatascanIamPolicy`: Authoritative. Sets the IAM policy for the datascan and replaces any existing policy already attached.
* `gcp.dataplex.DatascanIamBinding`: Authoritative for a given role. Updates the IAM policy to grant a role to a list of members. Other roles within the IAM policy for the datascan are preserved.
* `gcp.dataplex.DatascanIamMember`: Non-authoritative. Updates the IAM policy to grant a role to a new member. Other members for the role for the datascan are preserved.

A data source can be used to retrieve policy data in advent you do not need creation

* `gcp.dataplex.DatascanIamPolicy`: Retrieves the IAM policy for the datascan

> **Note:** `gcp.dataplex.DatascanIamPolicy` **cannot** be used in conjunction with `gcp.dataplex.DatascanIamBinding` and `gcp.dataplex.DatascanIamMember` or they will fight over what your policy should be.

> **Note:** `gcp.dataplex.DatascanIamBinding` resources **can be** used in conjunction with `gcp.dataplex.DatascanIamMember` resources **only if** they do not grant privilege to the same role.



## gcp.dataplex.DatascanIamPolicy

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const admin = gcp.organizations.getIAMPolicy({
    bindings: [{
        role: "roles/viewer",
        members: ["user:jane@example.com"],
    }],
});
const policy = new gcp.dataplex.DatascanIamPolicy("policy", {
    project: basicProfile.project,
    location: basicProfile.location,
    dataScanId: basicProfile.dataScanId,
    policyData: admin.then(admin => admin.policyData),
});
```
```python
import pulumi
import pulumi_gcp as gcp

admin = gcp.organizations.get_iam_policy(bindings=[{
    "role": "roles/viewer",
    "members": ["user:jane@example.com"],
}])
policy = gcp.dataplex.DatascanIamPolicy("policy",
    project=basic_profile["project"],
    location=basic_profile["location"],
    data_scan_id=basic_profile["dataScanId"],
    policy_data=admin.policy_data)
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var admin = Gcp.Organizations.GetIAMPolicy.Invoke(new()
    {
        Bindings = new[]
        {
            new Gcp.Organizations.Inputs.GetIAMPolicyBindingInputArgs
            {
                Role = "roles/viewer",
                Members = new[]
                {
                    "user:jane@example.com",
                },
            },
        },
    });

    var policy = new Gcp.DataPlex.DatascanIamPolicy("policy", new()
    {
        Project = basicProfile.Project,
        Location = basicProfile.Location,
        DataScanId = basicProfile.DataScanId,
        PolicyData = admin.Apply(getIAMPolicyResult => getIAMPolicyResult.PolicyData),
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/dataplex"
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/organizations"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		admin, err := organizations.LookupIAMPolicy(ctx, &organizations.LookupIAMPolicyArgs{
			Bindings: []organizations.GetIAMPolicyBinding{
				{
					Role: "roles/viewer",
					Members: []string{
						"user:jane@example.com",
					},
				},
			},
		}, nil)
		if err != nil {
			return err
		}
		_, err = dataplex.NewDatascanIamPolicy(ctx, "policy", &dataplex.DatascanIamPolicyArgs{
			Project:    pulumi.Any(basicProfile.Project),
			Location:   pulumi.Any(basicProfile.Location),
			DataScanId: pulumi.Any(basicProfile.DataScanId),
			PolicyData: pulumi.String(admin.PolicyData),
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.organizations.OrganizationsFunctions;
import com.pulumi.gcp.organizations.inputs.GetIAMPolicyArgs;
import com.pulumi.gcp.dataplex.DatascanIamPolicy;
import com.pulumi.gcp.dataplex.DatascanIamPolicyArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        final var admin = OrganizationsFunctions.getIAMPolicy(GetIAMPolicyArgs.builder()
            .bindings(GetIAMPolicyBindingArgs.builder()
                .role("roles/viewer")
                .members("user:jane@example.com")
                .build())
            .build());

        var policy = new DatascanIamPolicy("policy", DatascanIamPolicyArgs.builder()
            .project(basicProfile.project())
            .location(basicProfile.location())
            .dataScanId(basicProfile.dataScanId())
            .policyData(admin.applyValue(getIAMPolicyResult -> getIAMPolicyResult.policyData()))
            .build());

    }
}
```
```yaml
resources:
  policy:
    type: gcp:dataplex:DatascanIamPolicy
    properties:
      project: ${basicProfile.project}
      location: ${basicProfile.location}
      dataScanId: ${basicProfile.dataScanId}
      policyData: ${admin.policyData}
variables:
  admin:
    fn::invoke:
      function: gcp:organizations:getIAMPolicy
      arguments:
        bindings:
          - role: roles/viewer
            members:
              - user:jane@example.com
```
<!--End PulumiCodeChooser -->

## gcp.dataplex.DatascanIamBinding

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const binding = new gcp.dataplex.DatascanIamBinding("binding", {
    project: basicProfile.project,
    location: basicProfile.location,
    dataScanId: basicProfile.dataScanId,
    role: "roles/viewer",
    members: ["user:jane@example.com"],
});
```
```python
import pulumi
import pulumi_gcp as gcp

binding = gcp.dataplex.DatascanIamBinding("binding",
    project=basic_profile["project"],
    location=basic_profile["location"],
    data_scan_id=basic_profile["dataScanId"],
    role="roles/viewer",
    members=["user:jane@example.com"])
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var binding = new Gcp.DataPlex.DatascanIamBinding("binding", new()
    {
        Project = basicProfile.Project,
        Location = basicProfile.Location,
        DataScanId = basicProfile.DataScanId,
        Role = "roles/viewer",
        Members = new[]
        {
            "user:jane@example.com",
        },
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/dataplex"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		_, err := dataplex.NewDatascanIamBinding(ctx, "binding", &dataplex.DatascanIamBindingArgs{
			Project:    pulumi.Any(basicProfile.Project),
			Location:   pulumi.Any(basicProfile.Location),
			DataScanId: pulumi.Any(basicProfile.DataScanId),
			Role:       pulumi.String("roles/viewer"),
			Members: pulumi.StringArray{
				pulumi.String("user:jane@example.com"),
			},
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.dataplex.DatascanIamBinding;
import com.pulumi.gcp.dataplex.DatascanIamBindingArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        var binding = new DatascanIamBinding("binding", DatascanIamBindingArgs.builder()
            .project(basicProfile.project())
            .location(basicProfile.location())
            .dataScanId(basicProfile.dataScanId())
            .role("roles/viewer")
            .members("user:jane@example.com")
            .build());

    }
}
```
```yaml
resources:
  binding:
    type: gcp:dataplex:DatascanIamBinding
    properties:
      project: ${basicProfile.project}
      location: ${basicProfile.location}
      dataScanId: ${basicProfile.dataScanId}
      role: roles/viewer
      members:
        - user:jane@example.com
```
<!--End PulumiCodeChooser -->

## gcp.dataplex.DatascanIamMember

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const member = new gcp.dataplex.DatascanIamMember("member", {
    project: basicProfile.project,
    location: basicProfile.location,
    dataScanId: basicProfile.dataScanId,
    role: "roles/viewer",
    member: "user:jane@example.com",
});
```
```python
import pulumi
import pulumi_gcp as gcp

member = gcp.dataplex.DatascanIamMember("member",
    project=basic_profile["project"],
    location=basic_profile["location"],
    data_scan_id=basic_profile["dataScanId"],
    role="roles/viewer",
    member="user:jane@example.com")
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var member = new Gcp.DataPlex.DatascanIamMember("member", new()
    {
        Project = basicProfile.Project,
        Location = basicProfile.Location,
        DataScanId = basicProfile.DataScanId,
        Role = "roles/viewer",
        Member = "user:jane@example.com",
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/dataplex"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		_, err := dataplex.NewDatascanIamMember(ctx, "member", &dataplex.DatascanIamMemberArgs{
			Project:    pulumi.Any(basicProfile.Project),
			Location:   pulumi.Any(basicProfile.Location),
			DataScanId: pulumi.Any(basicProfile.DataScanId),
			Role:       pulumi.String("roles/viewer"),
			Member:     pulumi.String("user:jane@example.com"),
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.dataplex.DatascanIamMember;
import com.pulumi.gcp.dataplex.DatascanIamMemberArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        var member = new DatascanIamMember("member", DatascanIamMemberArgs.builder()
            .project(basicProfile.project())
            .location(basicProfile.location())
            .dataScanId(basicProfile.dataScanId())
            .role("roles/viewer")
            .member("user:jane@example.com")
            .build());

    }
}
```
```yaml
resources:
  member:
    type: gcp:dataplex:DatascanIamMember
    properties:
      project: ${basicProfile.project}
      location: ${basicProfile.location}
      dataScanId: ${basicProfile.dataScanId}
      role: roles/viewer
      member: user:jane@example.com
```
<!--End PulumiCodeChooser -->

## Import

For all import syntaxes, the "resource in question" can take any of the following forms:

* projects/{{project}}/locations/{{location}}/dataScans/{{data_scan_id}}

* {{project}}/{{location}}/{{data_scan_id}}

* {{location}}/{{data_scan_id}}

* {{data_scan_id}}

Any variables not passed in the import command will be taken from the provider configuration.

Dataplex datascan IAM resources can be imported using the resource identifiers, role, and member.

IAM member imports use space-delimited identifiers: the resource in question, the role, and the member identity, e.g.

```sh
$ pulumi import gcp:dataplex/datascanIamPolicy:DatascanIamPolicy editor "projects/{{project}}/locations/{{location}}/dataScans/{{data_scan_id}} roles/viewer user:jane@example.com"
```

IAM binding imports use space-delimited identifiers: the resource in question and the role, e.g.

```sh
$ pulumi import gcp:dataplex/datascanIamPolicy:DatascanIamPolicy editor "projects/{{project}}/locations/{{location}}/dataScans/{{data_scan_id}} roles/viewer"
```

IAM policy imports use the identifier of the resource in question, e.g.

```sh
$ pulumi import gcp:dataplex/datascanIamPolicy:DatascanIamPolicy editor projects/{{project}}/locations/{{location}}/dataScans/{{data_scan_id}}
```

-> **Custom Roles** If you're importing a IAM resource with a custom role, make sure to use the

 full name of the custom role, e.g. `[projects/my-project|organizations/my-org]/roles/my-custom-role`.



dataScanId" Õ
locationB" ÂThe location where the data scan should reside.
Used to find the parent resource to bind the IAM policy to. If not specified,
the value will be parsed from the identifier of the parent resource. If no location is provided in the parent identifier and no
location is specified, it is taken from the provider configuration.
_

policyData" MThe policy data generated by
a `gcp.organizations.getIAMPolicy` data source.

projectB" The ID of the project in which the resource belongs.
If it is not provided, the project will be parsed from the identifier of the parent resource. If no project is provided in the parent identifier and no project is specified, the provider project is used.
"

dataScanId" "3
etag" '(Computed) The etag of the IAM policy.
"Ó
location" ÂThe location where the data scan should reside.
Used to find the parent resource to bind the IAM policy to. If not specified,
the value will be parsed from the identifier of the parent resource. If no location is provided in the parent identifier and no
location is specified, it is taken from the provider configuration.
"_

policyData" MThe policy data generated by
a `gcp.organizations.getIAMPolicy` data source.
"
project" The ID of the project in which the resource belongs.
If it is not provided, the project will be parsed from the identifier of the parent resource. If no project is provided in the parent identifier and no project is specified, the provider project is used.
*E
:
dataplex
EntryGroup"gcp:dataplex/entryGroup:EntryGroup4An Entry Group represents a logical grouping of one or more Entries.



## Example Usage

### Dataplex Entry Group Basic


<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const testEntryGroupBasic = new gcp.dataplex.EntryGroup("test_entry_group_basic", {
    entryGroupId: "entry-group-basic",
    project: "my-project-name",
    location: "us-central1",
});
```
```python
import pulumi
import pulumi_gcp as gcp

test_entry_group_basic = gcp.dataplex.EntryGroup("test_entry_group_basic",
    entry_group_id="entry-group-basic",
    project="my-project-name",
    location="us-central1")
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var testEntryGroupBasic = new Gcp.DataPlex.EntryGroup("test_entry_group_basic", new()
    {
        EntryGroupId = "entry-group-basic",
        Project = "my-project-name",
        Location = "us-central1",
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/dataplex"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		_, err := dataplex.NewEntryGroup(ctx, "test_entry_group_basic", &dataplex.EntryGroupArgs{
			EntryGroupId: pulumi.String("entry-group-basic"),
			Project:      pulumi.String("my-project-name"),
			Location:     pulumi.String("us-central1"),
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.dataplex.EntryGroup;
import com.pulumi.gcp.dataplex.EntryGroupArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        var testEntryGroupBasic = new EntryGroup("testEntryGroupBasic", EntryGroupArgs.builder()
            .entryGroupId("entry-group-basic")
            .project("my-project-name")
            .location("us-central1")
            .build());

    }
}
```
```yaml
resources:
  testEntryGroupBasic:
    type: gcp:dataplex:EntryGroup
    name: test_entry_group_basic
    properties:
      entryGroupId: entry-group-basic
      project: my-project-name
      location: us-central1
```
<!--End PulumiCodeChooser -->
### Dataplex Entry Group Full


<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const testEntryGroupFull = new gcp.dataplex.EntryGroup("test_entry_group_full", {
    entryGroupId: "entry-group-full",
    project: "my-project-name",
    location: "us-central1",
    labels: {
        tag: "test-tf",
    },
    displayName: "terraform entry group",
    description: "entry group created by Terraform",
});
```
```python
import pulumi
import pulumi_gcp as gcp

test_entry_group_full = gcp.dataplex.EntryGroup("test_entry_group_full",
    entry_group_id="entry-group-full",
    project="my-project-name",
    location="us-central1",
    labels={
        "tag": "test-tf",
    },
    display_name="terraform entry group",
    description="entry group created by Terraform")
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var testEntryGroupFull = new Gcp.DataPlex.EntryGroup("test_entry_group_full", new()
    {
        EntryGroupId = "entry-group-full",
        Project = "my-project-name",
        Location = "us-central1",
        Labels = 
        {
            { "tag", "test-tf" },
        },
        DisplayName = "terraform entry group",
        Description = "entry group created by Terraform",
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/dataplex"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		_, err := dataplex.NewEntryGroup(ctx, "test_entry_group_full", &dataplex.EntryGroupArgs{
			EntryGroupId: pulumi.String("entry-group-full"),
			Project:      pulumi.String("my-project-name"),
			Location:     pulumi.String("us-central1"),
			Labels: pulumi.StringMap{
				"tag": pulumi.String("test-tf"),
			},
			DisplayName: pulumi.String("terraform entry group"),
			Description: pulumi.String("entry group created by Terraform"),
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.dataplex.EntryGroup;
import com.pulumi.gcp.dataplex.EntryGroupArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        var testEntryGroupFull = new EntryGroup("testEntryGroupFull", EntryGroupArgs.builder()
            .entryGroupId("entry-group-full")
            .project("my-project-name")
            .location("us-central1")
            .labels(Map.of("tag", "test-tf"))
            .displayName("terraform entry group")
            .description("entry group created by Terraform")
            .build());

    }
}
```
```yaml
resources:
  testEntryGroupFull:
    type: gcp:dataplex:EntryGroup
    name: test_entry_group_full
    properties:
      entryGroupId: entry-group-full
      project: my-project-name
      location: us-central1
      labels:
        tag: test-tf
      displayName: terraform entry group
      description: entry group created by Terraform
```
<!--End PulumiCodeChooser -->

## Import

EntryGroup can be imported using any of these accepted formats:

* `projects/{{project}}/locations/{{location}}/entryGroups/{{entry_group_id}}`

* `{{project}}/{{location}}/{{entry_group_id}}`

* `{{location}}/{{entry_group_id}}`

When using the `pulumi import` command, EntryGroup can be imported using one of the formats above. For example:

```sh
$ pulumi import gcp:dataplex/entryGroup:EntryGroup default projects/{{project}}/locations/{{location}}/entryGroups/{{entry_group_id}}
```

```sh
$ pulumi import gcp:dataplex/entryGroup:EntryGroup default {{project}}/{{location}}/{{entry_group_id}}
```

```sh
$ pulumi import gcp:dataplex/entryGroup:EntryGroup default {{location}}/{{entry_group_id}}
```

4
descriptionB" Description of the EntryGroup.
1
displayNameB" User friendly display name.
=
entryGroupIdB" 'The entry group id of the entry group.

labelsB2" ïUser-defined labels for the EntryGroup.

**Note**: This field is non-authoritative, and will only manage the labels present in your configuration.
Please refer to the field `effective_labels` for all of the labels present on the resource.
E
locationB" 3The location where entry group will be created in.
{
projectB" jThe ID of the project in which the resource belongs.
If it is not provided, the provider project is used.
"<

createTime" *The time when the EntryGroup was created.
"4
descriptionB" Description of the EntryGroup.
"1
displayNameB" User friendly display name.
"¦
effectiveLabels2" All of labels (key/value pairs) present on the resource in GCP, including the labels configured through Pulumi, other clients and services.
"=
entryGroupIdB" 'The entry group id of the entry group.
"
labelsB2" ïUser-defined labels for the EntryGroup.

**Note**: This field is non-authoritative, and will only manage the labels present in your configuration.
Please refer to the field `effective_labels` for all of the labels present on the resource.
"E
locationB" 3The location where entry group will be created in.
"
name" The relative resource name of the EntryGroup, of the form: projects/{project_number}/locations/{location_id}/entryGroups/{entry_group_id}
"y
project" jThe ID of the project in which the resource belongs.
If it is not provided, the provider project is used.
"
pulumiLabels2" mThe combination of labels configured directly on the resource
and default labels configured on the provider.
"
transferStatus" mDenotes the transfer status of the Entry Group. It is unspecified
for Entry Group created from Dataplex API.
"
uid" System generated globally unique ID for the EntryGroup. This ID will be different if the EntryGroup is deleted and re-created with the same name.
"A

updateTime" /The time when the EntryGroup was last updated.
*­î
X
dataplexEntryGroupIamBinding6gcp:dataplex/entryGroupIamBinding:EntryGroupIamBindingÊThree different resources help you manage your IAM policy for Dataplex EntryGroup. Each of these resources serves a different use case:

* `gcp.dataplex.EntryGroupIamPolicy`: Authoritative. Sets the IAM policy for the entrygroup and replaces any existing policy already attached.
* `gcp.dataplex.EntryGroupIamBinding`: Authoritative for a given role. Updates the IAM policy to grant a role to a list of members. Other roles within the IAM policy for the entrygroup are preserved.
* `gcp.dataplex.EntryGroupIamMember`: Non-authoritative. Updates the IAM policy to grant a role to a new member. Other members for the role for the entrygroup are preserved.

A data source can be used to retrieve policy data in advent you do not need creation

* `gcp.dataplex.EntryGroupIamPolicy`: Retrieves the IAM policy for the entrygroup

> **Note:** `gcp.dataplex.EntryGroupIamPolicy` **cannot** be used in conjunction with `gcp.dataplex.EntryGroupIamBinding` and `gcp.dataplex.EntryGroupIamMember` or they will fight over what your policy should be.

> **Note:** `gcp.dataplex.EntryGroupIamBinding` resources **can be** used in conjunction with `gcp.dataplex.EntryGroupIamMember` resources **only if** they do not grant privilege to the same role.



## gcp.dataplex.EntryGroupIamPolicy

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const admin = gcp.organizations.getIAMPolicy({
    bindings: [{
        role: "roles/viewer",
        members: ["user:jane@example.com"],
    }],
});
const policy = new gcp.dataplex.EntryGroupIamPolicy("policy", {
    project: testEntryGroupBasic.project,
    location: testEntryGroupBasic.location,
    entryGroupId: testEntryGroupBasic.entryGroupId,
    policyData: admin.then(admin => admin.policyData),
});
```
```python
import pulumi
import pulumi_gcp as gcp

admin = gcp.organizations.get_iam_policy(bindings=[{
    "role": "roles/viewer",
    "members": ["user:jane@example.com"],
}])
policy = gcp.dataplex.EntryGroupIamPolicy("policy",
    project=test_entry_group_basic["project"],
    location=test_entry_group_basic["location"],
    entry_group_id=test_entry_group_basic["entryGroupId"],
    policy_data=admin.policy_data)
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var admin = Gcp.Organizations.GetIAMPolicy.Invoke(new()
    {
        Bindings = new[]
        {
            new Gcp.Organizations.Inputs.GetIAMPolicyBindingInputArgs
            {
                Role = "roles/viewer",
                Members = new[]
                {
                    "user:jane@example.com",
                },
            },
        },
    });

    var policy = new Gcp.DataPlex.EntryGroupIamPolicy("policy", new()
    {
        Project = testEntryGroupBasic.Project,
        Location = testEntryGroupBasic.Location,
        EntryGroupId = testEntryGroupBasic.EntryGroupId,
        PolicyData = admin.Apply(getIAMPolicyResult => getIAMPolicyResult.PolicyData),
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/dataplex"
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/organizations"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		admin, err := organizations.LookupIAMPolicy(ctx, &organizations.LookupIAMPolicyArgs{
			Bindings: []organizations.GetIAMPolicyBinding{
				{
					Role: "roles/viewer",
					Members: []string{
						"user:jane@example.com",
					},
				},
			},
		}, nil)
		if err != nil {
			return err
		}
		_, err = dataplex.NewEntryGroupIamPolicy(ctx, "policy", &dataplex.EntryGroupIamPolicyArgs{
			Project:      pulumi.Any(testEntryGroupBasic.Project),
			Location:     pulumi.Any(testEntryGroupBasic.Location),
			EntryGroupId: pulumi.Any(testEntryGroupBasic.EntryGroupId),
			PolicyData:   pulumi.String(admin.PolicyData),
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.organizations.OrganizationsFunctions;
import com.pulumi.gcp.organizations.inputs.GetIAMPolicyArgs;
import com.pulumi.gcp.dataplex.EntryGroupIamPolicy;
import com.pulumi.gcp.dataplex.EntryGroupIamPolicyArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        final var admin = OrganizationsFunctions.getIAMPolicy(GetIAMPolicyArgs.builder()
            .bindings(GetIAMPolicyBindingArgs.builder()
                .role("roles/viewer")
                .members("user:jane@example.com")
                .build())
            .build());

        var policy = new EntryGroupIamPolicy("policy", EntryGroupIamPolicyArgs.builder()
            .project(testEntryGroupBasic.project())
            .location(testEntryGroupBasic.location())
            .entryGroupId(testEntryGroupBasic.entryGroupId())
            .policyData(admin.applyValue(getIAMPolicyResult -> getIAMPolicyResult.policyData()))
            .build());

    }
}
```
```yaml
resources:
  policy:
    type: gcp:dataplex:EntryGroupIamPolicy
    properties:
      project: ${testEntryGroupBasic.project}
      location: ${testEntryGroupBasic.location}
      entryGroupId: ${testEntryGroupBasic.entryGroupId}
      policyData: ${admin.policyData}
variables:
  admin:
    fn::invoke:
      function: gcp:organizations:getIAMPolicy
      arguments:
        bindings:
          - role: roles/viewer
            members:
              - user:jane@example.com
```
<!--End PulumiCodeChooser -->

## gcp.dataplex.EntryGroupIamBinding

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const binding = new gcp.dataplex.EntryGroupIamBinding("binding", {
    project: testEntryGroupBasic.project,
    location: testEntryGroupBasic.location,
    entryGroupId: testEntryGroupBasic.entryGroupId,
    role: "roles/viewer",
    members: ["user:jane@example.com"],
});
```
```python
import pulumi
import pulumi_gcp as gcp

binding = gcp.dataplex.EntryGroupIamBinding("binding",
    project=test_entry_group_basic["project"],
    location=test_entry_group_basic["location"],
    entry_group_id=test_entry_group_basic["entryGroupId"],
    role="roles/viewer",
    members=["user:jane@example.com"])
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var binding = new Gcp.DataPlex.EntryGroupIamBinding("binding", new()
    {
        Project = testEntryGroupBasic.Project,
        Location = testEntryGroupBasic.Location,
        EntryGroupId = testEntryGroupBasic.EntryGroupId,
        Role = "roles/viewer",
        Members = new[]
        {
            "user:jane@example.com",
        },
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/dataplex"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		_, err := dataplex.NewEntryGroupIamBinding(ctx, "binding", &dataplex.EntryGroupIamBindingArgs{
			Project:      pulumi.Any(testEntryGroupBasic.Project),
			Location:     pulumi.Any(testEntryGroupBasic.Location),
			EntryGroupId: pulumi.Any(testEntryGroupBasic.EntryGroupId),
			Role:         pulumi.String("roles/viewer"),
			Members: pulumi.StringArray{
				pulumi.String("user:jane@example.com"),
			},
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.dataplex.EntryGroupIamBinding;
import com.pulumi.gcp.dataplex.EntryGroupIamBindingArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        var binding = new EntryGroupIamBinding("binding", EntryGroupIamBindingArgs.builder()
            .project(testEntryGroupBasic.project())
            .location(testEntryGroupBasic.location())
            .entryGroupId(testEntryGroupBasic.entryGroupId())
            .role("roles/viewer")
            .members("user:jane@example.com")
            .build());

    }
}
```
```yaml
resources:
  binding:
    type: gcp:dataplex:EntryGroupIamBinding
    properties:
      project: ${testEntryGroupBasic.project}
      location: ${testEntryGroupBasic.location}
      entryGroupId: ${testEntryGroupBasic.entryGroupId}
      role: roles/viewer
      members:
        - user:jane@example.com
```
<!--End PulumiCodeChooser -->

## gcp.dataplex.EntryGroupIamMember

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const member = new gcp.dataplex.EntryGroupIamMember("member", {
    project: testEntryGroupBasic.project,
    location: testEntryGroupBasic.location,
    entryGroupId: testEntryGroupBasic.entryGroupId,
    role: "roles/viewer",
    member: "user:jane@example.com",
});
```
```python
import pulumi
import pulumi_gcp as gcp

member = gcp.dataplex.EntryGroupIamMember("member",
    project=test_entry_group_basic["project"],
    location=test_entry_group_basic["location"],
    entry_group_id=test_entry_group_basic["entryGroupId"],
    role="roles/viewer",
    member="user:jane@example.com")
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var member = new Gcp.DataPlex.EntryGroupIamMember("member", new()
    {
        Project = testEntryGroupBasic.Project,
        Location = testEntryGroupBasic.Location,
        EntryGroupId = testEntryGroupBasic.EntryGroupId,
        Role = "roles/viewer",
        Member = "user:jane@example.com",
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/dataplex"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		_, err := dataplex.NewEntryGroupIamMember(ctx, "member", &dataplex.EntryGroupIamMemberArgs{
			Project:      pulumi.Any(testEntryGroupBasic.Project),
			Location:     pulumi.Any(testEntryGroupBasic.Location),
			EntryGroupId: pulumi.Any(testEntryGroupBasic.EntryGroupId),
			Role:         pulumi.String("roles/viewer"),
			Member:       pulumi.String("user:jane@example.com"),
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.dataplex.EntryGroupIamMember;
import com.pulumi.gcp.dataplex.EntryGroupIamMemberArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        var member = new EntryGroupIamMember("member", EntryGroupIamMemberArgs.builder()
            .project(testEntryGroupBasic.project())
            .location(testEntryGroupBasic.location())
            .entryGroupId(testEntryGroupBasic.entryGroupId())
            .role("roles/viewer")
            .member("user:jane@example.com")
            .build());

    }
}
```
```yaml
resources:
  member:
    type: gcp:dataplex:EntryGroupIamMember
    properties:
      project: ${testEntryGroupBasic.project}
      location: ${testEntryGroupBasic.location}
      entryGroupId: ${testEntryGroupBasic.entryGroupId}
      role: roles/viewer
      member: user:jane@example.com
```
<!--End PulumiCodeChooser -->


## This resource supports User Project Overrides.

-

# IAM policy for Dataplex EntryGroup
Three different resources help you manage your IAM policy for Dataplex EntryGroup. Each of these resources serves a different use case:

* `gcp.dataplex.EntryGroupIamPolicy`: Authoritative. Sets the IAM policy for the entrygroup and replaces any existing policy already attached.
* `gcp.dataplex.EntryGroupIamBinding`: Authoritative for a given role. Updates the IAM policy to grant a role to a list of members. Other roles within the IAM policy for the entrygroup are preserved.
* `gcp.dataplex.EntryGroupIamMember`: Non-authoritative. Updates the IAM policy to grant a role to a new member. Other members for the role for the entrygroup are preserved.

A data source can be used to retrieve policy data in advent you do not need creation

* `gcp.dataplex.EntryGroupIamPolicy`: Retrieves the IAM policy for the entrygroup

> **Note:** `gcp.dataplex.EntryGroupIamPolicy` **cannot** be used in conjunction with `gcp.dataplex.EntryGroupIamBinding` and `gcp.dataplex.EntryGroupIamMember` or they will fight over what your policy should be.

> **Note:** `gcp.dataplex.EntryGroupIamBinding` resources **can be** used in conjunction with `gcp.dataplex.EntryGroupIamMember` resources **only if** they do not grant privilege to the same role.



## gcp.dataplex.EntryGroupIamPolicy

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const admin = gcp.organizations.getIAMPolicy({
    bindings: [{
        role: "roles/viewer",
        members: ["user:jane@example.com"],
    }],
});
const policy = new gcp.dataplex.EntryGroupIamPolicy("policy", {
    project: testEntryGroupBasic.project,
    location: testEntryGroupBasic.location,
    entryGroupId: testEntryGroupBasic.entryGroupId,
    policyData: admin.then(admin => admin.policyData),
});
```
```python
import pulumi
import pulumi_gcp as gcp

admin = gcp.organizations.get_iam_policy(bindings=[{
    "role": "roles/viewer",
    "members": ["user:jane@example.com"],
}])
policy = gcp.dataplex.EntryGroupIamPolicy("policy",
    project=test_entry_group_basic["project"],
    location=test_entry_group_basic["location"],
    entry_group_id=test_entry_group_basic["entryGroupId"],
    policy_data=admin.policy_data)
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var admin = Gcp.Organizations.GetIAMPolicy.Invoke(new()
    {
        Bindings = new[]
        {
            new Gcp.Organizations.Inputs.GetIAMPolicyBindingInputArgs
            {
                Role = "roles/viewer",
                Members = new[]
                {
                    "user:jane@example.com",
                },
            },
        },
    });

    var policy = new Gcp.DataPlex.EntryGroupIamPolicy("policy", new()
    {
        Project = testEntryGroupBasic.Project,
        Location = testEntryGroupBasic.Location,
        EntryGroupId = testEntryGroupBasic.EntryGroupId,
        PolicyData = admin.Apply(getIAMPolicyResult => getIAMPolicyResult.PolicyData),
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/dataplex"
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/organizations"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		admin, err := organizations.LookupIAMPolicy(ctx, &organizations.LookupIAMPolicyArgs{
			Bindings: []organizations.GetIAMPolicyBinding{
				{
					Role: "roles/viewer",
					Members: []string{
						"user:jane@example.com",
					},
				},
			},
		}, nil)
		if err != nil {
			return err
		}
		_, err = dataplex.NewEntryGroupIamPolicy(ctx, "policy", &dataplex.EntryGroupIamPolicyArgs{
			Project:      pulumi.Any(testEntryGroupBasic.Project),
			Location:     pulumi.Any(testEntryGroupBasic.Location),
			EntryGroupId: pulumi.Any(testEntryGroupBasic.EntryGroupId),
			PolicyData:   pulumi.String(admin.PolicyData),
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.organizations.OrganizationsFunctions;
import com.pulumi.gcp.organizations.inputs.GetIAMPolicyArgs;
import com.pulumi.gcp.dataplex.EntryGroupIamPolicy;
import com.pulumi.gcp.dataplex.EntryGroupIamPolicyArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        final var admin = OrganizationsFunctions.getIAMPolicy(GetIAMPolicyArgs.builder()
            .bindings(GetIAMPolicyBindingArgs.builder()
                .role("roles/viewer")
                .members("user:jane@example.com")
                .build())
            .build());

        var policy = new EntryGroupIamPolicy("policy", EntryGroupIamPolicyArgs.builder()
            .project(testEntryGroupBasic.project())
            .location(testEntryGroupBasic.location())
            .entryGroupId(testEntryGroupBasic.entryGroupId())
            .policyData(admin.applyValue(getIAMPolicyResult -> getIAMPolicyResult.policyData()))
            .build());

    }
}
```
```yaml
resources:
  policy:
    type: gcp:dataplex:EntryGroupIamPolicy
    properties:
      project: ${testEntryGroupBasic.project}
      location: ${testEntryGroupBasic.location}
      entryGroupId: ${testEntryGroupBasic.entryGroupId}
      policyData: ${admin.policyData}
variables:
  admin:
    fn::invoke:
      function: gcp:organizations:getIAMPolicy
      arguments:
        bindings:
          - role: roles/viewer
            members:
              - user:jane@example.com
```
<!--End PulumiCodeChooser -->

## gcp.dataplex.EntryGroupIamBinding

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const binding = new gcp.dataplex.EntryGroupIamBinding("binding", {
    project: testEntryGroupBasic.project,
    location: testEntryGroupBasic.location,
    entryGroupId: testEntryGroupBasic.entryGroupId,
    role: "roles/viewer",
    members: ["user:jane@example.com"],
});
```
```python
import pulumi
import pulumi_gcp as gcp

binding = gcp.dataplex.EntryGroupIamBinding("binding",
    project=test_entry_group_basic["project"],
    location=test_entry_group_basic["location"],
    entry_group_id=test_entry_group_basic["entryGroupId"],
    role="roles/viewer",
    members=["user:jane@example.com"])
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var binding = new Gcp.DataPlex.EntryGroupIamBinding("binding", new()
    {
        Project = testEntryGroupBasic.Project,
        Location = testEntryGroupBasic.Location,
        EntryGroupId = testEntryGroupBasic.EntryGroupId,
        Role = "roles/viewer",
        Members = new[]
        {
            "user:jane@example.com",
        },
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/dataplex"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		_, err := dataplex.NewEntryGroupIamBinding(ctx, "binding", &dataplex.EntryGroupIamBindingArgs{
			Project:      pulumi.Any(testEntryGroupBasic.Project),
			Location:     pulumi.Any(testEntryGroupBasic.Location),
			EntryGroupId: pulumi.Any(testEntryGroupBasic.EntryGroupId),
			Role:         pulumi.String("roles/viewer"),
			Members: pulumi.StringArray{
				pulumi.String("user:jane@example.com"),
			},
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.dataplex.EntryGroupIamBinding;
import com.pulumi.gcp.dataplex.EntryGroupIamBindingArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        var binding = new EntryGroupIamBinding("binding", EntryGroupIamBindingArgs.builder()
            .project(testEntryGroupBasic.project())
            .location(testEntryGroupBasic.location())
            .entryGroupId(testEntryGroupBasic.entryGroupId())
            .role("roles/viewer")
            .members("user:jane@example.com")
            .build());

    }
}
```
```yaml
resources:
  binding:
    type: gcp:dataplex:EntryGroupIamBinding
    properties:
      project: ${testEntryGroupBasic.project}
      location: ${testEntryGroupBasic.location}
      entryGroupId: ${testEntryGroupBasic.entryGroupId}
      role: roles/viewer
      members:
        - user:jane@example.com
```
<!--End PulumiCodeChooser -->

## gcp.dataplex.EntryGroupIamMember

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const member = new gcp.dataplex.EntryGroupIamMember("member", {
    project: testEntryGroupBasic.project,
    location: testEntryGroupBasic.location,
    entryGroupId: testEntryGroupBasic.entryGroupId,
    role: "roles/viewer",
    member: "user:jane@example.com",
});
```
```python
import pulumi
import pulumi_gcp as gcp

member = gcp.dataplex.EntryGroupIamMember("member",
    project=test_entry_group_basic["project"],
    location=test_entry_group_basic["location"],
    entry_group_id=test_entry_group_basic["entryGroupId"],
    role="roles/viewer",
    member="user:jane@example.com")
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var member = new Gcp.DataPlex.EntryGroupIamMember("member", new()
    {
        Project = testEntryGroupBasic.Project,
        Location = testEntryGroupBasic.Location,
        EntryGroupId = testEntryGroupBasic.EntryGroupId,
        Role = "roles/viewer",
        Member = "user:jane@example.com",
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/dataplex"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		_, err := dataplex.NewEntryGroupIamMember(ctx, "member", &dataplex.EntryGroupIamMemberArgs{
			Project:      pulumi.Any(testEntryGroupBasic.Project),
			Location:     pulumi.Any(testEntryGroupBasic.Location),
			EntryGroupId: pulumi.Any(testEntryGroupBasic.EntryGroupId),
			Role:         pulumi.String("roles/viewer"),
			Member:       pulumi.String("user:jane@example.com"),
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.dataplex.EntryGroupIamMember;
import com.pulumi.gcp.dataplex.EntryGroupIamMemberArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        var member = new EntryGroupIamMember("member", EntryGroupIamMemberArgs.builder()
            .project(testEntryGroupBasic.project())
            .location(testEntryGroupBasic.location())
            .entryGroupId(testEntryGroupBasic.entryGroupId())
            .role("roles/viewer")
            .member("user:jane@example.com")
            .build());

    }
}
```
```yaml
resources:
  member:
    type: gcp:dataplex:EntryGroupIamMember
    properties:
      project: ${testEntryGroupBasic.project}
      location: ${testEntryGroupBasic.location}
      entryGroupId: ${testEntryGroupBasic.entryGroupId}
      role: roles/viewer
      member: user:jane@example.com
```
<!--End PulumiCodeChooser -->

## Import

For all import syntaxes, the "resource in question" can take any of the following forms:

* projects/{{project}}/locations/{{location}}/entryGroups/{{entry_group_id}}

* {{project}}/{{location}}/{{entry_group_id}}

* {{location}}/{{entry_group_id}}

* {{entry_group_id}}

Any variables not passed in the import command will be taken from the provider configuration.

Dataplex entrygroup IAM resources can be imported using the resource identifiers, role, and member.

IAM member imports use space-delimited identifiers: the resource in question, the role, and the member identity, e.g.

```sh
$ pulumi import gcp:dataplex/entryGroupIamBinding:EntryGroupIamBinding editor "projects/{{project}}/locations/{{location}}/entryGroups/{{entry_group_id}} roles/viewer user:jane@example.com"
```

IAM binding imports use space-delimited identifiers: the resource in question and the role, e.g.

```sh
$ pulumi import gcp:dataplex/entryGroupIamBinding:EntryGroupIamBinding editor "projects/{{project}}/locations/{{location}}/entryGroups/{{entry_group_id}} roles/viewer"
```

IAM policy imports use the identifier of the resource in question, e.g.

```sh
$ pulumi import gcp:dataplex/entryGroupIamBinding:EntryGroupIamBinding editor projects/{{project}}/locations/{{location}}/entryGroups/{{entry_group_id}}
```

-> **Custom Roles** If you're importing a IAM resource with a custom role, make sure to use the

 full name of the custom role, e.g. `[projects/my-project|organizations/my-org]/roles/my-custom-role`.


	conditionyBw:u
s
dataplexEntryGroupIamBindingConditionHgcp:dataplex/EntryGroupIamBindingCondition:EntryGroupIamBindingCondition
entryGroupId" Ø
locationB" ÅThe location where entry group will be created in.
Used to find the parent resource to bind the IAM policy to. If not specified,
the value will be parsed from the identifier of the parent resource. If no location is provided in the parent identifier and no
location is specified, it is taken from the provider configuration.
Ö	
members*" Ä	Identities that will be granted the privilege in `role`.
Each entry can have one of the following values:
* **allUsers**: A special identifier that represents anyone who is on the internet; with or without a Google account.
* **allAuthenticatedUsers**: A special identifier that represents anyone who is authenticated with a Google account or a service account.
* **user:{emailid}**: An email address that represents a specific Google account. For example, alice@gmail.com or joe@example.com.
* **serviceAccount:{emailid}**: An email address that represents a service account. For example, my-other-app@appspot.gserviceaccount.com.
* **group:{emailid}**: An email address that represents a Google group. For example, admins@example.com.
* **domain:{domain}**: A G Suite domain (primary, instead of alias) name that represents all the users of that domain. For example, google.com or example.com.
* **projectOwner:projectid**: Owners of the given project. For example, "projectOwner:my-example-project"
* **projectEditor:projectid**: Editors of the given project. For example, "projectEditor:my-example-project"
* **projectViewer:projectid**: Viewers of the given project. For example, "projectViewer:my-example-project"

projectB" The ID of the project in which the resource belongs.
If it is not provided, the project will be parsed from the identifier of the parent resource. If no project is provided in the parent identifier and no project is specified, the provider project is used.
Ú
role" ÍThe role that should be applied. Only one
`gcp.dataplex.EntryGroupIamBinding` can be used per role. Note that custom roles must be of the format
`[projects|organizations]/{parent-name}/roles/{role-name}`.
"
	conditionyBw:u
s
dataplexEntryGroupIamBindingConditionHgcp:dataplex/EntryGroupIamBindingCondition:EntryGroupIamBindingCondition"
entryGroupId" "3
etag" '(Computed) The etag of the IAM policy.
"Ö
location" ÅThe location where entry group will be created in.
Used to find the parent resource to bind the IAM policy to. If not specified,
the value will be parsed from the identifier of the parent resource. If no location is provided in the parent identifier and no
location is specified, it is taken from the provider configuration.
"Ö	
members*" Ä	Identities that will be granted the privilege in `role`.
Each entry can have one of the following values:
* **allUsers**: A special identifier that represents anyone who is on the internet; with or without a Google account.
* **allAuthenticatedUsers**: A special identifier that represents anyone who is authenticated with a Google account or a service account.
* **user:{emailid}**: An email address that represents a specific Google account. For example, alice@gmail.com or joe@example.com.
* **serviceAccount:{emailid}**: An email address that represents a service account. For example, my-other-app@appspot.gserviceaccount.com.
* **group:{emailid}**: An email address that represents a Google group. For example, admins@example.com.
* **domain:{domain}**: A G Suite domain (primary, instead of alias) name that represents all the users of that domain. For example, google.com or example.com.
* **projectOwner:projectid**: Owners of the given project. For example, "projectOwner:my-example-project"
* **projectEditor:projectid**: Editors of the given project. For example, "projectEditor:my-example-project"
* **projectViewer:projectid**: Viewers of the given project. For example, "projectViewer:my-example-project"
"
project" The ID of the project in which the resource belongs.
If it is not provided, the project will be parsed from the identifier of the parent resource. If no project is provided in the parent identifier and no project is specified, the provider project is used.
"Ú
role" ÍThe role that should be applied. Only one
`gcp.dataplex.EntryGroupIamBinding` can be used per role. Note that custom roles must be of the format
`[projects|organizations]/{parent-name}/roles/{role-name}`.
*î
U
dataplexEntryGroupIamMember4gcp:dataplex/entryGroupIamMember:EntryGroupIamMemberÊThree different resources help you manage your IAM policy for Dataplex EntryGroup. Each of these resources serves a different use case:

* `gcp.dataplex.EntryGroupIamPolicy`: Authoritative. Sets the IAM policy for the entrygroup and replaces any existing policy already attached.
* `gcp.dataplex.EntryGroupIamBinding`: Authoritative for a given role. Updates the IAM policy to grant a role to a list of members. Other roles within the IAM policy for the entrygroup are preserved.
* `gcp.dataplex.EntryGroupIamMember`: Non-authoritative. Updates the IAM policy to grant a role to a new member. Other members for the role for the entrygroup are preserved.

A data source can be used to retrieve policy data in advent you do not need creation

* `gcp.dataplex.EntryGroupIamPolicy`: Retrieves the IAM policy for the entrygroup

> **Note:** `gcp.dataplex.EntryGroupIamPolicy` **cannot** be used in conjunction with `gcp.dataplex.EntryGroupIamBinding` and `gcp.dataplex.EntryGroupIamMember` or they will fight over what your policy should be.

> **Note:** `gcp.dataplex.EntryGroupIamBinding` resources **can be** used in conjunction with `gcp.dataplex.EntryGroupIamMember` resources **only if** they do not grant privilege to the same role.



## gcp.dataplex.EntryGroupIamPolicy

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const admin = gcp.organizations.getIAMPolicy({
    bindings: [{
        role: "roles/viewer",
        members: ["user:jane@example.com"],
    }],
});
const policy = new gcp.dataplex.EntryGroupIamPolicy("policy", {
    project: testEntryGroupBasic.project,
    location: testEntryGroupBasic.location,
    entryGroupId: testEntryGroupBasic.entryGroupId,
    policyData: admin.then(admin => admin.policyData),
});
```
```python
import pulumi
import pulumi_gcp as gcp

admin = gcp.organizations.get_iam_policy(bindings=[{
    "role": "roles/viewer",
    "members": ["user:jane@example.com"],
}])
policy = gcp.dataplex.EntryGroupIamPolicy("policy",
    project=test_entry_group_basic["project"],
    location=test_entry_group_basic["location"],
    entry_group_id=test_entry_group_basic["entryGroupId"],
    policy_data=admin.policy_data)
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var admin = Gcp.Organizations.GetIAMPolicy.Invoke(new()
    {
        Bindings = new[]
        {
            new Gcp.Organizations.Inputs.GetIAMPolicyBindingInputArgs
            {
                Role = "roles/viewer",
                Members = new[]
                {
                    "user:jane@example.com",
                },
            },
        },
    });

    var policy = new Gcp.DataPlex.EntryGroupIamPolicy("policy", new()
    {
        Project = testEntryGroupBasic.Project,
        Location = testEntryGroupBasic.Location,
        EntryGroupId = testEntryGroupBasic.EntryGroupId,
        PolicyData = admin.Apply(getIAMPolicyResult => getIAMPolicyResult.PolicyData),
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/dataplex"
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/organizations"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		admin, err := organizations.LookupIAMPolicy(ctx, &organizations.LookupIAMPolicyArgs{
			Bindings: []organizations.GetIAMPolicyBinding{
				{
					Role: "roles/viewer",
					Members: []string{
						"user:jane@example.com",
					},
				},
			},
		}, nil)
		if err != nil {
			return err
		}
		_, err = dataplex.NewEntryGroupIamPolicy(ctx, "policy", &dataplex.EntryGroupIamPolicyArgs{
			Project:      pulumi.Any(testEntryGroupBasic.Project),
			Location:     pulumi.Any(testEntryGroupBasic.Location),
			EntryGroupId: pulumi.Any(testEntryGroupBasic.EntryGroupId),
			PolicyData:   pulumi.String(admin.PolicyData),
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.organizations.OrganizationsFunctions;
import com.pulumi.gcp.organizations.inputs.GetIAMPolicyArgs;
import com.pulumi.gcp.dataplex.EntryGroupIamPolicy;
import com.pulumi.gcp.dataplex.EntryGroupIamPolicyArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        final var admin = OrganizationsFunctions.getIAMPolicy(GetIAMPolicyArgs.builder()
            .bindings(GetIAMPolicyBindingArgs.builder()
                .role("roles/viewer")
                .members("user:jane@example.com")
                .build())
            .build());

        var policy = new EntryGroupIamPolicy("policy", EntryGroupIamPolicyArgs.builder()
            .project(testEntryGroupBasic.project())
            .location(testEntryGroupBasic.location())
            .entryGroupId(testEntryGroupBasic.entryGroupId())
            .policyData(admin.applyValue(getIAMPolicyResult -> getIAMPolicyResult.policyData()))
            .build());

    }
}
```
```yaml
resources:
  policy:
    type: gcp:dataplex:EntryGroupIamPolicy
    properties:
      project: ${testEntryGroupBasic.project}
      location: ${testEntryGroupBasic.location}
      entryGroupId: ${testEntryGroupBasic.entryGroupId}
      policyData: ${admin.policyData}
variables:
  admin:
    fn::invoke:
      function: gcp:organizations:getIAMPolicy
      arguments:
        bindings:
          - role: roles/viewer
            members:
              - user:jane@example.com
```
<!--End PulumiCodeChooser -->

## gcp.dataplex.EntryGroupIamBinding

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const binding = new gcp.dataplex.EntryGroupIamBinding("binding", {
    project: testEntryGroupBasic.project,
    location: testEntryGroupBasic.location,
    entryGroupId: testEntryGroupBasic.entryGroupId,
    role: "roles/viewer",
    members: ["user:jane@example.com"],
});
```
```python
import pulumi
import pulumi_gcp as gcp

binding = gcp.dataplex.EntryGroupIamBinding("binding",
    project=test_entry_group_basic["project"],
    location=test_entry_group_basic["location"],
    entry_group_id=test_entry_group_basic["entryGroupId"],
    role="roles/viewer",
    members=["user:jane@example.com"])
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var binding = new Gcp.DataPlex.EntryGroupIamBinding("binding", new()
    {
        Project = testEntryGroupBasic.Project,
        Location = testEntryGroupBasic.Location,
        EntryGroupId = testEntryGroupBasic.EntryGroupId,
        Role = "roles/viewer",
        Members = new[]
        {
            "user:jane@example.com",
        },
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/dataplex"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		_, err := dataplex.NewEntryGroupIamBinding(ctx, "binding", &dataplex.EntryGroupIamBindingArgs{
			Project:      pulumi.Any(testEntryGroupBasic.Project),
			Location:     pulumi.Any(testEntryGroupBasic.Location),
			EntryGroupId: pulumi.Any(testEntryGroupBasic.EntryGroupId),
			Role:         pulumi.String("roles/viewer"),
			Members: pulumi.StringArray{
				pulumi.String("user:jane@example.com"),
			},
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.dataplex.EntryGroupIamBinding;
import com.pulumi.gcp.dataplex.EntryGroupIamBindingArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        var binding = new EntryGroupIamBinding("binding", EntryGroupIamBindingArgs.builder()
            .project(testEntryGroupBasic.project())
            .location(testEntryGroupBasic.location())
            .entryGroupId(testEntryGroupBasic.entryGroupId())
            .role("roles/viewer")
            .members("user:jane@example.com")
            .build());

    }
}
```
```yaml
resources:
  binding:
    type: gcp:dataplex:EntryGroupIamBinding
    properties:
      project: ${testEntryGroupBasic.project}
      location: ${testEntryGroupBasic.location}
      entryGroupId: ${testEntryGroupBasic.entryGroupId}
      role: roles/viewer
      members:
        - user:jane@example.com
```
<!--End PulumiCodeChooser -->

## gcp.dataplex.EntryGroupIamMember

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const member = new gcp.dataplex.EntryGroupIamMember("member", {
    project: testEntryGroupBasic.project,
    location: testEntryGroupBasic.location,
    entryGroupId: testEntryGroupBasic.entryGroupId,
    role: "roles/viewer",
    member: "user:jane@example.com",
});
```
```python
import pulumi
import pulumi_gcp as gcp

member = gcp.dataplex.EntryGroupIamMember("member",
    project=test_entry_group_basic["project"],
    location=test_entry_group_basic["location"],
    entry_group_id=test_entry_group_basic["entryGroupId"],
    role="roles/viewer",
    member="user:jane@example.com")
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var member = new Gcp.DataPlex.EntryGroupIamMember("member", new()
    {
        Project = testEntryGroupBasic.Project,
        Location = testEntryGroupBasic.Location,
        EntryGroupId = testEntryGroupBasic.EntryGroupId,
        Role = "roles/viewer",
        Member = "user:jane@example.com",
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/dataplex"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		_, err := dataplex.NewEntryGroupIamMember(ctx, "member", &dataplex.EntryGroupIamMemberArgs{
			Project:      pulumi.Any(testEntryGroupBasic.Project),
			Location:     pulumi.Any(testEntryGroupBasic.Location),
			EntryGroupId: pulumi.Any(testEntryGroupBasic.EntryGroupId),
			Role:         pulumi.String("roles/viewer"),
			Member:       pulumi.String("user:jane@example.com"),
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.dataplex.EntryGroupIamMember;
import com.pulumi.gcp.dataplex.EntryGroupIamMemberArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        var member = new EntryGroupIamMember("member", EntryGroupIamMemberArgs.builder()
            .project(testEntryGroupBasic.project())
            .location(testEntryGroupBasic.location())
            .entryGroupId(testEntryGroupBasic.entryGroupId())
            .role("roles/viewer")
            .member("user:jane@example.com")
            .build());

    }
}
```
```yaml
resources:
  member:
    type: gcp:dataplex:EntryGroupIamMember
    properties:
      project: ${testEntryGroupBasic.project}
      location: ${testEntryGroupBasic.location}
      entryGroupId: ${testEntryGroupBasic.entryGroupId}
      role: roles/viewer
      member: user:jane@example.com
```
<!--End PulumiCodeChooser -->


## This resource supports User Project Overrides.

-

# IAM policy for Dataplex EntryGroup
Three different resources help you manage your IAM policy for Dataplex EntryGroup. Each of these resources serves a different use case:

* `gcp.dataplex.EntryGroupIamPolicy`: Authoritative. Sets the IAM policy for the entrygroup and replaces any existing policy already attached.
* `gcp.dataplex.EntryGroupIamBinding`: Authoritative for a given role. Updates the IAM policy to grant a role to a list of members. Other roles within the IAM policy for the entrygroup are preserved.
* `gcp.dataplex.EntryGroupIamMember`: Non-authoritative. Updates the IAM policy to grant a role to a new member. Other members for the role for the entrygroup are preserved.

A data source can be used to retrieve policy data in advent you do not need creation

* `gcp.dataplex.EntryGroupIamPolicy`: Retrieves the IAM policy for the entrygroup

> **Note:** `gcp.dataplex.EntryGroupIamPolicy` **cannot** be used in conjunction with `gcp.dataplex.EntryGroupIamBinding` and `gcp.dataplex.EntryGroupIamMember` or they will fight over what your policy should be.

> **Note:** `gcp.dataplex.EntryGroupIamBinding` resources **can be** used in conjunction with `gcp.dataplex.EntryGroupIamMember` resources **only if** they do not grant privilege to the same role.



## gcp.dataplex.EntryGroupIamPolicy

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const admin = gcp.organizations.getIAMPolicy({
    bindings: [{
        role: "roles/viewer",
        members: ["user:jane@example.com"],
    }],
});
const policy = new gcp.dataplex.EntryGroupIamPolicy("policy", {
    project: testEntryGroupBasic.project,
    location: testEntryGroupBasic.location,
    entryGroupId: testEntryGroupBasic.entryGroupId,
    policyData: admin.then(admin => admin.policyData),
});
```
```python
import pulumi
import pulumi_gcp as gcp

admin = gcp.organizations.get_iam_policy(bindings=[{
    "role": "roles/viewer",
    "members": ["user:jane@example.com"],
}])
policy = gcp.dataplex.EntryGroupIamPolicy("policy",
    project=test_entry_group_basic["project"],
    location=test_entry_group_basic["location"],
    entry_group_id=test_entry_group_basic["entryGroupId"],
    policy_data=admin.policy_data)
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var admin = Gcp.Organizations.GetIAMPolicy.Invoke(new()
    {
        Bindings = new[]
        {
            new Gcp.Organizations.Inputs.GetIAMPolicyBindingInputArgs
            {
                Role = "roles/viewer",
                Members = new[]
                {
                    "user:jane@example.com",
                },
            },
        },
    });

    var policy = new Gcp.DataPlex.EntryGroupIamPolicy("policy", new()
    {
        Project = testEntryGroupBasic.Project,
        Location = testEntryGroupBasic.Location,
        EntryGroupId = testEntryGroupBasic.EntryGroupId,
        PolicyData = admin.Apply(getIAMPolicyResult => getIAMPolicyResult.PolicyData),
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/dataplex"
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/organizations"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		admin, err := organizations.LookupIAMPolicy(ctx, &organizations.LookupIAMPolicyArgs{
			Bindings: []organizations.GetIAMPolicyBinding{
				{
					Role: "roles/viewer",
					Members: []string{
						"user:jane@example.com",
					},
				},
			},
		}, nil)
		if err != nil {
			return err
		}
		_, err = dataplex.NewEntryGroupIamPolicy(ctx, "policy", &dataplex.EntryGroupIamPolicyArgs{
			Project:      pulumi.Any(testEntryGroupBasic.Project),
			Location:     pulumi.Any(testEntryGroupBasic.Location),
			EntryGroupId: pulumi.Any(testEntryGroupBasic.EntryGroupId),
			PolicyData:   pulumi.String(admin.PolicyData),
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.organizations.OrganizationsFunctions;
import com.pulumi.gcp.organizations.inputs.GetIAMPolicyArgs;
import com.pulumi.gcp.dataplex.EntryGroupIamPolicy;
import com.pulumi.gcp.dataplex.EntryGroupIamPolicyArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        final var admin = OrganizationsFunctions.getIAMPolicy(GetIAMPolicyArgs.builder()
            .bindings(GetIAMPolicyBindingArgs.builder()
                .role("roles/viewer")
                .members("user:jane@example.com")
                .build())
            .build());

        var policy = new EntryGroupIamPolicy("policy", EntryGroupIamPolicyArgs.builder()
            .project(testEntryGroupBasic.project())
            .location(testEntryGroupBasic.location())
            .entryGroupId(testEntryGroupBasic.entryGroupId())
            .policyData(admin.applyValue(getIAMPolicyResult -> getIAMPolicyResult.policyData()))
            .build());

    }
}
```
```yaml
resources:
  policy:
    type: gcp:dataplex:EntryGroupIamPolicy
    properties:
      project: ${testEntryGroupBasic.project}
      location: ${testEntryGroupBasic.location}
      entryGroupId: ${testEntryGroupBasic.entryGroupId}
      policyData: ${admin.policyData}
variables:
  admin:
    fn::invoke:
      function: gcp:organizations:getIAMPolicy
      arguments:
        bindings:
          - role: roles/viewer
            members:
              - user:jane@example.com
```
<!--End PulumiCodeChooser -->

## gcp.dataplex.EntryGroupIamBinding

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const binding = new gcp.dataplex.EntryGroupIamBinding("binding", {
    project: testEntryGroupBasic.project,
    location: testEntryGroupBasic.location,
    entryGroupId: testEntryGroupBasic.entryGroupId,
    role: "roles/viewer",
    members: ["user:jane@example.com"],
});
```
```python
import pulumi
import pulumi_gcp as gcp

binding = gcp.dataplex.EntryGroupIamBinding("binding",
    project=test_entry_group_basic["project"],
    location=test_entry_group_basic["location"],
    entry_group_id=test_entry_group_basic["entryGroupId"],
    role="roles/viewer",
    members=["user:jane@example.com"])
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var binding = new Gcp.DataPlex.EntryGroupIamBinding("binding", new()
    {
        Project = testEntryGroupBasic.Project,
        Location = testEntryGroupBasic.Location,
        EntryGroupId = testEntryGroupBasic.EntryGroupId,
        Role = "roles/viewer",
        Members = new[]
        {
            "user:jane@example.com",
        },
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/dataplex"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		_, err := dataplex.NewEntryGroupIamBinding(ctx, "binding", &dataplex.EntryGroupIamBindingArgs{
			Project:      pulumi.Any(testEntryGroupBasic.Project),
			Location:     pulumi.Any(testEntryGroupBasic.Location),
			EntryGroupId: pulumi.Any(testEntryGroupBasic.EntryGroupId),
			Role:         pulumi.String("roles/viewer"),
			Members: pulumi.StringArray{
				pulumi.String("user:jane@example.com"),
			},
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.dataplex.EntryGroupIamBinding;
import com.pulumi.gcp.dataplex.EntryGroupIamBindingArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        var binding = new EntryGroupIamBinding("binding", EntryGroupIamBindingArgs.builder()
            .project(testEntryGroupBasic.project())
            .location(testEntryGroupBasic.location())
            .entryGroupId(testEntryGroupBasic.entryGroupId())
            .role("roles/viewer")
            .members("user:jane@example.com")
            .build());

    }
}
```
```yaml
resources:
  binding:
    type: gcp:dataplex:EntryGroupIamBinding
    properties:
      project: ${testEntryGroupBasic.project}
      location: ${testEntryGroupBasic.location}
      entryGroupId: ${testEntryGroupBasic.entryGroupId}
      role: roles/viewer
      members:
        - user:jane@example.com
```
<!--End PulumiCodeChooser -->

## gcp.dataplex.EntryGroupIamMember

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const member = new gcp.dataplex.EntryGroupIamMember("member", {
    project: testEntryGroupBasic.project,
    location: testEntryGroupBasic.location,
    entryGroupId: testEntryGroupBasic.entryGroupId,
    role: "roles/viewer",
    member: "user:jane@example.com",
});
```
```python
import pulumi
import pulumi_gcp as gcp

member = gcp.dataplex.EntryGroupIamMember("member",
    project=test_entry_group_basic["project"],
    location=test_entry_group_basic["location"],
    entry_group_id=test_entry_group_basic["entryGroupId"],
    role="roles/viewer",
    member="user:jane@example.com")
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var member = new Gcp.DataPlex.EntryGroupIamMember("member", new()
    {
        Project = testEntryGroupBasic.Project,
        Location = testEntryGroupBasic.Location,
        EntryGroupId = testEntryGroupBasic.EntryGroupId,
        Role = "roles/viewer",
        Member = "user:jane@example.com",
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/dataplex"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		_, err := dataplex.NewEntryGroupIamMember(ctx, "member", &dataplex.EntryGroupIamMemberArgs{
			Project:      pulumi.Any(testEntryGroupBasic.Project),
			Location:     pulumi.Any(testEntryGroupBasic.Location),
			EntryGroupId: pulumi.Any(testEntryGroupBasic.EntryGroupId),
			Role:         pulumi.String("roles/viewer"),
			Member:       pulumi.String("user:jane@example.com"),
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.dataplex.EntryGroupIamMember;
import com.pulumi.gcp.dataplex.EntryGroupIamMemberArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        var member = new EntryGroupIamMember("member", EntryGroupIamMemberArgs.builder()
            .project(testEntryGroupBasic.project())
            .location(testEntryGroupBasic.location())
            .entryGroupId(testEntryGroupBasic.entryGroupId())
            .role("roles/viewer")
            .member("user:jane@example.com")
            .build());

    }
}
```
```yaml
resources:
  member:
    type: gcp:dataplex:EntryGroupIamMember
    properties:
      project: ${testEntryGroupBasic.project}
      location: ${testEntryGroupBasic.location}
      entryGroupId: ${testEntryGroupBasic.entryGroupId}
      role: roles/viewer
      member: user:jane@example.com
```
<!--End PulumiCodeChooser -->

## Import

For all import syntaxes, the "resource in question" can take any of the following forms:

* projects/{{project}}/locations/{{location}}/entryGroups/{{entry_group_id}}

* {{project}}/{{location}}/{{entry_group_id}}

* {{location}}/{{entry_group_id}}

* {{entry_group_id}}

Any variables not passed in the import command will be taken from the provider configuration.

Dataplex entrygroup IAM resources can be imported using the resource identifiers, role, and member.

IAM member imports use space-delimited identifiers: the resource in question, the role, and the member identity, e.g.

```sh
$ pulumi import gcp:dataplex/entryGroupIamMember:EntryGroupIamMember editor "projects/{{project}}/locations/{{location}}/entryGroups/{{entry_group_id}} roles/viewer user:jane@example.com"
```

IAM binding imports use space-delimited identifiers: the resource in question and the role, e.g.

```sh
$ pulumi import gcp:dataplex/entryGroupIamMember:EntryGroupIamMember editor "projects/{{project}}/locations/{{location}}/entryGroups/{{entry_group_id}} roles/viewer"
```

IAM policy imports use the identifier of the resource in question, e.g.

```sh
$ pulumi import gcp:dataplex/entryGroupIamMember:EntryGroupIamMember editor projects/{{project}}/locations/{{location}}/entryGroups/{{entry_group_id}}
```

-> **Custom Roles** If you're importing a IAM resource with a custom role, make sure to use the

 full name of the custom role, e.g. `[projects/my-project|organizations/my-org]/roles/my-custom-role`.


	conditionvBt:r
p
dataplexEntryGroupIamMemberConditionFgcp:dataplex/EntryGroupIamMemberCondition:EntryGroupIamMemberCondition
entryGroupId" Ø
locationB" ÅThe location where entry group will be created in.
Used to find the parent resource to bind the IAM policy to. If not specified,
the value will be parsed from the identifier of the parent resource. If no location is provided in the parent identifier and no
location is specified, it is taken from the provider configuration.
Ó	
member" Ä	Identities that will be granted the privilege in `role`.
Each entry can have one of the following values:
* **allUsers**: A special identifier that represents anyone who is on the internet; with or without a Google account.
* **allAuthenticatedUsers**: A special identifier that represents anyone who is authenticated with a Google account or a service account.
* **user:{emailid}**: An email address that represents a specific Google account. For example, alice@gmail.com or joe@example.com.
* **serviceAccount:{emailid}**: An email address that represents a service account. For example, my-other-app@appspot.gserviceaccount.com.
* **group:{emailid}**: An email address that represents a Google group. For example, admins@example.com.
* **domain:{domain}**: A G Suite domain (primary, instead of alias) name that represents all the users of that domain. For example, google.com or example.com.
* **projectOwner:projectid**: Owners of the given project. For example, "projectOwner:my-example-project"
* **projectEditor:projectid**: Editors of the given project. For example, "projectEditor:my-example-project"
* **projectViewer:projectid**: Viewers of the given project. For example, "projectViewer:my-example-project"

projectB" The ID of the project in which the resource belongs.
If it is not provided, the project will be parsed from the identifier of the parent resource. If no project is provided in the parent identifier and no project is specified, the provider project is used.
Ú
role" ÍThe role that should be applied. Only one
`gcp.dataplex.EntryGroupIamBinding` can be used per role. Note that custom roles must be of the format
`[projects|organizations]/{parent-name}/roles/{role-name}`.
"
	conditionvBt:r
p
dataplexEntryGroupIamMemberConditionFgcp:dataplex/EntryGroupIamMemberCondition:EntryGroupIamMemberCondition"
entryGroupId" "3
etag" '(Computed) The etag of the IAM policy.
"Ö
location" ÅThe location where entry group will be created in.
Used to find the parent resource to bind the IAM policy to. If not specified,
the value will be parsed from the identifier of the parent resource. If no location is provided in the parent identifier and no
location is specified, it is taken from the provider configuration.
"Ó	
member" Ä	Identities that will be granted the privilege in `role`.
Each entry can have one of the following values:
* **allUsers**: A special identifier that represents anyone who is on the internet; with or without a Google account.
* **allAuthenticatedUsers**: A special identifier that represents anyone who is authenticated with a Google account or a service account.
* **user:{emailid}**: An email address that represents a specific Google account. For example, alice@gmail.com or joe@example.com.
* **serviceAccount:{emailid}**: An email address that represents a service account. For example, my-other-app@appspot.gserviceaccount.com.
* **group:{emailid}**: An email address that represents a Google group. For example, admins@example.com.
* **domain:{domain}**: A G Suite domain (primary, instead of alias) name that represents all the users of that domain. For example, google.com or example.com.
* **projectOwner:projectid**: Owners of the given project. For example, "projectOwner:my-example-project"
* **projectEditor:projectid**: Editors of the given project. For example, "projectEditor:my-example-project"
* **projectViewer:projectid**: Viewers of the given project. For example, "projectViewer:my-example-project"
"
project" The ID of the project in which the resource belongs.
If it is not provided, the project will be parsed from the identifier of the parent resource. If no project is provided in the parent identifier and no project is specified, the provider project is used.
"Ú
role" ÍThe role that should be applied. Only one
`gcp.dataplex.EntryGroupIamBinding` can be used per role. Note that custom roles must be of the format
`[projects|organizations]/{parent-name}/roles/{role-name}`.
*èÖ
U
dataplexEntryGroupIamPolicy4gcp:dataplex/entryGroupIamPolicy:EntryGroupIamPolicyÊThree different resources help you manage your IAM policy for Dataplex EntryGroup. Each of these resources serves a different use case:

* `gcp.dataplex.EntryGroupIamPolicy`: Authoritative. Sets the IAM policy for the entrygroup and replaces any existing policy already attached.
* `gcp.dataplex.EntryGroupIamBinding`: Authoritative for a given role. Updates the IAM policy to grant a role to a list of members. Other roles within the IAM policy for the entrygroup are preserved.
* `gcp.dataplex.EntryGroupIamMember`: Non-authoritative. Updates the IAM policy to grant a role to a new member. Other members for the role for the entrygroup are preserved.

A data source can be used to retrieve policy data in advent you do not need creation

* `gcp.dataplex.EntryGroupIamPolicy`: Retrieves the IAM policy for the entrygroup

> **Note:** `gcp.dataplex.EntryGroupIamPolicy` **cannot** be used in conjunction with `gcp.dataplex.EntryGroupIamBinding` and `gcp.dataplex.EntryGroupIamMember` or they will fight over what your policy should be.

> **Note:** `gcp.dataplex.EntryGroupIamBinding` resources **can be** used in conjunction with `gcp.dataplex.EntryGroupIamMember` resources **only if** they do not grant privilege to the same role.



## gcp.dataplex.EntryGroupIamPolicy

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const admin = gcp.organizations.getIAMPolicy({
    bindings: [{
        role: "roles/viewer",
        members: ["user:jane@example.com"],
    }],
});
const policy = new gcp.dataplex.EntryGroupIamPolicy("policy", {
    project: testEntryGroupBasic.project,
    location: testEntryGroupBasic.location,
    entryGroupId: testEntryGroupBasic.entryGroupId,
    policyData: admin.then(admin => admin.policyData),
});
```
```python
import pulumi
import pulumi_gcp as gcp

admin = gcp.organizations.get_iam_policy(bindings=[{
    "role": "roles/viewer",
    "members": ["user:jane@example.com"],
}])
policy = gcp.dataplex.EntryGroupIamPolicy("policy",
    project=test_entry_group_basic["project"],
    location=test_entry_group_basic["location"],
    entry_group_id=test_entry_group_basic["entryGroupId"],
    policy_data=admin.policy_data)
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var admin = Gcp.Organizations.GetIAMPolicy.Invoke(new()
    {
        Bindings = new[]
        {
            new Gcp.Organizations.Inputs.GetIAMPolicyBindingInputArgs
            {
                Role = "roles/viewer",
                Members = new[]
                {
                    "user:jane@example.com",
                },
            },
        },
    });

    var policy = new Gcp.DataPlex.EntryGroupIamPolicy("policy", new()
    {
        Project = testEntryGroupBasic.Project,
        Location = testEntryGroupBasic.Location,
        EntryGroupId = testEntryGroupBasic.EntryGroupId,
        PolicyData = admin.Apply(getIAMPolicyResult => getIAMPolicyResult.PolicyData),
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/dataplex"
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/organizations"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		admin, err := organizations.LookupIAMPolicy(ctx, &organizations.LookupIAMPolicyArgs{
			Bindings: []organizations.GetIAMPolicyBinding{
				{
					Role: "roles/viewer",
					Members: []string{
						"user:jane@example.com",
					},
				},
			},
		}, nil)
		if err != nil {
			return err
		}
		_, err = dataplex.NewEntryGroupIamPolicy(ctx, "policy", &dataplex.EntryGroupIamPolicyArgs{
			Project:      pulumi.Any(testEntryGroupBasic.Project),
			Location:     pulumi.Any(testEntryGroupBasic.Location),
			EntryGroupId: pulumi.Any(testEntryGroupBasic.EntryGroupId),
			PolicyData:   pulumi.String(admin.PolicyData),
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.organizations.OrganizationsFunctions;
import com.pulumi.gcp.organizations.inputs.GetIAMPolicyArgs;
import com.pulumi.gcp.dataplex.EntryGroupIamPolicy;
import com.pulumi.gcp.dataplex.EntryGroupIamPolicyArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        final var admin = OrganizationsFunctions.getIAMPolicy(GetIAMPolicyArgs.builder()
            .bindings(GetIAMPolicyBindingArgs.builder()
                .role("roles/viewer")
                .members("user:jane@example.com")
                .build())
            .build());

        var policy = new EntryGroupIamPolicy("policy", EntryGroupIamPolicyArgs.builder()
            .project(testEntryGroupBasic.project())
            .location(testEntryGroupBasic.location())
            .entryGroupId(testEntryGroupBasic.entryGroupId())
            .policyData(admin.applyValue(getIAMPolicyResult -> getIAMPolicyResult.policyData()))
            .build());

    }
}
```
```yaml
resources:
  policy:
    type: gcp:dataplex:EntryGroupIamPolicy
    properties:
      project: ${testEntryGroupBasic.project}
      location: ${testEntryGroupBasic.location}
      entryGroupId: ${testEntryGroupBasic.entryGroupId}
      policyData: ${admin.policyData}
variables:
  admin:
    fn::invoke:
      function: gcp:organizations:getIAMPolicy
      arguments:
        bindings:
          - role: roles/viewer
            members:
              - user:jane@example.com
```
<!--End PulumiCodeChooser -->

## gcp.dataplex.EntryGroupIamBinding

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const binding = new gcp.dataplex.EntryGroupIamBinding("binding", {
    project: testEntryGroupBasic.project,
    location: testEntryGroupBasic.location,
    entryGroupId: testEntryGroupBasic.entryGroupId,
    role: "roles/viewer",
    members: ["user:jane@example.com"],
});
```
```python
import pulumi
import pulumi_gcp as gcp

binding = gcp.dataplex.EntryGroupIamBinding("binding",
    project=test_entry_group_basic["project"],
    location=test_entry_group_basic["location"],
    entry_group_id=test_entry_group_basic["entryGroupId"],
    role="roles/viewer",
    members=["user:jane@example.com"])
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var binding = new Gcp.DataPlex.EntryGroupIamBinding("binding", new()
    {
        Project = testEntryGroupBasic.Project,
        Location = testEntryGroupBasic.Location,
        EntryGroupId = testEntryGroupBasic.EntryGroupId,
        Role = "roles/viewer",
        Members = new[]
        {
            "user:jane@example.com",
        },
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/dataplex"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		_, err := dataplex.NewEntryGroupIamBinding(ctx, "binding", &dataplex.EntryGroupIamBindingArgs{
			Project:      pulumi.Any(testEntryGroupBasic.Project),
			Location:     pulumi.Any(testEntryGroupBasic.Location),
			EntryGroupId: pulumi.Any(testEntryGroupBasic.EntryGroupId),
			Role:         pulumi.String("roles/viewer"),
			Members: pulumi.StringArray{
				pulumi.String("user:jane@example.com"),
			},
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.dataplex.EntryGroupIamBinding;
import com.pulumi.gcp.dataplex.EntryGroupIamBindingArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        var binding = new EntryGroupIamBinding("binding", EntryGroupIamBindingArgs.builder()
            .project(testEntryGroupBasic.project())
            .location(testEntryGroupBasic.location())
            .entryGroupId(testEntryGroupBasic.entryGroupId())
            .role("roles/viewer")
            .members("user:jane@example.com")
            .build());

    }
}
```
```yaml
resources:
  binding:
    type: gcp:dataplex:EntryGroupIamBinding
    properties:
      project: ${testEntryGroupBasic.project}
      location: ${testEntryGroupBasic.location}
      entryGroupId: ${testEntryGroupBasic.entryGroupId}
      role: roles/viewer
      members:
        - user:jane@example.com
```
<!--End PulumiCodeChooser -->

## gcp.dataplex.EntryGroupIamMember

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const member = new gcp.dataplex.EntryGroupIamMember("member", {
    project: testEntryGroupBasic.project,
    location: testEntryGroupBasic.location,
    entryGroupId: testEntryGroupBasic.entryGroupId,
    role: "roles/viewer",
    member: "user:jane@example.com",
});
```
```python
import pulumi
import pulumi_gcp as gcp

member = gcp.dataplex.EntryGroupIamMember("member",
    project=test_entry_group_basic["project"],
    location=test_entry_group_basic["location"],
    entry_group_id=test_entry_group_basic["entryGroupId"],
    role="roles/viewer",
    member="user:jane@example.com")
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var member = new Gcp.DataPlex.EntryGroupIamMember("member", new()
    {
        Project = testEntryGroupBasic.Project,
        Location = testEntryGroupBasic.Location,
        EntryGroupId = testEntryGroupBasic.EntryGroupId,
        Role = "roles/viewer",
        Member = "user:jane@example.com",
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/dataplex"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		_, err := dataplex.NewEntryGroupIamMember(ctx, "member", &dataplex.EntryGroupIamMemberArgs{
			Project:      pulumi.Any(testEntryGroupBasic.Project),
			Location:     pulumi.Any(testEntryGroupBasic.Location),
			EntryGroupId: pulumi.Any(testEntryGroupBasic.EntryGroupId),
			Role:         pulumi.String("roles/viewer"),
			Member:       pulumi.String("user:jane@example.com"),
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.dataplex.EntryGroupIamMember;
import com.pulumi.gcp.dataplex.EntryGroupIamMemberArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        var member = new EntryGroupIamMember("member", EntryGroupIamMemberArgs.builder()
            .project(testEntryGroupBasic.project())
            .location(testEntryGroupBasic.location())
            .entryGroupId(testEntryGroupBasic.entryGroupId())
            .role("roles/viewer")
            .member("user:jane@example.com")
            .build());

    }
}
```
```yaml
resources:
  member:
    type: gcp:dataplex:EntryGroupIamMember
    properties:
      project: ${testEntryGroupBasic.project}
      location: ${testEntryGroupBasic.location}
      entryGroupId: ${testEntryGroupBasic.entryGroupId}
      role: roles/viewer
      member: user:jane@example.com
```
<!--End PulumiCodeChooser -->


## This resource supports User Project Overrides.

-

# IAM policy for Dataplex EntryGroup
Three different resources help you manage your IAM policy for Dataplex EntryGroup. Each of these resources serves a different use case:

* `gcp.dataplex.EntryGroupIamPolicy`: Authoritative. Sets the IAM policy for the entrygroup and replaces any existing policy already attached.
* `gcp.dataplex.EntryGroupIamBinding`: Authoritative for a given role. Updates the IAM policy to grant a role to a list of members. Other roles within the IAM policy for the entrygroup are preserved.
* `gcp.dataplex.EntryGroupIamMember`: Non-authoritative. Updates the IAM policy to grant a role to a new member. Other members for the role for the entrygroup are preserved.

A data source can be used to retrieve policy data in advent you do not need creation

* `gcp.dataplex.EntryGroupIamPolicy`: Retrieves the IAM policy for the entrygroup

> **Note:** `gcp.dataplex.EntryGroupIamPolicy` **cannot** be used in conjunction with `gcp.dataplex.EntryGroupIamBinding` and `gcp.dataplex.EntryGroupIamMember` or they will fight over what your policy should be.

> **Note:** `gcp.dataplex.EntryGroupIamBinding` resources **can be** used in conjunction with `gcp.dataplex.EntryGroupIamMember` resources **only if** they do not grant privilege to the same role.



## gcp.dataplex.EntryGroupIamPolicy

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const admin = gcp.organizations.getIAMPolicy({
    bindings: [{
        role: "roles/viewer",
        members: ["user:jane@example.com"],
    }],
});
const policy = new gcp.dataplex.EntryGroupIamPolicy("policy", {
    project: testEntryGroupBasic.project,
    location: testEntryGroupBasic.location,
    entryGroupId: testEntryGroupBasic.entryGroupId,
    policyData: admin.then(admin => admin.policyData),
});
```
```python
import pulumi
import pulumi_gcp as gcp

admin = gcp.organizations.get_iam_policy(bindings=[{
    "role": "roles/viewer",
    "members": ["user:jane@example.com"],
}])
policy = gcp.dataplex.EntryGroupIamPolicy("policy",
    project=test_entry_group_basic["project"],
    location=test_entry_group_basic["location"],
    entry_group_id=test_entry_group_basic["entryGroupId"],
    policy_data=admin.policy_data)
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var admin = Gcp.Organizations.GetIAMPolicy.Invoke(new()
    {
        Bindings = new[]
        {
            new Gcp.Organizations.Inputs.GetIAMPolicyBindingInputArgs
            {
                Role = "roles/viewer",
                Members = new[]
                {
                    "user:jane@example.com",
                },
            },
        },
    });

    var policy = new Gcp.DataPlex.EntryGroupIamPolicy("policy", new()
    {
        Project = testEntryGroupBasic.Project,
        Location = testEntryGroupBasic.Location,
        EntryGroupId = testEntryGroupBasic.EntryGroupId,
        PolicyData = admin.Apply(getIAMPolicyResult => getIAMPolicyResult.PolicyData),
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/dataplex"
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/organizations"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		admin, err := organizations.LookupIAMPolicy(ctx, &organizations.LookupIAMPolicyArgs{
			Bindings: []organizations.GetIAMPolicyBinding{
				{
					Role: "roles/viewer",
					Members: []string{
						"user:jane@example.com",
					},
				},
			},
		}, nil)
		if err != nil {
			return err
		}
		_, err = dataplex.NewEntryGroupIamPolicy(ctx, "policy", &dataplex.EntryGroupIamPolicyArgs{
			Project:      pulumi.Any(testEntryGroupBasic.Project),
			Location:     pulumi.Any(testEntryGroupBasic.Location),
			EntryGroupId: pulumi.Any(testEntryGroupBasic.EntryGroupId),
			PolicyData:   pulumi.String(admin.PolicyData),
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.organizations.OrganizationsFunctions;
import com.pulumi.gcp.organizations.inputs.GetIAMPolicyArgs;
import com.pulumi.gcp.dataplex.EntryGroupIamPolicy;
import com.pulumi.gcp.dataplex.EntryGroupIamPolicyArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        final var admin = OrganizationsFunctions.getIAMPolicy(GetIAMPolicyArgs.builder()
            .bindings(GetIAMPolicyBindingArgs.builder()
                .role("roles/viewer")
                .members("user:jane@example.com")
                .build())
            .build());

        var policy = new EntryGroupIamPolicy("policy", EntryGroupIamPolicyArgs.builder()
            .project(testEntryGroupBasic.project())
            .location(testEntryGroupBasic.location())
            .entryGroupId(testEntryGroupBasic.entryGroupId())
            .policyData(admin.applyValue(getIAMPolicyResult -> getIAMPolicyResult.policyData()))
            .build());

    }
}
```
```yaml
resources:
  policy:
    type: gcp:dataplex:EntryGroupIamPolicy
    properties:
      project: ${testEntryGroupBasic.project}
      location: ${testEntryGroupBasic.location}
      entryGroupId: ${testEntryGroupBasic.entryGroupId}
      policyData: ${admin.policyData}
variables:
  admin:
    fn::invoke:
      function: gcp:organizations:getIAMPolicy
      arguments:
        bindings:
          - role: roles/viewer
            members:
              - user:jane@example.com
```
<!--End PulumiCodeChooser -->

## gcp.dataplex.EntryGroupIamBinding

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const binding = new gcp.dataplex.EntryGroupIamBinding("binding", {
    project: testEntryGroupBasic.project,
    location: testEntryGroupBasic.location,
    entryGroupId: testEntryGroupBasic.entryGroupId,
    role: "roles/viewer",
    members: ["user:jane@example.com"],
});
```
```python
import pulumi
import pulumi_gcp as gcp

binding = gcp.dataplex.EntryGroupIamBinding("binding",
    project=test_entry_group_basic["project"],
    location=test_entry_group_basic["location"],
    entry_group_id=test_entry_group_basic["entryGroupId"],
    role="roles/viewer",
    members=["user:jane@example.com"])
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var binding = new Gcp.DataPlex.EntryGroupIamBinding("binding", new()
    {
        Project = testEntryGroupBasic.Project,
        Location = testEntryGroupBasic.Location,
        EntryGroupId = testEntryGroupBasic.EntryGroupId,
        Role = "roles/viewer",
        Members = new[]
        {
            "user:jane@example.com",
        },
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/dataplex"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		_, err := dataplex.NewEntryGroupIamBinding(ctx, "binding", &dataplex.EntryGroupIamBindingArgs{
			Project:      pulumi.Any(testEntryGroupBasic.Project),
			Location:     pulumi.Any(testEntryGroupBasic.Location),
			EntryGroupId: pulumi.Any(testEntryGroupBasic.EntryGroupId),
			Role:         pulumi.String("roles/viewer"),
			Members: pulumi.StringArray{
				pulumi.String("user:jane@example.com"),
			},
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.dataplex.EntryGroupIamBinding;
import com.pulumi.gcp.dataplex.EntryGroupIamBindingArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        var binding = new EntryGroupIamBinding("binding", EntryGroupIamBindingArgs.builder()
            .project(testEntryGroupBasic.project())
            .location(testEntryGroupBasic.location())
            .entryGroupId(testEntryGroupBasic.entryGroupId())
            .role("roles/viewer")
            .members("user:jane@example.com")
            .build());

    }
}
```
```yaml
resources:
  binding:
    type: gcp:dataplex:EntryGroupIamBinding
    properties:
      project: ${testEntryGroupBasic.project}
      location: ${testEntryGroupBasic.location}
      entryGroupId: ${testEntryGroupBasic.entryGroupId}
      role: roles/viewer
      members:
        - user:jane@example.com
```
<!--End PulumiCodeChooser -->

## gcp.dataplex.EntryGroupIamMember

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const member = new gcp.dataplex.EntryGroupIamMember("member", {
    project: testEntryGroupBasic.project,
    location: testEntryGroupBasic.location,
    entryGroupId: testEntryGroupBasic.entryGroupId,
    role: "roles/viewer",
    member: "user:jane@example.com",
});
```
```python
import pulumi
import pulumi_gcp as gcp

member = gcp.dataplex.EntryGroupIamMember("member",
    project=test_entry_group_basic["project"],
    location=test_entry_group_basic["location"],
    entry_group_id=test_entry_group_basic["entryGroupId"],
    role="roles/viewer",
    member="user:jane@example.com")
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var member = new Gcp.DataPlex.EntryGroupIamMember("member", new()
    {
        Project = testEntryGroupBasic.Project,
        Location = testEntryGroupBasic.Location,
        EntryGroupId = testEntryGroupBasic.EntryGroupId,
        Role = "roles/viewer",
        Member = "user:jane@example.com",
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/dataplex"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		_, err := dataplex.NewEntryGroupIamMember(ctx, "member", &dataplex.EntryGroupIamMemberArgs{
			Project:      pulumi.Any(testEntryGroupBasic.Project),
			Location:     pulumi.Any(testEntryGroupBasic.Location),
			EntryGroupId: pulumi.Any(testEntryGroupBasic.EntryGroupId),
			Role:         pulumi.String("roles/viewer"),
			Member:       pulumi.String("user:jane@example.com"),
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.dataplex.EntryGroupIamMember;
import com.pulumi.gcp.dataplex.EntryGroupIamMemberArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        var member = new EntryGroupIamMember("member", EntryGroupIamMemberArgs.builder()
            .project(testEntryGroupBasic.project())
            .location(testEntryGroupBasic.location())
            .entryGroupId(testEntryGroupBasic.entryGroupId())
            .role("roles/viewer")
            .member("user:jane@example.com")
            .build());

    }
}
```
```yaml
resources:
  member:
    type: gcp:dataplex:EntryGroupIamMember
    properties:
      project: ${testEntryGroupBasic.project}
      location: ${testEntryGroupBasic.location}
      entryGroupId: ${testEntryGroupBasic.entryGroupId}
      role: roles/viewer
      member: user:jane@example.com
```
<!--End PulumiCodeChooser -->

## Import

For all import syntaxes, the "resource in question" can take any of the following forms:

* projects/{{project}}/locations/{{location}}/entryGroups/{{entry_group_id}}

* {{project}}/{{location}}/{{entry_group_id}}

* {{location}}/{{entry_group_id}}

* {{entry_group_id}}

Any variables not passed in the import command will be taken from the provider configuration.

Dataplex entrygroup IAM resources can be imported using the resource identifiers, role, and member.

IAM member imports use space-delimited identifiers: the resource in question, the role, and the member identity, e.g.

```sh
$ pulumi import gcp:dataplex/entryGroupIamPolicy:EntryGroupIamPolicy editor "projects/{{project}}/locations/{{location}}/entryGroups/{{entry_group_id}} roles/viewer user:jane@example.com"
```

IAM binding imports use space-delimited identifiers: the resource in question and the role, e.g.

```sh
$ pulumi import gcp:dataplex/entryGroupIamPolicy:EntryGroupIamPolicy editor "projects/{{project}}/locations/{{location}}/entryGroups/{{entry_group_id}} roles/viewer"
```

IAM policy imports use the identifier of the resource in question, e.g.

```sh
$ pulumi import gcp:dataplex/entryGroupIamPolicy:EntryGroupIamPolicy editor projects/{{project}}/locations/{{location}}/entryGroups/{{entry_group_id}}
```

-> **Custom Roles** If you're importing a IAM resource with a custom role, make sure to use the

 full name of the custom role, e.g. `[projects/my-project|organizations/my-org]/roles/my-custom-role`.


entryGroupId" Ø
locationB" ÅThe location where entry group will be created in.
Used to find the parent resource to bind the IAM policy to. If not specified,
the value will be parsed from the identifier of the parent resource. If no location is provided in the parent identifier and no
location is specified, it is taken from the provider configuration.
_

policyData" MThe policy data generated by
a `gcp.organizations.getIAMPolicy` data source.

projectB" The ID of the project in which the resource belongs.
If it is not provided, the project will be parsed from the identifier of the parent resource. If no project is provided in the parent identifier and no project is specified, the provider project is used.
"
entryGroupId" "3
etag" '(Computed) The etag of the IAM policy.
"Ö
location" ÅThe location where entry group will be created in.
Used to find the parent resource to bind the IAM policy to. If not specified,
the value will be parsed from the identifier of the parent resource. If no location is provided in the parent identifier and no
location is specified, it is taken from the provider configuration.
"_

policyData" MThe policy data generated by
a `gcp.organizations.getIAMPolicy` data source.
"
project" The ID of the project in which the resource belongs.
If it is not provided, the project will be parsed from the identifier of the parent resource. If no project is provided in the parent identifier and no project is specified, the provider project is used.
*z
7
dataplex	EntryType gcp:dataplex/entryType:EntryType¯cAn Entry Type is a template for creating Entries.



## Example Usage

### Dataplex Entry Type Basic


<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const testEntryTypeBasic = new gcp.dataplex.EntryType("test_entry_type_basic", {
    entryTypeId: "entry-type-basic",
    project: "my-project-name",
    location: "us-central1",
});
```
```python
import pulumi
import pulumi_gcp as gcp

test_entry_type_basic = gcp.dataplex.EntryType("test_entry_type_basic",
    entry_type_id="entry-type-basic",
    project="my-project-name",
    location="us-central1")
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var testEntryTypeBasic = new Gcp.DataPlex.EntryType("test_entry_type_basic", new()
    {
        EntryTypeId = "entry-type-basic",
        Project = "my-project-name",
        Location = "us-central1",
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/dataplex"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		_, err := dataplex.NewEntryType(ctx, "test_entry_type_basic", &dataplex.EntryTypeArgs{
			EntryTypeId: pulumi.String("entry-type-basic"),
			Project:     pulumi.String("my-project-name"),
			Location:    pulumi.String("us-central1"),
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.dataplex.EntryType;
import com.pulumi.gcp.dataplex.EntryTypeArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        var testEntryTypeBasic = new EntryType("testEntryTypeBasic", EntryTypeArgs.builder()
            .entryTypeId("entry-type-basic")
            .project("my-project-name")
            .location("us-central1")
            .build());

    }
}
```
```yaml
resources:
  testEntryTypeBasic:
    type: gcp:dataplex:EntryType
    name: test_entry_type_basic
    properties:
      entryTypeId: entry-type-basic
      project: my-project-name
      location: us-central1
```
<!--End PulumiCodeChooser -->
### Dataplex Entry Type Full


<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const testEntryTypeFull = new gcp.dataplex.AspectType("test_entry_type_full", {
    aspectTypeId: "tf-test-aspect-type_22811",
    location: "us-central1",
    project: "my-project-name",
    metadataTemplate: `{
  "name": "tf-test-template",
  "type": "record",
  "recordFields": [
    {
      "name": "type",
      "type": "enum",
      "annotations": {
        "displayName": "Type",
        "description": "Specifies the type of view represented by the entry."
      },
      "index": 1,
      "constraints": {
        "required": true
      },
      "enumValues": [
        {
          "name": "VIEW",
          "index": 1
        }
      ]
    }
  ]
}
`,
});
const testEntryTypeFullEntryType = new gcp.dataplex.EntryType("test_entry_type_full", {
    entryTypeId: "entry-type-full",
    project: "my-project-name",
    location: "us-central1",
    labels: {
        tag: "test-tf",
    },
    displayName: "terraform entry type",
    description: "entry type created by Terraform",
    typeAliases: [
        "TABLE",
        "DATABASE",
    ],
    platform: "GCS",
    system: "CloudSQL",
    requiredAspects: [{
        type: testEntryTypeFull.name,
    }],
});
```
```python
import pulumi
import pulumi_gcp as gcp

test_entry_type_full = gcp.dataplex.AspectType("test_entry_type_full",
    aspect_type_id="tf-test-aspect-type_22811",
    location="us-central1",
    project="my-project-name",
    metadata_template="""{
  "name": "tf-test-template",
  "type": "record",
  "recordFields": [
    {
      "name": "type",
      "type": "enum",
      "annotations": {
        "displayName": "Type",
        "description": "Specifies the type of view represented by the entry."
      },
      "index": 1,
      "constraints": {
        "required": true
      },
      "enumValues": [
        {
          "name": "VIEW",
          "index": 1
        }
      ]
    }
  ]
}
""")
test_entry_type_full_entry_type = gcp.dataplex.EntryType("test_entry_type_full",
    entry_type_id="entry-type-full",
    project="my-project-name",
    location="us-central1",
    labels={
        "tag": "test-tf",
    },
    display_name="terraform entry type",
    description="entry type created by Terraform",
    type_aliases=[
        "TABLE",
        "DATABASE",
    ],
    platform="GCS",
    system="CloudSQL",
    required_aspects=[{
        "type": test_entry_type_full.name,
    }])
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var testEntryTypeFull = new Gcp.DataPlex.AspectType("test_entry_type_full", new()
    {
        AspectTypeId = "tf-test-aspect-type_22811",
        Location = "us-central1",
        Project = "my-project-name",
        MetadataTemplate = @"{
  ""name"": ""tf-test-template"",
  ""type"": ""record"",
  ""recordFields"": [
    {
      ""name"": ""type"",
      ""type"": ""enum"",
      ""annotations"": {
        ""displayName"": ""Type"",
        ""description"": ""Specifies the type of view represented by the entry.""
      },
      ""index"": 1,
      ""constraints"": {
        ""required"": true
      },
      ""enumValues"": [
        {
          ""name"": ""VIEW"",
          ""index"": 1
        }
      ]
    }
  ]
}
",
    });

    var testEntryTypeFullEntryType = new Gcp.DataPlex.EntryType("test_entry_type_full", new()
    {
        EntryTypeId = "entry-type-full",
        Project = "my-project-name",
        Location = "us-central1",
        Labels = 
        {
            { "tag", "test-tf" },
        },
        DisplayName = "terraform entry type",
        Description = "entry type created by Terraform",
        TypeAliases = new[]
        {
            "TABLE",
            "DATABASE",
        },
        Platform = "GCS",
        System = "CloudSQL",
        RequiredAspects = new[]
        {
            new Gcp.DataPlex.Inputs.EntryTypeRequiredAspectArgs
            {
                Type = testEntryTypeFull.Name,
            },
        },
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/dataplex"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		testEntryTypeFull, err := dataplex.NewAspectType(ctx, "test_entry_type_full", &dataplex.AspectTypeArgs{
			AspectTypeId: pulumi.String("tf-test-aspect-type_22811"),
			Location:     pulumi.String("us-central1"),
			Project:      pulumi.String("my-project-name"),
			MetadataTemplate: pulumi.String(`{
  "name": "tf-test-template",
  "type": "record",
  "recordFields": [
    {
      "name": "type",
      "type": "enum",
      "annotations": {
        "displayName": "Type",
        "description": "Specifies the type of view represented by the entry."
      },
      "index": 1,
      "constraints": {
        "required": true
      },
      "enumValues": [
        {
          "name": "VIEW",
          "index": 1
        }
      ]
    }
  ]
}
`),
		})
		if err != nil {
			return err
		}
		_, err = dataplex.NewEntryType(ctx, "test_entry_type_full", &dataplex.EntryTypeArgs{
			EntryTypeId: pulumi.String("entry-type-full"),
			Project:     pulumi.String("my-project-name"),
			Location:    pulumi.String("us-central1"),
			Labels: pulumi.StringMap{
				"tag": pulumi.String("test-tf"),
			},
			DisplayName: pulumi.String("terraform entry type"),
			Description: pulumi.String("entry type created by Terraform"),
			TypeAliases: pulumi.StringArray{
				pulumi.String("TABLE"),
				pulumi.String("DATABASE"),
			},
			Platform: pulumi.String("GCS"),
			System:   pulumi.String("CloudSQL"),
			RequiredAspects: dataplex.EntryTypeRequiredAspectArray{
				&dataplex.EntryTypeRequiredAspectArgs{
					Type: testEntryTypeFull.Name,
				},
			},
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.dataplex.AspectType;
import com.pulumi.gcp.dataplex.AspectTypeArgs;
import com.pulumi.gcp.dataplex.EntryType;
import com.pulumi.gcp.dataplex.EntryTypeArgs;
import com.pulumi.gcp.dataplex.inputs.EntryTypeRequiredAspectArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        var testEntryTypeFull = new AspectType("testEntryTypeFull", AspectTypeArgs.builder()
            .aspectTypeId("tf-test-aspect-type_22811")
            .location("us-central1")
            .project("my-project-name")
            .metadataTemplate("""
{
  "name": "tf-test-template",
  "type": "record",
  "recordFields": [
    {
      "name": "type",
      "type": "enum",
      "annotations": {
        "displayName": "Type",
        "description": "Specifies the type of view represented by the entry."
      },
      "index": 1,
      "constraints": {
        "required": true
      },
      "enumValues": [
        {
          "name": "VIEW",
          "index": 1
        }
      ]
    }
  ]
}
            """)
            .build());

        var testEntryTypeFullEntryType = new EntryType("testEntryTypeFullEntryType", EntryTypeArgs.builder()
            .entryTypeId("entry-type-full")
            .project("my-project-name")
            .location("us-central1")
            .labels(Map.of("tag", "test-tf"))
            .displayName("terraform entry type")
            .description("entry type created by Terraform")
            .typeAliases(            
                "TABLE",
                "DATABASE")
            .platform("GCS")
            .system("CloudSQL")
            .requiredAspects(EntryTypeRequiredAspectArgs.builder()
                .type(testEntryTypeFull.name())
                .build())
            .build());

    }
}
```
```yaml
resources:
  testEntryTypeFull:
    type: gcp:dataplex:AspectType
    name: test_entry_type_full
    properties:
      aspectTypeId: tf-test-aspect-type_22811
      location: us-central1
      project: my-project-name
      metadataTemplate: |
        {
          "name": "tf-test-template",
          "type": "record",
          "recordFields": [
            {
              "name": "type",
              "type": "enum",
              "annotations": {
                "displayName": "Type",
                "description": "Specifies the type of view represented by the entry."
              },
              "index": 1,
              "constraints": {
                "required": true
              },
              "enumValues": [
                {
                  "name": "VIEW",
                  "index": 1
                }
              ]
            }
          ]
        }
  testEntryTypeFullEntryType:
    type: gcp:dataplex:EntryType
    name: test_entry_type_full
    properties:
      entryTypeId: entry-type-full
      project: my-project-name
      location: us-central1
      labels:
        tag: test-tf
      displayName: terraform entry type
      description: entry type created by Terraform
      typeAliases:
        - TABLE
        - DATABASE
      platform: GCS
      system: CloudSQL
      requiredAspects:
        - type: ${testEntryTypeFull.name}
```
<!--End PulumiCodeChooser -->

## Import

EntryType can be imported using any of these accepted formats:

* `projects/{{project}}/locations/{{location}}/entryTypes/{{entry_type_id}}`

* `{{project}}/{{location}}/{{entry_type_id}}`

* `{{location}}/{{entry_type_id}}`

When using the `pulumi import` command, EntryType can be imported using one of the formats above. For example:

```sh
$ pulumi import gcp:dataplex/entryType:EntryType default projects/{{project}}/locations/{{location}}/entryTypes/{{entry_type_id}}
```

```sh
$ pulumi import gcp:dataplex/entryType:EntryType default {{project}}/{{location}}/{{entry_type_id}}
```

```sh
$ pulumi import gcp:dataplex/entryType:EntryType default {{location}}/{{entry_type_id}}
```

3
descriptionB" Description of the EntryType.
1
displayNameB" User friendly display name.
:
entryTypeIdB" %The entry type id of the entry type.

labelsB2" îUser-defined labels for the EntryType.

**Note**: This field is non-authoritative, and will only manage the labels present in your configuration.
Please refer to the field `effective_labels` for all of the labels present on the resource.
D
locationB" 2The location where entry type will be created in.
E
platformB" 3The platform that Entries of this type belongs to.
{
projectB" jThe ID of the project in which the resource belongs.
If it is not provided, the provider project is used.
¼
requiredAspectsiBg*e:c
a
dataplexEntryTypeRequiredAspect<gcp:dataplex/EntryTypeRequiredAspect:EntryTypeRequiredAspect>AspectInfo for the entry type.
Structure is documented below.
A
systemB" 1The system that Entries of this type belongs to.
l
typeAliasesB*" UIndicates the class this Entry Type belongs to, for example, TABLE, DATABASE, MODEL.
";

createTime" )The time when the EntryType was created.
"3
descriptionB" Description of the EntryType.
"1
displayNameB" User friendly display name.
"¦
effectiveLabels2" All of labels (key/value pairs) present on the resource in GCP, including the labels configured through Pulumi, other clients and services.
":
entryTypeIdB" %The entry type id of the entry type.
"
labelsB2" îUser-defined labels for the EntryType.

**Note**: This field is non-authoritative, and will only manage the labels present in your configuration.
Please refer to the field `effective_labels` for all of the labels present on the resource.
"D
locationB" 2The location where entry type will be created in.
"
name" The relative resource name of the EntryType, of the form: projects/{project_number}/locations/{location_id}/entryTypes/{entry_type_id}
"E
platformB" 3The platform that Entries of this type belongs to.
"y
project" jThe ID of the project in which the resource belongs.
If it is not provided, the provider project is used.
"
pulumiLabels2" mThe combination of labels configured directly on the resource
and default labels configured on the provider.
"¼
requiredAspectsiBg*e:c
a
dataplexEntryTypeRequiredAspect<gcp:dataplex/EntryTypeRequiredAspect:EntryTypeRequiredAspect>AspectInfo for the entry type.
Structure is documented below.
"A
systemB" 1The system that Entries of this type belongs to.
"l
typeAliasesB*" UIndicates the class this Entry Type belongs to, for example, TABLE, DATABASE, MODEL.
"
uid" System generated globally unique ID for the EntryType. This ID will be different if the EntryType is deleted and re-created with the same name.
"@

updateTime" .The time when the EntryType was last updated.
*åë
U
dataplexEntryTypeIamBinding4gcp:dataplex/entryTypeIamBinding:EntryTypeIamBindingÝÇThree different resources help you manage your IAM policy for Dataplex EntryType. Each of these resources serves a different use case:

* `gcp.dataplex.EntryTypeIamPolicy`: Authoritative. Sets the IAM policy for the entrytype and replaces any existing policy already attached.
* `gcp.dataplex.EntryTypeIamBinding`: Authoritative for a given role. Updates the IAM policy to grant a role to a list of members. Other roles within the IAM policy for the entrytype are preserved.
* `gcp.dataplex.EntryTypeIamMember`: Non-authoritative. Updates the IAM policy to grant a role to a new member. Other members for the role for the entrytype are preserved.

A data source can be used to retrieve policy data in advent you do not need creation

* `gcp.dataplex.EntryTypeIamPolicy`: Retrieves the IAM policy for the entrytype

> **Note:** `gcp.dataplex.EntryTypeIamPolicy` **cannot** be used in conjunction with `gcp.dataplex.EntryTypeIamBinding` and `gcp.dataplex.EntryTypeIamMember` or they will fight over what your policy should be.

> **Note:** `gcp.dataplex.EntryTypeIamBinding` resources **can be** used in conjunction with `gcp.dataplex.EntryTypeIamMember` resources **only if** they do not grant privilege to the same role.



## gcp.dataplex.EntryTypeIamPolicy

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const admin = gcp.organizations.getIAMPolicy({
    bindings: [{
        role: "roles/viewer",
        members: ["user:jane@example.com"],
    }],
});
const policy = new gcp.dataplex.EntryTypeIamPolicy("policy", {
    project: testEntryTypeBasic.project,
    location: testEntryTypeBasic.location,
    entryTypeId: testEntryTypeBasic.entryTypeId,
    policyData: admin.then(admin => admin.policyData),
});
```
```python
import pulumi
import pulumi_gcp as gcp

admin = gcp.organizations.get_iam_policy(bindings=[{
    "role": "roles/viewer",
    "members": ["user:jane@example.com"],
}])
policy = gcp.dataplex.EntryTypeIamPolicy("policy",
    project=test_entry_type_basic["project"],
    location=test_entry_type_basic["location"],
    entry_type_id=test_entry_type_basic["entryTypeId"],
    policy_data=admin.policy_data)
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var admin = Gcp.Organizations.GetIAMPolicy.Invoke(new()
    {
        Bindings = new[]
        {
            new Gcp.Organizations.Inputs.GetIAMPolicyBindingInputArgs
            {
                Role = "roles/viewer",
                Members = new[]
                {
                    "user:jane@example.com",
                },
            },
        },
    });

    var policy = new Gcp.DataPlex.EntryTypeIamPolicy("policy", new()
    {
        Project = testEntryTypeBasic.Project,
        Location = testEntryTypeBasic.Location,
        EntryTypeId = testEntryTypeBasic.EntryTypeId,
        PolicyData = admin.Apply(getIAMPolicyResult => getIAMPolicyResult.PolicyData),
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/dataplex"
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/organizations"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		admin, err := organizations.LookupIAMPolicy(ctx, &organizations.LookupIAMPolicyArgs{
			Bindings: []organizations.GetIAMPolicyBinding{
				{
					Role: "roles/viewer",
					Members: []string{
						"user:jane@example.com",
					},
				},
			},
		}, nil)
		if err != nil {
			return err
		}
		_, err = dataplex.NewEntryTypeIamPolicy(ctx, "policy", &dataplex.EntryTypeIamPolicyArgs{
			Project:     pulumi.Any(testEntryTypeBasic.Project),
			Location:    pulumi.Any(testEntryTypeBasic.Location),
			EntryTypeId: pulumi.Any(testEntryTypeBasic.EntryTypeId),
			PolicyData:  pulumi.String(admin.PolicyData),
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.organizations.OrganizationsFunctions;
import com.pulumi.gcp.organizations.inputs.GetIAMPolicyArgs;
import com.pulumi.gcp.dataplex.EntryTypeIamPolicy;
import com.pulumi.gcp.dataplex.EntryTypeIamPolicyArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        final var admin = OrganizationsFunctions.getIAMPolicy(GetIAMPolicyArgs.builder()
            .bindings(GetIAMPolicyBindingArgs.builder()
                .role("roles/viewer")
                .members("user:jane@example.com")
                .build())
            .build());

        var policy = new EntryTypeIamPolicy("policy", EntryTypeIamPolicyArgs.builder()
            .project(testEntryTypeBasic.project())
            .location(testEntryTypeBasic.location())
            .entryTypeId(testEntryTypeBasic.entryTypeId())
            .policyData(admin.applyValue(getIAMPolicyResult -> getIAMPolicyResult.policyData()))
            .build());

    }
}
```
```yaml
resources:
  policy:
    type: gcp:dataplex:EntryTypeIamPolicy
    properties:
      project: ${testEntryTypeBasic.project}
      location: ${testEntryTypeBasic.location}
      entryTypeId: ${testEntryTypeBasic.entryTypeId}
      policyData: ${admin.policyData}
variables:
  admin:
    fn::invoke:
      function: gcp:organizations:getIAMPolicy
      arguments:
        bindings:
          - role: roles/viewer
            members:
              - user:jane@example.com
```
<!--End PulumiCodeChooser -->

## gcp.dataplex.EntryTypeIamBinding

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const binding = new gcp.dataplex.EntryTypeIamBinding("binding", {
    project: testEntryTypeBasic.project,
    location: testEntryTypeBasic.location,
    entryTypeId: testEntryTypeBasic.entryTypeId,
    role: "roles/viewer",
    members: ["user:jane@example.com"],
});
```
```python
import pulumi
import pulumi_gcp as gcp

binding = gcp.dataplex.EntryTypeIamBinding("binding",
    project=test_entry_type_basic["project"],
    location=test_entry_type_basic["location"],
    entry_type_id=test_entry_type_basic["entryTypeId"],
    role="roles/viewer",
    members=["user:jane@example.com"])
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var binding = new Gcp.DataPlex.EntryTypeIamBinding("binding", new()
    {
        Project = testEntryTypeBasic.Project,
        Location = testEntryTypeBasic.Location,
        EntryTypeId = testEntryTypeBasic.EntryTypeId,
        Role = "roles/viewer",
        Members = new[]
        {
            "user:jane@example.com",
        },
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/dataplex"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		_, err := dataplex.NewEntryTypeIamBinding(ctx, "binding", &dataplex.EntryTypeIamBindingArgs{
			Project:     pulumi.Any(testEntryTypeBasic.Project),
			Location:    pulumi.Any(testEntryTypeBasic.Location),
			EntryTypeId: pulumi.Any(testEntryTypeBasic.EntryTypeId),
			Role:        pulumi.String("roles/viewer"),
			Members: pulumi.StringArray{
				pulumi.String("user:jane@example.com"),
			},
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.dataplex.EntryTypeIamBinding;
import com.pulumi.gcp.dataplex.EntryTypeIamBindingArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        var binding = new EntryTypeIamBinding("binding", EntryTypeIamBindingArgs.builder()
            .project(testEntryTypeBasic.project())
            .location(testEntryTypeBasic.location())
            .entryTypeId(testEntryTypeBasic.entryTypeId())
            .role("roles/viewer")
            .members("user:jane@example.com")
            .build());

    }
}
```
```yaml
resources:
  binding:
    type: gcp:dataplex:EntryTypeIamBinding
    properties:
      project: ${testEntryTypeBasic.project}
      location: ${testEntryTypeBasic.location}
      entryTypeId: ${testEntryTypeBasic.entryTypeId}
      role: roles/viewer
      members:
        - user:jane@example.com
```
<!--End PulumiCodeChooser -->

## gcp.dataplex.EntryTypeIamMember

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const member = new gcp.dataplex.EntryTypeIamMember("member", {
    project: testEntryTypeBasic.project,
    location: testEntryTypeBasic.location,
    entryTypeId: testEntryTypeBasic.entryTypeId,
    role: "roles/viewer",
    member: "user:jane@example.com",
});
```
```python
import pulumi
import pulumi_gcp as gcp

member = gcp.dataplex.EntryTypeIamMember("member",
    project=test_entry_type_basic["project"],
    location=test_entry_type_basic["location"],
    entry_type_id=test_entry_type_basic["entryTypeId"],
    role="roles/viewer",
    member="user:jane@example.com")
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var member = new Gcp.DataPlex.EntryTypeIamMember("member", new()
    {
        Project = testEntryTypeBasic.Project,
        Location = testEntryTypeBasic.Location,
        EntryTypeId = testEntryTypeBasic.EntryTypeId,
        Role = "roles/viewer",
        Member = "user:jane@example.com",
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/dataplex"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		_, err := dataplex.NewEntryTypeIamMember(ctx, "member", &dataplex.EntryTypeIamMemberArgs{
			Project:     pulumi.Any(testEntryTypeBasic.Project),
			Location:    pulumi.Any(testEntryTypeBasic.Location),
			EntryTypeId: pulumi.Any(testEntryTypeBasic.EntryTypeId),
			Role:        pulumi.String("roles/viewer"),
			Member:      pulumi.String("user:jane@example.com"),
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.dataplex.EntryTypeIamMember;
import com.pulumi.gcp.dataplex.EntryTypeIamMemberArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        var member = new EntryTypeIamMember("member", EntryTypeIamMemberArgs.builder()
            .project(testEntryTypeBasic.project())
            .location(testEntryTypeBasic.location())
            .entryTypeId(testEntryTypeBasic.entryTypeId())
            .role("roles/viewer")
            .member("user:jane@example.com")
            .build());

    }
}
```
```yaml
resources:
  member:
    type: gcp:dataplex:EntryTypeIamMember
    properties:
      project: ${testEntryTypeBasic.project}
      location: ${testEntryTypeBasic.location}
      entryTypeId: ${testEntryTypeBasic.entryTypeId}
      role: roles/viewer
      member: user:jane@example.com
```
<!--End PulumiCodeChooser -->


## This resource supports User Project Overrides.

-

# IAM policy for Dataplex EntryType
Three different resources help you manage your IAM policy for Dataplex EntryType. Each of these resources serves a different use case:

* `gcp.dataplex.EntryTypeIamPolicy`: Authoritative. Sets the IAM policy for the entrytype and replaces any existing policy already attached.
* `gcp.dataplex.EntryTypeIamBinding`: Authoritative for a given role. Updates the IAM policy to grant a role to a list of members. Other roles within the IAM policy for the entrytype are preserved.
* `gcp.dataplex.EntryTypeIamMember`: Non-authoritative. Updates the IAM policy to grant a role to a new member. Other members for the role for the entrytype are preserved.

A data source can be used to retrieve policy data in advent you do not need creation

* `gcp.dataplex.EntryTypeIamPolicy`: Retrieves the IAM policy for the entrytype

> **Note:** `gcp.dataplex.EntryTypeIamPolicy` **cannot** be used in conjunction with `gcp.dataplex.EntryTypeIamBinding` and `gcp.dataplex.EntryTypeIamMember` or they will fight over what your policy should be.

> **Note:** `gcp.dataplex.EntryTypeIamBinding` resources **can be** used in conjunction with `gcp.dataplex.EntryTypeIamMember` resources **only if** they do not grant privilege to the same role.



## gcp.dataplex.EntryTypeIamPolicy

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const admin = gcp.organizations.getIAMPolicy({
    bindings: [{
        role: "roles/viewer",
        members: ["user:jane@example.com"],
    }],
});
const policy = new gcp.dataplex.EntryTypeIamPolicy("policy", {
    project: testEntryTypeBasic.project,
    location: testEntryTypeBasic.location,
    entryTypeId: testEntryTypeBasic.entryTypeId,
    policyData: admin.then(admin => admin.policyData),
});
```
```python
import pulumi
import pulumi_gcp as gcp

admin = gcp.organizations.get_iam_policy(bindings=[{
    "role": "roles/viewer",
    "members": ["user:jane@example.com"],
}])
policy = gcp.dataplex.EntryTypeIamPolicy("policy",
    project=test_entry_type_basic["project"],
    location=test_entry_type_basic["location"],
    entry_type_id=test_entry_type_basic["entryTypeId"],
    policy_data=admin.policy_data)
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var admin = Gcp.Organizations.GetIAMPolicy.Invoke(new()
    {
        Bindings = new[]
        {
            new Gcp.Organizations.Inputs.GetIAMPolicyBindingInputArgs
            {
                Role = "roles/viewer",
                Members = new[]
                {
                    "user:jane@example.com",
                },
            },
        },
    });

    var policy = new Gcp.DataPlex.EntryTypeIamPolicy("policy", new()
    {
        Project = testEntryTypeBasic.Project,
        Location = testEntryTypeBasic.Location,
        EntryTypeId = testEntryTypeBasic.EntryTypeId,
        PolicyData = admin.Apply(getIAMPolicyResult => getIAMPolicyResult.PolicyData),
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/dataplex"
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/organizations"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		admin, err := organizations.LookupIAMPolicy(ctx, &organizations.LookupIAMPolicyArgs{
			Bindings: []organizations.GetIAMPolicyBinding{
				{
					Role: "roles/viewer",
					Members: []string{
						"user:jane@example.com",
					},
				},
			},
		}, nil)
		if err != nil {
			return err
		}
		_, err = dataplex.NewEntryTypeIamPolicy(ctx, "policy", &dataplex.EntryTypeIamPolicyArgs{
			Project:     pulumi.Any(testEntryTypeBasic.Project),
			Location:    pulumi.Any(testEntryTypeBasic.Location),
			EntryTypeId: pulumi.Any(testEntryTypeBasic.EntryTypeId),
			PolicyData:  pulumi.String(admin.PolicyData),
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.organizations.OrganizationsFunctions;
import com.pulumi.gcp.organizations.inputs.GetIAMPolicyArgs;
import com.pulumi.gcp.dataplex.EntryTypeIamPolicy;
import com.pulumi.gcp.dataplex.EntryTypeIamPolicyArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        final var admin = OrganizationsFunctions.getIAMPolicy(GetIAMPolicyArgs.builder()
            .bindings(GetIAMPolicyBindingArgs.builder()
                .role("roles/viewer")
                .members("user:jane@example.com")
                .build())
            .build());

        var policy = new EntryTypeIamPolicy("policy", EntryTypeIamPolicyArgs.builder()
            .project(testEntryTypeBasic.project())
            .location(testEntryTypeBasic.location())
            .entryTypeId(testEntryTypeBasic.entryTypeId())
            .policyData(admin.applyValue(getIAMPolicyResult -> getIAMPolicyResult.policyData()))
            .build());

    }
}
```
```yaml
resources:
  policy:
    type: gcp:dataplex:EntryTypeIamPolicy
    properties:
      project: ${testEntryTypeBasic.project}
      location: ${testEntryTypeBasic.location}
      entryTypeId: ${testEntryTypeBasic.entryTypeId}
      policyData: ${admin.policyData}
variables:
  admin:
    fn::invoke:
      function: gcp:organizations:getIAMPolicy
      arguments:
        bindings:
          - role: roles/viewer
            members:
              - user:jane@example.com
```
<!--End PulumiCodeChooser -->

## gcp.dataplex.EntryTypeIamBinding

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const binding = new gcp.dataplex.EntryTypeIamBinding("binding", {
    project: testEntryTypeBasic.project,
    location: testEntryTypeBasic.location,
    entryTypeId: testEntryTypeBasic.entryTypeId,
    role: "roles/viewer",
    members: ["user:jane@example.com"],
});
```
```python
import pulumi
import pulumi_gcp as gcp

binding = gcp.dataplex.EntryTypeIamBinding("binding",
    project=test_entry_type_basic["project"],
    location=test_entry_type_basic["location"],
    entry_type_id=test_entry_type_basic["entryTypeId"],
    role="roles/viewer",
    members=["user:jane@example.com"])
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var binding = new Gcp.DataPlex.EntryTypeIamBinding("binding", new()
    {
        Project = testEntryTypeBasic.Project,
        Location = testEntryTypeBasic.Location,
        EntryTypeId = testEntryTypeBasic.EntryTypeId,
        Role = "roles/viewer",
        Members = new[]
        {
            "user:jane@example.com",
        },
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/dataplex"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		_, err := dataplex.NewEntryTypeIamBinding(ctx, "binding", &dataplex.EntryTypeIamBindingArgs{
			Project:     pulumi.Any(testEntryTypeBasic.Project),
			Location:    pulumi.Any(testEntryTypeBasic.Location),
			EntryTypeId: pulumi.Any(testEntryTypeBasic.EntryTypeId),
			Role:        pulumi.String("roles/viewer"),
			Members: pulumi.StringArray{
				pulumi.String("user:jane@example.com"),
			},
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.dataplex.EntryTypeIamBinding;
import com.pulumi.gcp.dataplex.EntryTypeIamBindingArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        var binding = new EntryTypeIamBinding("binding", EntryTypeIamBindingArgs.builder()
            .project(testEntryTypeBasic.project())
            .location(testEntryTypeBasic.location())
            .entryTypeId(testEntryTypeBasic.entryTypeId())
            .role("roles/viewer")
            .members("user:jane@example.com")
            .build());

    }
}
```
```yaml
resources:
  binding:
    type: gcp:dataplex:EntryTypeIamBinding
    properties:
      project: ${testEntryTypeBasic.project}
      location: ${testEntryTypeBasic.location}
      entryTypeId: ${testEntryTypeBasic.entryTypeId}
      role: roles/viewer
      members:
        - user:jane@example.com
```
<!--End PulumiCodeChooser -->

## gcp.dataplex.EntryTypeIamMember

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const member = new gcp.dataplex.EntryTypeIamMember("member", {
    project: testEntryTypeBasic.project,
    location: testEntryTypeBasic.location,
    entryTypeId: testEntryTypeBasic.entryTypeId,
    role: "roles/viewer",
    member: "user:jane@example.com",
});
```
```python
import pulumi
import pulumi_gcp as gcp

member = gcp.dataplex.EntryTypeIamMember("member",
    project=test_entry_type_basic["project"],
    location=test_entry_type_basic["location"],
    entry_type_id=test_entry_type_basic["entryTypeId"],
    role="roles/viewer",
    member="user:jane@example.com")
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var member = new Gcp.DataPlex.EntryTypeIamMember("member", new()
    {
        Project = testEntryTypeBasic.Project,
        Location = testEntryTypeBasic.Location,
        EntryTypeId = testEntryTypeBasic.EntryTypeId,
        Role = "roles/viewer",
        Member = "user:jane@example.com",
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/dataplex"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		_, err := dataplex.NewEntryTypeIamMember(ctx, "member", &dataplex.EntryTypeIamMemberArgs{
			Project:     pulumi.Any(testEntryTypeBasic.Project),
			Location:    pulumi.Any(testEntryTypeBasic.Location),
			EntryTypeId: pulumi.Any(testEntryTypeBasic.EntryTypeId),
			Role:        pulumi.String("roles/viewer"),
			Member:      pulumi.String("user:jane@example.com"),
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.dataplex.EntryTypeIamMember;
import com.pulumi.gcp.dataplex.EntryTypeIamMemberArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        var member = new EntryTypeIamMember("member", EntryTypeIamMemberArgs.builder()
            .project(testEntryTypeBasic.project())
            .location(testEntryTypeBasic.location())
            .entryTypeId(testEntryTypeBasic.entryTypeId())
            .role("roles/viewer")
            .member("user:jane@example.com")
            .build());

    }
}
```
```yaml
resources:
  member:
    type: gcp:dataplex:EntryTypeIamMember
    properties:
      project: ${testEntryTypeBasic.project}
      location: ${testEntryTypeBasic.location}
      entryTypeId: ${testEntryTypeBasic.entryTypeId}
      role: roles/viewer
      member: user:jane@example.com
```
<!--End PulumiCodeChooser -->

## Import

For all import syntaxes, the "resource in question" can take any of the following forms:

* projects/{{project}}/locations/{{location}}/entryTypes/{{entry_type_id}}

* {{project}}/{{location}}/{{entry_type_id}}

* {{location}}/{{entry_type_id}}

* {{entry_type_id}}

Any variables not passed in the import command will be taken from the provider configuration.

Dataplex entrytype IAM resources can be imported using the resource identifiers, role, and member.

IAM member imports use space-delimited identifiers: the resource in question, the role, and the member identity, e.g.

```sh
$ pulumi import gcp:dataplex/entryTypeIamBinding:EntryTypeIamBinding editor "projects/{{project}}/locations/{{location}}/entryTypes/{{entry_type_id}} roles/viewer user:jane@example.com"
```

IAM binding imports use space-delimited identifiers: the resource in question and the role, e.g.

```sh
$ pulumi import gcp:dataplex/entryTypeIamBinding:EntryTypeIamBinding editor "projects/{{project}}/locations/{{location}}/entryTypes/{{entry_type_id}} roles/viewer"
```

IAM policy imports use the identifier of the resource in question, e.g.

```sh
$ pulumi import gcp:dataplex/entryTypeIamBinding:EntryTypeIamBinding editor projects/{{project}}/locations/{{location}}/entryTypes/{{entry_type_id}}
```

-> **Custom Roles** If you're importing a IAM resource with a custom role, make sure to use the

 full name of the custom role, e.g. `[projects/my-project|organizations/my-org]/roles/my-custom-role`.


	conditionvBt:r
p
dataplexEntryTypeIamBindingConditionFgcp:dataplex/EntryTypeIamBindingCondition:EntryTypeIamBindingCondition
entryTypeId" ×
locationB" ÄThe location where entry type will be created in.
Used to find the parent resource to bind the IAM policy to. If not specified,
the value will be parsed from the identifier of the parent resource. If no location is provided in the parent identifier and no
location is specified, it is taken from the provider configuration.
Ö	
members*" Ä	Identities that will be granted the privilege in `role`.
Each entry can have one of the following values:
* **allUsers**: A special identifier that represents anyone who is on the internet; with or without a Google account.
* **allAuthenticatedUsers**: A special identifier that represents anyone who is authenticated with a Google account or a service account.
* **user:{emailid}**: An email address that represents a specific Google account. For example, alice@gmail.com or joe@example.com.
* **serviceAccount:{emailid}**: An email address that represents a service account. For example, my-other-app@appspot.gserviceaccount.com.
* **group:{emailid}**: An email address that represents a Google group. For example, admins@example.com.
* **domain:{domain}**: A G Suite domain (primary, instead of alias) name that represents all the users of that domain. For example, google.com or example.com.
* **projectOwner:projectid**: Owners of the given project. For example, "projectOwner:my-example-project"
* **projectEditor:projectid**: Editors of the given project. For example, "projectEditor:my-example-project"
* **projectViewer:projectid**: Viewers of the given project. For example, "projectViewer:my-example-project"

projectB" The ID of the project in which the resource belongs.
If it is not provided, the project will be parsed from the identifier of the parent resource. If no project is provided in the parent identifier and no project is specified, the provider project is used.
Ù
role" ÌThe role that should be applied. Only one
`gcp.dataplex.EntryTypeIamBinding` can be used per role. Note that custom roles must be of the format
`[projects|organizations]/{parent-name}/roles/{role-name}`.
"
	conditionvBt:r
p
dataplexEntryTypeIamBindingConditionFgcp:dataplex/EntryTypeIamBindingCondition:EntryTypeIamBindingCondition"
entryTypeId" "3
etag" '(Computed) The etag of the IAM policy.
"Õ
location" ÄThe location where entry type will be created in.
Used to find the parent resource to bind the IAM policy to. If not specified,
the value will be parsed from the identifier of the parent resource. If no location is provided in the parent identifier and no
location is specified, it is taken from the provider configuration.
"Ö	
members*" Ä	Identities that will be granted the privilege in `role`.
Each entry can have one of the following values:
* **allUsers**: A special identifier that represents anyone who is on the internet; with or without a Google account.
* **allAuthenticatedUsers**: A special identifier that represents anyone who is authenticated with a Google account or a service account.
* **user:{emailid}**: An email address that represents a specific Google account. For example, alice@gmail.com or joe@example.com.
* **serviceAccount:{emailid}**: An email address that represents a service account. For example, my-other-app@appspot.gserviceaccount.com.
* **group:{emailid}**: An email address that represents a Google group. For example, admins@example.com.
* **domain:{domain}**: A G Suite domain (primary, instead of alias) name that represents all the users of that domain. For example, google.com or example.com.
* **projectOwner:projectid**: Owners of the given project. For example, "projectOwner:my-example-project"
* **projectEditor:projectid**: Editors of the given project. For example, "projectEditor:my-example-project"
* **projectViewer:projectid**: Viewers of the given project. For example, "projectViewer:my-example-project"
"
project" The ID of the project in which the resource belongs.
If it is not provided, the project will be parsed from the identifier of the parent resource. If no project is provided in the parent identifier and no project is specified, the provider project is used.
"Ù
role" ÌThe role that should be applied. Only one
`gcp.dataplex.EntryTypeIamBinding` can be used per role. Note that custom roles must be of the format
`[projects|organizations]/{parent-name}/roles/{role-name}`.
*Ðë
R
dataplexEntryTypeIamMember2gcp:dataplex/entryTypeIamMember:EntryTypeIamMember×ÇThree different resources help you manage your IAM policy for Dataplex EntryType. Each of these resources serves a different use case:

* `gcp.dataplex.EntryTypeIamPolicy`: Authoritative. Sets the IAM policy for the entrytype and replaces any existing policy already attached.
* `gcp.dataplex.EntryTypeIamBinding`: Authoritative for a given role. Updates the IAM policy to grant a role to a list of members. Other roles within the IAM policy for the entrytype are preserved.
* `gcp.dataplex.EntryTypeIamMember`: Non-authoritative. Updates the IAM policy to grant a role to a new member. Other members for the role for the entrytype are preserved.

A data source can be used to retrieve policy data in advent you do not need creation

* `gcp.dataplex.EntryTypeIamPolicy`: Retrieves the IAM policy for the entrytype

> **Note:** `gcp.dataplex.EntryTypeIamPolicy` **cannot** be used in conjunction with `gcp.dataplex.EntryTypeIamBinding` and `gcp.dataplex.EntryTypeIamMember` or they will fight over what your policy should be.

> **Note:** `gcp.dataplex.EntryTypeIamBinding` resources **can be** used in conjunction with `gcp.dataplex.EntryTypeIamMember` resources **only if** they do not grant privilege to the same role.



## gcp.dataplex.EntryTypeIamPolicy

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const admin = gcp.organizations.getIAMPolicy({
    bindings: [{
        role: "roles/viewer",
        members: ["user:jane@example.com"],
    }],
});
const policy = new gcp.dataplex.EntryTypeIamPolicy("policy", {
    project: testEntryTypeBasic.project,
    location: testEntryTypeBasic.location,
    entryTypeId: testEntryTypeBasic.entryTypeId,
    policyData: admin.then(admin => admin.policyData),
});
```
```python
import pulumi
import pulumi_gcp as gcp

admin = gcp.organizations.get_iam_policy(bindings=[{
    "role": "roles/viewer",
    "members": ["user:jane@example.com"],
}])
policy = gcp.dataplex.EntryTypeIamPolicy("policy",
    project=test_entry_type_basic["project"],
    location=test_entry_type_basic["location"],
    entry_type_id=test_entry_type_basic["entryTypeId"],
    policy_data=admin.policy_data)
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var admin = Gcp.Organizations.GetIAMPolicy.Invoke(new()
    {
        Bindings = new[]
        {
            new Gcp.Organizations.Inputs.GetIAMPolicyBindingInputArgs
            {
                Role = "roles/viewer",
                Members = new[]
                {
                    "user:jane@example.com",
                },
            },
        },
    });

    var policy = new Gcp.DataPlex.EntryTypeIamPolicy("policy", new()
    {
        Project = testEntryTypeBasic.Project,
        Location = testEntryTypeBasic.Location,
        EntryTypeId = testEntryTypeBasic.EntryTypeId,
        PolicyData = admin.Apply(getIAMPolicyResult => getIAMPolicyResult.PolicyData),
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/dataplex"
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/organizations"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		admin, err := organizations.LookupIAMPolicy(ctx, &organizations.LookupIAMPolicyArgs{
			Bindings: []organizations.GetIAMPolicyBinding{
				{
					Role: "roles/viewer",
					Members: []string{
						"user:jane@example.com",
					},
				},
			},
		}, nil)
		if err != nil {
			return err
		}
		_, err = dataplex.NewEntryTypeIamPolicy(ctx, "policy", &dataplex.EntryTypeIamPolicyArgs{
			Project:     pulumi.Any(testEntryTypeBasic.Project),
			Location:    pulumi.Any(testEntryTypeBasic.Location),
			EntryTypeId: pulumi.Any(testEntryTypeBasic.EntryTypeId),
			PolicyData:  pulumi.String(admin.PolicyData),
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.organizations.OrganizationsFunctions;
import com.pulumi.gcp.organizations.inputs.GetIAMPolicyArgs;
import com.pulumi.gcp.dataplex.EntryTypeIamPolicy;
import com.pulumi.gcp.dataplex.EntryTypeIamPolicyArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        final var admin = OrganizationsFunctions.getIAMPolicy(GetIAMPolicyArgs.builder()
            .bindings(GetIAMPolicyBindingArgs.builder()
                .role("roles/viewer")
                .members("user:jane@example.com")
                .build())
            .build());

        var policy = new EntryTypeIamPolicy("policy", EntryTypeIamPolicyArgs.builder()
            .project(testEntryTypeBasic.project())
            .location(testEntryTypeBasic.location())
            .entryTypeId(testEntryTypeBasic.entryTypeId())
            .policyData(admin.applyValue(getIAMPolicyResult -> getIAMPolicyResult.policyData()))
            .build());

    }
}
```
```yaml
resources:
  policy:
    type: gcp:dataplex:EntryTypeIamPolicy
    properties:
      project: ${testEntryTypeBasic.project}
      location: ${testEntryTypeBasic.location}
      entryTypeId: ${testEntryTypeBasic.entryTypeId}
      policyData: ${admin.policyData}
variables:
  admin:
    fn::invoke:
      function: gcp:organizations:getIAMPolicy
      arguments:
        bindings:
          - role: roles/viewer
            members:
              - user:jane@example.com
```
<!--End PulumiCodeChooser -->

## gcp.dataplex.EntryTypeIamBinding

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const binding = new gcp.dataplex.EntryTypeIamBinding("binding", {
    project: testEntryTypeBasic.project,
    location: testEntryTypeBasic.location,
    entryTypeId: testEntryTypeBasic.entryTypeId,
    role: "roles/viewer",
    members: ["user:jane@example.com"],
});
```
```python
import pulumi
import pulumi_gcp as gcp

binding = gcp.dataplex.EntryTypeIamBinding("binding",
    project=test_entry_type_basic["project"],
    location=test_entry_type_basic["location"],
    entry_type_id=test_entry_type_basic["entryTypeId"],
    role="roles/viewer",
    members=["user:jane@example.com"])
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var binding = new Gcp.DataPlex.EntryTypeIamBinding("binding", new()
    {
        Project = testEntryTypeBasic.Project,
        Location = testEntryTypeBasic.Location,
        EntryTypeId = testEntryTypeBasic.EntryTypeId,
        Role = "roles/viewer",
        Members = new[]
        {
            "user:jane@example.com",
        },
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/dataplex"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		_, err := dataplex.NewEntryTypeIamBinding(ctx, "binding", &dataplex.EntryTypeIamBindingArgs{
			Project:     pulumi.Any(testEntryTypeBasic.Project),
			Location:    pulumi.Any(testEntryTypeBasic.Location),
			EntryTypeId: pulumi.Any(testEntryTypeBasic.EntryTypeId),
			Role:        pulumi.String("roles/viewer"),
			Members: pulumi.StringArray{
				pulumi.String("user:jane@example.com"),
			},
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.dataplex.EntryTypeIamBinding;
import com.pulumi.gcp.dataplex.EntryTypeIamBindingArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        var binding = new EntryTypeIamBinding("binding", EntryTypeIamBindingArgs.builder()
            .project(testEntryTypeBasic.project())
            .location(testEntryTypeBasic.location())
            .entryTypeId(testEntryTypeBasic.entryTypeId())
            .role("roles/viewer")
            .members("user:jane@example.com")
            .build());

    }
}
```
```yaml
resources:
  binding:
    type: gcp:dataplex:EntryTypeIamBinding
    properties:
      project: ${testEntryTypeBasic.project}
      location: ${testEntryTypeBasic.location}
      entryTypeId: ${testEntryTypeBasic.entryTypeId}
      role: roles/viewer
      members:
        - user:jane@example.com
```
<!--End PulumiCodeChooser -->

## gcp.dataplex.EntryTypeIamMember

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const member = new gcp.dataplex.EntryTypeIamMember("member", {
    project: testEntryTypeBasic.project,
    location: testEntryTypeBasic.location,
    entryTypeId: testEntryTypeBasic.entryTypeId,
    role: "roles/viewer",
    member: "user:jane@example.com",
});
```
```python
import pulumi
import pulumi_gcp as gcp

member = gcp.dataplex.EntryTypeIamMember("member",
    project=test_entry_type_basic["project"],
    location=test_entry_type_basic["location"],
    entry_type_id=test_entry_type_basic["entryTypeId"],
    role="roles/viewer",
    member="user:jane@example.com")
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var member = new Gcp.DataPlex.EntryTypeIamMember("member", new()
    {
        Project = testEntryTypeBasic.Project,
        Location = testEntryTypeBasic.Location,
        EntryTypeId = testEntryTypeBasic.EntryTypeId,
        Role = "roles/viewer",
        Member = "user:jane@example.com",
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/dataplex"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		_, err := dataplex.NewEntryTypeIamMember(ctx, "member", &dataplex.EntryTypeIamMemberArgs{
			Project:     pulumi.Any(testEntryTypeBasic.Project),
			Location:    pulumi.Any(testEntryTypeBasic.Location),
			EntryTypeId: pulumi.Any(testEntryTypeBasic.EntryTypeId),
			Role:        pulumi.String("roles/viewer"),
			Member:      pulumi.String("user:jane@example.com"),
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.dataplex.EntryTypeIamMember;
import com.pulumi.gcp.dataplex.EntryTypeIamMemberArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        var member = new EntryTypeIamMember("member", EntryTypeIamMemberArgs.builder()
            .project(testEntryTypeBasic.project())
            .location(testEntryTypeBasic.location())
            .entryTypeId(testEntryTypeBasic.entryTypeId())
            .role("roles/viewer")
            .member("user:jane@example.com")
            .build());

    }
}
```
```yaml
resources:
  member:
    type: gcp:dataplex:EntryTypeIamMember
    properties:
      project: ${testEntryTypeBasic.project}
      location: ${testEntryTypeBasic.location}
      entryTypeId: ${testEntryTypeBasic.entryTypeId}
      role: roles/viewer
      member: user:jane@example.com
```
<!--End PulumiCodeChooser -->


## This resource supports User Project Overrides.

-

# IAM policy for Dataplex EntryType
Three different resources help you manage your IAM policy for Dataplex EntryType. Each of these resources serves a different use case:

* `gcp.dataplex.EntryTypeIamPolicy`: Authoritative. Sets the IAM policy for the entrytype and replaces any existing policy already attached.
* `gcp.dataplex.EntryTypeIamBinding`: Authoritative for a given role. Updates the IAM policy to grant a role to a list of members. Other roles within the IAM policy for the entrytype are preserved.
* `gcp.dataplex.EntryTypeIamMember`: Non-authoritative. Updates the IAM policy to grant a role to a new member. Other members for the role for the entrytype are preserved.

A data source can be used to retrieve policy data in advent you do not need creation

* `gcp.dataplex.EntryTypeIamPolicy`: Retrieves the IAM policy for the entrytype

> **Note:** `gcp.dataplex.EntryTypeIamPolicy` **cannot** be used in conjunction with `gcp.dataplex.EntryTypeIamBinding` and `gcp.dataplex.EntryTypeIamMember` or they will fight over what your policy should be.

> **Note:** `gcp.dataplex.EntryTypeIamBinding` resources **can be** used in conjunction with `gcp.dataplex.EntryTypeIamMember` resources **only if** they do not grant privilege to the same role.



## gcp.dataplex.EntryTypeIamPolicy

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const admin = gcp.organizations.getIAMPolicy({
    bindings: [{
        role: "roles/viewer",
        members: ["user:jane@example.com"],
    }],
});
const policy = new gcp.dataplex.EntryTypeIamPolicy("policy", {
    project: testEntryTypeBasic.project,
    location: testEntryTypeBasic.location,
    entryTypeId: testEntryTypeBasic.entryTypeId,
    policyData: admin.then(admin => admin.policyData),
});
```
```python
import pulumi
import pulumi_gcp as gcp

admin = gcp.organizations.get_iam_policy(bindings=[{
    "role": "roles/viewer",
    "members": ["user:jane@example.com"],
}])
policy = gcp.dataplex.EntryTypeIamPolicy("policy",
    project=test_entry_type_basic["project"],
    location=test_entry_type_basic["location"],
    entry_type_id=test_entry_type_basic["entryTypeId"],
    policy_data=admin.policy_data)
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var admin = Gcp.Organizations.GetIAMPolicy.Invoke(new()
    {
        Bindings = new[]
        {
            new Gcp.Organizations.Inputs.GetIAMPolicyBindingInputArgs
            {
                Role = "roles/viewer",
                Members = new[]
                {
                    "user:jane@example.com",
                },
            },
        },
    });

    var policy = new Gcp.DataPlex.EntryTypeIamPolicy("policy", new()
    {
        Project = testEntryTypeBasic.Project,
        Location = testEntryTypeBasic.Location,
        EntryTypeId = testEntryTypeBasic.EntryTypeId,
        PolicyData = admin.Apply(getIAMPolicyResult => getIAMPolicyResult.PolicyData),
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/dataplex"
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/organizations"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		admin, err := organizations.LookupIAMPolicy(ctx, &organizations.LookupIAMPolicyArgs{
			Bindings: []organizations.GetIAMPolicyBinding{
				{
					Role: "roles/viewer",
					Members: []string{
						"user:jane@example.com",
					},
				},
			},
		}, nil)
		if err != nil {
			return err
		}
		_, err = dataplex.NewEntryTypeIamPolicy(ctx, "policy", &dataplex.EntryTypeIamPolicyArgs{
			Project:     pulumi.Any(testEntryTypeBasic.Project),
			Location:    pulumi.Any(testEntryTypeBasic.Location),
			EntryTypeId: pulumi.Any(testEntryTypeBasic.EntryTypeId),
			PolicyData:  pulumi.String(admin.PolicyData),
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.organizations.OrganizationsFunctions;
import com.pulumi.gcp.organizations.inputs.GetIAMPolicyArgs;
import com.pulumi.gcp.dataplex.EntryTypeIamPolicy;
import com.pulumi.gcp.dataplex.EntryTypeIamPolicyArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        final var admin = OrganizationsFunctions.getIAMPolicy(GetIAMPolicyArgs.builder()
            .bindings(GetIAMPolicyBindingArgs.builder()
                .role("roles/viewer")
                .members("user:jane@example.com")
                .build())
            .build());

        var policy = new EntryTypeIamPolicy("policy", EntryTypeIamPolicyArgs.builder()
            .project(testEntryTypeBasic.project())
            .location(testEntryTypeBasic.location())
            .entryTypeId(testEntryTypeBasic.entryTypeId())
            .policyData(admin.applyValue(getIAMPolicyResult -> getIAMPolicyResult.policyData()))
            .build());

    }
}
```
```yaml
resources:
  policy:
    type: gcp:dataplex:EntryTypeIamPolicy
    properties:
      project: ${testEntryTypeBasic.project}
      location: ${testEntryTypeBasic.location}
      entryTypeId: ${testEntryTypeBasic.entryTypeId}
      policyData: ${admin.policyData}
variables:
  admin:
    fn::invoke:
      function: gcp:organizations:getIAMPolicy
      arguments:
        bindings:
          - role: roles/viewer
            members:
              - user:jane@example.com
```
<!--End PulumiCodeChooser -->

## gcp.dataplex.EntryTypeIamBinding

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const binding = new gcp.dataplex.EntryTypeIamBinding("binding", {
    project: testEntryTypeBasic.project,
    location: testEntryTypeBasic.location,
    entryTypeId: testEntryTypeBasic.entryTypeId,
    role: "roles/viewer",
    members: ["user:jane@example.com"],
});
```
```python
import pulumi
import pulumi_gcp as gcp

binding = gcp.dataplex.EntryTypeIamBinding("binding",
    project=test_entry_type_basic["project"],
    location=test_entry_type_basic["location"],
    entry_type_id=test_entry_type_basic["entryTypeId"],
    role="roles/viewer",
    members=["user:jane@example.com"])
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var binding = new Gcp.DataPlex.EntryTypeIamBinding("binding", new()
    {
        Project = testEntryTypeBasic.Project,
        Location = testEntryTypeBasic.Location,
        EntryTypeId = testEntryTypeBasic.EntryTypeId,
        Role = "roles/viewer",
        Members = new[]
        {
            "user:jane@example.com",
        },
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/dataplex"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		_, err := dataplex.NewEntryTypeIamBinding(ctx, "binding", &dataplex.EntryTypeIamBindingArgs{
			Project:     pulumi.Any(testEntryTypeBasic.Project),
			Location:    pulumi.Any(testEntryTypeBasic.Location),
			EntryTypeId: pulumi.Any(testEntryTypeBasic.EntryTypeId),
			Role:        pulumi.String("roles/viewer"),
			Members: pulumi.StringArray{
				pulumi.String("user:jane@example.com"),
			},
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.dataplex.EntryTypeIamBinding;
import com.pulumi.gcp.dataplex.EntryTypeIamBindingArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        var binding = new EntryTypeIamBinding("binding", EntryTypeIamBindingArgs.builder()
            .project(testEntryTypeBasic.project())
            .location(testEntryTypeBasic.location())
            .entryTypeId(testEntryTypeBasic.entryTypeId())
            .role("roles/viewer")
            .members("user:jane@example.com")
            .build());

    }
}
```
```yaml
resources:
  binding:
    type: gcp:dataplex:EntryTypeIamBinding
    properties:
      project: ${testEntryTypeBasic.project}
      location: ${testEntryTypeBasic.location}
      entryTypeId: ${testEntryTypeBasic.entryTypeId}
      role: roles/viewer
      members:
        - user:jane@example.com
```
<!--End PulumiCodeChooser -->

## gcp.dataplex.EntryTypeIamMember

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const member = new gcp.dataplex.EntryTypeIamMember("member", {
    project: testEntryTypeBasic.project,
    location: testEntryTypeBasic.location,
    entryTypeId: testEntryTypeBasic.entryTypeId,
    role: "roles/viewer",
    member: "user:jane@example.com",
});
```
```python
import pulumi
import pulumi_gcp as gcp

member = gcp.dataplex.EntryTypeIamMember("member",
    project=test_entry_type_basic["project"],
    location=test_entry_type_basic["location"],
    entry_type_id=test_entry_type_basic["entryTypeId"],
    role="roles/viewer",
    member="user:jane@example.com")
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var member = new Gcp.DataPlex.EntryTypeIamMember("member", new()
    {
        Project = testEntryTypeBasic.Project,
        Location = testEntryTypeBasic.Location,
        EntryTypeId = testEntryTypeBasic.EntryTypeId,
        Role = "roles/viewer",
        Member = "user:jane@example.com",
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/dataplex"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		_, err := dataplex.NewEntryTypeIamMember(ctx, "member", &dataplex.EntryTypeIamMemberArgs{
			Project:     pulumi.Any(testEntryTypeBasic.Project),
			Location:    pulumi.Any(testEntryTypeBasic.Location),
			EntryTypeId: pulumi.Any(testEntryTypeBasic.EntryTypeId),
			Role:        pulumi.String("roles/viewer"),
			Member:      pulumi.String("user:jane@example.com"),
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.dataplex.EntryTypeIamMember;
import com.pulumi.gcp.dataplex.EntryTypeIamMemberArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        var member = new EntryTypeIamMember("member", EntryTypeIamMemberArgs.builder()
            .project(testEntryTypeBasic.project())
            .location(testEntryTypeBasic.location())
            .entryTypeId(testEntryTypeBasic.entryTypeId())
            .role("roles/viewer")
            .member("user:jane@example.com")
            .build());

    }
}
```
```yaml
resources:
  member:
    type: gcp:dataplex:EntryTypeIamMember
    properties:
      project: ${testEntryTypeBasic.project}
      location: ${testEntryTypeBasic.location}
      entryTypeId: ${testEntryTypeBasic.entryTypeId}
      role: roles/viewer
      member: user:jane@example.com
```
<!--End PulumiCodeChooser -->

## Import

For all import syntaxes, the "resource in question" can take any of the following forms:

* projects/{{project}}/locations/{{location}}/entryTypes/{{entry_type_id}}

* {{project}}/{{location}}/{{entry_type_id}}

* {{location}}/{{entry_type_id}}

* {{entry_type_id}}

Any variables not passed in the import command will be taken from the provider configuration.

Dataplex entrytype IAM resources can be imported using the resource identifiers, role, and member.

IAM member imports use space-delimited identifiers: the resource in question, the role, and the member identity, e.g.

```sh
$ pulumi import gcp:dataplex/entryTypeIamMember:EntryTypeIamMember editor "projects/{{project}}/locations/{{location}}/entryTypes/{{entry_type_id}} roles/viewer user:jane@example.com"
```

IAM binding imports use space-delimited identifiers: the resource in question and the role, e.g.

```sh
$ pulumi import gcp:dataplex/entryTypeIamMember:EntryTypeIamMember editor "projects/{{project}}/locations/{{location}}/entryTypes/{{entry_type_id}} roles/viewer"
```

IAM policy imports use the identifier of the resource in question, e.g.

```sh
$ pulumi import gcp:dataplex/entryTypeIamMember:EntryTypeIamMember editor projects/{{project}}/locations/{{location}}/entryTypes/{{entry_type_id}}
```

-> **Custom Roles** If you're importing a IAM resource with a custom role, make sure to use the

 full name of the custom role, e.g. `[projects/my-project|organizations/my-org]/roles/my-custom-role`.


	conditionsBq:o
m
dataplexEntryTypeIamMemberConditionDgcp:dataplex/EntryTypeIamMemberCondition:EntryTypeIamMemberCondition
entryTypeId" ×
locationB" ÄThe location where entry type will be created in.
Used to find the parent resource to bind the IAM policy to. If not specified,
the value will be parsed from the identifier of the parent resource. If no location is provided in the parent identifier and no
location is specified, it is taken from the provider configuration.
Ó	
member" Ä	Identities that will be granted the privilege in `role`.
Each entry can have one of the following values:
* **allUsers**: A special identifier that represents anyone who is on the internet; with or without a Google account.
* **allAuthenticatedUsers**: A special identifier that represents anyone who is authenticated with a Google account or a service account.
* **user:{emailid}**: An email address that represents a specific Google account. For example, alice@gmail.com or joe@example.com.
* **serviceAccount:{emailid}**: An email address that represents a service account. For example, my-other-app@appspot.gserviceaccount.com.
* **group:{emailid}**: An email address that represents a Google group. For example, admins@example.com.
* **domain:{domain}**: A G Suite domain (primary, instead of alias) name that represents all the users of that domain. For example, google.com or example.com.
* **projectOwner:projectid**: Owners of the given project. For example, "projectOwner:my-example-project"
* **projectEditor:projectid**: Editors of the given project. For example, "projectEditor:my-example-project"
* **projectViewer:projectid**: Viewers of the given project. For example, "projectViewer:my-example-project"

projectB" The ID of the project in which the resource belongs.
If it is not provided, the project will be parsed from the identifier of the parent resource. If no project is provided in the parent identifier and no project is specified, the provider project is used.
Ù
role" ÌThe role that should be applied. Only one
`gcp.dataplex.EntryTypeIamBinding` can be used per role. Note that custom roles must be of the format
`[projects|organizations]/{parent-name}/roles/{role-name}`.
"
	conditionsBq:o
m
dataplexEntryTypeIamMemberConditionDgcp:dataplex/EntryTypeIamMemberCondition:EntryTypeIamMemberCondition"
entryTypeId" "3
etag" '(Computed) The etag of the IAM policy.
"Õ
location" ÄThe location where entry type will be created in.
Used to find the parent resource to bind the IAM policy to. If not specified,
the value will be parsed from the identifier of the parent resource. If no location is provided in the parent identifier and no
location is specified, it is taken from the provider configuration.
"Ó	
member" Ä	Identities that will be granted the privilege in `role`.
Each entry can have one of the following values:
* **allUsers**: A special identifier that represents anyone who is on the internet; with or without a Google account.
* **allAuthenticatedUsers**: A special identifier that represents anyone who is authenticated with a Google account or a service account.
* **user:{emailid}**: An email address that represents a specific Google account. For example, alice@gmail.com or joe@example.com.
* **serviceAccount:{emailid}**: An email address that represents a service account. For example, my-other-app@appspot.gserviceaccount.com.
* **group:{emailid}**: An email address that represents a Google group. For example, admins@example.com.
* **domain:{domain}**: A G Suite domain (primary, instead of alias) name that represents all the users of that domain. For example, google.com or example.com.
* **projectOwner:projectid**: Owners of the given project. For example, "projectOwner:my-example-project"
* **projectEditor:projectid**: Editors of the given project. For example, "projectEditor:my-example-project"
* **projectViewer:projectid**: Viewers of the given project. For example, "projectViewer:my-example-project"
"
project" The ID of the project in which the resource belongs.
If it is not provided, the project will be parsed from the identifier of the parent resource. If no project is provided in the parent identifier and no project is specified, the provider project is used.
"Ù
role" ÌThe role that should be applied. Only one
`gcp.dataplex.EntryTypeIamBinding` can be used per role. Note that custom roles must be of the format
`[projects|organizations]/{parent-name}/roles/{role-name}`.
*¨Ô
R
dataplexEntryTypeIamPolicy2gcp:dataplex/entryTypeIamPolicy:EntryTypeIamPolicy×ÇThree different resources help you manage your IAM policy for Dataplex EntryType. Each of these resources serves a different use case:

* `gcp.dataplex.EntryTypeIamPolicy`: Authoritative. Sets the IAM policy for the entrytype and replaces any existing policy already attached.
* `gcp.dataplex.EntryTypeIamBinding`: Authoritative for a given role. Updates the IAM policy to grant a role to a list of members. Other roles within the IAM policy for the entrytype are preserved.
* `gcp.dataplex.EntryTypeIamMember`: Non-authoritative. Updates the IAM policy to grant a role to a new member. Other members for the role for the entrytype are preserved.

A data source can be used to retrieve policy data in advent you do not need creation

* `gcp.dataplex.EntryTypeIamPolicy`: Retrieves the IAM policy for the entrytype

> **Note:** `gcp.dataplex.EntryTypeIamPolicy` **cannot** be used in conjunction with `gcp.dataplex.EntryTypeIamBinding` and `gcp.dataplex.EntryTypeIamMember` or they will fight over what your policy should be.

> **Note:** `gcp.dataplex.EntryTypeIamBinding` resources **can be** used in conjunction with `gcp.dataplex.EntryTypeIamMember` resources **only if** they do not grant privilege to the same role.



## gcp.dataplex.EntryTypeIamPolicy

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const admin = gcp.organizations.getIAMPolicy({
    bindings: [{
        role: "roles/viewer",
        members: ["user:jane@example.com"],
    }],
});
const policy = new gcp.dataplex.EntryTypeIamPolicy("policy", {
    project: testEntryTypeBasic.project,
    location: testEntryTypeBasic.location,
    entryTypeId: testEntryTypeBasic.entryTypeId,
    policyData: admin.then(admin => admin.policyData),
});
```
```python
import pulumi
import pulumi_gcp as gcp

admin = gcp.organizations.get_iam_policy(bindings=[{
    "role": "roles/viewer",
    "members": ["user:jane@example.com"],
}])
policy = gcp.dataplex.EntryTypeIamPolicy("policy",
    project=test_entry_type_basic["project"],
    location=test_entry_type_basic["location"],
    entry_type_id=test_entry_type_basic["entryTypeId"],
    policy_data=admin.policy_data)
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var admin = Gcp.Organizations.GetIAMPolicy.Invoke(new()
    {
        Bindings = new[]
        {
            new Gcp.Organizations.Inputs.GetIAMPolicyBindingInputArgs
            {
                Role = "roles/viewer",
                Members = new[]
                {
                    "user:jane@example.com",
                },
            },
        },
    });

    var policy = new Gcp.DataPlex.EntryTypeIamPolicy("policy", new()
    {
        Project = testEntryTypeBasic.Project,
        Location = testEntryTypeBasic.Location,
        EntryTypeId = testEntryTypeBasic.EntryTypeId,
        PolicyData = admin.Apply(getIAMPolicyResult => getIAMPolicyResult.PolicyData),
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/dataplex"
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/organizations"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		admin, err := organizations.LookupIAMPolicy(ctx, &organizations.LookupIAMPolicyArgs{
			Bindings: []organizations.GetIAMPolicyBinding{
				{
					Role: "roles/viewer",
					Members: []string{
						"user:jane@example.com",
					},
				},
			},
		}, nil)
		if err != nil {
			return err
		}
		_, err = dataplex.NewEntryTypeIamPolicy(ctx, "policy", &dataplex.EntryTypeIamPolicyArgs{
			Project:     pulumi.Any(testEntryTypeBasic.Project),
			Location:    pulumi.Any(testEntryTypeBasic.Location),
			EntryTypeId: pulumi.Any(testEntryTypeBasic.EntryTypeId),
			PolicyData:  pulumi.String(admin.PolicyData),
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.organizations.OrganizationsFunctions;
import com.pulumi.gcp.organizations.inputs.GetIAMPolicyArgs;
import com.pulumi.gcp.dataplex.EntryTypeIamPolicy;
import com.pulumi.gcp.dataplex.EntryTypeIamPolicyArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        final var admin = OrganizationsFunctions.getIAMPolicy(GetIAMPolicyArgs.builder()
            .bindings(GetIAMPolicyBindingArgs.builder()
                .role("roles/viewer")
                .members("user:jane@example.com")
                .build())
            .build());

        var policy = new EntryTypeIamPolicy("policy", EntryTypeIamPolicyArgs.builder()
            .project(testEntryTypeBasic.project())
            .location(testEntryTypeBasic.location())
            .entryTypeId(testEntryTypeBasic.entryTypeId())
            .policyData(admin.applyValue(getIAMPolicyResult -> getIAMPolicyResult.policyData()))
            .build());

    }
}
```
```yaml
resources:
  policy:
    type: gcp:dataplex:EntryTypeIamPolicy
    properties:
      project: ${testEntryTypeBasic.project}
      location: ${testEntryTypeBasic.location}
      entryTypeId: ${testEntryTypeBasic.entryTypeId}
      policyData: ${admin.policyData}
variables:
  admin:
    fn::invoke:
      function: gcp:organizations:getIAMPolicy
      arguments:
        bindings:
          - role: roles/viewer
            members:
              - user:jane@example.com
```
<!--End PulumiCodeChooser -->

## gcp.dataplex.EntryTypeIamBinding

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const binding = new gcp.dataplex.EntryTypeIamBinding("binding", {
    project: testEntryTypeBasic.project,
    location: testEntryTypeBasic.location,
    entryTypeId: testEntryTypeBasic.entryTypeId,
    role: "roles/viewer",
    members: ["user:jane@example.com"],
});
```
```python
import pulumi
import pulumi_gcp as gcp

binding = gcp.dataplex.EntryTypeIamBinding("binding",
    project=test_entry_type_basic["project"],
    location=test_entry_type_basic["location"],
    entry_type_id=test_entry_type_basic["entryTypeId"],
    role="roles/viewer",
    members=["user:jane@example.com"])
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var binding = new Gcp.DataPlex.EntryTypeIamBinding("binding", new()
    {
        Project = testEntryTypeBasic.Project,
        Location = testEntryTypeBasic.Location,
        EntryTypeId = testEntryTypeBasic.EntryTypeId,
        Role = "roles/viewer",
        Members = new[]
        {
            "user:jane@example.com",
        },
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/dataplex"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		_, err := dataplex.NewEntryTypeIamBinding(ctx, "binding", &dataplex.EntryTypeIamBindingArgs{
			Project:     pulumi.Any(testEntryTypeBasic.Project),
			Location:    pulumi.Any(testEntryTypeBasic.Location),
			EntryTypeId: pulumi.Any(testEntryTypeBasic.EntryTypeId),
			Role:        pulumi.String("roles/viewer"),
			Members: pulumi.StringArray{
				pulumi.String("user:jane@example.com"),
			},
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.dataplex.EntryTypeIamBinding;
import com.pulumi.gcp.dataplex.EntryTypeIamBindingArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        var binding = new EntryTypeIamBinding("binding", EntryTypeIamBindingArgs.builder()
            .project(testEntryTypeBasic.project())
            .location(testEntryTypeBasic.location())
            .entryTypeId(testEntryTypeBasic.entryTypeId())
            .role("roles/viewer")
            .members("user:jane@example.com")
            .build());

    }
}
```
```yaml
resources:
  binding:
    type: gcp:dataplex:EntryTypeIamBinding
    properties:
      project: ${testEntryTypeBasic.project}
      location: ${testEntryTypeBasic.location}
      entryTypeId: ${testEntryTypeBasic.entryTypeId}
      role: roles/viewer
      members:
        - user:jane@example.com
```
<!--End PulumiCodeChooser -->

## gcp.dataplex.EntryTypeIamMember

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const member = new gcp.dataplex.EntryTypeIamMember("member", {
    project: testEntryTypeBasic.project,
    location: testEntryTypeBasic.location,
    entryTypeId: testEntryTypeBasic.entryTypeId,
    role: "roles/viewer",
    member: "user:jane@example.com",
});
```
```python
import pulumi
import pulumi_gcp as gcp

member = gcp.dataplex.EntryTypeIamMember("member",
    project=test_entry_type_basic["project"],
    location=test_entry_type_basic["location"],
    entry_type_id=test_entry_type_basic["entryTypeId"],
    role="roles/viewer",
    member="user:jane@example.com")
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var member = new Gcp.DataPlex.EntryTypeIamMember("member", new()
    {
        Project = testEntryTypeBasic.Project,
        Location = testEntryTypeBasic.Location,
        EntryTypeId = testEntryTypeBasic.EntryTypeId,
        Role = "roles/viewer",
        Member = "user:jane@example.com",
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/dataplex"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		_, err := dataplex.NewEntryTypeIamMember(ctx, "member", &dataplex.EntryTypeIamMemberArgs{
			Project:     pulumi.Any(testEntryTypeBasic.Project),
			Location:    pulumi.Any(testEntryTypeBasic.Location),
			EntryTypeId: pulumi.Any(testEntryTypeBasic.EntryTypeId),
			Role:        pulumi.String("roles/viewer"),
			Member:      pulumi.String("user:jane@example.com"),
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.dataplex.EntryTypeIamMember;
import com.pulumi.gcp.dataplex.EntryTypeIamMemberArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        var member = new EntryTypeIamMember("member", EntryTypeIamMemberArgs.builder()
            .project(testEntryTypeBasic.project())
            .location(testEntryTypeBasic.location())
            .entryTypeId(testEntryTypeBasic.entryTypeId())
            .role("roles/viewer")
            .member("user:jane@example.com")
            .build());

    }
}
```
```yaml
resources:
  member:
    type: gcp:dataplex:EntryTypeIamMember
    properties:
      project: ${testEntryTypeBasic.project}
      location: ${testEntryTypeBasic.location}
      entryTypeId: ${testEntryTypeBasic.entryTypeId}
      role: roles/viewer
      member: user:jane@example.com
```
<!--End PulumiCodeChooser -->


## This resource supports User Project Overrides.

-

# IAM policy for Dataplex EntryType
Three different resources help you manage your IAM policy for Dataplex EntryType. Each of these resources serves a different use case:

* `gcp.dataplex.EntryTypeIamPolicy`: Authoritative. Sets the IAM policy for the entrytype and replaces any existing policy already attached.
* `gcp.dataplex.EntryTypeIamBinding`: Authoritative for a given role. Updates the IAM policy to grant a role to a list of members. Other roles within the IAM policy for the entrytype are preserved.
* `gcp.dataplex.EntryTypeIamMember`: Non-authoritative. Updates the IAM policy to grant a role to a new member. Other members for the role for the entrytype are preserved.

A data source can be used to retrieve policy data in advent you do not need creation

* `gcp.dataplex.EntryTypeIamPolicy`: Retrieves the IAM policy for the entrytype

> **Note:** `gcp.dataplex.EntryTypeIamPolicy` **cannot** be used in conjunction with `gcp.dataplex.EntryTypeIamBinding` and `gcp.dataplex.EntryTypeIamMember` or they will fight over what your policy should be.

> **Note:** `gcp.dataplex.EntryTypeIamBinding` resources **can be** used in conjunction with `gcp.dataplex.EntryTypeIamMember` resources **only if** they do not grant privilege to the same role.



## gcp.dataplex.EntryTypeIamPolicy

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const admin = gcp.organizations.getIAMPolicy({
    bindings: [{
        role: "roles/viewer",
        members: ["user:jane@example.com"],
    }],
});
const policy = new gcp.dataplex.EntryTypeIamPolicy("policy", {
    project: testEntryTypeBasic.project,
    location: testEntryTypeBasic.location,
    entryTypeId: testEntryTypeBasic.entryTypeId,
    policyData: admin.then(admin => admin.policyData),
});
```
```python
import pulumi
import pulumi_gcp as gcp

admin = gcp.organizations.get_iam_policy(bindings=[{
    "role": "roles/viewer",
    "members": ["user:jane@example.com"],
}])
policy = gcp.dataplex.EntryTypeIamPolicy("policy",
    project=test_entry_type_basic["project"],
    location=test_entry_type_basic["location"],
    entry_type_id=test_entry_type_basic["entryTypeId"],
    policy_data=admin.policy_data)
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var admin = Gcp.Organizations.GetIAMPolicy.Invoke(new()
    {
        Bindings = new[]
        {
            new Gcp.Organizations.Inputs.GetIAMPolicyBindingInputArgs
            {
                Role = "roles/viewer",
                Members = new[]
                {
                    "user:jane@example.com",
                },
            },
        },
    });

    var policy = new Gcp.DataPlex.EntryTypeIamPolicy("policy", new()
    {
        Project = testEntryTypeBasic.Project,
        Location = testEntryTypeBasic.Location,
        EntryTypeId = testEntryTypeBasic.EntryTypeId,
        PolicyData = admin.Apply(getIAMPolicyResult => getIAMPolicyResult.PolicyData),
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/dataplex"
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/organizations"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		admin, err := organizations.LookupIAMPolicy(ctx, &organizations.LookupIAMPolicyArgs{
			Bindings: []organizations.GetIAMPolicyBinding{
				{
					Role: "roles/viewer",
					Members: []string{
						"user:jane@example.com",
					},
				},
			},
		}, nil)
		if err != nil {
			return err
		}
		_, err = dataplex.NewEntryTypeIamPolicy(ctx, "policy", &dataplex.EntryTypeIamPolicyArgs{
			Project:     pulumi.Any(testEntryTypeBasic.Project),
			Location:    pulumi.Any(testEntryTypeBasic.Location),
			EntryTypeId: pulumi.Any(testEntryTypeBasic.EntryTypeId),
			PolicyData:  pulumi.String(admin.PolicyData),
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.organizations.OrganizationsFunctions;
import com.pulumi.gcp.organizations.inputs.GetIAMPolicyArgs;
import com.pulumi.gcp.dataplex.EntryTypeIamPolicy;
import com.pulumi.gcp.dataplex.EntryTypeIamPolicyArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        final var admin = OrganizationsFunctions.getIAMPolicy(GetIAMPolicyArgs.builder()
            .bindings(GetIAMPolicyBindingArgs.builder()
                .role("roles/viewer")
                .members("user:jane@example.com")
                .build())
            .build());

        var policy = new EntryTypeIamPolicy("policy", EntryTypeIamPolicyArgs.builder()
            .project(testEntryTypeBasic.project())
            .location(testEntryTypeBasic.location())
            .entryTypeId(testEntryTypeBasic.entryTypeId())
            .policyData(admin.applyValue(getIAMPolicyResult -> getIAMPolicyResult.policyData()))
            .build());

    }
}
```
```yaml
resources:
  policy:
    type: gcp:dataplex:EntryTypeIamPolicy
    properties:
      project: ${testEntryTypeBasic.project}
      location: ${testEntryTypeBasic.location}
      entryTypeId: ${testEntryTypeBasic.entryTypeId}
      policyData: ${admin.policyData}
variables:
  admin:
    fn::invoke:
      function: gcp:organizations:getIAMPolicy
      arguments:
        bindings:
          - role: roles/viewer
            members:
              - user:jane@example.com
```
<!--End PulumiCodeChooser -->

## gcp.dataplex.EntryTypeIamBinding

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const binding = new gcp.dataplex.EntryTypeIamBinding("binding", {
    project: testEntryTypeBasic.project,
    location: testEntryTypeBasic.location,
    entryTypeId: testEntryTypeBasic.entryTypeId,
    role: "roles/viewer",
    members: ["user:jane@example.com"],
});
```
```python
import pulumi
import pulumi_gcp as gcp

binding = gcp.dataplex.EntryTypeIamBinding("binding",
    project=test_entry_type_basic["project"],
    location=test_entry_type_basic["location"],
    entry_type_id=test_entry_type_basic["entryTypeId"],
    role="roles/viewer",
    members=["user:jane@example.com"])
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var binding = new Gcp.DataPlex.EntryTypeIamBinding("binding", new()
    {
        Project = testEntryTypeBasic.Project,
        Location = testEntryTypeBasic.Location,
        EntryTypeId = testEntryTypeBasic.EntryTypeId,
        Role = "roles/viewer",
        Members = new[]
        {
            "user:jane@example.com",
        },
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/dataplex"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		_, err := dataplex.NewEntryTypeIamBinding(ctx, "binding", &dataplex.EntryTypeIamBindingArgs{
			Project:     pulumi.Any(testEntryTypeBasic.Project),
			Location:    pulumi.Any(testEntryTypeBasic.Location),
			EntryTypeId: pulumi.Any(testEntryTypeBasic.EntryTypeId),
			Role:        pulumi.String("roles/viewer"),
			Members: pulumi.StringArray{
				pulumi.String("user:jane@example.com"),
			},
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.dataplex.EntryTypeIamBinding;
import com.pulumi.gcp.dataplex.EntryTypeIamBindingArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        var binding = new EntryTypeIamBinding("binding", EntryTypeIamBindingArgs.builder()
            .project(testEntryTypeBasic.project())
            .location(testEntryTypeBasic.location())
            .entryTypeId(testEntryTypeBasic.entryTypeId())
            .role("roles/viewer")
            .members("user:jane@example.com")
            .build());

    }
}
```
```yaml
resources:
  binding:
    type: gcp:dataplex:EntryTypeIamBinding
    properties:
      project: ${testEntryTypeBasic.project}
      location: ${testEntryTypeBasic.location}
      entryTypeId: ${testEntryTypeBasic.entryTypeId}
      role: roles/viewer
      members:
        - user:jane@example.com
```
<!--End PulumiCodeChooser -->

## gcp.dataplex.EntryTypeIamMember

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const member = new gcp.dataplex.EntryTypeIamMember("member", {
    project: testEntryTypeBasic.project,
    location: testEntryTypeBasic.location,
    entryTypeId: testEntryTypeBasic.entryTypeId,
    role: "roles/viewer",
    member: "user:jane@example.com",
});
```
```python
import pulumi
import pulumi_gcp as gcp

member = gcp.dataplex.EntryTypeIamMember("member",
    project=test_entry_type_basic["project"],
    location=test_entry_type_basic["location"],
    entry_type_id=test_entry_type_basic["entryTypeId"],
    role="roles/viewer",
    member="user:jane@example.com")
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var member = new Gcp.DataPlex.EntryTypeIamMember("member", new()
    {
        Project = testEntryTypeBasic.Project,
        Location = testEntryTypeBasic.Location,
        EntryTypeId = testEntryTypeBasic.EntryTypeId,
        Role = "roles/viewer",
        Member = "user:jane@example.com",
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/dataplex"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		_, err := dataplex.NewEntryTypeIamMember(ctx, "member", &dataplex.EntryTypeIamMemberArgs{
			Project:     pulumi.Any(testEntryTypeBasic.Project),
			Location:    pulumi.Any(testEntryTypeBasic.Location),
			EntryTypeId: pulumi.Any(testEntryTypeBasic.EntryTypeId),
			Role:        pulumi.String("roles/viewer"),
			Member:      pulumi.String("user:jane@example.com"),
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.dataplex.EntryTypeIamMember;
import com.pulumi.gcp.dataplex.EntryTypeIamMemberArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        var member = new EntryTypeIamMember("member", EntryTypeIamMemberArgs.builder()
            .project(testEntryTypeBasic.project())
            .location(testEntryTypeBasic.location())
            .entryTypeId(testEntryTypeBasic.entryTypeId())
            .role("roles/viewer")
            .member("user:jane@example.com")
            .build());

    }
}
```
```yaml
resources:
  member:
    type: gcp:dataplex:EntryTypeIamMember
    properties:
      project: ${testEntryTypeBasic.project}
      location: ${testEntryTypeBasic.location}
      entryTypeId: ${testEntryTypeBasic.entryTypeId}
      role: roles/viewer
      member: user:jane@example.com
```
<!--End PulumiCodeChooser -->

## Import

For all import syntaxes, the "resource in question" can take any of the following forms:

* projects/{{project}}/locations/{{location}}/entryTypes/{{entry_type_id}}

* {{project}}/{{location}}/{{entry_type_id}}

* {{location}}/{{entry_type_id}}

* {{entry_type_id}}

Any variables not passed in the import command will be taken from the provider configuration.

Dataplex entrytype IAM resources can be imported using the resource identifiers, role, and member.

IAM member imports use space-delimited identifiers: the resource in question, the role, and the member identity, e.g.

```sh
$ pulumi import gcp:dataplex/entryTypeIamPolicy:EntryTypeIamPolicy editor "projects/{{project}}/locations/{{location}}/entryTypes/{{entry_type_id}} roles/viewer user:jane@example.com"
```

IAM binding imports use space-delimited identifiers: the resource in question and the role, e.g.

```sh
$ pulumi import gcp:dataplex/entryTypeIamPolicy:EntryTypeIamPolicy editor "projects/{{project}}/locations/{{location}}/entryTypes/{{entry_type_id}} roles/viewer"
```

IAM policy imports use the identifier of the resource in question, e.g.

```sh
$ pulumi import gcp:dataplex/entryTypeIamPolicy:EntryTypeIamPolicy editor projects/{{project}}/locations/{{location}}/entryTypes/{{entry_type_id}}
```

-> **Custom Roles** If you're importing a IAM resource with a custom role, make sure to use the

 full name of the custom role, e.g. `[projects/my-project|organizations/my-org]/roles/my-custom-role`.


entryTypeId" ×
locationB" ÄThe location where entry type will be created in.
Used to find the parent resource to bind the IAM policy to. If not specified,
the value will be parsed from the identifier of the parent resource. If no location is provided in the parent identifier and no
location is specified, it is taken from the provider configuration.
_

policyData" MThe policy data generated by
a `gcp.organizations.getIAMPolicy` data source.

projectB" The ID of the project in which the resource belongs.
If it is not provided, the project will be parsed from the identifier of the parent resource. If no project is provided in the parent identifier and no project is specified, the provider project is used.
"
entryTypeId" "3
etag" '(Computed) The etag of the IAM policy.
"Õ
location" ÄThe location where entry type will be created in.
Used to find the parent resource to bind the IAM policy to. If not specified,
the value will be parsed from the identifier of the parent resource. If no location is provided in the parent identifier and no
location is specified, it is taken from the provider configuration.
"_

policyData" MThe policy data generated by
a `gcp.organizations.getIAMPolicy` data source.
"
project" The ID of the project in which the resource belongs.
If it is not provided, the project will be parsed from the identifier of the parent resource. If no project is provided in the parent identifier and no project is specified, the provider project is used.
*ç0
(
dataplexLakegcp:dataplex/lake:LakeÙThe Dataplex Lake resource

## Example Usage

### Basic_lake
A basic example of a dataplex lake
<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const primary = new gcp.dataplex.Lake("primary", {
    location: "us-west1",
    name: "lake",
    description: "Lake for DCL",
    displayName: "Lake for DCL",
    project: "my-project-name",
    labels: {
        "my-lake": "exists",
    },
});
```
```python
import pulumi
import pulumi_gcp as gcp

primary = gcp.dataplex.Lake("primary",
    location="us-west1",
    name="lake",
    description="Lake for DCL",
    display_name="Lake for DCL",
    project="my-project-name",
    labels={
        "my-lake": "exists",
    })
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var primary = new Gcp.DataPlex.Lake("primary", new()
    {
        Location = "us-west1",
        Name = "lake",
        Description = "Lake for DCL",
        DisplayName = "Lake for DCL",
        Project = "my-project-name",
        Labels = 
        {
            { "my-lake", "exists" },
        },
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/dataplex"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		_, err := dataplex.NewLake(ctx, "primary", &dataplex.LakeArgs{
			Location:    pulumi.String("us-west1"),
			Name:        pulumi.String("lake"),
			Description: pulumi.String("Lake for DCL"),
			DisplayName: pulumi.String("Lake for DCL"),
			Project:     pulumi.String("my-project-name"),
			Labels: pulumi.StringMap{
				"my-lake": pulumi.String("exists"),
			},
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.dataplex.Lake;
import com.pulumi.gcp.dataplex.LakeArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        var primary = new Lake("primary", LakeArgs.builder()
            .location("us-west1")
            .name("lake")
            .description("Lake for DCL")
            .displayName("Lake for DCL")
            .project("my-project-name")
            .labels(Map.of("my-lake", "exists"))
            .build());

    }
}
```
```yaml
resources:
  primary:
    type: gcp:dataplex:Lake
    properties:
      location: us-west1
      name: lake
      description: Lake for DCL
      displayName: Lake for DCL
      project: my-project-name
      labels:
        my-lake: exists
```
<!--End PulumiCodeChooser -->

## Import

Lake can be imported using any of these accepted formats:

* `projects/{{project}}/locations/{{location}}/lakes/{{name}}`

* `{{project}}/{{location}}/{{name}}`

* `{{location}}/{{name}}`

When using the `pulumi import` command, Lake can be imported using one of the formats above. For example:

```sh
$ pulumi import gcp:dataplex/lake:Lake default projects/{{project}}/locations/{{location}}/lakes/{{name}}
```

```sh
$ pulumi import gcp:dataplex/lake:Lake default {{project}}/{{location}}/{{name}}
```

```sh
$ pulumi import gcp:dataplex/lake:Lake default {{location}}/{{name}}
```

8
descriptionB" #Optional. Description of the lake.
;
displayNameB" &Optional. User friendly display name.

labelsB2" óOptional. User-defined labels for the lake.

**Note**: This field is non-authoritative, and will only manage the labels present in your configuration.
Please refer to the field `effective_labels` for all of the labels present on the resource.
.
location" The location for the resource
¯
	metastoreIBG:E
C
dataplexLakeMetastore(gcp:dataplex/LakeMetastore:LakeMetastoreWOptional. Settings to manage lake and Dataproc Metastore service instance association.
-
nameB" The name of the lake.



- - -
.
projectB" The project for the resource
"§
assetStatusesO*M:K
I
dataplexLakeAssetStatus,gcp:dataplex/LakeAssetStatus:LakeAssetStatusEOutput only. Aggregated status of the underlying assets of the lake.
"C

createTime" 1Output only. The time when the lake was created.
"8
descriptionB" #Optional. Description of the lake.
";
displayNameB" &Optional. User friendly display name.
"¦
effectiveLabels2" All of labels (key/value pairs) present on the resource in GCP, including the labels configured through Pulumi, other clients and services.
"
labelsB2" óOptional. User-defined labels for the lake.

**Note**: This field is non-authoritative, and will only manage the labels present in your configuration.
Please refer to the field `effective_labels` for all of the labels present on the resource.
".
location" The location for the resource
"¯
	metastoreIBG:E
C
dataplexLakeMetastore(gcp:dataplex/LakeMetastore:LakeMetastoreWOptional. Settings to manage lake and Dataproc Metastore service instance association.
"
metastoreStatuses[*Y:W
U
dataplexLakeMetastoreStatus4gcp:dataplex/LakeMetastoreStatus:LakeMetastoreStatus+Output only. Metastore status of the lake.
"+
name" The name of the lake.



- - -
",
project" The project for the resource
"
pulumiLabels2" mThe combination of labels configured directly on the resource and default labels configured on the provider.
"®
serviceAccount" Output only. Service account associated with this lake. This service account must be authorized to access or operate on resources managed by the lake.
"
state" xOutput only. Current state of the lake. Possible values: STATE_UNSPECIFIED, ACTIVE, CREATING, DELETING, ACTION_REQUIRED
"
uid" Output only. System generated globally unique ID for the lake. This ID will be different if the lake is deleted and re-created with the same name.
"H

updateTime" 6Output only. The time when the lake was last updated.
*ÅÔ
F
dataplexLakeIamBinding*gcp:dataplex/lakeIamBinding:LakeIamBindingµThree different resources help you manage your IAM policy for Dataplex Lake. Each of these resources serves a different use case:

* `gcp.dataplex.LakeIamPolicy`: Authoritative. Sets the IAM policy for the lake and replaces any existing policy already attached.
* `gcp.dataplex.LakeIamBinding`: Authoritative for a given role. Updates the IAM policy to grant a role to a list of members. Other roles within the IAM policy for the lake are preserved.
* `gcp.dataplex.LakeIamMember`: Non-authoritative. Updates the IAM policy to grant a role to a new member. Other members for the role for the lake are preserved.

A data source can be used to retrieve policy data in advent you do not need creation

* `gcp.dataplex.LakeIamPolicy`: Retrieves the IAM policy for the lake

> **Note:** `gcp.dataplex.LakeIamPolicy` **cannot** be used in conjunction with `gcp.dataplex.LakeIamBinding` and `gcp.dataplex.LakeIamMember` or they will fight over what your policy should be.

> **Note:** `gcp.dataplex.LakeIamBinding` resources **can be** used in conjunction with `gcp.dataplex.LakeIamMember` resources **only if** they do not grant privilege to the same role.



## gcp.dataplex.LakeIamPolicy

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const admin = gcp.organizations.getIAMPolicy({
    bindings: [{
        role: "roles/viewer",
        members: ["user:jane@example.com"],
    }],
});
const policy = new gcp.dataplex.LakeIamPolicy("policy", {
    project: example.project,
    location: example.location,
    lake: example.name,
    policyData: admin.then(admin => admin.policyData),
});
```
```python
import pulumi
import pulumi_gcp as gcp

admin = gcp.organizations.get_iam_policy(bindings=[{
    "role": "roles/viewer",
    "members": ["user:jane@example.com"],
}])
policy = gcp.dataplex.LakeIamPolicy("policy",
    project=example["project"],
    location=example["location"],
    lake=example["name"],
    policy_data=admin.policy_data)
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var admin = Gcp.Organizations.GetIAMPolicy.Invoke(new()
    {
        Bindings = new[]
        {
            new Gcp.Organizations.Inputs.GetIAMPolicyBindingInputArgs
            {
                Role = "roles/viewer",
                Members = new[]
                {
                    "user:jane@example.com",
                },
            },
        },
    });

    var policy = new Gcp.DataPlex.LakeIamPolicy("policy", new()
    {
        Project = example.Project,
        Location = example.Location,
        Lake = example.Name,
        PolicyData = admin.Apply(getIAMPolicyResult => getIAMPolicyResult.PolicyData),
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/dataplex"
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/organizations"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		admin, err := organizations.LookupIAMPolicy(ctx, &organizations.LookupIAMPolicyArgs{
			Bindings: []organizations.GetIAMPolicyBinding{
				{
					Role: "roles/viewer",
					Members: []string{
						"user:jane@example.com",
					},
				},
			},
		}, nil)
		if err != nil {
			return err
		}
		_, err = dataplex.NewLakeIamPolicy(ctx, "policy", &dataplex.LakeIamPolicyArgs{
			Project:    pulumi.Any(example.Project),
			Location:   pulumi.Any(example.Location),
			Lake:       pulumi.Any(example.Name),
			PolicyData: pulumi.String(admin.PolicyData),
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.organizations.OrganizationsFunctions;
import com.pulumi.gcp.organizations.inputs.GetIAMPolicyArgs;
import com.pulumi.gcp.dataplex.LakeIamPolicy;
import com.pulumi.gcp.dataplex.LakeIamPolicyArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        final var admin = OrganizationsFunctions.getIAMPolicy(GetIAMPolicyArgs.builder()
            .bindings(GetIAMPolicyBindingArgs.builder()
                .role("roles/viewer")
                .members("user:jane@example.com")
                .build())
            .build());

        var policy = new LakeIamPolicy("policy", LakeIamPolicyArgs.builder()
            .project(example.project())
            .location(example.location())
            .lake(example.name())
            .policyData(admin.applyValue(getIAMPolicyResult -> getIAMPolicyResult.policyData()))
            .build());

    }
}
```
```yaml
resources:
  policy:
    type: gcp:dataplex:LakeIamPolicy
    properties:
      project: ${example.project}
      location: ${example.location}
      lake: ${example.name}
      policyData: ${admin.policyData}
variables:
  admin:
    fn::invoke:
      function: gcp:organizations:getIAMPolicy
      arguments:
        bindings:
          - role: roles/viewer
            members:
              - user:jane@example.com
```
<!--End PulumiCodeChooser -->

## gcp.dataplex.LakeIamBinding

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const binding = new gcp.dataplex.LakeIamBinding("binding", {
    project: example.project,
    location: example.location,
    lake: example.name,
    role: "roles/viewer",
    members: ["user:jane@example.com"],
});
```
```python
import pulumi
import pulumi_gcp as gcp

binding = gcp.dataplex.LakeIamBinding("binding",
    project=example["project"],
    location=example["location"],
    lake=example["name"],
    role="roles/viewer",
    members=["user:jane@example.com"])
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var binding = new Gcp.DataPlex.LakeIamBinding("binding", new()
    {
        Project = example.Project,
        Location = example.Location,
        Lake = example.Name,
        Role = "roles/viewer",
        Members = new[]
        {
            "user:jane@example.com",
        },
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/dataplex"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		_, err := dataplex.NewLakeIamBinding(ctx, "binding", &dataplex.LakeIamBindingArgs{
			Project:  pulumi.Any(example.Project),
			Location: pulumi.Any(example.Location),
			Lake:     pulumi.Any(example.Name),
			Role:     pulumi.String("roles/viewer"),
			Members: pulumi.StringArray{
				pulumi.String("user:jane@example.com"),
			},
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.dataplex.LakeIamBinding;
import com.pulumi.gcp.dataplex.LakeIamBindingArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        var binding = new LakeIamBinding("binding", LakeIamBindingArgs.builder()
            .project(example.project())
            .location(example.location())
            .lake(example.name())
            .role("roles/viewer")
            .members("user:jane@example.com")
            .build());

    }
}
```
```yaml
resources:
  binding:
    type: gcp:dataplex:LakeIamBinding
    properties:
      project: ${example.project}
      location: ${example.location}
      lake: ${example.name}
      role: roles/viewer
      members:
        - user:jane@example.com
```
<!--End PulumiCodeChooser -->

## gcp.dataplex.LakeIamMember

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const member = new gcp.dataplex.LakeIamMember("member", {
    project: example.project,
    location: example.location,
    lake: example.name,
    role: "roles/viewer",
    member: "user:jane@example.com",
});
```
```python
import pulumi
import pulumi_gcp as gcp

member = gcp.dataplex.LakeIamMember("member",
    project=example["project"],
    location=example["location"],
    lake=example["name"],
    role="roles/viewer",
    member="user:jane@example.com")
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var member = new Gcp.DataPlex.LakeIamMember("member", new()
    {
        Project = example.Project,
        Location = example.Location,
        Lake = example.Name,
        Role = "roles/viewer",
        Member = "user:jane@example.com",
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/dataplex"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		_, err := dataplex.NewLakeIamMember(ctx, "member", &dataplex.LakeIamMemberArgs{
			Project:  pulumi.Any(example.Project),
			Location: pulumi.Any(example.Location),
			Lake:     pulumi.Any(example.Name),
			Role:     pulumi.String("roles/viewer"),
			Member:   pulumi.String("user:jane@example.com"),
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.dataplex.LakeIamMember;
import com.pulumi.gcp.dataplex.LakeIamMemberArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        var member = new LakeIamMember("member", LakeIamMemberArgs.builder()
            .project(example.project())
            .location(example.location())
            .lake(example.name())
            .role("roles/viewer")
            .member("user:jane@example.com")
            .build());

    }
}
```
```yaml
resources:
  member:
    type: gcp:dataplex:LakeIamMember
    properties:
      project: ${example.project}
      location: ${example.location}
      lake: ${example.name}
      role: roles/viewer
      member: user:jane@example.com
```
<!--End PulumiCodeChooser -->


## This resource supports User Project Overrides.

-

# IAM policy for Dataplex Lake
Three different resources help you manage your IAM policy for Dataplex Lake. Each of these resources serves a different use case:

* `gcp.dataplex.LakeIamPolicy`: Authoritative. Sets the IAM policy for the lake and replaces any existing policy already attached.
* `gcp.dataplex.LakeIamBinding`: Authoritative for a given role. Updates the IAM policy to grant a role to a list of members. Other roles within the IAM policy for the lake are preserved.
* `gcp.dataplex.LakeIamMember`: Non-authoritative. Updates the IAM policy to grant a role to a new member. Other members for the role for the lake are preserved.

A data source can be used to retrieve policy data in advent you do not need creation

* `gcp.dataplex.LakeIamPolicy`: Retrieves the IAM policy for the lake

> **Note:** `gcp.dataplex.LakeIamPolicy` **cannot** be used in conjunction with `gcp.dataplex.LakeIamBinding` and `gcp.dataplex.LakeIamMember` or they will fight over what your policy should be.

> **Note:** `gcp.dataplex.LakeIamBinding` resources **can be** used in conjunction with `gcp.dataplex.LakeIamMember` resources **only if** they do not grant privilege to the same role.



## gcp.dataplex.LakeIamPolicy

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const admin = gcp.organizations.getIAMPolicy({
    bindings: [{
        role: "roles/viewer",
        members: ["user:jane@example.com"],
    }],
});
const policy = new gcp.dataplex.LakeIamPolicy("policy", {
    project: example.project,
    location: example.location,
    lake: example.name,
    policyData: admin.then(admin => admin.policyData),
});
```
```python
import pulumi
import pulumi_gcp as gcp

admin = gcp.organizations.get_iam_policy(bindings=[{
    "role": "roles/viewer",
    "members": ["user:jane@example.com"],
}])
policy = gcp.dataplex.LakeIamPolicy("policy",
    project=example["project"],
    location=example["location"],
    lake=example["name"],
    policy_data=admin.policy_data)
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var admin = Gcp.Organizations.GetIAMPolicy.Invoke(new()
    {
        Bindings = new[]
        {
            new Gcp.Organizations.Inputs.GetIAMPolicyBindingInputArgs
            {
                Role = "roles/viewer",
                Members = new[]
                {
                    "user:jane@example.com",
                },
            },
        },
    });

    var policy = new Gcp.DataPlex.LakeIamPolicy("policy", new()
    {
        Project = example.Project,
        Location = example.Location,
        Lake = example.Name,
        PolicyData = admin.Apply(getIAMPolicyResult => getIAMPolicyResult.PolicyData),
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/dataplex"
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/organizations"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		admin, err := organizations.LookupIAMPolicy(ctx, &organizations.LookupIAMPolicyArgs{
			Bindings: []organizations.GetIAMPolicyBinding{
				{
					Role: "roles/viewer",
					Members: []string{
						"user:jane@example.com",
					},
				},
			},
		}, nil)
		if err != nil {
			return err
		}
		_, err = dataplex.NewLakeIamPolicy(ctx, "policy", &dataplex.LakeIamPolicyArgs{
			Project:    pulumi.Any(example.Project),
			Location:   pulumi.Any(example.Location),
			Lake:       pulumi.Any(example.Name),
			PolicyData: pulumi.String(admin.PolicyData),
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.organizations.OrganizationsFunctions;
import com.pulumi.gcp.organizations.inputs.GetIAMPolicyArgs;
import com.pulumi.gcp.dataplex.LakeIamPolicy;
import com.pulumi.gcp.dataplex.LakeIamPolicyArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        final var admin = OrganizationsFunctions.getIAMPolicy(GetIAMPolicyArgs.builder()
            .bindings(GetIAMPolicyBindingArgs.builder()
                .role("roles/viewer")
                .members("user:jane@example.com")
                .build())
            .build());

        var policy = new LakeIamPolicy("policy", LakeIamPolicyArgs.builder()
            .project(example.project())
            .location(example.location())
            .lake(example.name())
            .policyData(admin.applyValue(getIAMPolicyResult -> getIAMPolicyResult.policyData()))
            .build());

    }
}
```
```yaml
resources:
  policy:
    type: gcp:dataplex:LakeIamPolicy
    properties:
      project: ${example.project}
      location: ${example.location}
      lake: ${example.name}
      policyData: ${admin.policyData}
variables:
  admin:
    fn::invoke:
      function: gcp:organizations:getIAMPolicy
      arguments:
        bindings:
          - role: roles/viewer
            members:
              - user:jane@example.com
```
<!--End PulumiCodeChooser -->

## gcp.dataplex.LakeIamBinding

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const binding = new gcp.dataplex.LakeIamBinding("binding", {
    project: example.project,
    location: example.location,
    lake: example.name,
    role: "roles/viewer",
    members: ["user:jane@example.com"],
});
```
```python
import pulumi
import pulumi_gcp as gcp

binding = gcp.dataplex.LakeIamBinding("binding",
    project=example["project"],
    location=example["location"],
    lake=example["name"],
    role="roles/viewer",
    members=["user:jane@example.com"])
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var binding = new Gcp.DataPlex.LakeIamBinding("binding", new()
    {
        Project = example.Project,
        Location = example.Location,
        Lake = example.Name,
        Role = "roles/viewer",
        Members = new[]
        {
            "user:jane@example.com",
        },
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/dataplex"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		_, err := dataplex.NewLakeIamBinding(ctx, "binding", &dataplex.LakeIamBindingArgs{
			Project:  pulumi.Any(example.Project),
			Location: pulumi.Any(example.Location),
			Lake:     pulumi.Any(example.Name),
			Role:     pulumi.String("roles/viewer"),
			Members: pulumi.StringArray{
				pulumi.String("user:jane@example.com"),
			},
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.dataplex.LakeIamBinding;
import com.pulumi.gcp.dataplex.LakeIamBindingArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        var binding = new LakeIamBinding("binding", LakeIamBindingArgs.builder()
            .project(example.project())
            .location(example.location())
            .lake(example.name())
            .role("roles/viewer")
            .members("user:jane@example.com")
            .build());

    }
}
```
```yaml
resources:
  binding:
    type: gcp:dataplex:LakeIamBinding
    properties:
      project: ${example.project}
      location: ${example.location}
      lake: ${example.name}
      role: roles/viewer
      members:
        - user:jane@example.com
```
<!--End PulumiCodeChooser -->

## gcp.dataplex.LakeIamMember

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const member = new gcp.dataplex.LakeIamMember("member", {
    project: example.project,
    location: example.location,
    lake: example.name,
    role: "roles/viewer",
    member: "user:jane@example.com",
});
```
```python
import pulumi
import pulumi_gcp as gcp

member = gcp.dataplex.LakeIamMember("member",
    project=example["project"],
    location=example["location"],
    lake=example["name"],
    role="roles/viewer",
    member="user:jane@example.com")
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var member = new Gcp.DataPlex.LakeIamMember("member", new()
    {
        Project = example.Project,
        Location = example.Location,
        Lake = example.Name,
        Role = "roles/viewer",
        Member = "user:jane@example.com",
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/dataplex"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		_, err := dataplex.NewLakeIamMember(ctx, "member", &dataplex.LakeIamMemberArgs{
			Project:  pulumi.Any(example.Project),
			Location: pulumi.Any(example.Location),
			Lake:     pulumi.Any(example.Name),
			Role:     pulumi.String("roles/viewer"),
			Member:   pulumi.String("user:jane@example.com"),
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.dataplex.LakeIamMember;
import com.pulumi.gcp.dataplex.LakeIamMemberArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        var member = new LakeIamMember("member", LakeIamMemberArgs.builder()
            .project(example.project())
            .location(example.location())
            .lake(example.name())
            .role("roles/viewer")
            .member("user:jane@example.com")
            .build());

    }
}
```
```yaml
resources:
  member:
    type: gcp:dataplex:LakeIamMember
    properties:
      project: ${example.project}
      location: ${example.location}
      lake: ${example.name}
      role: roles/viewer
      member: user:jane@example.com
```
<!--End PulumiCodeChooser -->

## Import

For all import syntaxes, the "resource in question" can take any of the following forms:

* projects/{{project}}/locations/{{location}}/lakes/{{name}}

* {{project}}/{{location}}/{{name}}

* {{location}}/{{name}}

* {{name}}

Any variables not passed in the import command will be taken from the provider configuration.

Dataplex lake IAM resources can be imported using the resource identifiers, role, and member.

IAM member imports use space-delimited identifiers: the resource in question, the role, and the member identity, e.g.

```sh
$ pulumi import gcp:dataplex/lakeIamBinding:LakeIamBinding editor "projects/{{project}}/locations/{{location}}/lakes/{{lake}} roles/viewer user:jane@example.com"
```

IAM binding imports use space-delimited identifiers: the resource in question and the role, e.g.

```sh
$ pulumi import gcp:dataplex/lakeIamBinding:LakeIamBinding editor "projects/{{project}}/locations/{{location}}/lakes/{{lake}} roles/viewer"
```

IAM policy imports use the identifier of the resource in question, e.g.

```sh
$ pulumi import gcp:dataplex/lakeIamBinding:LakeIamBinding editor projects/{{project}}/locations/{{location}}/lakes/{{lake}}
```

-> **Custom Roles** If you're importing a IAM resource with a custom role, make sure to use the

 full name of the custom role, e.g. `[projects/my-project|organizations/my-org]/roles/my-custom-role`.

t
	conditiongBe:c
a
dataplexLakeIamBindingCondition<gcp:dataplex/LakeIamBindingCondition:LakeIamBindingConditionG
lake" ;Used to find the parent resource to bind the IAM policy to

locationB" Ö	
members*" Ä	Identities that will be granted the privilege in `role`.
Each entry can have one of the following values:
* **allUsers**: A special identifier that represents anyone who is on the internet; with or without a Google account.
* **allAuthenticatedUsers**: A special identifier that represents anyone who is authenticated with a Google account or a service account.
* **user:{emailid}**: An email address that represents a specific Google account. For example, alice@gmail.com or joe@example.com.
* **serviceAccount:{emailid}**: An email address that represents a service account. For example, my-other-app@appspot.gserviceaccount.com.
* **group:{emailid}**: An email address that represents a Google group. For example, admins@example.com.
* **domain:{domain}**: A G Suite domain (primary, instead of alias) name that represents all the users of that domain. For example, google.com or example.com.
* **projectOwner:projectid**: Owners of the given project. For example, "projectOwner:my-example-project"
* **projectEditor:projectid**: Editors of the given project. For example, "projectEditor:my-example-project"
* **projectViewer:projectid**: Viewers of the given project. For example, "projectViewer:my-example-project"

projectB" The ID of the project in which the resource belongs.
If it is not provided, the project will be parsed from the identifier of the parent resource. If no project is provided in the parent identifier and no project is specified, the provider project is used.
Ô
role" ÇThe role that should be applied. Only one
`gcp.dataplex.LakeIamBinding` can be used per role. Note that custom roles must be of the format
`[projects|organizations]/{parent-name}/roles/{role-name}`.
"t
	conditiongBe:c
a
dataplexLakeIamBindingCondition<gcp:dataplex/LakeIamBindingCondition:LakeIamBindingCondition"3
etag" '(Computed) The etag of the IAM policy.
"G
lake" ;Used to find the parent resource to bind the IAM policy to
"
location" "Ö	
members*" Ä	Identities that will be granted the privilege in `role`.
Each entry can have one of the following values:
* **allUsers**: A special identifier that represents anyone who is on the internet; with or without a Google account.
* **allAuthenticatedUsers**: A special identifier that represents anyone who is authenticated with a Google account or a service account.
* **user:{emailid}**: An email address that represents a specific Google account. For example, alice@gmail.com or joe@example.com.
* **serviceAccount:{emailid}**: An email address that represents a service account. For example, my-other-app@appspot.gserviceaccount.com.
* **group:{emailid}**: An email address that represents a Google group. For example, admins@example.com.
* **domain:{domain}**: A G Suite domain (primary, instead of alias) name that represents all the users of that domain. For example, google.com or example.com.
* **projectOwner:projectid**: Owners of the given project. For example, "projectOwner:my-example-project"
* **projectEditor:projectid**: Editors of the given project. For example, "projectEditor:my-example-project"
* **projectViewer:projectid**: Viewers of the given project. For example, "projectViewer:my-example-project"
"
project" The ID of the project in which the resource belongs.
If it is not provided, the project will be parsed from the identifier of the parent resource. If no project is provided in the parent identifier and no project is specified, the provider project is used.
"Ô
role" ÇThe role that should be applied. Only one
`gcp.dataplex.LakeIamBinding` can be used per role. Note that custom roles must be of the format
`[projects|organizations]/{parent-name}/roles/{role-name}`.
*°Ô
C
dataplexLakeIamMember(gcp:dataplex/lakeIamMember:LakeIamMemberµThree different resources help you manage your IAM policy for Dataplex Lake. Each of these resources serves a different use case:

* `gcp.dataplex.LakeIamPolicy`: Authoritative. Sets the IAM policy for the lake and replaces any existing policy already attached.
* `gcp.dataplex.LakeIamBinding`: Authoritative for a given role. Updates the IAM policy to grant a role to a list of members. Other roles within the IAM policy for the lake are preserved.
* `gcp.dataplex.LakeIamMember`: Non-authoritative. Updates the IAM policy to grant a role to a new member. Other members for the role for the lake are preserved.

A data source can be used to retrieve policy data in advent you do not need creation

* `gcp.dataplex.LakeIamPolicy`: Retrieves the IAM policy for the lake

> **Note:** `gcp.dataplex.LakeIamPolicy` **cannot** be used in conjunction with `gcp.dataplex.LakeIamBinding` and `gcp.dataplex.LakeIamMember` or they will fight over what your policy should be.

> **Note:** `gcp.dataplex.LakeIamBinding` resources **can be** used in conjunction with `gcp.dataplex.LakeIamMember` resources **only if** they do not grant privilege to the same role.



## gcp.dataplex.LakeIamPolicy

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const admin = gcp.organizations.getIAMPolicy({
    bindings: [{
        role: "roles/viewer",
        members: ["user:jane@example.com"],
    }],
});
const policy = new gcp.dataplex.LakeIamPolicy("policy", {
    project: example.project,
    location: example.location,
    lake: example.name,
    policyData: admin.then(admin => admin.policyData),
});
```
```python
import pulumi
import pulumi_gcp as gcp

admin = gcp.organizations.get_iam_policy(bindings=[{
    "role": "roles/viewer",
    "members": ["user:jane@example.com"],
}])
policy = gcp.dataplex.LakeIamPolicy("policy",
    project=example["project"],
    location=example["location"],
    lake=example["name"],
    policy_data=admin.policy_data)
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var admin = Gcp.Organizations.GetIAMPolicy.Invoke(new()
    {
        Bindings = new[]
        {
            new Gcp.Organizations.Inputs.GetIAMPolicyBindingInputArgs
            {
                Role = "roles/viewer",
                Members = new[]
                {
                    "user:jane@example.com",
                },
            },
        },
    });

    var policy = new Gcp.DataPlex.LakeIamPolicy("policy", new()
    {
        Project = example.Project,
        Location = example.Location,
        Lake = example.Name,
        PolicyData = admin.Apply(getIAMPolicyResult => getIAMPolicyResult.PolicyData),
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/dataplex"
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/organizations"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		admin, err := organizations.LookupIAMPolicy(ctx, &organizations.LookupIAMPolicyArgs{
			Bindings: []organizations.GetIAMPolicyBinding{
				{
					Role: "roles/viewer",
					Members: []string{
						"user:jane@example.com",
					},
				},
			},
		}, nil)
		if err != nil {
			return err
		}
		_, err = dataplex.NewLakeIamPolicy(ctx, "policy", &dataplex.LakeIamPolicyArgs{
			Project:    pulumi.Any(example.Project),
			Location:   pulumi.Any(example.Location),
			Lake:       pulumi.Any(example.Name),
			PolicyData: pulumi.String(admin.PolicyData),
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.organizations.OrganizationsFunctions;
import com.pulumi.gcp.organizations.inputs.GetIAMPolicyArgs;
import com.pulumi.gcp.dataplex.LakeIamPolicy;
import com.pulumi.gcp.dataplex.LakeIamPolicyArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        final var admin = OrganizationsFunctions.getIAMPolicy(GetIAMPolicyArgs.builder()
            .bindings(GetIAMPolicyBindingArgs.builder()
                .role("roles/viewer")
                .members("user:jane@example.com")
                .build())
            .build());

        var policy = new LakeIamPolicy("policy", LakeIamPolicyArgs.builder()
            .project(example.project())
            .location(example.location())
            .lake(example.name())
            .policyData(admin.applyValue(getIAMPolicyResult -> getIAMPolicyResult.policyData()))
            .build());

    }
}
```
```yaml
resources:
  policy:
    type: gcp:dataplex:LakeIamPolicy
    properties:
      project: ${example.project}
      location: ${example.location}
      lake: ${example.name}
      policyData: ${admin.policyData}
variables:
  admin:
    fn::invoke:
      function: gcp:organizations:getIAMPolicy
      arguments:
        bindings:
          - role: roles/viewer
            members:
              - user:jane@example.com
```
<!--End PulumiCodeChooser -->

## gcp.dataplex.LakeIamBinding

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const binding = new gcp.dataplex.LakeIamBinding("binding", {
    project: example.project,
    location: example.location,
    lake: example.name,
    role: "roles/viewer",
    members: ["user:jane@example.com"],
});
```
```python
import pulumi
import pulumi_gcp as gcp

binding = gcp.dataplex.LakeIamBinding("binding",
    project=example["project"],
    location=example["location"],
    lake=example["name"],
    role="roles/viewer",
    members=["user:jane@example.com"])
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var binding = new Gcp.DataPlex.LakeIamBinding("binding", new()
    {
        Project = example.Project,
        Location = example.Location,
        Lake = example.Name,
        Role = "roles/viewer",
        Members = new[]
        {
            "user:jane@example.com",
        },
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/dataplex"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		_, err := dataplex.NewLakeIamBinding(ctx, "binding", &dataplex.LakeIamBindingArgs{
			Project:  pulumi.Any(example.Project),
			Location: pulumi.Any(example.Location),
			Lake:     pulumi.Any(example.Name),
			Role:     pulumi.String("roles/viewer"),
			Members: pulumi.StringArray{
				pulumi.String("user:jane@example.com"),
			},
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.dataplex.LakeIamBinding;
import com.pulumi.gcp.dataplex.LakeIamBindingArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        var binding = new LakeIamBinding("binding", LakeIamBindingArgs.builder()
            .project(example.project())
            .location(example.location())
            .lake(example.name())
            .role("roles/viewer")
            .members("user:jane@example.com")
            .build());

    }
}
```
```yaml
resources:
  binding:
    type: gcp:dataplex:LakeIamBinding
    properties:
      project: ${example.project}
      location: ${example.location}
      lake: ${example.name}
      role: roles/viewer
      members:
        - user:jane@example.com
```
<!--End PulumiCodeChooser -->

## gcp.dataplex.LakeIamMember

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const member = new gcp.dataplex.LakeIamMember("member", {
    project: example.project,
    location: example.location,
    lake: example.name,
    role: "roles/viewer",
    member: "user:jane@example.com",
});
```
```python
import pulumi
import pulumi_gcp as gcp

member = gcp.dataplex.LakeIamMember("member",
    project=example["project"],
    location=example["location"],
    lake=example["name"],
    role="roles/viewer",
    member="user:jane@example.com")
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var member = new Gcp.DataPlex.LakeIamMember("member", new()
    {
        Project = example.Project,
        Location = example.Location,
        Lake = example.Name,
        Role = "roles/viewer",
        Member = "user:jane@example.com",
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/dataplex"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		_, err := dataplex.NewLakeIamMember(ctx, "member", &dataplex.LakeIamMemberArgs{
			Project:  pulumi.Any(example.Project),
			Location: pulumi.Any(example.Location),
			Lake:     pulumi.Any(example.Name),
			Role:     pulumi.String("roles/viewer"),
			Member:   pulumi.String("user:jane@example.com"),
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.dataplex.LakeIamMember;
import com.pulumi.gcp.dataplex.LakeIamMemberArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        var member = new LakeIamMember("member", LakeIamMemberArgs.builder()
            .project(example.project())
            .location(example.location())
            .lake(example.name())
            .role("roles/viewer")
            .member("user:jane@example.com")
            .build());

    }
}
```
```yaml
resources:
  member:
    type: gcp:dataplex:LakeIamMember
    properties:
      project: ${example.project}
      location: ${example.location}
      lake: ${example.name}
      role: roles/viewer
      member: user:jane@example.com
```
<!--End PulumiCodeChooser -->


## This resource supports User Project Overrides.

-

# IAM policy for Dataplex Lake
Three different resources help you manage your IAM policy for Dataplex Lake. Each of these resources serves a different use case:

* `gcp.dataplex.LakeIamPolicy`: Authoritative. Sets the IAM policy for the lake and replaces any existing policy already attached.
* `gcp.dataplex.LakeIamBinding`: Authoritative for a given role. Updates the IAM policy to grant a role to a list of members. Other roles within the IAM policy for the lake are preserved.
* `gcp.dataplex.LakeIamMember`: Non-authoritative. Updates the IAM policy to grant a role to a new member. Other members for the role for the lake are preserved.

A data source can be used to retrieve policy data in advent you do not need creation

* `gcp.dataplex.LakeIamPolicy`: Retrieves the IAM policy for the lake

> **Note:** `gcp.dataplex.LakeIamPolicy` **cannot** be used in conjunction with `gcp.dataplex.LakeIamBinding` and `gcp.dataplex.LakeIamMember` or they will fight over what your policy should be.

> **Note:** `gcp.dataplex.LakeIamBinding` resources **can be** used in conjunction with `gcp.dataplex.LakeIamMember` resources **only if** they do not grant privilege to the same role.



## gcp.dataplex.LakeIamPolicy

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const admin = gcp.organizations.getIAMPolicy({
    bindings: [{
        role: "roles/viewer",
        members: ["user:jane@example.com"],
    }],
});
const policy = new gcp.dataplex.LakeIamPolicy("policy", {
    project: example.project,
    location: example.location,
    lake: example.name,
    policyData: admin.then(admin => admin.policyData),
});
```
```python
import pulumi
import pulumi_gcp as gcp

admin = gcp.organizations.get_iam_policy(bindings=[{
    "role": "roles/viewer",
    "members": ["user:jane@example.com"],
}])
policy = gcp.dataplex.LakeIamPolicy("policy",
    project=example["project"],
    location=example["location"],
    lake=example["name"],
    policy_data=admin.policy_data)
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var admin = Gcp.Organizations.GetIAMPolicy.Invoke(new()
    {
        Bindings = new[]
        {
            new Gcp.Organizations.Inputs.GetIAMPolicyBindingInputArgs
            {
                Role = "roles/viewer",
                Members = new[]
                {
                    "user:jane@example.com",
                },
            },
        },
    });

    var policy = new Gcp.DataPlex.LakeIamPolicy("policy", new()
    {
        Project = example.Project,
        Location = example.Location,
        Lake = example.Name,
        PolicyData = admin.Apply(getIAMPolicyResult => getIAMPolicyResult.PolicyData),
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/dataplex"
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/organizations"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		admin, err := organizations.LookupIAMPolicy(ctx, &organizations.LookupIAMPolicyArgs{
			Bindings: []organizations.GetIAMPolicyBinding{
				{
					Role: "roles/viewer",
					Members: []string{
						"user:jane@example.com",
					},
				},
			},
		}, nil)
		if err != nil {
			return err
		}
		_, err = dataplex.NewLakeIamPolicy(ctx, "policy", &dataplex.LakeIamPolicyArgs{
			Project:    pulumi.Any(example.Project),
			Location:   pulumi.Any(example.Location),
			Lake:       pulumi.Any(example.Name),
			PolicyData: pulumi.String(admin.PolicyData),
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.organizations.OrganizationsFunctions;
import com.pulumi.gcp.organizations.inputs.GetIAMPolicyArgs;
import com.pulumi.gcp.dataplex.LakeIamPolicy;
import com.pulumi.gcp.dataplex.LakeIamPolicyArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        final var admin = OrganizationsFunctions.getIAMPolicy(GetIAMPolicyArgs.builder()
            .bindings(GetIAMPolicyBindingArgs.builder()
                .role("roles/viewer")
                .members("user:jane@example.com")
                .build())
            .build());

        var policy = new LakeIamPolicy("policy", LakeIamPolicyArgs.builder()
            .project(example.project())
            .location(example.location())
            .lake(example.name())
            .policyData(admin.applyValue(getIAMPolicyResult -> getIAMPolicyResult.policyData()))
            .build());

    }
}
```
```yaml
resources:
  policy:
    type: gcp:dataplex:LakeIamPolicy
    properties:
      project: ${example.project}
      location: ${example.location}
      lake: ${example.name}
      policyData: ${admin.policyData}
variables:
  admin:
    fn::invoke:
      function: gcp:organizations:getIAMPolicy
      arguments:
        bindings:
          - role: roles/viewer
            members:
              - user:jane@example.com
```
<!--End PulumiCodeChooser -->

## gcp.dataplex.LakeIamBinding

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const binding = new gcp.dataplex.LakeIamBinding("binding", {
    project: example.project,
    location: example.location,
    lake: example.name,
    role: "roles/viewer",
    members: ["user:jane@example.com"],
});
```
```python
import pulumi
import pulumi_gcp as gcp

binding = gcp.dataplex.LakeIamBinding("binding",
    project=example["project"],
    location=example["location"],
    lake=example["name"],
    role="roles/viewer",
    members=["user:jane@example.com"])
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var binding = new Gcp.DataPlex.LakeIamBinding("binding", new()
    {
        Project = example.Project,
        Location = example.Location,
        Lake = example.Name,
        Role = "roles/viewer",
        Members = new[]
        {
            "user:jane@example.com",
        },
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/dataplex"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		_, err := dataplex.NewLakeIamBinding(ctx, "binding", &dataplex.LakeIamBindingArgs{
			Project:  pulumi.Any(example.Project),
			Location: pulumi.Any(example.Location),
			Lake:     pulumi.Any(example.Name),
			Role:     pulumi.String("roles/viewer"),
			Members: pulumi.StringArray{
				pulumi.String("user:jane@example.com"),
			},
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.dataplex.LakeIamBinding;
import com.pulumi.gcp.dataplex.LakeIamBindingArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        var binding = new LakeIamBinding("binding", LakeIamBindingArgs.builder()
            .project(example.project())
            .location(example.location())
            .lake(example.name())
            .role("roles/viewer")
            .members("user:jane@example.com")
            .build());

    }
}
```
```yaml
resources:
  binding:
    type: gcp:dataplex:LakeIamBinding
    properties:
      project: ${example.project}
      location: ${example.location}
      lake: ${example.name}
      role: roles/viewer
      members:
        - user:jane@example.com
```
<!--End PulumiCodeChooser -->

## gcp.dataplex.LakeIamMember

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const member = new gcp.dataplex.LakeIamMember("member", {
    project: example.project,
    location: example.location,
    lake: example.name,
    role: "roles/viewer",
    member: "user:jane@example.com",
});
```
```python
import pulumi
import pulumi_gcp as gcp

member = gcp.dataplex.LakeIamMember("member",
    project=example["project"],
    location=example["location"],
    lake=example["name"],
    role="roles/viewer",
    member="user:jane@example.com")
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var member = new Gcp.DataPlex.LakeIamMember("member", new()
    {
        Project = example.Project,
        Location = example.Location,
        Lake = example.Name,
        Role = "roles/viewer",
        Member = "user:jane@example.com",
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/dataplex"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		_, err := dataplex.NewLakeIamMember(ctx, "member", &dataplex.LakeIamMemberArgs{
			Project:  pulumi.Any(example.Project),
			Location: pulumi.Any(example.Location),
			Lake:     pulumi.Any(example.Name),
			Role:     pulumi.String("roles/viewer"),
			Member:   pulumi.String("user:jane@example.com"),
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.dataplex.LakeIamMember;
import com.pulumi.gcp.dataplex.LakeIamMemberArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        var member = new LakeIamMember("member", LakeIamMemberArgs.builder()
            .project(example.project())
            .location(example.location())
            .lake(example.name())
            .role("roles/viewer")
            .member("user:jane@example.com")
            .build());

    }
}
```
```yaml
resources:
  member:
    type: gcp:dataplex:LakeIamMember
    properties:
      project: ${example.project}
      location: ${example.location}
      lake: ${example.name}
      role: roles/viewer
      member: user:jane@example.com
```
<!--End PulumiCodeChooser -->

## Import

For all import syntaxes, the "resource in question" can take any of the following forms:

* projects/{{project}}/locations/{{location}}/lakes/{{name}}

* {{project}}/{{location}}/{{name}}

* {{location}}/{{name}}

* {{name}}

Any variables not passed in the import command will be taken from the provider configuration.

Dataplex lake IAM resources can be imported using the resource identifiers, role, and member.

IAM member imports use space-delimited identifiers: the resource in question, the role, and the member identity, e.g.

```sh
$ pulumi import gcp:dataplex/lakeIamMember:LakeIamMember editor "projects/{{project}}/locations/{{location}}/lakes/{{lake}} roles/viewer user:jane@example.com"
```

IAM binding imports use space-delimited identifiers: the resource in question and the role, e.g.

```sh
$ pulumi import gcp:dataplex/lakeIamMember:LakeIamMember editor "projects/{{project}}/locations/{{location}}/lakes/{{lake}} roles/viewer"
```

IAM policy imports use the identifier of the resource in question, e.g.

```sh
$ pulumi import gcp:dataplex/lakeIamMember:LakeIamMember editor projects/{{project}}/locations/{{location}}/lakes/{{lake}}
```

-> **Custom Roles** If you're importing a IAM resource with a custom role, make sure to use the

 full name of the custom role, e.g. `[projects/my-project|organizations/my-org]/roles/my-custom-role`.

q
	conditiondBb:`
^
dataplexLakeIamMemberCondition:gcp:dataplex/LakeIamMemberCondition:LakeIamMemberConditionG
lake" ;Used to find the parent resource to bind the IAM policy to

locationB" Ó	
member" Ä	Identities that will be granted the privilege in `role`.
Each entry can have one of the following values:
* **allUsers**: A special identifier that represents anyone who is on the internet; with or without a Google account.
* **allAuthenticatedUsers**: A special identifier that represents anyone who is authenticated with a Google account or a service account.
* **user:{emailid}**: An email address that represents a specific Google account. For example, alice@gmail.com or joe@example.com.
* **serviceAccount:{emailid}**: An email address that represents a service account. For example, my-other-app@appspot.gserviceaccount.com.
* **group:{emailid}**: An email address that represents a Google group. For example, admins@example.com.
* **domain:{domain}**: A G Suite domain (primary, instead of alias) name that represents all the users of that domain. For example, google.com or example.com.
* **projectOwner:projectid**: Owners of the given project. For example, "projectOwner:my-example-project"
* **projectEditor:projectid**: Editors of the given project. For example, "projectEditor:my-example-project"
* **projectViewer:projectid**: Viewers of the given project. For example, "projectViewer:my-example-project"

projectB" The ID of the project in which the resource belongs.
If it is not provided, the project will be parsed from the identifier of the parent resource. If no project is provided in the parent identifier and no project is specified, the provider project is used.
Ô
role" ÇThe role that should be applied. Only one
`gcp.dataplex.LakeIamBinding` can be used per role. Note that custom roles must be of the format
`[projects|organizations]/{parent-name}/roles/{role-name}`.
"q
	conditiondBb:`
^
dataplexLakeIamMemberCondition:gcp:dataplex/LakeIamMemberCondition:LakeIamMemberCondition"3
etag" '(Computed) The etag of the IAM policy.
"G
lake" ;Used to find the parent resource to bind the IAM policy to
"
location" "Ó	
member" Ä	Identities that will be granted the privilege in `role`.
Each entry can have one of the following values:
* **allUsers**: A special identifier that represents anyone who is on the internet; with or without a Google account.
* **allAuthenticatedUsers**: A special identifier that represents anyone who is authenticated with a Google account or a service account.
* **user:{emailid}**: An email address that represents a specific Google account. For example, alice@gmail.com or joe@example.com.
* **serviceAccount:{emailid}**: An email address that represents a service account. For example, my-other-app@appspot.gserviceaccount.com.
* **group:{emailid}**: An email address that represents a Google group. For example, admins@example.com.
* **domain:{domain}**: A G Suite domain (primary, instead of alias) name that represents all the users of that domain. For example, google.com or example.com.
* **projectOwner:projectid**: Owners of the given project. For example, "projectOwner:my-example-project"
* **projectEditor:projectid**: Editors of the given project. For example, "projectEditor:my-example-project"
* **projectViewer:projectid**: Viewers of the given project. For example, "projectViewer:my-example-project"
"
project" The ID of the project in which the resource belongs.
If it is not provided, the project will be parsed from the identifier of the parent resource. If no project is provided in the parent identifier and no project is specified, the provider project is used.
"Ô
role" ÇThe role that should be applied. Only one
`gcp.dataplex.LakeIamBinding` can be used per role. Note that custom roles must be of the format
`[projects|organizations]/{parent-name}/roles/{role-name}`.
*²½
C
dataplexLakeIamPolicy(gcp:dataplex/lakeIamPolicy:LakeIamPolicyµThree different resources help you manage your IAM policy for Dataplex Lake. Each of these resources serves a different use case:

* `gcp.dataplex.LakeIamPolicy`: Authoritative. Sets the IAM policy for the lake and replaces any existing policy already attached.
* `gcp.dataplex.LakeIamBinding`: Authoritative for a given role. Updates the IAM policy to grant a role to a list of members. Other roles within the IAM policy for the lake are preserved.
* `gcp.dataplex.LakeIamMember`: Non-authoritative. Updates the IAM policy to grant a role to a new member. Other members for the role for the lake are preserved.

A data source can be used to retrieve policy data in advent you do not need creation

* `gcp.dataplex.LakeIamPolicy`: Retrieves the IAM policy for the lake

> **Note:** `gcp.dataplex.LakeIamPolicy` **cannot** be used in conjunction with `gcp.dataplex.LakeIamBinding` and `gcp.dataplex.LakeIamMember` or they will fight over what your policy should be.

> **Note:** `gcp.dataplex.LakeIamBinding` resources **can be** used in conjunction with `gcp.dataplex.LakeIamMember` resources **only if** they do not grant privilege to the same role.



## gcp.dataplex.LakeIamPolicy

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const admin = gcp.organizations.getIAMPolicy({
    bindings: [{
        role: "roles/viewer",
        members: ["user:jane@example.com"],
    }],
});
const policy = new gcp.dataplex.LakeIamPolicy("policy", {
    project: example.project,
    location: example.location,
    lake: example.name,
    policyData: admin.then(admin => admin.policyData),
});
```
```python
import pulumi
import pulumi_gcp as gcp

admin = gcp.organizations.get_iam_policy(bindings=[{
    "role": "roles/viewer",
    "members": ["user:jane@example.com"],
}])
policy = gcp.dataplex.LakeIamPolicy("policy",
    project=example["project"],
    location=example["location"],
    lake=example["name"],
    policy_data=admin.policy_data)
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var admin = Gcp.Organizations.GetIAMPolicy.Invoke(new()
    {
        Bindings = new[]
        {
            new Gcp.Organizations.Inputs.GetIAMPolicyBindingInputArgs
            {
                Role = "roles/viewer",
                Members = new[]
                {
                    "user:jane@example.com",
                },
            },
        },
    });

    var policy = new Gcp.DataPlex.LakeIamPolicy("policy", new()
    {
        Project = example.Project,
        Location = example.Location,
        Lake = example.Name,
        PolicyData = admin.Apply(getIAMPolicyResult => getIAMPolicyResult.PolicyData),
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/dataplex"
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/organizations"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		admin, err := organizations.LookupIAMPolicy(ctx, &organizations.LookupIAMPolicyArgs{
			Bindings: []organizations.GetIAMPolicyBinding{
				{
					Role: "roles/viewer",
					Members: []string{
						"user:jane@example.com",
					},
				},
			},
		}, nil)
		if err != nil {
			return err
		}
		_, err = dataplex.NewLakeIamPolicy(ctx, "policy", &dataplex.LakeIamPolicyArgs{
			Project:    pulumi.Any(example.Project),
			Location:   pulumi.Any(example.Location),
			Lake:       pulumi.Any(example.Name),
			PolicyData: pulumi.String(admin.PolicyData),
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.organizations.OrganizationsFunctions;
import com.pulumi.gcp.organizations.inputs.GetIAMPolicyArgs;
import com.pulumi.gcp.dataplex.LakeIamPolicy;
import com.pulumi.gcp.dataplex.LakeIamPolicyArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        final var admin = OrganizationsFunctions.getIAMPolicy(GetIAMPolicyArgs.builder()
            .bindings(GetIAMPolicyBindingArgs.builder()
                .role("roles/viewer")
                .members("user:jane@example.com")
                .build())
            .build());

        var policy = new LakeIamPolicy("policy", LakeIamPolicyArgs.builder()
            .project(example.project())
            .location(example.location())
            .lake(example.name())
            .policyData(admin.applyValue(getIAMPolicyResult -> getIAMPolicyResult.policyData()))
            .build());

    }
}
```
```yaml
resources:
  policy:
    type: gcp:dataplex:LakeIamPolicy
    properties:
      project: ${example.project}
      location: ${example.location}
      lake: ${example.name}
      policyData: ${admin.policyData}
variables:
  admin:
    fn::invoke:
      function: gcp:organizations:getIAMPolicy
      arguments:
        bindings:
          - role: roles/viewer
            members:
              - user:jane@example.com
```
<!--End PulumiCodeChooser -->

## gcp.dataplex.LakeIamBinding

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const binding = new gcp.dataplex.LakeIamBinding("binding", {
    project: example.project,
    location: example.location,
    lake: example.name,
    role: "roles/viewer",
    members: ["user:jane@example.com"],
});
```
```python
import pulumi
import pulumi_gcp as gcp

binding = gcp.dataplex.LakeIamBinding("binding",
    project=example["project"],
    location=example["location"],
    lake=example["name"],
    role="roles/viewer",
    members=["user:jane@example.com"])
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var binding = new Gcp.DataPlex.LakeIamBinding("binding", new()
    {
        Project = example.Project,
        Location = example.Location,
        Lake = example.Name,
        Role = "roles/viewer",
        Members = new[]
        {
            "user:jane@example.com",
        },
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/dataplex"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		_, err := dataplex.NewLakeIamBinding(ctx, "binding", &dataplex.LakeIamBindingArgs{
			Project:  pulumi.Any(example.Project),
			Location: pulumi.Any(example.Location),
			Lake:     pulumi.Any(example.Name),
			Role:     pulumi.String("roles/viewer"),
			Members: pulumi.StringArray{
				pulumi.String("user:jane@example.com"),
			},
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.dataplex.LakeIamBinding;
import com.pulumi.gcp.dataplex.LakeIamBindingArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        var binding = new LakeIamBinding("binding", LakeIamBindingArgs.builder()
            .project(example.project())
            .location(example.location())
            .lake(example.name())
            .role("roles/viewer")
            .members("user:jane@example.com")
            .build());

    }
}
```
```yaml
resources:
  binding:
    type: gcp:dataplex:LakeIamBinding
    properties:
      project: ${example.project}
      location: ${example.location}
      lake: ${example.name}
      role: roles/viewer
      members:
        - user:jane@example.com
```
<!--End PulumiCodeChooser -->

## gcp.dataplex.LakeIamMember

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const member = new gcp.dataplex.LakeIamMember("member", {
    project: example.project,
    location: example.location,
    lake: example.name,
    role: "roles/viewer",
    member: "user:jane@example.com",
});
```
```python
import pulumi
import pulumi_gcp as gcp

member = gcp.dataplex.LakeIamMember("member",
    project=example["project"],
    location=example["location"],
    lake=example["name"],
    role="roles/viewer",
    member="user:jane@example.com")
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var member = new Gcp.DataPlex.LakeIamMember("member", new()
    {
        Project = example.Project,
        Location = example.Location,
        Lake = example.Name,
        Role = "roles/viewer",
        Member = "user:jane@example.com",
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/dataplex"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		_, err := dataplex.NewLakeIamMember(ctx, "member", &dataplex.LakeIamMemberArgs{
			Project:  pulumi.Any(example.Project),
			Location: pulumi.Any(example.Location),
			Lake:     pulumi.Any(example.Name),
			Role:     pulumi.String("roles/viewer"),
			Member:   pulumi.String("user:jane@example.com"),
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.dataplex.LakeIamMember;
import com.pulumi.gcp.dataplex.LakeIamMemberArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        var member = new LakeIamMember("member", LakeIamMemberArgs.builder()
            .project(example.project())
            .location(example.location())
            .lake(example.name())
            .role("roles/viewer")
            .member("user:jane@example.com")
            .build());

    }
}
```
```yaml
resources:
  member:
    type: gcp:dataplex:LakeIamMember
    properties:
      project: ${example.project}
      location: ${example.location}
      lake: ${example.name}
      role: roles/viewer
      member: user:jane@example.com
```
<!--End PulumiCodeChooser -->


## This resource supports User Project Overrides.

-

# IAM policy for Dataplex Lake
Three different resources help you manage your IAM policy for Dataplex Lake. Each of these resources serves a different use case:

* `gcp.dataplex.LakeIamPolicy`: Authoritative. Sets the IAM policy for the lake and replaces any existing policy already attached.
* `gcp.dataplex.LakeIamBinding`: Authoritative for a given role. Updates the IAM policy to grant a role to a list of members. Other roles within the IAM policy for the lake are preserved.
* `gcp.dataplex.LakeIamMember`: Non-authoritative. Updates the IAM policy to grant a role to a new member. Other members for the role for the lake are preserved.

A data source can be used to retrieve policy data in advent you do not need creation

* `gcp.dataplex.LakeIamPolicy`: Retrieves the IAM policy for the lake

> **Note:** `gcp.dataplex.LakeIamPolicy` **cannot** be used in conjunction with `gcp.dataplex.LakeIamBinding` and `gcp.dataplex.LakeIamMember` or they will fight over what your policy should be.

> **Note:** `gcp.dataplex.LakeIamBinding` resources **can be** used in conjunction with `gcp.dataplex.LakeIamMember` resources **only if** they do not grant privilege to the same role.



## gcp.dataplex.LakeIamPolicy

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const admin = gcp.organizations.getIAMPolicy({
    bindings: [{
        role: "roles/viewer",
        members: ["user:jane@example.com"],
    }],
});
const policy = new gcp.dataplex.LakeIamPolicy("policy", {
    project: example.project,
    location: example.location,
    lake: example.name,
    policyData: admin.then(admin => admin.policyData),
});
```
```python
import pulumi
import pulumi_gcp as gcp

admin = gcp.organizations.get_iam_policy(bindings=[{
    "role": "roles/viewer",
    "members": ["user:jane@example.com"],
}])
policy = gcp.dataplex.LakeIamPolicy("policy",
    project=example["project"],
    location=example["location"],
    lake=example["name"],
    policy_data=admin.policy_data)
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var admin = Gcp.Organizations.GetIAMPolicy.Invoke(new()
    {
        Bindings = new[]
        {
            new Gcp.Organizations.Inputs.GetIAMPolicyBindingInputArgs
            {
                Role = "roles/viewer",
                Members = new[]
                {
                    "user:jane@example.com",
                },
            },
        },
    });

    var policy = new Gcp.DataPlex.LakeIamPolicy("policy", new()
    {
        Project = example.Project,
        Location = example.Location,
        Lake = example.Name,
        PolicyData = admin.Apply(getIAMPolicyResult => getIAMPolicyResult.PolicyData),
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/dataplex"
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/organizations"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		admin, err := organizations.LookupIAMPolicy(ctx, &organizations.LookupIAMPolicyArgs{
			Bindings: []organizations.GetIAMPolicyBinding{
				{
					Role: "roles/viewer",
					Members: []string{
						"user:jane@example.com",
					},
				},
			},
		}, nil)
		if err != nil {
			return err
		}
		_, err = dataplex.NewLakeIamPolicy(ctx, "policy", &dataplex.LakeIamPolicyArgs{
			Project:    pulumi.Any(example.Project),
			Location:   pulumi.Any(example.Location),
			Lake:       pulumi.Any(example.Name),
			PolicyData: pulumi.String(admin.PolicyData),
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.organizations.OrganizationsFunctions;
import com.pulumi.gcp.organizations.inputs.GetIAMPolicyArgs;
import com.pulumi.gcp.dataplex.LakeIamPolicy;
import com.pulumi.gcp.dataplex.LakeIamPolicyArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        final var admin = OrganizationsFunctions.getIAMPolicy(GetIAMPolicyArgs.builder()
            .bindings(GetIAMPolicyBindingArgs.builder()
                .role("roles/viewer")
                .members("user:jane@example.com")
                .build())
            .build());

        var policy = new LakeIamPolicy("policy", LakeIamPolicyArgs.builder()
            .project(example.project())
            .location(example.location())
            .lake(example.name())
            .policyData(admin.applyValue(getIAMPolicyResult -> getIAMPolicyResult.policyData()))
            .build());

    }
}
```
```yaml
resources:
  policy:
    type: gcp:dataplex:LakeIamPolicy
    properties:
      project: ${example.project}
      location: ${example.location}
      lake: ${example.name}
      policyData: ${admin.policyData}
variables:
  admin:
    fn::invoke:
      function: gcp:organizations:getIAMPolicy
      arguments:
        bindings:
          - role: roles/viewer
            members:
              - user:jane@example.com
```
<!--End PulumiCodeChooser -->

## gcp.dataplex.LakeIamBinding

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const binding = new gcp.dataplex.LakeIamBinding("binding", {
    project: example.project,
    location: example.location,
    lake: example.name,
    role: "roles/viewer",
    members: ["user:jane@example.com"],
});
```
```python
import pulumi
import pulumi_gcp as gcp

binding = gcp.dataplex.LakeIamBinding("binding",
    project=example["project"],
    location=example["location"],
    lake=example["name"],
    role="roles/viewer",
    members=["user:jane@example.com"])
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var binding = new Gcp.DataPlex.LakeIamBinding("binding", new()
    {
        Project = example.Project,
        Location = example.Location,
        Lake = example.Name,
        Role = "roles/viewer",
        Members = new[]
        {
            "user:jane@example.com",
        },
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/dataplex"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		_, err := dataplex.NewLakeIamBinding(ctx, "binding", &dataplex.LakeIamBindingArgs{
			Project:  pulumi.Any(example.Project),
			Location: pulumi.Any(example.Location),
			Lake:     pulumi.Any(example.Name),
			Role:     pulumi.String("roles/viewer"),
			Members: pulumi.StringArray{
				pulumi.String("user:jane@example.com"),
			},
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.dataplex.LakeIamBinding;
import com.pulumi.gcp.dataplex.LakeIamBindingArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        var binding = new LakeIamBinding("binding", LakeIamBindingArgs.builder()
            .project(example.project())
            .location(example.location())
            .lake(example.name())
            .role("roles/viewer")
            .members("user:jane@example.com")
            .build());

    }
}
```
```yaml
resources:
  binding:
    type: gcp:dataplex:LakeIamBinding
    properties:
      project: ${example.project}
      location: ${example.location}
      lake: ${example.name}
      role: roles/viewer
      members:
        - user:jane@example.com
```
<!--End PulumiCodeChooser -->

## gcp.dataplex.LakeIamMember

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const member = new gcp.dataplex.LakeIamMember("member", {
    project: example.project,
    location: example.location,
    lake: example.name,
    role: "roles/viewer",
    member: "user:jane@example.com",
});
```
```python
import pulumi
import pulumi_gcp as gcp

member = gcp.dataplex.LakeIamMember("member",
    project=example["project"],
    location=example["location"],
    lake=example["name"],
    role="roles/viewer",
    member="user:jane@example.com")
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var member = new Gcp.DataPlex.LakeIamMember("member", new()
    {
        Project = example.Project,
        Location = example.Location,
        Lake = example.Name,
        Role = "roles/viewer",
        Member = "user:jane@example.com",
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/dataplex"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		_, err := dataplex.NewLakeIamMember(ctx, "member", &dataplex.LakeIamMemberArgs{
			Project:  pulumi.Any(example.Project),
			Location: pulumi.Any(example.Location),
			Lake:     pulumi.Any(example.Name),
			Role:     pulumi.String("roles/viewer"),
			Member:   pulumi.String("user:jane@example.com"),
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.dataplex.LakeIamMember;
import com.pulumi.gcp.dataplex.LakeIamMemberArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        var member = new LakeIamMember("member", LakeIamMemberArgs.builder()
            .project(example.project())
            .location(example.location())
            .lake(example.name())
            .role("roles/viewer")
            .member("user:jane@example.com")
            .build());

    }
}
```
```yaml
resources:
  member:
    type: gcp:dataplex:LakeIamMember
    properties:
      project: ${example.project}
      location: ${example.location}
      lake: ${example.name}
      role: roles/viewer
      member: user:jane@example.com
```
<!--End PulumiCodeChooser -->

## Import

For all import syntaxes, the "resource in question" can take any of the following forms:

* projects/{{project}}/locations/{{location}}/lakes/{{name}}

* {{project}}/{{location}}/{{name}}

* {{location}}/{{name}}

* {{name}}

Any variables not passed in the import command will be taken from the provider configuration.

Dataplex lake IAM resources can be imported using the resource identifiers, role, and member.

IAM member imports use space-delimited identifiers: the resource in question, the role, and the member identity, e.g.

```sh
$ pulumi import gcp:dataplex/lakeIamPolicy:LakeIamPolicy editor "projects/{{project}}/locations/{{location}}/lakes/{{lake}} roles/viewer user:jane@example.com"
```

IAM binding imports use space-delimited identifiers: the resource in question and the role, e.g.

```sh
$ pulumi import gcp:dataplex/lakeIamPolicy:LakeIamPolicy editor "projects/{{project}}/locations/{{location}}/lakes/{{lake}} roles/viewer"
```

IAM policy imports use the identifier of the resource in question, e.g.

```sh
$ pulumi import gcp:dataplex/lakeIamPolicy:LakeIamPolicy editor projects/{{project}}/locations/{{location}}/lakes/{{lake}}
```

-> **Custom Roles** If you're importing a IAM resource with a custom role, make sure to use the

 full name of the custom role, e.g. `[projects/my-project|organizations/my-org]/roles/my-custom-role`.

G
lake" ;Used to find the parent resource to bind the IAM policy to

locationB" _

policyData" MThe policy data generated by
a `gcp.organizations.getIAMPolicy` data source.

projectB" The ID of the project in which the resource belongs.
If it is not provided, the project will be parsed from the identifier of the parent resource. If no project is provided in the parent identifier and no project is specified, the provider project is used.
"3
etag" '(Computed) The etag of the IAM policy.
"G
lake" ;Used to find the parent resource to bind the IAM policy to
"
location" "_

policyData" MThe policy data generated by
a `gcp.organizations.getIAMPolicy` data source.
"
project" The ID of the project in which the resource belongs.
If it is not provided, the project will be parsed from the identifier of the parent resource. If no project is provided in the parent identifier and no project is specified, the provider project is used.
*Ø
(
dataplexTaskgcp:dataplex/task:Task¼A Dataplex task represents the work that you want Dataplex to do on a schedule. It encapsulates code, parameters, and the schedule.


To get more information about Task, see:

* [API documentation](https://cloud.google.com/dataplex/docs/reference/rest/v1/projects.locations.lakes.tasks)
* How-to Guides
    * [Official Documentation](https://cloud.google.com/dataplex/docs)

## Example Usage

### Dataplex Task Basic


<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const project = gcp.organizations.getProject({});
const example = new gcp.dataplex.Lake("example", {
    name: "tf-test-lake_91042",
    location: "us-central1",
    project: "my-project-name",
});
const exampleTask = new gcp.dataplex.Task("example", {
    taskId: "tf-test-task_72490",
    location: "us-central1",
    lake: example.name,
    description: "Test Task Basic",
    displayName: "task-basic",
    labels: {
        count: "3",
    },
    triggerSpec: {
        type: "RECURRING",
        disabled: false,
        maxRetries: 3,
        startTime: "2023-10-02T15:01:23Z",
        schedule: "1 * * * *",
    },
    executionSpec: {
        serviceAccount: project.then(project => `${project.number}-compute@developer.gserviceaccount.com`),
        project: "my-project-name",
        maxJobExecutionLifetime: "100s",
        kmsKey: "234jn2kjn42k3n423",
    },
    spark: {
        pythonScriptFile: "gs://dataproc-examples/pyspark/hello-world/hello-world.py",
    },
    project: "my-project-name",
});
```
```python
import pulumi
import pulumi_gcp as gcp

project = gcp.organizations.get_project()
example = gcp.dataplex.Lake("example",
    name="tf-test-lake_91042",
    location="us-central1",
    project="my-project-name")
example_task = gcp.dataplex.Task("example",
    task_id="tf-test-task_72490",
    location="us-central1",
    lake=example.name,
    description="Test Task Basic",
    display_name="task-basic",
    labels={
        "count": "3",
    },
    trigger_spec={
        "type": "RECURRING",
        "disabled": False,
        "max_retries": 3,
        "start_time": "2023-10-02T15:01:23Z",
        "schedule": "1 * * * *",
    },
    execution_spec={
        "service_account": f"{project.number}-compute@developer.gserviceaccount.com",
        "project": "my-project-name",
        "max_job_execution_lifetime": "100s",
        "kms_key": "234jn2kjn42k3n423",
    },
    spark={
        "python_script_file": "gs://dataproc-examples/pyspark/hello-world/hello-world.py",
    },
    project="my-project-name")
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var project = Gcp.Organizations.GetProject.Invoke();

    var example = new Gcp.DataPlex.Lake("example", new()
    {
        Name = "tf-test-lake_91042",
        Location = "us-central1",
        Project = "my-project-name",
    });

    var exampleTask = new Gcp.DataPlex.Task("example", new()
    {
        TaskId = "tf-test-task_72490",
        Location = "us-central1",
        Lake = example.Name,
        Description = "Test Task Basic",
        DisplayName = "task-basic",
        Labels = 
        {
            { "count", "3" },
        },
        TriggerSpec = new Gcp.DataPlex.Inputs.TaskTriggerSpecArgs
        {
            Type = "RECURRING",
            Disabled = false,
            MaxRetries = 3,
            StartTime = "2023-10-02T15:01:23Z",
            Schedule = "1 * * * *",
        },
        ExecutionSpec = new Gcp.DataPlex.Inputs.TaskExecutionSpecArgs
        {
            ServiceAccount = $"{project.Apply(getProjectResult => getProjectResult.Number)}-compute@developer.gserviceaccount.com",
            Project = "my-project-name",
            MaxJobExecutionLifetime = "100s",
            KmsKey = "234jn2kjn42k3n423",
        },
        Spark = new Gcp.DataPlex.Inputs.TaskSparkArgs
        {
            PythonScriptFile = "gs://dataproc-examples/pyspark/hello-world/hello-world.py",
        },
        Project = "my-project-name",
    });

});
```
```go
package main

import (
	"fmt"

	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/dataplex"
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/organizations"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		project, err := organizations.LookupProject(ctx, &organizations.LookupProjectArgs{}, nil)
		if err != nil {
			return err
		}
		example, err := dataplex.NewLake(ctx, "example", &dataplex.LakeArgs{
			Name:     pulumi.String("tf-test-lake_91042"),
			Location: pulumi.String("us-central1"),
			Project:  pulumi.String("my-project-name"),
		})
		if err != nil {
			return err
		}
		_, err = dataplex.NewTask(ctx, "example", &dataplex.TaskArgs{
			TaskId:      pulumi.String("tf-test-task_72490"),
			Location:    pulumi.String("us-central1"),
			Lake:        example.Name,
			Description: pulumi.String("Test Task Basic"),
			DisplayName: pulumi.String("task-basic"),
			Labels: pulumi.StringMap{
				"count": pulumi.String("3"),
			},
			TriggerSpec: &dataplex.TaskTriggerSpecArgs{
				Type:       pulumi.String("RECURRING"),
				Disabled:   pulumi.Bool(false),
				MaxRetries: pulumi.Int(3),
				StartTime:  pulumi.String("2023-10-02T15:01:23Z"),
				Schedule:   pulumi.String("1 * * * *"),
			},
			ExecutionSpec: &dataplex.TaskExecutionSpecArgs{
				ServiceAccount:          pulumi.Sprintf("%v-compute@developer.gserviceaccount.com", project.Number),
				Project:                 pulumi.String("my-project-name"),
				MaxJobExecutionLifetime: pulumi.String("100s"),
				KmsKey:                  pulumi.String("234jn2kjn42k3n423"),
			},
			Spark: &dataplex.TaskSparkArgs{
				PythonScriptFile: pulumi.String("gs://dataproc-examples/pyspark/hello-world/hello-world.py"),
			},
			Project: pulumi.String("my-project-name"),
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.organizations.OrganizationsFunctions;
import com.pulumi.gcp.organizations.inputs.GetProjectArgs;
import com.pulumi.gcp.dataplex.Lake;
import com.pulumi.gcp.dataplex.LakeArgs;
import com.pulumi.gcp.dataplex.Task;
import com.pulumi.gcp.dataplex.TaskArgs;
import com.pulumi.gcp.dataplex.inputs.TaskTriggerSpecArgs;
import com.pulumi.gcp.dataplex.inputs.TaskExecutionSpecArgs;
import com.pulumi.gcp.dataplex.inputs.TaskSparkArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        final var project = OrganizationsFunctions.getProject();

        var example = new Lake("example", LakeArgs.builder()
            .name("tf-test-lake_91042")
            .location("us-central1")
            .project("my-project-name")
            .build());

        var exampleTask = new Task("exampleTask", TaskArgs.builder()
            .taskId("tf-test-task_72490")
            .location("us-central1")
            .lake(example.name())
            .description("Test Task Basic")
            .displayName("task-basic")
            .labels(Map.of("count", "3"))
            .triggerSpec(TaskTriggerSpecArgs.builder()
                .type("RECURRING")
                .disabled(false)
                .maxRetries(3)
                .startTime("2023-10-02T15:01:23Z")
                .schedule("1 * * * *")
                .build())
            .executionSpec(TaskExecutionSpecArgs.builder()
                .serviceAccount(String.format("%s-compute@developer.gserviceaccount.com", project.applyValue(getProjectResult -> getProjectResult.number())))
                .project("my-project-name")
                .maxJobExecutionLifetime("100s")
                .kmsKey("234jn2kjn42k3n423")
                .build())
            .spark(TaskSparkArgs.builder()
                .pythonScriptFile("gs://dataproc-examples/pyspark/hello-world/hello-world.py")
                .build())
            .project("my-project-name")
            .build());

    }
}
```
```yaml
resources:
  example:
    type: gcp:dataplex:Lake
    properties:
      name: tf-test-lake_91042
      location: us-central1
      project: my-project-name
  exampleTask:
    type: gcp:dataplex:Task
    name: example
    properties:
      taskId: tf-test-task_72490
      location: us-central1
      lake: ${example.name}
      description: Test Task Basic
      displayName: task-basic
      labels:
        count: '3'
      triggerSpec:
        type: RECURRING
        disabled: false
        maxRetries: 3
        startTime: 2023-10-02T15:01:23Z
        schedule: 1 * * * *
      executionSpec:
        serviceAccount: ${project.number}-compute@developer.gserviceaccount.com
        project: my-project-name
        maxJobExecutionLifetime: 100s
        kmsKey: 234jn2kjn42k3n423
      spark:
        pythonScriptFile: gs://dataproc-examples/pyspark/hello-world/hello-world.py
      project: my-project-name
variables:
  project:
    fn::invoke:
      function: gcp:organizations:getProject
      arguments: {}
```
<!--End PulumiCodeChooser -->
### Dataplex Task Spark


<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

// VPC network
const _default = new gcp.compute.Network("default", {
    name: "tf-test-workstation-cluster_89605",
    autoCreateSubnetworks: true,
});
const project = gcp.organizations.getProject({});
const exampleSpark = new gcp.dataplex.Lake("example_spark", {
    name: "tf-test-lake_56730",
    location: "us-central1",
    project: "my-project-name",
});
const exampleSparkTask = new gcp.dataplex.Task("example_spark", {
    taskId: "tf-test-task_95154",
    location: "us-central1",
    lake: exampleSpark.name,
    triggerSpec: {
        type: "ON_DEMAND",
    },
    description: "task-spark-terraform",
    executionSpec: {
        serviceAccount: project.then(project => `${project.number}-compute@developer.gserviceaccount.com`),
        args: {
            TASK_ARGS: "--output_location,gs://spark-job/task-result, --output_format, json",
        },
    },
    spark: {
        infrastructureSpec: {
            batch: {
                executorsCount: 2,
                maxExecutorsCount: 100,
            },
            containerImage: {
                image: "test-image",
                javaJars: ["test-java-jars.jar"],
                pythonPackages: ["gs://bucket-name/my/path/to/lib.tar.gz"],
                properties: {
                    name: "wrench",
                    mass: "1.3kg",
                    count: "3",
                },
            },
            vpcNetwork: {
                networkTags: ["test-network-tag"],
                subNetwork: _default.id,
            },
        },
        fileUris: ["gs://terrafrom-test/test.csv"],
        archiveUris: ["gs://terraform-test/test.csv"],
        sqlScript: "show databases",
    },
    project: "my-project-name",
});
```
```python
import pulumi
import pulumi_gcp as gcp

# VPC network
default = gcp.compute.Network("default",
    name="tf-test-workstation-cluster_89605",
    auto_create_subnetworks=True)
project = gcp.organizations.get_project()
example_spark = gcp.dataplex.Lake("example_spark",
    name="tf-test-lake_56730",
    location="us-central1",
    project="my-project-name")
example_spark_task = gcp.dataplex.Task("example_spark",
    task_id="tf-test-task_95154",
    location="us-central1",
    lake=example_spark.name,
    trigger_spec={
        "type": "ON_DEMAND",
    },
    description="task-spark-terraform",
    execution_spec={
        "service_account": f"{project.number}-compute@developer.gserviceaccount.com",
        "args": {
            "TASK_ARGS": "--output_location,gs://spark-job/task-result, --output_format, json",
        },
    },
    spark={
        "infrastructure_spec": {
            "batch": {
                "executors_count": 2,
                "max_executors_count": 100,
            },
            "container_image": {
                "image": "test-image",
                "java_jars": ["test-java-jars.jar"],
                "python_packages": ["gs://bucket-name/my/path/to/lib.tar.gz"],
                "properties": {
                    "name": "wrench",
                    "mass": "1.3kg",
                    "count": "3",
                },
            },
            "vpc_network": {
                "network_tags": ["test-network-tag"],
                "sub_network": default.id,
            },
        },
        "file_uris": ["gs://terrafrom-test/test.csv"],
        "archive_uris": ["gs://terraform-test/test.csv"],
        "sql_script": "show databases",
    },
    project="my-project-name")
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    // VPC network
    var @default = new Gcp.Compute.Network("default", new()
    {
        Name = "tf-test-workstation-cluster_89605",
        AutoCreateSubnetworks = true,
    });

    var project = Gcp.Organizations.GetProject.Invoke();

    var exampleSpark = new Gcp.DataPlex.Lake("example_spark", new()
    {
        Name = "tf-test-lake_56730",
        Location = "us-central1",
        Project = "my-project-name",
    });

    var exampleSparkTask = new Gcp.DataPlex.Task("example_spark", new()
    {
        TaskId = "tf-test-task_95154",
        Location = "us-central1",
        Lake = exampleSpark.Name,
        TriggerSpec = new Gcp.DataPlex.Inputs.TaskTriggerSpecArgs
        {
            Type = "ON_DEMAND",
        },
        Description = "task-spark-terraform",
        ExecutionSpec = new Gcp.DataPlex.Inputs.TaskExecutionSpecArgs
        {
            ServiceAccount = $"{project.Apply(getProjectResult => getProjectResult.Number)}-compute@developer.gserviceaccount.com",
            Args = 
            {
                { "TASK_ARGS", "--output_location,gs://spark-job/task-result, --output_format, json" },
            },
        },
        Spark = new Gcp.DataPlex.Inputs.TaskSparkArgs
        {
            InfrastructureSpec = new Gcp.DataPlex.Inputs.TaskSparkInfrastructureSpecArgs
            {
                Batch = new Gcp.DataPlex.Inputs.TaskSparkInfrastructureSpecBatchArgs
                {
                    ExecutorsCount = 2,
                    MaxExecutorsCount = 100,
                },
                ContainerImage = new Gcp.DataPlex.Inputs.TaskSparkInfrastructureSpecContainerImageArgs
                {
                    Image = "test-image",
                    JavaJars = new[]
                    {
                        "test-java-jars.jar",
                    },
                    PythonPackages = new[]
                    {
                        "gs://bucket-name/my/path/to/lib.tar.gz",
                    },
                    Properties = 
                    {
                        { "name", "wrench" },
                        { "mass", "1.3kg" },
                        { "count", "3" },
                    },
                },
                VpcNetwork = new Gcp.DataPlex.Inputs.TaskSparkInfrastructureSpecVpcNetworkArgs
                {
                    NetworkTags = new[]
                    {
                        "test-network-tag",
                    },
                    SubNetwork = @default.Id,
                },
            },
            FileUris = new[]
            {
                "gs://terrafrom-test/test.csv",
            },
            ArchiveUris = new[]
            {
                "gs://terraform-test/test.csv",
            },
            SqlScript = "show databases",
        },
        Project = "my-project-name",
    });

});
```
```go
package main

import (
	"fmt"

	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/compute"
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/dataplex"
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/organizations"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		// VPC network
		_, err := compute.NewNetwork(ctx, "default", &compute.NetworkArgs{
			Name:                  pulumi.String("tf-test-workstation-cluster_89605"),
			AutoCreateSubnetworks: pulumi.Bool(true),
		})
		if err != nil {
			return err
		}
		project, err := organizations.LookupProject(ctx, &organizations.LookupProjectArgs{}, nil)
		if err != nil {
			return err
		}
		exampleSpark, err := dataplex.NewLake(ctx, "example_spark", &dataplex.LakeArgs{
			Name:     pulumi.String("tf-test-lake_56730"),
			Location: pulumi.String("us-central1"),
			Project:  pulumi.String("my-project-name"),
		})
		if err != nil {
			return err
		}
		_, err = dataplex.NewTask(ctx, "example_spark", &dataplex.TaskArgs{
			TaskId:   pulumi.String("tf-test-task_95154"),
			Location: pulumi.String("us-central1"),
			Lake:     exampleSpark.Name,
			TriggerSpec: &dataplex.TaskTriggerSpecArgs{
				Type: pulumi.String("ON_DEMAND"),
			},
			Description: pulumi.String("task-spark-terraform"),
			ExecutionSpec: &dataplex.TaskExecutionSpecArgs{
				ServiceAccount: pulumi.Sprintf("%v-compute@developer.gserviceaccount.com", project.Number),
				Args: pulumi.StringMap{
					"TASK_ARGS": pulumi.String("--output_location,gs://spark-job/task-result, --output_format, json"),
				},
			},
			Spark: &dataplex.TaskSparkArgs{
				InfrastructureSpec: &dataplex.TaskSparkInfrastructureSpecArgs{
					Batch: &dataplex.TaskSparkInfrastructureSpecBatchArgs{
						ExecutorsCount:    pulumi.Int(2),
						MaxExecutorsCount: pulumi.Int(100),
					},
					ContainerImage: &dataplex.TaskSparkInfrastructureSpecContainerImageArgs{
						Image: pulumi.String("test-image"),
						JavaJars: pulumi.StringArray{
							pulumi.String("test-java-jars.jar"),
						},
						PythonPackages: pulumi.StringArray{
							pulumi.String("gs://bucket-name/my/path/to/lib.tar.gz"),
						},
						Properties: pulumi.StringMap{
							"name":  pulumi.String("wrench"),
							"mass":  pulumi.String("1.3kg"),
							"count": pulumi.String("3"),
						},
					},
					VpcNetwork: &dataplex.TaskSparkInfrastructureSpecVpcNetworkArgs{
						NetworkTags: pulumi.StringArray{
							pulumi.String("test-network-tag"),
						},
						SubNetwork: _default.ID(),
					},
				},
				FileUris: pulumi.StringArray{
					pulumi.String("gs://terrafrom-test/test.csv"),
				},
				ArchiveUris: pulumi.StringArray{
					pulumi.String("gs://terraform-test/test.csv"),
				},
				SqlScript: pulumi.String("show databases"),
			},
			Project: pulumi.String("my-project-name"),
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.compute.Network;
import com.pulumi.gcp.compute.NetworkArgs;
import com.pulumi.gcp.organizations.OrganizationsFunctions;
import com.pulumi.gcp.organizations.inputs.GetProjectArgs;
import com.pulumi.gcp.dataplex.Lake;
import com.pulumi.gcp.dataplex.LakeArgs;
import com.pulumi.gcp.dataplex.Task;
import com.pulumi.gcp.dataplex.TaskArgs;
import com.pulumi.gcp.dataplex.inputs.TaskTriggerSpecArgs;
import com.pulumi.gcp.dataplex.inputs.TaskExecutionSpecArgs;
import com.pulumi.gcp.dataplex.inputs.TaskSparkArgs;
import com.pulumi.gcp.dataplex.inputs.TaskSparkInfrastructureSpecArgs;
import com.pulumi.gcp.dataplex.inputs.TaskSparkInfrastructureSpecBatchArgs;
import com.pulumi.gcp.dataplex.inputs.TaskSparkInfrastructureSpecContainerImageArgs;
import com.pulumi.gcp.dataplex.inputs.TaskSparkInfrastructureSpecVpcNetworkArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        // VPC network
        var default_ = new Network("default", NetworkArgs.builder()
            .name("tf-test-workstation-cluster_89605")
            .autoCreateSubnetworks(true)
            .build());

        final var project = OrganizationsFunctions.getProject();

        var exampleSpark = new Lake("exampleSpark", LakeArgs.builder()
            .name("tf-test-lake_56730")
            .location("us-central1")
            .project("my-project-name")
            .build());

        var exampleSparkTask = new Task("exampleSparkTask", TaskArgs.builder()
            .taskId("tf-test-task_95154")
            .location("us-central1")
            .lake(exampleSpark.name())
            .triggerSpec(TaskTriggerSpecArgs.builder()
                .type("ON_DEMAND")
                .build())
            .description("task-spark-terraform")
            .executionSpec(TaskExecutionSpecArgs.builder()
                .serviceAccount(String.format("%s-compute@developer.gserviceaccount.com", project.applyValue(getProjectResult -> getProjectResult.number())))
                .args(Map.of("TASK_ARGS", "--output_location,gs://spark-job/task-result, --output_format, json"))
                .build())
            .spark(TaskSparkArgs.builder()
                .infrastructureSpec(TaskSparkInfrastructureSpecArgs.builder()
                    .batch(TaskSparkInfrastructureSpecBatchArgs.builder()
                        .executorsCount(2)
                        .maxExecutorsCount(100)
                        .build())
                    .containerImage(TaskSparkInfrastructureSpecContainerImageArgs.builder()
                        .image("test-image")
                        .javaJars("test-java-jars.jar")
                        .pythonPackages("gs://bucket-name/my/path/to/lib.tar.gz")
                        .properties(Map.ofEntries(
                            Map.entry("name", "wrench"),
                            Map.entry("mass", "1.3kg"),
                            Map.entry("count", "3")
                        ))
                        .build())
                    .vpcNetwork(TaskSparkInfrastructureSpecVpcNetworkArgs.builder()
                        .networkTags("test-network-tag")
                        .subNetwork(default_.id())
                        .build())
                    .build())
                .fileUris("gs://terrafrom-test/test.csv")
                .archiveUris("gs://terraform-test/test.csv")
                .sqlScript("show databases")
                .build())
            .project("my-project-name")
            .build());

    }
}
```
```yaml
resources:
  # VPC network
  default:
    type: gcp:compute:Network
    properties:
      name: tf-test-workstation-cluster_89605
      autoCreateSubnetworks: true
  exampleSpark:
    type: gcp:dataplex:Lake
    name: example_spark
    properties:
      name: tf-test-lake_56730
      location: us-central1
      project: my-project-name
  exampleSparkTask:
    type: gcp:dataplex:Task
    name: example_spark
    properties:
      taskId: tf-test-task_95154
      location: us-central1
      lake: ${exampleSpark.name}
      triggerSpec:
        type: ON_DEMAND
      description: task-spark-terraform
      executionSpec:
        serviceAccount: ${project.number}-compute@developer.gserviceaccount.com
        args:
          TASK_ARGS: --output_location,gs://spark-job/task-result, --output_format, json
      spark:
        infrastructureSpec:
          batch:
            executorsCount: 2
            maxExecutorsCount: 100
          containerImage:
            image: test-image
            javaJars:
              - test-java-jars.jar
            pythonPackages:
              - gs://bucket-name/my/path/to/lib.tar.gz
            properties:
              name: wrench
              mass: 1.3kg
              count: '3'
          vpcNetwork:
            networkTags:
              - test-network-tag
            subNetwork: ${default.id}
        fileUris:
          - gs://terrafrom-test/test.csv
        archiveUris:
          - gs://terraform-test/test.csv
        sqlScript: show databases
      project: my-project-name
variables:
  project:
    fn::invoke:
      function: gcp:organizations:getProject
      arguments: {}
```
<!--End PulumiCodeChooser -->
### Dataplex Task Notebook


<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

// VPC network
const _default = new gcp.compute.Network("default", {
    name: "tf-test-workstation-cluster_64336",
    autoCreateSubnetworks: true,
});
const project = gcp.organizations.getProject({});
const exampleNotebook = new gcp.dataplex.Lake("example_notebook", {
    name: "tf-test-lake_34962",
    location: "us-central1",
    project: "my-project-name",
});
const exampleNotebookTask = new gcp.dataplex.Task("example_notebook", {
    taskId: "tf-test-task_74000",
    location: "us-central1",
    lake: exampleNotebook.name,
    triggerSpec: {
        type: "RECURRING",
        schedule: "1 * * * *",
    },
    executionSpec: {
        serviceAccount: project.then(project => `${project.number}-compute@developer.gserviceaccount.com`),
        args: {
            TASK_ARGS: "--output_location,gs://spark-job-jars-anrajitha/task-result, --output_format, json",
        },
    },
    notebook: {
        notebook: "gs://terraform-test/test-notebook.ipynb",
        infrastructureSpec: {
            batch: {
                executorsCount: 2,
                maxExecutorsCount: 100,
            },
            containerImage: {
                image: "test-image",
                javaJars: ["test-java-jars.jar"],
                pythonPackages: ["gs://bucket-name/my/path/to/lib.tar.gz"],
                properties: {
                    name: "wrench",
                    mass: "1.3kg",
                    count: "3",
                },
            },
            vpcNetwork: {
                networkTags: ["test-network-tag"],
                network: _default.id,
            },
        },
        fileUris: ["gs://terraform-test/test.csv"],
        archiveUris: ["gs://terraform-test/test.csv"],
    },
    project: "my-project-name",
});
```
```python
import pulumi
import pulumi_gcp as gcp

# VPC network
default = gcp.compute.Network("default",
    name="tf-test-workstation-cluster_64336",
    auto_create_subnetworks=True)
project = gcp.organizations.get_project()
example_notebook = gcp.dataplex.Lake("example_notebook",
    name="tf-test-lake_34962",
    location="us-central1",
    project="my-project-name")
example_notebook_task = gcp.dataplex.Task("example_notebook",
    task_id="tf-test-task_74000",
    location="us-central1",
    lake=example_notebook.name,
    trigger_spec={
        "type": "RECURRING",
        "schedule": "1 * * * *",
    },
    execution_spec={
        "service_account": f"{project.number}-compute@developer.gserviceaccount.com",
        "args": {
            "TASK_ARGS": "--output_location,gs://spark-job-jars-anrajitha/task-result, --output_format, json",
        },
    },
    notebook={
        "notebook": "gs://terraform-test/test-notebook.ipynb",
        "infrastructure_spec": {
            "batch": {
                "executors_count": 2,
                "max_executors_count": 100,
            },
            "container_image": {
                "image": "test-image",
                "java_jars": ["test-java-jars.jar"],
                "python_packages": ["gs://bucket-name/my/path/to/lib.tar.gz"],
                "properties": {
                    "name": "wrench",
                    "mass": "1.3kg",
                    "count": "3",
                },
            },
            "vpc_network": {
                "network_tags": ["test-network-tag"],
                "network": default.id,
            },
        },
        "file_uris": ["gs://terraform-test/test.csv"],
        "archive_uris": ["gs://terraform-test/test.csv"],
    },
    project="my-project-name")
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    // VPC network
    var @default = new Gcp.Compute.Network("default", new()
    {
        Name = "tf-test-workstation-cluster_64336",
        AutoCreateSubnetworks = true,
    });

    var project = Gcp.Organizations.GetProject.Invoke();

    var exampleNotebook = new Gcp.DataPlex.Lake("example_notebook", new()
    {
        Name = "tf-test-lake_34962",
        Location = "us-central1",
        Project = "my-project-name",
    });

    var exampleNotebookTask = new Gcp.DataPlex.Task("example_notebook", new()
    {
        TaskId = "tf-test-task_74000",
        Location = "us-central1",
        Lake = exampleNotebook.Name,
        TriggerSpec = new Gcp.DataPlex.Inputs.TaskTriggerSpecArgs
        {
            Type = "RECURRING",
            Schedule = "1 * * * *",
        },
        ExecutionSpec = new Gcp.DataPlex.Inputs.TaskExecutionSpecArgs
        {
            ServiceAccount = $"{project.Apply(getProjectResult => getProjectResult.Number)}-compute@developer.gserviceaccount.com",
            Args = 
            {
                { "TASK_ARGS", "--output_location,gs://spark-job-jars-anrajitha/task-result, --output_format, json" },
            },
        },
        Notebook = new Gcp.DataPlex.Inputs.TaskNotebookArgs
        {
            Notebook = "gs://terraform-test/test-notebook.ipynb",
            InfrastructureSpec = new Gcp.DataPlex.Inputs.TaskNotebookInfrastructureSpecArgs
            {
                Batch = new Gcp.DataPlex.Inputs.TaskNotebookInfrastructureSpecBatchArgs
                {
                    ExecutorsCount = 2,
                    MaxExecutorsCount = 100,
                },
                ContainerImage = new Gcp.DataPlex.Inputs.TaskNotebookInfrastructureSpecContainerImageArgs
                {
                    Image = "test-image",
                    JavaJars = new[]
                    {
                        "test-java-jars.jar",
                    },
                    PythonPackages = new[]
                    {
                        "gs://bucket-name/my/path/to/lib.tar.gz",
                    },
                    Properties = 
                    {
                        { "name", "wrench" },
                        { "mass", "1.3kg" },
                        { "count", "3" },
                    },
                },
                VpcNetwork = new Gcp.DataPlex.Inputs.TaskNotebookInfrastructureSpecVpcNetworkArgs
                {
                    NetworkTags = new[]
                    {
                        "test-network-tag",
                    },
                    Network = @default.Id,
                },
            },
            FileUris = new[]
            {
                "gs://terraform-test/test.csv",
            },
            ArchiveUris = new[]
            {
                "gs://terraform-test/test.csv",
            },
        },
        Project = "my-project-name",
    });

});
```
```go
package main

import (
	"fmt"

	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/compute"
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/dataplex"
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/organizations"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		// VPC network
		_, err := compute.NewNetwork(ctx, "default", &compute.NetworkArgs{
			Name:                  pulumi.String("tf-test-workstation-cluster_64336"),
			AutoCreateSubnetworks: pulumi.Bool(true),
		})
		if err != nil {
			return err
		}
		project, err := organizations.LookupProject(ctx, &organizations.LookupProjectArgs{}, nil)
		if err != nil {
			return err
		}
		exampleNotebook, err := dataplex.NewLake(ctx, "example_notebook", &dataplex.LakeArgs{
			Name:     pulumi.String("tf-test-lake_34962"),
			Location: pulumi.String("us-central1"),
			Project:  pulumi.String("my-project-name"),
		})
		if err != nil {
			return err
		}
		_, err = dataplex.NewTask(ctx, "example_notebook", &dataplex.TaskArgs{
			TaskId:   pulumi.String("tf-test-task_74000"),
			Location: pulumi.String("us-central1"),
			Lake:     exampleNotebook.Name,
			TriggerSpec: &dataplex.TaskTriggerSpecArgs{
				Type:     pulumi.String("RECURRING"),
				Schedule: pulumi.String("1 * * * *"),
			},
			ExecutionSpec: &dataplex.TaskExecutionSpecArgs{
				ServiceAccount: pulumi.Sprintf("%v-compute@developer.gserviceaccount.com", project.Number),
				Args: pulumi.StringMap{
					"TASK_ARGS": pulumi.String("--output_location,gs://spark-job-jars-anrajitha/task-result, --output_format, json"),
				},
			},
			Notebook: &dataplex.TaskNotebookArgs{
				Notebook: pulumi.String("gs://terraform-test/test-notebook.ipynb"),
				InfrastructureSpec: &dataplex.TaskNotebookInfrastructureSpecArgs{
					Batch: &dataplex.TaskNotebookInfrastructureSpecBatchArgs{
						ExecutorsCount:    pulumi.Int(2),
						MaxExecutorsCount: pulumi.Int(100),
					},
					ContainerImage: &dataplex.TaskNotebookInfrastructureSpecContainerImageArgs{
						Image: pulumi.String("test-image"),
						JavaJars: pulumi.StringArray{
							pulumi.String("test-java-jars.jar"),
						},
						PythonPackages: pulumi.StringArray{
							pulumi.String("gs://bucket-name/my/path/to/lib.tar.gz"),
						},
						Properties: pulumi.StringMap{
							"name":  pulumi.String("wrench"),
							"mass":  pulumi.String("1.3kg"),
							"count": pulumi.String("3"),
						},
					},
					VpcNetwork: &dataplex.TaskNotebookInfrastructureSpecVpcNetworkArgs{
						NetworkTags: pulumi.StringArray{
							pulumi.String("test-network-tag"),
						},
						Network: _default.ID(),
					},
				},
				FileUris: pulumi.StringArray{
					pulumi.String("gs://terraform-test/test.csv"),
				},
				ArchiveUris: pulumi.StringArray{
					pulumi.String("gs://terraform-test/test.csv"),
				},
			},
			Project: pulumi.String("my-project-name"),
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.compute.Network;
import com.pulumi.gcp.compute.NetworkArgs;
import com.pulumi.gcp.organizations.OrganizationsFunctions;
import com.pulumi.gcp.organizations.inputs.GetProjectArgs;
import com.pulumi.gcp.dataplex.Lake;
import com.pulumi.gcp.dataplex.LakeArgs;
import com.pulumi.gcp.dataplex.Task;
import com.pulumi.gcp.dataplex.TaskArgs;
import com.pulumi.gcp.dataplex.inputs.TaskTriggerSpecArgs;
import com.pulumi.gcp.dataplex.inputs.TaskExecutionSpecArgs;
import com.pulumi.gcp.dataplex.inputs.TaskNotebookArgs;
import com.pulumi.gcp.dataplex.inputs.TaskNotebookInfrastructureSpecArgs;
import com.pulumi.gcp.dataplex.inputs.TaskNotebookInfrastructureSpecBatchArgs;
import com.pulumi.gcp.dataplex.inputs.TaskNotebookInfrastructureSpecContainerImageArgs;
import com.pulumi.gcp.dataplex.inputs.TaskNotebookInfrastructureSpecVpcNetworkArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        // VPC network
        var default_ = new Network("default", NetworkArgs.builder()
            .name("tf-test-workstation-cluster_64336")
            .autoCreateSubnetworks(true)
            .build());

        final var project = OrganizationsFunctions.getProject();

        var exampleNotebook = new Lake("exampleNotebook", LakeArgs.builder()
            .name("tf-test-lake_34962")
            .location("us-central1")
            .project("my-project-name")
            .build());

        var exampleNotebookTask = new Task("exampleNotebookTask", TaskArgs.builder()
            .taskId("tf-test-task_74000")
            .location("us-central1")
            .lake(exampleNotebook.name())
            .triggerSpec(TaskTriggerSpecArgs.builder()
                .type("RECURRING")
                .schedule("1 * * * *")
                .build())
            .executionSpec(TaskExecutionSpecArgs.builder()
                .serviceAccount(String.format("%s-compute@developer.gserviceaccount.com", project.applyValue(getProjectResult -> getProjectResult.number())))
                .args(Map.of("TASK_ARGS", "--output_location,gs://spark-job-jars-anrajitha/task-result, --output_format, json"))
                .build())
            .notebook(TaskNotebookArgs.builder()
                .notebook("gs://terraform-test/test-notebook.ipynb")
                .infrastructureSpec(TaskNotebookInfrastructureSpecArgs.builder()
                    .batch(TaskNotebookInfrastructureSpecBatchArgs.builder()
                        .executorsCount(2)
                        .maxExecutorsCount(100)
                        .build())
                    .containerImage(TaskNotebookInfrastructureSpecContainerImageArgs.builder()
                        .image("test-image")
                        .javaJars("test-java-jars.jar")
                        .pythonPackages("gs://bucket-name/my/path/to/lib.tar.gz")
                        .properties(Map.ofEntries(
                            Map.entry("name", "wrench"),
                            Map.entry("mass", "1.3kg"),
                            Map.entry("count", "3")
                        ))
                        .build())
                    .vpcNetwork(TaskNotebookInfrastructureSpecVpcNetworkArgs.builder()
                        .networkTags("test-network-tag")
                        .network(default_.id())
                        .build())
                    .build())
                .fileUris("gs://terraform-test/test.csv")
                .archiveUris("gs://terraform-test/test.csv")
                .build())
            .project("my-project-name")
            .build());

    }
}
```
```yaml
resources:
  # VPC network
  default:
    type: gcp:compute:Network
    properties:
      name: tf-test-workstation-cluster_64336
      autoCreateSubnetworks: true
  exampleNotebook:
    type: gcp:dataplex:Lake
    name: example_notebook
    properties:
      name: tf-test-lake_34962
      location: us-central1
      project: my-project-name
  exampleNotebookTask:
    type: gcp:dataplex:Task
    name: example_notebook
    properties:
      taskId: tf-test-task_74000
      location: us-central1
      lake: ${exampleNotebook.name}
      triggerSpec:
        type: RECURRING
        schedule: 1 * * * *
      executionSpec:
        serviceAccount: ${project.number}-compute@developer.gserviceaccount.com
        args:
          TASK_ARGS: --output_location,gs://spark-job-jars-anrajitha/task-result, --output_format, json
      notebook:
        notebook: gs://terraform-test/test-notebook.ipynb
        infrastructureSpec:
          batch:
            executorsCount: 2
            maxExecutorsCount: 100
          containerImage:
            image: test-image
            javaJars:
              - test-java-jars.jar
            pythonPackages:
              - gs://bucket-name/my/path/to/lib.tar.gz
            properties:
              name: wrench
              mass: 1.3kg
              count: '3'
          vpcNetwork:
            networkTags:
              - test-network-tag
            network: ${default.id}
        fileUris:
          - gs://terraform-test/test.csv
        archiveUris:
          - gs://terraform-test/test.csv
      project: my-project-name
variables:
  project:
    fn::invoke:
      function: gcp:organizations:getProject
      arguments: {}
```
<!--End PulumiCodeChooser -->

## Import

Task can be imported using any of these accepted formats:

* `projects/{{project}}/locations/{{location}}/lakes/{{lake}}/tasks/{{task_id}}`

* `{{project}}/{{location}}/{{lake}}/{{task_id}}`

* `{{location}}/{{lake}}/{{task_id}}`

When using the `pulumi import` command, Task can be imported using one of the formats above. For example:

```sh
$ pulumi import gcp:dataplex/task:Task default projects/{{project}}/locations/{{location}}/lakes/{{lake}}/tasks/{{task_id}}
```

```sh
$ pulumi import gcp:dataplex/task:Task default {{project}}/{{location}}/{{lake}}/{{task_id}}
```

```sh
$ pulumi import gcp:dataplex/task:Task default {{location}}/{{lake}}/{{task_id}}
```

<
descriptionB" 'User-provided description of the task.
1
displayNameB" User friendly display name.
£
executionSpecS:Q
O
dataplexTaskExecutionSpec0gcp:dataplex/TaskExecutionSpec:TaskExecutionSpec=Configuration for the cluster
Structure is documented below.
û
labelsB2" èUser-defined labels for the task. **Note**: This field is non-authoritative, and will only manage the labels present in
your configuration. Please refer to the field 'effective_labels' for all of the labels present on the resource.
=
lakeB" /The lake in which the task will be created in.
E
locationB" 3The location in which the task will be created in.
ä
notebookFBD:B
@
dataplexTaskNotebook&gcp:dataplex/TaskNotebook:TaskNotebookA service with manual scaling runs continuously, allowing you to perform complex initialization and rely on the state of
its memory over time.

projectB" Ø
spark=B;:9
7
dataplex	TaskSpark gcp:dataplex/TaskSpark:TaskSparkA service with manual scaling runs continuously, allowing you to perform complex initialization and rely on the state of
its memory over time.
)
taskIdB" The task Id of the task.

triggerSpecM:K
I
dataplexTaskTriggerSpec,gcp:dataplex/TaskTriggerSpec:TaskTriggerSpec=Configuration for the cluster
Structure is documented below.
"6

createTime" $The time when the task was created.
"<
descriptionB" 'User-provided description of the task.
"1
displayNameB" User friendly display name.
"¦
effectiveLabels2" All of labels (key/value pairs) present on the resource in GCP, including the labels configured through Pulumi, other clients and services.
"£
executionSpecS:Q
O
dataplexTaskExecutionSpec0gcp:dataplex/TaskExecutionSpec:TaskExecutionSpec=Configuration for the cluster
Structure is documented below.
"¯
executionStatuses[*Y:W
U
dataplexTaskExecutionStatus4gcp:dataplex/TaskExecutionStatus:TaskExecutionStatus=Configuration for the cluster
Structure is documented below.
"û
labelsB2" èUser-defined labels for the task. **Note**: This field is non-authoritative, and will only manage the labels present in
your configuration. Please refer to the field 'effective_labels' for all of the labels present on the resource.
"=
lakeB" /The lake in which the task will be created in.
"E
locationB" 3The location in which the task will be created in.
"§
name" (Output)
The relative resource name of the job, of the form: projects/{project_number}/locations/{locationId}/lakes/{lakeId}/tasks/{taskId}/jobs/{jobId}.
"ä
notebookFBD:B
@
dataplexTaskNotebook&gcp:dataplex/TaskNotebook:TaskNotebookA service with manual scaling runs continuously, allowing you to perform complex initialization and rely on the state of
its memory over time.
"
project" "
pulumiLabels2" mThe combination of labels configured directly on the resource
and default labels configured on the provider.
"Ø
spark=B;:9
7
dataplex	TaskSpark gcp:dataplex/TaskSpark:TaskSparkA service with manual scaling runs continuously, allowing you to perform complex initialization and rely on the state of
its memory over time.
"3
state" &(Output)
Execution state for the job.
")
taskIdB" The task Id of the task.
"
triggerSpecM:K
I
dataplexTaskTriggerSpec,gcp:dataplex/TaskTriggerSpec:TaskTriggerSpec=Configuration for the cluster
Structure is documented below.
"E
uid" :(Output)
System generated globally unique ID for the job.
";

updateTime" )(Output)
Last update time of the status.
*úä
F
dataplexTaskIamBinding*gcp:dataplex/taskIamBinding:TaskIamBindingÃ¿Three different resources help you manage your IAM policy for Dataplex Task. Each of these resources serves a different use case:

* `gcp.dataplex.TaskIamPolicy`: Authoritative. Sets the IAM policy for the task and replaces any existing policy already attached.
* `gcp.dataplex.TaskIamBinding`: Authoritative for a given role. Updates the IAM policy to grant a role to a list of members. Other roles within the IAM policy for the task are preserved.
* `gcp.dataplex.TaskIamMember`: Non-authoritative. Updates the IAM policy to grant a role to a new member. Other members for the role for the task are preserved.

A data source can be used to retrieve policy data in advent you do not need creation

* `gcp.dataplex.TaskIamPolicy`: Retrieves the IAM policy for the task

> **Note:** `gcp.dataplex.TaskIamPolicy` **cannot** be used in conjunction with `gcp.dataplex.TaskIamBinding` and `gcp.dataplex.TaskIamMember` or they will fight over what your policy should be.

> **Note:** `gcp.dataplex.TaskIamBinding` resources **can be** used in conjunction with `gcp.dataplex.TaskIamMember` resources **only if** they do not grant privilege to the same role.



## gcp.dataplex.TaskIamPolicy

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const admin = gcp.organizations.getIAMPolicy({
    bindings: [{
        role: "roles/viewer",
        members: ["user:jane@example.com"],
    }],
});
const policy = new gcp.dataplex.TaskIamPolicy("policy", {
    project: example.project,
    location: example.location,
    lake: example.lake,
    taskId: example.taskId,
    policyData: admin.then(admin => admin.policyData),
});
```
```python
import pulumi
import pulumi_gcp as gcp

admin = gcp.organizations.get_iam_policy(bindings=[{
    "role": "roles/viewer",
    "members": ["user:jane@example.com"],
}])
policy = gcp.dataplex.TaskIamPolicy("policy",
    project=example["project"],
    location=example["location"],
    lake=example["lake"],
    task_id=example["taskId"],
    policy_data=admin.policy_data)
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var admin = Gcp.Organizations.GetIAMPolicy.Invoke(new()
    {
        Bindings = new[]
        {
            new Gcp.Organizations.Inputs.GetIAMPolicyBindingInputArgs
            {
                Role = "roles/viewer",
                Members = new[]
                {
                    "user:jane@example.com",
                },
            },
        },
    });

    var policy = new Gcp.DataPlex.TaskIamPolicy("policy", new()
    {
        Project = example.Project,
        Location = example.Location,
        Lake = example.Lake,
        TaskId = example.TaskId,
        PolicyData = admin.Apply(getIAMPolicyResult => getIAMPolicyResult.PolicyData),
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/dataplex"
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/organizations"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		admin, err := organizations.LookupIAMPolicy(ctx, &organizations.LookupIAMPolicyArgs{
			Bindings: []organizations.GetIAMPolicyBinding{
				{
					Role: "roles/viewer",
					Members: []string{
						"user:jane@example.com",
					},
				},
			},
		}, nil)
		if err != nil {
			return err
		}
		_, err = dataplex.NewTaskIamPolicy(ctx, "policy", &dataplex.TaskIamPolicyArgs{
			Project:    pulumi.Any(example.Project),
			Location:   pulumi.Any(example.Location),
			Lake:       pulumi.Any(example.Lake),
			TaskId:     pulumi.Any(example.TaskId),
			PolicyData: pulumi.String(admin.PolicyData),
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.organizations.OrganizationsFunctions;
import com.pulumi.gcp.organizations.inputs.GetIAMPolicyArgs;
import com.pulumi.gcp.dataplex.TaskIamPolicy;
import com.pulumi.gcp.dataplex.TaskIamPolicyArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        final var admin = OrganizationsFunctions.getIAMPolicy(GetIAMPolicyArgs.builder()
            .bindings(GetIAMPolicyBindingArgs.builder()
                .role("roles/viewer")
                .members("user:jane@example.com")
                .build())
            .build());

        var policy = new TaskIamPolicy("policy", TaskIamPolicyArgs.builder()
            .project(example.project())
            .location(example.location())
            .lake(example.lake())
            .taskId(example.taskId())
            .policyData(admin.applyValue(getIAMPolicyResult -> getIAMPolicyResult.policyData()))
            .build());

    }
}
```
```yaml
resources:
  policy:
    type: gcp:dataplex:TaskIamPolicy
    properties:
      project: ${example.project}
      location: ${example.location}
      lake: ${example.lake}
      taskId: ${example.taskId}
      policyData: ${admin.policyData}
variables:
  admin:
    fn::invoke:
      function: gcp:organizations:getIAMPolicy
      arguments:
        bindings:
          - role: roles/viewer
            members:
              - user:jane@example.com
```
<!--End PulumiCodeChooser -->

## gcp.dataplex.TaskIamBinding

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const binding = new gcp.dataplex.TaskIamBinding("binding", {
    project: example.project,
    location: example.location,
    lake: example.lake,
    taskId: example.taskId,
    role: "roles/viewer",
    members: ["user:jane@example.com"],
});
```
```python
import pulumi
import pulumi_gcp as gcp

binding = gcp.dataplex.TaskIamBinding("binding",
    project=example["project"],
    location=example["location"],
    lake=example["lake"],
    task_id=example["taskId"],
    role="roles/viewer",
    members=["user:jane@example.com"])
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var binding = new Gcp.DataPlex.TaskIamBinding("binding", new()
    {
        Project = example.Project,
        Location = example.Location,
        Lake = example.Lake,
        TaskId = example.TaskId,
        Role = "roles/viewer",
        Members = new[]
        {
            "user:jane@example.com",
        },
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/dataplex"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		_, err := dataplex.NewTaskIamBinding(ctx, "binding", &dataplex.TaskIamBindingArgs{
			Project:  pulumi.Any(example.Project),
			Location: pulumi.Any(example.Location),
			Lake:     pulumi.Any(example.Lake),
			TaskId:   pulumi.Any(example.TaskId),
			Role:     pulumi.String("roles/viewer"),
			Members: pulumi.StringArray{
				pulumi.String("user:jane@example.com"),
			},
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.dataplex.TaskIamBinding;
import com.pulumi.gcp.dataplex.TaskIamBindingArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        var binding = new TaskIamBinding("binding", TaskIamBindingArgs.builder()
            .project(example.project())
            .location(example.location())
            .lake(example.lake())
            .taskId(example.taskId())
            .role("roles/viewer")
            .members("user:jane@example.com")
            .build());

    }
}
```
```yaml
resources:
  binding:
    type: gcp:dataplex:TaskIamBinding
    properties:
      project: ${example.project}
      location: ${example.location}
      lake: ${example.lake}
      taskId: ${example.taskId}
      role: roles/viewer
      members:
        - user:jane@example.com
```
<!--End PulumiCodeChooser -->

## gcp.dataplex.TaskIamMember

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const member = new gcp.dataplex.TaskIamMember("member", {
    project: example.project,
    location: example.location,
    lake: example.lake,
    taskId: example.taskId,
    role: "roles/viewer",
    member: "user:jane@example.com",
});
```
```python
import pulumi
import pulumi_gcp as gcp

member = gcp.dataplex.TaskIamMember("member",
    project=example["project"],
    location=example["location"],
    lake=example["lake"],
    task_id=example["taskId"],
    role="roles/viewer",
    member="user:jane@example.com")
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var member = new Gcp.DataPlex.TaskIamMember("member", new()
    {
        Project = example.Project,
        Location = example.Location,
        Lake = example.Lake,
        TaskId = example.TaskId,
        Role = "roles/viewer",
        Member = "user:jane@example.com",
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/dataplex"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		_, err := dataplex.NewTaskIamMember(ctx, "member", &dataplex.TaskIamMemberArgs{
			Project:  pulumi.Any(example.Project),
			Location: pulumi.Any(example.Location),
			Lake:     pulumi.Any(example.Lake),
			TaskId:   pulumi.Any(example.TaskId),
			Role:     pulumi.String("roles/viewer"),
			Member:   pulumi.String("user:jane@example.com"),
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.dataplex.TaskIamMember;
import com.pulumi.gcp.dataplex.TaskIamMemberArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        var member = new TaskIamMember("member", TaskIamMemberArgs.builder()
            .project(example.project())
            .location(example.location())
            .lake(example.lake())
            .taskId(example.taskId())
            .role("roles/viewer")
            .member("user:jane@example.com")
            .build());

    }
}
```
```yaml
resources:
  member:
    type: gcp:dataplex:TaskIamMember
    properties:
      project: ${example.project}
      location: ${example.location}
      lake: ${example.lake}
      taskId: ${example.taskId}
      role: roles/viewer
      member: user:jane@example.com
```
<!--End PulumiCodeChooser -->


## This resource supports User Project Overrides.

-

# IAM policy for Dataplex Task
Three different resources help you manage your IAM policy for Dataplex Task. Each of these resources serves a different use case:

* `gcp.dataplex.TaskIamPolicy`: Authoritative. Sets the IAM policy for the task and replaces any existing policy already attached.
* `gcp.dataplex.TaskIamBinding`: Authoritative for a given role. Updates the IAM policy to grant a role to a list of members. Other roles within the IAM policy for the task are preserved.
* `gcp.dataplex.TaskIamMember`: Non-authoritative. Updates the IAM policy to grant a role to a new member. Other members for the role for the task are preserved.

A data source can be used to retrieve policy data in advent you do not need creation

* `gcp.dataplex.TaskIamPolicy`: Retrieves the IAM policy for the task

> **Note:** `gcp.dataplex.TaskIamPolicy` **cannot** be used in conjunction with `gcp.dataplex.TaskIamBinding` and `gcp.dataplex.TaskIamMember` or they will fight over what your policy should be.

> **Note:** `gcp.dataplex.TaskIamBinding` resources **can be** used in conjunction with `gcp.dataplex.TaskIamMember` resources **only if** they do not grant privilege to the same role.



## gcp.dataplex.TaskIamPolicy

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const admin = gcp.organizations.getIAMPolicy({
    bindings: [{
        role: "roles/viewer",
        members: ["user:jane@example.com"],
    }],
});
const policy = new gcp.dataplex.TaskIamPolicy("policy", {
    project: example.project,
    location: example.location,
    lake: example.lake,
    taskId: example.taskId,
    policyData: admin.then(admin => admin.policyData),
});
```
```python
import pulumi
import pulumi_gcp as gcp

admin = gcp.organizations.get_iam_policy(bindings=[{
    "role": "roles/viewer",
    "members": ["user:jane@example.com"],
}])
policy = gcp.dataplex.TaskIamPolicy("policy",
    project=example["project"],
    location=example["location"],
    lake=example["lake"],
    task_id=example["taskId"],
    policy_data=admin.policy_data)
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var admin = Gcp.Organizations.GetIAMPolicy.Invoke(new()
    {
        Bindings = new[]
        {
            new Gcp.Organizations.Inputs.GetIAMPolicyBindingInputArgs
            {
                Role = "roles/viewer",
                Members = new[]
                {
                    "user:jane@example.com",
                },
            },
        },
    });

    var policy = new Gcp.DataPlex.TaskIamPolicy("policy", new()
    {
        Project = example.Project,
        Location = example.Location,
        Lake = example.Lake,
        TaskId = example.TaskId,
        PolicyData = admin.Apply(getIAMPolicyResult => getIAMPolicyResult.PolicyData),
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/dataplex"
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/organizations"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		admin, err := organizations.LookupIAMPolicy(ctx, &organizations.LookupIAMPolicyArgs{
			Bindings: []organizations.GetIAMPolicyBinding{
				{
					Role: "roles/viewer",
					Members: []string{
						"user:jane@example.com",
					},
				},
			},
		}, nil)
		if err != nil {
			return err
		}
		_, err = dataplex.NewTaskIamPolicy(ctx, "policy", &dataplex.TaskIamPolicyArgs{
			Project:    pulumi.Any(example.Project),
			Location:   pulumi.Any(example.Location),
			Lake:       pulumi.Any(example.Lake),
			TaskId:     pulumi.Any(example.TaskId),
			PolicyData: pulumi.String(admin.PolicyData),
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.organizations.OrganizationsFunctions;
import com.pulumi.gcp.organizations.inputs.GetIAMPolicyArgs;
import com.pulumi.gcp.dataplex.TaskIamPolicy;
import com.pulumi.gcp.dataplex.TaskIamPolicyArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        final var admin = OrganizationsFunctions.getIAMPolicy(GetIAMPolicyArgs.builder()
            .bindings(GetIAMPolicyBindingArgs.builder()
                .role("roles/viewer")
                .members("user:jane@example.com")
                .build())
            .build());

        var policy = new TaskIamPolicy("policy", TaskIamPolicyArgs.builder()
            .project(example.project())
            .location(example.location())
            .lake(example.lake())
            .taskId(example.taskId())
            .policyData(admin.applyValue(getIAMPolicyResult -> getIAMPolicyResult.policyData()))
            .build());

    }
}
```
```yaml
resources:
  policy:
    type: gcp:dataplex:TaskIamPolicy
    properties:
      project: ${example.project}
      location: ${example.location}
      lake: ${example.lake}
      taskId: ${example.taskId}
      policyData: ${admin.policyData}
variables:
  admin:
    fn::invoke:
      function: gcp:organizations:getIAMPolicy
      arguments:
        bindings:
          - role: roles/viewer
            members:
              - user:jane@example.com
```
<!--End PulumiCodeChooser -->

## gcp.dataplex.TaskIamBinding

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const binding = new gcp.dataplex.TaskIamBinding("binding", {
    project: example.project,
    location: example.location,
    lake: example.lake,
    taskId: example.taskId,
    role: "roles/viewer",
    members: ["user:jane@example.com"],
});
```
```python
import pulumi
import pulumi_gcp as gcp

binding = gcp.dataplex.TaskIamBinding("binding",
    project=example["project"],
    location=example["location"],
    lake=example["lake"],
    task_id=example["taskId"],
    role="roles/viewer",
    members=["user:jane@example.com"])
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var binding = new Gcp.DataPlex.TaskIamBinding("binding", new()
    {
        Project = example.Project,
        Location = example.Location,
        Lake = example.Lake,
        TaskId = example.TaskId,
        Role = "roles/viewer",
        Members = new[]
        {
            "user:jane@example.com",
        },
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/dataplex"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		_, err := dataplex.NewTaskIamBinding(ctx, "binding", &dataplex.TaskIamBindingArgs{
			Project:  pulumi.Any(example.Project),
			Location: pulumi.Any(example.Location),
			Lake:     pulumi.Any(example.Lake),
			TaskId:   pulumi.Any(example.TaskId),
			Role:     pulumi.String("roles/viewer"),
			Members: pulumi.StringArray{
				pulumi.String("user:jane@example.com"),
			},
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.dataplex.TaskIamBinding;
import com.pulumi.gcp.dataplex.TaskIamBindingArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        var binding = new TaskIamBinding("binding", TaskIamBindingArgs.builder()
            .project(example.project())
            .location(example.location())
            .lake(example.lake())
            .taskId(example.taskId())
            .role("roles/viewer")
            .members("user:jane@example.com")
            .build());

    }
}
```
```yaml
resources:
  binding:
    type: gcp:dataplex:TaskIamBinding
    properties:
      project: ${example.project}
      location: ${example.location}
      lake: ${example.lake}
      taskId: ${example.taskId}
      role: roles/viewer
      members:
        - user:jane@example.com
```
<!--End PulumiCodeChooser -->

## gcp.dataplex.TaskIamMember

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const member = new gcp.dataplex.TaskIamMember("member", {
    project: example.project,
    location: example.location,
    lake: example.lake,
    taskId: example.taskId,
    role: "roles/viewer",
    member: "user:jane@example.com",
});
```
```python
import pulumi
import pulumi_gcp as gcp

member = gcp.dataplex.TaskIamMember("member",
    project=example["project"],
    location=example["location"],
    lake=example["lake"],
    task_id=example["taskId"],
    role="roles/viewer",
    member="user:jane@example.com")
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var member = new Gcp.DataPlex.TaskIamMember("member", new()
    {
        Project = example.Project,
        Location = example.Location,
        Lake = example.Lake,
        TaskId = example.TaskId,
        Role = "roles/viewer",
        Member = "user:jane@example.com",
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/dataplex"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		_, err := dataplex.NewTaskIamMember(ctx, "member", &dataplex.TaskIamMemberArgs{
			Project:  pulumi.Any(example.Project),
			Location: pulumi.Any(example.Location),
			Lake:     pulumi.Any(example.Lake),
			TaskId:   pulumi.Any(example.TaskId),
			Role:     pulumi.String("roles/viewer"),
			Member:   pulumi.String("user:jane@example.com"),
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.dataplex.TaskIamMember;
import com.pulumi.gcp.dataplex.TaskIamMemberArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        var member = new TaskIamMember("member", TaskIamMemberArgs.builder()
            .project(example.project())
            .location(example.location())
            .lake(example.lake())
            .taskId(example.taskId())
            .role("roles/viewer")
            .member("user:jane@example.com")
            .build());

    }
}
```
```yaml
resources:
  member:
    type: gcp:dataplex:TaskIamMember
    properties:
      project: ${example.project}
      location: ${example.location}
      lake: ${example.lake}
      taskId: ${example.taskId}
      role: roles/viewer
      member: user:jane@example.com
```
<!--End PulumiCodeChooser -->

## Import

For all import syntaxes, the "resource in question" can take any of the following forms:

* projects/{{project}}/locations/{{location}}/lakes/{{lake}}/tasks/{{task_id}}

* {{project}}/{{location}}/{{lake}}/{{task_id}}

* {{location}}/{{lake}}/{{task_id}}

* {{task_id}}

Any variables not passed in the import command will be taken from the provider configuration.

Dataplex task IAM resources can be imported using the resource identifiers, role, and member.

IAM member imports use space-delimited identifiers: the resource in question, the role, and the member identity, e.g.

```sh
$ pulumi import gcp:dataplex/taskIamBinding:TaskIamBinding editor "projects/{{project}}/locations/{{location}}/lakes/{{lake}}/tasks/{{task_id}} roles/viewer user:jane@example.com"
```

IAM binding imports use space-delimited identifiers: the resource in question and the role, e.g.

```sh
$ pulumi import gcp:dataplex/taskIamBinding:TaskIamBinding editor "projects/{{project}}/locations/{{location}}/lakes/{{lake}}/tasks/{{task_id}} roles/viewer"
```

IAM policy imports use the identifier of the resource in question, e.g.

```sh
$ pulumi import gcp:dataplex/taskIamBinding:TaskIamBinding editor projects/{{project}}/locations/{{location}}/lakes/{{lake}}/tasks/{{task_id}}
```

-> **Custom Roles** If you're importing a IAM resource with a custom role, make sure to use the

 full name of the custom role, e.g. `[projects/my-project|organizations/my-org]/roles/my-custom-role`.

t
	conditiongBe:c
a
dataplexTaskIamBindingCondition<gcp:dataplex/TaskIamBindingCondition:TaskIamBindingConditionv
lake" jThe lake in which the task will be created in.
Used to find the parent resource to bind the IAM policy to
Ø
locationB" ÅThe location in which the task will be created in.
Used to find the parent resource to bind the IAM policy to. If not specified,
the value will be parsed from the identifier of the parent resource. If no location is provided in the parent identifier and no
location is specified, it is taken from the provider configuration.
Ö	
members*" Ä	Identities that will be granted the privilege in `role`.
Each entry can have one of the following values:
* **allUsers**: A special identifier that represents anyone who is on the internet; with or without a Google account.
* **allAuthenticatedUsers**: A special identifier that represents anyone who is authenticated with a Google account or a service account.
* **user:{emailid}**: An email address that represents a specific Google account. For example, alice@gmail.com or joe@example.com.
* **serviceAccount:{emailid}**: An email address that represents a service account. For example, my-other-app@appspot.gserviceaccount.com.
* **group:{emailid}**: An email address that represents a Google group. For example, admins@example.com.
* **domain:{domain}**: A G Suite domain (primary, instead of alias) name that represents all the users of that domain. For example, google.com or example.com.
* **projectOwner:projectid**: Owners of the given project. For example, "projectOwner:my-example-project"
* **projectEditor:projectid**: Editors of the given project. For example, "projectEditor:my-example-project"
* **projectViewer:projectid**: Viewers of the given project. For example, "projectViewer:my-example-project"

projectB" The ID of the project in which the resource belongs.
If it is not provided, the project will be parsed from the identifier of the parent resource. If no project is provided in the parent identifier and no project is specified, the provider project is used.
Ô
role" ÇThe role that should be applied. Only one
`gcp.dataplex.TaskIamBinding` can be used per role. Note that custom roles must be of the format
`[projects|organizations]/{parent-name}/roles/{role-name}`.

taskId" "t
	conditiongBe:c
a
dataplexTaskIamBindingCondition<gcp:dataplex/TaskIamBindingCondition:TaskIamBindingCondition"3
etag" '(Computed) The etag of the IAM policy.
"v
lake" jThe lake in which the task will be created in.
Used to find the parent resource to bind the IAM policy to
"Ö
location" ÅThe location in which the task will be created in.
Used to find the parent resource to bind the IAM policy to. If not specified,
the value will be parsed from the identifier of the parent resource. If no location is provided in the parent identifier and no
location is specified, it is taken from the provider configuration.
"Ö	
members*" Ä	Identities that will be granted the privilege in `role`.
Each entry can have one of the following values:
* **allUsers**: A special identifier that represents anyone who is on the internet; with or without a Google account.
* **allAuthenticatedUsers**: A special identifier that represents anyone who is authenticated with a Google account or a service account.
* **user:{emailid}**: An email address that represents a specific Google account. For example, alice@gmail.com or joe@example.com.
* **serviceAccount:{emailid}**: An email address that represents a service account. For example, my-other-app@appspot.gserviceaccount.com.
* **group:{emailid}**: An email address that represents a Google group. For example, admins@example.com.
* **domain:{domain}**: A G Suite domain (primary, instead of alias) name that represents all the users of that domain. For example, google.com or example.com.
* **projectOwner:projectid**: Owners of the given project. For example, "projectOwner:my-example-project"
* **projectEditor:projectid**: Editors of the given project. For example, "projectEditor:my-example-project"
* **projectViewer:projectid**: Viewers of the given project. For example, "projectViewer:my-example-project"
"
project" The ID of the project in which the resource belongs.
If it is not provided, the project will be parsed from the identifier of the parent resource. If no project is provided in the parent identifier and no project is specified, the provider project is used.
"Ô
role" ÇThe role that should be applied. Only one
`gcp.dataplex.TaskIamBinding` can be used per role. Note that custom roles must be of the format
`[projects|organizations]/{parent-name}/roles/{role-name}`.
"
taskId" *åä
C
dataplexTaskIamMember(gcp:dataplex/taskIamMember:TaskIamMember½¿Three different resources help you manage your IAM policy for Dataplex Task. Each of these resources serves a different use case:

* `gcp.dataplex.TaskIamPolicy`: Authoritative. Sets the IAM policy for the task and replaces any existing policy already attached.
* `gcp.dataplex.TaskIamBinding`: Authoritative for a given role. Updates the IAM policy to grant a role to a list of members. Other roles within the IAM policy for the task are preserved.
* `gcp.dataplex.TaskIamMember`: Non-authoritative. Updates the IAM policy to grant a role to a new member. Other members for the role for the task are preserved.

A data source can be used to retrieve policy data in advent you do not need creation

* `gcp.dataplex.TaskIamPolicy`: Retrieves the IAM policy for the task

> **Note:** `gcp.dataplex.TaskIamPolicy` **cannot** be used in conjunction with `gcp.dataplex.TaskIamBinding` and `gcp.dataplex.TaskIamMember` or they will fight over what your policy should be.

> **Note:** `gcp.dataplex.TaskIamBinding` resources **can be** used in conjunction with `gcp.dataplex.TaskIamMember` resources **only if** they do not grant privilege to the same role.



## gcp.dataplex.TaskIamPolicy

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const admin = gcp.organizations.getIAMPolicy({
    bindings: [{
        role: "roles/viewer",
        members: ["user:jane@example.com"],
    }],
});
const policy = new gcp.dataplex.TaskIamPolicy("policy", {
    project: example.project,
    location: example.location,
    lake: example.lake,
    taskId: example.taskId,
    policyData: admin.then(admin => admin.policyData),
});
```
```python
import pulumi
import pulumi_gcp as gcp

admin = gcp.organizations.get_iam_policy(bindings=[{
    "role": "roles/viewer",
    "members": ["user:jane@example.com"],
}])
policy = gcp.dataplex.TaskIamPolicy("policy",
    project=example["project"],
    location=example["location"],
    lake=example["lake"],
    task_id=example["taskId"],
    policy_data=admin.policy_data)
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var admin = Gcp.Organizations.GetIAMPolicy.Invoke(new()
    {
        Bindings = new[]
        {
            new Gcp.Organizations.Inputs.GetIAMPolicyBindingInputArgs
            {
                Role = "roles/viewer",
                Members = new[]
                {
                    "user:jane@example.com",
                },
            },
        },
    });

    var policy = new Gcp.DataPlex.TaskIamPolicy("policy", new()
    {
        Project = example.Project,
        Location = example.Location,
        Lake = example.Lake,
        TaskId = example.TaskId,
        PolicyData = admin.Apply(getIAMPolicyResult => getIAMPolicyResult.PolicyData),
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/dataplex"
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/organizations"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		admin, err := organizations.LookupIAMPolicy(ctx, &organizations.LookupIAMPolicyArgs{
			Bindings: []organizations.GetIAMPolicyBinding{
				{
					Role: "roles/viewer",
					Members: []string{
						"user:jane@example.com",
					},
				},
			},
		}, nil)
		if err != nil {
			return err
		}
		_, err = dataplex.NewTaskIamPolicy(ctx, "policy", &dataplex.TaskIamPolicyArgs{
			Project:    pulumi.Any(example.Project),
			Location:   pulumi.Any(example.Location),
			Lake:       pulumi.Any(example.Lake),
			TaskId:     pulumi.Any(example.TaskId),
			PolicyData: pulumi.String(admin.PolicyData),
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.organizations.OrganizationsFunctions;
import com.pulumi.gcp.organizations.inputs.GetIAMPolicyArgs;
import com.pulumi.gcp.dataplex.TaskIamPolicy;
import com.pulumi.gcp.dataplex.TaskIamPolicyArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        final var admin = OrganizationsFunctions.getIAMPolicy(GetIAMPolicyArgs.builder()
            .bindings(GetIAMPolicyBindingArgs.builder()
                .role("roles/viewer")
                .members("user:jane@example.com")
                .build())
            .build());

        var policy = new TaskIamPolicy("policy", TaskIamPolicyArgs.builder()
            .project(example.project())
            .location(example.location())
            .lake(example.lake())
            .taskId(example.taskId())
            .policyData(admin.applyValue(getIAMPolicyResult -> getIAMPolicyResult.policyData()))
            .build());

    }
}
```
```yaml
resources:
  policy:
    type: gcp:dataplex:TaskIamPolicy
    properties:
      project: ${example.project}
      location: ${example.location}
      lake: ${example.lake}
      taskId: ${example.taskId}
      policyData: ${admin.policyData}
variables:
  admin:
    fn::invoke:
      function: gcp:organizations:getIAMPolicy
      arguments:
        bindings:
          - role: roles/viewer
            members:
              - user:jane@example.com
```
<!--End PulumiCodeChooser -->

## gcp.dataplex.TaskIamBinding

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const binding = new gcp.dataplex.TaskIamBinding("binding", {
    project: example.project,
    location: example.location,
    lake: example.lake,
    taskId: example.taskId,
    role: "roles/viewer",
    members: ["user:jane@example.com"],
});
```
```python
import pulumi
import pulumi_gcp as gcp

binding = gcp.dataplex.TaskIamBinding("binding",
    project=example["project"],
    location=example["location"],
    lake=example["lake"],
    task_id=example["taskId"],
    role="roles/viewer",
    members=["user:jane@example.com"])
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var binding = new Gcp.DataPlex.TaskIamBinding("binding", new()
    {
        Project = example.Project,
        Location = example.Location,
        Lake = example.Lake,
        TaskId = example.TaskId,
        Role = "roles/viewer",
        Members = new[]
        {
            "user:jane@example.com",
        },
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/dataplex"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		_, err := dataplex.NewTaskIamBinding(ctx, "binding", &dataplex.TaskIamBindingArgs{
			Project:  pulumi.Any(example.Project),
			Location: pulumi.Any(example.Location),
			Lake:     pulumi.Any(example.Lake),
			TaskId:   pulumi.Any(example.TaskId),
			Role:     pulumi.String("roles/viewer"),
			Members: pulumi.StringArray{
				pulumi.String("user:jane@example.com"),
			},
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.dataplex.TaskIamBinding;
import com.pulumi.gcp.dataplex.TaskIamBindingArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        var binding = new TaskIamBinding("binding", TaskIamBindingArgs.builder()
            .project(example.project())
            .location(example.location())
            .lake(example.lake())
            .taskId(example.taskId())
            .role("roles/viewer")
            .members("user:jane@example.com")
            .build());

    }
}
```
```yaml
resources:
  binding:
    type: gcp:dataplex:TaskIamBinding
    properties:
      project: ${example.project}
      location: ${example.location}
      lake: ${example.lake}
      taskId: ${example.taskId}
      role: roles/viewer
      members:
        - user:jane@example.com
```
<!--End PulumiCodeChooser -->

## gcp.dataplex.TaskIamMember

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const member = new gcp.dataplex.TaskIamMember("member", {
    project: example.project,
    location: example.location,
    lake: example.lake,
    taskId: example.taskId,
    role: "roles/viewer",
    member: "user:jane@example.com",
});
```
```python
import pulumi
import pulumi_gcp as gcp

member = gcp.dataplex.TaskIamMember("member",
    project=example["project"],
    location=example["location"],
    lake=example["lake"],
    task_id=example["taskId"],
    role="roles/viewer",
    member="user:jane@example.com")
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var member = new Gcp.DataPlex.TaskIamMember("member", new()
    {
        Project = example.Project,
        Location = example.Location,
        Lake = example.Lake,
        TaskId = example.TaskId,
        Role = "roles/viewer",
        Member = "user:jane@example.com",
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/dataplex"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		_, err := dataplex.NewTaskIamMember(ctx, "member", &dataplex.TaskIamMemberArgs{
			Project:  pulumi.Any(example.Project),
			Location: pulumi.Any(example.Location),
			Lake:     pulumi.Any(example.Lake),
			TaskId:   pulumi.Any(example.TaskId),
			Role:     pulumi.String("roles/viewer"),
			Member:   pulumi.String("user:jane@example.com"),
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.dataplex.TaskIamMember;
import com.pulumi.gcp.dataplex.TaskIamMemberArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        var member = new TaskIamMember("member", TaskIamMemberArgs.builder()
            .project(example.project())
            .location(example.location())
            .lake(example.lake())
            .taskId(example.taskId())
            .role("roles/viewer")
            .member("user:jane@example.com")
            .build());

    }
}
```
```yaml
resources:
  member:
    type: gcp:dataplex:TaskIamMember
    properties:
      project: ${example.project}
      location: ${example.location}
      lake: ${example.lake}
      taskId: ${example.taskId}
      role: roles/viewer
      member: user:jane@example.com
```
<!--End PulumiCodeChooser -->


## This resource supports User Project Overrides.

-

# IAM policy for Dataplex Task
Three different resources help you manage your IAM policy for Dataplex Task. Each of these resources serves a different use case:

* `gcp.dataplex.TaskIamPolicy`: Authoritative. Sets the IAM policy for the task and replaces any existing policy already attached.
* `gcp.dataplex.TaskIamBinding`: Authoritative for a given role. Updates the IAM policy to grant a role to a list of members. Other roles within the IAM policy for the task are preserved.
* `gcp.dataplex.TaskIamMember`: Non-authoritative. Updates the IAM policy to grant a role to a new member. Other members for the role for the task are preserved.

A data source can be used to retrieve policy data in advent you do not need creation

* `gcp.dataplex.TaskIamPolicy`: Retrieves the IAM policy for the task

> **Note:** `gcp.dataplex.TaskIamPolicy` **cannot** be used in conjunction with `gcp.dataplex.TaskIamBinding` and `gcp.dataplex.TaskIamMember` or they will fight over what your policy should be.

> **Note:** `gcp.dataplex.TaskIamBinding` resources **can be** used in conjunction with `gcp.dataplex.TaskIamMember` resources **only if** they do not grant privilege to the same role.



## gcp.dataplex.TaskIamPolicy

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const admin = gcp.organizations.getIAMPolicy({
    bindings: [{
        role: "roles/viewer",
        members: ["user:jane@example.com"],
    }],
});
const policy = new gcp.dataplex.TaskIamPolicy("policy", {
    project: example.project,
    location: example.location,
    lake: example.lake,
    taskId: example.taskId,
    policyData: admin.then(admin => admin.policyData),
});
```
```python
import pulumi
import pulumi_gcp as gcp

admin = gcp.organizations.get_iam_policy(bindings=[{
    "role": "roles/viewer",
    "members": ["user:jane@example.com"],
}])
policy = gcp.dataplex.TaskIamPolicy("policy",
    project=example["project"],
    location=example["location"],
    lake=example["lake"],
    task_id=example["taskId"],
    policy_data=admin.policy_data)
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var admin = Gcp.Organizations.GetIAMPolicy.Invoke(new()
    {
        Bindings = new[]
        {
            new Gcp.Organizations.Inputs.GetIAMPolicyBindingInputArgs
            {
                Role = "roles/viewer",
                Members = new[]
                {
                    "user:jane@example.com",
                },
            },
        },
    });

    var policy = new Gcp.DataPlex.TaskIamPolicy("policy", new()
    {
        Project = example.Project,
        Location = example.Location,
        Lake = example.Lake,
        TaskId = example.TaskId,
        PolicyData = admin.Apply(getIAMPolicyResult => getIAMPolicyResult.PolicyData),
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/dataplex"
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/organizations"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		admin, err := organizations.LookupIAMPolicy(ctx, &organizations.LookupIAMPolicyArgs{
			Bindings: []organizations.GetIAMPolicyBinding{
				{
					Role: "roles/viewer",
					Members: []string{
						"user:jane@example.com",
					},
				},
			},
		}, nil)
		if err != nil {
			return err
		}
		_, err = dataplex.NewTaskIamPolicy(ctx, "policy", &dataplex.TaskIamPolicyArgs{
			Project:    pulumi.Any(example.Project),
			Location:   pulumi.Any(example.Location),
			Lake:       pulumi.Any(example.Lake),
			TaskId:     pulumi.Any(example.TaskId),
			PolicyData: pulumi.String(admin.PolicyData),
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.organizations.OrganizationsFunctions;
import com.pulumi.gcp.organizations.inputs.GetIAMPolicyArgs;
import com.pulumi.gcp.dataplex.TaskIamPolicy;
import com.pulumi.gcp.dataplex.TaskIamPolicyArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        final var admin = OrganizationsFunctions.getIAMPolicy(GetIAMPolicyArgs.builder()
            .bindings(GetIAMPolicyBindingArgs.builder()
                .role("roles/viewer")
                .members("user:jane@example.com")
                .build())
            .build());

        var policy = new TaskIamPolicy("policy", TaskIamPolicyArgs.builder()
            .project(example.project())
            .location(example.location())
            .lake(example.lake())
            .taskId(example.taskId())
            .policyData(admin.applyValue(getIAMPolicyResult -> getIAMPolicyResult.policyData()))
            .build());

    }
}
```
```yaml
resources:
  policy:
    type: gcp:dataplex:TaskIamPolicy
    properties:
      project: ${example.project}
      location: ${example.location}
      lake: ${example.lake}
      taskId: ${example.taskId}
      policyData: ${admin.policyData}
variables:
  admin:
    fn::invoke:
      function: gcp:organizations:getIAMPolicy
      arguments:
        bindings:
          - role: roles/viewer
            members:
              - user:jane@example.com
```
<!--End PulumiCodeChooser -->

## gcp.dataplex.TaskIamBinding

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const binding = new gcp.dataplex.TaskIamBinding("binding", {
    project: example.project,
    location: example.location,
    lake: example.lake,
    taskId: example.taskId,
    role: "roles/viewer",
    members: ["user:jane@example.com"],
});
```
```python
import pulumi
import pulumi_gcp as gcp

binding = gcp.dataplex.TaskIamBinding("binding",
    project=example["project"],
    location=example["location"],
    lake=example["lake"],
    task_id=example["taskId"],
    role="roles/viewer",
    members=["user:jane@example.com"])
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var binding = new Gcp.DataPlex.TaskIamBinding("binding", new()
    {
        Project = example.Project,
        Location = example.Location,
        Lake = example.Lake,
        TaskId = example.TaskId,
        Role = "roles/viewer",
        Members = new[]
        {
            "user:jane@example.com",
        },
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/dataplex"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		_, err := dataplex.NewTaskIamBinding(ctx, "binding", &dataplex.TaskIamBindingArgs{
			Project:  pulumi.Any(example.Project),
			Location: pulumi.Any(example.Location),
			Lake:     pulumi.Any(example.Lake),
			TaskId:   pulumi.Any(example.TaskId),
			Role:     pulumi.String("roles/viewer"),
			Members: pulumi.StringArray{
				pulumi.String("user:jane@example.com"),
			},
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.dataplex.TaskIamBinding;
import com.pulumi.gcp.dataplex.TaskIamBindingArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        var binding = new TaskIamBinding("binding", TaskIamBindingArgs.builder()
            .project(example.project())
            .location(example.location())
            .lake(example.lake())
            .taskId(example.taskId())
            .role("roles/viewer")
            .members("user:jane@example.com")
            .build());

    }
}
```
```yaml
resources:
  binding:
    type: gcp:dataplex:TaskIamBinding
    properties:
      project: ${example.project}
      location: ${example.location}
      lake: ${example.lake}
      taskId: ${example.taskId}
      role: roles/viewer
      members:
        - user:jane@example.com
```
<!--End PulumiCodeChooser -->

## gcp.dataplex.TaskIamMember

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const member = new gcp.dataplex.TaskIamMember("member", {
    project: example.project,
    location: example.location,
    lake: example.lake,
    taskId: example.taskId,
    role: "roles/viewer",
    member: "user:jane@example.com",
});
```
```python
import pulumi
import pulumi_gcp as gcp

member = gcp.dataplex.TaskIamMember("member",
    project=example["project"],
    location=example["location"],
    lake=example["lake"],
    task_id=example["taskId"],
    role="roles/viewer",
    member="user:jane@example.com")
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var member = new Gcp.DataPlex.TaskIamMember("member", new()
    {
        Project = example.Project,
        Location = example.Location,
        Lake = example.Lake,
        TaskId = example.TaskId,
        Role = "roles/viewer",
        Member = "user:jane@example.com",
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/dataplex"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		_, err := dataplex.NewTaskIamMember(ctx, "member", &dataplex.TaskIamMemberArgs{
			Project:  pulumi.Any(example.Project),
			Location: pulumi.Any(example.Location),
			Lake:     pulumi.Any(example.Lake),
			TaskId:   pulumi.Any(example.TaskId),
			Role:     pulumi.String("roles/viewer"),
			Member:   pulumi.String("user:jane@example.com"),
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.dataplex.TaskIamMember;
import com.pulumi.gcp.dataplex.TaskIamMemberArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        var member = new TaskIamMember("member", TaskIamMemberArgs.builder()
            .project(example.project())
            .location(example.location())
            .lake(example.lake())
            .taskId(example.taskId())
            .role("roles/viewer")
            .member("user:jane@example.com")
            .build());

    }
}
```
```yaml
resources:
  member:
    type: gcp:dataplex:TaskIamMember
    properties:
      project: ${example.project}
      location: ${example.location}
      lake: ${example.lake}
      taskId: ${example.taskId}
      role: roles/viewer
      member: user:jane@example.com
```
<!--End PulumiCodeChooser -->

## Import

For all import syntaxes, the "resource in question" can take any of the following forms:

* projects/{{project}}/locations/{{location}}/lakes/{{lake}}/tasks/{{task_id}}

* {{project}}/{{location}}/{{lake}}/{{task_id}}

* {{location}}/{{lake}}/{{task_id}}

* {{task_id}}

Any variables not passed in the import command will be taken from the provider configuration.

Dataplex task IAM resources can be imported using the resource identifiers, role, and member.

IAM member imports use space-delimited identifiers: the resource in question, the role, and the member identity, e.g.

```sh
$ pulumi import gcp:dataplex/taskIamMember:TaskIamMember editor "projects/{{project}}/locations/{{location}}/lakes/{{lake}}/tasks/{{task_id}} roles/viewer user:jane@example.com"
```

IAM binding imports use space-delimited identifiers: the resource in question and the role, e.g.

```sh
$ pulumi import gcp:dataplex/taskIamMember:TaskIamMember editor "projects/{{project}}/locations/{{location}}/lakes/{{lake}}/tasks/{{task_id}} roles/viewer"
```

IAM policy imports use the identifier of the resource in question, e.g.

```sh
$ pulumi import gcp:dataplex/taskIamMember:TaskIamMember editor projects/{{project}}/locations/{{location}}/lakes/{{lake}}/tasks/{{task_id}}
```

-> **Custom Roles** If you're importing a IAM resource with a custom role, make sure to use the

 full name of the custom role, e.g. `[projects/my-project|organizations/my-org]/roles/my-custom-role`.

q
	conditiondBb:`
^
dataplexTaskIamMemberCondition:gcp:dataplex/TaskIamMemberCondition:TaskIamMemberConditionv
lake" jThe lake in which the task will be created in.
Used to find the parent resource to bind the IAM policy to
Ø
locationB" ÅThe location in which the task will be created in.
Used to find the parent resource to bind the IAM policy to. If not specified,
the value will be parsed from the identifier of the parent resource. If no location is provided in the parent identifier and no
location is specified, it is taken from the provider configuration.
Ó	
member" Ä	Identities that will be granted the privilege in `role`.
Each entry can have one of the following values:
* **allUsers**: A special identifier that represents anyone who is on the internet; with or without a Google account.
* **allAuthenticatedUsers**: A special identifier that represents anyone who is authenticated with a Google account or a service account.
* **user:{emailid}**: An email address that represents a specific Google account. For example, alice@gmail.com or joe@example.com.
* **serviceAccount:{emailid}**: An email address that represents a service account. For example, my-other-app@appspot.gserviceaccount.com.
* **group:{emailid}**: An email address that represents a Google group. For example, admins@example.com.
* **domain:{domain}**: A G Suite domain (primary, instead of alias) name that represents all the users of that domain. For example, google.com or example.com.
* **projectOwner:projectid**: Owners of the given project. For example, "projectOwner:my-example-project"
* **projectEditor:projectid**: Editors of the given project. For example, "projectEditor:my-example-project"
* **projectViewer:projectid**: Viewers of the given project. For example, "projectViewer:my-example-project"

projectB" The ID of the project in which the resource belongs.
If it is not provided, the project will be parsed from the identifier of the parent resource. If no project is provided in the parent identifier and no project is specified, the provider project is used.
Ô
role" ÇThe role that should be applied. Only one
`gcp.dataplex.TaskIamBinding` can be used per role. Note that custom roles must be of the format
`[projects|organizations]/{parent-name}/roles/{role-name}`.

taskId" "q
	conditiondBb:`
^
dataplexTaskIamMemberCondition:gcp:dataplex/TaskIamMemberCondition:TaskIamMemberCondition"3
etag" '(Computed) The etag of the IAM policy.
"v
lake" jThe lake in which the task will be created in.
Used to find the parent resource to bind the IAM policy to
"Ö
location" ÅThe location in which the task will be created in.
Used to find the parent resource to bind the IAM policy to. If not specified,
the value will be parsed from the identifier of the parent resource. If no location is provided in the parent identifier and no
location is specified, it is taken from the provider configuration.
"Ó	
member" Ä	Identities that will be granted the privilege in `role`.
Each entry can have one of the following values:
* **allUsers**: A special identifier that represents anyone who is on the internet; with or without a Google account.
* **allAuthenticatedUsers**: A special identifier that represents anyone who is authenticated with a Google account or a service account.
* **user:{emailid}**: An email address that represents a specific Google account. For example, alice@gmail.com or joe@example.com.
* **serviceAccount:{emailid}**: An email address that represents a service account. For example, my-other-app@appspot.gserviceaccount.com.
* **group:{emailid}**: An email address that represents a Google group. For example, admins@example.com.
* **domain:{domain}**: A G Suite domain (primary, instead of alias) name that represents all the users of that domain. For example, google.com or example.com.
* **projectOwner:projectid**: Owners of the given project. For example, "projectOwner:my-example-project"
* **projectEditor:projectid**: Editors of the given project. For example, "projectEditor:my-example-project"
* **projectViewer:projectid**: Viewers of the given project. For example, "projectViewer:my-example-project"
"
project" The ID of the project in which the resource belongs.
If it is not provided, the project will be parsed from the identifier of the parent resource. If no project is provided in the parent identifier and no project is specified, the provider project is used.
"Ô
role" ÇThe role that should be applied. Only one
`gcp.dataplex.TaskIamBinding` can be used per role. Note that custom roles must be of the format
`[projects|organizations]/{parent-name}/roles/{role-name}`.
"
taskId" *çÍ
C
dataplexTaskIamPolicy(gcp:dataplex/taskIamPolicy:TaskIamPolicy½¿Three different resources help you manage your IAM policy for Dataplex Task. Each of these resources serves a different use case:

* `gcp.dataplex.TaskIamPolicy`: Authoritative. Sets the IAM policy for the task and replaces any existing policy already attached.
* `gcp.dataplex.TaskIamBinding`: Authoritative for a given role. Updates the IAM policy to grant a role to a list of members. Other roles within the IAM policy for the task are preserved.
* `gcp.dataplex.TaskIamMember`: Non-authoritative. Updates the IAM policy to grant a role to a new member. Other members for the role for the task are preserved.

A data source can be used to retrieve policy data in advent you do not need creation

* `gcp.dataplex.TaskIamPolicy`: Retrieves the IAM policy for the task

> **Note:** `gcp.dataplex.TaskIamPolicy` **cannot** be used in conjunction with `gcp.dataplex.TaskIamBinding` and `gcp.dataplex.TaskIamMember` or they will fight over what your policy should be.

> **Note:** `gcp.dataplex.TaskIamBinding` resources **can be** used in conjunction with `gcp.dataplex.TaskIamMember` resources **only if** they do not grant privilege to the same role.



## gcp.dataplex.TaskIamPolicy

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const admin = gcp.organizations.getIAMPolicy({
    bindings: [{
        role: "roles/viewer",
        members: ["user:jane@example.com"],
    }],
});
const policy = new gcp.dataplex.TaskIamPolicy("policy", {
    project: example.project,
    location: example.location,
    lake: example.lake,
    taskId: example.taskId,
    policyData: admin.then(admin => admin.policyData),
});
```
```python
import pulumi
import pulumi_gcp as gcp

admin = gcp.organizations.get_iam_policy(bindings=[{
    "role": "roles/viewer",
    "members": ["user:jane@example.com"],
}])
policy = gcp.dataplex.TaskIamPolicy("policy",
    project=example["project"],
    location=example["location"],
    lake=example["lake"],
    task_id=example["taskId"],
    policy_data=admin.policy_data)
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var admin = Gcp.Organizations.GetIAMPolicy.Invoke(new()
    {
        Bindings = new[]
        {
            new Gcp.Organizations.Inputs.GetIAMPolicyBindingInputArgs
            {
                Role = "roles/viewer",
                Members = new[]
                {
                    "user:jane@example.com",
                },
            },
        },
    });

    var policy = new Gcp.DataPlex.TaskIamPolicy("policy", new()
    {
        Project = example.Project,
        Location = example.Location,
        Lake = example.Lake,
        TaskId = example.TaskId,
        PolicyData = admin.Apply(getIAMPolicyResult => getIAMPolicyResult.PolicyData),
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/dataplex"
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/organizations"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		admin, err := organizations.LookupIAMPolicy(ctx, &organizations.LookupIAMPolicyArgs{
			Bindings: []organizations.GetIAMPolicyBinding{
				{
					Role: "roles/viewer",
					Members: []string{
						"user:jane@example.com",
					},
				},
			},
		}, nil)
		if err != nil {
			return err
		}
		_, err = dataplex.NewTaskIamPolicy(ctx, "policy", &dataplex.TaskIamPolicyArgs{
			Project:    pulumi.Any(example.Project),
			Location:   pulumi.Any(example.Location),
			Lake:       pulumi.Any(example.Lake),
			TaskId:     pulumi.Any(example.TaskId),
			PolicyData: pulumi.String(admin.PolicyData),
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.organizations.OrganizationsFunctions;
import com.pulumi.gcp.organizations.inputs.GetIAMPolicyArgs;
import com.pulumi.gcp.dataplex.TaskIamPolicy;
import com.pulumi.gcp.dataplex.TaskIamPolicyArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        final var admin = OrganizationsFunctions.getIAMPolicy(GetIAMPolicyArgs.builder()
            .bindings(GetIAMPolicyBindingArgs.builder()
                .role("roles/viewer")
                .members("user:jane@example.com")
                .build())
            .build());

        var policy = new TaskIamPolicy("policy", TaskIamPolicyArgs.builder()
            .project(example.project())
            .location(example.location())
            .lake(example.lake())
            .taskId(example.taskId())
            .policyData(admin.applyValue(getIAMPolicyResult -> getIAMPolicyResult.policyData()))
            .build());

    }
}
```
```yaml
resources:
  policy:
    type: gcp:dataplex:TaskIamPolicy
    properties:
      project: ${example.project}
      location: ${example.location}
      lake: ${example.lake}
      taskId: ${example.taskId}
      policyData: ${admin.policyData}
variables:
  admin:
    fn::invoke:
      function: gcp:organizations:getIAMPolicy
      arguments:
        bindings:
          - role: roles/viewer
            members:
              - user:jane@example.com
```
<!--End PulumiCodeChooser -->

## gcp.dataplex.TaskIamBinding

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const binding = new gcp.dataplex.TaskIamBinding("binding", {
    project: example.project,
    location: example.location,
    lake: example.lake,
    taskId: example.taskId,
    role: "roles/viewer",
    members: ["user:jane@example.com"],
});
```
```python
import pulumi
import pulumi_gcp as gcp

binding = gcp.dataplex.TaskIamBinding("binding",
    project=example["project"],
    location=example["location"],
    lake=example["lake"],
    task_id=example["taskId"],
    role="roles/viewer",
    members=["user:jane@example.com"])
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var binding = new Gcp.DataPlex.TaskIamBinding("binding", new()
    {
        Project = example.Project,
        Location = example.Location,
        Lake = example.Lake,
        TaskId = example.TaskId,
        Role = "roles/viewer",
        Members = new[]
        {
            "user:jane@example.com",
        },
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/dataplex"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		_, err := dataplex.NewTaskIamBinding(ctx, "binding", &dataplex.TaskIamBindingArgs{
			Project:  pulumi.Any(example.Project),
			Location: pulumi.Any(example.Location),
			Lake:     pulumi.Any(example.Lake),
			TaskId:   pulumi.Any(example.TaskId),
			Role:     pulumi.String("roles/viewer"),
			Members: pulumi.StringArray{
				pulumi.String("user:jane@example.com"),
			},
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.dataplex.TaskIamBinding;
import com.pulumi.gcp.dataplex.TaskIamBindingArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        var binding = new TaskIamBinding("binding", TaskIamBindingArgs.builder()
            .project(example.project())
            .location(example.location())
            .lake(example.lake())
            .taskId(example.taskId())
            .role("roles/viewer")
            .members("user:jane@example.com")
            .build());

    }
}
```
```yaml
resources:
  binding:
    type: gcp:dataplex:TaskIamBinding
    properties:
      project: ${example.project}
      location: ${example.location}
      lake: ${example.lake}
      taskId: ${example.taskId}
      role: roles/viewer
      members:
        - user:jane@example.com
```
<!--End PulumiCodeChooser -->

## gcp.dataplex.TaskIamMember

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const member = new gcp.dataplex.TaskIamMember("member", {
    project: example.project,
    location: example.location,
    lake: example.lake,
    taskId: example.taskId,
    role: "roles/viewer",
    member: "user:jane@example.com",
});
```
```python
import pulumi
import pulumi_gcp as gcp

member = gcp.dataplex.TaskIamMember("member",
    project=example["project"],
    location=example["location"],
    lake=example["lake"],
    task_id=example["taskId"],
    role="roles/viewer",
    member="user:jane@example.com")
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var member = new Gcp.DataPlex.TaskIamMember("member", new()
    {
        Project = example.Project,
        Location = example.Location,
        Lake = example.Lake,
        TaskId = example.TaskId,
        Role = "roles/viewer",
        Member = "user:jane@example.com",
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/dataplex"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		_, err := dataplex.NewTaskIamMember(ctx, "member", &dataplex.TaskIamMemberArgs{
			Project:  pulumi.Any(example.Project),
			Location: pulumi.Any(example.Location),
			Lake:     pulumi.Any(example.Lake),
			TaskId:   pulumi.Any(example.TaskId),
			Role:     pulumi.String("roles/viewer"),
			Member:   pulumi.String("user:jane@example.com"),
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.dataplex.TaskIamMember;
import com.pulumi.gcp.dataplex.TaskIamMemberArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        var member = new TaskIamMember("member", TaskIamMemberArgs.builder()
            .project(example.project())
            .location(example.location())
            .lake(example.lake())
            .taskId(example.taskId())
            .role("roles/viewer")
            .member("user:jane@example.com")
            .build());

    }
}
```
```yaml
resources:
  member:
    type: gcp:dataplex:TaskIamMember
    properties:
      project: ${example.project}
      location: ${example.location}
      lake: ${example.lake}
      taskId: ${example.taskId}
      role: roles/viewer
      member: user:jane@example.com
```
<!--End PulumiCodeChooser -->


## This resource supports User Project Overrides.

-

# IAM policy for Dataplex Task
Three different resources help you manage your IAM policy for Dataplex Task. Each of these resources serves a different use case:

* `gcp.dataplex.TaskIamPolicy`: Authoritative. Sets the IAM policy for the task and replaces any existing policy already attached.
* `gcp.dataplex.TaskIamBinding`: Authoritative for a given role. Updates the IAM policy to grant a role to a list of members. Other roles within the IAM policy for the task are preserved.
* `gcp.dataplex.TaskIamMember`: Non-authoritative. Updates the IAM policy to grant a role to a new member. Other members for the role for the task are preserved.

A data source can be used to retrieve policy data in advent you do not need creation

* `gcp.dataplex.TaskIamPolicy`: Retrieves the IAM policy for the task

> **Note:** `gcp.dataplex.TaskIamPolicy` **cannot** be used in conjunction with `gcp.dataplex.TaskIamBinding` and `gcp.dataplex.TaskIamMember` or they will fight over what your policy should be.

> **Note:** `gcp.dataplex.TaskIamBinding` resources **can be** used in conjunction with `gcp.dataplex.TaskIamMember` resources **only if** they do not grant privilege to the same role.



## gcp.dataplex.TaskIamPolicy

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const admin = gcp.organizations.getIAMPolicy({
    bindings: [{
        role: "roles/viewer",
        members: ["user:jane@example.com"],
    }],
});
const policy = new gcp.dataplex.TaskIamPolicy("policy", {
    project: example.project,
    location: example.location,
    lake: example.lake,
    taskId: example.taskId,
    policyData: admin.then(admin => admin.policyData),
});
```
```python
import pulumi
import pulumi_gcp as gcp

admin = gcp.organizations.get_iam_policy(bindings=[{
    "role": "roles/viewer",
    "members": ["user:jane@example.com"],
}])
policy = gcp.dataplex.TaskIamPolicy("policy",
    project=example["project"],
    location=example["location"],
    lake=example["lake"],
    task_id=example["taskId"],
    policy_data=admin.policy_data)
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var admin = Gcp.Organizations.GetIAMPolicy.Invoke(new()
    {
        Bindings = new[]
        {
            new Gcp.Organizations.Inputs.GetIAMPolicyBindingInputArgs
            {
                Role = "roles/viewer",
                Members = new[]
                {
                    "user:jane@example.com",
                },
            },
        },
    });

    var policy = new Gcp.DataPlex.TaskIamPolicy("policy", new()
    {
        Project = example.Project,
        Location = example.Location,
        Lake = example.Lake,
        TaskId = example.TaskId,
        PolicyData = admin.Apply(getIAMPolicyResult => getIAMPolicyResult.PolicyData),
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/dataplex"
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/organizations"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		admin, err := organizations.LookupIAMPolicy(ctx, &organizations.LookupIAMPolicyArgs{
			Bindings: []organizations.GetIAMPolicyBinding{
				{
					Role: "roles/viewer",
					Members: []string{
						"user:jane@example.com",
					},
				},
			},
		}, nil)
		if err != nil {
			return err
		}
		_, err = dataplex.NewTaskIamPolicy(ctx, "policy", &dataplex.TaskIamPolicyArgs{
			Project:    pulumi.Any(example.Project),
			Location:   pulumi.Any(example.Location),
			Lake:       pulumi.Any(example.Lake),
			TaskId:     pulumi.Any(example.TaskId),
			PolicyData: pulumi.String(admin.PolicyData),
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.organizations.OrganizationsFunctions;
import com.pulumi.gcp.organizations.inputs.GetIAMPolicyArgs;
import com.pulumi.gcp.dataplex.TaskIamPolicy;
import com.pulumi.gcp.dataplex.TaskIamPolicyArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        final var admin = OrganizationsFunctions.getIAMPolicy(GetIAMPolicyArgs.builder()
            .bindings(GetIAMPolicyBindingArgs.builder()
                .role("roles/viewer")
                .members("user:jane@example.com")
                .build())
            .build());

        var policy = new TaskIamPolicy("policy", TaskIamPolicyArgs.builder()
            .project(example.project())
            .location(example.location())
            .lake(example.lake())
            .taskId(example.taskId())
            .policyData(admin.applyValue(getIAMPolicyResult -> getIAMPolicyResult.policyData()))
            .build());

    }
}
```
```yaml
resources:
  policy:
    type: gcp:dataplex:TaskIamPolicy
    properties:
      project: ${example.project}
      location: ${example.location}
      lake: ${example.lake}
      taskId: ${example.taskId}
      policyData: ${admin.policyData}
variables:
  admin:
    fn::invoke:
      function: gcp:organizations:getIAMPolicy
      arguments:
        bindings:
          - role: roles/viewer
            members:
              - user:jane@example.com
```
<!--End PulumiCodeChooser -->

## gcp.dataplex.TaskIamBinding

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const binding = new gcp.dataplex.TaskIamBinding("binding", {
    project: example.project,
    location: example.location,
    lake: example.lake,
    taskId: example.taskId,
    role: "roles/viewer",
    members: ["user:jane@example.com"],
});
```
```python
import pulumi
import pulumi_gcp as gcp

binding = gcp.dataplex.TaskIamBinding("binding",
    project=example["project"],
    location=example["location"],
    lake=example["lake"],
    task_id=example["taskId"],
    role="roles/viewer",
    members=["user:jane@example.com"])
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var binding = new Gcp.DataPlex.TaskIamBinding("binding", new()
    {
        Project = example.Project,
        Location = example.Location,
        Lake = example.Lake,
        TaskId = example.TaskId,
        Role = "roles/viewer",
        Members = new[]
        {
            "user:jane@example.com",
        },
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/dataplex"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		_, err := dataplex.NewTaskIamBinding(ctx, "binding", &dataplex.TaskIamBindingArgs{
			Project:  pulumi.Any(example.Project),
			Location: pulumi.Any(example.Location),
			Lake:     pulumi.Any(example.Lake),
			TaskId:   pulumi.Any(example.TaskId),
			Role:     pulumi.String("roles/viewer"),
			Members: pulumi.StringArray{
				pulumi.String("user:jane@example.com"),
			},
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.dataplex.TaskIamBinding;
import com.pulumi.gcp.dataplex.TaskIamBindingArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        var binding = new TaskIamBinding("binding", TaskIamBindingArgs.builder()
            .project(example.project())
            .location(example.location())
            .lake(example.lake())
            .taskId(example.taskId())
            .role("roles/viewer")
            .members("user:jane@example.com")
            .build());

    }
}
```
```yaml
resources:
  binding:
    type: gcp:dataplex:TaskIamBinding
    properties:
      project: ${example.project}
      location: ${example.location}
      lake: ${example.lake}
      taskId: ${example.taskId}
      role: roles/viewer
      members:
        - user:jane@example.com
```
<!--End PulumiCodeChooser -->

## gcp.dataplex.TaskIamMember

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const member = new gcp.dataplex.TaskIamMember("member", {
    project: example.project,
    location: example.location,
    lake: example.lake,
    taskId: example.taskId,
    role: "roles/viewer",
    member: "user:jane@example.com",
});
```
```python
import pulumi
import pulumi_gcp as gcp

member = gcp.dataplex.TaskIamMember("member",
    project=example["project"],
    location=example["location"],
    lake=example["lake"],
    task_id=example["taskId"],
    role="roles/viewer",
    member="user:jane@example.com")
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var member = new Gcp.DataPlex.TaskIamMember("member", new()
    {
        Project = example.Project,
        Location = example.Location,
        Lake = example.Lake,
        TaskId = example.TaskId,
        Role = "roles/viewer",
        Member = "user:jane@example.com",
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/dataplex"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		_, err := dataplex.NewTaskIamMember(ctx, "member", &dataplex.TaskIamMemberArgs{
			Project:  pulumi.Any(example.Project),
			Location: pulumi.Any(example.Location),
			Lake:     pulumi.Any(example.Lake),
			TaskId:   pulumi.Any(example.TaskId),
			Role:     pulumi.String("roles/viewer"),
			Member:   pulumi.String("user:jane@example.com"),
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.dataplex.TaskIamMember;
import com.pulumi.gcp.dataplex.TaskIamMemberArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        var member = new TaskIamMember("member", TaskIamMemberArgs.builder()
            .project(example.project())
            .location(example.location())
            .lake(example.lake())
            .taskId(example.taskId())
            .role("roles/viewer")
            .member("user:jane@example.com")
            .build());

    }
}
```
```yaml
resources:
  member:
    type: gcp:dataplex:TaskIamMember
    properties:
      project: ${example.project}
      location: ${example.location}
      lake: ${example.lake}
      taskId: ${example.taskId}
      role: roles/viewer
      member: user:jane@example.com
```
<!--End PulumiCodeChooser -->

## Import

For all import syntaxes, the "resource in question" can take any of the following forms:

* projects/{{project}}/locations/{{location}}/lakes/{{lake}}/tasks/{{task_id}}

* {{project}}/{{location}}/{{lake}}/{{task_id}}

* {{location}}/{{lake}}/{{task_id}}

* {{task_id}}

Any variables not passed in the import command will be taken from the provider configuration.

Dataplex task IAM resources can be imported using the resource identifiers, role, and member.

IAM member imports use space-delimited identifiers: the resource in question, the role, and the member identity, e.g.

```sh
$ pulumi import gcp:dataplex/taskIamPolicy:TaskIamPolicy editor "projects/{{project}}/locations/{{location}}/lakes/{{lake}}/tasks/{{task_id}} roles/viewer user:jane@example.com"
```

IAM binding imports use space-delimited identifiers: the resource in question and the role, e.g.

```sh
$ pulumi import gcp:dataplex/taskIamPolicy:TaskIamPolicy editor "projects/{{project}}/locations/{{location}}/lakes/{{lake}}/tasks/{{task_id}} roles/viewer"
```

IAM policy imports use the identifier of the resource in question, e.g.

```sh
$ pulumi import gcp:dataplex/taskIamPolicy:TaskIamPolicy editor projects/{{project}}/locations/{{location}}/lakes/{{lake}}/tasks/{{task_id}}
```

-> **Custom Roles** If you're importing a IAM resource with a custom role, make sure to use the

 full name of the custom role, e.g. `[projects/my-project|organizations/my-org]/roles/my-custom-role`.

v
lake" jThe lake in which the task will be created in.
Used to find the parent resource to bind the IAM policy to
Ø
locationB" ÅThe location in which the task will be created in.
Used to find the parent resource to bind the IAM policy to. If not specified,
the value will be parsed from the identifier of the parent resource. If no location is provided in the parent identifier and no
location is specified, it is taken from the provider configuration.
_

policyData" MThe policy data generated by
a `gcp.organizations.getIAMPolicy` data source.

projectB" The ID of the project in which the resource belongs.
If it is not provided, the project will be parsed from the identifier of the parent resource. If no project is provided in the parent identifier and no project is specified, the provider project is used.

taskId" "3
etag" '(Computed) The etag of the IAM policy.
"v
lake" jThe lake in which the task will be created in.
Used to find the parent resource to bind the IAM policy to
"Ö
location" ÅThe location in which the task will be created in.
Used to find the parent resource to bind the IAM policy to. If not specified,
the value will be parsed from the identifier of the parent resource. If no location is provided in the parent identifier and no
location is specified, it is taken from the provider configuration.
"_

policyData" MThe policy data generated by
a `gcp.organizations.getIAMPolicy` data source.
"
project" The ID of the project in which the resource belongs.
If it is not provided, the project will be parsed from the identifier of the parent resource. If no project is provided in the parent identifier and no project is specified, the provider project is used.
"
taskId" *ÞK
(
dataplexZonegcp:dataplex/zone:Zoneí3The Dataplex Zone resource

## Example Usage

### Basic_zone
A basic example of a dataplex zone
<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const basic = new gcp.dataplex.Lake("basic", {
    location: "us-west1",
    name: "lake",
    description: "Lake for DCL",
    displayName: "Lake for DCL",
    project: "my-project-name",
    labels: {
        "my-lake": "exists",
    },
});
const primary = new gcp.dataplex.Zone("primary", {
    discoverySpec: {
        enabled: false,
    },
    lake: basic.name,
    location: "us-west1",
    name: "zone",
    resourceSpec: {
        locationType: "MULTI_REGION",
    },
    type: "RAW",
    description: "Zone for DCL",
    displayName: "Zone for DCL",
    project: "my-project-name",
    labels: {},
});
```
```python
import pulumi
import pulumi_gcp as gcp

basic = gcp.dataplex.Lake("basic",
    location="us-west1",
    name="lake",
    description="Lake for DCL",
    display_name="Lake for DCL",
    project="my-project-name",
    labels={
        "my-lake": "exists",
    })
primary = gcp.dataplex.Zone("primary",
    discovery_spec={
        "enabled": False,
    },
    lake=basic.name,
    location="us-west1",
    name="zone",
    resource_spec={
        "location_type": "MULTI_REGION",
    },
    type="RAW",
    description="Zone for DCL",
    display_name="Zone for DCL",
    project="my-project-name",
    labels={})
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var basic = new Gcp.DataPlex.Lake("basic", new()
    {
        Location = "us-west1",
        Name = "lake",
        Description = "Lake for DCL",
        DisplayName = "Lake for DCL",
        Project = "my-project-name",
        Labels = 
        {
            { "my-lake", "exists" },
        },
    });

    var primary = new Gcp.DataPlex.Zone("primary", new()
    {
        DiscoverySpec = new Gcp.DataPlex.Inputs.ZoneDiscoverySpecArgs
        {
            Enabled = false,
        },
        Lake = basic.Name,
        Location = "us-west1",
        Name = "zone",
        ResourceSpec = new Gcp.DataPlex.Inputs.ZoneResourceSpecArgs
        {
            LocationType = "MULTI_REGION",
        },
        Type = "RAW",
        Description = "Zone for DCL",
        DisplayName = "Zone for DCL",
        Project = "my-project-name",
        Labels = null,
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/dataplex"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		basic, err := dataplex.NewLake(ctx, "basic", &dataplex.LakeArgs{
			Location:    pulumi.String("us-west1"),
			Name:        pulumi.String("lake"),
			Description: pulumi.String("Lake for DCL"),
			DisplayName: pulumi.String("Lake for DCL"),
			Project:     pulumi.String("my-project-name"),
			Labels: pulumi.StringMap{
				"my-lake": pulumi.String("exists"),
			},
		})
		if err != nil {
			return err
		}
		_, err = dataplex.NewZone(ctx, "primary", &dataplex.ZoneArgs{
			DiscoverySpec: &dataplex.ZoneDiscoverySpecArgs{
				Enabled: pulumi.Bool(false),
			},
			Lake:     basic.Name,
			Location: pulumi.String("us-west1"),
			Name:     pulumi.String("zone"),
			ResourceSpec: &dataplex.ZoneResourceSpecArgs{
				LocationType: pulumi.String("MULTI_REGION"),
			},
			Type:        pulumi.String("RAW"),
			Description: pulumi.String("Zone for DCL"),
			DisplayName: pulumi.String("Zone for DCL"),
			Project:     pulumi.String("my-project-name"),
			Labels:      pulumi.StringMap{},
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.dataplex.Lake;
import com.pulumi.gcp.dataplex.LakeArgs;
import com.pulumi.gcp.dataplex.Zone;
import com.pulumi.gcp.dataplex.ZoneArgs;
import com.pulumi.gcp.dataplex.inputs.ZoneDiscoverySpecArgs;
import com.pulumi.gcp.dataplex.inputs.ZoneResourceSpecArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        var basic = new Lake("basic", LakeArgs.builder()
            .location("us-west1")
            .name("lake")
            .description("Lake for DCL")
            .displayName("Lake for DCL")
            .project("my-project-name")
            .labels(Map.of("my-lake", "exists"))
            .build());

        var primary = new Zone("primary", ZoneArgs.builder()
            .discoverySpec(ZoneDiscoverySpecArgs.builder()
                .enabled(false)
                .build())
            .lake(basic.name())
            .location("us-west1")
            .name("zone")
            .resourceSpec(ZoneResourceSpecArgs.builder()
                .locationType("MULTI_REGION")
                .build())
            .type("RAW")
            .description("Zone for DCL")
            .displayName("Zone for DCL")
            .project("my-project-name")
            .labels()
            .build());

    }
}
```
```yaml
resources:
  primary:
    type: gcp:dataplex:Zone
    properties:
      discoverySpec:
        enabled: false
      lake: ${basic.name}
      location: us-west1
      name: zone
      resourceSpec:
        locationType: MULTI_REGION
      type: RAW
      description: Zone for DCL
      displayName: Zone for DCL
      project: my-project-name
      labels: {}
  basic:
    type: gcp:dataplex:Lake
    properties:
      location: us-west1
      name: lake
      description: Lake for DCL
      displayName: Lake for DCL
      project: my-project-name
      labels:
        my-lake: exists
```
<!--End PulumiCodeChooser -->

## Import

Zone can be imported using any of these accepted formats:

* `projects/{{project}}/locations/{{location}}/lakes/{{lake}}/zones/{{name}}`

* `{{project}}/{{location}}/{{lake}}/{{name}}`

* `{{location}}/{{lake}}/{{name}}`

When using the `pulumi import` command, Zone can be imported using one of the formats above. For example:

```sh
$ pulumi import gcp:dataplex/zone:Zone default projects/{{project}}/locations/{{location}}/lakes/{{lake}}/zones/{{name}}
```

```sh
$ pulumi import gcp:dataplex/zone:Zone default {{project}}/{{location}}/{{lake}}/{{name}}
```

```sh
$ pulumi import gcp:dataplex/zone:Zone default {{location}}/{{lake}}/{{name}}
```

8
descriptionB" #Optional. Description of the zone.
µ
discoverySpecS:Q
O
dataplexZoneDiscoverySpec0gcp:dataplex/ZoneDiscoverySpec:ZoneDiscoverySpecORequired. Specification of the discovery feature applied to data in this zone.
;
displayNameB" &Optional. User friendly display name.

labelsB2" òOptional. User defined labels for the zone. **Note**: This field is non-authoritative, and will only manage the labels
present in your configuration. Please refer to the field `effective_labels` for all of the labels present on the
resource.
&
lake" The lake for the resource
.
location" The location for the resource
$
nameB" The name of the zone.
.
projectB" The project for the resource
Ê
resourceSpecP:N
L
dataplexZoneResourceSpec.gcp:dataplex/ZoneResourceSpec:ZoneResourceSpechRequired. Immutable. Specification of the resources that are referenced by the assets within this zone.
g
type" [Required. Immutable. The type of the zone. Possible values: TYPE_UNSPECIFIED, RAW, CURATED
"§
assetStatusesO*M:K
I
dataplexZoneAssetStatus,gcp:dataplex/ZoneAssetStatus:ZoneAssetStatusEOutput only. Aggregated status of the underlying assets of the zone.
"C

createTime" 1Output only. The time when the zone was created.
"8
descriptionB" #Optional. Description of the zone.
"µ
discoverySpecS:Q
O
dataplexZoneDiscoverySpec0gcp:dataplex/ZoneDiscoverySpec:ZoneDiscoverySpecORequired. Specification of the discovery feature applied to data in this zone.
";
displayNameB" &Optional. User friendly display name.
"¦
effectiveLabels2" All of labels (key/value pairs) present on the resource in GCP, including the labels configured through Pulumi, other clients and services.
"
labelsB2" òOptional. User defined labels for the zone. **Note**: This field is non-authoritative, and will only manage the labels
present in your configuration. Please refer to the field `effective_labels` for all of the labels present on the
resource.
"&
lake" The lake for the resource
".
location" The location for the resource
""
name" The name of the zone.
",
project" The project for the resource
"
pulumiLabels2" mThe combination of labels configured directly on the resource and default labels configured on the provider.
"Ê
resourceSpecP:N
L
dataplexZoneResourceSpec.gcp:dataplex/ZoneResourceSpec:ZoneResourceSpechRequired. Immutable. Specification of the resources that are referenced by the assets within this zone.
"
state" xOutput only. Current state of the zone. Possible values: STATE_UNSPECIFIED, ACTIVE, CREATING, DELETING, ACTION_REQUIRED
"g
type" [Required. Immutable. The type of the zone. Possible values: TYPE_UNSPECIFIED, RAW, CURATED
"
uid" Output only. System generated globally unique ID for the zone. This ID will be different if the zone is deleted and re-created with the same name.
"H

updateTime" 6Output only. The time when the zone was last updated.
*Ùà
F
dataplexZoneIamBinding*gcp:dataplex/zoneIamBinding:ZoneIamBindingÁThree different resources help you manage your IAM policy for Dataplex Zone. Each of these resources serves a different use case:

* `gcp.dataplex.ZoneIamPolicy`: Authoritative. Sets the IAM policy for the zone and replaces any existing policy already attached.
* `gcp.dataplex.ZoneIamBinding`: Authoritative for a given role. Updates the IAM policy to grant a role to a list of members. Other roles within the IAM policy for the zone are preserved.
* `gcp.dataplex.ZoneIamMember`: Non-authoritative. Updates the IAM policy to grant a role to a new member. Other members for the role for the zone are preserved.

A data source can be used to retrieve policy data in advent you do not need creation

* `gcp.dataplex.ZoneIamPolicy`: Retrieves the IAM policy for the zone

> **Note:** `gcp.dataplex.ZoneIamPolicy` **cannot** be used in conjunction with `gcp.dataplex.ZoneIamBinding` and `gcp.dataplex.ZoneIamMember` or they will fight over what your policy should be.

> **Note:** `gcp.dataplex.ZoneIamBinding` resources **can be** used in conjunction with `gcp.dataplex.ZoneIamMember` resources **only if** they do not grant privilege to the same role.



## gcp.dataplex.ZoneIamPolicy

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const admin = gcp.organizations.getIAMPolicy({
    bindings: [{
        role: "roles/viewer",
        members: ["user:jane@example.com"],
    }],
});
const policy = new gcp.dataplex.ZoneIamPolicy("policy", {
    project: example.project,
    location: example.location,
    lake: example.lake,
    dataplexZone: example.name,
    policyData: admin.then(admin => admin.policyData),
});
```
```python
import pulumi
import pulumi_gcp as gcp

admin = gcp.organizations.get_iam_policy(bindings=[{
    "role": "roles/viewer",
    "members": ["user:jane@example.com"],
}])
policy = gcp.dataplex.ZoneIamPolicy("policy",
    project=example["project"],
    location=example["location"],
    lake=example["lake"],
    dataplex_zone=example["name"],
    policy_data=admin.policy_data)
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var admin = Gcp.Organizations.GetIAMPolicy.Invoke(new()
    {
        Bindings = new[]
        {
            new Gcp.Organizations.Inputs.GetIAMPolicyBindingInputArgs
            {
                Role = "roles/viewer",
                Members = new[]
                {
                    "user:jane@example.com",
                },
            },
        },
    });

    var policy = new Gcp.DataPlex.ZoneIamPolicy("policy", new()
    {
        Project = example.Project,
        Location = example.Location,
        Lake = example.Lake,
        DataplexZone = example.Name,
        PolicyData = admin.Apply(getIAMPolicyResult => getIAMPolicyResult.PolicyData),
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/dataplex"
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/organizations"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		admin, err := organizations.LookupIAMPolicy(ctx, &organizations.LookupIAMPolicyArgs{
			Bindings: []organizations.GetIAMPolicyBinding{
				{
					Role: "roles/viewer",
					Members: []string{
						"user:jane@example.com",
					},
				},
			},
		}, nil)
		if err != nil {
			return err
		}
		_, err = dataplex.NewZoneIamPolicy(ctx, "policy", &dataplex.ZoneIamPolicyArgs{
			Project:      pulumi.Any(example.Project),
			Location:     pulumi.Any(example.Location),
			Lake:         pulumi.Any(example.Lake),
			DataplexZone: pulumi.Any(example.Name),
			PolicyData:   pulumi.String(admin.PolicyData),
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.organizations.OrganizationsFunctions;
import com.pulumi.gcp.organizations.inputs.GetIAMPolicyArgs;
import com.pulumi.gcp.dataplex.ZoneIamPolicy;
import com.pulumi.gcp.dataplex.ZoneIamPolicyArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        final var admin = OrganizationsFunctions.getIAMPolicy(GetIAMPolicyArgs.builder()
            .bindings(GetIAMPolicyBindingArgs.builder()
                .role("roles/viewer")
                .members("user:jane@example.com")
                .build())
            .build());

        var policy = new ZoneIamPolicy("policy", ZoneIamPolicyArgs.builder()
            .project(example.project())
            .location(example.location())
            .lake(example.lake())
            .dataplexZone(example.name())
            .policyData(admin.applyValue(getIAMPolicyResult -> getIAMPolicyResult.policyData()))
            .build());

    }
}
```
```yaml
resources:
  policy:
    type: gcp:dataplex:ZoneIamPolicy
    properties:
      project: ${example.project}
      location: ${example.location}
      lake: ${example.lake}
      dataplexZone: ${example.name}
      policyData: ${admin.policyData}
variables:
  admin:
    fn::invoke:
      function: gcp:organizations:getIAMPolicy
      arguments:
        bindings:
          - role: roles/viewer
            members:
              - user:jane@example.com
```
<!--End PulumiCodeChooser -->

## gcp.dataplex.ZoneIamBinding

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const binding = new gcp.dataplex.ZoneIamBinding("binding", {
    project: example.project,
    location: example.location,
    lake: example.lake,
    dataplexZone: example.name,
    role: "roles/viewer",
    members: ["user:jane@example.com"],
});
```
```python
import pulumi
import pulumi_gcp as gcp

binding = gcp.dataplex.ZoneIamBinding("binding",
    project=example["project"],
    location=example["location"],
    lake=example["lake"],
    dataplex_zone=example["name"],
    role="roles/viewer",
    members=["user:jane@example.com"])
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var binding = new Gcp.DataPlex.ZoneIamBinding("binding", new()
    {
        Project = example.Project,
        Location = example.Location,
        Lake = example.Lake,
        DataplexZone = example.Name,
        Role = "roles/viewer",
        Members = new[]
        {
            "user:jane@example.com",
        },
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/dataplex"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		_, err := dataplex.NewZoneIamBinding(ctx, "binding", &dataplex.ZoneIamBindingArgs{
			Project:      pulumi.Any(example.Project),
			Location:     pulumi.Any(example.Location),
			Lake:         pulumi.Any(example.Lake),
			DataplexZone: pulumi.Any(example.Name),
			Role:         pulumi.String("roles/viewer"),
			Members: pulumi.StringArray{
				pulumi.String("user:jane@example.com"),
			},
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.dataplex.ZoneIamBinding;
import com.pulumi.gcp.dataplex.ZoneIamBindingArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        var binding = new ZoneIamBinding("binding", ZoneIamBindingArgs.builder()
            .project(example.project())
            .location(example.location())
            .lake(example.lake())
            .dataplexZone(example.name())
            .role("roles/viewer")
            .members("user:jane@example.com")
            .build());

    }
}
```
```yaml
resources:
  binding:
    type: gcp:dataplex:ZoneIamBinding
    properties:
      project: ${example.project}
      location: ${example.location}
      lake: ${example.lake}
      dataplexZone: ${example.name}
      role: roles/viewer
      members:
        - user:jane@example.com
```
<!--End PulumiCodeChooser -->

## gcp.dataplex.ZoneIamMember

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const member = new gcp.dataplex.ZoneIamMember("member", {
    project: example.project,
    location: example.location,
    lake: example.lake,
    dataplexZone: example.name,
    role: "roles/viewer",
    member: "user:jane@example.com",
});
```
```python
import pulumi
import pulumi_gcp as gcp

member = gcp.dataplex.ZoneIamMember("member",
    project=example["project"],
    location=example["location"],
    lake=example["lake"],
    dataplex_zone=example["name"],
    role="roles/viewer",
    member="user:jane@example.com")
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var member = new Gcp.DataPlex.ZoneIamMember("member", new()
    {
        Project = example.Project,
        Location = example.Location,
        Lake = example.Lake,
        DataplexZone = example.Name,
        Role = "roles/viewer",
        Member = "user:jane@example.com",
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/dataplex"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		_, err := dataplex.NewZoneIamMember(ctx, "member", &dataplex.ZoneIamMemberArgs{
			Project:      pulumi.Any(example.Project),
			Location:     pulumi.Any(example.Location),
			Lake:         pulumi.Any(example.Lake),
			DataplexZone: pulumi.Any(example.Name),
			Role:         pulumi.String("roles/viewer"),
			Member:       pulumi.String("user:jane@example.com"),
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.dataplex.ZoneIamMember;
import com.pulumi.gcp.dataplex.ZoneIamMemberArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        var member = new ZoneIamMember("member", ZoneIamMemberArgs.builder()
            .project(example.project())
            .location(example.location())
            .lake(example.lake())
            .dataplexZone(example.name())
            .role("roles/viewer")
            .member("user:jane@example.com")
            .build());

    }
}
```
```yaml
resources:
  member:
    type: gcp:dataplex:ZoneIamMember
    properties:
      project: ${example.project}
      location: ${example.location}
      lake: ${example.lake}
      dataplexZone: ${example.name}
      role: roles/viewer
      member: user:jane@example.com
```
<!--End PulumiCodeChooser -->


## This resource supports User Project Overrides.

-

# IAM policy for Dataplex Zone
Three different resources help you manage your IAM policy for Dataplex Zone. Each of these resources serves a different use case:

* `gcp.dataplex.ZoneIamPolicy`: Authoritative. Sets the IAM policy for the zone and replaces any existing policy already attached.
* `gcp.dataplex.ZoneIamBinding`: Authoritative for a given role. Updates the IAM policy to grant a role to a list of members. Other roles within the IAM policy for the zone are preserved.
* `gcp.dataplex.ZoneIamMember`: Non-authoritative. Updates the IAM policy to grant a role to a new member. Other members for the role for the zone are preserved.

A data source can be used to retrieve policy data in advent you do not need creation

* `gcp.dataplex.ZoneIamPolicy`: Retrieves the IAM policy for the zone

> **Note:** `gcp.dataplex.ZoneIamPolicy` **cannot** be used in conjunction with `gcp.dataplex.ZoneIamBinding` and `gcp.dataplex.ZoneIamMember` or they will fight over what your policy should be.

> **Note:** `gcp.dataplex.ZoneIamBinding` resources **can be** used in conjunction with `gcp.dataplex.ZoneIamMember` resources **only if** they do not grant privilege to the same role.



## gcp.dataplex.ZoneIamPolicy

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const admin = gcp.organizations.getIAMPolicy({
    bindings: [{
        role: "roles/viewer",
        members: ["user:jane@example.com"],
    }],
});
const policy = new gcp.dataplex.ZoneIamPolicy("policy", {
    project: example.project,
    location: example.location,
    lake: example.lake,
    dataplexZone: example.name,
    policyData: admin.then(admin => admin.policyData),
});
```
```python
import pulumi
import pulumi_gcp as gcp

admin = gcp.organizations.get_iam_policy(bindings=[{
    "role": "roles/viewer",
    "members": ["user:jane@example.com"],
}])
policy = gcp.dataplex.ZoneIamPolicy("policy",
    project=example["project"],
    location=example["location"],
    lake=example["lake"],
    dataplex_zone=example["name"],
    policy_data=admin.policy_data)
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var admin = Gcp.Organizations.GetIAMPolicy.Invoke(new()
    {
        Bindings = new[]
        {
            new Gcp.Organizations.Inputs.GetIAMPolicyBindingInputArgs
            {
                Role = "roles/viewer",
                Members = new[]
                {
                    "user:jane@example.com",
                },
            },
        },
    });

    var policy = new Gcp.DataPlex.ZoneIamPolicy("policy", new()
    {
        Project = example.Project,
        Location = example.Location,
        Lake = example.Lake,
        DataplexZone = example.Name,
        PolicyData = admin.Apply(getIAMPolicyResult => getIAMPolicyResult.PolicyData),
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/dataplex"
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/organizations"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		admin, err := organizations.LookupIAMPolicy(ctx, &organizations.LookupIAMPolicyArgs{
			Bindings: []organizations.GetIAMPolicyBinding{
				{
					Role: "roles/viewer",
					Members: []string{
						"user:jane@example.com",
					},
				},
			},
		}, nil)
		if err != nil {
			return err
		}
		_, err = dataplex.NewZoneIamPolicy(ctx, "policy", &dataplex.ZoneIamPolicyArgs{
			Project:      pulumi.Any(example.Project),
			Location:     pulumi.Any(example.Location),
			Lake:         pulumi.Any(example.Lake),
			DataplexZone: pulumi.Any(example.Name),
			PolicyData:   pulumi.String(admin.PolicyData),
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.organizations.OrganizationsFunctions;
import com.pulumi.gcp.organizations.inputs.GetIAMPolicyArgs;
import com.pulumi.gcp.dataplex.ZoneIamPolicy;
import com.pulumi.gcp.dataplex.ZoneIamPolicyArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        final var admin = OrganizationsFunctions.getIAMPolicy(GetIAMPolicyArgs.builder()
            .bindings(GetIAMPolicyBindingArgs.builder()
                .role("roles/viewer")
                .members("user:jane@example.com")
                .build())
            .build());

        var policy = new ZoneIamPolicy("policy", ZoneIamPolicyArgs.builder()
            .project(example.project())
            .location(example.location())
            .lake(example.lake())
            .dataplexZone(example.name())
            .policyData(admin.applyValue(getIAMPolicyResult -> getIAMPolicyResult.policyData()))
            .build());

    }
}
```
```yaml
resources:
  policy:
    type: gcp:dataplex:ZoneIamPolicy
    properties:
      project: ${example.project}
      location: ${example.location}
      lake: ${example.lake}
      dataplexZone: ${example.name}
      policyData: ${admin.policyData}
variables:
  admin:
    fn::invoke:
      function: gcp:organizations:getIAMPolicy
      arguments:
        bindings:
          - role: roles/viewer
            members:
              - user:jane@example.com
```
<!--End PulumiCodeChooser -->

## gcp.dataplex.ZoneIamBinding

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const binding = new gcp.dataplex.ZoneIamBinding("binding", {
    project: example.project,
    location: example.location,
    lake: example.lake,
    dataplexZone: example.name,
    role: "roles/viewer",
    members: ["user:jane@example.com"],
});
```
```python
import pulumi
import pulumi_gcp as gcp

binding = gcp.dataplex.ZoneIamBinding("binding",
    project=example["project"],
    location=example["location"],
    lake=example["lake"],
    dataplex_zone=example["name"],
    role="roles/viewer",
    members=["user:jane@example.com"])
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var binding = new Gcp.DataPlex.ZoneIamBinding("binding", new()
    {
        Project = example.Project,
        Location = example.Location,
        Lake = example.Lake,
        DataplexZone = example.Name,
        Role = "roles/viewer",
        Members = new[]
        {
            "user:jane@example.com",
        },
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/dataplex"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		_, err := dataplex.NewZoneIamBinding(ctx, "binding", &dataplex.ZoneIamBindingArgs{
			Project:      pulumi.Any(example.Project),
			Location:     pulumi.Any(example.Location),
			Lake:         pulumi.Any(example.Lake),
			DataplexZone: pulumi.Any(example.Name),
			Role:         pulumi.String("roles/viewer"),
			Members: pulumi.StringArray{
				pulumi.String("user:jane@example.com"),
			},
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.dataplex.ZoneIamBinding;
import com.pulumi.gcp.dataplex.ZoneIamBindingArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        var binding = new ZoneIamBinding("binding", ZoneIamBindingArgs.builder()
            .project(example.project())
            .location(example.location())
            .lake(example.lake())
            .dataplexZone(example.name())
            .role("roles/viewer")
            .members("user:jane@example.com")
            .build());

    }
}
```
```yaml
resources:
  binding:
    type: gcp:dataplex:ZoneIamBinding
    properties:
      project: ${example.project}
      location: ${example.location}
      lake: ${example.lake}
      dataplexZone: ${example.name}
      role: roles/viewer
      members:
        - user:jane@example.com
```
<!--End PulumiCodeChooser -->

## gcp.dataplex.ZoneIamMember

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const member = new gcp.dataplex.ZoneIamMember("member", {
    project: example.project,
    location: example.location,
    lake: example.lake,
    dataplexZone: example.name,
    role: "roles/viewer",
    member: "user:jane@example.com",
});
```
```python
import pulumi
import pulumi_gcp as gcp

member = gcp.dataplex.ZoneIamMember("member",
    project=example["project"],
    location=example["location"],
    lake=example["lake"],
    dataplex_zone=example["name"],
    role="roles/viewer",
    member="user:jane@example.com")
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var member = new Gcp.DataPlex.ZoneIamMember("member", new()
    {
        Project = example.Project,
        Location = example.Location,
        Lake = example.Lake,
        DataplexZone = example.Name,
        Role = "roles/viewer",
        Member = "user:jane@example.com",
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/dataplex"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		_, err := dataplex.NewZoneIamMember(ctx, "member", &dataplex.ZoneIamMemberArgs{
			Project:      pulumi.Any(example.Project),
			Location:     pulumi.Any(example.Location),
			Lake:         pulumi.Any(example.Lake),
			DataplexZone: pulumi.Any(example.Name),
			Role:         pulumi.String("roles/viewer"),
			Member:       pulumi.String("user:jane@example.com"),
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.dataplex.ZoneIamMember;
import com.pulumi.gcp.dataplex.ZoneIamMemberArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        var member = new ZoneIamMember("member", ZoneIamMemberArgs.builder()
            .project(example.project())
            .location(example.location())
            .lake(example.lake())
            .dataplexZone(example.name())
            .role("roles/viewer")
            .member("user:jane@example.com")
            .build());

    }
}
```
```yaml
resources:
  member:
    type: gcp:dataplex:ZoneIamMember
    properties:
      project: ${example.project}
      location: ${example.location}
      lake: ${example.lake}
      dataplexZone: ${example.name}
      role: roles/viewer
      member: user:jane@example.com
```
<!--End PulumiCodeChooser -->

## Import

For all import syntaxes, the "resource in question" can take any of the following forms:

* projects/{{project}}/locations/{{location}}/lakes/{{lake}}/zones/{{name}}

* {{project}}/{{location}}/{{lake}}/{{name}}

* {{location}}/{{lake}}/{{name}}

* {{name}}

Any variables not passed in the import command will be taken from the provider configuration.

Dataplex zone IAM resources can be imported using the resource identifiers, role, and member.

IAM member imports use space-delimited identifiers: the resource in question, the role, and the member identity, e.g.

```sh
$ pulumi import gcp:dataplex/zoneIamBinding:ZoneIamBinding editor "projects/{{project}}/locations/{{location}}/lakes/{{lake}}/zones/{{zone}} roles/viewer user:jane@example.com"
```

IAM binding imports use space-delimited identifiers: the resource in question and the role, e.g.

```sh
$ pulumi import gcp:dataplex/zoneIamBinding:ZoneIamBinding editor "projects/{{project}}/locations/{{location}}/lakes/{{lake}}/zones/{{zone}} roles/viewer"
```

IAM policy imports use the identifier of the resource in question, e.g.

```sh
$ pulumi import gcp:dataplex/zoneIamBinding:ZoneIamBinding editor projects/{{project}}/locations/{{location}}/lakes/{{lake}}/zones/{{zone}}
```

-> **Custom Roles** If you're importing a IAM resource with a custom role, make sure to use the

 full name of the custom role, e.g. `[projects/my-project|organizations/my-org]/roles/my-custom-role`.

t
	conditiongBe:c
a
dataplexZoneIamBindingCondition<gcp:dataplex/ZoneIamBindingCondition:ZoneIamBindingConditionO
dataplexZone" ;Used to find the parent resource to bind the IAM policy to


lake" 
locationB" Ö	
members*" Ä	Identities that will be granted the privilege in `role`.
Each entry can have one of the following values:
* **allUsers**: A special identifier that represents anyone who is on the internet; with or without a Google account.
* **allAuthenticatedUsers**: A special identifier that represents anyone who is authenticated with a Google account or a service account.
* **user:{emailid}**: An email address that represents a specific Google account. For example, alice@gmail.com or joe@example.com.
* **serviceAccount:{emailid}**: An email address that represents a service account. For example, my-other-app@appspot.gserviceaccount.com.
* **group:{emailid}**: An email address that represents a Google group. For example, admins@example.com.
* **domain:{domain}**: A G Suite domain (primary, instead of alias) name that represents all the users of that domain. For example, google.com or example.com.
* **projectOwner:projectid**: Owners of the given project. For example, "projectOwner:my-example-project"
* **projectEditor:projectid**: Editors of the given project. For example, "projectEditor:my-example-project"
* **projectViewer:projectid**: Viewers of the given project. For example, "projectViewer:my-example-project"

projectB" The ID of the project in which the resource belongs.
If it is not provided, the project will be parsed from the identifier of the parent resource. If no project is provided in the parent identifier and no project is specified, the provider project is used.
Ô
role" ÇThe role that should be applied. Only one
`gcp.dataplex.ZoneIamBinding` can be used per role. Note that custom roles must be of the format
`[projects|organizations]/{parent-name}/roles/{role-name}`.
"t
	conditiongBe:c
a
dataplexZoneIamBindingCondition<gcp:dataplex/ZoneIamBindingCondition:ZoneIamBindingCondition"O
dataplexZone" ;Used to find the parent resource to bind the IAM policy to
"3
etag" '(Computed) The etag of the IAM policy.
"

lake" "
location" "Ö	
members*" Ä	Identities that will be granted the privilege in `role`.
Each entry can have one of the following values:
* **allUsers**: A special identifier that represents anyone who is on the internet; with or without a Google account.
* **allAuthenticatedUsers**: A special identifier that represents anyone who is authenticated with a Google account or a service account.
* **user:{emailid}**: An email address that represents a specific Google account. For example, alice@gmail.com or joe@example.com.
* **serviceAccount:{emailid}**: An email address that represents a service account. For example, my-other-app@appspot.gserviceaccount.com.
* **group:{emailid}**: An email address that represents a Google group. For example, admins@example.com.
* **domain:{domain}**: A G Suite domain (primary, instead of alias) name that represents all the users of that domain. For example, google.com or example.com.
* **projectOwner:projectid**: Owners of the given project. For example, "projectOwner:my-example-project"
* **projectEditor:projectid**: Editors of the given project. For example, "projectEditor:my-example-project"
* **projectViewer:projectid**: Viewers of the given project. For example, "projectViewer:my-example-project"
"
project" The ID of the project in which the resource belongs.
If it is not provided, the project will be parsed from the identifier of the parent resource. If no project is provided in the parent identifier and no project is specified, the provider project is used.
"Ô
role" ÇThe role that should be applied. Only one
`gcp.dataplex.ZoneIamBinding` can be used per role. Note that custom roles must be of the format
`[projects|organizations]/{parent-name}/roles/{role-name}`.
*Äà
C
dataplexZoneIamMember(gcp:dataplex/zoneIamMember:ZoneIamMemberÁThree different resources help you manage your IAM policy for Dataplex Zone. Each of these resources serves a different use case:

* `gcp.dataplex.ZoneIamPolicy`: Authoritative. Sets the IAM policy for the zone and replaces any existing policy already attached.
* `gcp.dataplex.ZoneIamBinding`: Authoritative for a given role. Updates the IAM policy to grant a role to a list of members. Other roles within the IAM policy for the zone are preserved.
* `gcp.dataplex.ZoneIamMember`: Non-authoritative. Updates the IAM policy to grant a role to a new member. Other members for the role for the zone are preserved.

A data source can be used to retrieve policy data in advent you do not need creation

* `gcp.dataplex.ZoneIamPolicy`: Retrieves the IAM policy for the zone

> **Note:** `gcp.dataplex.ZoneIamPolicy` **cannot** be used in conjunction with `gcp.dataplex.ZoneIamBinding` and `gcp.dataplex.ZoneIamMember` or they will fight over what your policy should be.

> **Note:** `gcp.dataplex.ZoneIamBinding` resources **can be** used in conjunction with `gcp.dataplex.ZoneIamMember` resources **only if** they do not grant privilege to the same role.



## gcp.dataplex.ZoneIamPolicy

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const admin = gcp.organizations.getIAMPolicy({
    bindings: [{
        role: "roles/viewer",
        members: ["user:jane@example.com"],
    }],
});
const policy = new gcp.dataplex.ZoneIamPolicy("policy", {
    project: example.project,
    location: example.location,
    lake: example.lake,
    dataplexZone: example.name,
    policyData: admin.then(admin => admin.policyData),
});
```
```python
import pulumi
import pulumi_gcp as gcp

admin = gcp.organizations.get_iam_policy(bindings=[{
    "role": "roles/viewer",
    "members": ["user:jane@example.com"],
}])
policy = gcp.dataplex.ZoneIamPolicy("policy",
    project=example["project"],
    location=example["location"],
    lake=example["lake"],
    dataplex_zone=example["name"],
    policy_data=admin.policy_data)
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var admin = Gcp.Organizations.GetIAMPolicy.Invoke(new()
    {
        Bindings = new[]
        {
            new Gcp.Organizations.Inputs.GetIAMPolicyBindingInputArgs
            {
                Role = "roles/viewer",
                Members = new[]
                {
                    "user:jane@example.com",
                },
            },
        },
    });

    var policy = new Gcp.DataPlex.ZoneIamPolicy("policy", new()
    {
        Project = example.Project,
        Location = example.Location,
        Lake = example.Lake,
        DataplexZone = example.Name,
        PolicyData = admin.Apply(getIAMPolicyResult => getIAMPolicyResult.PolicyData),
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/dataplex"
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/organizations"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		admin, err := organizations.LookupIAMPolicy(ctx, &organizations.LookupIAMPolicyArgs{
			Bindings: []organizations.GetIAMPolicyBinding{
				{
					Role: "roles/viewer",
					Members: []string{
						"user:jane@example.com",
					},
				},
			},
		}, nil)
		if err != nil {
			return err
		}
		_, err = dataplex.NewZoneIamPolicy(ctx, "policy", &dataplex.ZoneIamPolicyArgs{
			Project:      pulumi.Any(example.Project),
			Location:     pulumi.Any(example.Location),
			Lake:         pulumi.Any(example.Lake),
			DataplexZone: pulumi.Any(example.Name),
			PolicyData:   pulumi.String(admin.PolicyData),
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.organizations.OrganizationsFunctions;
import com.pulumi.gcp.organizations.inputs.GetIAMPolicyArgs;
import com.pulumi.gcp.dataplex.ZoneIamPolicy;
import com.pulumi.gcp.dataplex.ZoneIamPolicyArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        final var admin = OrganizationsFunctions.getIAMPolicy(GetIAMPolicyArgs.builder()
            .bindings(GetIAMPolicyBindingArgs.builder()
                .role("roles/viewer")
                .members("user:jane@example.com")
                .build())
            .build());

        var policy = new ZoneIamPolicy("policy", ZoneIamPolicyArgs.builder()
            .project(example.project())
            .location(example.location())
            .lake(example.lake())
            .dataplexZone(example.name())
            .policyData(admin.applyValue(getIAMPolicyResult -> getIAMPolicyResult.policyData()))
            .build());

    }
}
```
```yaml
resources:
  policy:
    type: gcp:dataplex:ZoneIamPolicy
    properties:
      project: ${example.project}
      location: ${example.location}
      lake: ${example.lake}
      dataplexZone: ${example.name}
      policyData: ${admin.policyData}
variables:
  admin:
    fn::invoke:
      function: gcp:organizations:getIAMPolicy
      arguments:
        bindings:
          - role: roles/viewer
            members:
              - user:jane@example.com
```
<!--End PulumiCodeChooser -->

## gcp.dataplex.ZoneIamBinding

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const binding = new gcp.dataplex.ZoneIamBinding("binding", {
    project: example.project,
    location: example.location,
    lake: example.lake,
    dataplexZone: example.name,
    role: "roles/viewer",
    members: ["user:jane@example.com"],
});
```
```python
import pulumi
import pulumi_gcp as gcp

binding = gcp.dataplex.ZoneIamBinding("binding",
    project=example["project"],
    location=example["location"],
    lake=example["lake"],
    dataplex_zone=example["name"],
    role="roles/viewer",
    members=["user:jane@example.com"])
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var binding = new Gcp.DataPlex.ZoneIamBinding("binding", new()
    {
        Project = example.Project,
        Location = example.Location,
        Lake = example.Lake,
        DataplexZone = example.Name,
        Role = "roles/viewer",
        Members = new[]
        {
            "user:jane@example.com",
        },
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/dataplex"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		_, err := dataplex.NewZoneIamBinding(ctx, "binding", &dataplex.ZoneIamBindingArgs{
			Project:      pulumi.Any(example.Project),
			Location:     pulumi.Any(example.Location),
			Lake:         pulumi.Any(example.Lake),
			DataplexZone: pulumi.Any(example.Name),
			Role:         pulumi.String("roles/viewer"),
			Members: pulumi.StringArray{
				pulumi.String("user:jane@example.com"),
			},
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.dataplex.ZoneIamBinding;
import com.pulumi.gcp.dataplex.ZoneIamBindingArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        var binding = new ZoneIamBinding("binding", ZoneIamBindingArgs.builder()
            .project(example.project())
            .location(example.location())
            .lake(example.lake())
            .dataplexZone(example.name())
            .role("roles/viewer")
            .members("user:jane@example.com")
            .build());

    }
}
```
```yaml
resources:
  binding:
    type: gcp:dataplex:ZoneIamBinding
    properties:
      project: ${example.project}
      location: ${example.location}
      lake: ${example.lake}
      dataplexZone: ${example.name}
      role: roles/viewer
      members:
        - user:jane@example.com
```
<!--End PulumiCodeChooser -->

## gcp.dataplex.ZoneIamMember

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const member = new gcp.dataplex.ZoneIamMember("member", {
    project: example.project,
    location: example.location,
    lake: example.lake,
    dataplexZone: example.name,
    role: "roles/viewer",
    member: "user:jane@example.com",
});
```
```python
import pulumi
import pulumi_gcp as gcp

member = gcp.dataplex.ZoneIamMember("member",
    project=example["project"],
    location=example["location"],
    lake=example["lake"],
    dataplex_zone=example["name"],
    role="roles/viewer",
    member="user:jane@example.com")
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var member = new Gcp.DataPlex.ZoneIamMember("member", new()
    {
        Project = example.Project,
        Location = example.Location,
        Lake = example.Lake,
        DataplexZone = example.Name,
        Role = "roles/viewer",
        Member = "user:jane@example.com",
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/dataplex"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		_, err := dataplex.NewZoneIamMember(ctx, "member", &dataplex.ZoneIamMemberArgs{
			Project:      pulumi.Any(example.Project),
			Location:     pulumi.Any(example.Location),
			Lake:         pulumi.Any(example.Lake),
			DataplexZone: pulumi.Any(example.Name),
			Role:         pulumi.String("roles/viewer"),
			Member:       pulumi.String("user:jane@example.com"),
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.dataplex.ZoneIamMember;
import com.pulumi.gcp.dataplex.ZoneIamMemberArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        var member = new ZoneIamMember("member", ZoneIamMemberArgs.builder()
            .project(example.project())
            .location(example.location())
            .lake(example.lake())
            .dataplexZone(example.name())
            .role("roles/viewer")
            .member("user:jane@example.com")
            .build());

    }
}
```
```yaml
resources:
  member:
    type: gcp:dataplex:ZoneIamMember
    properties:
      project: ${example.project}
      location: ${example.location}
      lake: ${example.lake}
      dataplexZone: ${example.name}
      role: roles/viewer
      member: user:jane@example.com
```
<!--End PulumiCodeChooser -->


## This resource supports User Project Overrides.

-

# IAM policy for Dataplex Zone
Three different resources help you manage your IAM policy for Dataplex Zone. Each of these resources serves a different use case:

* `gcp.dataplex.ZoneIamPolicy`: Authoritative. Sets the IAM policy for the zone and replaces any existing policy already attached.
* `gcp.dataplex.ZoneIamBinding`: Authoritative for a given role. Updates the IAM policy to grant a role to a list of members. Other roles within the IAM policy for the zone are preserved.
* `gcp.dataplex.ZoneIamMember`: Non-authoritative. Updates the IAM policy to grant a role to a new member. Other members for the role for the zone are preserved.

A data source can be used to retrieve policy data in advent you do not need creation

* `gcp.dataplex.ZoneIamPolicy`: Retrieves the IAM policy for the zone

> **Note:** `gcp.dataplex.ZoneIamPolicy` **cannot** be used in conjunction with `gcp.dataplex.ZoneIamBinding` and `gcp.dataplex.ZoneIamMember` or they will fight over what your policy should be.

> **Note:** `gcp.dataplex.ZoneIamBinding` resources **can be** used in conjunction with `gcp.dataplex.ZoneIamMember` resources **only if** they do not grant privilege to the same role.



## gcp.dataplex.ZoneIamPolicy

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const admin = gcp.organizations.getIAMPolicy({
    bindings: [{
        role: "roles/viewer",
        members: ["user:jane@example.com"],
    }],
});
const policy = new gcp.dataplex.ZoneIamPolicy("policy", {
    project: example.project,
    location: example.location,
    lake: example.lake,
    dataplexZone: example.name,
    policyData: admin.then(admin => admin.policyData),
});
```
```python
import pulumi
import pulumi_gcp as gcp

admin = gcp.organizations.get_iam_policy(bindings=[{
    "role": "roles/viewer",
    "members": ["user:jane@example.com"],
}])
policy = gcp.dataplex.ZoneIamPolicy("policy",
    project=example["project"],
    location=example["location"],
    lake=example["lake"],
    dataplex_zone=example["name"],
    policy_data=admin.policy_data)
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var admin = Gcp.Organizations.GetIAMPolicy.Invoke(new()
    {
        Bindings = new[]
        {
            new Gcp.Organizations.Inputs.GetIAMPolicyBindingInputArgs
            {
                Role = "roles/viewer",
                Members = new[]
                {
                    "user:jane@example.com",
                },
            },
        },
    });

    var policy = new Gcp.DataPlex.ZoneIamPolicy("policy", new()
    {
        Project = example.Project,
        Location = example.Location,
        Lake = example.Lake,
        DataplexZone = example.Name,
        PolicyData = admin.Apply(getIAMPolicyResult => getIAMPolicyResult.PolicyData),
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/dataplex"
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/organizations"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		admin, err := organizations.LookupIAMPolicy(ctx, &organizations.LookupIAMPolicyArgs{
			Bindings: []organizations.GetIAMPolicyBinding{
				{
					Role: "roles/viewer",
					Members: []string{
						"user:jane@example.com",
					},
				},
			},
		}, nil)
		if err != nil {
			return err
		}
		_, err = dataplex.NewZoneIamPolicy(ctx, "policy", &dataplex.ZoneIamPolicyArgs{
			Project:      pulumi.Any(example.Project),
			Location:     pulumi.Any(example.Location),
			Lake:         pulumi.Any(example.Lake),
			DataplexZone: pulumi.Any(example.Name),
			PolicyData:   pulumi.String(admin.PolicyData),
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.organizations.OrganizationsFunctions;
import com.pulumi.gcp.organizations.inputs.GetIAMPolicyArgs;
import com.pulumi.gcp.dataplex.ZoneIamPolicy;
import com.pulumi.gcp.dataplex.ZoneIamPolicyArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        final var admin = OrganizationsFunctions.getIAMPolicy(GetIAMPolicyArgs.builder()
            .bindings(GetIAMPolicyBindingArgs.builder()
                .role("roles/viewer")
                .members("user:jane@example.com")
                .build())
            .build());

        var policy = new ZoneIamPolicy("policy", ZoneIamPolicyArgs.builder()
            .project(example.project())
            .location(example.location())
            .lake(example.lake())
            .dataplexZone(example.name())
            .policyData(admin.applyValue(getIAMPolicyResult -> getIAMPolicyResult.policyData()))
            .build());

    }
}
```
```yaml
resources:
  policy:
    type: gcp:dataplex:ZoneIamPolicy
    properties:
      project: ${example.project}
      location: ${example.location}
      lake: ${example.lake}
      dataplexZone: ${example.name}
      policyData: ${admin.policyData}
variables:
  admin:
    fn::invoke:
      function: gcp:organizations:getIAMPolicy
      arguments:
        bindings:
          - role: roles/viewer
            members:
              - user:jane@example.com
```
<!--End PulumiCodeChooser -->

## gcp.dataplex.ZoneIamBinding

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const binding = new gcp.dataplex.ZoneIamBinding("binding", {
    project: example.project,
    location: example.location,
    lake: example.lake,
    dataplexZone: example.name,
    role: "roles/viewer",
    members: ["user:jane@example.com"],
});
```
```python
import pulumi
import pulumi_gcp as gcp

binding = gcp.dataplex.ZoneIamBinding("binding",
    project=example["project"],
    location=example["location"],
    lake=example["lake"],
    dataplex_zone=example["name"],
    role="roles/viewer",
    members=["user:jane@example.com"])
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var binding = new Gcp.DataPlex.ZoneIamBinding("binding", new()
    {
        Project = example.Project,
        Location = example.Location,
        Lake = example.Lake,
        DataplexZone = example.Name,
        Role = "roles/viewer",
        Members = new[]
        {
            "user:jane@example.com",
        },
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/dataplex"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		_, err := dataplex.NewZoneIamBinding(ctx, "binding", &dataplex.ZoneIamBindingArgs{
			Project:      pulumi.Any(example.Project),
			Location:     pulumi.Any(example.Location),
			Lake:         pulumi.Any(example.Lake),
			DataplexZone: pulumi.Any(example.Name),
			Role:         pulumi.String("roles/viewer"),
			Members: pulumi.StringArray{
				pulumi.String("user:jane@example.com"),
			},
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.dataplex.ZoneIamBinding;
import com.pulumi.gcp.dataplex.ZoneIamBindingArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        var binding = new ZoneIamBinding("binding", ZoneIamBindingArgs.builder()
            .project(example.project())
            .location(example.location())
            .lake(example.lake())
            .dataplexZone(example.name())
            .role("roles/viewer")
            .members("user:jane@example.com")
            .build());

    }
}
```
```yaml
resources:
  binding:
    type: gcp:dataplex:ZoneIamBinding
    properties:
      project: ${example.project}
      location: ${example.location}
      lake: ${example.lake}
      dataplexZone: ${example.name}
      role: roles/viewer
      members:
        - user:jane@example.com
```
<!--End PulumiCodeChooser -->

## gcp.dataplex.ZoneIamMember

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const member = new gcp.dataplex.ZoneIamMember("member", {
    project: example.project,
    location: example.location,
    lake: example.lake,
    dataplexZone: example.name,
    role: "roles/viewer",
    member: "user:jane@example.com",
});
```
```python
import pulumi
import pulumi_gcp as gcp

member = gcp.dataplex.ZoneIamMember("member",
    project=example["project"],
    location=example["location"],
    lake=example["lake"],
    dataplex_zone=example["name"],
    role="roles/viewer",
    member="user:jane@example.com")
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var member = new Gcp.DataPlex.ZoneIamMember("member", new()
    {
        Project = example.Project,
        Location = example.Location,
        Lake = example.Lake,
        DataplexZone = example.Name,
        Role = "roles/viewer",
        Member = "user:jane@example.com",
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/dataplex"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		_, err := dataplex.NewZoneIamMember(ctx, "member", &dataplex.ZoneIamMemberArgs{
			Project:      pulumi.Any(example.Project),
			Location:     pulumi.Any(example.Location),
			Lake:         pulumi.Any(example.Lake),
			DataplexZone: pulumi.Any(example.Name),
			Role:         pulumi.String("roles/viewer"),
			Member:       pulumi.String("user:jane@example.com"),
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.dataplex.ZoneIamMember;
import com.pulumi.gcp.dataplex.ZoneIamMemberArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        var member = new ZoneIamMember("member", ZoneIamMemberArgs.builder()
            .project(example.project())
            .location(example.location())
            .lake(example.lake())
            .dataplexZone(example.name())
            .role("roles/viewer")
            .member("user:jane@example.com")
            .build());

    }
}
```
```yaml
resources:
  member:
    type: gcp:dataplex:ZoneIamMember
    properties:
      project: ${example.project}
      location: ${example.location}
      lake: ${example.lake}
      dataplexZone: ${example.name}
      role: roles/viewer
      member: user:jane@example.com
```
<!--End PulumiCodeChooser -->

## Import

For all import syntaxes, the "resource in question" can take any of the following forms:

* projects/{{project}}/locations/{{location}}/lakes/{{lake}}/zones/{{name}}

* {{project}}/{{location}}/{{lake}}/{{name}}

* {{location}}/{{lake}}/{{name}}

* {{name}}

Any variables not passed in the import command will be taken from the provider configuration.

Dataplex zone IAM resources can be imported using the resource identifiers, role, and member.

IAM member imports use space-delimited identifiers: the resource in question, the role, and the member identity, e.g.

```sh
$ pulumi import gcp:dataplex/zoneIamMember:ZoneIamMember editor "projects/{{project}}/locations/{{location}}/lakes/{{lake}}/zones/{{zone}} roles/viewer user:jane@example.com"
```

IAM binding imports use space-delimited identifiers: the resource in question and the role, e.g.

```sh
$ pulumi import gcp:dataplex/zoneIamMember:ZoneIamMember editor "projects/{{project}}/locations/{{location}}/lakes/{{lake}}/zones/{{zone}} roles/viewer"
```

IAM policy imports use the identifier of the resource in question, e.g.

```sh
$ pulumi import gcp:dataplex/zoneIamMember:ZoneIamMember editor projects/{{project}}/locations/{{location}}/lakes/{{lake}}/zones/{{zone}}
```

-> **Custom Roles** If you're importing a IAM resource with a custom role, make sure to use the

 full name of the custom role, e.g. `[projects/my-project|organizations/my-org]/roles/my-custom-role`.

q
	conditiondBb:`
^
dataplexZoneIamMemberCondition:gcp:dataplex/ZoneIamMemberCondition:ZoneIamMemberConditionO
dataplexZone" ;Used to find the parent resource to bind the IAM policy to


lake" 
locationB" Ó	
member" Ä	Identities that will be granted the privilege in `role`.
Each entry can have one of the following values:
* **allUsers**: A special identifier that represents anyone who is on the internet; with or without a Google account.
* **allAuthenticatedUsers**: A special identifier that represents anyone who is authenticated with a Google account or a service account.
* **user:{emailid}**: An email address that represents a specific Google account. For example, alice@gmail.com or joe@example.com.
* **serviceAccount:{emailid}**: An email address that represents a service account. For example, my-other-app@appspot.gserviceaccount.com.
* **group:{emailid}**: An email address that represents a Google group. For example, admins@example.com.
* **domain:{domain}**: A G Suite domain (primary, instead of alias) name that represents all the users of that domain. For example, google.com or example.com.
* **projectOwner:projectid**: Owners of the given project. For example, "projectOwner:my-example-project"
* **projectEditor:projectid**: Editors of the given project. For example, "projectEditor:my-example-project"
* **projectViewer:projectid**: Viewers of the given project. For example, "projectViewer:my-example-project"

projectB" The ID of the project in which the resource belongs.
If it is not provided, the project will be parsed from the identifier of the parent resource. If no project is provided in the parent identifier and no project is specified, the provider project is used.
Ô
role" ÇThe role that should be applied. Only one
`gcp.dataplex.ZoneIamBinding` can be used per role. Note that custom roles must be of the format
`[projects|organizations]/{parent-name}/roles/{role-name}`.
"q
	conditiondBb:`
^
dataplexZoneIamMemberCondition:gcp:dataplex/ZoneIamMemberCondition:ZoneIamMemberCondition"O
dataplexZone" ;Used to find the parent resource to bind the IAM policy to
"3
etag" '(Computed) The etag of the IAM policy.
"

lake" "
location" "Ó	
member" Ä	Identities that will be granted the privilege in `role`.
Each entry can have one of the following values:
* **allUsers**: A special identifier that represents anyone who is on the internet; with or without a Google account.
* **allAuthenticatedUsers**: A special identifier that represents anyone who is authenticated with a Google account or a service account.
* **user:{emailid}**: An email address that represents a specific Google account. For example, alice@gmail.com or joe@example.com.
* **serviceAccount:{emailid}**: An email address that represents a service account. For example, my-other-app@appspot.gserviceaccount.com.
* **group:{emailid}**: An email address that represents a Google group. For example, admins@example.com.
* **domain:{domain}**: A G Suite domain (primary, instead of alias) name that represents all the users of that domain. For example, google.com or example.com.
* **projectOwner:projectid**: Owners of the given project. For example, "projectOwner:my-example-project"
* **projectEditor:projectid**: Editors of the given project. For example, "projectEditor:my-example-project"
* **projectViewer:projectid**: Viewers of the given project. For example, "projectViewer:my-example-project"
"
project" The ID of the project in which the resource belongs.
If it is not provided, the project will be parsed from the identifier of the parent resource. If no project is provided in the parent identifier and no project is specified, the provider project is used.
"Ô
role" ÇThe role that should be applied. Only one
`gcp.dataplex.ZoneIamBinding` can be used per role. Note that custom roles must be of the format
`[projects|organizations]/{parent-name}/roles/{role-name}`.
*ÆÉ
C
dataplexZoneIamPolicy(gcp:dataplex/zoneIamPolicy:ZoneIamPolicyÁThree different resources help you manage your IAM policy for Dataplex Zone. Each of these resources serves a different use case:

* `gcp.dataplex.ZoneIamPolicy`: Authoritative. Sets the IAM policy for the zone and replaces any existing policy already attached.
* `gcp.dataplex.ZoneIamBinding`: Authoritative for a given role. Updates the IAM policy to grant a role to a list of members. Other roles within the IAM policy for the zone are preserved.
* `gcp.dataplex.ZoneIamMember`: Non-authoritative. Updates the IAM policy to grant a role to a new member. Other members for the role for the zone are preserved.

A data source can be used to retrieve policy data in advent you do not need creation

* `gcp.dataplex.ZoneIamPolicy`: Retrieves the IAM policy for the zone

> **Note:** `gcp.dataplex.ZoneIamPolicy` **cannot** be used in conjunction with `gcp.dataplex.ZoneIamBinding` and `gcp.dataplex.ZoneIamMember` or they will fight over what your policy should be.

> **Note:** `gcp.dataplex.ZoneIamBinding` resources **can be** used in conjunction with `gcp.dataplex.ZoneIamMember` resources **only if** they do not grant privilege to the same role.



## gcp.dataplex.ZoneIamPolicy

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const admin = gcp.organizations.getIAMPolicy({
    bindings: [{
        role: "roles/viewer",
        members: ["user:jane@example.com"],
    }],
});
const policy = new gcp.dataplex.ZoneIamPolicy("policy", {
    project: example.project,
    location: example.location,
    lake: example.lake,
    dataplexZone: example.name,
    policyData: admin.then(admin => admin.policyData),
});
```
```python
import pulumi
import pulumi_gcp as gcp

admin = gcp.organizations.get_iam_policy(bindings=[{
    "role": "roles/viewer",
    "members": ["user:jane@example.com"],
}])
policy = gcp.dataplex.ZoneIamPolicy("policy",
    project=example["project"],
    location=example["location"],
    lake=example["lake"],
    dataplex_zone=example["name"],
    policy_data=admin.policy_data)
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var admin = Gcp.Organizations.GetIAMPolicy.Invoke(new()
    {
        Bindings = new[]
        {
            new Gcp.Organizations.Inputs.GetIAMPolicyBindingInputArgs
            {
                Role = "roles/viewer",
                Members = new[]
                {
                    "user:jane@example.com",
                },
            },
        },
    });

    var policy = new Gcp.DataPlex.ZoneIamPolicy("policy", new()
    {
        Project = example.Project,
        Location = example.Location,
        Lake = example.Lake,
        DataplexZone = example.Name,
        PolicyData = admin.Apply(getIAMPolicyResult => getIAMPolicyResult.PolicyData),
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/dataplex"
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/organizations"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		admin, err := organizations.LookupIAMPolicy(ctx, &organizations.LookupIAMPolicyArgs{
			Bindings: []organizations.GetIAMPolicyBinding{
				{
					Role: "roles/viewer",
					Members: []string{
						"user:jane@example.com",
					},
				},
			},
		}, nil)
		if err != nil {
			return err
		}
		_, err = dataplex.NewZoneIamPolicy(ctx, "policy", &dataplex.ZoneIamPolicyArgs{
			Project:      pulumi.Any(example.Project),
			Location:     pulumi.Any(example.Location),
			Lake:         pulumi.Any(example.Lake),
			DataplexZone: pulumi.Any(example.Name),
			PolicyData:   pulumi.String(admin.PolicyData),
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.organizations.OrganizationsFunctions;
import com.pulumi.gcp.organizations.inputs.GetIAMPolicyArgs;
import com.pulumi.gcp.dataplex.ZoneIamPolicy;
import com.pulumi.gcp.dataplex.ZoneIamPolicyArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        final var admin = OrganizationsFunctions.getIAMPolicy(GetIAMPolicyArgs.builder()
            .bindings(GetIAMPolicyBindingArgs.builder()
                .role("roles/viewer")
                .members("user:jane@example.com")
                .build())
            .build());

        var policy = new ZoneIamPolicy("policy", ZoneIamPolicyArgs.builder()
            .project(example.project())
            .location(example.location())
            .lake(example.lake())
            .dataplexZone(example.name())
            .policyData(admin.applyValue(getIAMPolicyResult -> getIAMPolicyResult.policyData()))
            .build());

    }
}
```
```yaml
resources:
  policy:
    type: gcp:dataplex:ZoneIamPolicy
    properties:
      project: ${example.project}
      location: ${example.location}
      lake: ${example.lake}
      dataplexZone: ${example.name}
      policyData: ${admin.policyData}
variables:
  admin:
    fn::invoke:
      function: gcp:organizations:getIAMPolicy
      arguments:
        bindings:
          - role: roles/viewer
            members:
              - user:jane@example.com
```
<!--End PulumiCodeChooser -->

## gcp.dataplex.ZoneIamBinding

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const binding = new gcp.dataplex.ZoneIamBinding("binding", {
    project: example.project,
    location: example.location,
    lake: example.lake,
    dataplexZone: example.name,
    role: "roles/viewer",
    members: ["user:jane@example.com"],
});
```
```python
import pulumi
import pulumi_gcp as gcp

binding = gcp.dataplex.ZoneIamBinding("binding",
    project=example["project"],
    location=example["location"],
    lake=example["lake"],
    dataplex_zone=example["name"],
    role="roles/viewer",
    members=["user:jane@example.com"])
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var binding = new Gcp.DataPlex.ZoneIamBinding("binding", new()
    {
        Project = example.Project,
        Location = example.Location,
        Lake = example.Lake,
        DataplexZone = example.Name,
        Role = "roles/viewer",
        Members = new[]
        {
            "user:jane@example.com",
        },
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/dataplex"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		_, err := dataplex.NewZoneIamBinding(ctx, "binding", &dataplex.ZoneIamBindingArgs{
			Project:      pulumi.Any(example.Project),
			Location:     pulumi.Any(example.Location),
			Lake:         pulumi.Any(example.Lake),
			DataplexZone: pulumi.Any(example.Name),
			Role:         pulumi.String("roles/viewer"),
			Members: pulumi.StringArray{
				pulumi.String("user:jane@example.com"),
			},
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.dataplex.ZoneIamBinding;
import com.pulumi.gcp.dataplex.ZoneIamBindingArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        var binding = new ZoneIamBinding("binding", ZoneIamBindingArgs.builder()
            .project(example.project())
            .location(example.location())
            .lake(example.lake())
            .dataplexZone(example.name())
            .role("roles/viewer")
            .members("user:jane@example.com")
            .build());

    }
}
```
```yaml
resources:
  binding:
    type: gcp:dataplex:ZoneIamBinding
    properties:
      project: ${example.project}
      location: ${example.location}
      lake: ${example.lake}
      dataplexZone: ${example.name}
      role: roles/viewer
      members:
        - user:jane@example.com
```
<!--End PulumiCodeChooser -->

## gcp.dataplex.ZoneIamMember

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const member = new gcp.dataplex.ZoneIamMember("member", {
    project: example.project,
    location: example.location,
    lake: example.lake,
    dataplexZone: example.name,
    role: "roles/viewer",
    member: "user:jane@example.com",
});
```
```python
import pulumi
import pulumi_gcp as gcp

member = gcp.dataplex.ZoneIamMember("member",
    project=example["project"],
    location=example["location"],
    lake=example["lake"],
    dataplex_zone=example["name"],
    role="roles/viewer",
    member="user:jane@example.com")
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var member = new Gcp.DataPlex.ZoneIamMember("member", new()
    {
        Project = example.Project,
        Location = example.Location,
        Lake = example.Lake,
        DataplexZone = example.Name,
        Role = "roles/viewer",
        Member = "user:jane@example.com",
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/dataplex"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		_, err := dataplex.NewZoneIamMember(ctx, "member", &dataplex.ZoneIamMemberArgs{
			Project:      pulumi.Any(example.Project),
			Location:     pulumi.Any(example.Location),
			Lake:         pulumi.Any(example.Lake),
			DataplexZone: pulumi.Any(example.Name),
			Role:         pulumi.String("roles/viewer"),
			Member:       pulumi.String("user:jane@example.com"),
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.dataplex.ZoneIamMember;
import com.pulumi.gcp.dataplex.ZoneIamMemberArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        var member = new ZoneIamMember("member", ZoneIamMemberArgs.builder()
            .project(example.project())
            .location(example.location())
            .lake(example.lake())
            .dataplexZone(example.name())
            .role("roles/viewer")
            .member("user:jane@example.com")
            .build());

    }
}
```
```yaml
resources:
  member:
    type: gcp:dataplex:ZoneIamMember
    properties:
      project: ${example.project}
      location: ${example.location}
      lake: ${example.lake}
      dataplexZone: ${example.name}
      role: roles/viewer
      member: user:jane@example.com
```
<!--End PulumiCodeChooser -->


## This resource supports User Project Overrides.

-

# IAM policy for Dataplex Zone
Three different resources help you manage your IAM policy for Dataplex Zone. Each of these resources serves a different use case:

* `gcp.dataplex.ZoneIamPolicy`: Authoritative. Sets the IAM policy for the zone and replaces any existing policy already attached.
* `gcp.dataplex.ZoneIamBinding`: Authoritative for a given role. Updates the IAM policy to grant a role to a list of members. Other roles within the IAM policy for the zone are preserved.
* `gcp.dataplex.ZoneIamMember`: Non-authoritative. Updates the IAM policy to grant a role to a new member. Other members for the role for the zone are preserved.

A data source can be used to retrieve policy data in advent you do not need creation

* `gcp.dataplex.ZoneIamPolicy`: Retrieves the IAM policy for the zone

> **Note:** `gcp.dataplex.ZoneIamPolicy` **cannot** be used in conjunction with `gcp.dataplex.ZoneIamBinding` and `gcp.dataplex.ZoneIamMember` or they will fight over what your policy should be.

> **Note:** `gcp.dataplex.ZoneIamBinding` resources **can be** used in conjunction with `gcp.dataplex.ZoneIamMember` resources **only if** they do not grant privilege to the same role.



## gcp.dataplex.ZoneIamPolicy

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const admin = gcp.organizations.getIAMPolicy({
    bindings: [{
        role: "roles/viewer",
        members: ["user:jane@example.com"],
    }],
});
const policy = new gcp.dataplex.ZoneIamPolicy("policy", {
    project: example.project,
    location: example.location,
    lake: example.lake,
    dataplexZone: example.name,
    policyData: admin.then(admin => admin.policyData),
});
```
```python
import pulumi
import pulumi_gcp as gcp

admin = gcp.organizations.get_iam_policy(bindings=[{
    "role": "roles/viewer",
    "members": ["user:jane@example.com"],
}])
policy = gcp.dataplex.ZoneIamPolicy("policy",
    project=example["project"],
    location=example["location"],
    lake=example["lake"],
    dataplex_zone=example["name"],
    policy_data=admin.policy_data)
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var admin = Gcp.Organizations.GetIAMPolicy.Invoke(new()
    {
        Bindings = new[]
        {
            new Gcp.Organizations.Inputs.GetIAMPolicyBindingInputArgs
            {
                Role = "roles/viewer",
                Members = new[]
                {
                    "user:jane@example.com",
                },
            },
        },
    });

    var policy = new Gcp.DataPlex.ZoneIamPolicy("policy", new()
    {
        Project = example.Project,
        Location = example.Location,
        Lake = example.Lake,
        DataplexZone = example.Name,
        PolicyData = admin.Apply(getIAMPolicyResult => getIAMPolicyResult.PolicyData),
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/dataplex"
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/organizations"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		admin, err := organizations.LookupIAMPolicy(ctx, &organizations.LookupIAMPolicyArgs{
			Bindings: []organizations.GetIAMPolicyBinding{
				{
					Role: "roles/viewer",
					Members: []string{
						"user:jane@example.com",
					},
				},
			},
		}, nil)
		if err != nil {
			return err
		}
		_, err = dataplex.NewZoneIamPolicy(ctx, "policy", &dataplex.ZoneIamPolicyArgs{
			Project:      pulumi.Any(example.Project),
			Location:     pulumi.Any(example.Location),
			Lake:         pulumi.Any(example.Lake),
			DataplexZone: pulumi.Any(example.Name),
			PolicyData:   pulumi.String(admin.PolicyData),
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.organizations.OrganizationsFunctions;
import com.pulumi.gcp.organizations.inputs.GetIAMPolicyArgs;
import com.pulumi.gcp.dataplex.ZoneIamPolicy;
import com.pulumi.gcp.dataplex.ZoneIamPolicyArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        final var admin = OrganizationsFunctions.getIAMPolicy(GetIAMPolicyArgs.builder()
            .bindings(GetIAMPolicyBindingArgs.builder()
                .role("roles/viewer")
                .members("user:jane@example.com")
                .build())
            .build());

        var policy = new ZoneIamPolicy("policy", ZoneIamPolicyArgs.builder()
            .project(example.project())
            .location(example.location())
            .lake(example.lake())
            .dataplexZone(example.name())
            .policyData(admin.applyValue(getIAMPolicyResult -> getIAMPolicyResult.policyData()))
            .build());

    }
}
```
```yaml
resources:
  policy:
    type: gcp:dataplex:ZoneIamPolicy
    properties:
      project: ${example.project}
      location: ${example.location}
      lake: ${example.lake}
      dataplexZone: ${example.name}
      policyData: ${admin.policyData}
variables:
  admin:
    fn::invoke:
      function: gcp:organizations:getIAMPolicy
      arguments:
        bindings:
          - role: roles/viewer
            members:
              - user:jane@example.com
```
<!--End PulumiCodeChooser -->

## gcp.dataplex.ZoneIamBinding

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const binding = new gcp.dataplex.ZoneIamBinding("binding", {
    project: example.project,
    location: example.location,
    lake: example.lake,
    dataplexZone: example.name,
    role: "roles/viewer",
    members: ["user:jane@example.com"],
});
```
```python
import pulumi
import pulumi_gcp as gcp

binding = gcp.dataplex.ZoneIamBinding("binding",
    project=example["project"],
    location=example["location"],
    lake=example["lake"],
    dataplex_zone=example["name"],
    role="roles/viewer",
    members=["user:jane@example.com"])
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var binding = new Gcp.DataPlex.ZoneIamBinding("binding", new()
    {
        Project = example.Project,
        Location = example.Location,
        Lake = example.Lake,
        DataplexZone = example.Name,
        Role = "roles/viewer",
        Members = new[]
        {
            "user:jane@example.com",
        },
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/dataplex"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		_, err := dataplex.NewZoneIamBinding(ctx, "binding", &dataplex.ZoneIamBindingArgs{
			Project:      pulumi.Any(example.Project),
			Location:     pulumi.Any(example.Location),
			Lake:         pulumi.Any(example.Lake),
			DataplexZone: pulumi.Any(example.Name),
			Role:         pulumi.String("roles/viewer"),
			Members: pulumi.StringArray{
				pulumi.String("user:jane@example.com"),
			},
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.dataplex.ZoneIamBinding;
import com.pulumi.gcp.dataplex.ZoneIamBindingArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        var binding = new ZoneIamBinding("binding", ZoneIamBindingArgs.builder()
            .project(example.project())
            .location(example.location())
            .lake(example.lake())
            .dataplexZone(example.name())
            .role("roles/viewer")
            .members("user:jane@example.com")
            .build());

    }
}
```
```yaml
resources:
  binding:
    type: gcp:dataplex:ZoneIamBinding
    properties:
      project: ${example.project}
      location: ${example.location}
      lake: ${example.lake}
      dataplexZone: ${example.name}
      role: roles/viewer
      members:
        - user:jane@example.com
```
<!--End PulumiCodeChooser -->

## gcp.dataplex.ZoneIamMember

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const member = new gcp.dataplex.ZoneIamMember("member", {
    project: example.project,
    location: example.location,
    lake: example.lake,
    dataplexZone: example.name,
    role: "roles/viewer",
    member: "user:jane@example.com",
});
```
```python
import pulumi
import pulumi_gcp as gcp

member = gcp.dataplex.ZoneIamMember("member",
    project=example["project"],
    location=example["location"],
    lake=example["lake"],
    dataplex_zone=example["name"],
    role="roles/viewer",
    member="user:jane@example.com")
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var member = new Gcp.DataPlex.ZoneIamMember("member", new()
    {
        Project = example.Project,
        Location = example.Location,
        Lake = example.Lake,
        DataplexZone = example.Name,
        Role = "roles/viewer",
        Member = "user:jane@example.com",
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/dataplex"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		_, err := dataplex.NewZoneIamMember(ctx, "member", &dataplex.ZoneIamMemberArgs{
			Project:      pulumi.Any(example.Project),
			Location:     pulumi.Any(example.Location),
			Lake:         pulumi.Any(example.Lake),
			DataplexZone: pulumi.Any(example.Name),
			Role:         pulumi.String("roles/viewer"),
			Member:       pulumi.String("user:jane@example.com"),
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.dataplex.ZoneIamMember;
import com.pulumi.gcp.dataplex.ZoneIamMemberArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        var member = new ZoneIamMember("member", ZoneIamMemberArgs.builder()
            .project(example.project())
            .location(example.location())
            .lake(example.lake())
            .dataplexZone(example.name())
            .role("roles/viewer")
            .member("user:jane@example.com")
            .build());

    }
}
```
```yaml
resources:
  member:
    type: gcp:dataplex:ZoneIamMember
    properties:
      project: ${example.project}
      location: ${example.location}
      lake: ${example.lake}
      dataplexZone: ${example.name}
      role: roles/viewer
      member: user:jane@example.com
```
<!--End PulumiCodeChooser -->

## Import

For all import syntaxes, the "resource in question" can take any of the following forms:

* projects/{{project}}/locations/{{location}}/lakes/{{lake}}/zones/{{name}}

* {{project}}/{{location}}/{{lake}}/{{name}}

* {{location}}/{{lake}}/{{name}}

* {{name}}

Any variables not passed in the import command will be taken from the provider configuration.

Dataplex zone IAM resources can be imported using the resource identifiers, role, and member.

IAM member imports use space-delimited identifiers: the resource in question, the role, and the member identity, e.g.

```sh
$ pulumi import gcp:dataplex/zoneIamPolicy:ZoneIamPolicy editor "projects/{{project}}/locations/{{location}}/lakes/{{lake}}/zones/{{zone}} roles/viewer user:jane@example.com"
```

IAM binding imports use space-delimited identifiers: the resource in question and the role, e.g.

```sh
$ pulumi import gcp:dataplex/zoneIamPolicy:ZoneIamPolicy editor "projects/{{project}}/locations/{{location}}/lakes/{{lake}}/zones/{{zone}} roles/viewer"
```

IAM policy imports use the identifier of the resource in question, e.g.

```sh
$ pulumi import gcp:dataplex/zoneIamPolicy:ZoneIamPolicy editor projects/{{project}}/locations/{{location}}/lakes/{{lake}}/zones/{{zone}}
```

-> **Custom Roles** If you're importing a IAM resource with a custom role, make sure to use the

 full name of the custom role, e.g. `[projects/my-project|organizations/my-org]/roles/my-custom-role`.

O
dataplexZone" ;Used to find the parent resource to bind the IAM policy to


lake" 
locationB" _

policyData" MThe policy data generated by
a `gcp.organizations.getIAMPolicy` data source.

projectB" The ID of the project in which the resource belongs.
If it is not provided, the project will be parsed from the identifier of the parent resource. If no project is provided in the parent identifier and no project is specified, the provider project is used.
"O
dataplexZone" ;Used to find the parent resource to bind the IAM policy to
"3
etag" '(Computed) The etag of the IAM policy.
"

lake" "
location" "_

policyData" MThe policy data generated by
a `gcp.organizations.getIAMPolicy` data source.
"
project" The ID of the project in which the resource belongs.
If it is not provided, the project will be parsed from the identifier of the parent resource. If no project is provided in the parent identifier and no project is specified, the provider project is used.
*þK
O
dataprocAutoscalingPolicy0gcp:dataproc/autoscalingPolicy:AutoscalingPolicy¡8Describes an autoscaling policy for Dataproc cluster autoscaler.



## Example Usage

### Dataproc Autoscaling Policy


<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const asp = new gcp.dataproc.AutoscalingPolicy("asp", {
    policyId: "dataproc-policy",
    location: "us-central1",
    workerConfig: {
        maxInstances: 3,
    },
    basicAlgorithm: {
        yarnConfig: {
            gracefulDecommissionTimeout: "30s",
            scaleUpFactor: 0.5,
            scaleDownFactor: 0.5,
        },
    },
});
const basic = new gcp.dataproc.Cluster("basic", {
    name: "dataproc-policy",
    region: "us-central1",
    clusterConfig: {
        autoscalingConfig: {
            policyUri: asp.name,
        },
    },
});
```
```python
import pulumi
import pulumi_gcp as gcp

asp = gcp.dataproc.AutoscalingPolicy("asp",
    policy_id="dataproc-policy",
    location="us-central1",
    worker_config={
        "max_instances": 3,
    },
    basic_algorithm={
        "yarn_config": {
            "graceful_decommission_timeout": "30s",
            "scale_up_factor": 0.5,
            "scale_down_factor": 0.5,
        },
    })
basic = gcp.dataproc.Cluster("basic",
    name="dataproc-policy",
    region="us-central1",
    cluster_config={
        "autoscaling_config": {
            "policy_uri": asp.name,
        },
    })
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var asp = new Gcp.Dataproc.AutoscalingPolicy("asp", new()
    {
        PolicyId = "dataproc-policy",
        Location = "us-central1",
        WorkerConfig = new Gcp.Dataproc.Inputs.AutoscalingPolicyWorkerConfigArgs
        {
            MaxInstances = 3,
        },
        BasicAlgorithm = new Gcp.Dataproc.Inputs.AutoscalingPolicyBasicAlgorithmArgs
        {
            YarnConfig = new Gcp.Dataproc.Inputs.AutoscalingPolicyBasicAlgorithmYarnConfigArgs
            {
                GracefulDecommissionTimeout = "30s",
                ScaleUpFactor = 0.5,
                ScaleDownFactor = 0.5,
            },
        },
    });

    var basic = new Gcp.Dataproc.Cluster("basic", new()
    {
        Name = "dataproc-policy",
        Region = "us-central1",
        ClusterConfig = new Gcp.Dataproc.Inputs.ClusterClusterConfigArgs
        {
            AutoscalingConfig = new Gcp.Dataproc.Inputs.ClusterClusterConfigAutoscalingConfigArgs
            {
                PolicyUri = asp.Name,
            },
        },
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/dataproc"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		asp, err := dataproc.NewAutoscalingPolicy(ctx, "asp", &dataproc.AutoscalingPolicyArgs{
			PolicyId: pulumi.String("dataproc-policy"),
			Location: pulumi.String("us-central1"),
			WorkerConfig: &dataproc.AutoscalingPolicyWorkerConfigArgs{
				MaxInstances: pulumi.Int(3),
			},
			BasicAlgorithm: &dataproc.AutoscalingPolicyBasicAlgorithmArgs{
				YarnConfig: &dataproc.AutoscalingPolicyBasicAlgorithmYarnConfigArgs{
					GracefulDecommissionTimeout: pulumi.String("30s"),
					ScaleUpFactor:               pulumi.Float64(0.5),
					ScaleDownFactor:             pulumi.Float64(0.5),
				},
			},
		})
		if err != nil {
			return err
		}
		_, err = dataproc.NewCluster(ctx, "basic", &dataproc.ClusterArgs{
			Name:   pulumi.String("dataproc-policy"),
			Region: pulumi.String("us-central1"),
			ClusterConfig: &dataproc.ClusterClusterConfigArgs{
				AutoscalingConfig: &dataproc.ClusterClusterConfigAutoscalingConfigArgs{
					PolicyUri: asp.Name,
				},
			},
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.dataproc.AutoscalingPolicy;
import com.pulumi.gcp.dataproc.AutoscalingPolicyArgs;
import com.pulumi.gcp.dataproc.inputs.AutoscalingPolicyWorkerConfigArgs;
import com.pulumi.gcp.dataproc.inputs.AutoscalingPolicyBasicAlgorithmArgs;
import com.pulumi.gcp.dataproc.inputs.AutoscalingPolicyBasicAlgorithmYarnConfigArgs;
import com.pulumi.gcp.dataproc.Cluster;
import com.pulumi.gcp.dataproc.ClusterArgs;
import com.pulumi.gcp.dataproc.inputs.ClusterClusterConfigArgs;
import com.pulumi.gcp.dataproc.inputs.ClusterClusterConfigAutoscalingConfigArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        var asp = new AutoscalingPolicy("asp", AutoscalingPolicyArgs.builder()
            .policyId("dataproc-policy")
            .location("us-central1")
            .workerConfig(AutoscalingPolicyWorkerConfigArgs.builder()
                .maxInstances(3)
                .build())
            .basicAlgorithm(AutoscalingPolicyBasicAlgorithmArgs.builder()
                .yarnConfig(AutoscalingPolicyBasicAlgorithmYarnConfigArgs.builder()
                    .gracefulDecommissionTimeout("30s")
                    .scaleUpFactor(0.5)
                    .scaleDownFactor(0.5)
                    .build())
                .build())
            .build());

        var basic = new Cluster("basic", ClusterArgs.builder()
            .name("dataproc-policy")
            .region("us-central1")
            .clusterConfig(ClusterClusterConfigArgs.builder()
                .autoscalingConfig(ClusterClusterConfigAutoscalingConfigArgs.builder()
                    .policyUri(asp.name())
                    .build())
                .build())
            .build());

    }
}
```
```yaml
resources:
  basic:
    type: gcp:dataproc:Cluster
    properties:
      name: dataproc-policy
      region: us-central1
      clusterConfig:
        autoscalingConfig:
          policyUri: ${asp.name}
  asp:
    type: gcp:dataproc:AutoscalingPolicy
    properties:
      policyId: dataproc-policy
      location: us-central1
      workerConfig:
        maxInstances: 3
      basicAlgorithm:
        yarnConfig:
          gracefulDecommissionTimeout: 30s
          scaleUpFactor: 0.5
          scaleDownFactor: 0.5
```
<!--End PulumiCodeChooser -->

## Import

AutoscalingPolicy can be imported using any of these accepted formats:

* `projects/{{project}}/locations/{{location}}/autoscalingPolicies/{{policy_id}}`

* `{{project}}/{{location}}/{{policy_id}}`

* `{{location}}/{{policy_id}}`

When using the `pulumi import` command, AutoscalingPolicy can be imported using one of the formats above. For example:

```sh
$ pulumi import gcp:dataproc/autoscalingPolicy:AutoscalingPolicy default projects/{{project}}/locations/{{location}}/autoscalingPolicies/{{policy_id}}
```

```sh
$ pulumi import gcp:dataproc/autoscalingPolicy:AutoscalingPolicy default {{project}}/{{location}}/{{policy_id}}
```

```sh
$ pulumi import gcp:dataproc/autoscalingPolicy:AutoscalingPolicy default {{location}}/{{policy_id}}
```

Ó
basicAlgorithmB}:{
y
dataprocAutoscalingPolicyBasicAlgorithmLgcp:dataproc/AutoscalingPolicyBasicAlgorithm:AutoscalingPolicyBasicAlgorithm@Basic algorithm for autoscaling.
Structure is documented below.
k
locationB" YThe  location where the autoscaling policy should reside.
The default value is `global`.
â
policyId" ÑThe policy id. The id must contain only letters (a-z, A-Z), numbers (0-9), underscores (_),
and hyphens (-). Cannot begin or end with underscore or hyphen. Must consist of between
3 and 50 characters.


- - -
{
projectB" jThe ID of the project in which the resource belongs.
If it is not provided, the provider project is used.

secondaryWorkerConfigB:

dataproc&AutoscalingPolicySecondaryWorkerConfigZgcp:dataproc/AutoscalingPolicySecondaryWorkerConfig:AutoscalingPolicySecondaryWorkerConfig`Describes how the autoscaler will operate for secondary workers.
Structure is documented below.
é
workerConfigyBw:u
s
dataprocAutoscalingPolicyWorkerConfigHgcp:dataproc/AutoscalingPolicyWorkerConfig:AutoscalingPolicyWorkerConfig^Describes how the autoscaler will operate for primary workers.
Structure is documented below.
"Ó
basicAlgorithmB}:{
y
dataprocAutoscalingPolicyBasicAlgorithmLgcp:dataproc/AutoscalingPolicyBasicAlgorithm:AutoscalingPolicyBasicAlgorithm@Basic algorithm for autoscaling.
Structure is documented below.
"k
locationB" YThe  location where the autoscaling policy should reside.
The default value is `global`.
";
name" /The "resource name" of the autoscaling policy.
"â
policyId" ÑThe policy id. The id must contain only letters (a-z, A-Z), numbers (0-9), underscores (_),
and hyphens (-). Cannot begin or end with underscore or hyphen. Must consist of between
3 and 50 characters.


- - -
"y
project" jThe ID of the project in which the resource belongs.
If it is not provided, the provider project is used.
"
secondaryWorkerConfigB:

dataproc&AutoscalingPolicySecondaryWorkerConfigZgcp:dataproc/AutoscalingPolicySecondaryWorkerConfig:AutoscalingPolicySecondaryWorkerConfig`Describes how the autoscaler will operate for secondary workers.
Structure is documented below.
"é
workerConfigyBw:u
s
dataprocAutoscalingPolicyWorkerConfigHgcp:dataproc/AutoscalingPolicyWorkerConfig:AutoscalingPolicyWorkerConfig^Describes how the autoscaler will operate for primary workers.
Structure is documented below.
*ê
m
dataprocAutoscalingPolicyIamBindingDgcp:dataproc/autoscalingPolicyIamBinding:AutoscalingPolicyIamBindingÙÀThree different resources help you manage your IAM policy for Dataproc AutoscalingPolicy. Each of these resources serves a different use case:

* `gcp.dataproc.AutoscalingPolicyIamPolicy`: Authoritative. Sets the IAM policy for the autoscalingpolicy and replaces any existing policy already attached.
* `gcp.dataproc.AutoscalingPolicyIamBinding`: Authoritative for a given role. Updates the IAM policy to grant a role to a list of members. Other roles within the IAM policy for the autoscalingpolicy are preserved.
* `gcp.dataproc.AutoscalingPolicyIamMember`: Non-authoritative. Updates the IAM policy to grant a role to a new member. Other members for the role for the autoscalingpolicy are preserved.

A data source can be used to retrieve policy data in advent you do not need creation

* `gcp.dataproc.AutoscalingPolicyIamPolicy`: Retrieves the IAM policy for the autoscalingpolicy

> **Note:** `gcp.dataproc.AutoscalingPolicyIamPolicy` **cannot** be used in conjunction with `gcp.dataproc.AutoscalingPolicyIamBinding` and `gcp.dataproc.AutoscalingPolicyIamMember` or they will fight over what your policy should be.

> **Note:** `gcp.dataproc.AutoscalingPolicyIamBinding` resources **can be** used in conjunction with `gcp.dataproc.AutoscalingPolicyIamMember` resources **only if** they do not grant privilege to the same role.



## gcp.dataproc.AutoscalingPolicyIamPolicy

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const admin = gcp.organizations.getIAMPolicy({
    bindings: [{
        role: "roles/viewer",
        members: ["user:jane@example.com"],
    }],
});
const policy = new gcp.dataproc.AutoscalingPolicyIamPolicy("policy", {
    project: basic.project,
    location: basic.location,
    policyId: basic.policyId,
    policyData: admin.then(admin => admin.policyData),
});
```
```python
import pulumi
import pulumi_gcp as gcp

admin = gcp.organizations.get_iam_policy(bindings=[{
    "role": "roles/viewer",
    "members": ["user:jane@example.com"],
}])
policy = gcp.dataproc.AutoscalingPolicyIamPolicy("policy",
    project=basic["project"],
    location=basic["location"],
    policy_id=basic["policyId"],
    policy_data=admin.policy_data)
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var admin = Gcp.Organizations.GetIAMPolicy.Invoke(new()
    {
        Bindings = new[]
        {
            new Gcp.Organizations.Inputs.GetIAMPolicyBindingInputArgs
            {
                Role = "roles/viewer",
                Members = new[]
                {
                    "user:jane@example.com",
                },
            },
        },
    });

    var policy = new Gcp.Dataproc.AutoscalingPolicyIamPolicy("policy", new()
    {
        Project = basic.Project,
        Location = basic.Location,
        PolicyId = basic.PolicyId,
        PolicyData = admin.Apply(getIAMPolicyResult => getIAMPolicyResult.PolicyData),
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/dataproc"
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/organizations"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		admin, err := organizations.LookupIAMPolicy(ctx, &organizations.LookupIAMPolicyArgs{
			Bindings: []organizations.GetIAMPolicyBinding{
				{
					Role: "roles/viewer",
					Members: []string{
						"user:jane@example.com",
					},
				},
			},
		}, nil)
		if err != nil {
			return err
		}
		_, err = dataproc.NewAutoscalingPolicyIamPolicy(ctx, "policy", &dataproc.AutoscalingPolicyIamPolicyArgs{
			Project:    pulumi.Any(basic.Project),
			Location:   pulumi.Any(basic.Location),
			PolicyId:   pulumi.Any(basic.PolicyId),
			PolicyData: pulumi.String(admin.PolicyData),
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.organizations.OrganizationsFunctions;
import com.pulumi.gcp.organizations.inputs.GetIAMPolicyArgs;
import com.pulumi.gcp.dataproc.AutoscalingPolicyIamPolicy;
import com.pulumi.gcp.dataproc.AutoscalingPolicyIamPolicyArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        final var admin = OrganizationsFunctions.getIAMPolicy(GetIAMPolicyArgs.builder()
            .bindings(GetIAMPolicyBindingArgs.builder()
                .role("roles/viewer")
                .members("user:jane@example.com")
                .build())
            .build());

        var policy = new AutoscalingPolicyIamPolicy("policy", AutoscalingPolicyIamPolicyArgs.builder()
            .project(basic.project())
            .location(basic.location())
            .policyId(basic.policyId())
            .policyData(admin.applyValue(getIAMPolicyResult -> getIAMPolicyResult.policyData()))
            .build());

    }
}
```
```yaml
resources:
  policy:
    type: gcp:dataproc:AutoscalingPolicyIamPolicy
    properties:
      project: ${basic.project}
      location: ${basic.location}
      policyId: ${basic.policyId}
      policyData: ${admin.policyData}
variables:
  admin:
    fn::invoke:
      function: gcp:organizations:getIAMPolicy
      arguments:
        bindings:
          - role: roles/viewer
            members:
              - user:jane@example.com
```
<!--End PulumiCodeChooser -->

## gcp.dataproc.AutoscalingPolicyIamBinding

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const binding = new gcp.dataproc.AutoscalingPolicyIamBinding("binding", {
    project: basic.project,
    location: basic.location,
    policyId: basic.policyId,
    role: "roles/viewer",
    members: ["user:jane@example.com"],
});
```
```python
import pulumi
import pulumi_gcp as gcp

binding = gcp.dataproc.AutoscalingPolicyIamBinding("binding",
    project=basic["project"],
    location=basic["location"],
    policy_id=basic["policyId"],
    role="roles/viewer",
    members=["user:jane@example.com"])
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var binding = new Gcp.Dataproc.AutoscalingPolicyIamBinding("binding", new()
    {
        Project = basic.Project,
        Location = basic.Location,
        PolicyId = basic.PolicyId,
        Role = "roles/viewer",
        Members = new[]
        {
            "user:jane@example.com",
        },
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/dataproc"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		_, err := dataproc.NewAutoscalingPolicyIamBinding(ctx, "binding", &dataproc.AutoscalingPolicyIamBindingArgs{
			Project:  pulumi.Any(basic.Project),
			Location: pulumi.Any(basic.Location),
			PolicyId: pulumi.Any(basic.PolicyId),
			Role:     pulumi.String("roles/viewer"),
			Members: pulumi.StringArray{
				pulumi.String("user:jane@example.com"),
			},
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.dataproc.AutoscalingPolicyIamBinding;
import com.pulumi.gcp.dataproc.AutoscalingPolicyIamBindingArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        var binding = new AutoscalingPolicyIamBinding("binding", AutoscalingPolicyIamBindingArgs.builder()
            .project(basic.project())
            .location(basic.location())
            .policyId(basic.policyId())
            .role("roles/viewer")
            .members("user:jane@example.com")
            .build());

    }
}
```
```yaml
resources:
  binding:
    type: gcp:dataproc:AutoscalingPolicyIamBinding
    properties:
      project: ${basic.project}
      location: ${basic.location}
      policyId: ${basic.policyId}
      role: roles/viewer
      members:
        - user:jane@example.com
```
<!--End PulumiCodeChooser -->

## gcp.dataproc.AutoscalingPolicyIamMember

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const member = new gcp.dataproc.AutoscalingPolicyIamMember("member", {
    project: basic.project,
    location: basic.location,
    policyId: basic.policyId,
    role: "roles/viewer",
    member: "user:jane@example.com",
});
```
```python
import pulumi
import pulumi_gcp as gcp

member = gcp.dataproc.AutoscalingPolicyIamMember("member",
    project=basic["project"],
    location=basic["location"],
    policy_id=basic["policyId"],
    role="roles/viewer",
    member="user:jane@example.com")
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var member = new Gcp.Dataproc.AutoscalingPolicyIamMember("member", new()
    {
        Project = basic.Project,
        Location = basic.Location,
        PolicyId = basic.PolicyId,
        Role = "roles/viewer",
        Member = "user:jane@example.com",
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/dataproc"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		_, err := dataproc.NewAutoscalingPolicyIamMember(ctx, "member", &dataproc.AutoscalingPolicyIamMemberArgs{
			Project:  pulumi.Any(basic.Project),
			Location: pulumi.Any(basic.Location),
			PolicyId: pulumi.Any(basic.PolicyId),
			Role:     pulumi.String("roles/viewer"),
			Member:   pulumi.String("user:jane@example.com"),
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.dataproc.AutoscalingPolicyIamMember;
import com.pulumi.gcp.dataproc.AutoscalingPolicyIamMemberArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        var member = new AutoscalingPolicyIamMember("member", AutoscalingPolicyIamMemberArgs.builder()
            .project(basic.project())
            .location(basic.location())
            .policyId(basic.policyId())
            .role("roles/viewer")
            .member("user:jane@example.com")
            .build());

    }
}
```
```yaml
resources:
  member:
    type: gcp:dataproc:AutoscalingPolicyIamMember
    properties:
      project: ${basic.project}
      location: ${basic.location}
      policyId: ${basic.policyId}
      role: roles/viewer
      member: user:jane@example.com
```
<!--End PulumiCodeChooser -->


## This resource supports User Project Overrides.

-

# IAM policy for Dataproc AutoscalingPolicy
Three different resources help you manage your IAM policy for Dataproc AutoscalingPolicy. Each of these resources serves a different use case:

* `gcp.dataproc.AutoscalingPolicyIamPolicy`: Authoritative. Sets the IAM policy for the autoscalingpolicy and replaces any existing policy already attached.
* `gcp.dataproc.AutoscalingPolicyIamBinding`: Authoritative for a given role. Updates the IAM policy to grant a role to a list of members. Other roles within the IAM policy for the autoscalingpolicy are preserved.
* `gcp.dataproc.AutoscalingPolicyIamMember`: Non-authoritative. Updates the IAM policy to grant a role to a new member. Other members for the role for the autoscalingpolicy are preserved.

A data source can be used to retrieve policy data in advent you do not need creation

* `gcp.dataproc.AutoscalingPolicyIamPolicy`: Retrieves the IAM policy for the autoscalingpolicy

> **Note:** `gcp.dataproc.AutoscalingPolicyIamPolicy` **cannot** be used in conjunction with `gcp.dataproc.AutoscalingPolicyIamBinding` and `gcp.dataproc.AutoscalingPolicyIamMember` or they will fight over what your policy should be.

> **Note:** `gcp.dataproc.AutoscalingPolicyIamBinding` resources **can be** used in conjunction with `gcp.dataproc.AutoscalingPolicyIamMember` resources **only if** they do not grant privilege to the same role.



## gcp.dataproc.AutoscalingPolicyIamPolicy

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const admin = gcp.organizations.getIAMPolicy({
    bindings: [{
        role: "roles/viewer",
        members: ["user:jane@example.com"],
    }],
});
const policy = new gcp.dataproc.AutoscalingPolicyIamPolicy("policy", {
    project: basic.project,
    location: basic.location,
    policyId: basic.policyId,
    policyData: admin.then(admin => admin.policyData),
});
```
```python
import pulumi
import pulumi_gcp as gcp

admin = gcp.organizations.get_iam_policy(bindings=[{
    "role": "roles/viewer",
    "members": ["user:jane@example.com"],
}])
policy = gcp.dataproc.AutoscalingPolicyIamPolicy("policy",
    project=basic["project"],
    location=basic["location"],
    policy_id=basic["policyId"],
    policy_data=admin.policy_data)
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var admin = Gcp.Organizations.GetIAMPolicy.Invoke(new()
    {
        Bindings = new[]
        {
            new Gcp.Organizations.Inputs.GetIAMPolicyBindingInputArgs
            {
                Role = "roles/viewer",
                Members = new[]
                {
                    "user:jane@example.com",
                },
            },
        },
    });

    var policy = new Gcp.Dataproc.AutoscalingPolicyIamPolicy("policy", new()
    {
        Project = basic.Project,
        Location = basic.Location,
        PolicyId = basic.PolicyId,
        PolicyData = admin.Apply(getIAMPolicyResult => getIAMPolicyResult.PolicyData),
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/dataproc"
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/organizations"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		admin, err := organizations.LookupIAMPolicy(ctx, &organizations.LookupIAMPolicyArgs{
			Bindings: []organizations.GetIAMPolicyBinding{
				{
					Role: "roles/viewer",
					Members: []string{
						"user:jane@example.com",
					},
				},
			},
		}, nil)
		if err != nil {
			return err
		}
		_, err = dataproc.NewAutoscalingPolicyIamPolicy(ctx, "policy", &dataproc.AutoscalingPolicyIamPolicyArgs{
			Project:    pulumi.Any(basic.Project),
			Location:   pulumi.Any(basic.Location),
			PolicyId:   pulumi.Any(basic.PolicyId),
			PolicyData: pulumi.String(admin.PolicyData),
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.organizations.OrganizationsFunctions;
import com.pulumi.gcp.organizations.inputs.GetIAMPolicyArgs;
import com.pulumi.gcp.dataproc.AutoscalingPolicyIamPolicy;
import com.pulumi.gcp.dataproc.AutoscalingPolicyIamPolicyArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        final var admin = OrganizationsFunctions.getIAMPolicy(GetIAMPolicyArgs.builder()
            .bindings(GetIAMPolicyBindingArgs.builder()
                .role("roles/viewer")
                .members("user:jane@example.com")
                .build())
            .build());

        var policy = new AutoscalingPolicyIamPolicy("policy", AutoscalingPolicyIamPolicyArgs.builder()
            .project(basic.project())
            .location(basic.location())
            .policyId(basic.policyId())
            .policyData(admin.applyValue(getIAMPolicyResult -> getIAMPolicyResult.policyData()))
            .build());

    }
}
```
```yaml
resources:
  policy:
    type: gcp:dataproc:AutoscalingPolicyIamPolicy
    properties:
      project: ${basic.project}
      location: ${basic.location}
      policyId: ${basic.policyId}
      policyData: ${admin.policyData}
variables:
  admin:
    fn::invoke:
      function: gcp:organizations:getIAMPolicy
      arguments:
        bindings:
          - role: roles/viewer
            members:
              - user:jane@example.com
```
<!--End PulumiCodeChooser -->

## gcp.dataproc.AutoscalingPolicyIamBinding

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const binding = new gcp.dataproc.AutoscalingPolicyIamBinding("binding", {
    project: basic.project,
    location: basic.location,
    policyId: basic.policyId,
    role: "roles/viewer",
    members: ["user:jane@example.com"],
});
```
```python
import pulumi
import pulumi_gcp as gcp

binding = gcp.dataproc.AutoscalingPolicyIamBinding("binding",
    project=basic["project"],
    location=basic["location"],
    policy_id=basic["policyId"],
    role="roles/viewer",
    members=["user:jane@example.com"])
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var binding = new Gcp.Dataproc.AutoscalingPolicyIamBinding("binding", new()
    {
        Project = basic.Project,
        Location = basic.Location,
        PolicyId = basic.PolicyId,
        Role = "roles/viewer",
        Members = new[]
        {
            "user:jane@example.com",
        },
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/dataproc"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		_, err := dataproc.NewAutoscalingPolicyIamBinding(ctx, "binding", &dataproc.AutoscalingPolicyIamBindingArgs{
			Project:  pulumi.Any(basic.Project),
			Location: pulumi.Any(basic.Location),
			PolicyId: pulumi.Any(basic.PolicyId),
			Role:     pulumi.String("roles/viewer"),
			Members: pulumi.StringArray{
				pulumi.String("user:jane@example.com"),
			},
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.dataproc.AutoscalingPolicyIamBinding;
import com.pulumi.gcp.dataproc.AutoscalingPolicyIamBindingArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        var binding = new AutoscalingPolicyIamBinding("binding", AutoscalingPolicyIamBindingArgs.builder()
            .project(basic.project())
            .location(basic.location())
            .policyId(basic.policyId())
            .role("roles/viewer")
            .members("user:jane@example.com")
            .build());

    }
}
```
```yaml
resources:
  binding:
    type: gcp:dataproc:AutoscalingPolicyIamBinding
    properties:
      project: ${basic.project}
      location: ${basic.location}
      policyId: ${basic.policyId}
      role: roles/viewer
      members:
        - user:jane@example.com
```
<!--End PulumiCodeChooser -->

## gcp.dataproc.AutoscalingPolicyIamMember

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const member = new gcp.dataproc.AutoscalingPolicyIamMember("member", {
    project: basic.project,
    location: basic.location,
    policyId: basic.policyId,
    role: "roles/viewer",
    member: "user:jane@example.com",
});
```
```python
import pulumi
import pulumi_gcp as gcp

member = gcp.dataproc.AutoscalingPolicyIamMember("member",
    project=basic["project"],
    location=basic["location"],
    policy_id=basic["policyId"],
    role="roles/viewer",
    member="user:jane@example.com")
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var member = new Gcp.Dataproc.AutoscalingPolicyIamMember("member", new()
    {
        Project = basic.Project,
        Location = basic.Location,
        PolicyId = basic.PolicyId,
        Role = "roles/viewer",
        Member = "user:jane@example.com",
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/dataproc"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		_, err := dataproc.NewAutoscalingPolicyIamMember(ctx, "member", &dataproc.AutoscalingPolicyIamMemberArgs{
			Project:  pulumi.Any(basic.Project),
			Location: pulumi.Any(basic.Location),
			PolicyId: pulumi.Any(basic.PolicyId),
			Role:     pulumi.String("roles/viewer"),
			Member:   pulumi.String("user:jane@example.com"),
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.dataproc.AutoscalingPolicyIamMember;
import com.pulumi.gcp.dataproc.AutoscalingPolicyIamMemberArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        var member = new AutoscalingPolicyIamMember("member", AutoscalingPolicyIamMemberArgs.builder()
            .project(basic.project())
            .location(basic.location())
            .policyId(basic.policyId())
            .role("roles/viewer")
            .member("user:jane@example.com")
            .build());

    }
}
```
```yaml
resources:
  member:
    type: gcp:dataproc:AutoscalingPolicyIamMember
    properties:
      project: ${basic.project}
      location: ${basic.location}
      policyId: ${basic.policyId}
      role: roles/viewer
      member: user:jane@example.com
```
<!--End PulumiCodeChooser -->

## Import

For all import syntaxes, the "resource in question" can take any of the following forms:

* projects/{{project}}/locations/{{location}}/autoscalingPolicies/{{policy_id}}

* {{project}}/{{location}}/{{policy_id}}

* {{location}}/{{policy_id}}

* {{policy_id}}

Any variables not passed in the import command will be taken from the provider configuration.

Dataproc autoscalingpolicy IAM resources can be imported using the resource identifiers, role, and member.

IAM member imports use space-delimited identifiers: the resource in question, the role, and the member identity, e.g.

```sh
$ pulumi import gcp:dataproc/autoscalingPolicyIamBinding:AutoscalingPolicyIamBinding editor "projects/{{project}}/locations/{{location}}/autoscalingPolicies/{{policy_id}} roles/viewer user:jane@example.com"
```

IAM binding imports use space-delimited identifiers: the resource in question and the role, e.g.

```sh
$ pulumi import gcp:dataproc/autoscalingPolicyIamBinding:AutoscalingPolicyIamBinding editor "projects/{{project}}/locations/{{location}}/autoscalingPolicies/{{policy_id}} roles/viewer"
```

IAM policy imports use the identifier of the resource in question, e.g.

```sh
$ pulumi import gcp:dataproc/autoscalingPolicyIamBinding:AutoscalingPolicyIamBinding editor projects/{{project}}/locations/{{location}}/autoscalingPolicies/{{policy_id}}
```

-> **Custom Roles** If you're importing a IAM resource with a custom role, make sure to use the

 full name of the custom role, e.g. `[projects/my-project|organizations/my-org]/roles/my-custom-role`.


	conditionB:

dataproc$AutoscalingPolicyIamBindingConditionVgcp:dataproc/AutoscalingPolicyIamBindingCondition:AutoscalingPolicyIamBindingConditionþ
locationB" ëThe  location where the autoscaling policy should reside.
The default value is `global`.
Used to find the parent resource to bind the IAM policy to. If not specified,
the value will be parsed from the identifier of the parent resource. If no location is provided in the parent identifier and no
location is specified, it is taken from the provider configuration.
Ö	
members*" Ä	Identities that will be granted the privilege in `role`.
Each entry can have one of the following values:
* **allUsers**: A special identifier that represents anyone who is on the internet; with or without a Google account.
* **allAuthenticatedUsers**: A special identifier that represents anyone who is authenticated with a Google account or a service account.
* **user:{emailid}**: An email address that represents a specific Google account. For example, alice@gmail.com or joe@example.com.
* **serviceAccount:{emailid}**: An email address that represents a service account. For example, my-other-app@appspot.gserviceaccount.com.
* **group:{emailid}**: An email address that represents a Google group. For example, admins@example.com.
* **domain:{domain}**: A G Suite domain (primary, instead of alias) name that represents all the users of that domain. For example, google.com or example.com.
* **projectOwner:projectid**: Owners of the given project. For example, "projectOwner:my-example-project"
* **projectEditor:projectid**: Editors of the given project. For example, "projectEditor:my-example-project"
* **projectViewer:projectid**: Viewers of the given project. For example, "projectViewer:my-example-project"

policyId" The policy id. The id must contain only letters (a-z, A-Z), numbers (0-9), underscores (_),
and hyphens (-). Cannot begin or end with underscore or hyphen. Must consist of between
3 and 50 characters.
Used to find the parent resource to bind the IAM policy to

projectB" The ID of the project in which the resource belongs.
If it is not provided, the project will be parsed from the identifier of the parent resource. If no project is provided in the parent identifier and no project is specified, the provider project is used.
á
role" ÔThe role that should be applied. Only one
`gcp.dataproc.AutoscalingPolicyIamBinding` can be used per role. Note that custom roles must be of the format
`[projects|organizations]/{parent-name}/roles/{role-name}`.
"
	conditionB:

dataproc$AutoscalingPolicyIamBindingConditionVgcp:dataproc/AutoscalingPolicyIamBindingCondition:AutoscalingPolicyIamBindingCondition"3
etag" '(Computed) The etag of the IAM policy.
"ü
location" ëThe  location where the autoscaling policy should reside.
The default value is `global`.
Used to find the parent resource to bind the IAM policy to. If not specified,
the value will be parsed from the identifier of the parent resource. If no location is provided in the parent identifier and no
location is specified, it is taken from the provider configuration.
"Ö	
members*" Ä	Identities that will be granted the privilege in `role`.
Each entry can have one of the following values:
* **allUsers**: A special identifier that represents anyone who is on the internet; with or without a Google account.
* **allAuthenticatedUsers**: A special identifier that represents anyone who is authenticated with a Google account or a service account.
* **user:{emailid}**: An email address that represents a specific Google account. For example, alice@gmail.com or joe@example.com.
* **serviceAccount:{emailid}**: An email address that represents a service account. For example, my-other-app@appspot.gserviceaccount.com.
* **group:{emailid}**: An email address that represents a Google group. For example, admins@example.com.
* **domain:{domain}**: A G Suite domain (primary, instead of alias) name that represents all the users of that domain. For example, google.com or example.com.
* **projectOwner:projectid**: Owners of the given project. For example, "projectOwner:my-example-project"
* **projectEditor:projectid**: Editors of the given project. For example, "projectEditor:my-example-project"
* **projectViewer:projectid**: Viewers of the given project. For example, "projectViewer:my-example-project"
"
policyId" The policy id. The id must contain only letters (a-z, A-Z), numbers (0-9), underscores (_),
and hyphens (-). Cannot begin or end with underscore or hyphen. Must consist of between
3 and 50 characters.
Used to find the parent resource to bind the IAM policy to
"
project" The ID of the project in which the resource belongs.
If it is not provided, the project will be parsed from the identifier of the parent resource. If no project is provided in the parent identifier and no project is specified, the provider project is used.
"á
role" ÔThe role that should be applied. Only one
`gcp.dataproc.AutoscalingPolicyIamBinding` can be used per role. Note that custom roles must be of the format
`[projects|organizations]/{parent-name}/roles/{role-name}`.
*ê
j
dataprocAutoscalingPolicyIamMemberBgcp:dataproc/autoscalingPolicyIamMember:AutoscalingPolicyIamMemberÓÀThree different resources help you manage your IAM policy for Dataproc AutoscalingPolicy. Each of these resources serves a different use case:

* `gcp.dataproc.AutoscalingPolicyIamPolicy`: Authoritative. Sets the IAM policy for the autoscalingpolicy and replaces any existing policy already attached.
* `gcp.dataproc.AutoscalingPolicyIamBinding`: Authoritative for a given role. Updates the IAM policy to grant a role to a list of members. Other roles within the IAM policy for the autoscalingpolicy are preserved.
* `gcp.dataproc.AutoscalingPolicyIamMember`: Non-authoritative. Updates the IAM policy to grant a role to a new member. Other members for the role for the autoscalingpolicy are preserved.

A data source can be used to retrieve policy data in advent you do not need creation

* `gcp.dataproc.AutoscalingPolicyIamPolicy`: Retrieves the IAM policy for the autoscalingpolicy

> **Note:** `gcp.dataproc.AutoscalingPolicyIamPolicy` **cannot** be used in conjunction with `gcp.dataproc.AutoscalingPolicyIamBinding` and `gcp.dataproc.AutoscalingPolicyIamMember` or they will fight over what your policy should be.

> **Note:** `gcp.dataproc.AutoscalingPolicyIamBinding` resources **can be** used in conjunction with `gcp.dataproc.AutoscalingPolicyIamMember` resources **only if** they do not grant privilege to the same role.



## gcp.dataproc.AutoscalingPolicyIamPolicy

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const admin = gcp.organizations.getIAMPolicy({
    bindings: [{
        role: "roles/viewer",
        members: ["user:jane@example.com"],
    }],
});
const policy = new gcp.dataproc.AutoscalingPolicyIamPolicy("policy", {
    project: basic.project,
    location: basic.location,
    policyId: basic.policyId,
    policyData: admin.then(admin => admin.policyData),
});
```
```python
import pulumi
import pulumi_gcp as gcp

admin = gcp.organizations.get_iam_policy(bindings=[{
    "role": "roles/viewer",
    "members": ["user:jane@example.com"],
}])
policy = gcp.dataproc.AutoscalingPolicyIamPolicy("policy",
    project=basic["project"],
    location=basic["location"],
    policy_id=basic["policyId"],
    policy_data=admin.policy_data)
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var admin = Gcp.Organizations.GetIAMPolicy.Invoke(new()
    {
        Bindings = new[]
        {
            new Gcp.Organizations.Inputs.GetIAMPolicyBindingInputArgs
            {
                Role = "roles/viewer",
                Members = new[]
                {
                    "user:jane@example.com",
                },
            },
        },
    });

    var policy = new Gcp.Dataproc.AutoscalingPolicyIamPolicy("policy", new()
    {
        Project = basic.Project,
        Location = basic.Location,
        PolicyId = basic.PolicyId,
        PolicyData = admin.Apply(getIAMPolicyResult => getIAMPolicyResult.PolicyData),
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/dataproc"
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/organizations"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		admin, err := organizations.LookupIAMPolicy(ctx, &organizations.LookupIAMPolicyArgs{
			Bindings: []organizations.GetIAMPolicyBinding{
				{
					Role: "roles/viewer",
					Members: []string{
						"user:jane@example.com",
					},
				},
			},
		}, nil)
		if err != nil {
			return err
		}
		_, err = dataproc.NewAutoscalingPolicyIamPolicy(ctx, "policy", &dataproc.AutoscalingPolicyIamPolicyArgs{
			Project:    pulumi.Any(basic.Project),
			Location:   pulumi.Any(basic.Location),
			PolicyId:   pulumi.Any(basic.PolicyId),
			PolicyData: pulumi.String(admin.PolicyData),
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.organizations.OrganizationsFunctions;
import com.pulumi.gcp.organizations.inputs.GetIAMPolicyArgs;
import com.pulumi.gcp.dataproc.AutoscalingPolicyIamPolicy;
import com.pulumi.gcp.dataproc.AutoscalingPolicyIamPolicyArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        final var admin = OrganizationsFunctions.getIAMPolicy(GetIAMPolicyArgs.builder()
            .bindings(GetIAMPolicyBindingArgs.builder()
                .role("roles/viewer")
                .members("user:jane@example.com")
                .build())
            .build());

        var policy = new AutoscalingPolicyIamPolicy("policy", AutoscalingPolicyIamPolicyArgs.builder()
            .project(basic.project())
            .location(basic.location())
            .policyId(basic.policyId())
            .policyData(admin.applyValue(getIAMPolicyResult -> getIAMPolicyResult.policyData()))
            .build());

    }
}
```
```yaml
resources:
  policy:
    type: gcp:dataproc:AutoscalingPolicyIamPolicy
    properties:
      project: ${basic.project}
      location: ${basic.location}
      policyId: ${basic.policyId}
      policyData: ${admin.policyData}
variables:
  admin:
    fn::invoke:
      function: gcp:organizations:getIAMPolicy
      arguments:
        bindings:
          - role: roles/viewer
            members:
              - user:jane@example.com
```
<!--End PulumiCodeChooser -->

## gcp.dataproc.AutoscalingPolicyIamBinding

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const binding = new gcp.dataproc.AutoscalingPolicyIamBinding("binding", {
    project: basic.project,
    location: basic.location,
    policyId: basic.policyId,
    role: "roles/viewer",
    members: ["user:jane@example.com"],
});
```
```python
import pulumi
import pulumi_gcp as gcp

binding = gcp.dataproc.AutoscalingPolicyIamBinding("binding",
    project=basic["project"],
    location=basic["location"],
    policy_id=basic["policyId"],
    role="roles/viewer",
    members=["user:jane@example.com"])
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var binding = new Gcp.Dataproc.AutoscalingPolicyIamBinding("binding", new()
    {
        Project = basic.Project,
        Location = basic.Location,
        PolicyId = basic.PolicyId,
        Role = "roles/viewer",
        Members = new[]
        {
            "user:jane@example.com",
        },
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/dataproc"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		_, err := dataproc.NewAutoscalingPolicyIamBinding(ctx, "binding", &dataproc.AutoscalingPolicyIamBindingArgs{
			Project:  pulumi.Any(basic.Project),
			Location: pulumi.Any(basic.Location),
			PolicyId: pulumi.Any(basic.PolicyId),
			Role:     pulumi.String("roles/viewer"),
			Members: pulumi.StringArray{
				pulumi.String("user:jane@example.com"),
			},
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.dataproc.AutoscalingPolicyIamBinding;
import com.pulumi.gcp.dataproc.AutoscalingPolicyIamBindingArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        var binding = new AutoscalingPolicyIamBinding("binding", AutoscalingPolicyIamBindingArgs.builder()
            .project(basic.project())
            .location(basic.location())
            .policyId(basic.policyId())
            .role("roles/viewer")
            .members("user:jane@example.com")
            .build());

    }
}
```
```yaml
resources:
  binding:
    type: gcp:dataproc:AutoscalingPolicyIamBinding
    properties:
      project: ${basic.project}
      location: ${basic.location}
      policyId: ${basic.policyId}
      role: roles/viewer
      members:
        - user:jane@example.com
```
<!--End PulumiCodeChooser -->

## gcp.dataproc.AutoscalingPolicyIamMember

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const member = new gcp.dataproc.AutoscalingPolicyIamMember("member", {
    project: basic.project,
    location: basic.location,
    policyId: basic.policyId,
    role: "roles/viewer",
    member: "user:jane@example.com",
});
```
```python
import pulumi
import pulumi_gcp as gcp

member = gcp.dataproc.AutoscalingPolicyIamMember("member",
    project=basic["project"],
    location=basic["location"],
    policy_id=basic["policyId"],
    role="roles/viewer",
    member="user:jane@example.com")
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var member = new Gcp.Dataproc.AutoscalingPolicyIamMember("member", new()
    {
        Project = basic.Project,
        Location = basic.Location,
        PolicyId = basic.PolicyId,
        Role = "roles/viewer",
        Member = "user:jane@example.com",
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/dataproc"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		_, err := dataproc.NewAutoscalingPolicyIamMember(ctx, "member", &dataproc.AutoscalingPolicyIamMemberArgs{
			Project:  pulumi.Any(basic.Project),
			Location: pulumi.Any(basic.Location),
			PolicyId: pulumi.Any(basic.PolicyId),
			Role:     pulumi.String("roles/viewer"),
			Member:   pulumi.String("user:jane@example.com"),
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.dataproc.AutoscalingPolicyIamMember;
import com.pulumi.gcp.dataproc.AutoscalingPolicyIamMemberArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        var member = new AutoscalingPolicyIamMember("member", AutoscalingPolicyIamMemberArgs.builder()
            .project(basic.project())
            .location(basic.location())
            .policyId(basic.policyId())
            .role("roles/viewer")
            .member("user:jane@example.com")
            .build());

    }
}
```
```yaml
resources:
  member:
    type: gcp:dataproc:AutoscalingPolicyIamMember
    properties:
      project: ${basic.project}
      location: ${basic.location}
      policyId: ${basic.policyId}
      role: roles/viewer
      member: user:jane@example.com
```
<!--End PulumiCodeChooser -->


## This resource supports User Project Overrides.

-

# IAM policy for Dataproc AutoscalingPolicy
Three different resources help you manage your IAM policy for Dataproc AutoscalingPolicy. Each of these resources serves a different use case:

* `gcp.dataproc.AutoscalingPolicyIamPolicy`: Authoritative. Sets the IAM policy for the autoscalingpolicy and replaces any existing policy already attached.
* `gcp.dataproc.AutoscalingPolicyIamBinding`: Authoritative for a given role. Updates the IAM policy to grant a role to a list of members. Other roles within the IAM policy for the autoscalingpolicy are preserved.
* `gcp.dataproc.AutoscalingPolicyIamMember`: Non-authoritative. Updates the IAM policy to grant a role to a new member. Other members for the role for the autoscalingpolicy are preserved.

A data source can be used to retrieve policy data in advent you do not need creation

* `gcp.dataproc.AutoscalingPolicyIamPolicy`: Retrieves the IAM policy for the autoscalingpolicy

> **Note:** `gcp.dataproc.AutoscalingPolicyIamPolicy` **cannot** be used in conjunction with `gcp.dataproc.AutoscalingPolicyIamBinding` and `gcp.dataproc.AutoscalingPolicyIamMember` or they will fight over what your policy should be.

> **Note:** `gcp.dataproc.AutoscalingPolicyIamBinding` resources **can be** used in conjunction with `gcp.dataproc.AutoscalingPolicyIamMember` resources **only if** they do not grant privilege to the same role.



## gcp.dataproc.AutoscalingPolicyIamPolicy

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const admin = gcp.organizations.getIAMPolicy({
    bindings: [{
        role: "roles/viewer",
        members: ["user:jane@example.com"],
    }],
});
const policy = new gcp.dataproc.AutoscalingPolicyIamPolicy("policy", {
    project: basic.project,
    location: basic.location,
    policyId: basic.policyId,
    policyData: admin.then(admin => admin.policyData),
});
```
```python
import pulumi
import pulumi_gcp as gcp

admin = gcp.organizations.get_iam_policy(bindings=[{
    "role": "roles/viewer",
    "members": ["user:jane@example.com"],
}])
policy = gcp.dataproc.AutoscalingPolicyIamPolicy("policy",
    project=basic["project"],
    location=basic["location"],
    policy_id=basic["policyId"],
    policy_data=admin.policy_data)
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var admin = Gcp.Organizations.GetIAMPolicy.Invoke(new()
    {
        Bindings = new[]
        {
            new Gcp.Organizations.Inputs.GetIAMPolicyBindingInputArgs
            {
                Role = "roles/viewer",
                Members = new[]
                {
                    "user:jane@example.com",
                },
            },
        },
    });

    var policy = new Gcp.Dataproc.AutoscalingPolicyIamPolicy("policy", new()
    {
        Project = basic.Project,
        Location = basic.Location,
        PolicyId = basic.PolicyId,
        PolicyData = admin.Apply(getIAMPolicyResult => getIAMPolicyResult.PolicyData),
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/dataproc"
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/organizations"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		admin, err := organizations.LookupIAMPolicy(ctx, &organizations.LookupIAMPolicyArgs{
			Bindings: []organizations.GetIAMPolicyBinding{
				{
					Role: "roles/viewer",
					Members: []string{
						"user:jane@example.com",
					},
				},
			},
		}, nil)
		if err != nil {
			return err
		}
		_, err = dataproc.NewAutoscalingPolicyIamPolicy(ctx, "policy", &dataproc.AutoscalingPolicyIamPolicyArgs{
			Project:    pulumi.Any(basic.Project),
			Location:   pulumi.Any(basic.Location),
			PolicyId:   pulumi.Any(basic.PolicyId),
			PolicyData: pulumi.String(admin.PolicyData),
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.organizations.OrganizationsFunctions;
import com.pulumi.gcp.organizations.inputs.GetIAMPolicyArgs;
import com.pulumi.gcp.dataproc.AutoscalingPolicyIamPolicy;
import com.pulumi.gcp.dataproc.AutoscalingPolicyIamPolicyArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        final var admin = OrganizationsFunctions.getIAMPolicy(GetIAMPolicyArgs.builder()
            .bindings(GetIAMPolicyBindingArgs.builder()
                .role("roles/viewer")
                .members("user:jane@example.com")
                .build())
            .build());

        var policy = new AutoscalingPolicyIamPolicy("policy", AutoscalingPolicyIamPolicyArgs.builder()
            .project(basic.project())
            .location(basic.location())
            .policyId(basic.policyId())
            .policyData(admin.applyValue(getIAMPolicyResult -> getIAMPolicyResult.policyData()))
            .build());

    }
}
```
```yaml
resources:
  policy:
    type: gcp:dataproc:AutoscalingPolicyIamPolicy
    properties:
      project: ${basic.project}
      location: ${basic.location}
      policyId: ${basic.policyId}
      policyData: ${admin.policyData}
variables:
  admin:
    fn::invoke:
      function: gcp:organizations:getIAMPolicy
      arguments:
        bindings:
          - role: roles/viewer
            members:
              - user:jane@example.com
```
<!--End PulumiCodeChooser -->

## gcp.dataproc.AutoscalingPolicyIamBinding

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const binding = new gcp.dataproc.AutoscalingPolicyIamBinding("binding", {
    project: basic.project,
    location: basic.location,
    policyId: basic.policyId,
    role: "roles/viewer",
    members: ["user:jane@example.com"],
});
```
```python
import pulumi
import pulumi_gcp as gcp

binding = gcp.dataproc.AutoscalingPolicyIamBinding("binding",
    project=basic["project"],
    location=basic["location"],
    policy_id=basic["policyId"],
    role="roles/viewer",
    members=["user:jane@example.com"])
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var binding = new Gcp.Dataproc.AutoscalingPolicyIamBinding("binding", new()
    {
        Project = basic.Project,
        Location = basic.Location,
        PolicyId = basic.PolicyId,
        Role = "roles/viewer",
        Members = new[]
        {
            "user:jane@example.com",
        },
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/dataproc"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		_, err := dataproc.NewAutoscalingPolicyIamBinding(ctx, "binding", &dataproc.AutoscalingPolicyIamBindingArgs{
			Project:  pulumi.Any(basic.Project),
			Location: pulumi.Any(basic.Location),
			PolicyId: pulumi.Any(basic.PolicyId),
			Role:     pulumi.String("roles/viewer"),
			Members: pulumi.StringArray{
				pulumi.String("user:jane@example.com"),
			},
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.dataproc.AutoscalingPolicyIamBinding;
import com.pulumi.gcp.dataproc.AutoscalingPolicyIamBindingArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        var binding = new AutoscalingPolicyIamBinding("binding", AutoscalingPolicyIamBindingArgs.builder()
            .project(basic.project())
            .location(basic.location())
            .policyId(basic.policyId())
            .role("roles/viewer")
            .members("user:jane@example.com")
            .build());

    }
}
```
```yaml
resources:
  binding:
    type: gcp:dataproc:AutoscalingPolicyIamBinding
    properties:
      project: ${basic.project}
      location: ${basic.location}
      policyId: ${basic.policyId}
      role: roles/viewer
      members:
        - user:jane@example.com
```
<!--End PulumiCodeChooser -->

## gcp.dataproc.AutoscalingPolicyIamMember

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const member = new gcp.dataproc.AutoscalingPolicyIamMember("member", {
    project: basic.project,
    location: basic.location,
    policyId: basic.policyId,
    role: "roles/viewer",
    member: "user:jane@example.com",
});
```
```python
import pulumi
import pulumi_gcp as gcp

member = gcp.dataproc.AutoscalingPolicyIamMember("member",
    project=basic["project"],
    location=basic["location"],
    policy_id=basic["policyId"],
    role="roles/viewer",
    member="user:jane@example.com")
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var member = new Gcp.Dataproc.AutoscalingPolicyIamMember("member", new()
    {
        Project = basic.Project,
        Location = basic.Location,
        PolicyId = basic.PolicyId,
        Role = "roles/viewer",
        Member = "user:jane@example.com",
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/dataproc"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		_, err := dataproc.NewAutoscalingPolicyIamMember(ctx, "member", &dataproc.AutoscalingPolicyIamMemberArgs{
			Project:  pulumi.Any(basic.Project),
			Location: pulumi.Any(basic.Location),
			PolicyId: pulumi.Any(basic.PolicyId),
			Role:     pulumi.String("roles/viewer"),
			Member:   pulumi.String("user:jane@example.com"),
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.dataproc.AutoscalingPolicyIamMember;
import com.pulumi.gcp.dataproc.AutoscalingPolicyIamMemberArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        var member = new AutoscalingPolicyIamMember("member", AutoscalingPolicyIamMemberArgs.builder()
            .project(basic.project())
            .location(basic.location())
            .policyId(basic.policyId())
            .role("roles/viewer")
            .member("user:jane@example.com")
            .build());

    }
}
```
```yaml
resources:
  member:
    type: gcp:dataproc:AutoscalingPolicyIamMember
    properties:
      project: ${basic.project}
      location: ${basic.location}
      policyId: ${basic.policyId}
      role: roles/viewer
      member: user:jane@example.com
```
<!--End PulumiCodeChooser -->

## Import

For all import syntaxes, the "resource in question" can take any of the following forms:

* projects/{{project}}/locations/{{location}}/autoscalingPolicies/{{policy_id}}

* {{project}}/{{location}}/{{policy_id}}

* {{location}}/{{policy_id}}

* {{policy_id}}

Any variables not passed in the import command will be taken from the provider configuration.

Dataproc autoscalingpolicy IAM resources can be imported using the resource identifiers, role, and member.

IAM member imports use space-delimited identifiers: the resource in question, the role, and the member identity, e.g.

```sh
$ pulumi import gcp:dataproc/autoscalingPolicyIamMember:AutoscalingPolicyIamMember editor "projects/{{project}}/locations/{{location}}/autoscalingPolicies/{{policy_id}} roles/viewer user:jane@example.com"
```

IAM binding imports use space-delimited identifiers: the resource in question and the role, e.g.

```sh
$ pulumi import gcp:dataproc/autoscalingPolicyIamMember:AutoscalingPolicyIamMember editor "projects/{{project}}/locations/{{location}}/autoscalingPolicies/{{policy_id}} roles/viewer"
```

IAM policy imports use the identifier of the resource in question, e.g.

```sh
$ pulumi import gcp:dataproc/autoscalingPolicyIamMember:AutoscalingPolicyIamMember editor projects/{{project}}/locations/{{location}}/autoscalingPolicies/{{policy_id}}
```

-> **Custom Roles** If you're importing a IAM resource with a custom role, make sure to use the

 full name of the custom role, e.g. `[projects/my-project|organizations/my-org]/roles/my-custom-role`.


	conditionB:

dataproc#AutoscalingPolicyIamMemberConditionTgcp:dataproc/AutoscalingPolicyIamMemberCondition:AutoscalingPolicyIamMemberConditionþ
locationB" ëThe  location where the autoscaling policy should reside.
The default value is `global`.
Used to find the parent resource to bind the IAM policy to. If not specified,
the value will be parsed from the identifier of the parent resource. If no location is provided in the parent identifier and no
location is specified, it is taken from the provider configuration.
Ó	
member" Ä	Identities that will be granted the privilege in `role`.
Each entry can have one of the following values:
* **allUsers**: A special identifier that represents anyone who is on the internet; with or without a Google account.
* **allAuthenticatedUsers**: A special identifier that represents anyone who is authenticated with a Google account or a service account.
* **user:{emailid}**: An email address that represents a specific Google account. For example, alice@gmail.com or joe@example.com.
* **serviceAccount:{emailid}**: An email address that represents a service account. For example, my-other-app@appspot.gserviceaccount.com.
* **group:{emailid}**: An email address that represents a Google group. For example, admins@example.com.
* **domain:{domain}**: A G Suite domain (primary, instead of alias) name that represents all the users of that domain. For example, google.com or example.com.
* **projectOwner:projectid**: Owners of the given project. For example, "projectOwner:my-example-project"
* **projectEditor:projectid**: Editors of the given project. For example, "projectEditor:my-example-project"
* **projectViewer:projectid**: Viewers of the given project. For example, "projectViewer:my-example-project"

policyId" The policy id. The id must contain only letters (a-z, A-Z), numbers (0-9), underscores (_),
and hyphens (-). Cannot begin or end with underscore or hyphen. Must consist of between
3 and 50 characters.
Used to find the parent resource to bind the IAM policy to

projectB" The ID of the project in which the resource belongs.
If it is not provided, the project will be parsed from the identifier of the parent resource. If no project is provided in the parent identifier and no project is specified, the provider project is used.
á
role" ÔThe role that should be applied. Only one
`gcp.dataproc.AutoscalingPolicyIamBinding` can be used per role. Note that custom roles must be of the format
`[projects|organizations]/{parent-name}/roles/{role-name}`.
"
	conditionB:

dataproc#AutoscalingPolicyIamMemberConditionTgcp:dataproc/AutoscalingPolicyIamMemberCondition:AutoscalingPolicyIamMemberCondition"3
etag" '(Computed) The etag of the IAM policy.
"ü
location" ëThe  location where the autoscaling policy should reside.
The default value is `global`.
Used to find the parent resource to bind the IAM policy to. If not specified,
the value will be parsed from the identifier of the parent resource. If no location is provided in the parent identifier and no
location is specified, it is taken from the provider configuration.
"Ó	
member" Ä	Identities that will be granted the privilege in `role`.
Each entry can have one of the following values:
* **allUsers**: A special identifier that represents anyone who is on the internet; with or without a Google account.
* **allAuthenticatedUsers**: A special identifier that represents anyone who is authenticated with a Google account or a service account.
* **user:{emailid}**: An email address that represents a specific Google account. For example, alice@gmail.com or joe@example.com.
* **serviceAccount:{emailid}**: An email address that represents a service account. For example, my-other-app@appspot.gserviceaccount.com.
* **group:{emailid}**: An email address that represents a Google group. For example, admins@example.com.
* **domain:{domain}**: A G Suite domain (primary, instead of alias) name that represents all the users of that domain. For example, google.com or example.com.
* **projectOwner:projectid**: Owners of the given project. For example, "projectOwner:my-example-project"
* **projectEditor:projectid**: Editors of the given project. For example, "projectEditor:my-example-project"
* **projectViewer:projectid**: Viewers of the given project. For example, "projectViewer:my-example-project"
"
policyId" The policy id. The id must contain only letters (a-z, A-Z), numbers (0-9), underscores (_),
and hyphens (-). Cannot begin or end with underscore or hyphen. Must consist of between
3 and 50 characters.
Used to find the parent resource to bind the IAM policy to
"
project" The ID of the project in which the resource belongs.
If it is not provided, the project will be parsed from the identifier of the parent resource. If no project is provided in the parent identifier and no project is specified, the provider project is used.
"á
role" ÔThe role that should be applied. Only one
`gcp.dataproc.AutoscalingPolicyIamBinding` can be used per role. Note that custom roles must be of the format
`[projects|organizations]/{parent-name}/roles/{role-name}`.
*Ò
j
dataprocAutoscalingPolicyIamPolicyBgcp:dataproc/autoscalingPolicyIamPolicy:AutoscalingPolicyIamPolicyÓÀThree different resources help you manage your IAM policy for Dataproc AutoscalingPolicy. Each of these resources serves a different use case:

* `gcp.dataproc.AutoscalingPolicyIamPolicy`: Authoritative. Sets the IAM policy for the autoscalingpolicy and replaces any existing policy already attached.
* `gcp.dataproc.AutoscalingPolicyIamBinding`: Authoritative for a given role. Updates the IAM policy to grant a role to a list of members. Other roles within the IAM policy for the autoscalingpolicy are preserved.
* `gcp.dataproc.AutoscalingPolicyIamMember`: Non-authoritative. Updates the IAM policy to grant a role to a new member. Other members for the role for the autoscalingpolicy are preserved.

A data source can be used to retrieve policy data in advent you do not need creation

* `gcp.dataproc.AutoscalingPolicyIamPolicy`: Retrieves the IAM policy for the autoscalingpolicy

> **Note:** `gcp.dataproc.AutoscalingPolicyIamPolicy` **cannot** be used in conjunction with `gcp.dataproc.AutoscalingPolicyIamBinding` and `gcp.dataproc.AutoscalingPolicyIamMember` or they will fight over what your policy should be.

> **Note:** `gcp.dataproc.AutoscalingPolicyIamBinding` resources **can be** used in conjunction with `gcp.dataproc.AutoscalingPolicyIamMember` resources **only if** they do not grant privilege to the same role.



## gcp.dataproc.AutoscalingPolicyIamPolicy

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const admin = gcp.organizations.getIAMPolicy({
    bindings: [{
        role: "roles/viewer",
        members: ["user:jane@example.com"],
    }],
});
const policy = new gcp.dataproc.AutoscalingPolicyIamPolicy("policy", {
    project: basic.project,
    location: basic.location,
    policyId: basic.policyId,
    policyData: admin.then(admin => admin.policyData),
});
```
```python
import pulumi
import pulumi_gcp as gcp

admin = gcp.organizations.get_iam_policy(bindings=[{
    "role": "roles/viewer",
    "members": ["user:jane@example.com"],
}])
policy = gcp.dataproc.AutoscalingPolicyIamPolicy("policy",
    project=basic["project"],
    location=basic["location"],
    policy_id=basic["policyId"],
    policy_data=admin.policy_data)
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var admin = Gcp.Organizations.GetIAMPolicy.Invoke(new()
    {
        Bindings = new[]
        {
            new Gcp.Organizations.Inputs.GetIAMPolicyBindingInputArgs
            {
                Role = "roles/viewer",
                Members = new[]
                {
                    "user:jane@example.com",
                },
            },
        },
    });

    var policy = new Gcp.Dataproc.AutoscalingPolicyIamPolicy("policy", new()
    {
        Project = basic.Project,
        Location = basic.Location,
        PolicyId = basic.PolicyId,
        PolicyData = admin.Apply(getIAMPolicyResult => getIAMPolicyResult.PolicyData),
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/dataproc"
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/organizations"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		admin, err := organizations.LookupIAMPolicy(ctx, &organizations.LookupIAMPolicyArgs{
			Bindings: []organizations.GetIAMPolicyBinding{
				{
					Role: "roles/viewer",
					Members: []string{
						"user:jane@example.com",
					},
				},
			},
		}, nil)
		if err != nil {
			return err
		}
		_, err = dataproc.NewAutoscalingPolicyIamPolicy(ctx, "policy", &dataproc.AutoscalingPolicyIamPolicyArgs{
			Project:    pulumi.Any(basic.Project),
			Location:   pulumi.Any(basic.Location),
			PolicyId:   pulumi.Any(basic.PolicyId),
			PolicyData: pulumi.String(admin.PolicyData),
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.organizations.OrganizationsFunctions;
import com.pulumi.gcp.organizations.inputs.GetIAMPolicyArgs;
import com.pulumi.gcp.dataproc.AutoscalingPolicyIamPolicy;
import com.pulumi.gcp.dataproc.AutoscalingPolicyIamPolicyArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        final var admin = OrganizationsFunctions.getIAMPolicy(GetIAMPolicyArgs.builder()
            .bindings(GetIAMPolicyBindingArgs.builder()
                .role("roles/viewer")
                .members("user:jane@example.com")
                .build())
            .build());

        var policy = new AutoscalingPolicyIamPolicy("policy", AutoscalingPolicyIamPolicyArgs.builder()
            .project(basic.project())
            .location(basic.location())
            .policyId(basic.policyId())
            .policyData(admin.applyValue(getIAMPolicyResult -> getIAMPolicyResult.policyData()))
            .build());

    }
}
```
```yaml
resources:
  policy:
    type: gcp:dataproc:AutoscalingPolicyIamPolicy
    properties:
      project: ${basic.project}
      location: ${basic.location}
      policyId: ${basic.policyId}
      policyData: ${admin.policyData}
variables:
  admin:
    fn::invoke:
      function: gcp:organizations:getIAMPolicy
      arguments:
        bindings:
          - role: roles/viewer
            members:
              - user:jane@example.com
```
<!--End PulumiCodeChooser -->

## gcp.dataproc.AutoscalingPolicyIamBinding

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const binding = new gcp.dataproc.AutoscalingPolicyIamBinding("binding", {
    project: basic.project,
    location: basic.location,
    policyId: basic.policyId,
    role: "roles/viewer",
    members: ["user:jane@example.com"],
});
```
```python
import pulumi
import pulumi_gcp as gcp

binding = gcp.dataproc.AutoscalingPolicyIamBinding("binding",
    project=basic["project"],
    location=basic["location"],
    policy_id=basic["policyId"],
    role="roles/viewer",
    members=["user:jane@example.com"])
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var binding = new Gcp.Dataproc.AutoscalingPolicyIamBinding("binding", new()
    {
        Project = basic.Project,
        Location = basic.Location,
        PolicyId = basic.PolicyId,
        Role = "roles/viewer",
        Members = new[]
        {
            "user:jane@example.com",
        },
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/dataproc"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		_, err := dataproc.NewAutoscalingPolicyIamBinding(ctx, "binding", &dataproc.AutoscalingPolicyIamBindingArgs{
			Project:  pulumi.Any(basic.Project),
			Location: pulumi.Any(basic.Location),
			PolicyId: pulumi.Any(basic.PolicyId),
			Role:     pulumi.String("roles/viewer"),
			Members: pulumi.StringArray{
				pulumi.String("user:jane@example.com"),
			},
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.dataproc.AutoscalingPolicyIamBinding;
import com.pulumi.gcp.dataproc.AutoscalingPolicyIamBindingArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        var binding = new AutoscalingPolicyIamBinding("binding", AutoscalingPolicyIamBindingArgs.builder()
            .project(basic.project())
            .location(basic.location())
            .policyId(basic.policyId())
            .role("roles/viewer")
            .members("user:jane@example.com")
            .build());

    }
}
```
```yaml
resources:
  binding:
    type: gcp:dataproc:AutoscalingPolicyIamBinding
    properties:
      project: ${basic.project}
      location: ${basic.location}
      policyId: ${basic.policyId}
      role: roles/viewer
      members:
        - user:jane@example.com
```
<!--End PulumiCodeChooser -->

## gcp.dataproc.AutoscalingPolicyIamMember

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const member = new gcp.dataproc.AutoscalingPolicyIamMember("member", {
    project: basic.project,
    location: basic.location,
    policyId: basic.policyId,
    role: "roles/viewer",
    member: "user:jane@example.com",
});
```
```python
import pulumi
import pulumi_gcp as gcp

member = gcp.dataproc.AutoscalingPolicyIamMember("member",
    project=basic["project"],
    location=basic["location"],
    policy_id=basic["policyId"],
    role="roles/viewer",
    member="user:jane@example.com")
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var member = new Gcp.Dataproc.AutoscalingPolicyIamMember("member", new()
    {
        Project = basic.Project,
        Location = basic.Location,
        PolicyId = basic.PolicyId,
        Role = "roles/viewer",
        Member = "user:jane@example.com",
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/dataproc"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		_, err := dataproc.NewAutoscalingPolicyIamMember(ctx, "member", &dataproc.AutoscalingPolicyIamMemberArgs{
			Project:  pulumi.Any(basic.Project),
			Location: pulumi.Any(basic.Location),
			PolicyId: pulumi.Any(basic.PolicyId),
			Role:     pulumi.String("roles/viewer"),
			Member:   pulumi.String("user:jane@example.com"),
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.dataproc.AutoscalingPolicyIamMember;
import com.pulumi.gcp.dataproc.AutoscalingPolicyIamMemberArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        var member = new AutoscalingPolicyIamMember("member", AutoscalingPolicyIamMemberArgs.builder()
            .project(basic.project())
            .location(basic.location())
            .policyId(basic.policyId())
            .role("roles/viewer")
            .member("user:jane@example.com")
            .build());

    }
}
```
```yaml
resources:
  member:
    type: gcp:dataproc:AutoscalingPolicyIamMember
    properties:
      project: ${basic.project}
      location: ${basic.location}
      policyId: ${basic.policyId}
      role: roles/viewer
      member: user:jane@example.com
```
<!--End PulumiCodeChooser -->


## This resource supports User Project Overrides.

-

# IAM policy for Dataproc AutoscalingPolicy
Three different resources help you manage your IAM policy for Dataproc AutoscalingPolicy. Each of these resources serves a different use case:

* `gcp.dataproc.AutoscalingPolicyIamPolicy`: Authoritative. Sets the IAM policy for the autoscalingpolicy and replaces any existing policy already attached.
* `gcp.dataproc.AutoscalingPolicyIamBinding`: Authoritative for a given role. Updates the IAM policy to grant a role to a list of members. Other roles within the IAM policy for the autoscalingpolicy are preserved.
* `gcp.dataproc.AutoscalingPolicyIamMember`: Non-authoritative. Updates the IAM policy to grant a role to a new member. Other members for the role for the autoscalingpolicy are preserved.

A data source can be used to retrieve policy data in advent you do not need creation

* `gcp.dataproc.AutoscalingPolicyIamPolicy`: Retrieves the IAM policy for the autoscalingpolicy

> **Note:** `gcp.dataproc.AutoscalingPolicyIamPolicy` **cannot** be used in conjunction with `gcp.dataproc.AutoscalingPolicyIamBinding` and `gcp.dataproc.AutoscalingPolicyIamMember` or they will fight over what your policy should be.

> **Note:** `gcp.dataproc.AutoscalingPolicyIamBinding` resources **can be** used in conjunction with `gcp.dataproc.AutoscalingPolicyIamMember` resources **only if** they do not grant privilege to the same role.



## gcp.dataproc.AutoscalingPolicyIamPolicy

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const admin = gcp.organizations.getIAMPolicy({
    bindings: [{
        role: "roles/viewer",
        members: ["user:jane@example.com"],
    }],
});
const policy = new gcp.dataproc.AutoscalingPolicyIamPolicy("policy", {
    project: basic.project,
    location: basic.location,
    policyId: basic.policyId,
    policyData: admin.then(admin => admin.policyData),
});
```
```python
import pulumi
import pulumi_gcp as gcp

admin = gcp.organizations.get_iam_policy(bindings=[{
    "role": "roles/viewer",
    "members": ["user:jane@example.com"],
}])
policy = gcp.dataproc.AutoscalingPolicyIamPolicy("policy",
    project=basic["project"],
    location=basic["location"],
    policy_id=basic["policyId"],
    policy_data=admin.policy_data)
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var admin = Gcp.Organizations.GetIAMPolicy.Invoke(new()
    {
        Bindings = new[]
        {
            new Gcp.Organizations.Inputs.GetIAMPolicyBindingInputArgs
            {
                Role = "roles/viewer",
                Members = new[]
                {
                    "user:jane@example.com",
                },
            },
        },
    });

    var policy = new Gcp.Dataproc.AutoscalingPolicyIamPolicy("policy", new()
    {
        Project = basic.Project,
        Location = basic.Location,
        PolicyId = basic.PolicyId,
        PolicyData = admin.Apply(getIAMPolicyResult => getIAMPolicyResult.PolicyData),
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/dataproc"
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/organizations"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		admin, err := organizations.LookupIAMPolicy(ctx, &organizations.LookupIAMPolicyArgs{
			Bindings: []organizations.GetIAMPolicyBinding{
				{
					Role: "roles/viewer",
					Members: []string{
						"user:jane@example.com",
					},
				},
			},
		}, nil)
		if err != nil {
			return err
		}
		_, err = dataproc.NewAutoscalingPolicyIamPolicy(ctx, "policy", &dataproc.AutoscalingPolicyIamPolicyArgs{
			Project:    pulumi.Any(basic.Project),
			Location:   pulumi.Any(basic.Location),
			PolicyId:   pulumi.Any(basic.PolicyId),
			PolicyData: pulumi.String(admin.PolicyData),
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.organizations.OrganizationsFunctions;
import com.pulumi.gcp.organizations.inputs.GetIAMPolicyArgs;
import com.pulumi.gcp.dataproc.AutoscalingPolicyIamPolicy;
import com.pulumi.gcp.dataproc.AutoscalingPolicyIamPolicyArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        final var admin = OrganizationsFunctions.getIAMPolicy(GetIAMPolicyArgs.builder()
            .bindings(GetIAMPolicyBindingArgs.builder()
                .role("roles/viewer")
                .members("user:jane@example.com")
                .build())
            .build());

        var policy = new AutoscalingPolicyIamPolicy("policy", AutoscalingPolicyIamPolicyArgs.builder()
            .project(basic.project())
            .location(basic.location())
            .policyId(basic.policyId())
            .policyData(admin.applyValue(getIAMPolicyResult -> getIAMPolicyResult.policyData()))
            .build());

    }
}
```
```yaml
resources:
  policy:
    type: gcp:dataproc:AutoscalingPolicyIamPolicy
    properties:
      project: ${basic.project}
      location: ${basic.location}
      policyId: ${basic.policyId}
      policyData: ${admin.policyData}
variables:
  admin:
    fn::invoke:
      function: gcp:organizations:getIAMPolicy
      arguments:
        bindings:
          - role: roles/viewer
            members:
              - user:jane@example.com
```
<!--End PulumiCodeChooser -->

## gcp.dataproc.AutoscalingPolicyIamBinding

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const binding = new gcp.dataproc.AutoscalingPolicyIamBinding("binding", {
    project: basic.project,
    location: basic.location,
    policyId: basic.policyId,
    role: "roles/viewer",
    members: ["user:jane@example.com"],
});
```
```python
import pulumi
import pulumi_gcp as gcp

binding = gcp.dataproc.AutoscalingPolicyIamBinding("binding",
    project=basic["project"],
    location=basic["location"],
    policy_id=basic["policyId"],
    role="roles/viewer",
    members=["user:jane@example.com"])
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var binding = new Gcp.Dataproc.AutoscalingPolicyIamBinding("binding", new()
    {
        Project = basic.Project,
        Location = basic.Location,
        PolicyId = basic.PolicyId,
        Role = "roles/viewer",
        Members = new[]
        {
            "user:jane@example.com",
        },
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/dataproc"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		_, err := dataproc.NewAutoscalingPolicyIamBinding(ctx, "binding", &dataproc.AutoscalingPolicyIamBindingArgs{
			Project:  pulumi.Any(basic.Project),
			Location: pulumi.Any(basic.Location),
			PolicyId: pulumi.Any(basic.PolicyId),
			Role:     pulumi.String("roles/viewer"),
			Members: pulumi.StringArray{
				pulumi.String("user:jane@example.com"),
			},
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.dataproc.AutoscalingPolicyIamBinding;
import com.pulumi.gcp.dataproc.AutoscalingPolicyIamBindingArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        var binding = new AutoscalingPolicyIamBinding("binding", AutoscalingPolicyIamBindingArgs.builder()
            .project(basic.project())
            .location(basic.location())
            .policyId(basic.policyId())
            .role("roles/viewer")
            .members("user:jane@example.com")
            .build());

    }
}
```
```yaml
resources:
  binding:
    type: gcp:dataproc:AutoscalingPolicyIamBinding
    properties:
      project: ${basic.project}
      location: ${basic.location}
      policyId: ${basic.policyId}
      role: roles/viewer
      members:
        - user:jane@example.com
```
<!--End PulumiCodeChooser -->

## gcp.dataproc.AutoscalingPolicyIamMember

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const member = new gcp.dataproc.AutoscalingPolicyIamMember("member", {
    project: basic.project,
    location: basic.location,
    policyId: basic.policyId,
    role: "roles/viewer",
    member: "user:jane@example.com",
});
```
```python
import pulumi
import pulumi_gcp as gcp

member = gcp.dataproc.AutoscalingPolicyIamMember("member",
    project=basic["project"],
    location=basic["location"],
    policy_id=basic["policyId"],
    role="roles/viewer",
    member="user:jane@example.com")
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var member = new Gcp.Dataproc.AutoscalingPolicyIamMember("member", new()
    {
        Project = basic.Project,
        Location = basic.Location,
        PolicyId = basic.PolicyId,
        Role = "roles/viewer",
        Member = "user:jane@example.com",
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/dataproc"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		_, err := dataproc.NewAutoscalingPolicyIamMember(ctx, "member", &dataproc.AutoscalingPolicyIamMemberArgs{
			Project:  pulumi.Any(basic.Project),
			Location: pulumi.Any(basic.Location),
			PolicyId: pulumi.Any(basic.PolicyId),
			Role:     pulumi.String("roles/viewer"),
			Member:   pulumi.String("user:jane@example.com"),
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.dataproc.AutoscalingPolicyIamMember;
import com.pulumi.gcp.dataproc.AutoscalingPolicyIamMemberArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        var member = new AutoscalingPolicyIamMember("member", AutoscalingPolicyIamMemberArgs.builder()
            .project(basic.project())
            .location(basic.location())
            .policyId(basic.policyId())
            .role("roles/viewer")
            .member("user:jane@example.com")
            .build());

    }
}
```
```yaml
resources:
  member:
    type: gcp:dataproc:AutoscalingPolicyIamMember
    properties:
      project: ${basic.project}
      location: ${basic.location}
      policyId: ${basic.policyId}
      role: roles/viewer
      member: user:jane@example.com
```
<!--End PulumiCodeChooser -->

## Import

For all import syntaxes, the "resource in question" can take any of the following forms:

* projects/{{project}}/locations/{{location}}/autoscalingPolicies/{{policy_id}}

* {{project}}/{{location}}/{{policy_id}}

* {{location}}/{{policy_id}}

* {{policy_id}}

Any variables not passed in the import command will be taken from the provider configuration.

Dataproc autoscalingpolicy IAM resources can be imported using the resource identifiers, role, and member.

IAM member imports use space-delimited identifiers: the resource in question, the role, and the member identity, e.g.

```sh
$ pulumi import gcp:dataproc/autoscalingPolicyIamPolicy:AutoscalingPolicyIamPolicy editor "projects/{{project}}/locations/{{location}}/autoscalingPolicies/{{policy_id}} roles/viewer user:jane@example.com"
```

IAM binding imports use space-delimited identifiers: the resource in question and the role, e.g.

```sh
$ pulumi import gcp:dataproc/autoscalingPolicyIamPolicy:AutoscalingPolicyIamPolicy editor "projects/{{project}}/locations/{{location}}/autoscalingPolicies/{{policy_id}} roles/viewer"
```

IAM policy imports use the identifier of the resource in question, e.g.

```sh
$ pulumi import gcp:dataproc/autoscalingPolicyIamPolicy:AutoscalingPolicyIamPolicy editor projects/{{project}}/locations/{{location}}/autoscalingPolicies/{{policy_id}}
```

-> **Custom Roles** If you're importing a IAM resource with a custom role, make sure to use the

 full name of the custom role, e.g. `[projects/my-project|organizations/my-org]/roles/my-custom-role`.

þ
locationB" ëThe  location where the autoscaling policy should reside.
The default value is `global`.
Used to find the parent resource to bind the IAM policy to. If not specified,
the value will be parsed from the identifier of the parent resource. If no location is provided in the parent identifier and no
location is specified, it is taken from the provider configuration.
_

policyData" MThe policy data generated by
a `gcp.organizations.getIAMPolicy` data source.

policyId" The policy id. The id must contain only letters (a-z, A-Z), numbers (0-9), underscores (_),
and hyphens (-). Cannot begin or end with underscore or hyphen. Must consist of between
3 and 50 characters.
Used to find the parent resource to bind the IAM policy to

projectB" The ID of the project in which the resource belongs.
If it is not provided, the project will be parsed from the identifier of the parent resource. If no project is provided in the parent identifier and no project is specified, the provider project is used.
"3
etag" '(Computed) The etag of the IAM policy.
"ü
location" ëThe  location where the autoscaling policy should reside.
The default value is `global`.
Used to find the parent resource to bind the IAM policy to. If not specified,
the value will be parsed from the identifier of the parent resource. If no location is provided in the parent identifier and no
location is specified, it is taken from the provider configuration.
"_

policyData" MThe policy data generated by
a `gcp.organizations.getIAMPolicy` data source.
"
policyId" The policy id. The id must contain only letters (a-z, A-Z), numbers (0-9), underscores (_),
and hyphens (-). Cannot begin or end with underscore or hyphen. Must consist of between
3 and 50 characters.
Used to find the parent resource to bind the IAM policy to
"
project" The ID of the project in which the resource belongs.
If it is not provided, the project will be parsed from the identifier of the parent resource. If no project is provided in the parent identifier and no project is specified, the provider project is used.
*¤ª
+
dataprocBatchgcp:dataproc/batch:BatchÇDataproc Serverless Batches lets you run Spark workloads without requiring you to
provision and manage your own Dataproc cluster.


To get more information about Batch, see:

* [API documentation](https://cloud.google.com/dataproc-serverless/docs/reference/rest/v1/projects.locations.batches)
* How-to Guides
    * [Dataproc Serverless Batches Intro](https://cloud.google.com/dataproc-serverless/docs/overview)

## Example Usage

### Dataproc Batch Spark


<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const exampleBatchSpark = new gcp.dataproc.Batch("example_batch_spark", {
    batchId: "tf-test-batch_75125",
    location: "us-central1",
    labels: {
        batch_test: "terraform",
    },
    runtimeConfig: {
        properties: {
            "spark.dynamicAllocation.enabled": "false",
            "spark.executor.instances": "2",
        },
    },
    environmentConfig: {
        executionConfig: {
            subnetworkUri: "default",
            ttl: "3600s",
            networkTags: ["tag1"],
        },
    },
    sparkBatch: {
        mainClass: "org.apache.spark.examples.SparkPi",
        args: ["10"],
        jarFileUris: ["file:///usr/lib/spark/examples/jars/spark-examples.jar"],
    },
});
```
```python
import pulumi
import pulumi_gcp as gcp

example_batch_spark = gcp.dataproc.Batch("example_batch_spark",
    batch_id="tf-test-batch_75125",
    location="us-central1",
    labels={
        "batch_test": "terraform",
    },
    runtime_config={
        "properties": {
            "spark.dynamicAllocation.enabled": "false",
            "spark.executor.instances": "2",
        },
    },
    environment_config={
        "execution_config": {
            "subnetwork_uri": "default",
            "ttl": "3600s",
            "network_tags": ["tag1"],
        },
    },
    spark_batch={
        "main_class": "org.apache.spark.examples.SparkPi",
        "args": ["10"],
        "jar_file_uris": ["file:///usr/lib/spark/examples/jars/spark-examples.jar"],
    })
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var exampleBatchSpark = new Gcp.Dataproc.Batch("example_batch_spark", new()
    {
        BatchId = "tf-test-batch_75125",
        Location = "us-central1",
        Labels = 
        {
            { "batch_test", "terraform" },
        },
        RuntimeConfig = new Gcp.Dataproc.Inputs.BatchRuntimeConfigArgs
        {
            Properties = 
            {
                { "spark.dynamicAllocation.enabled", "false" },
                { "spark.executor.instances", "2" },
            },
        },
        EnvironmentConfig = new Gcp.Dataproc.Inputs.BatchEnvironmentConfigArgs
        {
            ExecutionConfig = new Gcp.Dataproc.Inputs.BatchEnvironmentConfigExecutionConfigArgs
            {
                SubnetworkUri = "default",
                Ttl = "3600s",
                NetworkTags = new[]
                {
                    "tag1",
                },
            },
        },
        SparkBatch = new Gcp.Dataproc.Inputs.BatchSparkBatchArgs
        {
            MainClass = "org.apache.spark.examples.SparkPi",
            Args = new[]
            {
                "10",
            },
            JarFileUris = new[]
            {
                "file:///usr/lib/spark/examples/jars/spark-examples.jar",
            },
        },
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/dataproc"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		_, err := dataproc.NewBatch(ctx, "example_batch_spark", &dataproc.BatchArgs{
			BatchId:  pulumi.String("tf-test-batch_75125"),
			Location: pulumi.String("us-central1"),
			Labels: pulumi.StringMap{
				"batch_test": pulumi.String("terraform"),
			},
			RuntimeConfig: &dataproc.BatchRuntimeConfigArgs{
				Properties: pulumi.StringMap{
					"spark.dynamicAllocation.enabled": pulumi.String("false"),
					"spark.executor.instances":        pulumi.String("2"),
				},
			},
			EnvironmentConfig: &dataproc.BatchEnvironmentConfigArgs{
				ExecutionConfig: &dataproc.BatchEnvironmentConfigExecutionConfigArgs{
					SubnetworkUri: pulumi.String("default"),
					Ttl:           pulumi.String("3600s"),
					NetworkTags: pulumi.StringArray{
						pulumi.String("tag1"),
					},
				},
			},
			SparkBatch: &dataproc.BatchSparkBatchArgs{
				MainClass: pulumi.String("org.apache.spark.examples.SparkPi"),
				Args: pulumi.StringArray{
					pulumi.String("10"),
				},
				JarFileUris: pulumi.StringArray{
					pulumi.String("file:///usr/lib/spark/examples/jars/spark-examples.jar"),
				},
			},
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.dataproc.Batch;
import com.pulumi.gcp.dataproc.BatchArgs;
import com.pulumi.gcp.dataproc.inputs.BatchRuntimeConfigArgs;
import com.pulumi.gcp.dataproc.inputs.BatchEnvironmentConfigArgs;
import com.pulumi.gcp.dataproc.inputs.BatchEnvironmentConfigExecutionConfigArgs;
import com.pulumi.gcp.dataproc.inputs.BatchSparkBatchArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        var exampleBatchSpark = new Batch("exampleBatchSpark", BatchArgs.builder()
            .batchId("tf-test-batch_75125")
            .location("us-central1")
            .labels(Map.of("batch_test", "terraform"))
            .runtimeConfig(BatchRuntimeConfigArgs.builder()
                .properties(Map.ofEntries(
                    Map.entry("spark.dynamicAllocation.enabled", "false"),
                    Map.entry("spark.executor.instances", "2")
                ))
                .build())
            .environmentConfig(BatchEnvironmentConfigArgs.builder()
                .executionConfig(BatchEnvironmentConfigExecutionConfigArgs.builder()
                    .subnetworkUri("default")
                    .ttl("3600s")
                    .networkTags("tag1")
                    .build())
                .build())
            .sparkBatch(BatchSparkBatchArgs.builder()
                .mainClass("org.apache.spark.examples.SparkPi")
                .args("10")
                .jarFileUris("file:///usr/lib/spark/examples/jars/spark-examples.jar")
                .build())
            .build());

    }
}
```
```yaml
resources:
  exampleBatchSpark:
    type: gcp:dataproc:Batch
    name: example_batch_spark
    properties:
      batchId: tf-test-batch_75125
      location: us-central1
      labels:
        batch_test: terraform
      runtimeConfig:
        properties:
          spark.dynamicAllocation.enabled: 'false'
          spark.executor.instances: '2'
      environmentConfig:
        executionConfig:
          subnetworkUri: default
          ttl: 3600s
          networkTags:
            - tag1
      sparkBatch:
        mainClass: org.apache.spark.examples.SparkPi
        args:
          - '10'
        jarFileUris:
          - file:///usr/lib/spark/examples/jars/spark-examples.jar
```
<!--End PulumiCodeChooser -->
### Dataproc Batch Spark Full


<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const project = gcp.organizations.getProject({});
const gcsAccount = gcp.storage.getProjectServiceAccount({});
const bucket = new gcp.storage.Bucket("bucket", {
    uniformBucketLevelAccess: true,
    name: "dataproc-bucket",
    location: "US",
    forceDestroy: true,
});
const keyRing = new gcp.kms.KeyRing("key_ring", {
    name: "example-keyring",
    location: "us-central1",
});
const cryptoKey = new gcp.kms.CryptoKey("crypto_key", {
    name: "example-key",
    keyRing: keyRing.id,
    purpose: "ENCRYPT_DECRYPT",
});
const cryptoKeyMember1 = new gcp.kms.CryptoKeyIAMMember("crypto_key_member_1", {
    cryptoKeyId: cryptoKey.id,
    role: "roles/cloudkms.cryptoKeyEncrypterDecrypter",
    member: project.then(project => `serviceAccount:service-${project.number}@dataproc-accounts.iam.gserviceaccount.com`),
});
const ms = new gcp.dataproc.MetastoreService("ms", {
    serviceId: "dataproc-batch",
    location: "us-central1",
    port: 9080,
    tier: "DEVELOPER",
    maintenanceWindow: {
        hourOfDay: 2,
        dayOfWeek: "SUNDAY",
    },
    hiveMetastoreConfig: {
        version: "3.1.2",
    },
});
const basic = new gcp.dataproc.Cluster("basic", {
    name: "dataproc-batch",
    region: "us-central1",
    clusterConfig: {
        softwareConfig: {
            overrideProperties: {
                "dataproc:dataproc.allow.zero.workers": "true",
                "spark:spark.history.fs.logDirectory": pulumi.interpolate`gs://${bucket.name}/*/spark-job-history`,
            },
        },
        endpointConfig: {
            enableHttpPortAccess: true,
        },
        masterConfig: {
            numInstances: 1,
            machineType: "e2-standard-2",
            diskConfig: {
                bootDiskSizeGb: 35,
            },
        },
        metastoreConfig: {
            dataprocMetastoreService: ms.name,
        },
    },
});
const exampleBatchSpark = new gcp.dataproc.Batch("example_batch_spark", {
    batchId: "dataproc-batch",
    location: "us-central1",
    labels: {
        batch_test: "terraform",
    },
    runtimeConfig: {
        properties: {
            "spark.dynamicAllocation.enabled": "false",
            "spark.executor.instances": "2",
        },
        version: "2.2",
    },
    environmentConfig: {
        executionConfig: {
            ttl: "3600s",
            networkTags: ["tag1"],
            kmsKey: cryptoKey.id,
            networkUri: "default",
            serviceAccount: project.then(project => `${project.number}-compute@developer.gserviceaccount.com`),
            stagingBucket: bucket.name,
        },
        peripheralsConfig: {
            metastoreService: ms.name,
            sparkHistoryServerConfig: {
                dataprocCluster: basic.id,
            },
        },
    },
    sparkBatch: {
        mainClass: "org.apache.spark.examples.SparkPi",
        args: ["10"],
        jarFileUris: ["file:///usr/lib/spark/examples/jars/spark-examples.jar"],
    },
}, {
    dependsOn: [cryptoKeyMember1],
});
```
```python
import pulumi
import pulumi_gcp as gcp

project = gcp.organizations.get_project()
gcs_account = gcp.storage.get_project_service_account()
bucket = gcp.storage.Bucket("bucket",
    uniform_bucket_level_access=True,
    name="dataproc-bucket",
    location="US",
    force_destroy=True)
key_ring = gcp.kms.KeyRing("key_ring",
    name="example-keyring",
    location="us-central1")
crypto_key = gcp.kms.CryptoKey("crypto_key",
    name="example-key",
    key_ring=key_ring.id,
    purpose="ENCRYPT_DECRYPT")
crypto_key_member1 = gcp.kms.CryptoKeyIAMMember("crypto_key_member_1",
    crypto_key_id=crypto_key.id,
    role="roles/cloudkms.cryptoKeyEncrypterDecrypter",
    member=f"serviceAccount:service-{project.number}@dataproc-accounts.iam.gserviceaccount.com")
ms = gcp.dataproc.MetastoreService("ms",
    service_id="dataproc-batch",
    location="us-central1",
    port=9080,
    tier="DEVELOPER",
    maintenance_window={
        "hour_of_day": 2,
        "day_of_week": "SUNDAY",
    },
    hive_metastore_config={
        "version": "3.1.2",
    })
basic = gcp.dataproc.Cluster("basic",
    name="dataproc-batch",
    region="us-central1",
    cluster_config={
        "software_config": {
            "override_properties": {
                "dataproc:dataproc.allow.zero.workers": "true",
                "spark:spark.history.fs.logDirectory": bucket.name.apply(lambda name: f"gs://{name}/*/spark-job-history"),
            },
        },
        "endpoint_config": {
            "enable_http_port_access": True,
        },
        "master_config": {
            "num_instances": 1,
            "machine_type": "e2-standard-2",
            "disk_config": {
                "boot_disk_size_gb": 35,
            },
        },
        "metastore_config": {
            "dataproc_metastore_service": ms.name,
        },
    })
example_batch_spark = gcp.dataproc.Batch("example_batch_spark",
    batch_id="dataproc-batch",
    location="us-central1",
    labels={
        "batch_test": "terraform",
    },
    runtime_config={
        "properties": {
            "spark.dynamicAllocation.enabled": "false",
            "spark.executor.instances": "2",
        },
        "version": "2.2",
    },
    environment_config={
        "execution_config": {
            "ttl": "3600s",
            "network_tags": ["tag1"],
            "kms_key": crypto_key.id,
            "network_uri": "default",
            "service_account": f"{project.number}-compute@developer.gserviceaccount.com",
            "staging_bucket": bucket.name,
        },
        "peripherals_config": {
            "metastore_service": ms.name,
            "spark_history_server_config": {
                "dataproc_cluster": basic.id,
            },
        },
    },
    spark_batch={
        "main_class": "org.apache.spark.examples.SparkPi",
        "args": ["10"],
        "jar_file_uris": ["file:///usr/lib/spark/examples/jars/spark-examples.jar"],
    },
    opts = pulumi.ResourceOptions(depends_on=[crypto_key_member1]))
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var project = Gcp.Organizations.GetProject.Invoke();

    var gcsAccount = Gcp.Storage.GetProjectServiceAccount.Invoke();

    var bucket = new Gcp.Storage.Bucket("bucket", new()
    {
        UniformBucketLevelAccess = true,
        Name = "dataproc-bucket",
        Location = "US",
        ForceDestroy = true,
    });

    var keyRing = new Gcp.Kms.KeyRing("key_ring", new()
    {
        Name = "example-keyring",
        Location = "us-central1",
    });

    var cryptoKey = new Gcp.Kms.CryptoKey("crypto_key", new()
    {
        Name = "example-key",
        KeyRing = keyRing.Id,
        Purpose = "ENCRYPT_DECRYPT",
    });

    var cryptoKeyMember1 = new Gcp.Kms.CryptoKeyIAMMember("crypto_key_member_1", new()
    {
        CryptoKeyId = cryptoKey.Id,
        Role = "roles/cloudkms.cryptoKeyEncrypterDecrypter",
        Member = $"serviceAccount:service-{project.Apply(getProjectResult => getProjectResult.Number)}@dataproc-accounts.iam.gserviceaccount.com",
    });

    var ms = new Gcp.Dataproc.MetastoreService("ms", new()
    {
        ServiceId = "dataproc-batch",
        Location = "us-central1",
        Port = 9080,
        Tier = "DEVELOPER",
        MaintenanceWindow = new Gcp.Dataproc.Inputs.MetastoreServiceMaintenanceWindowArgs
        {
            HourOfDay = 2,
            DayOfWeek = "SUNDAY",
        },
        HiveMetastoreConfig = new Gcp.Dataproc.Inputs.MetastoreServiceHiveMetastoreConfigArgs
        {
            Version = "3.1.2",
        },
    });

    var basic = new Gcp.Dataproc.Cluster("basic", new()
    {
        Name = "dataproc-batch",
        Region = "us-central1",
        ClusterConfig = new Gcp.Dataproc.Inputs.ClusterClusterConfigArgs
        {
            SoftwareConfig = new Gcp.Dataproc.Inputs.ClusterClusterConfigSoftwareConfigArgs
            {
                OverrideProperties = 
                {
                    { "dataproc:dataproc.allow.zero.workers", "true" },
                    { "spark:spark.history.fs.logDirectory", bucket.Name.Apply(name => $"gs://{name}/*/spark-job-history") },
                },
            },
            EndpointConfig = new Gcp.Dataproc.Inputs.ClusterClusterConfigEndpointConfigArgs
            {
                EnableHttpPortAccess = true,
            },
            MasterConfig = new Gcp.Dataproc.Inputs.ClusterClusterConfigMasterConfigArgs
            {
                NumInstances = 1,
                MachineType = "e2-standard-2",
                DiskConfig = new Gcp.Dataproc.Inputs.ClusterClusterConfigMasterConfigDiskConfigArgs
                {
                    BootDiskSizeGb = 35,
                },
            },
            MetastoreConfig = new Gcp.Dataproc.Inputs.ClusterClusterConfigMetastoreConfigArgs
            {
                DataprocMetastoreService = ms.Name,
            },
        },
    });

    var exampleBatchSpark = new Gcp.Dataproc.Batch("example_batch_spark", new()
    {
        BatchId = "dataproc-batch",
        Location = "us-central1",
        Labels = 
        {
            { "batch_test", "terraform" },
        },
        RuntimeConfig = new Gcp.Dataproc.Inputs.BatchRuntimeConfigArgs
        {
            Properties = 
            {
                { "spark.dynamicAllocation.enabled", "false" },
                { "spark.executor.instances", "2" },
            },
            Version = "2.2",
        },
        EnvironmentConfig = new Gcp.Dataproc.Inputs.BatchEnvironmentConfigArgs
        {
            ExecutionConfig = new Gcp.Dataproc.Inputs.BatchEnvironmentConfigExecutionConfigArgs
            {
                Ttl = "3600s",
                NetworkTags = new[]
                {
                    "tag1",
                },
                KmsKey = cryptoKey.Id,
                NetworkUri = "default",
                ServiceAccount = $"{project.Apply(getProjectResult => getProjectResult.Number)}-compute@developer.gserviceaccount.com",
                StagingBucket = bucket.Name,
            },
            PeripheralsConfig = new Gcp.Dataproc.Inputs.BatchEnvironmentConfigPeripheralsConfigArgs
            {
                MetastoreService = ms.Name,
                SparkHistoryServerConfig = new Gcp.Dataproc.Inputs.BatchEnvironmentConfigPeripheralsConfigSparkHistoryServerConfigArgs
                {
                    DataprocCluster = basic.Id,
                },
            },
        },
        SparkBatch = new Gcp.Dataproc.Inputs.BatchSparkBatchArgs
        {
            MainClass = "org.apache.spark.examples.SparkPi",
            Args = new[]
            {
                "10",
            },
            JarFileUris = new[]
            {
                "file:///usr/lib/spark/examples/jars/spark-examples.jar",
            },
        },
    }, new CustomResourceOptions
    {
        DependsOn =
        {
            cryptoKeyMember1,
        },
    });

});
```
```go
package main

import (
	"fmt"

	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/dataproc"
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/kms"
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/organizations"
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/storage"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		project, err := organizations.LookupProject(ctx, &organizations.LookupProjectArgs{}, nil)
		if err != nil {
			return err
		}
		_, err = storage.GetProjectServiceAccount(ctx, &storage.GetProjectServiceAccountArgs{}, nil)
		if err != nil {
			return err
		}
		bucket, err := storage.NewBucket(ctx, "bucket", &storage.BucketArgs{
			UniformBucketLevelAccess: pulumi.Bool(true),
			Name:                     pulumi.String("dataproc-bucket"),
			Location:                 pulumi.String("US"),
			ForceDestroy:             pulumi.Bool(true),
		})
		if err != nil {
			return err
		}
		keyRing, err := kms.NewKeyRing(ctx, "key_ring", &kms.KeyRingArgs{
			Name:     pulumi.String("example-keyring"),
			Location: pulumi.String("us-central1"),
		})
		if err != nil {
			return err
		}
		cryptoKey, err := kms.NewCryptoKey(ctx, "crypto_key", &kms.CryptoKeyArgs{
			Name:    pulumi.String("example-key"),
			KeyRing: keyRing.ID(),
			Purpose: pulumi.String("ENCRYPT_DECRYPT"),
		})
		if err != nil {
			return err
		}
		cryptoKeyMember1, err := kms.NewCryptoKeyIAMMember(ctx, "crypto_key_member_1", &kms.CryptoKeyIAMMemberArgs{
			CryptoKeyId: cryptoKey.ID(),
			Role:        pulumi.String("roles/cloudkms.cryptoKeyEncrypterDecrypter"),
			Member:      pulumi.Sprintf("serviceAccount:service-%v@dataproc-accounts.iam.gserviceaccount.com", project.Number),
		})
		if err != nil {
			return err
		}
		ms, err := dataproc.NewMetastoreService(ctx, "ms", &dataproc.MetastoreServiceArgs{
			ServiceId: pulumi.String("dataproc-batch"),
			Location:  pulumi.String("us-central1"),
			Port:      pulumi.Int(9080),
			Tier:      pulumi.String("DEVELOPER"),
			MaintenanceWindow: &dataproc.MetastoreServiceMaintenanceWindowArgs{
				HourOfDay: pulumi.Int(2),
				DayOfWeek: pulumi.String("SUNDAY"),
			},
			HiveMetastoreConfig: &dataproc.MetastoreServiceHiveMetastoreConfigArgs{
				Version: pulumi.String("3.1.2"),
			},
		})
		if err != nil {
			return err
		}
		basic, err := dataproc.NewCluster(ctx, "basic", &dataproc.ClusterArgs{
			Name:   pulumi.String("dataproc-batch"),
			Region: pulumi.String("us-central1"),
			ClusterConfig: &dataproc.ClusterClusterConfigArgs{
				SoftwareConfig: &dataproc.ClusterClusterConfigSoftwareConfigArgs{
					OverrideProperties: pulumi.StringMap{
						"dataproc:dataproc.allow.zero.workers": pulumi.String("true"),
						"spark:spark.history.fs.logDirectory": bucket.Name.ApplyT(func(name string) (string, error) {
							return fmt.Sprintf("gs://%v/*/spark-job-history", name), nil
						}).(pulumi.StringOutput),
					},
				},
				EndpointConfig: &dataproc.ClusterClusterConfigEndpointConfigArgs{
					EnableHttpPortAccess: pulumi.Bool(true),
				},
				MasterConfig: &dataproc.ClusterClusterConfigMasterConfigArgs{
					NumInstances: pulumi.Int(1),
					MachineType:  pulumi.String("e2-standard-2"),
					DiskConfig: &dataproc.ClusterClusterConfigMasterConfigDiskConfigArgs{
						BootDiskSizeGb: pulumi.Int(35),
					},
				},
				MetastoreConfig: &dataproc.ClusterClusterConfigMetastoreConfigArgs{
					DataprocMetastoreService: ms.Name,
				},
			},
		})
		if err != nil {
			return err
		}
		_, err = dataproc.NewBatch(ctx, "example_batch_spark", &dataproc.BatchArgs{
			BatchId:  pulumi.String("dataproc-batch"),
			Location: pulumi.String("us-central1"),
			Labels: pulumi.StringMap{
				"batch_test": pulumi.String("terraform"),
			},
			RuntimeConfig: &dataproc.BatchRuntimeConfigArgs{
				Properties: pulumi.StringMap{
					"spark.dynamicAllocation.enabled": pulumi.String("false"),
					"spark.executor.instances":        pulumi.String("2"),
				},
				Version: pulumi.String("2.2"),
			},
			EnvironmentConfig: &dataproc.BatchEnvironmentConfigArgs{
				ExecutionConfig: &dataproc.BatchEnvironmentConfigExecutionConfigArgs{
					Ttl: pulumi.String("3600s"),
					NetworkTags: pulumi.StringArray{
						pulumi.String("tag1"),
					},
					KmsKey:         cryptoKey.ID(),
					NetworkUri:     pulumi.String("default"),
					ServiceAccount: pulumi.Sprintf("%v-compute@developer.gserviceaccount.com", project.Number),
					StagingBucket:  bucket.Name,
				},
				PeripheralsConfig: &dataproc.BatchEnvironmentConfigPeripheralsConfigArgs{
					MetastoreService: ms.Name,
					SparkHistoryServerConfig: &dataproc.BatchEnvironmentConfigPeripheralsConfigSparkHistoryServerConfigArgs{
						DataprocCluster: basic.ID(),
					},
				},
			},
			SparkBatch: &dataproc.BatchSparkBatchArgs{
				MainClass: pulumi.String("org.apache.spark.examples.SparkPi"),
				Args: pulumi.StringArray{
					pulumi.String("10"),
				},
				JarFileUris: pulumi.StringArray{
					pulumi.String("file:///usr/lib/spark/examples/jars/spark-examples.jar"),
				},
			},
		}, pulumi.DependsOn([]pulumi.Resource{
			cryptoKeyMember1,
		}))
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.organizations.OrganizationsFunctions;
import com.pulumi.gcp.organizations.inputs.GetProjectArgs;
import com.pulumi.gcp.storage.StorageFunctions;
import com.pulumi.gcp.storage.inputs.GetProjectServiceAccountArgs;
import com.pulumi.gcp.storage.Bucket;
import com.pulumi.gcp.storage.BucketArgs;
import com.pulumi.gcp.kms.KeyRing;
import com.pulumi.gcp.kms.KeyRingArgs;
import com.pulumi.gcp.kms.CryptoKey;
import com.pulumi.gcp.kms.CryptoKeyArgs;
import com.pulumi.gcp.kms.CryptoKeyIAMMember;
import com.pulumi.gcp.kms.CryptoKeyIAMMemberArgs;
import com.pulumi.gcp.dataproc.MetastoreService;
import com.pulumi.gcp.dataproc.MetastoreServiceArgs;
import com.pulumi.gcp.dataproc.inputs.MetastoreServiceMaintenanceWindowArgs;
import com.pulumi.gcp.dataproc.inputs.MetastoreServiceHiveMetastoreConfigArgs;
import com.pulumi.gcp.dataproc.Cluster;
import com.pulumi.gcp.dataproc.ClusterArgs;
import com.pulumi.gcp.dataproc.inputs.ClusterClusterConfigArgs;
import com.pulumi.gcp.dataproc.inputs.ClusterClusterConfigSoftwareConfigArgs;
import com.pulumi.gcp.dataproc.inputs.ClusterClusterConfigEndpointConfigArgs;
import com.pulumi.gcp.dataproc.inputs.ClusterClusterConfigMasterConfigArgs;
import com.pulumi.gcp.dataproc.inputs.ClusterClusterConfigMasterConfigDiskConfigArgs;
import com.pulumi.gcp.dataproc.inputs.ClusterClusterConfigMetastoreConfigArgs;
import com.pulumi.gcp.dataproc.Batch;
import com.pulumi.gcp.dataproc.BatchArgs;
import com.pulumi.gcp.dataproc.inputs.BatchRuntimeConfigArgs;
import com.pulumi.gcp.dataproc.inputs.BatchEnvironmentConfigArgs;
import com.pulumi.gcp.dataproc.inputs.BatchEnvironmentConfigExecutionConfigArgs;
import com.pulumi.gcp.dataproc.inputs.BatchEnvironmentConfigPeripheralsConfigArgs;
import com.pulumi.gcp.dataproc.inputs.BatchEnvironmentConfigPeripheralsConfigSparkHistoryServerConfigArgs;
import com.pulumi.gcp.dataproc.inputs.BatchSparkBatchArgs;
import com.pulumi.resources.CustomResourceOptions;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        final var project = OrganizationsFunctions.getProject();

        final var gcsAccount = StorageFunctions.getProjectServiceAccount();

        var bucket = new Bucket("bucket", BucketArgs.builder()
            .uniformBucketLevelAccess(true)
            .name("dataproc-bucket")
            .location("US")
            .forceDestroy(true)
            .build());

        var keyRing = new KeyRing("keyRing", KeyRingArgs.builder()
            .name("example-keyring")
            .location("us-central1")
            .build());

        var cryptoKey = new CryptoKey("cryptoKey", CryptoKeyArgs.builder()
            .name("example-key")
            .keyRing(keyRing.id())
            .purpose("ENCRYPT_DECRYPT")
            .build());

        var cryptoKeyMember1 = new CryptoKeyIAMMember("cryptoKeyMember1", CryptoKeyIAMMemberArgs.builder()
            .cryptoKeyId(cryptoKey.id())
            .role("roles/cloudkms.cryptoKeyEncrypterDecrypter")
            .member(String.format("serviceAccount:service-%s@dataproc-accounts.iam.gserviceaccount.com", project.applyValue(getProjectResult -> getProjectResult.number())))
            .build());

        var ms = new MetastoreService("ms", MetastoreServiceArgs.builder()
            .serviceId("dataproc-batch")
            .location("us-central1")
            .port(9080)
            .tier("DEVELOPER")
            .maintenanceWindow(MetastoreServiceMaintenanceWindowArgs.builder()
                .hourOfDay(2)
                .dayOfWeek("SUNDAY")
                .build())
            .hiveMetastoreConfig(MetastoreServiceHiveMetastoreConfigArgs.builder()
                .version("3.1.2")
                .build())
            .build());

        var basic = new Cluster("basic", ClusterArgs.builder()
            .name("dataproc-batch")
            .region("us-central1")
            .clusterConfig(ClusterClusterConfigArgs.builder()
                .softwareConfig(ClusterClusterConfigSoftwareConfigArgs.builder()
                    .overrideProperties(Map.ofEntries(
                        Map.entry("dataproc:dataproc.allow.zero.workers", "true"),
                        Map.entry("spark:spark.history.fs.logDirectory", bucket.name().applyValue(name -> String.format("gs://%s/*/spark-job-history", name)))
                    ))
                    .build())
                .endpointConfig(ClusterClusterConfigEndpointConfigArgs.builder()
                    .enableHttpPortAccess(true)
                    .build())
                .masterConfig(ClusterClusterConfigMasterConfigArgs.builder()
                    .numInstances(1)
                    .machineType("e2-standard-2")
                    .diskConfig(ClusterClusterConfigMasterConfigDiskConfigArgs.builder()
                        .bootDiskSizeGb(35)
                        .build())
                    .build())
                .metastoreConfig(ClusterClusterConfigMetastoreConfigArgs.builder()
                    .dataprocMetastoreService(ms.name())
                    .build())
                .build())
            .build());

        var exampleBatchSpark = new Batch("exampleBatchSpark", BatchArgs.builder()
            .batchId("dataproc-batch")
            .location("us-central1")
            .labels(Map.of("batch_test", "terraform"))
            .runtimeConfig(BatchRuntimeConfigArgs.builder()
                .properties(Map.ofEntries(
                    Map.entry("spark.dynamicAllocation.enabled", "false"),
                    Map.entry("spark.executor.instances", "2")
                ))
                .version("2.2")
                .build())
            .environmentConfig(BatchEnvironmentConfigArgs.builder()
                .executionConfig(BatchEnvironmentConfigExecutionConfigArgs.builder()
                    .ttl("3600s")
                    .networkTags("tag1")
                    .kmsKey(cryptoKey.id())
                    .networkUri("default")
                    .serviceAccount(String.format("%s-compute@developer.gserviceaccount.com", project.applyValue(getProjectResult -> getProjectResult.number())))
                    .stagingBucket(bucket.name())
                    .build())
                .peripheralsConfig(BatchEnvironmentConfigPeripheralsConfigArgs.builder()
                    .metastoreService(ms.name())
                    .sparkHistoryServerConfig(BatchEnvironmentConfigPeripheralsConfigSparkHistoryServerConfigArgs.builder()
                        .dataprocCluster(basic.id())
                        .build())
                    .build())
                .build())
            .sparkBatch(BatchSparkBatchArgs.builder()
                .mainClass("org.apache.spark.examples.SparkPi")
                .args("10")
                .jarFileUris("file:///usr/lib/spark/examples/jars/spark-examples.jar")
                .build())
            .build(), CustomResourceOptions.builder()
                .dependsOn(cryptoKeyMember1)
                .build());

    }
}
```
```yaml
resources:
  exampleBatchSpark:
    type: gcp:dataproc:Batch
    name: example_batch_spark
    properties:
      batchId: dataproc-batch
      location: us-central1
      labels:
        batch_test: terraform
      runtimeConfig:
        properties:
          spark.dynamicAllocation.enabled: 'false'
          spark.executor.instances: '2'
        version: '2.2'
      environmentConfig:
        executionConfig:
          ttl: 3600s
          networkTags:
            - tag1
          kmsKey: ${cryptoKey.id}
          networkUri: default
          serviceAccount: ${project.number}-compute@developer.gserviceaccount.com
          stagingBucket: ${bucket.name}
        peripheralsConfig:
          metastoreService: ${ms.name}
          sparkHistoryServerConfig:
            dataprocCluster: ${basic.id}
      sparkBatch:
        mainClass: org.apache.spark.examples.SparkPi
        args:
          - '10'
        jarFileUris:
          - file:///usr/lib/spark/examples/jars/spark-examples.jar
    options:
      dependsOn:
        - ${cryptoKeyMember1}
  bucket:
    type: gcp:storage:Bucket
    properties:
      uniformBucketLevelAccess: true
      name: dataproc-bucket
      location: US
      forceDestroy: true
  cryptoKey:
    type: gcp:kms:CryptoKey
    name: crypto_key
    properties:
      name: example-key
      keyRing: ${keyRing.id}
      purpose: ENCRYPT_DECRYPT
  keyRing:
    type: gcp:kms:KeyRing
    name: key_ring
    properties:
      name: example-keyring
      location: us-central1
  cryptoKeyMember1:
    type: gcp:kms:CryptoKeyIAMMember
    name: crypto_key_member_1
    properties:
      cryptoKeyId: ${cryptoKey.id}
      role: roles/cloudkms.cryptoKeyEncrypterDecrypter
      member: serviceAccount:service-${project.number}@dataproc-accounts.iam.gserviceaccount.com
  basic:
    type: gcp:dataproc:Cluster
    properties:
      name: dataproc-batch
      region: us-central1
      clusterConfig:
        softwareConfig:
          overrideProperties:
            dataproc:dataproc.allow.zero.workers: 'true'
            spark:spark.history.fs.logDirectory: gs://${bucket.name}/*/spark-job-history
        endpointConfig:
          enableHttpPortAccess: true
        masterConfig:
          numInstances: 1
          machineType: e2-standard-2
          diskConfig:
            bootDiskSizeGb: 35
        metastoreConfig:
          dataprocMetastoreService: ${ms.name}
  ms:
    type: gcp:dataproc:MetastoreService
    properties:
      serviceId: dataproc-batch
      location: us-central1
      port: 9080
      tier: DEVELOPER
      maintenanceWindow:
        hourOfDay: 2
        dayOfWeek: SUNDAY
      hiveMetastoreConfig:
        version: 3.1.2
variables:
  project:
    fn::invoke:
      function: gcp:organizations:getProject
      arguments: {}
  gcsAccount:
    fn::invoke:
      function: gcp:storage:getProjectServiceAccount
      arguments: {}
```
<!--End PulumiCodeChooser -->
### Dataproc Batch Sparksql


<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const exampleBatchSparsql = new gcp.dataproc.Batch("example_batch_sparsql", {
    batchId: "tf-test-batch_88722",
    location: "us-central1",
    runtimeConfig: {
        properties: {
            "spark.dynamicAllocation.enabled": "false",
            "spark.executor.instances": "2",
        },
    },
    environmentConfig: {
        executionConfig: {
            subnetworkUri: "default",
        },
    },
    sparkSqlBatch: {
        queryFileUri: "gs://dataproc-examples/spark-sql/natality/cigarette_correlations.sql",
        jarFileUris: ["file:///usr/lib/spark/examples/jars/spark-examples.jar"],
        queryVariables: {
            name: "value",
        },
    },
});
```
```python
import pulumi
import pulumi_gcp as gcp

example_batch_sparsql = gcp.dataproc.Batch("example_batch_sparsql",
    batch_id="tf-test-batch_88722",
    location="us-central1",
    runtime_config={
        "properties": {
            "spark.dynamicAllocation.enabled": "false",
            "spark.executor.instances": "2",
        },
    },
    environment_config={
        "execution_config": {
            "subnetwork_uri": "default",
        },
    },
    spark_sql_batch={
        "query_file_uri": "gs://dataproc-examples/spark-sql/natality/cigarette_correlations.sql",
        "jar_file_uris": ["file:///usr/lib/spark/examples/jars/spark-examples.jar"],
        "query_variables": {
            "name": "value",
        },
    })
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var exampleBatchSparsql = new Gcp.Dataproc.Batch("example_batch_sparsql", new()
    {
        BatchId = "tf-test-batch_88722",
        Location = "us-central1",
        RuntimeConfig = new Gcp.Dataproc.Inputs.BatchRuntimeConfigArgs
        {
            Properties = 
            {
                { "spark.dynamicAllocation.enabled", "false" },
                { "spark.executor.instances", "2" },
            },
        },
        EnvironmentConfig = new Gcp.Dataproc.Inputs.BatchEnvironmentConfigArgs
        {
            ExecutionConfig = new Gcp.Dataproc.Inputs.BatchEnvironmentConfigExecutionConfigArgs
            {
                SubnetworkUri = "default",
            },
        },
        SparkSqlBatch = new Gcp.Dataproc.Inputs.BatchSparkSqlBatchArgs
        {
            QueryFileUri = "gs://dataproc-examples/spark-sql/natality/cigarette_correlations.sql",
            JarFileUris = new[]
            {
                "file:///usr/lib/spark/examples/jars/spark-examples.jar",
            },
            QueryVariables = 
            {
                { "name", "value" },
            },
        },
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/dataproc"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		_, err := dataproc.NewBatch(ctx, "example_batch_sparsql", &dataproc.BatchArgs{
			BatchId:  pulumi.String("tf-test-batch_88722"),
			Location: pulumi.String("us-central1"),
			RuntimeConfig: &dataproc.BatchRuntimeConfigArgs{
				Properties: pulumi.StringMap{
					"spark.dynamicAllocation.enabled": pulumi.String("false"),
					"spark.executor.instances":        pulumi.String("2"),
				},
			},
			EnvironmentConfig: &dataproc.BatchEnvironmentConfigArgs{
				ExecutionConfig: &dataproc.BatchEnvironmentConfigExecutionConfigArgs{
					SubnetworkUri: pulumi.String("default"),
				},
			},
			SparkSqlBatch: &dataproc.BatchSparkSqlBatchArgs{
				QueryFileUri: pulumi.String("gs://dataproc-examples/spark-sql/natality/cigarette_correlations.sql"),
				JarFileUris: pulumi.StringArray{
					pulumi.String("file:///usr/lib/spark/examples/jars/spark-examples.jar"),
				},
				QueryVariables: pulumi.StringMap{
					"name": pulumi.String("value"),
				},
			},
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.dataproc.Batch;
import com.pulumi.gcp.dataproc.BatchArgs;
import com.pulumi.gcp.dataproc.inputs.BatchRuntimeConfigArgs;
import com.pulumi.gcp.dataproc.inputs.BatchEnvironmentConfigArgs;
import com.pulumi.gcp.dataproc.inputs.BatchEnvironmentConfigExecutionConfigArgs;
import com.pulumi.gcp.dataproc.inputs.BatchSparkSqlBatchArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        var exampleBatchSparsql = new Batch("exampleBatchSparsql", BatchArgs.builder()
            .batchId("tf-test-batch_88722")
            .location("us-central1")
            .runtimeConfig(BatchRuntimeConfigArgs.builder()
                .properties(Map.ofEntries(
                    Map.entry("spark.dynamicAllocation.enabled", "false"),
                    Map.entry("spark.executor.instances", "2")
                ))
                .build())
            .environmentConfig(BatchEnvironmentConfigArgs.builder()
                .executionConfig(BatchEnvironmentConfigExecutionConfigArgs.builder()
                    .subnetworkUri("default")
                    .build())
                .build())
            .sparkSqlBatch(BatchSparkSqlBatchArgs.builder()
                .queryFileUri("gs://dataproc-examples/spark-sql/natality/cigarette_correlations.sql")
                .jarFileUris("file:///usr/lib/spark/examples/jars/spark-examples.jar")
                .queryVariables(Map.of("name", "value"))
                .build())
            .build());

    }
}
```
```yaml
resources:
  exampleBatchSparsql:
    type: gcp:dataproc:Batch
    name: example_batch_sparsql
    properties:
      batchId: tf-test-batch_88722
      location: us-central1
      runtimeConfig:
        properties:
          spark.dynamicAllocation.enabled: 'false'
          spark.executor.instances: '2'
      environmentConfig:
        executionConfig:
          subnetworkUri: default
      sparkSqlBatch:
        queryFileUri: gs://dataproc-examples/spark-sql/natality/cigarette_correlations.sql
        jarFileUris:
          - file:///usr/lib/spark/examples/jars/spark-examples.jar
        queryVariables:
          name: value
```
<!--End PulumiCodeChooser -->
### Dataproc Batch Pyspark


<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const exampleBatchPyspark = new gcp.dataproc.Batch("example_batch_pyspark", {
    batchId: "tf-test-batch_39249",
    location: "us-central1",
    runtimeConfig: {
        properties: {
            "spark.dynamicAllocation.enabled": "false",
            "spark.executor.instances": "2",
        },
    },
    environmentConfig: {
        executionConfig: {
            subnetworkUri: "default",
        },
    },
    pysparkBatch: {
        mainPythonFileUri: "https://storage.googleapis.com/terraform-batches/test_util.py",
        args: ["10"],
        jarFileUris: ["file:///usr/lib/spark/examples/jars/spark-examples.jar"],
        pythonFileUris: ["gs://dataproc-examples/pyspark/hello-world/hello-world.py"],
        archiveUris: [
            "https://storage.googleapis.com/terraform-batches/animals.txt.tar.gz#unpacked",
            "https://storage.googleapis.com/terraform-batches/animals.txt.jar",
            "https://storage.googleapis.com/terraform-batches/animals.txt",
        ],
        fileUris: ["https://storage.googleapis.com/terraform-batches/people.txt"],
    },
});
```
```python
import pulumi
import pulumi_gcp as gcp

example_batch_pyspark = gcp.dataproc.Batch("example_batch_pyspark",
    batch_id="tf-test-batch_39249",
    location="us-central1",
    runtime_config={
        "properties": {
            "spark.dynamicAllocation.enabled": "false",
            "spark.executor.instances": "2",
        },
    },
    environment_config={
        "execution_config": {
            "subnetwork_uri": "default",
        },
    },
    pyspark_batch={
        "main_python_file_uri": "https://storage.googleapis.com/terraform-batches/test_util.py",
        "args": ["10"],
        "jar_file_uris": ["file:///usr/lib/spark/examples/jars/spark-examples.jar"],
        "python_file_uris": ["gs://dataproc-examples/pyspark/hello-world/hello-world.py"],
        "archive_uris": [
            "https://storage.googleapis.com/terraform-batches/animals.txt.tar.gz#unpacked",
            "https://storage.googleapis.com/terraform-batches/animals.txt.jar",
            "https://storage.googleapis.com/terraform-batches/animals.txt",
        ],
        "file_uris": ["https://storage.googleapis.com/terraform-batches/people.txt"],
    })
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var exampleBatchPyspark = new Gcp.Dataproc.Batch("example_batch_pyspark", new()
    {
        BatchId = "tf-test-batch_39249",
        Location = "us-central1",
        RuntimeConfig = new Gcp.Dataproc.Inputs.BatchRuntimeConfigArgs
        {
            Properties = 
            {
                { "spark.dynamicAllocation.enabled", "false" },
                { "spark.executor.instances", "2" },
            },
        },
        EnvironmentConfig = new Gcp.Dataproc.Inputs.BatchEnvironmentConfigArgs
        {
            ExecutionConfig = new Gcp.Dataproc.Inputs.BatchEnvironmentConfigExecutionConfigArgs
            {
                SubnetworkUri = "default",
            },
        },
        PysparkBatch = new Gcp.Dataproc.Inputs.BatchPysparkBatchArgs
        {
            MainPythonFileUri = "https://storage.googleapis.com/terraform-batches/test_util.py",
            Args = new[]
            {
                "10",
            },
            JarFileUris = new[]
            {
                "file:///usr/lib/spark/examples/jars/spark-examples.jar",
            },
            PythonFileUris = new[]
            {
                "gs://dataproc-examples/pyspark/hello-world/hello-world.py",
            },
            ArchiveUris = new[]
            {
                "https://storage.googleapis.com/terraform-batches/animals.txt.tar.gz#unpacked",
                "https://storage.googleapis.com/terraform-batches/animals.txt.jar",
                "https://storage.googleapis.com/terraform-batches/animals.txt",
            },
            FileUris = new[]
            {
                "https://storage.googleapis.com/terraform-batches/people.txt",
            },
        },
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/dataproc"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		_, err := dataproc.NewBatch(ctx, "example_batch_pyspark", &dataproc.BatchArgs{
			BatchId:  pulumi.String("tf-test-batch_39249"),
			Location: pulumi.String("us-central1"),
			RuntimeConfig: &dataproc.BatchRuntimeConfigArgs{
				Properties: pulumi.StringMap{
					"spark.dynamicAllocation.enabled": pulumi.String("false"),
					"spark.executor.instances":        pulumi.String("2"),
				},
			},
			EnvironmentConfig: &dataproc.BatchEnvironmentConfigArgs{
				ExecutionConfig: &dataproc.BatchEnvironmentConfigExecutionConfigArgs{
					SubnetworkUri: pulumi.String("default"),
				},
			},
			PysparkBatch: &dataproc.BatchPysparkBatchArgs{
				MainPythonFileUri: pulumi.String("https://storage.googleapis.com/terraform-batches/test_util.py"),
				Args: pulumi.StringArray{
					pulumi.String("10"),
				},
				JarFileUris: pulumi.StringArray{
					pulumi.String("file:///usr/lib/spark/examples/jars/spark-examples.jar"),
				},
				PythonFileUris: pulumi.StringArray{
					pulumi.String("gs://dataproc-examples/pyspark/hello-world/hello-world.py"),
				},
				ArchiveUris: pulumi.StringArray{
					pulumi.String("https://storage.googleapis.com/terraform-batches/animals.txt.tar.gz#unpacked"),
					pulumi.String("https://storage.googleapis.com/terraform-batches/animals.txt.jar"),
					pulumi.String("https://storage.googleapis.com/terraform-batches/animals.txt"),
				},
				FileUris: pulumi.StringArray{
					pulumi.String("https://storage.googleapis.com/terraform-batches/people.txt"),
				},
			},
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.dataproc.Batch;
import com.pulumi.gcp.dataproc.BatchArgs;
import com.pulumi.gcp.dataproc.inputs.BatchRuntimeConfigArgs;
import com.pulumi.gcp.dataproc.inputs.BatchEnvironmentConfigArgs;
import com.pulumi.gcp.dataproc.inputs.BatchEnvironmentConfigExecutionConfigArgs;
import com.pulumi.gcp.dataproc.inputs.BatchPysparkBatchArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        var exampleBatchPyspark = new Batch("exampleBatchPyspark", BatchArgs.builder()
            .batchId("tf-test-batch_39249")
            .location("us-central1")
            .runtimeConfig(BatchRuntimeConfigArgs.builder()
                .properties(Map.ofEntries(
                    Map.entry("spark.dynamicAllocation.enabled", "false"),
                    Map.entry("spark.executor.instances", "2")
                ))
                .build())
            .environmentConfig(BatchEnvironmentConfigArgs.builder()
                .executionConfig(BatchEnvironmentConfigExecutionConfigArgs.builder()
                    .subnetworkUri("default")
                    .build())
                .build())
            .pysparkBatch(BatchPysparkBatchArgs.builder()
                .mainPythonFileUri("https://storage.googleapis.com/terraform-batches/test_util.py")
                .args("10")
                .jarFileUris("file:///usr/lib/spark/examples/jars/spark-examples.jar")
                .pythonFileUris("gs://dataproc-examples/pyspark/hello-world/hello-world.py")
                .archiveUris(                
                    "https://storage.googleapis.com/terraform-batches/animals.txt.tar.gz#unpacked",
                    "https://storage.googleapis.com/terraform-batches/animals.txt.jar",
                    "https://storage.googleapis.com/terraform-batches/animals.txt")
                .fileUris("https://storage.googleapis.com/terraform-batches/people.txt")
                .build())
            .build());

    }
}
```
```yaml
resources:
  exampleBatchPyspark:
    type: gcp:dataproc:Batch
    name: example_batch_pyspark
    properties:
      batchId: tf-test-batch_39249
      location: us-central1
      runtimeConfig:
        properties:
          spark.dynamicAllocation.enabled: 'false'
          spark.executor.instances: '2'
      environmentConfig:
        executionConfig:
          subnetworkUri: default
      pysparkBatch:
        mainPythonFileUri: https://storage.googleapis.com/terraform-batches/test_util.py
        args:
          - '10'
        jarFileUris:
          - file:///usr/lib/spark/examples/jars/spark-examples.jar
        pythonFileUris:
          - gs://dataproc-examples/pyspark/hello-world/hello-world.py
        archiveUris:
          - https://storage.googleapis.com/terraform-batches/animals.txt.tar.gz#unpacked
          - https://storage.googleapis.com/terraform-batches/animals.txt.jar
          - https://storage.googleapis.com/terraform-batches/animals.txt
        fileUris:
          - https://storage.googleapis.com/terraform-batches/people.txt
```
<!--End PulumiCodeChooser -->
### Dataproc Batch Sparkr


<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const exampleBatchSparkr = new gcp.dataproc.Batch("example_batch_sparkr", {
    batchId: "tf-test-batch_74391",
    location: "us-central1",
    labels: {
        batch_test: "terraform",
    },
    runtimeConfig: {
        properties: {
            "spark.dynamicAllocation.enabled": "false",
            "spark.executor.instances": "2",
        },
    },
    environmentConfig: {
        executionConfig: {
            subnetworkUri: "default",
            ttl: "3600s",
            networkTags: ["tag1"],
        },
    },
    sparkRBatch: {
        mainRFileUri: "https://storage.googleapis.com/terraform-batches/spark-r-flights.r",
        args: ["https://storage.googleapis.com/terraform-batches/flights.csv"],
    },
});
```
```python
import pulumi
import pulumi_gcp as gcp

example_batch_sparkr = gcp.dataproc.Batch("example_batch_sparkr",
    batch_id="tf-test-batch_74391",
    location="us-central1",
    labels={
        "batch_test": "terraform",
    },
    runtime_config={
        "properties": {
            "spark.dynamicAllocation.enabled": "false",
            "spark.executor.instances": "2",
        },
    },
    environment_config={
        "execution_config": {
            "subnetwork_uri": "default",
            "ttl": "3600s",
            "network_tags": ["tag1"],
        },
    },
    spark_r_batch={
        "main_r_file_uri": "https://storage.googleapis.com/terraform-batches/spark-r-flights.r",
        "args": ["https://storage.googleapis.com/terraform-batches/flights.csv"],
    })
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var exampleBatchSparkr = new Gcp.Dataproc.Batch("example_batch_sparkr", new()
    {
        BatchId = "tf-test-batch_74391",
        Location = "us-central1",
        Labels = 
        {
            { "batch_test", "terraform" },
        },
        RuntimeConfig = new Gcp.Dataproc.Inputs.BatchRuntimeConfigArgs
        {
            Properties = 
            {
                { "spark.dynamicAllocation.enabled", "false" },
                { "spark.executor.instances", "2" },
            },
        },
        EnvironmentConfig = new Gcp.Dataproc.Inputs.BatchEnvironmentConfigArgs
        {
            ExecutionConfig = new Gcp.Dataproc.Inputs.BatchEnvironmentConfigExecutionConfigArgs
            {
                SubnetworkUri = "default",
                Ttl = "3600s",
                NetworkTags = new[]
                {
                    "tag1",
                },
            },
        },
        SparkRBatch = new Gcp.Dataproc.Inputs.BatchSparkRBatchArgs
        {
            MainRFileUri = "https://storage.googleapis.com/terraform-batches/spark-r-flights.r",
            Args = new[]
            {
                "https://storage.googleapis.com/terraform-batches/flights.csv",
            },
        },
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/dataproc"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		_, err := dataproc.NewBatch(ctx, "example_batch_sparkr", &dataproc.BatchArgs{
			BatchId:  pulumi.String("tf-test-batch_74391"),
			Location: pulumi.String("us-central1"),
			Labels: pulumi.StringMap{
				"batch_test": pulumi.String("terraform"),
			},
			RuntimeConfig: &dataproc.BatchRuntimeConfigArgs{
				Properties: pulumi.StringMap{
					"spark.dynamicAllocation.enabled": pulumi.String("false"),
					"spark.executor.instances":        pulumi.String("2"),
				},
			},
			EnvironmentConfig: &dataproc.BatchEnvironmentConfigArgs{
				ExecutionConfig: &dataproc.BatchEnvironmentConfigExecutionConfigArgs{
					SubnetworkUri: pulumi.String("default"),
					Ttl:           pulumi.String("3600s"),
					NetworkTags: pulumi.StringArray{
						pulumi.String("tag1"),
					},
				},
			},
			SparkRBatch: &dataproc.BatchSparkRBatchArgs{
				MainRFileUri: pulumi.String("https://storage.googleapis.com/terraform-batches/spark-r-flights.r"),
				Args: pulumi.StringArray{
					pulumi.String("https://storage.googleapis.com/terraform-batches/flights.csv"),
				},
			},
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.dataproc.Batch;
import com.pulumi.gcp.dataproc.BatchArgs;
import com.pulumi.gcp.dataproc.inputs.BatchRuntimeConfigArgs;
import com.pulumi.gcp.dataproc.inputs.BatchEnvironmentConfigArgs;
import com.pulumi.gcp.dataproc.inputs.BatchEnvironmentConfigExecutionConfigArgs;
import com.pulumi.gcp.dataproc.inputs.BatchSparkRBatchArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        var exampleBatchSparkr = new Batch("exampleBatchSparkr", BatchArgs.builder()
            .batchId("tf-test-batch_74391")
            .location("us-central1")
            .labels(Map.of("batch_test", "terraform"))
            .runtimeConfig(BatchRuntimeConfigArgs.builder()
                .properties(Map.ofEntries(
                    Map.entry("spark.dynamicAllocation.enabled", "false"),
                    Map.entry("spark.executor.instances", "2")
                ))
                .build())
            .environmentConfig(BatchEnvironmentConfigArgs.builder()
                .executionConfig(BatchEnvironmentConfigExecutionConfigArgs.builder()
                    .subnetworkUri("default")
                    .ttl("3600s")
                    .networkTags("tag1")
                    .build())
                .build())
            .sparkRBatch(BatchSparkRBatchArgs.builder()
                .mainRFileUri("https://storage.googleapis.com/terraform-batches/spark-r-flights.r")
                .args("https://storage.googleapis.com/terraform-batches/flights.csv")
                .build())
            .build());

    }
}
```
```yaml
resources:
  exampleBatchSparkr:
    type: gcp:dataproc:Batch
    name: example_batch_sparkr
    properties:
      batchId: tf-test-batch_74391
      location: us-central1
      labels:
        batch_test: terraform
      runtimeConfig:
        properties:
          spark.dynamicAllocation.enabled: 'false'
          spark.executor.instances: '2'
      environmentConfig:
        executionConfig:
          subnetworkUri: default
          ttl: 3600s
          networkTags:
            - tag1
      sparkRBatch:
        mainRFileUri: https://storage.googleapis.com/terraform-batches/spark-r-flights.r
        args:
          - https://storage.googleapis.com/terraform-batches/flights.csv
```
<!--End PulumiCodeChooser -->
### Dataproc Batch Autotuning


<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const exampleBatchAutotuning = new gcp.dataproc.Batch("example_batch_autotuning", {
    batchId: "tf-test-batch_16511",
    location: "us-central1",
    labels: {
        batch_test: "terraform",
    },
    runtimeConfig: {
        version: "2.2",
        properties: {
            "spark.dynamicAllocation.enabled": "false",
            "spark.executor.instances": "2",
        },
        cohort: "tf-dataproc-batch-example",
        autotuningConfig: {
            scenarios: [
                "SCALING",
                "MEMORY",
            ],
        },
    },
    environmentConfig: {
        executionConfig: {
            subnetworkUri: "default",
            ttl: "3600s",
        },
    },
    sparkBatch: {
        mainClass: "org.apache.spark.examples.SparkPi",
        args: ["10"],
        jarFileUris: ["file:///usr/lib/spark/examples/jars/spark-examples.jar"],
    },
});
```
```python
import pulumi
import pulumi_gcp as gcp

example_batch_autotuning = gcp.dataproc.Batch("example_batch_autotuning",
    batch_id="tf-test-batch_16511",
    location="us-central1",
    labels={
        "batch_test": "terraform",
    },
    runtime_config={
        "version": "2.2",
        "properties": {
            "spark.dynamicAllocation.enabled": "false",
            "spark.executor.instances": "2",
        },
        "cohort": "tf-dataproc-batch-example",
        "autotuning_config": {
            "scenarios": [
                "SCALING",
                "MEMORY",
            ],
        },
    },
    environment_config={
        "execution_config": {
            "subnetwork_uri": "default",
            "ttl": "3600s",
        },
    },
    spark_batch={
        "main_class": "org.apache.spark.examples.SparkPi",
        "args": ["10"],
        "jar_file_uris": ["file:///usr/lib/spark/examples/jars/spark-examples.jar"],
    })
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var exampleBatchAutotuning = new Gcp.Dataproc.Batch("example_batch_autotuning", new()
    {
        BatchId = "tf-test-batch_16511",
        Location = "us-central1",
        Labels = 
        {
            { "batch_test", "terraform" },
        },
        RuntimeConfig = new Gcp.Dataproc.Inputs.BatchRuntimeConfigArgs
        {
            Version = "2.2",
            Properties = 
            {
                { "spark.dynamicAllocation.enabled", "false" },
                { "spark.executor.instances", "2" },
            },
            Cohort = "tf-dataproc-batch-example",
            AutotuningConfig = new Gcp.Dataproc.Inputs.BatchRuntimeConfigAutotuningConfigArgs
            {
                Scenarios = new[]
                {
                    "SCALING",
                    "MEMORY",
                },
            },
        },
        EnvironmentConfig = new Gcp.Dataproc.Inputs.BatchEnvironmentConfigArgs
        {
            ExecutionConfig = new Gcp.Dataproc.Inputs.BatchEnvironmentConfigExecutionConfigArgs
            {
                SubnetworkUri = "default",
                Ttl = "3600s",
            },
        },
        SparkBatch = new Gcp.Dataproc.Inputs.BatchSparkBatchArgs
        {
            MainClass = "org.apache.spark.examples.SparkPi",
            Args = new[]
            {
                "10",
            },
            JarFileUris = new[]
            {
                "file:///usr/lib/spark/examples/jars/spark-examples.jar",
            },
        },
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/dataproc"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		_, err := dataproc.NewBatch(ctx, "example_batch_autotuning", &dataproc.BatchArgs{
			BatchId:  pulumi.String("tf-test-batch_16511"),
			Location: pulumi.String("us-central1"),
			Labels: pulumi.StringMap{
				"batch_test": pulumi.String("terraform"),
			},
			RuntimeConfig: &dataproc.BatchRuntimeConfigArgs{
				Version: pulumi.String("2.2"),
				Properties: pulumi.StringMap{
					"spark.dynamicAllocation.enabled": pulumi.String("false"),
					"spark.executor.instances":        pulumi.String("2"),
				},
				Cohort: pulumi.String("tf-dataproc-batch-example"),
				AutotuningConfig: &dataproc.BatchRuntimeConfigAutotuningConfigArgs{
					Scenarios: pulumi.StringArray{
						pulumi.String("SCALING"),
						pulumi.String("MEMORY"),
					},
				},
			},
			EnvironmentConfig: &dataproc.BatchEnvironmentConfigArgs{
				ExecutionConfig: &dataproc.BatchEnvironmentConfigExecutionConfigArgs{
					SubnetworkUri: pulumi.String("default"),
					Ttl:           pulumi.String("3600s"),
				},
			},
			SparkBatch: &dataproc.BatchSparkBatchArgs{
				MainClass: pulumi.String("org.apache.spark.examples.SparkPi"),
				Args: pulumi.StringArray{
					pulumi.String("10"),
				},
				JarFileUris: pulumi.StringArray{
					pulumi.String("file:///usr/lib/spark/examples/jars/spark-examples.jar"),
				},
			},
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.dataproc.Batch;
import com.pulumi.gcp.dataproc.BatchArgs;
import com.pulumi.gcp.dataproc.inputs.BatchRuntimeConfigArgs;
import com.pulumi.gcp.dataproc.inputs.BatchRuntimeConfigAutotuningConfigArgs;
import com.pulumi.gcp.dataproc.inputs.BatchEnvironmentConfigArgs;
import com.pulumi.gcp.dataproc.inputs.BatchEnvironmentConfigExecutionConfigArgs;
import com.pulumi.gcp.dataproc.inputs.BatchSparkBatchArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        var exampleBatchAutotuning = new Batch("exampleBatchAutotuning", BatchArgs.builder()
            .batchId("tf-test-batch_16511")
            .location("us-central1")
            .labels(Map.of("batch_test", "terraform"))
            .runtimeConfig(BatchRuntimeConfigArgs.builder()
                .version("2.2")
                .properties(Map.ofEntries(
                    Map.entry("spark.dynamicAllocation.enabled", "false"),
                    Map.entry("spark.executor.instances", "2")
                ))
                .cohort("tf-dataproc-batch-example")
                .autotuningConfig(BatchRuntimeConfigAutotuningConfigArgs.builder()
                    .scenarios(                    
                        "SCALING",
                        "MEMORY")
                    .build())
                .build())
            .environmentConfig(BatchEnvironmentConfigArgs.builder()
                .executionConfig(BatchEnvironmentConfigExecutionConfigArgs.builder()
                    .subnetworkUri("default")
                    .ttl("3600s")
                    .build())
                .build())
            .sparkBatch(BatchSparkBatchArgs.builder()
                .mainClass("org.apache.spark.examples.SparkPi")
                .args("10")
                .jarFileUris("file:///usr/lib/spark/examples/jars/spark-examples.jar")
                .build())
            .build());

    }
}
```
```yaml
resources:
  exampleBatchAutotuning:
    type: gcp:dataproc:Batch
    name: example_batch_autotuning
    properties:
      batchId: tf-test-batch_16511
      location: us-central1
      labels:
        batch_test: terraform
      runtimeConfig:
        version: '2.2'
        properties:
          spark.dynamicAllocation.enabled: 'false'
          spark.executor.instances: '2'
        cohort: tf-dataproc-batch-example
        autotuningConfig:
          scenarios:
            - SCALING
            - MEMORY
      environmentConfig:
        executionConfig:
          subnetworkUri: default
          ttl: 3600s
      sparkBatch:
        mainClass: org.apache.spark.examples.SparkPi
        args:
          - '10'
        jarFileUris:
          - file:///usr/lib/spark/examples/jars/spark-examples.jar
```
<!--End PulumiCodeChooser -->

## Import

Batch can be imported using any of these accepted formats:

* `projects/{{project}}/locations/{{location}}/batches/{{batch_id}}`

* `{{project}}/{{location}}/{{batch_id}}`

* `{{location}}/{{batch_id}}`

When using the `pulumi import` command, Batch can be imported using one of the formats above. For example:

```sh
$ pulumi import gcp:dataproc/batch:Batch default projects/{{project}}/locations/{{location}}/batches/{{batch_id}}
```

```sh
$ pulumi import gcp:dataproc/batch:Batch default {{project}}/{{location}}/{{batch_id}}
```

```sh
$ pulumi import gcp:dataproc/batch:Batch default {{location}}/{{batch_id}}
```

»
batchIdB" ©The ID to use for the batch, which will become the final component of the batch's resource name.
This value must be 4-63 characters. Valid characters are /[a-z][0-9]-/.
Í
environmentConfigdBb:`
^
dataprocBatchEnvironmentConfig:gcp:dataproc/BatchEnvironmentConfig:BatchEnvironmentConfigREnvironment configuration for the batch execution.
Structure is documented below.

labelsB2" ðThe labels to associate with this batch.

**Note**: This field is non-authoritative, and will only manage the labels present in your configuration.
Please refer to the field `effective_labels` for all of the labels present on the resource.
F
locationB" 4The location in which the batch will be created in.
{
projectB" jThe ID of the project in which the resource belongs.
If it is not provided, the provider project is used.

pysparkBatchUBS:Q
O
dataprocBatchPysparkBatch0gcp:dataproc/BatchPysparkBatch:BatchPysparkBatch5PySpark batch config.
Structure is documented below.
¹
runtimeConfigXBV:T
R
dataprocBatchRuntimeConfig2gcp:dataproc/BatchRuntimeConfig:BatchRuntimeConfigNRuntime configuration for the batch execution.
Structure is documented below.


sparkBatchOBM:K
I
dataprocBatchSparkBatch,gcp:dataproc/BatchSparkBatch:BatchSparkBatch3Spark batch config.
Structure is documented below.

sparkRBatchRBP:N
L
dataprocBatchSparkRBatch.gcp:dataproc/BatchSparkRBatch:BatchSparkRBatch4SparkR batch config.
Structure is documented below.
¢
sparkSqlBatchXBV:T
R
dataprocBatchSparkSqlBatch2gcp:dataproc/BatchSparkSqlBatch:BatchSparkSqlBatch7Spark SQL batch config.
Structure is documented below.
"»
batchIdB" ©The ID to use for the batch, which will become the final component of the batch's resource name.
This value must be 4-63 characters. Valid characters are /[a-z][0-9]-/.
"7

createTime" %The time when the batch was created.
"D
creator" 5The email address of the user who created the batch.
"¦
effectiveLabels2" All of labels (key/value pairs) present on the resource in GCP, including the labels configured through Pulumi, other clients and services.
"Í
environmentConfigdBb:`
^
dataprocBatchEnvironmentConfig:gcp:dataproc/BatchEnvironmentConfig:BatchEnvironmentConfigREnvironment configuration for the batch execution.
Structure is documented below.
"
labelsB2" ðThe labels to associate with this batch.

**Note**: This field is non-authoritative, and will only manage the labels present in your configuration.
Please refer to the field `effective_labels` for all of the labels present on the resource.
"F
locationB" 4The location in which the batch will be created in.
",
name"  The resource name of the batch.
"P
	operation" ?The resource name of the operation associated with this batch.
"y
project" jThe ID of the project in which the resource belongs.
If it is not provided, the provider project is used.
"
pulumiLabels2" mThe combination of labels configured directly on the resource
and default labels configured on the provider.
"
pysparkBatchUBS:Q
O
dataprocBatchPysparkBatch0gcp:dataproc/BatchPysparkBatch:BatchPysparkBatch5PySpark batch config.
Structure is documented below.
"¹
runtimeConfigXBV:T
R
dataprocBatchRuntimeConfig2gcp:dataproc/BatchRuntimeConfig:BatchRuntimeConfigNRuntime configuration for the batch execution.
Structure is documented below.
"®
runtimeInfosR*P:N
L
dataprocBatchRuntimeInfo.gcp:dataproc/BatchRuntimeInfo:BatchRuntimeInfoJRuntime information about batch execution.
Structure is documented below.
"

sparkBatchOBM:K
I
dataprocBatchSparkBatch,gcp:dataproc/BatchSparkBatch:BatchSparkBatch3Spark batch config.
Structure is documented below.
"
sparkRBatchRBP:N
L
dataprocBatchSparkRBatch.gcp:dataproc/BatchSparkRBatch:BatchSparkRBatch4SparkR batch config.
Structure is documented below.
"¢
sparkSqlBatchXBV:T
R
dataprocBatchSparkSqlBatch2gcp:dataproc/BatchSparkSqlBatch:BatchSparkSqlBatch7Spark SQL batch config.
Structure is documented below.
"à
state" Ò(Output)
The state of the batch at this point in history. For possible values, see the [API documentation](https://cloud.google.com/dataproc-serverless/docs/reference/rest/v1/projects.locations.batches#State).
"´
stateHistoriesU*S:Q
O
dataprocBatchStateHistory0gcp:dataproc/BatchStateHistory:BatchStateHistoryKHistorical state information for the batch.
Structure is documented below.
"O
stateMessage" ;(Output)
Details about the state at this point in history.
"\
	stateTime" KBatch state details, such as a failure description if the state is FAILED.
"t
uuid" hA batch UUID (Unique Universal Identifier). The service generates this value when it creates the batch.
*ý»
1
dataprocClustergcp:dataproc/cluster:Cluster²§Manages a Cloud Dataproc cluster resource within GCP.

* [API documentation](https://cloud.google.com/dataproc/docs/reference/rest/v1/projects.regions.clusters)
* How-to Guides
    * [Official Documentation](https://cloud.google.com/dataproc/docs)


!> **Warning:** Due to limitations of the API, all arguments except
`labels`,`cluster_config.worker_config.num_instances` and `cluster_config.preemptible_worker_config.num_instances` are non-updatable. Changing `cluster_config.worker_config.min_num_instances` will be ignored. Changing others will cause recreation of the
whole cluster!

## Example Usage

### Basic

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const simplecluster = new gcp.dataproc.Cluster("simplecluster", {
    name: "simplecluster",
    region: "us-central1",
});
```
```python
import pulumi
import pulumi_gcp as gcp

simplecluster = gcp.dataproc.Cluster("simplecluster",
    name="simplecluster",
    region="us-central1")
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var simplecluster = new Gcp.Dataproc.Cluster("simplecluster", new()
    {
        Name = "simplecluster",
        Region = "us-central1",
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/dataproc"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		_, err := dataproc.NewCluster(ctx, "simplecluster", &dataproc.ClusterArgs{
			Name:   pulumi.String("simplecluster"),
			Region: pulumi.String("us-central1"),
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.dataproc.Cluster;
import com.pulumi.gcp.dataproc.ClusterArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        var simplecluster = new Cluster("simplecluster", ClusterArgs.builder()
            .name("simplecluster")
            .region("us-central1")
            .build());

    }
}
```
```yaml
resources:
  simplecluster:
    type: gcp:dataproc:Cluster
    properties:
      name: simplecluster
      region: us-central1
```
<!--End PulumiCodeChooser -->

### Advanced

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const _default = new gcp.serviceaccount.Account("default", {
    accountId: "service-account-id",
    displayName: "Service Account",
});
const mycluster = new gcp.dataproc.Cluster("mycluster", {
    name: "mycluster",
    region: "us-central1",
    gracefulDecommissionTimeout: "120s",
    labels: {
        foo: "bar",
    },
    clusterConfig: {
        stagingBucket: "dataproc-staging-bucket",
        masterConfig: {
            numInstances: 1,
            machineType: "e2-medium",
            diskConfig: {
                bootDiskType: "pd-ssd",
                bootDiskSizeGb: 30,
            },
        },
        workerConfig: {
            numInstances: 2,
            machineType: "e2-medium",
            minCpuPlatform: "Intel Skylake",
            diskConfig: {
                bootDiskSizeGb: 30,
                numLocalSsds: 1,
            },
        },
        preemptibleWorkerConfig: {
            numInstances: 0,
        },
        softwareConfig: {
            imageVersion: "2.0.35-debian10",
            overrideProperties: {
                "dataproc:dataproc.allow.zero.workers": "true",
            },
        },
        gceClusterConfig: {
            tags: [
                "foo",
                "bar",
            ],
            serviceAccount: _default.email,
            serviceAccountScopes: ["cloud-platform"],
        },
        initializationActions: [{
            script: "gs://dataproc-initialization-actions/stackdriver/stackdriver.sh",
            timeoutSec: 500,
        }],
    },
});
```
```python
import pulumi
import pulumi_gcp as gcp

default = gcp.serviceaccount.Account("default",
    account_id="service-account-id",
    display_name="Service Account")
mycluster = gcp.dataproc.Cluster("mycluster",
    name="mycluster",
    region="us-central1",
    graceful_decommission_timeout="120s",
    labels={
        "foo": "bar",
    },
    cluster_config={
        "staging_bucket": "dataproc-staging-bucket",
        "master_config": {
            "num_instances": 1,
            "machine_type": "e2-medium",
            "disk_config": {
                "boot_disk_type": "pd-ssd",
                "boot_disk_size_gb": 30,
            },
        },
        "worker_config": {
            "num_instances": 2,
            "machine_type": "e2-medium",
            "min_cpu_platform": "Intel Skylake",
            "disk_config": {
                "boot_disk_size_gb": 30,
                "num_local_ssds": 1,
            },
        },
        "preemptible_worker_config": {
            "num_instances": 0,
        },
        "software_config": {
            "image_version": "2.0.35-debian10",
            "override_properties": {
                "dataproc:dataproc.allow.zero.workers": "true",
            },
        },
        "gce_cluster_config": {
            "tags": [
                "foo",
                "bar",
            ],
            "service_account": default.email,
            "service_account_scopes": ["cloud-platform"],
        },
        "initialization_actions": [{
            "script": "gs://dataproc-initialization-actions/stackdriver/stackdriver.sh",
            "timeout_sec": 500,
        }],
    })
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var @default = new Gcp.ServiceAccount.Account("default", new()
    {
        AccountId = "service-account-id",
        DisplayName = "Service Account",
    });

    var mycluster = new Gcp.Dataproc.Cluster("mycluster", new()
    {
        Name = "mycluster",
        Region = "us-central1",
        GracefulDecommissionTimeout = "120s",
        Labels = 
        {
            { "foo", "bar" },
        },
        ClusterConfig = new Gcp.Dataproc.Inputs.ClusterClusterConfigArgs
        {
            StagingBucket = "dataproc-staging-bucket",
            MasterConfig = new Gcp.Dataproc.Inputs.ClusterClusterConfigMasterConfigArgs
            {
                NumInstances = 1,
                MachineType = "e2-medium",
                DiskConfig = new Gcp.Dataproc.Inputs.ClusterClusterConfigMasterConfigDiskConfigArgs
                {
                    BootDiskType = "pd-ssd",
                    BootDiskSizeGb = 30,
                },
            },
            WorkerConfig = new Gcp.Dataproc.Inputs.ClusterClusterConfigWorkerConfigArgs
            {
                NumInstances = 2,
                MachineType = "e2-medium",
                MinCpuPlatform = "Intel Skylake",
                DiskConfig = new Gcp.Dataproc.Inputs.ClusterClusterConfigWorkerConfigDiskConfigArgs
                {
                    BootDiskSizeGb = 30,
                    NumLocalSsds = 1,
                },
            },
            PreemptibleWorkerConfig = new Gcp.Dataproc.Inputs.ClusterClusterConfigPreemptibleWorkerConfigArgs
            {
                NumInstances = 0,
            },
            SoftwareConfig = new Gcp.Dataproc.Inputs.ClusterClusterConfigSoftwareConfigArgs
            {
                ImageVersion = "2.0.35-debian10",
                OverrideProperties = 
                {
                    { "dataproc:dataproc.allow.zero.workers", "true" },
                },
            },
            GceClusterConfig = new Gcp.Dataproc.Inputs.ClusterClusterConfigGceClusterConfigArgs
            {
                Tags = new[]
                {
                    "foo",
                    "bar",
                },
                ServiceAccount = @default.Email,
                ServiceAccountScopes = new[]
                {
                    "cloud-platform",
                },
            },
            InitializationActions = new[]
            {
                new Gcp.Dataproc.Inputs.ClusterClusterConfigInitializationActionArgs
                {
                    Script = "gs://dataproc-initialization-actions/stackdriver/stackdriver.sh",
                    TimeoutSec = 500,
                },
            },
        },
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/dataproc"
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/serviceaccount"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		_, err := serviceaccount.NewAccount(ctx, "default", &serviceaccount.AccountArgs{
			AccountId:   pulumi.String("service-account-id"),
			DisplayName: pulumi.String("Service Account"),
		})
		if err != nil {
			return err
		}
		_, err = dataproc.NewCluster(ctx, "mycluster", &dataproc.ClusterArgs{
			Name:                        pulumi.String("mycluster"),
			Region:                      pulumi.String("us-central1"),
			GracefulDecommissionTimeout: pulumi.String("120s"),
			Labels: pulumi.StringMap{
				"foo": pulumi.String("bar"),
			},
			ClusterConfig: &dataproc.ClusterClusterConfigArgs{
				StagingBucket: pulumi.String("dataproc-staging-bucket"),
				MasterConfig: &dataproc.ClusterClusterConfigMasterConfigArgs{
					NumInstances: pulumi.Int(1),
					MachineType:  pulumi.String("e2-medium"),
					DiskConfig: &dataproc.ClusterClusterConfigMasterConfigDiskConfigArgs{
						BootDiskType:   pulumi.String("pd-ssd"),
						BootDiskSizeGb: pulumi.Int(30),
					},
				},
				WorkerConfig: &dataproc.ClusterClusterConfigWorkerConfigArgs{
					NumInstances:   pulumi.Int(2),
					MachineType:    pulumi.String("e2-medium"),
					MinCpuPlatform: pulumi.String("Intel Skylake"),
					DiskConfig: &dataproc.ClusterClusterConfigWorkerConfigDiskConfigArgs{
						BootDiskSizeGb: pulumi.Int(30),
						NumLocalSsds:   pulumi.Int(1),
					},
				},
				PreemptibleWorkerConfig: &dataproc.ClusterClusterConfigPreemptibleWorkerConfigArgs{
					NumInstances: pulumi.Int(0),
				},
				SoftwareConfig: &dataproc.ClusterClusterConfigSoftwareConfigArgs{
					ImageVersion: pulumi.String("2.0.35-debian10"),
					OverrideProperties: pulumi.StringMap{
						"dataproc:dataproc.allow.zero.workers": pulumi.String("true"),
					},
				},
				GceClusterConfig: &dataproc.ClusterClusterConfigGceClusterConfigArgs{
					Tags: pulumi.StringArray{
						pulumi.String("foo"),
						pulumi.String("bar"),
					},
					ServiceAccount: _default.Email,
					ServiceAccountScopes: pulumi.StringArray{
						pulumi.String("cloud-platform"),
					},
				},
				InitializationActions: dataproc.ClusterClusterConfigInitializationActionArray{
					&dataproc.ClusterClusterConfigInitializationActionArgs{
						Script:     pulumi.String("gs://dataproc-initialization-actions/stackdriver/stackdriver.sh"),
						TimeoutSec: pulumi.Int(500),
					},
				},
			},
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.serviceaccount.Account;
import com.pulumi.gcp.serviceaccount.AccountArgs;
import com.pulumi.gcp.dataproc.Cluster;
import com.pulumi.gcp.dataproc.ClusterArgs;
import com.pulumi.gcp.dataproc.inputs.ClusterClusterConfigArgs;
import com.pulumi.gcp.dataproc.inputs.ClusterClusterConfigMasterConfigArgs;
import com.pulumi.gcp.dataproc.inputs.ClusterClusterConfigMasterConfigDiskConfigArgs;
import com.pulumi.gcp.dataproc.inputs.ClusterClusterConfigWorkerConfigArgs;
import com.pulumi.gcp.dataproc.inputs.ClusterClusterConfigWorkerConfigDiskConfigArgs;
import com.pulumi.gcp.dataproc.inputs.ClusterClusterConfigPreemptibleWorkerConfigArgs;
import com.pulumi.gcp.dataproc.inputs.ClusterClusterConfigSoftwareConfigArgs;
import com.pulumi.gcp.dataproc.inputs.ClusterClusterConfigGceClusterConfigArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        var default_ = new Account("default", AccountArgs.builder()
            .accountId("service-account-id")
            .displayName("Service Account")
            .build());

        var mycluster = new Cluster("mycluster", ClusterArgs.builder()
            .name("mycluster")
            .region("us-central1")
            .gracefulDecommissionTimeout("120s")
            .labels(Map.of("foo", "bar"))
            .clusterConfig(ClusterClusterConfigArgs.builder()
                .stagingBucket("dataproc-staging-bucket")
                .masterConfig(ClusterClusterConfigMasterConfigArgs.builder()
                    .numInstances(1)
                    .machineType("e2-medium")
                    .diskConfig(ClusterClusterConfigMasterConfigDiskConfigArgs.builder()
                        .bootDiskType("pd-ssd")
                        .bootDiskSizeGb(30)
                        .build())
                    .build())
                .workerConfig(ClusterClusterConfigWorkerConfigArgs.builder()
                    .numInstances(2)
                    .machineType("e2-medium")
                    .minCpuPlatform("Intel Skylake")
                    .diskConfig(ClusterClusterConfigWorkerConfigDiskConfigArgs.builder()
                        .bootDiskSizeGb(30)
                        .numLocalSsds(1)
                        .build())
                    .build())
                .preemptibleWorkerConfig(ClusterClusterConfigPreemptibleWorkerConfigArgs.builder()
                    .numInstances(0)
                    .build())
                .softwareConfig(ClusterClusterConfigSoftwareConfigArgs.builder()
                    .imageVersion("2.0.35-debian10")
                    .overrideProperties(Map.of("dataproc:dataproc.allow.zero.workers", "true"))
                    .build())
                .gceClusterConfig(ClusterClusterConfigGceClusterConfigArgs.builder()
                    .tags(                    
                        "foo",
                        "bar")
                    .serviceAccount(default_.email())
                    .serviceAccountScopes("cloud-platform")
                    .build())
                .initializationActions(ClusterClusterConfigInitializationActionArgs.builder()
                    .script("gs://dataproc-initialization-actions/stackdriver/stackdriver.sh")
                    .timeoutSec(500)
                    .build())
                .build())
            .build());

    }
}
```
```yaml
resources:
  default:
    type: gcp:serviceaccount:Account
    properties:
      accountId: service-account-id
      displayName: Service Account
  mycluster:
    type: gcp:dataproc:Cluster
    properties:
      name: mycluster
      region: us-central1
      gracefulDecommissionTimeout: 120s
      labels:
        foo: bar
      clusterConfig:
        stagingBucket: dataproc-staging-bucket
        masterConfig:
          numInstances: 1
          machineType: e2-medium
          diskConfig:
            bootDiskType: pd-ssd
            bootDiskSizeGb: 30
        workerConfig:
          numInstances: 2
          machineType: e2-medium
          minCpuPlatform: Intel Skylake
          diskConfig:
            bootDiskSizeGb: 30
            numLocalSsds: 1
        preemptibleWorkerConfig:
          numInstances: 0
        softwareConfig:
          imageVersion: 2.0.35-debian10
          overrideProperties:
            dataproc:dataproc.allow.zero.workers: 'true'
        gceClusterConfig:
          tags:
            - foo
            - bar
          serviceAccount: ${default.email}
          serviceAccountScopes:
            - cloud-platform
        initializationActions:
          - script: gs://dataproc-initialization-actions/stackdriver/stackdriver.sh
            timeoutSec: 500
```
<!--End PulumiCodeChooser -->

### Using A GPU Accelerator

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const acceleratedCluster = new gcp.dataproc.Cluster("accelerated_cluster", {
    name: "my-cluster-with-gpu",
    region: "us-central1",
    clusterConfig: {
        gceClusterConfig: {
            zone: "us-central1-a",
        },
        masterConfig: {
            accelerators: [{
                acceleratorType: "nvidia-tesla-k80",
                acceleratorCount: 1,
            }],
        },
    },
});
```
```python
import pulumi
import pulumi_gcp as gcp

accelerated_cluster = gcp.dataproc.Cluster("accelerated_cluster",
    name="my-cluster-with-gpu",
    region="us-central1",
    cluster_config={
        "gce_cluster_config": {
            "zone": "us-central1-a",
        },
        "master_config": {
            "accelerators": [{
                "accelerator_type": "nvidia-tesla-k80",
                "accelerator_count": 1,
            }],
        },
    })
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var acceleratedCluster = new Gcp.Dataproc.Cluster("accelerated_cluster", new()
    {
        Name = "my-cluster-with-gpu",
        Region = "us-central1",
        ClusterConfig = new Gcp.Dataproc.Inputs.ClusterClusterConfigArgs
        {
            GceClusterConfig = new Gcp.Dataproc.Inputs.ClusterClusterConfigGceClusterConfigArgs
            {
                Zone = "us-central1-a",
            },
            MasterConfig = new Gcp.Dataproc.Inputs.ClusterClusterConfigMasterConfigArgs
            {
                Accelerators = new[]
                {
                    new Gcp.Dataproc.Inputs.ClusterClusterConfigMasterConfigAcceleratorArgs
                    {
                        AcceleratorType = "nvidia-tesla-k80",
                        AcceleratorCount = 1,
                    },
                },
            },
        },
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/dataproc"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		_, err := dataproc.NewCluster(ctx, "accelerated_cluster", &dataproc.ClusterArgs{
			Name:   pulumi.String("my-cluster-with-gpu"),
			Region: pulumi.String("us-central1"),
			ClusterConfig: &dataproc.ClusterClusterConfigArgs{
				GceClusterConfig: &dataproc.ClusterClusterConfigGceClusterConfigArgs{
					Zone: pulumi.String("us-central1-a"),
				},
				MasterConfig: &dataproc.ClusterClusterConfigMasterConfigArgs{
					Accelerators: dataproc.ClusterClusterConfigMasterConfigAcceleratorArray{
						&dataproc.ClusterClusterConfigMasterConfigAcceleratorArgs{
							AcceleratorType:  pulumi.String("nvidia-tesla-k80"),
							AcceleratorCount: pulumi.Int(1),
						},
					},
				},
			},
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.dataproc.Cluster;
import com.pulumi.gcp.dataproc.ClusterArgs;
import com.pulumi.gcp.dataproc.inputs.ClusterClusterConfigArgs;
import com.pulumi.gcp.dataproc.inputs.ClusterClusterConfigGceClusterConfigArgs;
import com.pulumi.gcp.dataproc.inputs.ClusterClusterConfigMasterConfigArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        var acceleratedCluster = new Cluster("acceleratedCluster", ClusterArgs.builder()
            .name("my-cluster-with-gpu")
            .region("us-central1")
            .clusterConfig(ClusterClusterConfigArgs.builder()
                .gceClusterConfig(ClusterClusterConfigGceClusterConfigArgs.builder()
                    .zone("us-central1-a")
                    .build())
                .masterConfig(ClusterClusterConfigMasterConfigArgs.builder()
                    .accelerators(ClusterClusterConfigMasterConfigAcceleratorArgs.builder()
                        .acceleratorType("nvidia-tesla-k80")
                        .acceleratorCount("1")
                        .build())
                    .build())
                .build())
            .build());

    }
}
```
```yaml
resources:
  acceleratedCluster:
    type: gcp:dataproc:Cluster
    name: accelerated_cluster
    properties:
      name: my-cluster-with-gpu
      region: us-central1
      clusterConfig:
        gceClusterConfig:
          zone: us-central1-a
        masterConfig:
          accelerators:
            - acceleratorType: nvidia-tesla-k80
              acceleratorCount: '1'
```
<!--End PulumiCodeChooser -->

## Import

This resource does not support import.

Â
clusterConfig^B\:Z
X
dataprocClusterClusterConfig6gcp:dataproc/ClusterClusterConfig:ClusterClusterConfigQAllows you to configure various aspects of the cluster.
Structure defined below.
#
gracefulDecommissionTimeoutB" Ì
labelsB2" ¹The list of the labels (key/value pairs) configured on the resource and to be applied to instances in the cluster.
**Note**: This field is non-authoritative, and will only manage the labels present in your configuration. Please refer
to the field 'effective_labels' for all of the labels present on the resource.
R
nameB" DThe name of the cluster, unique within the project and
zone.

- - -

projectB" nThe ID of the project in which the `cluster` will exist. If it
is not provided, the provider project is used.
o
regionB" _The region in which the cluster and associated nodes will be created in.
Defaults to `global`.
á
virtualClusterConfigsBq:o
m
dataprocClusterVirtualClusterConfigDgcp:dataproc/ClusterVirtualClusterConfig:ClusterVirtualClusterConfigTAllows you to configure a virtual Dataproc on GKE cluster.
Structure defined below.
"À
clusterConfig\:Z
X
dataprocClusterClusterConfig6gcp:dataproc/ClusterClusterConfig:ClusterClusterConfigQAllows you to configure various aspects of the cluster.
Structure defined below.
"Í
effectiveLabels2" ³The list of labels (key/value pairs) to be applied to
instances in the cluster. GCP generates some itself including `goog-dataproc-cluster-name`
which is the name of the cluster.
"#
gracefulDecommissionTimeoutB" "Ì
labelsB2" ¹The list of the labels (key/value pairs) configured on the resource and to be applied to instances in the cluster.
**Note**: This field is non-authoritative, and will only manage the labels present in your configuration. Please refer
to the field 'effective_labels' for all of the labels present on the resource.
"P
name" DThe name of the cluster, unique within the project and
zone.

- - -
"}
project" nThe ID of the project in which the `cluster` will exist. If it
is not provided, the provider project is used.
"
pulumiLabels2" mThe combination of labels configured directly on the resource and default labels configured on the provider.
"o
regionB" _The region in which the cluster and associated nodes will be created in.
Defaults to `global`.
"ß
virtualClusterConfigq:o
m
dataprocClusterVirtualClusterConfigDgcp:dataproc/ClusterVirtualClusterConfig:ClusterVirtualClusterConfigTAllows you to configure a virtual Dataproc on GKE cluster.
Structure defined below.
*Ò·
O
dataprocClusterIAMBinding0gcp:dataproc/clusterIAMBinding:ClusterIAMBindingõThree different resources help you manage IAM policies on dataproc clusters. Each of these resources serves a different use case:

* `gcp.dataproc.ClusterIAMPolicy`: Authoritative. Sets the IAM policy for the cluster and replaces any existing policy already attached.
* `gcp.dataproc.ClusterIAMBinding`: Authoritative for a given role. Updates the IAM policy to grant a role to a list of members. Other roles within the IAM policy for the cluster are preserved.
* `gcp.dataproc.ClusterIAMMember`: Non-authoritative. Updates the IAM policy to grant a role to a new member. Other members for the role for the cluster are preserved.

> **Note:** `gcp.dataproc.ClusterIAMPolicy` **cannot** be used in conjunction with `gcp.dataproc.ClusterIAMBinding` and `gcp.dataproc.ClusterIAMMember` or they will fight over what your policy should be. In addition, be careful not to accidentally unset ownership of the cluster as `gcp.dataproc.ClusterIAMPolicy` replaces the entire policy.

> **Note:** `gcp.dataproc.ClusterIAMBinding` resources **can be** used in conjunction with `gcp.dataproc.ClusterIAMMember` resources **only if** they do not grant privilege to the same role.

## gcp.dataproc.ClusterIAMPolicy

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const admin = gcp.organizations.getIAMPolicy({
    bindings: [{
        role: "roles/editor",
        members: ["user:jane@example.com"],
    }],
});
const editor = new gcp.dataproc.ClusterIAMPolicy("editor", {
    project: "your-project",
    region: "your-region",
    cluster: "your-dataproc-cluster",
    policyData: admin.then(admin => admin.policyData),
});
```
```python
import pulumi
import pulumi_gcp as gcp

admin = gcp.organizations.get_iam_policy(bindings=[{
    "role": "roles/editor",
    "members": ["user:jane@example.com"],
}])
editor = gcp.dataproc.ClusterIAMPolicy("editor",
    project="your-project",
    region="your-region",
    cluster="your-dataproc-cluster",
    policy_data=admin.policy_data)
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var admin = Gcp.Organizations.GetIAMPolicy.Invoke(new()
    {
        Bindings = new[]
        {
            new Gcp.Organizations.Inputs.GetIAMPolicyBindingInputArgs
            {
                Role = "roles/editor",
                Members = new[]
                {
                    "user:jane@example.com",
                },
            },
        },
    });

    var editor = new Gcp.Dataproc.ClusterIAMPolicy("editor", new()
    {
        Project = "your-project",
        Region = "your-region",
        Cluster = "your-dataproc-cluster",
        PolicyData = admin.Apply(getIAMPolicyResult => getIAMPolicyResult.PolicyData),
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/dataproc"
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/organizations"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		admin, err := organizations.LookupIAMPolicy(ctx, &organizations.LookupIAMPolicyArgs{
			Bindings: []organizations.GetIAMPolicyBinding{
				{
					Role: "roles/editor",
					Members: []string{
						"user:jane@example.com",
					},
				},
			},
		}, nil)
		if err != nil {
			return err
		}
		_, err = dataproc.NewClusterIAMPolicy(ctx, "editor", &dataproc.ClusterIAMPolicyArgs{
			Project:    pulumi.String("your-project"),
			Region:     pulumi.String("your-region"),
			Cluster:    pulumi.String("your-dataproc-cluster"),
			PolicyData: pulumi.String(admin.PolicyData),
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.organizations.OrganizationsFunctions;
import com.pulumi.gcp.organizations.inputs.GetIAMPolicyArgs;
import com.pulumi.gcp.dataproc.ClusterIAMPolicy;
import com.pulumi.gcp.dataproc.ClusterIAMPolicyArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        final var admin = OrganizationsFunctions.getIAMPolicy(GetIAMPolicyArgs.builder()
            .bindings(GetIAMPolicyBindingArgs.builder()
                .role("roles/editor")
                .members("user:jane@example.com")
                .build())
            .build());

        var editor = new ClusterIAMPolicy("editor", ClusterIAMPolicyArgs.builder()
            .project("your-project")
            .region("your-region")
            .cluster("your-dataproc-cluster")
            .policyData(admin.applyValue(getIAMPolicyResult -> getIAMPolicyResult.policyData()))
            .build());

    }
}
```
```yaml
resources:
  editor:
    type: gcp:dataproc:ClusterIAMPolicy
    properties:
      project: your-project
      region: your-region
      cluster: your-dataproc-cluster
      policyData: ${admin.policyData}
variables:
  admin:
    fn::invoke:
      function: gcp:organizations:getIAMPolicy
      arguments:
        bindings:
          - role: roles/editor
            members:
              - user:jane@example.com
```
<!--End PulumiCodeChooser -->

## gcp.dataproc.ClusterIAMBinding

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const editor = new gcp.dataproc.ClusterIAMBinding("editor", {
    cluster: "your-dataproc-cluster",
    role: "roles/editor",
    members: ["user:jane@example.com"],
});
```
```python
import pulumi
import pulumi_gcp as gcp

editor = gcp.dataproc.ClusterIAMBinding("editor",
    cluster="your-dataproc-cluster",
    role="roles/editor",
    members=["user:jane@example.com"])
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var editor = new Gcp.Dataproc.ClusterIAMBinding("editor", new()
    {
        Cluster = "your-dataproc-cluster",
        Role = "roles/editor",
        Members = new[]
        {
            "user:jane@example.com",
        },
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/dataproc"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		_, err := dataproc.NewClusterIAMBinding(ctx, "editor", &dataproc.ClusterIAMBindingArgs{
			Cluster: pulumi.String("your-dataproc-cluster"),
			Role:    pulumi.String("roles/editor"),
			Members: pulumi.StringArray{
				pulumi.String("user:jane@example.com"),
			},
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.dataproc.ClusterIAMBinding;
import com.pulumi.gcp.dataproc.ClusterIAMBindingArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        var editor = new ClusterIAMBinding("editor", ClusterIAMBindingArgs.builder()
            .cluster("your-dataproc-cluster")
            .role("roles/editor")
            .members("user:jane@example.com")
            .build());

    }
}
```
```yaml
resources:
  editor:
    type: gcp:dataproc:ClusterIAMBinding
    properties:
      cluster: your-dataproc-cluster
      role: roles/editor
      members:
        - user:jane@example.com
```
<!--End PulumiCodeChooser -->

## gcp.dataproc.ClusterIAMMember

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const editor = new gcp.dataproc.ClusterIAMMember("editor", {
    cluster: "your-dataproc-cluster",
    role: "roles/editor",
    member: "user:jane@example.com",
});
```
```python
import pulumi
import pulumi_gcp as gcp

editor = gcp.dataproc.ClusterIAMMember("editor",
    cluster="your-dataproc-cluster",
    role="roles/editor",
    member="user:jane@example.com")
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var editor = new Gcp.Dataproc.ClusterIAMMember("editor", new()
    {
        Cluster = "your-dataproc-cluster",
        Role = "roles/editor",
        Member = "user:jane@example.com",
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/dataproc"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		_, err := dataproc.NewClusterIAMMember(ctx, "editor", &dataproc.ClusterIAMMemberArgs{
			Cluster: pulumi.String("your-dataproc-cluster"),
			Role:    pulumi.String("roles/editor"),
			Member:  pulumi.String("user:jane@example.com"),
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.dataproc.ClusterIAMMember;
import com.pulumi.gcp.dataproc.ClusterIAMMemberArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        var editor = new ClusterIAMMember("editor", ClusterIAMMemberArgs.builder()
            .cluster("your-dataproc-cluster")
            .role("roles/editor")
            .member("user:jane@example.com")
            .build());

    }
}
```
```yaml
resources:
  editor:
    type: gcp:dataproc:ClusterIAMMember
    properties:
      cluster: your-dataproc-cluster
      role: roles/editor
      member: user:jane@example.com
```
<!--End PulumiCodeChooser -->

## gcp.dataproc.ClusterIAMPolicy

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const admin = gcp.organizations.getIAMPolicy({
    bindings: [{
        role: "roles/editor",
        members: ["user:jane@example.com"],
    }],
});
const editor = new gcp.dataproc.ClusterIAMPolicy("editor", {
    project: "your-project",
    region: "your-region",
    cluster: "your-dataproc-cluster",
    policyData: admin.then(admin => admin.policyData),
});
```
```python
import pulumi
import pulumi_gcp as gcp

admin = gcp.organizations.get_iam_policy(bindings=[{
    "role": "roles/editor",
    "members": ["user:jane@example.com"],
}])
editor = gcp.dataproc.ClusterIAMPolicy("editor",
    project="your-project",
    region="your-region",
    cluster="your-dataproc-cluster",
    policy_data=admin.policy_data)
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var admin = Gcp.Organizations.GetIAMPolicy.Invoke(new()
    {
        Bindings = new[]
        {
            new Gcp.Organizations.Inputs.GetIAMPolicyBindingInputArgs
            {
                Role = "roles/editor",
                Members = new[]
                {
                    "user:jane@example.com",
                },
            },
        },
    });

    var editor = new Gcp.Dataproc.ClusterIAMPolicy("editor", new()
    {
        Project = "your-project",
        Region = "your-region",
        Cluster = "your-dataproc-cluster",
        PolicyData = admin.Apply(getIAMPolicyResult => getIAMPolicyResult.PolicyData),
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/dataproc"
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/organizations"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		admin, err := organizations.LookupIAMPolicy(ctx, &organizations.LookupIAMPolicyArgs{
			Bindings: []organizations.GetIAMPolicyBinding{
				{
					Role: "roles/editor",
					Members: []string{
						"user:jane@example.com",
					},
				},
			},
		}, nil)
		if err != nil {
			return err
		}
		_, err = dataproc.NewClusterIAMPolicy(ctx, "editor", &dataproc.ClusterIAMPolicyArgs{
			Project:    pulumi.String("your-project"),
			Region:     pulumi.String("your-region"),
			Cluster:    pulumi.String("your-dataproc-cluster"),
			PolicyData: pulumi.String(admin.PolicyData),
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.organizations.OrganizationsFunctions;
import com.pulumi.gcp.organizations.inputs.GetIAMPolicyArgs;
import com.pulumi.gcp.dataproc.ClusterIAMPolicy;
import com.pulumi.gcp.dataproc.ClusterIAMPolicyArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        final var admin = OrganizationsFunctions.getIAMPolicy(GetIAMPolicyArgs.builder()
            .bindings(GetIAMPolicyBindingArgs.builder()
                .role("roles/editor")
                .members("user:jane@example.com")
                .build())
            .build());

        var editor = new ClusterIAMPolicy("editor", ClusterIAMPolicyArgs.builder()
            .project("your-project")
            .region("your-region")
            .cluster("your-dataproc-cluster")
            .policyData(admin.applyValue(getIAMPolicyResult -> getIAMPolicyResult.policyData()))
            .build());

    }
}
```
```yaml
resources:
  editor:
    type: gcp:dataproc:ClusterIAMPolicy
    properties:
      project: your-project
      region: your-region
      cluster: your-dataproc-cluster
      policyData: ${admin.policyData}
variables:
  admin:
    fn::invoke:
      function: gcp:organizations:getIAMPolicy
      arguments:
        bindings:
          - role: roles/editor
            members:
              - user:jane@example.com
```
<!--End PulumiCodeChooser -->

## gcp.dataproc.ClusterIAMBinding

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const editor = new gcp.dataproc.ClusterIAMBinding("editor", {
    cluster: "your-dataproc-cluster",
    role: "roles/editor",
    members: ["user:jane@example.com"],
});
```
```python
import pulumi
import pulumi_gcp as gcp

editor = gcp.dataproc.ClusterIAMBinding("editor",
    cluster="your-dataproc-cluster",
    role="roles/editor",
    members=["user:jane@example.com"])
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var editor = new Gcp.Dataproc.ClusterIAMBinding("editor", new()
    {
        Cluster = "your-dataproc-cluster",
        Role = "roles/editor",
        Members = new[]
        {
            "user:jane@example.com",
        },
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/dataproc"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		_, err := dataproc.NewClusterIAMBinding(ctx, "editor", &dataproc.ClusterIAMBindingArgs{
			Cluster: pulumi.String("your-dataproc-cluster"),
			Role:    pulumi.String("roles/editor"),
			Members: pulumi.StringArray{
				pulumi.String("user:jane@example.com"),
			},
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.dataproc.ClusterIAMBinding;
import com.pulumi.gcp.dataproc.ClusterIAMBindingArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        var editor = new ClusterIAMBinding("editor", ClusterIAMBindingArgs.builder()
            .cluster("your-dataproc-cluster")
            .role("roles/editor")
            .members("user:jane@example.com")
            .build());

    }
}
```
```yaml
resources:
  editor:
    type: gcp:dataproc:ClusterIAMBinding
    properties:
      cluster: your-dataproc-cluster
      role: roles/editor
      members:
        - user:jane@example.com
```
<!--End PulumiCodeChooser -->

## gcp.dataproc.ClusterIAMMember

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const editor = new gcp.dataproc.ClusterIAMMember("editor", {
    cluster: "your-dataproc-cluster",
    role: "roles/editor",
    member: "user:jane@example.com",
});
```
```python
import pulumi
import pulumi_gcp as gcp

editor = gcp.dataproc.ClusterIAMMember("editor",
    cluster="your-dataproc-cluster",
    role="roles/editor",
    member="user:jane@example.com")
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var editor = new Gcp.Dataproc.ClusterIAMMember("editor", new()
    {
        Cluster = "your-dataproc-cluster",
        Role = "roles/editor",
        Member = "user:jane@example.com",
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/dataproc"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		_, err := dataproc.NewClusterIAMMember(ctx, "editor", &dataproc.ClusterIAMMemberArgs{
			Cluster: pulumi.String("your-dataproc-cluster"),
			Role:    pulumi.String("roles/editor"),
			Member:  pulumi.String("user:jane@example.com"),
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.dataproc.ClusterIAMMember;
import com.pulumi.gcp.dataproc.ClusterIAMMemberArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        var editor = new ClusterIAMMember("editor", ClusterIAMMemberArgs.builder()
            .cluster("your-dataproc-cluster")
            .role("roles/editor")
            .member("user:jane@example.com")
            .build());

    }
}
```
```yaml
resources:
  editor:
    type: gcp:dataproc:ClusterIAMMember
    properties:
      cluster: your-dataproc-cluster
      role: roles/editor
      member: user:jane@example.com
```
<!--End PulumiCodeChooser -->

## Import

### Importing IAM policies

IAM policy imports use the `cluster` identifier of the Dataproc Cluster resource only. For example:

* `projects/{project}/regions/{region}/clusters/{cluster}`

An `import` block (Terraform v1.5.0 and later) can be used to import IAM policies:

tf

import {

  id = projects/{project}/regions/{region}/clusters/{cluster}

  to = google_dataproc_cluster_iam_policy.default

}

The `pulumi import` command can also be used:

```sh
$ pulumi import gcp:dataproc/clusterIAMBinding:ClusterIAMBinding default projects/{project}/regions/{region}/clusters/{cluster}
```

¦
cluster" The name or relative resource id of the cluster to manage IAM policies for.

For `gcp.dataproc.ClusterIAMMember` or `gcp.dataproc.ClusterIAMBinding`:
}
	conditionpBn:l
j
dataprocClusterIAMBindingConditionBgcp:dataproc/ClusterIAMBindingCondition:ClusterIAMBindingCondition
members*" Identities that will be granted the privilege in `role`.
Each entry can have one of the following values:
* **allUsers**: A special identifier that represents anyone who is on the internet; with or without a Google account.
* **allAuthenticatedUsers**: A special identifier that represents anyone who is authenticated with a Google account or a service account.
* **user:{emailid}**: An email address that represents a specific Google account. For example, alice@gmail.com or joe@example.com.
* **serviceAccount:{emailid}**: An email address that represents a service account. For example, my-other-app@appspot.gserviceaccount.com.
* **group:{emailid}**: An email address that represents a Google group. For example, admins@example.com.
* **domain:{domain}**: A G Suite domain (primary, instead of alias) name that represents all the users of that domain. For example, google.com or example.com.
s
projectB" bThe project in which the cluster belongs. If it
is not provided, the provider will use a default.
q
regionB" aThe region in which the cluster belongs. If it
is not provided, the provider will use a default.
þ
role" ñThe role that should be applied. Only one
`gcp.dataproc.ClusterIAMBinding` can be used per role. Note that custom roles must be of the format
`[projects|organizations]/{parent-name}/roles/{role-name}`.

`gcp.dataproc.ClusterIAMPolicy` only:
"¦
cluster" The name or relative resource id of the cluster to manage IAM policies for.

For `gcp.dataproc.ClusterIAMMember` or `gcp.dataproc.ClusterIAMBinding`:
"}
	conditionpBn:l
j
dataprocClusterIAMBindingConditionBgcp:dataproc/ClusterIAMBindingCondition:ClusterIAMBindingCondition">
etag" 2(Computed) The etag of the clusters's IAM policy.
"
members*" Identities that will be granted the privilege in `role`.
Each entry can have one of the following values:
* **allUsers**: A special identifier that represents anyone who is on the internet; with or without a Google account.
* **allAuthenticatedUsers**: A special identifier that represents anyone who is authenticated with a Google account or a service account.
* **user:{emailid}**: An email address that represents a specific Google account. For example, alice@gmail.com or joe@example.com.
* **serviceAccount:{emailid}**: An email address that represents a service account. For example, my-other-app@appspot.gserviceaccount.com.
* **group:{emailid}**: An email address that represents a Google group. For example, admins@example.com.
* **domain:{domain}**: A G Suite domain (primary, instead of alias) name that represents all the users of that domain. For example, google.com or example.com.
"q
project" bThe project in which the cluster belongs. If it
is not provided, the provider will use a default.
"o
region" aThe region in which the cluster belongs. If it
is not provided, the provider will use a default.
"þ
role" ñThe role that should be applied. Only one
`gcp.dataproc.ClusterIAMBinding` can be used per role. Note that custom roles must be of the format
`[projects|organizations]/{parent-name}/roles/{role-name}`.

`gcp.dataproc.ClusterIAMPolicy` only:
*Á·
L
dataprocClusterIAMMember.gcp:dataproc/clusterIAMMember:ClusterIAMMemberóThree different resources help you manage IAM policies on dataproc clusters. Each of these resources serves a different use case:

* `gcp.dataproc.ClusterIAMPolicy`: Authoritative. Sets the IAM policy for the cluster and replaces any existing policy already attached.
* `gcp.dataproc.ClusterIAMBinding`: Authoritative for a given role. Updates the IAM policy to grant a role to a list of members. Other roles within the IAM policy for the cluster are preserved.
* `gcp.dataproc.ClusterIAMMember`: Non-authoritative. Updates the IAM policy to grant a role to a new member. Other members for the role for the cluster are preserved.

> **Note:** `gcp.dataproc.ClusterIAMPolicy` **cannot** be used in conjunction with `gcp.dataproc.ClusterIAMBinding` and `gcp.dataproc.ClusterIAMMember` or they will fight over what your policy should be. In addition, be careful not to accidentally unset ownership of the cluster as `gcp.dataproc.ClusterIAMPolicy` replaces the entire policy.

> **Note:** `gcp.dataproc.ClusterIAMBinding` resources **can be** used in conjunction with `gcp.dataproc.ClusterIAMMember` resources **only if** they do not grant privilege to the same role.

## gcp.dataproc.ClusterIAMPolicy

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const admin = gcp.organizations.getIAMPolicy({
    bindings: [{
        role: "roles/editor",
        members: ["user:jane@example.com"],
    }],
});
const editor = new gcp.dataproc.ClusterIAMPolicy("editor", {
    project: "your-project",
    region: "your-region",
    cluster: "your-dataproc-cluster",
    policyData: admin.then(admin => admin.policyData),
});
```
```python
import pulumi
import pulumi_gcp as gcp

admin = gcp.organizations.get_iam_policy(bindings=[{
    "role": "roles/editor",
    "members": ["user:jane@example.com"],
}])
editor = gcp.dataproc.ClusterIAMPolicy("editor",
    project="your-project",
    region="your-region",
    cluster="your-dataproc-cluster",
    policy_data=admin.policy_data)
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var admin = Gcp.Organizations.GetIAMPolicy.Invoke(new()
    {
        Bindings = new[]
        {
            new Gcp.Organizations.Inputs.GetIAMPolicyBindingInputArgs
            {
                Role = "roles/editor",
                Members = new[]
                {
                    "user:jane@example.com",
                },
            },
        },
    });

    var editor = new Gcp.Dataproc.ClusterIAMPolicy("editor", new()
    {
        Project = "your-project",
        Region = "your-region",
        Cluster = "your-dataproc-cluster",
        PolicyData = admin.Apply(getIAMPolicyResult => getIAMPolicyResult.PolicyData),
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/dataproc"
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/organizations"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		admin, err := organizations.LookupIAMPolicy(ctx, &organizations.LookupIAMPolicyArgs{
			Bindings: []organizations.GetIAMPolicyBinding{
				{
					Role: "roles/editor",
					Members: []string{
						"user:jane@example.com",
					},
				},
			},
		}, nil)
		if err != nil {
			return err
		}
		_, err = dataproc.NewClusterIAMPolicy(ctx, "editor", &dataproc.ClusterIAMPolicyArgs{
			Project:    pulumi.String("your-project"),
			Region:     pulumi.String("your-region"),
			Cluster:    pulumi.String("your-dataproc-cluster"),
			PolicyData: pulumi.String(admin.PolicyData),
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.organizations.OrganizationsFunctions;
import com.pulumi.gcp.organizations.inputs.GetIAMPolicyArgs;
import com.pulumi.gcp.dataproc.ClusterIAMPolicy;
import com.pulumi.gcp.dataproc.ClusterIAMPolicyArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        final var admin = OrganizationsFunctions.getIAMPolicy(GetIAMPolicyArgs.builder()
            .bindings(GetIAMPolicyBindingArgs.builder()
                .role("roles/editor")
                .members("user:jane@example.com")
                .build())
            .build());

        var editor = new ClusterIAMPolicy("editor", ClusterIAMPolicyArgs.builder()
            .project("your-project")
            .region("your-region")
            .cluster("your-dataproc-cluster")
            .policyData(admin.applyValue(getIAMPolicyResult -> getIAMPolicyResult.policyData()))
            .build());

    }
}
```
```yaml
resources:
  editor:
    type: gcp:dataproc:ClusterIAMPolicy
    properties:
      project: your-project
      region: your-region
      cluster: your-dataproc-cluster
      policyData: ${admin.policyData}
variables:
  admin:
    fn::invoke:
      function: gcp:organizations:getIAMPolicy
      arguments:
        bindings:
          - role: roles/editor
            members:
              - user:jane@example.com
```
<!--End PulumiCodeChooser -->

## gcp.dataproc.ClusterIAMBinding

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const editor = new gcp.dataproc.ClusterIAMBinding("editor", {
    cluster: "your-dataproc-cluster",
    role: "roles/editor",
    members: ["user:jane@example.com"],
});
```
```python
import pulumi
import pulumi_gcp as gcp

editor = gcp.dataproc.ClusterIAMBinding("editor",
    cluster="your-dataproc-cluster",
    role="roles/editor",
    members=["user:jane@example.com"])
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var editor = new Gcp.Dataproc.ClusterIAMBinding("editor", new()
    {
        Cluster = "your-dataproc-cluster",
        Role = "roles/editor",
        Members = new[]
        {
            "user:jane@example.com",
        },
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/dataproc"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		_, err := dataproc.NewClusterIAMBinding(ctx, "editor", &dataproc.ClusterIAMBindingArgs{
			Cluster: pulumi.String("your-dataproc-cluster"),
			Role:    pulumi.String("roles/editor"),
			Members: pulumi.StringArray{
				pulumi.String("user:jane@example.com"),
			},
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.dataproc.ClusterIAMBinding;
import com.pulumi.gcp.dataproc.ClusterIAMBindingArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        var editor = new ClusterIAMBinding("editor", ClusterIAMBindingArgs.builder()
            .cluster("your-dataproc-cluster")
            .role("roles/editor")
            .members("user:jane@example.com")
            .build());

    }
}
```
```yaml
resources:
  editor:
    type: gcp:dataproc:ClusterIAMBinding
    properties:
      cluster: your-dataproc-cluster
      role: roles/editor
      members:
        - user:jane@example.com
```
<!--End PulumiCodeChooser -->

## gcp.dataproc.ClusterIAMMember

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const editor = new gcp.dataproc.ClusterIAMMember("editor", {
    cluster: "your-dataproc-cluster",
    role: "roles/editor",
    member: "user:jane@example.com",
});
```
```python
import pulumi
import pulumi_gcp as gcp

editor = gcp.dataproc.ClusterIAMMember("editor",
    cluster="your-dataproc-cluster",
    role="roles/editor",
    member="user:jane@example.com")
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var editor = new Gcp.Dataproc.ClusterIAMMember("editor", new()
    {
        Cluster = "your-dataproc-cluster",
        Role = "roles/editor",
        Member = "user:jane@example.com",
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/dataproc"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		_, err := dataproc.NewClusterIAMMember(ctx, "editor", &dataproc.ClusterIAMMemberArgs{
			Cluster: pulumi.String("your-dataproc-cluster"),
			Role:    pulumi.String("roles/editor"),
			Member:  pulumi.String("user:jane@example.com"),
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.dataproc.ClusterIAMMember;
import com.pulumi.gcp.dataproc.ClusterIAMMemberArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        var editor = new ClusterIAMMember("editor", ClusterIAMMemberArgs.builder()
            .cluster("your-dataproc-cluster")
            .role("roles/editor")
            .member("user:jane@example.com")
            .build());

    }
}
```
```yaml
resources:
  editor:
    type: gcp:dataproc:ClusterIAMMember
    properties:
      cluster: your-dataproc-cluster
      role: roles/editor
      member: user:jane@example.com
```
<!--End PulumiCodeChooser -->

## gcp.dataproc.ClusterIAMPolicy

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const admin = gcp.organizations.getIAMPolicy({
    bindings: [{
        role: "roles/editor",
        members: ["user:jane@example.com"],
    }],
});
const editor = new gcp.dataproc.ClusterIAMPolicy("editor", {
    project: "your-project",
    region: "your-region",
    cluster: "your-dataproc-cluster",
    policyData: admin.then(admin => admin.policyData),
});
```
```python
import pulumi
import pulumi_gcp as gcp

admin = gcp.organizations.get_iam_policy(bindings=[{
    "role": "roles/editor",
    "members": ["user:jane@example.com"],
}])
editor = gcp.dataproc.ClusterIAMPolicy("editor",
    project="your-project",
    region="your-region",
    cluster="your-dataproc-cluster",
    policy_data=admin.policy_data)
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var admin = Gcp.Organizations.GetIAMPolicy.Invoke(new()
    {
        Bindings = new[]
        {
            new Gcp.Organizations.Inputs.GetIAMPolicyBindingInputArgs
            {
                Role = "roles/editor",
                Members = new[]
                {
                    "user:jane@example.com",
                },
            },
        },
    });

    var editor = new Gcp.Dataproc.ClusterIAMPolicy("editor", new()
    {
        Project = "your-project",
        Region = "your-region",
        Cluster = "your-dataproc-cluster",
        PolicyData = admin.Apply(getIAMPolicyResult => getIAMPolicyResult.PolicyData),
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/dataproc"
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/organizations"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		admin, err := organizations.LookupIAMPolicy(ctx, &organizations.LookupIAMPolicyArgs{
			Bindings: []organizations.GetIAMPolicyBinding{
				{
					Role: "roles/editor",
					Members: []string{
						"user:jane@example.com",
					},
				},
			},
		}, nil)
		if err != nil {
			return err
		}
		_, err = dataproc.NewClusterIAMPolicy(ctx, "editor", &dataproc.ClusterIAMPolicyArgs{
			Project:    pulumi.String("your-project"),
			Region:     pulumi.String("your-region"),
			Cluster:    pulumi.String("your-dataproc-cluster"),
			PolicyData: pulumi.String(admin.PolicyData),
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.organizations.OrganizationsFunctions;
import com.pulumi.gcp.organizations.inputs.GetIAMPolicyArgs;
import com.pulumi.gcp.dataproc.ClusterIAMPolicy;
import com.pulumi.gcp.dataproc.ClusterIAMPolicyArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        final var admin = OrganizationsFunctions.getIAMPolicy(GetIAMPolicyArgs.builder()
            .bindings(GetIAMPolicyBindingArgs.builder()
                .role("roles/editor")
                .members("user:jane@example.com")
                .build())
            .build());

        var editor = new ClusterIAMPolicy("editor", ClusterIAMPolicyArgs.builder()
            .project("your-project")
            .region("your-region")
            .cluster("your-dataproc-cluster")
            .policyData(admin.applyValue(getIAMPolicyResult -> getIAMPolicyResult.policyData()))
            .build());

    }
}
```
```yaml
resources:
  editor:
    type: gcp:dataproc:ClusterIAMPolicy
    properties:
      project: your-project
      region: your-region
      cluster: your-dataproc-cluster
      policyData: ${admin.policyData}
variables:
  admin:
    fn::invoke:
      function: gcp:organizations:getIAMPolicy
      arguments:
        bindings:
          - role: roles/editor
            members:
              - user:jane@example.com
```
<!--End PulumiCodeChooser -->

## gcp.dataproc.ClusterIAMBinding

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const editor = new gcp.dataproc.ClusterIAMBinding("editor", {
    cluster: "your-dataproc-cluster",
    role: "roles/editor",
    members: ["user:jane@example.com"],
});
```
```python
import pulumi
import pulumi_gcp as gcp

editor = gcp.dataproc.ClusterIAMBinding("editor",
    cluster="your-dataproc-cluster",
    role="roles/editor",
    members=["user:jane@example.com"])
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var editor = new Gcp.Dataproc.ClusterIAMBinding("editor", new()
    {
        Cluster = "your-dataproc-cluster",
        Role = "roles/editor",
        Members = new[]
        {
            "user:jane@example.com",
        },
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/dataproc"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		_, err := dataproc.NewClusterIAMBinding(ctx, "editor", &dataproc.ClusterIAMBindingArgs{
			Cluster: pulumi.String("your-dataproc-cluster"),
			Role:    pulumi.String("roles/editor"),
			Members: pulumi.StringArray{
				pulumi.String("user:jane@example.com"),
			},
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.dataproc.ClusterIAMBinding;
import com.pulumi.gcp.dataproc.ClusterIAMBindingArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        var editor = new ClusterIAMBinding("editor", ClusterIAMBindingArgs.builder()
            .cluster("your-dataproc-cluster")
            .role("roles/editor")
            .members("user:jane@example.com")
            .build());

    }
}
```
```yaml
resources:
  editor:
    type: gcp:dataproc:ClusterIAMBinding
    properties:
      cluster: your-dataproc-cluster
      role: roles/editor
      members:
        - user:jane@example.com
```
<!--End PulumiCodeChooser -->

## gcp.dataproc.ClusterIAMMember

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const editor = new gcp.dataproc.ClusterIAMMember("editor", {
    cluster: "your-dataproc-cluster",
    role: "roles/editor",
    member: "user:jane@example.com",
});
```
```python
import pulumi
import pulumi_gcp as gcp

editor = gcp.dataproc.ClusterIAMMember("editor",
    cluster="your-dataproc-cluster",
    role="roles/editor",
    member="user:jane@example.com")
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var editor = new Gcp.Dataproc.ClusterIAMMember("editor", new()
    {
        Cluster = "your-dataproc-cluster",
        Role = "roles/editor",
        Member = "user:jane@example.com",
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/dataproc"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		_, err := dataproc.NewClusterIAMMember(ctx, "editor", &dataproc.ClusterIAMMemberArgs{
			Cluster: pulumi.String("your-dataproc-cluster"),
			Role:    pulumi.String("roles/editor"),
			Member:  pulumi.String("user:jane@example.com"),
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.dataproc.ClusterIAMMember;
import com.pulumi.gcp.dataproc.ClusterIAMMemberArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        var editor = new ClusterIAMMember("editor", ClusterIAMMemberArgs.builder()
            .cluster("your-dataproc-cluster")
            .role("roles/editor")
            .member("user:jane@example.com")
            .build());

    }
}
```
```yaml
resources:
  editor:
    type: gcp:dataproc:ClusterIAMMember
    properties:
      cluster: your-dataproc-cluster
      role: roles/editor
      member: user:jane@example.com
```
<!--End PulumiCodeChooser -->

## Import

### Importing IAM policies

IAM policy imports use the `cluster` identifier of the Dataproc Cluster resource only. For example:

* `projects/{project}/regions/{region}/clusters/{cluster}`

An `import` block (Terraform v1.5.0 and later) can be used to import IAM policies:

tf

import {

  id = projects/{project}/regions/{region}/clusters/{cluster}

  to = google_dataproc_cluster_iam_policy.default

}

The `pulumi import` command can also be used:

```sh
$ pulumi import gcp:dataproc/clusterIAMMember:ClusterIAMMember default projects/{project}/regions/{region}/clusters/{cluster}
```

¦
cluster" The name or relative resource id of the cluster to manage IAM policies for.

For `gcp.dataproc.ClusterIAMMember` or `gcp.dataproc.ClusterIAMBinding`:
z
	conditionmBk:i
g
dataprocClusterIAMMemberCondition@gcp:dataproc/ClusterIAMMemberCondition:ClusterIAMMemberCondition
member" Identities that will be granted the privilege in `role`.
Each entry can have one of the following values:
* **allUsers**: A special identifier that represents anyone who is on the internet; with or without a Google account.
* **allAuthenticatedUsers**: A special identifier that represents anyone who is authenticated with a Google account or a service account.
* **user:{emailid}**: An email address that represents a specific Google account. For example, alice@gmail.com or joe@example.com.
* **serviceAccount:{emailid}**: An email address that represents a service account. For example, my-other-app@appspot.gserviceaccount.com.
* **group:{emailid}**: An email address that represents a Google group. For example, admins@example.com.
* **domain:{domain}**: A G Suite domain (primary, instead of alias) name that represents all the users of that domain. For example, google.com or example.com.
s
projectB" bThe project in which the cluster belongs. If it
is not provided, the provider will use a default.
q
regionB" aThe region in which the cluster belongs. If it
is not provided, the provider will use a default.
þ
role" ñThe role that should be applied. Only one
`gcp.dataproc.ClusterIAMBinding` can be used per role. Note that custom roles must be of the format
`[projects|organizations]/{parent-name}/roles/{role-name}`.

`gcp.dataproc.ClusterIAMPolicy` only:
"¦
cluster" The name or relative resource id of the cluster to manage IAM policies for.

For `gcp.dataproc.ClusterIAMMember` or `gcp.dataproc.ClusterIAMBinding`:
"z
	conditionmBk:i
g
dataprocClusterIAMMemberCondition@gcp:dataproc/ClusterIAMMemberCondition:ClusterIAMMemberCondition">
etag" 2(Computed) The etag of the clusters's IAM policy.
"
member" Identities that will be granted the privilege in `role`.
Each entry can have one of the following values:
* **allUsers**: A special identifier that represents anyone who is on the internet; with or without a Google account.
* **allAuthenticatedUsers**: A special identifier that represents anyone who is authenticated with a Google account or a service account.
* **user:{emailid}**: An email address that represents a specific Google account. For example, alice@gmail.com or joe@example.com.
* **serviceAccount:{emailid}**: An email address that represents a service account. For example, my-other-app@appspot.gserviceaccount.com.
* **group:{emailid}**: An email address that represents a Google group. For example, admins@example.com.
* **domain:{domain}**: A G Suite domain (primary, instead of alias) name that represents all the users of that domain. For example, google.com or example.com.
"q
project" bThe project in which the cluster belongs. If it
is not provided, the provider will use a default.
"o
region" aThe region in which the cluster belongs. If it
is not provided, the provider will use a default.
"þ
role" ñThe role that should be applied. Only one
`gcp.dataproc.ClusterIAMBinding` can be used per role. Note that custom roles must be of the format
`[projects|organizations]/{parent-name}/roles/{role-name}`.

`gcp.dataproc.ClusterIAMPolicy` only:
*ó¤
L
dataprocClusterIAMPolicy.gcp:dataproc/clusterIAMPolicy:ClusterIAMPolicyóThree different resources help you manage IAM policies on dataproc clusters. Each of these resources serves a different use case:

* `gcp.dataproc.ClusterIAMPolicy`: Authoritative. Sets the IAM policy for the cluster and replaces any existing policy already attached.
* `gcp.dataproc.ClusterIAMBinding`: Authoritative for a given role. Updates the IAM policy to grant a role to a list of members. Other roles within the IAM policy for the cluster are preserved.
* `gcp.dataproc.ClusterIAMMember`: Non-authoritative. Updates the IAM policy to grant a role to a new member. Other members for the role for the cluster are preserved.

> **Note:** `gcp.dataproc.ClusterIAMPolicy` **cannot** be used in conjunction with `gcp.dataproc.ClusterIAMBinding` and `gcp.dataproc.ClusterIAMMember` or they will fight over what your policy should be. In addition, be careful not to accidentally unset ownership of the cluster as `gcp.dataproc.ClusterIAMPolicy` replaces the entire policy.

> **Note:** `gcp.dataproc.ClusterIAMBinding` resources **can be** used in conjunction with `gcp.dataproc.ClusterIAMMember` resources **only if** they do not grant privilege to the same role.

## gcp.dataproc.ClusterIAMPolicy

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const admin = gcp.organizations.getIAMPolicy({
    bindings: [{
        role: "roles/editor",
        members: ["user:jane@example.com"],
    }],
});
const editor = new gcp.dataproc.ClusterIAMPolicy("editor", {
    project: "your-project",
    region: "your-region",
    cluster: "your-dataproc-cluster",
    policyData: admin.then(admin => admin.policyData),
});
```
```python
import pulumi
import pulumi_gcp as gcp

admin = gcp.organizations.get_iam_policy(bindings=[{
    "role": "roles/editor",
    "members": ["user:jane@example.com"],
}])
editor = gcp.dataproc.ClusterIAMPolicy("editor",
    project="your-project",
    region="your-region",
    cluster="your-dataproc-cluster",
    policy_data=admin.policy_data)
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var admin = Gcp.Organizations.GetIAMPolicy.Invoke(new()
    {
        Bindings = new[]
        {
            new Gcp.Organizations.Inputs.GetIAMPolicyBindingInputArgs
            {
                Role = "roles/editor",
                Members = new[]
                {
                    "user:jane@example.com",
                },
            },
        },
    });

    var editor = new Gcp.Dataproc.ClusterIAMPolicy("editor", new()
    {
        Project = "your-project",
        Region = "your-region",
        Cluster = "your-dataproc-cluster",
        PolicyData = admin.Apply(getIAMPolicyResult => getIAMPolicyResult.PolicyData),
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/dataproc"
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/organizations"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		admin, err := organizations.LookupIAMPolicy(ctx, &organizations.LookupIAMPolicyArgs{
			Bindings: []organizations.GetIAMPolicyBinding{
				{
					Role: "roles/editor",
					Members: []string{
						"user:jane@example.com",
					},
				},
			},
		}, nil)
		if err != nil {
			return err
		}
		_, err = dataproc.NewClusterIAMPolicy(ctx, "editor", &dataproc.ClusterIAMPolicyArgs{
			Project:    pulumi.String("your-project"),
			Region:     pulumi.String("your-region"),
			Cluster:    pulumi.String("your-dataproc-cluster"),
			PolicyData: pulumi.String(admin.PolicyData),
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.organizations.OrganizationsFunctions;
import com.pulumi.gcp.organizations.inputs.GetIAMPolicyArgs;
import com.pulumi.gcp.dataproc.ClusterIAMPolicy;
import com.pulumi.gcp.dataproc.ClusterIAMPolicyArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        final var admin = OrganizationsFunctions.getIAMPolicy(GetIAMPolicyArgs.builder()
            .bindings(GetIAMPolicyBindingArgs.builder()
                .role("roles/editor")
                .members("user:jane@example.com")
                .build())
            .build());

        var editor = new ClusterIAMPolicy("editor", ClusterIAMPolicyArgs.builder()
            .project("your-project")
            .region("your-region")
            .cluster("your-dataproc-cluster")
            .policyData(admin.applyValue(getIAMPolicyResult -> getIAMPolicyResult.policyData()))
            .build());

    }
}
```
```yaml
resources:
  editor:
    type: gcp:dataproc:ClusterIAMPolicy
    properties:
      project: your-project
      region: your-region
      cluster: your-dataproc-cluster
      policyData: ${admin.policyData}
variables:
  admin:
    fn::invoke:
      function: gcp:organizations:getIAMPolicy
      arguments:
        bindings:
          - role: roles/editor
            members:
              - user:jane@example.com
```
<!--End PulumiCodeChooser -->

## gcp.dataproc.ClusterIAMBinding

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const editor = new gcp.dataproc.ClusterIAMBinding("editor", {
    cluster: "your-dataproc-cluster",
    role: "roles/editor",
    members: ["user:jane@example.com"],
});
```
```python
import pulumi
import pulumi_gcp as gcp

editor = gcp.dataproc.ClusterIAMBinding("editor",
    cluster="your-dataproc-cluster",
    role="roles/editor",
    members=["user:jane@example.com"])
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var editor = new Gcp.Dataproc.ClusterIAMBinding("editor", new()
    {
        Cluster = "your-dataproc-cluster",
        Role = "roles/editor",
        Members = new[]
        {
            "user:jane@example.com",
        },
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/dataproc"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		_, err := dataproc.NewClusterIAMBinding(ctx, "editor", &dataproc.ClusterIAMBindingArgs{
			Cluster: pulumi.String("your-dataproc-cluster"),
			Role:    pulumi.String("roles/editor"),
			Members: pulumi.StringArray{
				pulumi.String("user:jane@example.com"),
			},
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.dataproc.ClusterIAMBinding;
import com.pulumi.gcp.dataproc.ClusterIAMBindingArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        var editor = new ClusterIAMBinding("editor", ClusterIAMBindingArgs.builder()
            .cluster("your-dataproc-cluster")
            .role("roles/editor")
            .members("user:jane@example.com")
            .build());

    }
}
```
```yaml
resources:
  editor:
    type: gcp:dataproc:ClusterIAMBinding
    properties:
      cluster: your-dataproc-cluster
      role: roles/editor
      members:
        - user:jane@example.com
```
<!--End PulumiCodeChooser -->

## gcp.dataproc.ClusterIAMMember

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const editor = new gcp.dataproc.ClusterIAMMember("editor", {
    cluster: "your-dataproc-cluster",
    role: "roles/editor",
    member: "user:jane@example.com",
});
```
```python
import pulumi
import pulumi_gcp as gcp

editor = gcp.dataproc.ClusterIAMMember("editor",
    cluster="your-dataproc-cluster",
    role="roles/editor",
    member="user:jane@example.com")
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var editor = new Gcp.Dataproc.ClusterIAMMember("editor", new()
    {
        Cluster = "your-dataproc-cluster",
        Role = "roles/editor",
        Member = "user:jane@example.com",
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/dataproc"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		_, err := dataproc.NewClusterIAMMember(ctx, "editor", &dataproc.ClusterIAMMemberArgs{
			Cluster: pulumi.String("your-dataproc-cluster"),
			Role:    pulumi.String("roles/editor"),
			Member:  pulumi.String("user:jane@example.com"),
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.dataproc.ClusterIAMMember;
import com.pulumi.gcp.dataproc.ClusterIAMMemberArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        var editor = new ClusterIAMMember("editor", ClusterIAMMemberArgs.builder()
            .cluster("your-dataproc-cluster")
            .role("roles/editor")
            .member("user:jane@example.com")
            .build());

    }
}
```
```yaml
resources:
  editor:
    type: gcp:dataproc:ClusterIAMMember
    properties:
      cluster: your-dataproc-cluster
      role: roles/editor
      member: user:jane@example.com
```
<!--End PulumiCodeChooser -->

## gcp.dataproc.ClusterIAMPolicy

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const admin = gcp.organizations.getIAMPolicy({
    bindings: [{
        role: "roles/editor",
        members: ["user:jane@example.com"],
    }],
});
const editor = new gcp.dataproc.ClusterIAMPolicy("editor", {
    project: "your-project",
    region: "your-region",
    cluster: "your-dataproc-cluster",
    policyData: admin.then(admin => admin.policyData),
});
```
```python
import pulumi
import pulumi_gcp as gcp

admin = gcp.organizations.get_iam_policy(bindings=[{
    "role": "roles/editor",
    "members": ["user:jane@example.com"],
}])
editor = gcp.dataproc.ClusterIAMPolicy("editor",
    project="your-project",
    region="your-region",
    cluster="your-dataproc-cluster",
    policy_data=admin.policy_data)
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var admin = Gcp.Organizations.GetIAMPolicy.Invoke(new()
    {
        Bindings = new[]
        {
            new Gcp.Organizations.Inputs.GetIAMPolicyBindingInputArgs
            {
                Role = "roles/editor",
                Members = new[]
                {
                    "user:jane@example.com",
                },
            },
        },
    });

    var editor = new Gcp.Dataproc.ClusterIAMPolicy("editor", new()
    {
        Project = "your-project",
        Region = "your-region",
        Cluster = "your-dataproc-cluster",
        PolicyData = admin.Apply(getIAMPolicyResult => getIAMPolicyResult.PolicyData),
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/dataproc"
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/organizations"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		admin, err := organizations.LookupIAMPolicy(ctx, &organizations.LookupIAMPolicyArgs{
			Bindings: []organizations.GetIAMPolicyBinding{
				{
					Role: "roles/editor",
					Members: []string{
						"user:jane@example.com",
					},
				},
			},
		}, nil)
		if err != nil {
			return err
		}
		_, err = dataproc.NewClusterIAMPolicy(ctx, "editor", &dataproc.ClusterIAMPolicyArgs{
			Project:    pulumi.String("your-project"),
			Region:     pulumi.String("your-region"),
			Cluster:    pulumi.String("your-dataproc-cluster"),
			PolicyData: pulumi.String(admin.PolicyData),
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.organizations.OrganizationsFunctions;
import com.pulumi.gcp.organizations.inputs.GetIAMPolicyArgs;
import com.pulumi.gcp.dataproc.ClusterIAMPolicy;
import com.pulumi.gcp.dataproc.ClusterIAMPolicyArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        final var admin = OrganizationsFunctions.getIAMPolicy(GetIAMPolicyArgs.builder()
            .bindings(GetIAMPolicyBindingArgs.builder()
                .role("roles/editor")
                .members("user:jane@example.com")
                .build())
            .build());

        var editor = new ClusterIAMPolicy("editor", ClusterIAMPolicyArgs.builder()
            .project("your-project")
            .region("your-region")
            .cluster("your-dataproc-cluster")
            .policyData(admin.applyValue(getIAMPolicyResult -> getIAMPolicyResult.policyData()))
            .build());

    }
}
```
```yaml
resources:
  editor:
    type: gcp:dataproc:ClusterIAMPolicy
    properties:
      project: your-project
      region: your-region
      cluster: your-dataproc-cluster
      policyData: ${admin.policyData}
variables:
  admin:
    fn::invoke:
      function: gcp:organizations:getIAMPolicy
      arguments:
        bindings:
          - role: roles/editor
            members:
              - user:jane@example.com
```
<!--End PulumiCodeChooser -->

## gcp.dataproc.ClusterIAMBinding

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const editor = new gcp.dataproc.ClusterIAMBinding("editor", {
    cluster: "your-dataproc-cluster",
    role: "roles/editor",
    members: ["user:jane@example.com"],
});
```
```python
import pulumi
import pulumi_gcp as gcp

editor = gcp.dataproc.ClusterIAMBinding("editor",
    cluster="your-dataproc-cluster",
    role="roles/editor",
    members=["user:jane@example.com"])
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var editor = new Gcp.Dataproc.ClusterIAMBinding("editor", new()
    {
        Cluster = "your-dataproc-cluster",
        Role = "roles/editor",
        Members = new[]
        {
            "user:jane@example.com",
        },
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/dataproc"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		_, err := dataproc.NewClusterIAMBinding(ctx, "editor", &dataproc.ClusterIAMBindingArgs{
			Cluster: pulumi.String("your-dataproc-cluster"),
			Role:    pulumi.String("roles/editor"),
			Members: pulumi.StringArray{
				pulumi.String("user:jane@example.com"),
			},
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.dataproc.ClusterIAMBinding;
import com.pulumi.gcp.dataproc.ClusterIAMBindingArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        var editor = new ClusterIAMBinding("editor", ClusterIAMBindingArgs.builder()
            .cluster("your-dataproc-cluster")
            .role("roles/editor")
            .members("user:jane@example.com")
            .build());

    }
}
```
```yaml
resources:
  editor:
    type: gcp:dataproc:ClusterIAMBinding
    properties:
      cluster: your-dataproc-cluster
      role: roles/editor
      members:
        - user:jane@example.com
```
<!--End PulumiCodeChooser -->

## gcp.dataproc.ClusterIAMMember

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const editor = new gcp.dataproc.ClusterIAMMember("editor", {
    cluster: "your-dataproc-cluster",
    role: "roles/editor",
    member: "user:jane@example.com",
});
```
```python
import pulumi
import pulumi_gcp as gcp

editor = gcp.dataproc.ClusterIAMMember("editor",
    cluster="your-dataproc-cluster",
    role="roles/editor",
    member="user:jane@example.com")
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var editor = new Gcp.Dataproc.ClusterIAMMember("editor", new()
    {
        Cluster = "your-dataproc-cluster",
        Role = "roles/editor",
        Member = "user:jane@example.com",
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/dataproc"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		_, err := dataproc.NewClusterIAMMember(ctx, "editor", &dataproc.ClusterIAMMemberArgs{
			Cluster: pulumi.String("your-dataproc-cluster"),
			Role:    pulumi.String("roles/editor"),
			Member:  pulumi.String("user:jane@example.com"),
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.dataproc.ClusterIAMMember;
import com.pulumi.gcp.dataproc.ClusterIAMMemberArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        var editor = new ClusterIAMMember("editor", ClusterIAMMemberArgs.builder()
            .cluster("your-dataproc-cluster")
            .role("roles/editor")
            .member("user:jane@example.com")
            .build());

    }
}
```
```yaml
resources:
  editor:
    type: gcp:dataproc:ClusterIAMMember
    properties:
      cluster: your-dataproc-cluster
      role: roles/editor
      member: user:jane@example.com
```
<!--End PulumiCodeChooser -->

## Import

### Importing IAM policies

IAM policy imports use the `cluster` identifier of the Dataproc Cluster resource only. For example:

* `projects/{project}/regions/{region}/clusters/{cluster}`

An `import` block (Terraform v1.5.0 and later) can be used to import IAM policies:

tf

import {

  id = projects/{project}/regions/{region}/clusters/{cluster}

  to = google_dataproc_cluster_iam_policy.default

}

The `pulumi import` command can also be used:

```sh
$ pulumi import gcp:dataproc/clusterIAMPolicy:ClusterIAMPolicy default projects/{project}/regions/{region}/clusters/{cluster}
```

¦
cluster" The name or relative resource id of the cluster to manage IAM policies for.

For `gcp.dataproc.ClusterIAMMember` or `gcp.dataproc.ClusterIAMBinding`:
f

policyData" TThe policy data generated by a `gcp.organizations.getIAMPolicy` data source.

- - -
s
projectB" bThe project in which the cluster belongs. If it
is not provided, the provider will use a default.
q
regionB" aThe region in which the cluster belongs. If it
is not provided, the provider will use a default.
"¦
cluster" The name or relative resource id of the cluster to manage IAM policies for.

For `gcp.dataproc.ClusterIAMMember` or `gcp.dataproc.ClusterIAMBinding`:
">
etag" 2(Computed) The etag of the clusters's IAM policy.
"f

policyData" TThe policy data generated by a `gcp.organizations.getIAMPolicy` data source.

- - -
"q
project" bThe project in which the cluster belongs. If it
is not provided, the provider will use a default.
"o
region" aThe region in which the cluster belongs. If it
is not provided, the provider will use a default.
*u
g
dataprocGdcApplicationEnvironment@gcp:dataproc/gdcApplicationEnvironment:GdcApplicationEnvironmentTAn ApplicationEnvironment contains shared configuration that may be referenced by multiple SparkApplications.


To get more information about ApplicationEnvironment, see:

* [API documentation](https://cloud.google.com/dataproc-gdc/docs/reference/rest/v1/projects.locations.applicationEnvironments)
* How-to Guides
    * [Dataproc Intro](https://cloud.google.com/dataproc/)

## Example Usage

### Dataprocgdc Applicationenvironment Basic


<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const application_environment = new gcp.dataproc.GdcApplicationEnvironment("application-environment", {
    applicationEnvironmentId: "dp-tf-e2e-application-environment-basic",
    serviceinstance: "do-not-delete-dataproc-gdc-instance",
    project: "my-project",
    location: "us-west2",
    namespace: "default",
});
```
```python
import pulumi
import pulumi_gcp as gcp

application_environment = gcp.dataproc.GdcApplicationEnvironment("application-environment",
    application_environment_id="dp-tf-e2e-application-environment-basic",
    serviceinstance="do-not-delete-dataproc-gdc-instance",
    project="my-project",
    location="us-west2",
    namespace="default")
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var application_environment = new Gcp.Dataproc.GdcApplicationEnvironment("application-environment", new()
    {
        ApplicationEnvironmentId = "dp-tf-e2e-application-environment-basic",
        Serviceinstance = "do-not-delete-dataproc-gdc-instance",
        Project = "my-project",
        Location = "us-west2",
        Namespace = "default",
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/dataproc"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		_, err := dataproc.NewGdcApplicationEnvironment(ctx, "application-environment", &dataproc.GdcApplicationEnvironmentArgs{
			ApplicationEnvironmentId: pulumi.String("dp-tf-e2e-application-environment-basic"),
			Serviceinstance:          pulumi.String("do-not-delete-dataproc-gdc-instance"),
			Project:                  pulumi.String("my-project"),
			Location:                 pulumi.String("us-west2"),
			Namespace:                pulumi.String("default"),
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.dataproc.GdcApplicationEnvironment;
import com.pulumi.gcp.dataproc.GdcApplicationEnvironmentArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        var application_environment = new GdcApplicationEnvironment("application-environment", GdcApplicationEnvironmentArgs.builder()
            .applicationEnvironmentId("dp-tf-e2e-application-environment-basic")
            .serviceinstance("do-not-delete-dataproc-gdc-instance")
            .project("my-project")
            .location("us-west2")
            .namespace("default")
            .build());

    }
}
```
```yaml
resources:
  application-environment:
    type: gcp:dataproc:GdcApplicationEnvironment
    properties:
      applicationEnvironmentId: dp-tf-e2e-application-environment-basic
      serviceinstance: do-not-delete-dataproc-gdc-instance
      project: my-project
      location: us-west2
      namespace: default
```
<!--End PulumiCodeChooser -->
### Dataprocgdc Applicationenvironment


<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const application_environment = new gcp.dataproc.GdcApplicationEnvironment("application-environment", {
    applicationEnvironmentId: "dp-tf-e2e-application-environment",
    serviceinstance: "do-not-delete-dataproc-gdc-instance",
    project: "my-project",
    location: "us-west2",
    namespace: "default",
    displayName: "An application environment",
    labels: {
        "test-label": "label-value",
    },
    annotations: {
        an_annotation: "annotation_value",
    },
    sparkApplicationEnvironmentConfig: {
        defaultProperties: {
            "spark.executor.memory": "4g",
        },
        defaultVersion: "1.2",
    },
});
```
```python
import pulumi
import pulumi_gcp as gcp

application_environment = gcp.dataproc.GdcApplicationEnvironment("application-environment",
    application_environment_id="dp-tf-e2e-application-environment",
    serviceinstance="do-not-delete-dataproc-gdc-instance",
    project="my-project",
    location="us-west2",
    namespace="default",
    display_name="An application environment",
    labels={
        "test-label": "label-value",
    },
    annotations={
        "an_annotation": "annotation_value",
    },
    spark_application_environment_config={
        "default_properties": {
            "spark.executor.memory": "4g",
        },
        "default_version": "1.2",
    })
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var application_environment = new Gcp.Dataproc.GdcApplicationEnvironment("application-environment", new()
    {
        ApplicationEnvironmentId = "dp-tf-e2e-application-environment",
        Serviceinstance = "do-not-delete-dataproc-gdc-instance",
        Project = "my-project",
        Location = "us-west2",
        Namespace = "default",
        DisplayName = "An application environment",
        Labels = 
        {
            { "test-label", "label-value" },
        },
        Annotations = 
        {
            { "an_annotation", "annotation_value" },
        },
        SparkApplicationEnvironmentConfig = new Gcp.Dataproc.Inputs.GdcApplicationEnvironmentSparkApplicationEnvironmentConfigArgs
        {
            DefaultProperties = 
            {
                { "spark.executor.memory", "4g" },
            },
            DefaultVersion = "1.2",
        },
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/dataproc"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		_, err := dataproc.NewGdcApplicationEnvironment(ctx, "application-environment", &dataproc.GdcApplicationEnvironmentArgs{
			ApplicationEnvironmentId: pulumi.String("dp-tf-e2e-application-environment"),
			Serviceinstance:          pulumi.String("do-not-delete-dataproc-gdc-instance"),
			Project:                  pulumi.String("my-project"),
			Location:                 pulumi.String("us-west2"),
			Namespace:                pulumi.String("default"),
			DisplayName:              pulumi.String("An application environment"),
			Labels: pulumi.StringMap{
				"test-label": pulumi.String("label-value"),
			},
			Annotations: pulumi.StringMap{
				"an_annotation": pulumi.String("annotation_value"),
			},
			SparkApplicationEnvironmentConfig: &dataproc.GdcApplicationEnvironmentSparkApplicationEnvironmentConfigArgs{
				DefaultProperties: pulumi.StringMap{
					"spark.executor.memory": pulumi.String("4g"),
				},
				DefaultVersion: pulumi.String("1.2"),
			},
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.dataproc.GdcApplicationEnvironment;
import com.pulumi.gcp.dataproc.GdcApplicationEnvironmentArgs;
import com.pulumi.gcp.dataproc.inputs.GdcApplicationEnvironmentSparkApplicationEnvironmentConfigArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        var application_environment = new GdcApplicationEnvironment("application-environment", GdcApplicationEnvironmentArgs.builder()
            .applicationEnvironmentId("dp-tf-e2e-application-environment")
            .serviceinstance("do-not-delete-dataproc-gdc-instance")
            .project("my-project")
            .location("us-west2")
            .namespace("default")
            .displayName("An application environment")
            .labels(Map.of("test-label", "label-value"))
            .annotations(Map.of("an_annotation", "annotation_value"))
            .sparkApplicationEnvironmentConfig(GdcApplicationEnvironmentSparkApplicationEnvironmentConfigArgs.builder()
                .defaultProperties(Map.of("spark.executor.memory", "4g"))
                .defaultVersion("1.2")
                .build())
            .build());

    }
}
```
```yaml
resources:
  application-environment:
    type: gcp:dataproc:GdcApplicationEnvironment
    properties:
      applicationEnvironmentId: dp-tf-e2e-application-environment
      serviceinstance: do-not-delete-dataproc-gdc-instance
      project: my-project
      location: us-west2
      namespace: default
      displayName: An application environment
      labels:
        test-label: label-value
      annotations:
        an_annotation: annotation_value
      sparkApplicationEnvironmentConfig:
        defaultProperties:
          spark.executor.memory: 4g
        defaultVersion: '1.2'
```
<!--End PulumiCodeChooser -->

## Import

ApplicationEnvironment can be imported using any of these accepted formats:

* `projects/{{project}}/locations/{{location}}/serviceInstances/{{serviceinstance}}/applicationEnvironments/{{application_environment_id}}`

* `{{project}}/{{location}}/{{serviceinstance}}/{{application_environment_id}}`

* `{{location}}/{{serviceinstance}}/{{application_environment_id}}`

When using the `pulumi import` command, ApplicationEnvironment can be imported using one of the formats above. For example:

```sh
$ pulumi import gcp:dataproc/gdcApplicationEnvironment:GdcApplicationEnvironment default projects/{{project}}/locations/{{location}}/serviceInstances/{{serviceinstance}}/applicationEnvironments/{{application_environment_id}}
```

```sh
$ pulumi import gcp:dataproc/gdcApplicationEnvironment:GdcApplicationEnvironment default {{project}}/{{location}}/{{serviceinstance}}/{{application_environment_id}}
```

```sh
$ pulumi import gcp:dataproc/gdcApplicationEnvironment:GdcApplicationEnvironment default {{location}}/{{serviceinstance}}/{{application_environment_id}}
```


annotationsB2" êThe annotations to associate with this application environment. Annotations may be used to store client information, but are not used by the server.
**Note**: This field is non-authoritative, and will only manage the annotations present in your configuration.
Please refer to the field `effective_annotations` for all of the annotations present on the resource.
H
applicationEnvironmentIdB" &The id of the application environment
V
displayNameB" AUser-provided human-readable name to be used in user interfaces.
Ë
labelsB2" ¸The labels to associate with this application environment. Labels may be used for filtering and billing tracking.
**Note**: This field is non-authoritative, and will only manage the labels present in your configuration.
Please refer to the field `effective_labels` for all of the labels present on the resource.
<
location" ,The location of the application environment

	namespaceB" {The name of the namespace in which to create this ApplicationEnvironment. This namespace must already exist in the cluster
{
projectB" jThe ID of the project in which the resource belongs.
If it is not provided, the provider project is used.
m
serviceinstance" VThe id of the service instance to which this application environment belongs.


- - -
Í
!sparkApplicationEnvironmentConfigÔBÑ:Î
Ë
dataproc:GdcApplicationEnvironmentSparkApplicationEnvironmentConfiggcp:dataproc/GdcApplicationEnvironmentSparkApplicationEnvironmentConfig:GdcApplicationEnvironmentSparkApplicationEnvironmentConfigQRepresents the SparkApplicationEnvironmentConfig.
Structure is documented below.
"
annotationsB2" êThe annotations to associate with this application environment. Annotations may be used to store client information, but are not used by the server.
**Note**: This field is non-authoritative, and will only manage the annotations present in your configuration.
Please refer to the field `effective_annotations` for all of the annotations present on the resource.
"H
applicationEnvironmentIdB" &The id of the application environment
"?

createTime" -The timestamp when the resource was created.
"V
displayNameB" AUser-provided human-readable name to be used in user interfaces.
"
effectiveAnnotations2" "¦
effectiveLabels2" All of labels (key/value pairs) present on the resource in GCP, including the labels configured through Pulumi, other clients and services.
"Ë
labelsB2" ¸The labels to associate with this application environment. Labels may be used for filtering and billing tracking.
**Note**: This field is non-authoritative, and will only manage the labels present in your configuration.
Please refer to the field `effective_labels` for all of the labels present on the resource.
"<
location" ,The location of the application environment
"Ë
name" ¾Identifier. The name of the application environment. Format: projects/{project}/locations/{location}/serviceInstances/{service_instance}/applicationEnvironments/{application_environment_id}
"
	namespaceB" {The name of the namespace in which to create this ApplicationEnvironment. This namespace must already exist in the cluster
"y
project" jThe ID of the project in which the resource belongs.
If it is not provided, the provider project is used.
"
pulumiLabels2" mThe combination of labels configured directly on the resource
and default labels configured on the provider.
"m
serviceinstance" VThe id of the service instance to which this application environment belongs.


- - -
"Í
!sparkApplicationEnvironmentConfigÔBÑ:Î
Ë
dataproc:GdcApplicationEnvironmentSparkApplicationEnvironmentConfiggcp:dataproc/GdcApplicationEnvironmentSparkApplicationEnvironmentConfig:GdcApplicationEnvironmentSparkApplicationEnvironmentConfigQRepresents the SparkApplicationEnvironmentConfig.
Structure is documented below.
"d
uid" YSystem generated unique identifier for this application environment, formatted as UUID4.
"M

updateTime" ;The timestamp when the resource was most recently updated.
*¿N
R
dataprocGdcServiceInstance2gcp:dataproc/gdcServiceInstance:GdcServiceInstanceþ.A service instance is an instance of the Dataproc operator running on a GDC cluster.


To get more information about ServiceInstance, see:

* [API documentation](https://cloud.google.com/dataproc-gdc/docs/reference/rest/v1/projects.locations.serviceInstances)
* How-to Guides
    * [Dataproc Intro](https://cloud.google.com/dataproc/)

## Example Usage

### Dataprocgdc Serviceinstance


<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const service_instance = new gcp.dataproc.GdcServiceInstance("service-instance", {
    serviceInstanceId: "tf-e2e-service-instance",
    project: "my-project",
    location: "us-west2",
    gdceCluster: {
        gdceCluster: "projects/gdce-cluster-monitoring/locations/us-west2/clusters/gdce-prism-prober-ord106",
    },
    displayName: "A service instance",
    labels: {
        "test-label": "label-value",
    },
    serviceAccount: "dataprocgdc-cep-workflows@gdce-cluster-monitoring.iam.gserviceaccount.com",
});
```
```python
import pulumi
import pulumi_gcp as gcp

service_instance = gcp.dataproc.GdcServiceInstance("service-instance",
    service_instance_id="tf-e2e-service-instance",
    project="my-project",
    location="us-west2",
    gdce_cluster={
        "gdce_cluster": "projects/gdce-cluster-monitoring/locations/us-west2/clusters/gdce-prism-prober-ord106",
    },
    display_name="A service instance",
    labels={
        "test-label": "label-value",
    },
    service_account="dataprocgdc-cep-workflows@gdce-cluster-monitoring.iam.gserviceaccount.com")
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var service_instance = new Gcp.Dataproc.GdcServiceInstance("service-instance", new()
    {
        ServiceInstanceId = "tf-e2e-service-instance",
        Project = "my-project",
        Location = "us-west2",
        GdceCluster = new Gcp.Dataproc.Inputs.GdcServiceInstanceGdceClusterArgs
        {
            GdceCluster = "projects/gdce-cluster-monitoring/locations/us-west2/clusters/gdce-prism-prober-ord106",
        },
        DisplayName = "A service instance",
        Labels = 
        {
            { "test-label", "label-value" },
        },
        ServiceAccount = "dataprocgdc-cep-workflows@gdce-cluster-monitoring.iam.gserviceaccount.com",
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/dataproc"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		_, err := dataproc.NewGdcServiceInstance(ctx, "service-instance", &dataproc.GdcServiceInstanceArgs{
			ServiceInstanceId: pulumi.String("tf-e2e-service-instance"),
			Project:           pulumi.String("my-project"),
			Location:          pulumi.String("us-west2"),
			GdceCluster: &dataproc.GdcServiceInstanceGdceClusterArgs{
				GdceCluster: pulumi.String("projects/gdce-cluster-monitoring/locations/us-west2/clusters/gdce-prism-prober-ord106"),
			},
			DisplayName: pulumi.String("A service instance"),
			Labels: pulumi.StringMap{
				"test-label": pulumi.String("label-value"),
			},
			ServiceAccount: pulumi.String("dataprocgdc-cep-workflows@gdce-cluster-monitoring.iam.gserviceaccount.com"),
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.dataproc.GdcServiceInstance;
import com.pulumi.gcp.dataproc.GdcServiceInstanceArgs;
import com.pulumi.gcp.dataproc.inputs.GdcServiceInstanceGdceClusterArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        var service_instance = new GdcServiceInstance("service-instance", GdcServiceInstanceArgs.builder()
            .serviceInstanceId("tf-e2e-service-instance")
            .project("my-project")
            .location("us-west2")
            .gdceCluster(GdcServiceInstanceGdceClusterArgs.builder()
                .gdceCluster("projects/gdce-cluster-monitoring/locations/us-west2/clusters/gdce-prism-prober-ord106")
                .build())
            .displayName("A service instance")
            .labels(Map.of("test-label", "label-value"))
            .serviceAccount("dataprocgdc-cep-workflows@gdce-cluster-monitoring.iam.gserviceaccount.com")
            .build());

    }
}
```
```yaml
resources:
  service-instance:
    type: gcp:dataproc:GdcServiceInstance
    properties:
      serviceInstanceId: tf-e2e-service-instance
      project: my-project
      location: us-west2
      gdceCluster:
        gdceCluster: projects/gdce-cluster-monitoring/locations/us-west2/clusters/gdce-prism-prober-ord106
      displayName: A service instance
      labels:
        test-label: label-value
      serviceAccount: dataprocgdc-cep-workflows@gdce-cluster-monitoring.iam.gserviceaccount.com
```
<!--End PulumiCodeChooser -->

## Import

ServiceInstance can be imported using any of these accepted formats:

* `projects/{{project}}/locations/{{location}}/serviceInstances/{{service_instance_id}}`

* `{{project}}/{{location}}/{{service_instance_id}}`

* `{{location}}/{{service_instance_id}}`

When using the `pulumi import` command, ServiceInstance can be imported using one of the formats above. For example:

```sh
$ pulumi import gcp:dataproc/gdcServiceInstance:GdcServiceInstance default projects/{{project}}/locations/{{location}}/serviceInstances/{{service_instance_id}}
```

```sh
$ pulumi import gcp:dataproc/gdcServiceInstance:GdcServiceInstance default {{project}}/{{location}}/{{service_instance_id}}
```

```sh
$ pulumi import gcp:dataproc/gdcServiceInstance:GdcServiceInstance default {{location}}/{{service_instance_id}}
```

V
displayNameB" AUser-provided human-readable name to be used in user interfaces.
Ã
gdceClusteryBw:u
s
dataprocGdcServiceInstanceGdceClusterHgcp:dataproc/GdcServiceInstanceGdceCluster:GdcServiceInstanceGdceCluster9Gdce cluster information.
Structure is documented below.
Ä
labelsB2" ±The labels to associate with this service instance. Labels may be used for filtering and billing tracking.
**Note**: This field is non-authoritative, and will only manage the labels present in your configuration.
Please refer to the field `effective_labels` for all of the labels present on the resource.
*
location" Location of the resource.
{
projectB" jThe ID of the project in which the resource belongs.
If it is not provided, the provider project is used.
U
serviceAccountB" =Requested service account to associate with ServiceInstance.
=
serviceInstanceId" $Id of the service instance.


- - -
ù
sparkServiceInstanceConfig©B¦:£
 
dataproc,GdcServiceInstanceSparkServiceInstanceConfigfgcp:dataproc/GdcServiceInstanceSparkServiceInstanceConfig:GdcServiceInstanceSparkServiceInstanceConfig/Spark-specific service instance configuration.
"?

createTime" -The timestamp when the resource was created.
"V
displayNameB" AUser-provided human-readable name to be used in user interfaces.
"¦
effectiveLabels2" All of labels (key/value pairs) present on the resource in GCP, including the labels configured through Pulumi, other clients and services.
"
effectiveServiceAccount" òEffective service account associated with ServiceInstance. This will be the service_account if specified. Otherwise, it will be an automatically created per-resource P4SA that also automatically has Fleet Workload. Identity bindings applied.
"Ã
gdceClusteryBw:u
s
dataprocGdcServiceInstanceGdceClusterHgcp:dataproc/GdcServiceInstanceGdceCluster:GdcServiceInstanceGdceCluster9Gdce cluster information.
Structure is documented below.
"Ä
labelsB2" ±The labels to associate with this service instance. Labels may be used for filtering and billing tracking.
**Note**: This field is non-authoritative, and will only manage the labels present in your configuration.
Please refer to the field `effective_labels` for all of the labels present on the resource.
"*
location" Location of the resource.
":
name" .Identifier. The name of the service instance.
"y
project" jThe ID of the project in which the resource belongs.
If it is not provided, the provider project is used.
"
pulumiLabels2" mThe combination of labels configured directly on the resource
and default labels configured on the provider.
"ó
reconciling
 ßWhether the service instance is currently reconciling. True if the current state of the resource does not match the intended state, and the system is working to reconcile them, whether or not the change was user initiated.
"Ý
requestedState" ÆThe intended state to which the service instance is reconciling. Possible values:
* `CREATING`
* `ACTIVE`
* `DISCONNECTED`
* `DELETING`
* `STOPPING`
* `STOPPED`
* `STARTING`
* `UPDATING`
* `FAILED`
"U
serviceAccountB" =Requested service account to associate with ServiceInstance.
"=
serviceInstanceId" $Id of the service instance.


- - -
"ù
sparkServiceInstanceConfig©B¦:£
 
dataproc,GdcServiceInstanceSparkServiceInstanceConfigfgcp:dataproc/GdcServiceInstanceSparkServiceInstanceConfig:GdcServiceInstanceSparkServiceInstanceConfig/Spark-specific service instance configuration.
"¦
state" The current state. Possible values:
* `CREATING`
* `ACTIVE`
* `DISCONNECTED`
* `DELETING`
* `STOPPING`
* `STOPPED`
* `STARTING`
* `UPDATING`
* `FAILED`
"<
stateMessage" (A message explaining the current state.
"]
uid" RSystem generated unique identifier for this service instance, formatted as UUID4.
"M

updateTime" ;The timestamp when the resource was most recently updated.
*öö
U
dataprocGdcSparkApplication4gcp:dataproc/gdcSparkApplication:GdcSparkApplicationÝ¾A Spark application is a single Spark workload run on a GDC cluster.


To get more information about SparkApplication, see:

* [API documentation](https://cloud.google.com/dataproc-gdc/docs/reference/rest/v1/projects.locations.serviceInstances.sparkApplications)
* How-to Guides
    * [Dataproc Intro](https://cloud.google.com/dataproc/)

## Example Usage

### Dataprocgdc Sparkapplication Basic


<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const spark_application = new gcp.dataproc.GdcSparkApplication("spark-application", {
    sparkApplicationId: "tf-e2e-spark-app-basic",
    serviceinstance: "do-not-delete-dataproc-gdc-instance",
    project: "my-project",
    location: "us-west2",
    namespace: "default",
    sparkApplicationConfig: {
        mainClass: "org.apache.spark.examples.SparkPi",
        jarFileUris: ["file:///usr/lib/spark/examples/jars/spark-examples.jar"],
        args: ["10000"],
    },
});
```
```python
import pulumi
import pulumi_gcp as gcp

spark_application = gcp.dataproc.GdcSparkApplication("spark-application",
    spark_application_id="tf-e2e-spark-app-basic",
    serviceinstance="do-not-delete-dataproc-gdc-instance",
    project="my-project",
    location="us-west2",
    namespace="default",
    spark_application_config={
        "main_class": "org.apache.spark.examples.SparkPi",
        "jar_file_uris": ["file:///usr/lib/spark/examples/jars/spark-examples.jar"],
        "args": ["10000"],
    })
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var spark_application = new Gcp.Dataproc.GdcSparkApplication("spark-application", new()
    {
        SparkApplicationId = "tf-e2e-spark-app-basic",
        Serviceinstance = "do-not-delete-dataproc-gdc-instance",
        Project = "my-project",
        Location = "us-west2",
        Namespace = "default",
        SparkApplicationConfig = new Gcp.Dataproc.Inputs.GdcSparkApplicationSparkApplicationConfigArgs
        {
            MainClass = "org.apache.spark.examples.SparkPi",
            JarFileUris = new[]
            {
                "file:///usr/lib/spark/examples/jars/spark-examples.jar",
            },
            Args = new[]
            {
                "10000",
            },
        },
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/dataproc"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		_, err := dataproc.NewGdcSparkApplication(ctx, "spark-application", &dataproc.GdcSparkApplicationArgs{
			SparkApplicationId: pulumi.String("tf-e2e-spark-app-basic"),
			Serviceinstance:    pulumi.String("do-not-delete-dataproc-gdc-instance"),
			Project:            pulumi.String("my-project"),
			Location:           pulumi.String("us-west2"),
			Namespace:          pulumi.String("default"),
			SparkApplicationConfig: &dataproc.GdcSparkApplicationSparkApplicationConfigArgs{
				MainClass: pulumi.String("org.apache.spark.examples.SparkPi"),
				JarFileUris: pulumi.StringArray{
					pulumi.String("file:///usr/lib/spark/examples/jars/spark-examples.jar"),
				},
				Args: pulumi.StringArray{
					pulumi.String("10000"),
				},
			},
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.dataproc.GdcSparkApplication;
import com.pulumi.gcp.dataproc.GdcSparkApplicationArgs;
import com.pulumi.gcp.dataproc.inputs.GdcSparkApplicationSparkApplicationConfigArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        var spark_application = new GdcSparkApplication("spark-application", GdcSparkApplicationArgs.builder()
            .sparkApplicationId("tf-e2e-spark-app-basic")
            .serviceinstance("do-not-delete-dataproc-gdc-instance")
            .project("my-project")
            .location("us-west2")
            .namespace("default")
            .sparkApplicationConfig(GdcSparkApplicationSparkApplicationConfigArgs.builder()
                .mainClass("org.apache.spark.examples.SparkPi")
                .jarFileUris("file:///usr/lib/spark/examples/jars/spark-examples.jar")
                .args("10000")
                .build())
            .build());

    }
}
```
```yaml
resources:
  spark-application:
    type: gcp:dataproc:GdcSparkApplication
    properties:
      sparkApplicationId: tf-e2e-spark-app-basic
      serviceinstance: do-not-delete-dataproc-gdc-instance
      project: my-project
      location: us-west2
      namespace: default
      sparkApplicationConfig:
        mainClass: org.apache.spark.examples.SparkPi
        jarFileUris:
          - file:///usr/lib/spark/examples/jars/spark-examples.jar
        args:
          - '10000'
```
<!--End PulumiCodeChooser -->
### Dataprocgdc Sparkapplication


<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const appEnv = new gcp.dataproc.GdcApplicationEnvironment("app_env", {
    applicationEnvironmentId: "tf-e2e-spark-app-env",
    serviceinstance: "do-not-delete-dataproc-gdc-instance",
    project: "my-project",
    location: "us-west2",
    namespace: "default",
});
const spark_application = new gcp.dataproc.GdcSparkApplication("spark-application", {
    sparkApplicationId: "tf-e2e-spark-app",
    serviceinstance: "do-not-delete-dataproc-gdc-instance",
    project: "my-project",
    location: "us-west2",
    namespace: "default",
    labels: {
        "test-label": "label-value",
    },
    annotations: {
        an_annotation: "annotation_value",
    },
    properties: {
        "spark.executor.instances": "2",
    },
    applicationEnvironment: appEnv.name,
    version: "1.2",
    sparkApplicationConfig: {
        mainJarFileUri: "file:///usr/lib/spark/examples/jars/spark-examples.jar",
        jarFileUris: ["file:///usr/lib/spark/examples/jars/spark-examples.jar"],
        archiveUris: ["file://usr/lib/spark/examples/spark-examples.jar"],
        fileUris: ["file:///usr/lib/spark/examples/jars/spark-examples.jar"],
    },
});
```
```python
import pulumi
import pulumi_gcp as gcp

app_env = gcp.dataproc.GdcApplicationEnvironment("app_env",
    application_environment_id="tf-e2e-spark-app-env",
    serviceinstance="do-not-delete-dataproc-gdc-instance",
    project="my-project",
    location="us-west2",
    namespace="default")
spark_application = gcp.dataproc.GdcSparkApplication("spark-application",
    spark_application_id="tf-e2e-spark-app",
    serviceinstance="do-not-delete-dataproc-gdc-instance",
    project="my-project",
    location="us-west2",
    namespace="default",
    labels={
        "test-label": "label-value",
    },
    annotations={
        "an_annotation": "annotation_value",
    },
    properties={
        "spark.executor.instances": "2",
    },
    application_environment=app_env.name,
    version="1.2",
    spark_application_config={
        "main_jar_file_uri": "file:///usr/lib/spark/examples/jars/spark-examples.jar",
        "jar_file_uris": ["file:///usr/lib/spark/examples/jars/spark-examples.jar"],
        "archive_uris": ["file://usr/lib/spark/examples/spark-examples.jar"],
        "file_uris": ["file:///usr/lib/spark/examples/jars/spark-examples.jar"],
    })
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var appEnv = new Gcp.Dataproc.GdcApplicationEnvironment("app_env", new()
    {
        ApplicationEnvironmentId = "tf-e2e-spark-app-env",
        Serviceinstance = "do-not-delete-dataproc-gdc-instance",
        Project = "my-project",
        Location = "us-west2",
        Namespace = "default",
    });

    var spark_application = new Gcp.Dataproc.GdcSparkApplication("spark-application", new()
    {
        SparkApplicationId = "tf-e2e-spark-app",
        Serviceinstance = "do-not-delete-dataproc-gdc-instance",
        Project = "my-project",
        Location = "us-west2",
        Namespace = "default",
        Labels = 
        {
            { "test-label", "label-value" },
        },
        Annotations = 
        {
            { "an_annotation", "annotation_value" },
        },
        Properties = 
        {
            { "spark.executor.instances", "2" },
        },
        ApplicationEnvironment = appEnv.Name,
        Version = "1.2",
        SparkApplicationConfig = new Gcp.Dataproc.Inputs.GdcSparkApplicationSparkApplicationConfigArgs
        {
            MainJarFileUri = "file:///usr/lib/spark/examples/jars/spark-examples.jar",
            JarFileUris = new[]
            {
                "file:///usr/lib/spark/examples/jars/spark-examples.jar",
            },
            ArchiveUris = new[]
            {
                "file://usr/lib/spark/examples/spark-examples.jar",
            },
            FileUris = new[]
            {
                "file:///usr/lib/spark/examples/jars/spark-examples.jar",
            },
        },
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/dataproc"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		appEnv, err := dataproc.NewGdcApplicationEnvironment(ctx, "app_env", &dataproc.GdcApplicationEnvironmentArgs{
			ApplicationEnvironmentId: pulumi.String("tf-e2e-spark-app-env"),
			Serviceinstance:          pulumi.String("do-not-delete-dataproc-gdc-instance"),
			Project:                  pulumi.String("my-project"),
			Location:                 pulumi.String("us-west2"),
			Namespace:                pulumi.String("default"),
		})
		if err != nil {
			return err
		}
		_, err = dataproc.NewGdcSparkApplication(ctx, "spark-application", &dataproc.GdcSparkApplicationArgs{
			SparkApplicationId: pulumi.String("tf-e2e-spark-app"),
			Serviceinstance:    pulumi.String("do-not-delete-dataproc-gdc-instance"),
			Project:            pulumi.String("my-project"),
			Location:           pulumi.String("us-west2"),
			Namespace:          pulumi.String("default"),
			Labels: pulumi.StringMap{
				"test-label": pulumi.String("label-value"),
			},
			Annotations: pulumi.StringMap{
				"an_annotation": pulumi.String("annotation_value"),
			},
			Properties: pulumi.StringMap{
				"spark.executor.instances": pulumi.String("2"),
			},
			ApplicationEnvironment: appEnv.Name,
			Version:                pulumi.String("1.2"),
			SparkApplicationConfig: &dataproc.GdcSparkApplicationSparkApplicationConfigArgs{
				MainJarFileUri: pulumi.String("file:///usr/lib/spark/examples/jars/spark-examples.jar"),
				JarFileUris: pulumi.StringArray{
					pulumi.String("file:///usr/lib/spark/examples/jars/spark-examples.jar"),
				},
				ArchiveUris: pulumi.StringArray{
					pulumi.String("file://usr/lib/spark/examples/spark-examples.jar"),
				},
				FileUris: pulumi.StringArray{
					pulumi.String("file:///usr/lib/spark/examples/jars/spark-examples.jar"),
				},
			},
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.dataproc.GdcApplicationEnvironment;
import com.pulumi.gcp.dataproc.GdcApplicationEnvironmentArgs;
import com.pulumi.gcp.dataproc.GdcSparkApplication;
import com.pulumi.gcp.dataproc.GdcSparkApplicationArgs;
import com.pulumi.gcp.dataproc.inputs.GdcSparkApplicationSparkApplicationConfigArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        var appEnv = new GdcApplicationEnvironment("appEnv", GdcApplicationEnvironmentArgs.builder()
            .applicationEnvironmentId("tf-e2e-spark-app-env")
            .serviceinstance("do-not-delete-dataproc-gdc-instance")
            .project("my-project")
            .location("us-west2")
            .namespace("default")
            .build());

        var spark_application = new GdcSparkApplication("spark-application", GdcSparkApplicationArgs.builder()
            .sparkApplicationId("tf-e2e-spark-app")
            .serviceinstance("do-not-delete-dataproc-gdc-instance")
            .project("my-project")
            .location("us-west2")
            .namespace("default")
            .labels(Map.of("test-label", "label-value"))
            .annotations(Map.of("an_annotation", "annotation_value"))
            .properties(Map.of("spark.executor.instances", "2"))
            .applicationEnvironment(appEnv.name())
            .version("1.2")
            .sparkApplicationConfig(GdcSparkApplicationSparkApplicationConfigArgs.builder()
                .mainJarFileUri("file:///usr/lib/spark/examples/jars/spark-examples.jar")
                .jarFileUris("file:///usr/lib/spark/examples/jars/spark-examples.jar")
                .archiveUris("file://usr/lib/spark/examples/spark-examples.jar")
                .fileUris("file:///usr/lib/spark/examples/jars/spark-examples.jar")
                .build())
            .build());

    }
}
```
```yaml
resources:
  appEnv:
    type: gcp:dataproc:GdcApplicationEnvironment
    name: app_env
    properties:
      applicationEnvironmentId: tf-e2e-spark-app-env
      serviceinstance: do-not-delete-dataproc-gdc-instance
      project: my-project
      location: us-west2
      namespace: default
  spark-application:
    type: gcp:dataproc:GdcSparkApplication
    properties:
      sparkApplicationId: tf-e2e-spark-app
      serviceinstance: do-not-delete-dataproc-gdc-instance
      project: my-project
      location: us-west2
      namespace: default
      labels:
        test-label: label-value
      annotations:
        an_annotation: annotation_value
      properties:
        spark.executor.instances: '2'
      applicationEnvironment: ${appEnv.name}
      version: '1.2'
      sparkApplicationConfig:
        mainJarFileUri: file:///usr/lib/spark/examples/jars/spark-examples.jar
        jarFileUris:
          - file:///usr/lib/spark/examples/jars/spark-examples.jar
        archiveUris:
          - file://usr/lib/spark/examples/spark-examples.jar
        fileUris:
          - file:///usr/lib/spark/examples/jars/spark-examples.jar
```
<!--End PulumiCodeChooser -->
### Dataprocgdc Sparkapplication Pyspark


<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const spark_application = new gcp.dataproc.GdcSparkApplication("spark-application", {
    sparkApplicationId: "tf-e2e-pyspark-app",
    serviceinstance: "do-not-delete-dataproc-gdc-instance",
    project: "my-project",
    location: "us-west2",
    namespace: "default",
    displayName: "A Pyspark application for a Terraform create test",
    dependencyImages: ["gcr.io/some/image"],
    pysparkApplicationConfig: {
        mainPythonFileUri: "gs://goog-dataproc-initialization-actions-us-west2/conda/test_conda.py",
        jarFileUris: ["file:///usr/lib/spark/examples/jars/spark-examples.jar"],
        pythonFileUris: ["gs://goog-dataproc-initialization-actions-us-west2/conda/get-sys-exec.py"],
        fileUris: ["file://usr/lib/spark/examples/spark-examples.jar"],
        archiveUris: ["file://usr/lib/spark/examples/spark-examples.jar"],
        args: ["10"],
    },
});
```
```python
import pulumi
import pulumi_gcp as gcp

spark_application = gcp.dataproc.GdcSparkApplication("spark-application",
    spark_application_id="tf-e2e-pyspark-app",
    serviceinstance="do-not-delete-dataproc-gdc-instance",
    project="my-project",
    location="us-west2",
    namespace="default",
    display_name="A Pyspark application for a Terraform create test",
    dependency_images=["gcr.io/some/image"],
    pyspark_application_config={
        "main_python_file_uri": "gs://goog-dataproc-initialization-actions-us-west2/conda/test_conda.py",
        "jar_file_uris": ["file:///usr/lib/spark/examples/jars/spark-examples.jar"],
        "python_file_uris": ["gs://goog-dataproc-initialization-actions-us-west2/conda/get-sys-exec.py"],
        "file_uris": ["file://usr/lib/spark/examples/spark-examples.jar"],
        "archive_uris": ["file://usr/lib/spark/examples/spark-examples.jar"],
        "args": ["10"],
    })
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var spark_application = new Gcp.Dataproc.GdcSparkApplication("spark-application", new()
    {
        SparkApplicationId = "tf-e2e-pyspark-app",
        Serviceinstance = "do-not-delete-dataproc-gdc-instance",
        Project = "my-project",
        Location = "us-west2",
        Namespace = "default",
        DisplayName = "A Pyspark application for a Terraform create test",
        DependencyImages = new[]
        {
            "gcr.io/some/image",
        },
        PysparkApplicationConfig = new Gcp.Dataproc.Inputs.GdcSparkApplicationPysparkApplicationConfigArgs
        {
            MainPythonFileUri = "gs://goog-dataproc-initialization-actions-us-west2/conda/test_conda.py",
            JarFileUris = new[]
            {
                "file:///usr/lib/spark/examples/jars/spark-examples.jar",
            },
            PythonFileUris = new[]
            {
                "gs://goog-dataproc-initialization-actions-us-west2/conda/get-sys-exec.py",
            },
            FileUris = new[]
            {
                "file://usr/lib/spark/examples/spark-examples.jar",
            },
            ArchiveUris = new[]
            {
                "file://usr/lib/spark/examples/spark-examples.jar",
            },
            Args = new[]
            {
                "10",
            },
        },
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/dataproc"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		_, err := dataproc.NewGdcSparkApplication(ctx, "spark-application", &dataproc.GdcSparkApplicationArgs{
			SparkApplicationId: pulumi.String("tf-e2e-pyspark-app"),
			Serviceinstance:    pulumi.String("do-not-delete-dataproc-gdc-instance"),
			Project:            pulumi.String("my-project"),
			Location:           pulumi.String("us-west2"),
			Namespace:          pulumi.String("default"),
			DisplayName:        pulumi.String("A Pyspark application for a Terraform create test"),
			DependencyImages: pulumi.StringArray{
				pulumi.String("gcr.io/some/image"),
			},
			PysparkApplicationConfig: &dataproc.GdcSparkApplicationPysparkApplicationConfigArgs{
				MainPythonFileUri: pulumi.String("gs://goog-dataproc-initialization-actions-us-west2/conda/test_conda.py"),
				JarFileUris: pulumi.StringArray{
					pulumi.String("file:///usr/lib/spark/examples/jars/spark-examples.jar"),
				},
				PythonFileUris: pulumi.StringArray{
					pulumi.String("gs://goog-dataproc-initialization-actions-us-west2/conda/get-sys-exec.py"),
				},
				FileUris: pulumi.StringArray{
					pulumi.String("file://usr/lib/spark/examples/spark-examples.jar"),
				},
				ArchiveUris: pulumi.StringArray{
					pulumi.String("file://usr/lib/spark/examples/spark-examples.jar"),
				},
				Args: pulumi.StringArray{
					pulumi.String("10"),
				},
			},
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.dataproc.GdcSparkApplication;
import com.pulumi.gcp.dataproc.GdcSparkApplicationArgs;
import com.pulumi.gcp.dataproc.inputs.GdcSparkApplicationPysparkApplicationConfigArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        var spark_application = new GdcSparkApplication("spark-application", GdcSparkApplicationArgs.builder()
            .sparkApplicationId("tf-e2e-pyspark-app")
            .serviceinstance("do-not-delete-dataproc-gdc-instance")
            .project("my-project")
            .location("us-west2")
            .namespace("default")
            .displayName("A Pyspark application for a Terraform create test")
            .dependencyImages("gcr.io/some/image")
            .pysparkApplicationConfig(GdcSparkApplicationPysparkApplicationConfigArgs.builder()
                .mainPythonFileUri("gs://goog-dataproc-initialization-actions-us-west2/conda/test_conda.py")
                .jarFileUris("file:///usr/lib/spark/examples/jars/spark-examples.jar")
                .pythonFileUris("gs://goog-dataproc-initialization-actions-us-west2/conda/get-sys-exec.py")
                .fileUris("file://usr/lib/spark/examples/spark-examples.jar")
                .archiveUris("file://usr/lib/spark/examples/spark-examples.jar")
                .args("10")
                .build())
            .build());

    }
}
```
```yaml
resources:
  spark-application:
    type: gcp:dataproc:GdcSparkApplication
    properties:
      sparkApplicationId: tf-e2e-pyspark-app
      serviceinstance: do-not-delete-dataproc-gdc-instance
      project: my-project
      location: us-west2
      namespace: default
      displayName: A Pyspark application for a Terraform create test
      dependencyImages:
        - gcr.io/some/image
      pysparkApplicationConfig:
        mainPythonFileUri: gs://goog-dataproc-initialization-actions-us-west2/conda/test_conda.py
        jarFileUris:
          - file:///usr/lib/spark/examples/jars/spark-examples.jar
        pythonFileUris:
          - gs://goog-dataproc-initialization-actions-us-west2/conda/get-sys-exec.py
        fileUris:
          - file://usr/lib/spark/examples/spark-examples.jar
        archiveUris:
          - file://usr/lib/spark/examples/spark-examples.jar
        args:
          - '10'
```
<!--End PulumiCodeChooser -->
### Dataprocgdc Sparkapplication Sparkr


<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const spark_application = new gcp.dataproc.GdcSparkApplication("spark-application", {
    sparkApplicationId: "tf-e2e-sparkr-app",
    serviceinstance: "do-not-delete-dataproc-gdc-instance",
    project: "my-project",
    location: "us-west2",
    namespace: "default",
    displayName: "A SparkR application for a Terraform create test",
    sparkRApplicationConfig: {
        mainRFileUri: "gs://some-bucket/something.R",
        fileUris: ["file://usr/lib/spark/examples/spark-examples.jar"],
        archiveUris: ["file://usr/lib/spark/examples/spark-examples.jar"],
        args: ["10"],
    },
});
```
```python
import pulumi
import pulumi_gcp as gcp

spark_application = gcp.dataproc.GdcSparkApplication("spark-application",
    spark_application_id="tf-e2e-sparkr-app",
    serviceinstance="do-not-delete-dataproc-gdc-instance",
    project="my-project",
    location="us-west2",
    namespace="default",
    display_name="A SparkR application for a Terraform create test",
    spark_r_application_config={
        "main_r_file_uri": "gs://some-bucket/something.R",
        "file_uris": ["file://usr/lib/spark/examples/spark-examples.jar"],
        "archive_uris": ["file://usr/lib/spark/examples/spark-examples.jar"],
        "args": ["10"],
    })
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var spark_application = new Gcp.Dataproc.GdcSparkApplication("spark-application", new()
    {
        SparkApplicationId = "tf-e2e-sparkr-app",
        Serviceinstance = "do-not-delete-dataproc-gdc-instance",
        Project = "my-project",
        Location = "us-west2",
        Namespace = "default",
        DisplayName = "A SparkR application for a Terraform create test",
        SparkRApplicationConfig = new Gcp.Dataproc.Inputs.GdcSparkApplicationSparkRApplicationConfigArgs
        {
            MainRFileUri = "gs://some-bucket/something.R",
            FileUris = new[]
            {
                "file://usr/lib/spark/examples/spark-examples.jar",
            },
            ArchiveUris = new[]
            {
                "file://usr/lib/spark/examples/spark-examples.jar",
            },
            Args = new[]
            {
                "10",
            },
        },
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/dataproc"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		_, err := dataproc.NewGdcSparkApplication(ctx, "spark-application", &dataproc.GdcSparkApplicationArgs{
			SparkApplicationId: pulumi.String("tf-e2e-sparkr-app"),
			Serviceinstance:    pulumi.String("do-not-delete-dataproc-gdc-instance"),
			Project:            pulumi.String("my-project"),
			Location:           pulumi.String("us-west2"),
			Namespace:          pulumi.String("default"),
			DisplayName:        pulumi.String("A SparkR application for a Terraform create test"),
			SparkRApplicationConfig: &dataproc.GdcSparkApplicationSparkRApplicationConfigArgs{
				MainRFileUri: pulumi.String("gs://some-bucket/something.R"),
				FileUris: pulumi.StringArray{
					pulumi.String("file://usr/lib/spark/examples/spark-examples.jar"),
				},
				ArchiveUris: pulumi.StringArray{
					pulumi.String("file://usr/lib/spark/examples/spark-examples.jar"),
				},
				Args: pulumi.StringArray{
					pulumi.String("10"),
				},
			},
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.dataproc.GdcSparkApplication;
import com.pulumi.gcp.dataproc.GdcSparkApplicationArgs;
import com.pulumi.gcp.dataproc.inputs.GdcSparkApplicationSparkRApplicationConfigArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        var spark_application = new GdcSparkApplication("spark-application", GdcSparkApplicationArgs.builder()
            .sparkApplicationId("tf-e2e-sparkr-app")
            .serviceinstance("do-not-delete-dataproc-gdc-instance")
            .project("my-project")
            .location("us-west2")
            .namespace("default")
            .displayName("A SparkR application for a Terraform create test")
            .sparkRApplicationConfig(GdcSparkApplicationSparkRApplicationConfigArgs.builder()
                .mainRFileUri("gs://some-bucket/something.R")
                .fileUris("file://usr/lib/spark/examples/spark-examples.jar")
                .archiveUris("file://usr/lib/spark/examples/spark-examples.jar")
                .args("10")
                .build())
            .build());

    }
}
```
```yaml
resources:
  spark-application:
    type: gcp:dataproc:GdcSparkApplication
    properties:
      sparkApplicationId: tf-e2e-sparkr-app
      serviceinstance: do-not-delete-dataproc-gdc-instance
      project: my-project
      location: us-west2
      namespace: default
      displayName: A SparkR application for a Terraform create test
      sparkRApplicationConfig:
        mainRFileUri: gs://some-bucket/something.R
        fileUris:
          - file://usr/lib/spark/examples/spark-examples.jar
        archiveUris:
          - file://usr/lib/spark/examples/spark-examples.jar
        args:
          - '10'
```
<!--End PulumiCodeChooser -->
### Dataprocgdc Sparkapplication Sparksql


<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const spark_application = new gcp.dataproc.GdcSparkApplication("spark-application", {
    sparkApplicationId: "tf-e2e-sparksql-app",
    serviceinstance: "do-not-delete-dataproc-gdc-instance",
    project: "my-project",
    location: "us-west2",
    namespace: "default",
    displayName: "A SparkSql application for a Terraform create test",
    sparkSqlApplicationConfig: {
        jarFileUris: ["file:///usr/lib/spark/examples/jars/spark-examples.jar"],
        queryList: {
            queries: ["show tables;"],
        },
        scriptVariables: {
            MY_VAR: "1",
        },
    },
});
```
```python
import pulumi
import pulumi_gcp as gcp

spark_application = gcp.dataproc.GdcSparkApplication("spark-application",
    spark_application_id="tf-e2e-sparksql-app",
    serviceinstance="do-not-delete-dataproc-gdc-instance",
    project="my-project",
    location="us-west2",
    namespace="default",
    display_name="A SparkSql application for a Terraform create test",
    spark_sql_application_config={
        "jar_file_uris": ["file:///usr/lib/spark/examples/jars/spark-examples.jar"],
        "query_list": {
            "queries": ["show tables;"],
        },
        "script_variables": {
            "MY_VAR": "1",
        },
    })
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var spark_application = new Gcp.Dataproc.GdcSparkApplication("spark-application", new()
    {
        SparkApplicationId = "tf-e2e-sparksql-app",
        Serviceinstance = "do-not-delete-dataproc-gdc-instance",
        Project = "my-project",
        Location = "us-west2",
        Namespace = "default",
        DisplayName = "A SparkSql application for a Terraform create test",
        SparkSqlApplicationConfig = new Gcp.Dataproc.Inputs.GdcSparkApplicationSparkSqlApplicationConfigArgs
        {
            JarFileUris = new[]
            {
                "file:///usr/lib/spark/examples/jars/spark-examples.jar",
            },
            QueryList = new Gcp.Dataproc.Inputs.GdcSparkApplicationSparkSqlApplicationConfigQueryListArgs
            {
                Queries = new[]
                {
                    "show tables;",
                },
            },
            ScriptVariables = 
            {
                { "MY_VAR", "1" },
            },
        },
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/dataproc"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		_, err := dataproc.NewGdcSparkApplication(ctx, "spark-application", &dataproc.GdcSparkApplicationArgs{
			SparkApplicationId: pulumi.String("tf-e2e-sparksql-app"),
			Serviceinstance:    pulumi.String("do-not-delete-dataproc-gdc-instance"),
			Project:            pulumi.String("my-project"),
			Location:           pulumi.String("us-west2"),
			Namespace:          pulumi.String("default"),
			DisplayName:        pulumi.String("A SparkSql application for a Terraform create test"),
			SparkSqlApplicationConfig: &dataproc.GdcSparkApplicationSparkSqlApplicationConfigArgs{
				JarFileUris: pulumi.StringArray{
					pulumi.String("file:///usr/lib/spark/examples/jars/spark-examples.jar"),
				},
				QueryList: &dataproc.GdcSparkApplicationSparkSqlApplicationConfigQueryListArgs{
					Queries: pulumi.StringArray{
						pulumi.String("show tables;"),
					},
				},
				ScriptVariables: pulumi.StringMap{
					"MY_VAR": pulumi.String("1"),
				},
			},
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.dataproc.GdcSparkApplication;
import com.pulumi.gcp.dataproc.GdcSparkApplicationArgs;
import com.pulumi.gcp.dataproc.inputs.GdcSparkApplicationSparkSqlApplicationConfigArgs;
import com.pulumi.gcp.dataproc.inputs.GdcSparkApplicationSparkSqlApplicationConfigQueryListArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        var spark_application = new GdcSparkApplication("spark-application", GdcSparkApplicationArgs.builder()
            .sparkApplicationId("tf-e2e-sparksql-app")
            .serviceinstance("do-not-delete-dataproc-gdc-instance")
            .project("my-project")
            .location("us-west2")
            .namespace("default")
            .displayName("A SparkSql application for a Terraform create test")
            .sparkSqlApplicationConfig(GdcSparkApplicationSparkSqlApplicationConfigArgs.builder()
                .jarFileUris("file:///usr/lib/spark/examples/jars/spark-examples.jar")
                .queryList(GdcSparkApplicationSparkSqlApplicationConfigQueryListArgs.builder()
                    .queries("show tables;")
                    .build())
                .scriptVariables(Map.of("MY_VAR", "1"))
                .build())
            .build());

    }
}
```
```yaml
resources:
  spark-application:
    type: gcp:dataproc:GdcSparkApplication
    properties:
      sparkApplicationId: tf-e2e-sparksql-app
      serviceinstance: do-not-delete-dataproc-gdc-instance
      project: my-project
      location: us-west2
      namespace: default
      displayName: A SparkSql application for a Terraform create test
      sparkSqlApplicationConfig:
        jarFileUris:
          - file:///usr/lib/spark/examples/jars/spark-examples.jar
        queryList:
          queries:
            - show tables;
        scriptVariables:
          MY_VAR: '1'
```
<!--End PulumiCodeChooser -->
### Dataprocgdc Sparkapplication Sparksql Query File


<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const spark_application = new gcp.dataproc.GdcSparkApplication("spark-application", {
    sparkApplicationId: "tf-e2e-sparksql-app",
    serviceinstance: "do-not-delete-dataproc-gdc-instance",
    project: "my-project",
    location: "us-west2",
    namespace: "default",
    displayName: "A SparkSql application for a Terraform create test",
    sparkSqlApplicationConfig: {
        jarFileUris: ["file:///usr/lib/spark/examples/jars/spark-examples.jar"],
        queryFileUri: "gs://some-bucket/something.sql",
        scriptVariables: {
            MY_VAR: "1",
        },
    },
});
```
```python
import pulumi
import pulumi_gcp as gcp

spark_application = gcp.dataproc.GdcSparkApplication("spark-application",
    spark_application_id="tf-e2e-sparksql-app",
    serviceinstance="do-not-delete-dataproc-gdc-instance",
    project="my-project",
    location="us-west2",
    namespace="default",
    display_name="A SparkSql application for a Terraform create test",
    spark_sql_application_config={
        "jar_file_uris": ["file:///usr/lib/spark/examples/jars/spark-examples.jar"],
        "query_file_uri": "gs://some-bucket/something.sql",
        "script_variables": {
            "MY_VAR": "1",
        },
    })
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var spark_application = new Gcp.Dataproc.GdcSparkApplication("spark-application", new()
    {
        SparkApplicationId = "tf-e2e-sparksql-app",
        Serviceinstance = "do-not-delete-dataproc-gdc-instance",
        Project = "my-project",
        Location = "us-west2",
        Namespace = "default",
        DisplayName = "A SparkSql application for a Terraform create test",
        SparkSqlApplicationConfig = new Gcp.Dataproc.Inputs.GdcSparkApplicationSparkSqlApplicationConfigArgs
        {
            JarFileUris = new[]
            {
                "file:///usr/lib/spark/examples/jars/spark-examples.jar",
            },
            QueryFileUri = "gs://some-bucket/something.sql",
            ScriptVariables = 
            {
                { "MY_VAR", "1" },
            },
        },
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/dataproc"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		_, err := dataproc.NewGdcSparkApplication(ctx, "spark-application", &dataproc.GdcSparkApplicationArgs{
			SparkApplicationId: pulumi.String("tf-e2e-sparksql-app"),
			Serviceinstance:    pulumi.String("do-not-delete-dataproc-gdc-instance"),
			Project:            pulumi.String("my-project"),
			Location:           pulumi.String("us-west2"),
			Namespace:          pulumi.String("default"),
			DisplayName:        pulumi.String("A SparkSql application for a Terraform create test"),
			SparkSqlApplicationConfig: &dataproc.GdcSparkApplicationSparkSqlApplicationConfigArgs{
				JarFileUris: pulumi.StringArray{
					pulumi.String("file:///usr/lib/spark/examples/jars/spark-examples.jar"),
				},
				QueryFileUri: pulumi.String("gs://some-bucket/something.sql"),
				ScriptVariables: pulumi.StringMap{
					"MY_VAR": pulumi.String("1"),
				},
			},
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.dataproc.GdcSparkApplication;
import com.pulumi.gcp.dataproc.GdcSparkApplicationArgs;
import com.pulumi.gcp.dataproc.inputs.GdcSparkApplicationSparkSqlApplicationConfigArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        var spark_application = new GdcSparkApplication("spark-application", GdcSparkApplicationArgs.builder()
            .sparkApplicationId("tf-e2e-sparksql-app")
            .serviceinstance("do-not-delete-dataproc-gdc-instance")
            .project("my-project")
            .location("us-west2")
            .namespace("default")
            .displayName("A SparkSql application for a Terraform create test")
            .sparkSqlApplicationConfig(GdcSparkApplicationSparkSqlApplicationConfigArgs.builder()
                .jarFileUris("file:///usr/lib/spark/examples/jars/spark-examples.jar")
                .queryFileUri("gs://some-bucket/something.sql")
                .scriptVariables(Map.of("MY_VAR", "1"))
                .build())
            .build());

    }
}
```
```yaml
resources:
  spark-application:
    type: gcp:dataproc:GdcSparkApplication
    properties:
      sparkApplicationId: tf-e2e-sparksql-app
      serviceinstance: do-not-delete-dataproc-gdc-instance
      project: my-project
      location: us-west2
      namespace: default
      displayName: A SparkSql application for a Terraform create test
      sparkSqlApplicationConfig:
        jarFileUris:
          - file:///usr/lib/spark/examples/jars/spark-examples.jar
        queryFileUri: gs://some-bucket/something.sql
        scriptVariables:
          MY_VAR: '1'
```
<!--End PulumiCodeChooser -->

## Import

SparkApplication can be imported using any of these accepted formats:

* `projects/{{project}}/locations/{{location}}/serviceInstances/{{serviceinstance}}/sparkApplications/{{spark_application_id}}`

* `{{project}}/{{location}}/{{serviceinstance}}/{{spark_application_id}}`

* `{{location}}/{{serviceinstance}}/{{spark_application_id}}`

When using the `pulumi import` command, SparkApplication can be imported using one of the formats above. For example:

```sh
$ pulumi import gcp:dataproc/gdcSparkApplication:GdcSparkApplication default projects/{{project}}/locations/{{location}}/serviceInstances/{{serviceinstance}}/sparkApplications/{{spark_application_id}}
```

```sh
$ pulumi import gcp:dataproc/gdcSparkApplication:GdcSparkApplication default {{project}}/{{location}}/{{serviceinstance}}/{{spark_application_id}}
```

```sh
$ pulumi import gcp:dataproc/gdcSparkApplication:GdcSparkApplication default {{location}}/{{serviceinstance}}/{{spark_application_id}}
```

ö
annotationsB2" ÞThe annotations to associate with this application. Annotations may be used to store client information, but are not used by the server.
**Note**: This field is non-authoritative, and will only manage the annotations present in your configuration.
Please refer to the field `effective_annotations` for all of the annotations present on the resource.
j
applicationEnvironmentB" JAn ApplicationEnvironment from which to inherit configuration properties.
í
dependencyImagesB*" ÐList of container image uris for additional file dependencies. Dependent files are sequentially copied from each image. If a file with the same name exists in 2 images then the file from later image is used.
V
displayNameB" AUser-provided human-readable name to be used in user interfaces.
¿
labelsB2" ¬The labels to associate with this application. Labels may be used for filtering and billing tracking.
**Note**: This field is non-authoritative, and will only manage the labels present in your configuration.
Please refer to the field `effective_labels` for all of the labels present on the resource.
7
location" 'The location of the spark application.

	namespaceB" oThe Kubernetes namespace in which to create the application. This namespace must already exist on the cluster.
{
projectB" jThe ID of the project in which the resource belongs.
If it is not provided, the provider project is used.
7

propertiesB2" !application-specific properties.

pysparkApplicationConfig¦B£: 

dataproc+GdcSparkApplicationPysparkApplicationConfigdgcp:dataproc/GdcSparkApplicationPysparkApplicationConfig:GdcSparkApplicationPysparkApplicationConfigHRepresents the PySparkApplicationConfig.
Structure is documented below.
_
serviceinstance" HThe id of the service instance to which this spark application belongs.

sparkApplicationConfig B:

dataproc)GdcSparkApplicationSparkApplicationConfig`gcp:dataproc/GdcSparkApplicationSparkApplicationConfig:GdcSparkApplicationSparkApplicationConfigFRepresents the SparkApplicationConfig.
Structure is documented below.
<
sparkApplicationId" "The id of the application


- - -

sparkRApplicationConfig£B :

dataproc*GdcSparkApplicationSparkRApplicationConfigbgcp:dataproc/GdcSparkApplicationSparkRApplicationConfig:GdcSparkApplicationSparkRApplicationConfigGRepresents the SparkRApplicationConfig.
Structure is documented below.

sparkSqlApplicationConfig©B¦:£
 
dataproc,GdcSparkApplicationSparkSqlApplicationConfigfgcp:dataproc/GdcSparkApplicationSparkSqlApplicationConfig:GdcSparkApplicationSparkSqlApplicationConfigGRepresents the SparkRApplicationConfig.
Structure is documented below.
;
versionB" *The Dataproc version of this application.
"ö
annotationsB2" ÞThe annotations to associate with this application. Annotations may be used to store client information, but are not used by the server.
**Note**: This field is non-authoritative, and will only manage the annotations present in your configuration.
Please refer to the field `effective_annotations` for all of the annotations present on the resource.
"j
applicationEnvironmentB" JAn ApplicationEnvironment from which to inherit configuration properties.
"?

createTime" -The timestamp when the resource was created.
"í
dependencyImagesB*" ÐList of container image uris for additional file dependencies. Dependent files are sequentially copied from each image. If a file with the same name exists in 2 images then the file from later image is used.
"V
displayNameB" AUser-provided human-readable name to be used in user interfaces.
"
effectiveAnnotations2" "¦
effectiveLabels2" All of labels (key/value pairs) present on the resource in GCP, including the labels configured through Pulumi, other clients and services.
"¿
labelsB2" ¬The labels to associate with this application. Labels may be used for filtering and billing tracking.
**Note**: This field is non-authoritative, and will only manage the labels present in your configuration.
Please refer to the field `effective_labels` for all of the labels present on the resource.
"7
location" 'The location of the spark application.
"
monitoringEndpoint" mURL for a monitoring UI for this application (for eventual Spark PHS/UI support) Out of scope for private GA
"ª
name" Identifier. The name of the application. Format: projects/{project}/locations/{location}/serviceInstances/{service_instance}/sparkApplications/{application}
"
	namespaceB" oThe Kubernetes namespace in which to create the application. This namespace must already exist on the cluster.
"¡
	outputUri" An HCFS URI pointing to the location of stdout and stdout of the application Mainly useful for Pantheon and gcloud Not in scope for private GA
"y
project" jThe ID of the project in which the resource belongs.
If it is not provided, the provider project is used.
"7

propertiesB2" !application-specific properties.
"
pulumiLabels2" mThe combination of labels configured directly on the resource
and default labels configured on the provider.
"
pysparkApplicationConfig¦B£: 

dataproc+GdcSparkApplicationPysparkApplicationConfigdgcp:dataproc/GdcSparkApplicationPysparkApplicationConfig:GdcSparkApplicationPysparkApplicationConfigHRepresents the PySparkApplicationConfig.
Structure is documented below.
"î
reconciling
 ÚWhether the application is currently reconciling. True if the current state of the resource does not match the intended state, and the system is working to reconcile them, whether or not the change was user initiated.
"_
serviceinstance" HThe id of the service instance to which this spark application belongs.
"
sparkApplicationConfig B:

dataproc)GdcSparkApplicationSparkApplicationConfig`gcp:dataproc/GdcSparkApplicationSparkApplicationConfig:GdcSparkApplicationSparkApplicationConfigFRepresents the SparkApplicationConfig.
Structure is documented below.
"<
sparkApplicationId" "The id of the application


- - -
"
sparkRApplicationConfig£B :

dataproc*GdcSparkApplicationSparkRApplicationConfigbgcp:dataproc/GdcSparkApplicationSparkRApplicationConfig:GdcSparkApplicationSparkRApplicationConfigGRepresents the SparkRApplicationConfig.
Structure is documented below.
"
sparkSqlApplicationConfig©B¦:£
 
dataproc,GdcSparkApplicationSparkSqlApplicationConfigfgcp:dataproc/GdcSparkApplicationSparkSqlApplicationConfig:GdcSparkApplicationSparkSqlApplicationConfigGRepresents the SparkRApplicationConfig.
Structure is documented below.
"
state" The current state.
Possible values:
* `STATE_UNSPECIFIED`
* `PENDING`
* `RUNNING`
* `CANCELLING`
* `CANCELLED`
* `SUCCEEDED`
* `FAILED`
"<
stateMessage" (A message explaining the current state.
"X
uid" MSystem generated unique identifier for this application, formatted as UUID4.
"M

updateTime" ;The timestamp when the resource was most recently updated.
";
versionB" *The Dataproc version of this application.
*ü
%
dataprocJobgcp:dataproc/job:JobYManages a job resource within a Dataproc cluster within GCE. For more information see
[the official dataproc documentation](https://cloud.google.com/dataproc/).

!> **Note:** This resource does not support 'update' and changing any attributes will cause the resource to be recreated.

## Example Usage

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const mycluster = new gcp.dataproc.Cluster("mycluster", {
    name: "dproc-cluster-unique-name",
    region: "us-central1",
});
// Submit an example spark job to a dataproc cluster
const spark = new gcp.dataproc.Job("spark", {
    region: mycluster.region,
    forceDelete: true,
    placement: {
        clusterName: mycluster.name,
    },
    sparkConfig: {
        mainClass: "org.apache.spark.examples.SparkPi",
        jarFileUris: ["file:///usr/lib/spark/examples/jars/spark-examples.jar"],
        args: ["1000"],
        properties: {
            "spark.logConf": "true",
        },
        loggingConfig: {
            driverLogLevels: {
                root: "INFO",
            },
        },
    },
});
// Submit an example pyspark job to a dataproc cluster
const pyspark = new gcp.dataproc.Job("pyspark", {
    region: mycluster.region,
    forceDelete: true,
    placement: {
        clusterName: mycluster.name,
    },
    pysparkConfig: {
        mainPythonFileUri: "gs://dataproc-examples-2f10d78d114f6aaec76462e3c310f31f/src/pyspark/hello-world/hello-world.py",
        properties: {
            "spark.logConf": "true",
        },
    },
});
export const sparkStatus = spark.statuses.apply(statuses => statuses[0].state);
export const pysparkStatus = pyspark.statuses.apply(statuses => statuses[0].state);
```
```python
import pulumi
import pulumi_gcp as gcp

mycluster = gcp.dataproc.Cluster("mycluster",
    name="dproc-cluster-unique-name",
    region="us-central1")
# Submit an example spark job to a dataproc cluster
spark = gcp.dataproc.Job("spark",
    region=mycluster.region,
    force_delete=True,
    placement={
        "cluster_name": mycluster.name,
    },
    spark_config={
        "main_class": "org.apache.spark.examples.SparkPi",
        "jar_file_uris": ["file:///usr/lib/spark/examples/jars/spark-examples.jar"],
        "args": ["1000"],
        "properties": {
            "spark.logConf": "true",
        },
        "logging_config": {
            "driver_log_levels": {
                "root": "INFO",
            },
        },
    })
# Submit an example pyspark job to a dataproc cluster
pyspark = gcp.dataproc.Job("pyspark",
    region=mycluster.region,
    force_delete=True,
    placement={
        "cluster_name": mycluster.name,
    },
    pyspark_config={
        "main_python_file_uri": "gs://dataproc-examples-2f10d78d114f6aaec76462e3c310f31f/src/pyspark/hello-world/hello-world.py",
        "properties": {
            "spark.logConf": "true",
        },
    })
pulumi.export("sparkStatus", spark.statuses[0].state)
pulumi.export("pysparkStatus", pyspark.statuses[0].state)
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var mycluster = new Gcp.Dataproc.Cluster("mycluster", new()
    {
        Name = "dproc-cluster-unique-name",
        Region = "us-central1",
    });

    // Submit an example spark job to a dataproc cluster
    var spark = new Gcp.Dataproc.Job("spark", new()
    {
        Region = mycluster.Region,
        ForceDelete = true,
        Placement = new Gcp.Dataproc.Inputs.JobPlacementArgs
        {
            ClusterName = mycluster.Name,
        },
        SparkConfig = new Gcp.Dataproc.Inputs.JobSparkConfigArgs
        {
            MainClass = "org.apache.spark.examples.SparkPi",
            JarFileUris = new[]
            {
                "file:///usr/lib/spark/examples/jars/spark-examples.jar",
            },
            Args = new[]
            {
                "1000",
            },
            Properties = 
            {
                { "spark.logConf", "true" },
            },
            LoggingConfig = new Gcp.Dataproc.Inputs.JobSparkConfigLoggingConfigArgs
            {
                DriverLogLevels = 
                {
                    { "root", "INFO" },
                },
            },
        },
    });

    // Submit an example pyspark job to a dataproc cluster
    var pyspark = new Gcp.Dataproc.Job("pyspark", new()
    {
        Region = mycluster.Region,
        ForceDelete = true,
        Placement = new Gcp.Dataproc.Inputs.JobPlacementArgs
        {
            ClusterName = mycluster.Name,
        },
        PysparkConfig = new Gcp.Dataproc.Inputs.JobPysparkConfigArgs
        {
            MainPythonFileUri = "gs://dataproc-examples-2f10d78d114f6aaec76462e3c310f31f/src/pyspark/hello-world/hello-world.py",
            Properties = 
            {
                { "spark.logConf", "true" },
            },
        },
    });

    return new Dictionary<string, object?>
    {
        ["sparkStatus"] = spark.Statuses.Apply(statuses => statuses[0].State),
        ["pysparkStatus"] = pyspark.Statuses.Apply(statuses => statuses[0].State),
    };
});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/dataproc"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		mycluster, err := dataproc.NewCluster(ctx, "mycluster", &dataproc.ClusterArgs{
			Name:   pulumi.String("dproc-cluster-unique-name"),
			Region: pulumi.String("us-central1"),
		})
		if err != nil {
			return err
		}
		// Submit an example spark job to a dataproc cluster
		spark, err := dataproc.NewJob(ctx, "spark", &dataproc.JobArgs{
			Region:      mycluster.Region,
			ForceDelete: pulumi.Bool(true),
			Placement: &dataproc.JobPlacementArgs{
				ClusterName: mycluster.Name,
			},
			SparkConfig: &dataproc.JobSparkConfigArgs{
				MainClass: pulumi.String("org.apache.spark.examples.SparkPi"),
				JarFileUris: pulumi.StringArray{
					pulumi.String("file:///usr/lib/spark/examples/jars/spark-examples.jar"),
				},
				Args: pulumi.StringArray{
					pulumi.String("1000"),
				},
				Properties: pulumi.StringMap{
					"spark.logConf": pulumi.String("true"),
				},
				LoggingConfig: &dataproc.JobSparkConfigLoggingConfigArgs{
					DriverLogLevels: pulumi.StringMap{
						"root": pulumi.String("INFO"),
					},
				},
			},
		})
		if err != nil {
			return err
		}
		// Submit an example pyspark job to a dataproc cluster
		pyspark, err := dataproc.NewJob(ctx, "pyspark", &dataproc.JobArgs{
			Region:      mycluster.Region,
			ForceDelete: pulumi.Bool(true),
			Placement: &dataproc.JobPlacementArgs{
				ClusterName: mycluster.Name,
			},
			PysparkConfig: &dataproc.JobPysparkConfigArgs{
				MainPythonFileUri: pulumi.String("gs://dataproc-examples-2f10d78d114f6aaec76462e3c310f31f/src/pyspark/hello-world/hello-world.py"),
				Properties: pulumi.StringMap{
					"spark.logConf": pulumi.String("true"),
				},
			},
		})
		if err != nil {
			return err
		}
		ctx.Export("sparkStatus", spark.Statuses.ApplyT(func(statuses []dataproc.JobStatus) (*string, error) {
			return &statuses[0].State, nil
		}).(pulumi.StringPtrOutput))
		ctx.Export("pysparkStatus", pyspark.Statuses.ApplyT(func(statuses []dataproc.JobStatus) (*string, error) {
			return &statuses[0].State, nil
		}).(pulumi.StringPtrOutput))
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.dataproc.Cluster;
import com.pulumi.gcp.dataproc.ClusterArgs;
import com.pulumi.gcp.dataproc.Job;
import com.pulumi.gcp.dataproc.JobArgs;
import com.pulumi.gcp.dataproc.inputs.JobPlacementArgs;
import com.pulumi.gcp.dataproc.inputs.JobSparkConfigArgs;
import com.pulumi.gcp.dataproc.inputs.JobSparkConfigLoggingConfigArgs;
import com.pulumi.gcp.dataproc.inputs.JobPysparkConfigArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        var mycluster = new Cluster("mycluster", ClusterArgs.builder()
            .name("dproc-cluster-unique-name")
            .region("us-central1")
            .build());

        // Submit an example spark job to a dataproc cluster
        var spark = new Job("spark", JobArgs.builder()
            .region(mycluster.region())
            .forceDelete(true)
            .placement(JobPlacementArgs.builder()
                .clusterName(mycluster.name())
                .build())
            .sparkConfig(JobSparkConfigArgs.builder()
                .mainClass("org.apache.spark.examples.SparkPi")
                .jarFileUris("file:///usr/lib/spark/examples/jars/spark-examples.jar")
                .args("1000")
                .properties(Map.of("spark.logConf", "true"))
                .loggingConfig(JobSparkConfigLoggingConfigArgs.builder()
                    .driverLogLevels(Map.of("root", "INFO"))
                    .build())
                .build())
            .build());

        // Submit an example pyspark job to a dataproc cluster
        var pyspark = new Job("pyspark", JobArgs.builder()
            .region(mycluster.region())
            .forceDelete(true)
            .placement(JobPlacementArgs.builder()
                .clusterName(mycluster.name())
                .build())
            .pysparkConfig(JobPysparkConfigArgs.builder()
                .mainPythonFileUri("gs://dataproc-examples-2f10d78d114f6aaec76462e3c310f31f/src/pyspark/hello-world/hello-world.py")
                .properties(Map.of("spark.logConf", "true"))
                .build())
            .build());

        ctx.export("sparkStatus", spark.statuses().applyValue(statuses -> statuses[0].state()));
        ctx.export("pysparkStatus", pyspark.statuses().applyValue(statuses -> statuses[0].state()));
    }
}
```
```yaml
resources:
  mycluster:
    type: gcp:dataproc:Cluster
    properties:
      name: dproc-cluster-unique-name
      region: us-central1
  # Submit an example spark job to a dataproc cluster
  spark:
    type: gcp:dataproc:Job
    properties:
      region: ${mycluster.region}
      forceDelete: true
      placement:
        clusterName: ${mycluster.name}
      sparkConfig:
        mainClass: org.apache.spark.examples.SparkPi
        jarFileUris:
          - file:///usr/lib/spark/examples/jars/spark-examples.jar
        args:
          - '1000'
        properties:
          spark.logConf: 'true'
        loggingConfig:
          driverLogLevels:
            root: INFO
  # Submit an example pyspark job to a dataproc cluster
  pyspark:
    type: gcp:dataproc:Job
    properties:
      region: ${mycluster.region}
      forceDelete: true
      placement:
        clusterName: ${mycluster.name}
      pysparkConfig:
        mainPythonFileUri: gs://dataproc-examples-2f10d78d114f6aaec76462e3c310f31f/src/pyspark/hello-world/hello-world.py
        properties:
          spark.logConf: 'true'
outputs:
  # Check out current state of the jobs
  sparkStatus: ${spark.statuses[0].state}
  pysparkStatus: ${pyspark.statuses[0].state}
```
<!--End PulumiCodeChooser -->

## Import

This resource does not support import.

Ç
forceDeleteB
 ±By default, you can only delete inactive jobs within
Dataproc. Setting this to true, and calling destroy, will ensure that the
job is first cancelled before issuing the delete.
z
hadoopConfigOBM:K
I
dataprocJobHadoopConfig,gcp:dataproc/JobHadoopConfig:JobHadoopConfigThe config of Hadoop job
p

hiveConfigIBG:E
C
dataprocJobHiveConfig(gcp:dataproc/JobHiveConfig:JobHiveConfigThe config of hive job

labelsB2" þThe list of labels (key/value pairs) to add to the job.
**Note**: This field is non-authoritative, and will only manage the labels present in your configuration.
Please refer to the field 'effective_labels' for all of the labels present on the resource.
l
	pigConfigFBD:B
@
dataprocJobPigConfig&gcp:dataproc/JobPigConfig:JobPigConfigThe config of pag job.
p
	placementD:B
@
dataprocJobPlacement&gcp:dataproc/JobPlacement:JobPlacementThe config of job placement.
z
prestoConfigOBM:K
I
dataprocJobPrestoConfig,gcp:dataproc/JobPrestoConfig:JobPrestoConfigThe config of presto job

projectB" The project in which the `cluster` can be found and jobs
subsequently run against. If it is not provided, the provider project is used.

pysparkConfigRBP:N
L
dataprocJobPysparkConfig.gcp:dataproc/JobPysparkConfig:JobPysparkConfigThe config of pySpark job.
n
	referenceFBD:B
@
dataprocJobReference&gcp:dataproc/JobReference:JobReferenceThe reference of the job
®
regionB" The Cloud Dataproc region. This essentially determines which clusters are available
for this job to be submitted to. If not specified, defaults to `global`.


schedulingIBG:E
C
dataprocJobScheduling(gcp:dataproc/JobScheduling:JobScheduling(Optional. Job scheduling configuration.
z
sparkConfigLBJ:H
F
dataprocJobSparkConfig*gcp:dataproc/JobSparkConfig:JobSparkConfigThe config of the Spark job.

sparksqlConfigUBS:Q
O
dataprocJobSparksqlConfig0gcp:dataproc/JobSparksqlConfig:JobSparksqlConfigThe config of SparkSql job
"ã
driverControlsFilesUri" ÄIf present, the location of miscellaneous control files which may be used as part of job setup and handling. If not present, control files may be placed in the same location as driver_output_uri.
"i
driverOutputResourceUri" JA URI pointing to the location of the stdout of the job's driver program.
"
effectiveLabels2" All of labels (key/value pairs) present on the resource in GCP, including the labels configured through Pulumi, other clients and services.

* `scheduling.max_failures_per_hour` - (Required) Maximum number of times per hour a driver may be restarted as a result of driver exiting with non-zero code before job is reported failed.

* `scheduling.max_failures_total` - (Required) Maximum number of times in total a driver may be restarted as a result of driver exiting with non-zero code before job is reported failed.
"Ç
forceDeleteB
 ±By default, you can only delete inactive jobs within
Dataproc. Setting this to true, and calling destroy, will ensure that the
job is first cancelled before issuing the delete.
"z
hadoopConfigOBM:K
I
dataprocJobHadoopConfig,gcp:dataproc/JobHadoopConfig:JobHadoopConfigThe config of Hadoop job
"p

hiveConfigIBG:E
C
dataprocJobHiveConfig(gcp:dataproc/JobHiveConfig:JobHiveConfigThe config of hive job
"
labelsB2" þThe list of labels (key/value pairs) to add to the job.
**Note**: This field is non-authoritative, and will only manage the labels present in your configuration.
Please refer to the field 'effective_labels' for all of the labels present on the resource.
"l
	pigConfigFBD:B
@
dataprocJobPigConfig&gcp:dataproc/JobPigConfig:JobPigConfigThe config of pag job.
"p
	placementD:B
@
dataprocJobPlacement&gcp:dataproc/JobPlacement:JobPlacementThe config of job placement.
"z
prestoConfigOBM:K
I
dataprocJobPrestoConfig,gcp:dataproc/JobPrestoConfig:JobPrestoConfigThe config of presto job
"
project" The project in which the `cluster` can be found and jobs
subsequently run against. If it is not provided, the provider project is used.
"
pulumiLabels2" mThe combination of labels configured directly on the resource and default labels configured on the provider.
"
pysparkConfigRBP:N
L
dataprocJobPysparkConfig.gcp:dataproc/JobPysparkConfig:JobPysparkConfigThe config of pySpark job.
"l
	referenceD:B
@
dataprocJobReference&gcp:dataproc/JobReference:JobReferenceThe reference of the job
"®
regionB" The Cloud Dataproc region. This essentially determines which clusters are available
for this job to be submitted to. If not specified, defaults to `global`.
"

schedulingIBG:E
C
dataprocJobScheduling(gcp:dataproc/JobScheduling:JobScheduling(Optional. Job scheduling configuration.
"z
sparkConfigLBJ:H
F
dataprocJobSparkConfig*gcp:dataproc/JobSparkConfig:JobSparkConfigThe config of the Spark job.
"
sparksqlConfigUBS:Q
O
dataprocJobSparksqlConfig0gcp:dataproc/JobSparksqlConfig:JobSparksqlConfigThe config of SparkSql job
"b
statuses=*;:9
7
dataproc	JobStatus gcp:dataproc/JobStatus:JobStatusThe status of the job.
*¢°
C
dataprocJobIAMBinding(gcp:dataproc/jobIAMBinding:JobIAMBindingÅThree different resources help you manage IAM policies on dataproc jobs. Each of these resources serves a different use case:

* `gcp.dataproc.JobIAMPolicy`: Authoritative. Sets the IAM policy for the job and replaces any existing policy already attached.
* `gcp.dataproc.JobIAMBinding`: Authoritative for a given role. Updates the IAM policy to grant a role to a list of members. Other roles within the IAM policy for the job are preserved.
* `gcp.dataproc.JobIAMMember`: Non-authoritative. Updates the IAM policy to grant a role to a new member. Other members for the role for the job are preserved.

> **Note:** `gcp.dataproc.JobIAMPolicy` **cannot** be used in conjunction with `gcp.dataproc.JobIAMBinding` and `gcp.dataproc.JobIAMMember` or they will fight over what your policy should be. In addition, be careful not to accidentally unset ownership of the job as `gcp.dataproc.JobIAMPolicy` replaces the entire policy.

> **Note:** `gcp.dataproc.JobIAMBinding` resources **can be** used in conjunction with `gcp.dataproc.JobIAMMember` resources **only if** they do not grant privilege to the same role.

## gcp.dataproc.JobIAMPolicy

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const admin = gcp.organizations.getIAMPolicy({
    bindings: [{
        role: "roles/editor",
        members: ["user:jane@example.com"],
    }],
});
const editor = new gcp.dataproc.JobIAMPolicy("editor", {
    project: "your-project",
    region: "your-region",
    jobId: "your-dataproc-job",
    policyData: admin.then(admin => admin.policyData),
});
```
```python
import pulumi
import pulumi_gcp as gcp

admin = gcp.organizations.get_iam_policy(bindings=[{
    "role": "roles/editor",
    "members": ["user:jane@example.com"],
}])
editor = gcp.dataproc.JobIAMPolicy("editor",
    project="your-project",
    region="your-region",
    job_id="your-dataproc-job",
    policy_data=admin.policy_data)
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var admin = Gcp.Organizations.GetIAMPolicy.Invoke(new()
    {
        Bindings = new[]
        {
            new Gcp.Organizations.Inputs.GetIAMPolicyBindingInputArgs
            {
                Role = "roles/editor",
                Members = new[]
                {
                    "user:jane@example.com",
                },
            },
        },
    });

    var editor = new Gcp.Dataproc.JobIAMPolicy("editor", new()
    {
        Project = "your-project",
        Region = "your-region",
        JobId = "your-dataproc-job",
        PolicyData = admin.Apply(getIAMPolicyResult => getIAMPolicyResult.PolicyData),
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/dataproc"
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/organizations"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		admin, err := organizations.LookupIAMPolicy(ctx, &organizations.LookupIAMPolicyArgs{
			Bindings: []organizations.GetIAMPolicyBinding{
				{
					Role: "roles/editor",
					Members: []string{
						"user:jane@example.com",
					},
				},
			},
		}, nil)
		if err != nil {
			return err
		}
		_, err = dataproc.NewJobIAMPolicy(ctx, "editor", &dataproc.JobIAMPolicyArgs{
			Project:    pulumi.String("your-project"),
			Region:     pulumi.String("your-region"),
			JobId:      pulumi.String("your-dataproc-job"),
			PolicyData: pulumi.String(admin.PolicyData),
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.organizations.OrganizationsFunctions;
import com.pulumi.gcp.organizations.inputs.GetIAMPolicyArgs;
import com.pulumi.gcp.dataproc.JobIAMPolicy;
import com.pulumi.gcp.dataproc.JobIAMPolicyArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        final var admin = OrganizationsFunctions.getIAMPolicy(GetIAMPolicyArgs.builder()
            .bindings(GetIAMPolicyBindingArgs.builder()
                .role("roles/editor")
                .members("user:jane@example.com")
                .build())
            .build());

        var editor = new JobIAMPolicy("editor", JobIAMPolicyArgs.builder()
            .project("your-project")
            .region("your-region")
            .jobId("your-dataproc-job")
            .policyData(admin.applyValue(getIAMPolicyResult -> getIAMPolicyResult.policyData()))
            .build());

    }
}
```
```yaml
resources:
  editor:
    type: gcp:dataproc:JobIAMPolicy
    properties:
      project: your-project
      region: your-region
      jobId: your-dataproc-job
      policyData: ${admin.policyData}
variables:
  admin:
    fn::invoke:
      function: gcp:organizations:getIAMPolicy
      arguments:
        bindings:
          - role: roles/editor
            members:
              - user:jane@example.com
```
<!--End PulumiCodeChooser -->

## gcp.dataproc.JobIAMBinding

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const editor = new gcp.dataproc.JobIAMBinding("editor", {
    jobId: "your-dataproc-job",
    role: "roles/editor",
    members: ["user:jane@example.com"],
});
```
```python
import pulumi
import pulumi_gcp as gcp

editor = gcp.dataproc.JobIAMBinding("editor",
    job_id="your-dataproc-job",
    role="roles/editor",
    members=["user:jane@example.com"])
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var editor = new Gcp.Dataproc.JobIAMBinding("editor", new()
    {
        JobId = "your-dataproc-job",
        Role = "roles/editor",
        Members = new[]
        {
            "user:jane@example.com",
        },
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/dataproc"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		_, err := dataproc.NewJobIAMBinding(ctx, "editor", &dataproc.JobIAMBindingArgs{
			JobId: pulumi.String("your-dataproc-job"),
			Role:  pulumi.String("roles/editor"),
			Members: pulumi.StringArray{
				pulumi.String("user:jane@example.com"),
			},
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.dataproc.JobIAMBinding;
import com.pulumi.gcp.dataproc.JobIAMBindingArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        var editor = new JobIAMBinding("editor", JobIAMBindingArgs.builder()
            .jobId("your-dataproc-job")
            .role("roles/editor")
            .members("user:jane@example.com")
            .build());

    }
}
```
```yaml
resources:
  editor:
    type: gcp:dataproc:JobIAMBinding
    properties:
      jobId: your-dataproc-job
      role: roles/editor
      members:
        - user:jane@example.com
```
<!--End PulumiCodeChooser -->

## gcp.dataproc.JobIAMMember

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const editor = new gcp.dataproc.JobIAMMember("editor", {
    jobId: "your-dataproc-job",
    role: "roles/editor",
    member: "user:jane@example.com",
});
```
```python
import pulumi
import pulumi_gcp as gcp

editor = gcp.dataproc.JobIAMMember("editor",
    job_id="your-dataproc-job",
    role="roles/editor",
    member="user:jane@example.com")
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var editor = new Gcp.Dataproc.JobIAMMember("editor", new()
    {
        JobId = "your-dataproc-job",
        Role = "roles/editor",
        Member = "user:jane@example.com",
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/dataproc"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		_, err := dataproc.NewJobIAMMember(ctx, "editor", &dataproc.JobIAMMemberArgs{
			JobId:  pulumi.String("your-dataproc-job"),
			Role:   pulumi.String("roles/editor"),
			Member: pulumi.String("user:jane@example.com"),
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.dataproc.JobIAMMember;
import com.pulumi.gcp.dataproc.JobIAMMemberArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        var editor = new JobIAMMember("editor", JobIAMMemberArgs.builder()
            .jobId("your-dataproc-job")
            .role("roles/editor")
            .member("user:jane@example.com")
            .build());

    }
}
```
```yaml
resources:
  editor:
    type: gcp:dataproc:JobIAMMember
    properties:
      jobId: your-dataproc-job
      role: roles/editor
      member: user:jane@example.com
```
<!--End PulumiCodeChooser -->

## gcp.dataproc.JobIAMPolicy

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const admin = gcp.organizations.getIAMPolicy({
    bindings: [{
        role: "roles/editor",
        members: ["user:jane@example.com"],
    }],
});
const editor = new gcp.dataproc.JobIAMPolicy("editor", {
    project: "your-project",
    region: "your-region",
    jobId: "your-dataproc-job",
    policyData: admin.then(admin => admin.policyData),
});
```
```python
import pulumi
import pulumi_gcp as gcp

admin = gcp.organizations.get_iam_policy(bindings=[{
    "role": "roles/editor",
    "members": ["user:jane@example.com"],
}])
editor = gcp.dataproc.JobIAMPolicy("editor",
    project="your-project",
    region="your-region",
    job_id="your-dataproc-job",
    policy_data=admin.policy_data)
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var admin = Gcp.Organizations.GetIAMPolicy.Invoke(new()
    {
        Bindings = new[]
        {
            new Gcp.Organizations.Inputs.GetIAMPolicyBindingInputArgs
            {
                Role = "roles/editor",
                Members = new[]
                {
                    "user:jane@example.com",
                },
            },
        },
    });

    var editor = new Gcp.Dataproc.JobIAMPolicy("editor", new()
    {
        Project = "your-project",
        Region = "your-region",
        JobId = "your-dataproc-job",
        PolicyData = admin.Apply(getIAMPolicyResult => getIAMPolicyResult.PolicyData),
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/dataproc"
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/organizations"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		admin, err := organizations.LookupIAMPolicy(ctx, &organizations.LookupIAMPolicyArgs{
			Bindings: []organizations.GetIAMPolicyBinding{
				{
					Role: "roles/editor",
					Members: []string{
						"user:jane@example.com",
					},
				},
			},
		}, nil)
		if err != nil {
			return err
		}
		_, err = dataproc.NewJobIAMPolicy(ctx, "editor", &dataproc.JobIAMPolicyArgs{
			Project:    pulumi.String("your-project"),
			Region:     pulumi.String("your-region"),
			JobId:      pulumi.String("your-dataproc-job"),
			PolicyData: pulumi.String(admin.PolicyData),
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.organizations.OrganizationsFunctions;
import com.pulumi.gcp.organizations.inputs.GetIAMPolicyArgs;
import com.pulumi.gcp.dataproc.JobIAMPolicy;
import com.pulumi.gcp.dataproc.JobIAMPolicyArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        final var admin = OrganizationsFunctions.getIAMPolicy(GetIAMPolicyArgs.builder()
            .bindings(GetIAMPolicyBindingArgs.builder()
                .role("roles/editor")
                .members("user:jane@example.com")
                .build())
            .build());

        var editor = new JobIAMPolicy("editor", JobIAMPolicyArgs.builder()
            .project("your-project")
            .region("your-region")
            .jobId("your-dataproc-job")
            .policyData(admin.applyValue(getIAMPolicyResult -> getIAMPolicyResult.policyData()))
            .build());

    }
}
```
```yaml
resources:
  editor:
    type: gcp:dataproc:JobIAMPolicy
    properties:
      project: your-project
      region: your-region
      jobId: your-dataproc-job
      policyData: ${admin.policyData}
variables:
  admin:
    fn::invoke:
      function: gcp:organizations:getIAMPolicy
      arguments:
        bindings:
          - role: roles/editor
            members:
              - user:jane@example.com
```
<!--End PulumiCodeChooser -->

## gcp.dataproc.JobIAMBinding

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const editor = new gcp.dataproc.JobIAMBinding("editor", {
    jobId: "your-dataproc-job",
    role: "roles/editor",
    members: ["user:jane@example.com"],
});
```
```python
import pulumi
import pulumi_gcp as gcp

editor = gcp.dataproc.JobIAMBinding("editor",
    job_id="your-dataproc-job",
    role="roles/editor",
    members=["user:jane@example.com"])
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var editor = new Gcp.Dataproc.JobIAMBinding("editor", new()
    {
        JobId = "your-dataproc-job",
        Role = "roles/editor",
        Members = new[]
        {
            "user:jane@example.com",
        },
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/dataproc"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		_, err := dataproc.NewJobIAMBinding(ctx, "editor", &dataproc.JobIAMBindingArgs{
			JobId: pulumi.String("your-dataproc-job"),
			Role:  pulumi.String("roles/editor"),
			Members: pulumi.StringArray{
				pulumi.String("user:jane@example.com"),
			},
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.dataproc.JobIAMBinding;
import com.pulumi.gcp.dataproc.JobIAMBindingArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        var editor = new JobIAMBinding("editor", JobIAMBindingArgs.builder()
            .jobId("your-dataproc-job")
            .role("roles/editor")
            .members("user:jane@example.com")
            .build());

    }
}
```
```yaml
resources:
  editor:
    type: gcp:dataproc:JobIAMBinding
    properties:
      jobId: your-dataproc-job
      role: roles/editor
      members:
        - user:jane@example.com
```
<!--End PulumiCodeChooser -->

## gcp.dataproc.JobIAMMember

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const editor = new gcp.dataproc.JobIAMMember("editor", {
    jobId: "your-dataproc-job",
    role: "roles/editor",
    member: "user:jane@example.com",
});
```
```python
import pulumi
import pulumi_gcp as gcp

editor = gcp.dataproc.JobIAMMember("editor",
    job_id="your-dataproc-job",
    role="roles/editor",
    member="user:jane@example.com")
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var editor = new Gcp.Dataproc.JobIAMMember("editor", new()
    {
        JobId = "your-dataproc-job",
        Role = "roles/editor",
        Member = "user:jane@example.com",
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/dataproc"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		_, err := dataproc.NewJobIAMMember(ctx, "editor", &dataproc.JobIAMMemberArgs{
			JobId:  pulumi.String("your-dataproc-job"),
			Role:   pulumi.String("roles/editor"),
			Member: pulumi.String("user:jane@example.com"),
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.dataproc.JobIAMMember;
import com.pulumi.gcp.dataproc.JobIAMMemberArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        var editor = new JobIAMMember("editor", JobIAMMemberArgs.builder()
            .jobId("your-dataproc-job")
            .role("roles/editor")
            .member("user:jane@example.com")
            .build());

    }
}
```
```yaml
resources:
  editor:
    type: gcp:dataproc:JobIAMMember
    properties:
      jobId: your-dataproc-job
      role: roles/editor
      member: user:jane@example.com
```
<!--End PulumiCodeChooser -->

## Import

### Importing IAM policies

IAM policy imports use the `job_id` identifier of the Dataproc Job resource only. For example:

* `projects/{project}/regions/{region}/jobs/{job_id}`

An `import` block (Terraform v1.5.0 and later) can be used to import IAM policies:

tf

import {

  id = "projects/{project}/regions/{region}/jobs/{job_id}"

  to = google_dataproc_job_iam_policy.default

}

The `pulumi import` command can also be used:

```sh
$ pulumi import gcp:dataproc/jobIAMBinding:JobIAMBinding default "projects/{project}/regions/{region}/jobs/{job_id}"
```

q
	conditiondBb:`
^
dataprocJobIAMBindingCondition:gcp:dataproc/JobIAMBindingCondition:JobIAMBindingCondition
jobId" 
members*" Identities that will be granted the privilege in `role`.
Each entry can have one of the following values:
* **allUsers**: A special identifier that represents anyone who is on the internet; with or without a Google account.
* **allAuthenticatedUsers**: A special identifier that represents anyone who is authenticated with a Google account or a service account.
* **user:{emailid}**: An email address that represents a specific Google account. For example, alice@gmail.com or joe@example.com.
* **serviceAccount:{emailid}**: An email address that represents a service account. For example, my-other-app@appspot.gserviceaccount.com.
* **group:{emailid}**: An email address that represents a Google group. For example, admins@example.com.
* **domain:{domain}**: A G Suite domain (primary, instead of alias) name that represents all the users of that domain. For example, google.com or example.com.
o
projectB" ^The project in which the job belongs. If it
is not provided, the provider will use a default.
m
regionB" ]The region in which the job belongs. If it
is not provided, the provider will use a default.
ö
role" éThe role that should be applied. Only one
`gcp.dataproc.JobIAMBinding` can be used per role. Note that custom roles must be of the format
`[projects|organizations]/{parent-name}/roles/{role-name}`.

`gcp.dataproc.JobIAMPolicy` only:
"q
	conditiondBb:`
^
dataprocJobIAMBindingCondition:gcp:dataproc/JobIAMBindingCondition:JobIAMBindingCondition":
etag" .(Computed) The etag of the jobs's IAM policy.
"
jobId" "
members*" Identities that will be granted the privilege in `role`.
Each entry can have one of the following values:
* **allUsers**: A special identifier that represents anyone who is on the internet; with or without a Google account.
* **allAuthenticatedUsers**: A special identifier that represents anyone who is authenticated with a Google account or a service account.
* **user:{emailid}**: An email address that represents a specific Google account. For example, alice@gmail.com or joe@example.com.
* **serviceAccount:{emailid}**: An email address that represents a service account. For example, my-other-app@appspot.gserviceaccount.com.
* **group:{emailid}**: An email address that represents a Google group. For example, admins@example.com.
* **domain:{domain}**: A G Suite domain (primary, instead of alias) name that represents all the users of that domain. For example, google.com or example.com.
"m
project" ^The project in which the job belongs. If it
is not provided, the provider will use a default.
"k
region" ]The region in which the job belongs. If it
is not provided, the provider will use a default.
"ö
role" éThe role that should be applied. Only one
`gcp.dataproc.JobIAMBinding` can be used per role. Note that custom roles must be of the format
`[projects|organizations]/{parent-name}/roles/{role-name}`.

`gcp.dataproc.JobIAMPolicy` only:
*°
@
dataprocJobIAMMember&gcp:dataproc/jobIAMMember:JobIAMMemberÃThree different resources help you manage IAM policies on dataproc jobs. Each of these resources serves a different use case:

* `gcp.dataproc.JobIAMPolicy`: Authoritative. Sets the IAM policy for the job and replaces any existing policy already attached.
* `gcp.dataproc.JobIAMBinding`: Authoritative for a given role. Updates the IAM policy to grant a role to a list of members. Other roles within the IAM policy for the job are preserved.
* `gcp.dataproc.JobIAMMember`: Non-authoritative. Updates the IAM policy to grant a role to a new member. Other members for the role for the job are preserved.

> **Note:** `gcp.dataproc.JobIAMPolicy` **cannot** be used in conjunction with `gcp.dataproc.JobIAMBinding` and `gcp.dataproc.JobIAMMember` or they will fight over what your policy should be. In addition, be careful not to accidentally unset ownership of the job as `gcp.dataproc.JobIAMPolicy` replaces the entire policy.

> **Note:** `gcp.dataproc.JobIAMBinding` resources **can be** used in conjunction with `gcp.dataproc.JobIAMMember` resources **only if** they do not grant privilege to the same role.

## gcp.dataproc.JobIAMPolicy

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const admin = gcp.organizations.getIAMPolicy({
    bindings: [{
        role: "roles/editor",
        members: ["user:jane@example.com"],
    }],
});
const editor = new gcp.dataproc.JobIAMPolicy("editor", {
    project: "your-project",
    region: "your-region",
    jobId: "your-dataproc-job",
    policyData: admin.then(admin => admin.policyData),
});
```
```python
import pulumi
import pulumi_gcp as gcp

admin = gcp.organizations.get_iam_policy(bindings=[{
    "role": "roles/editor",
    "members": ["user:jane@example.com"],
}])
editor = gcp.dataproc.JobIAMPolicy("editor",
    project="your-project",
    region="your-region",
    job_id="your-dataproc-job",
    policy_data=admin.policy_data)
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var admin = Gcp.Organizations.GetIAMPolicy.Invoke(new()
    {
        Bindings = new[]
        {
            new Gcp.Organizations.Inputs.GetIAMPolicyBindingInputArgs
            {
                Role = "roles/editor",
                Members = new[]
                {
                    "user:jane@example.com",
                },
            },
        },
    });

    var editor = new Gcp.Dataproc.JobIAMPolicy("editor", new()
    {
        Project = "your-project",
        Region = "your-region",
        JobId = "your-dataproc-job",
        PolicyData = admin.Apply(getIAMPolicyResult => getIAMPolicyResult.PolicyData),
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/dataproc"
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/organizations"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		admin, err := organizations.LookupIAMPolicy(ctx, &organizations.LookupIAMPolicyArgs{
			Bindings: []organizations.GetIAMPolicyBinding{
				{
					Role: "roles/editor",
					Members: []string{
						"user:jane@example.com",
					},
				},
			},
		}, nil)
		if err != nil {
			return err
		}
		_, err = dataproc.NewJobIAMPolicy(ctx, "editor", &dataproc.JobIAMPolicyArgs{
			Project:    pulumi.String("your-project"),
			Region:     pulumi.String("your-region"),
			JobId:      pulumi.String("your-dataproc-job"),
			PolicyData: pulumi.String(admin.PolicyData),
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.organizations.OrganizationsFunctions;
import com.pulumi.gcp.organizations.inputs.GetIAMPolicyArgs;
import com.pulumi.gcp.dataproc.JobIAMPolicy;
import com.pulumi.gcp.dataproc.JobIAMPolicyArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        final var admin = OrganizationsFunctions.getIAMPolicy(GetIAMPolicyArgs.builder()
            .bindings(GetIAMPolicyBindingArgs.builder()
                .role("roles/editor")
                .members("user:jane@example.com")
                .build())
            .build());

        var editor = new JobIAMPolicy("editor", JobIAMPolicyArgs.builder()
            .project("your-project")
            .region("your-region")
            .jobId("your-dataproc-job")
            .policyData(admin.applyValue(getIAMPolicyResult -> getIAMPolicyResult.policyData()))
            .build());

    }
}
```
```yaml
resources:
  editor:
    type: gcp:dataproc:JobIAMPolicy
    properties:
      project: your-project
      region: your-region
      jobId: your-dataproc-job
      policyData: ${admin.policyData}
variables:
  admin:
    fn::invoke:
      function: gcp:organizations:getIAMPolicy
      arguments:
        bindings:
          - role: roles/editor
            members:
              - user:jane@example.com
```
<!--End PulumiCodeChooser -->

## gcp.dataproc.JobIAMBinding

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const editor = new gcp.dataproc.JobIAMBinding("editor", {
    jobId: "your-dataproc-job",
    role: "roles/editor",
    members: ["user:jane@example.com"],
});
```
```python
import pulumi
import pulumi_gcp as gcp

editor = gcp.dataproc.JobIAMBinding("editor",
    job_id="your-dataproc-job",
    role="roles/editor",
    members=["user:jane@example.com"])
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var editor = new Gcp.Dataproc.JobIAMBinding("editor", new()
    {
        JobId = "your-dataproc-job",
        Role = "roles/editor",
        Members = new[]
        {
            "user:jane@example.com",
        },
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/dataproc"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		_, err := dataproc.NewJobIAMBinding(ctx, "editor", &dataproc.JobIAMBindingArgs{
			JobId: pulumi.String("your-dataproc-job"),
			Role:  pulumi.String("roles/editor"),
			Members: pulumi.StringArray{
				pulumi.String("user:jane@example.com"),
			},
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.dataproc.JobIAMBinding;
import com.pulumi.gcp.dataproc.JobIAMBindingArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        var editor = new JobIAMBinding("editor", JobIAMBindingArgs.builder()
            .jobId("your-dataproc-job")
            .role("roles/editor")
            .members("user:jane@example.com")
            .build());

    }
}
```
```yaml
resources:
  editor:
    type: gcp:dataproc:JobIAMBinding
    properties:
      jobId: your-dataproc-job
      role: roles/editor
      members:
        - user:jane@example.com
```
<!--End PulumiCodeChooser -->

## gcp.dataproc.JobIAMMember

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const editor = new gcp.dataproc.JobIAMMember("editor", {
    jobId: "your-dataproc-job",
    role: "roles/editor",
    member: "user:jane@example.com",
});
```
```python
import pulumi
import pulumi_gcp as gcp

editor = gcp.dataproc.JobIAMMember("editor",
    job_id="your-dataproc-job",
    role="roles/editor",
    member="user:jane@example.com")
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var editor = new Gcp.Dataproc.JobIAMMember("editor", new()
    {
        JobId = "your-dataproc-job",
        Role = "roles/editor",
        Member = "user:jane@example.com",
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/dataproc"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		_, err := dataproc.NewJobIAMMember(ctx, "editor", &dataproc.JobIAMMemberArgs{
			JobId:  pulumi.String("your-dataproc-job"),
			Role:   pulumi.String("roles/editor"),
			Member: pulumi.String("user:jane@example.com"),
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.dataproc.JobIAMMember;
import com.pulumi.gcp.dataproc.JobIAMMemberArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        var editor = new JobIAMMember("editor", JobIAMMemberArgs.builder()
            .jobId("your-dataproc-job")
            .role("roles/editor")
            .member("user:jane@example.com")
            .build());

    }
}
```
```yaml
resources:
  editor:
    type: gcp:dataproc:JobIAMMember
    properties:
      jobId: your-dataproc-job
      role: roles/editor
      member: user:jane@example.com
```
<!--End PulumiCodeChooser -->

## gcp.dataproc.JobIAMPolicy

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const admin = gcp.organizations.getIAMPolicy({
    bindings: [{
        role: "roles/editor",
        members: ["user:jane@example.com"],
    }],
});
const editor = new gcp.dataproc.JobIAMPolicy("editor", {
    project: "your-project",
    region: "your-region",
    jobId: "your-dataproc-job",
    policyData: admin.then(admin => admin.policyData),
});
```
```python
import pulumi
import pulumi_gcp as gcp

admin = gcp.organizations.get_iam_policy(bindings=[{
    "role": "roles/editor",
    "members": ["user:jane@example.com"],
}])
editor = gcp.dataproc.JobIAMPolicy("editor",
    project="your-project",
    region="your-region",
    job_id="your-dataproc-job",
    policy_data=admin.policy_data)
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var admin = Gcp.Organizations.GetIAMPolicy.Invoke(new()
    {
        Bindings = new[]
        {
            new Gcp.Organizations.Inputs.GetIAMPolicyBindingInputArgs
            {
                Role = "roles/editor",
                Members = new[]
                {
                    "user:jane@example.com",
                },
            },
        },
    });

    var editor = new Gcp.Dataproc.JobIAMPolicy("editor", new()
    {
        Project = "your-project",
        Region = "your-region",
        JobId = "your-dataproc-job",
        PolicyData = admin.Apply(getIAMPolicyResult => getIAMPolicyResult.PolicyData),
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/dataproc"
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/organizations"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		admin, err := organizations.LookupIAMPolicy(ctx, &organizations.LookupIAMPolicyArgs{
			Bindings: []organizations.GetIAMPolicyBinding{
				{
					Role: "roles/editor",
					Members: []string{
						"user:jane@example.com",
					},
				},
			},
		}, nil)
		if err != nil {
			return err
		}
		_, err = dataproc.NewJobIAMPolicy(ctx, "editor", &dataproc.JobIAMPolicyArgs{
			Project:    pulumi.String("your-project"),
			Region:     pulumi.String("your-region"),
			JobId:      pulumi.String("your-dataproc-job"),
			PolicyData: pulumi.String(admin.PolicyData),
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.organizations.OrganizationsFunctions;
import com.pulumi.gcp.organizations.inputs.GetIAMPolicyArgs;
import com.pulumi.gcp.dataproc.JobIAMPolicy;
import com.pulumi.gcp.dataproc.JobIAMPolicyArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        final var admin = OrganizationsFunctions.getIAMPolicy(GetIAMPolicyArgs.builder()
            .bindings(GetIAMPolicyBindingArgs.builder()
                .role("roles/editor")
                .members("user:jane@example.com")
                .build())
            .build());

        var editor = new JobIAMPolicy("editor", JobIAMPolicyArgs.builder()
            .project("your-project")
            .region("your-region")
            .jobId("your-dataproc-job")
            .policyData(admin.applyValue(getIAMPolicyResult -> getIAMPolicyResult.policyData()))
            .build());

    }
}
```
```yaml
resources:
  editor:
    type: gcp:dataproc:JobIAMPolicy
    properties:
      project: your-project
      region: your-region
      jobId: your-dataproc-job
      policyData: ${admin.policyData}
variables:
  admin:
    fn::invoke:
      function: gcp:organizations:getIAMPolicy
      arguments:
        bindings:
          - role: roles/editor
            members:
              - user:jane@example.com
```
<!--End PulumiCodeChooser -->

## gcp.dataproc.JobIAMBinding

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const editor = new gcp.dataproc.JobIAMBinding("editor", {
    jobId: "your-dataproc-job",
    role: "roles/editor",
    members: ["user:jane@example.com"],
});
```
```python
import pulumi
import pulumi_gcp as gcp

editor = gcp.dataproc.JobIAMBinding("editor",
    job_id="your-dataproc-job",
    role="roles/editor",
    members=["user:jane@example.com"])
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var editor = new Gcp.Dataproc.JobIAMBinding("editor", new()
    {
        JobId = "your-dataproc-job",
        Role = "roles/editor",
        Members = new[]
        {
            "user:jane@example.com",
        },
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/dataproc"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		_, err := dataproc.NewJobIAMBinding(ctx, "editor", &dataproc.JobIAMBindingArgs{
			JobId: pulumi.String("your-dataproc-job"),
			Role:  pulumi.String("roles/editor"),
			Members: pulumi.StringArray{
				pulumi.String("user:jane@example.com"),
			},
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.dataproc.JobIAMBinding;
import com.pulumi.gcp.dataproc.JobIAMBindingArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        var editor = new JobIAMBinding("editor", JobIAMBindingArgs.builder()
            .jobId("your-dataproc-job")
            .role("roles/editor")
            .members("user:jane@example.com")
            .build());

    }
}
```
```yaml
resources:
  editor:
    type: gcp:dataproc:JobIAMBinding
    properties:
      jobId: your-dataproc-job
      role: roles/editor
      members:
        - user:jane@example.com
```
<!--End PulumiCodeChooser -->

## gcp.dataproc.JobIAMMember

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const editor = new gcp.dataproc.JobIAMMember("editor", {
    jobId: "your-dataproc-job",
    role: "roles/editor",
    member: "user:jane@example.com",
});
```
```python
import pulumi
import pulumi_gcp as gcp

editor = gcp.dataproc.JobIAMMember("editor",
    job_id="your-dataproc-job",
    role="roles/editor",
    member="user:jane@example.com")
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var editor = new Gcp.Dataproc.JobIAMMember("editor", new()
    {
        JobId = "your-dataproc-job",
        Role = "roles/editor",
        Member = "user:jane@example.com",
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/dataproc"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		_, err := dataproc.NewJobIAMMember(ctx, "editor", &dataproc.JobIAMMemberArgs{
			JobId:  pulumi.String("your-dataproc-job"),
			Role:   pulumi.String("roles/editor"),
			Member: pulumi.String("user:jane@example.com"),
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.dataproc.JobIAMMember;
import com.pulumi.gcp.dataproc.JobIAMMemberArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        var editor = new JobIAMMember("editor", JobIAMMemberArgs.builder()
            .jobId("your-dataproc-job")
            .role("roles/editor")
            .member("user:jane@example.com")
            .build());

    }
}
```
```yaml
resources:
  editor:
    type: gcp:dataproc:JobIAMMember
    properties:
      jobId: your-dataproc-job
      role: roles/editor
      member: user:jane@example.com
```
<!--End PulumiCodeChooser -->

## Import

### Importing IAM policies

IAM policy imports use the `job_id` identifier of the Dataproc Job resource only. For example:

* `projects/{project}/regions/{region}/jobs/{job_id}`

An `import` block (Terraform v1.5.0 and later) can be used to import IAM policies:

tf

import {

  id = "projects/{project}/regions/{region}/jobs/{job_id}"

  to = google_dataproc_job_iam_policy.default

}

The `pulumi import` command can also be used:

```sh
$ pulumi import gcp:dataproc/jobIAMMember:JobIAMMember default "projects/{project}/regions/{region}/jobs/{job_id}"
```

n
	conditionaB_:]
[
dataprocJobIAMMemberCondition8gcp:dataproc/JobIAMMemberCondition:JobIAMMemberCondition
jobId" 
member" Identities that will be granted the privilege in `role`.
Each entry can have one of the following values:
* **allUsers**: A special identifier that represents anyone who is on the internet; with or without a Google account.
* **allAuthenticatedUsers**: A special identifier that represents anyone who is authenticated with a Google account or a service account.
* **user:{emailid}**: An email address that represents a specific Google account. For example, alice@gmail.com or joe@example.com.
* **serviceAccount:{emailid}**: An email address that represents a service account. For example, my-other-app@appspot.gserviceaccount.com.
* **group:{emailid}**: An email address that represents a Google group. For example, admins@example.com.
* **domain:{domain}**: A G Suite domain (primary, instead of alias) name that represents all the users of that domain. For example, google.com or example.com.
o
projectB" ^The project in which the job belongs. If it
is not provided, the provider will use a default.
m
regionB" ]The region in which the job belongs. If it
is not provided, the provider will use a default.
ö
role" éThe role that should be applied. Only one
`gcp.dataproc.JobIAMBinding` can be used per role. Note that custom roles must be of the format
`[projects|organizations]/{parent-name}/roles/{role-name}`.

`gcp.dataproc.JobIAMPolicy` only:
"n
	conditionaB_:]
[
dataprocJobIAMMemberCondition8gcp:dataproc/JobIAMMemberCondition:JobIAMMemberCondition":
etag" .(Computed) The etag of the jobs's IAM policy.
"
jobId" "
member" Identities that will be granted the privilege in `role`.
Each entry can have one of the following values:
* **allUsers**: A special identifier that represents anyone who is on the internet; with or without a Google account.
* **allAuthenticatedUsers**: A special identifier that represents anyone who is authenticated with a Google account or a service account.
* **user:{emailid}**: An email address that represents a specific Google account. For example, alice@gmail.com or joe@example.com.
* **serviceAccount:{emailid}**: An email address that represents a service account. For example, my-other-app@appspot.gserviceaccount.com.
* **group:{emailid}**: An email address that represents a Google group. For example, admins@example.com.
* **domain:{domain}**: A G Suite domain (primary, instead of alias) name that represents all the users of that domain. For example, google.com or example.com.
"m
project" ^The project in which the job belongs. If it
is not provided, the provider will use a default.
"k
region" ]The region in which the job belongs. If it
is not provided, the provider will use a default.
"ö
role" éThe role that should be applied. Only one
`gcp.dataproc.JobIAMBinding` can be used per role. Note that custom roles must be of the format
`[projects|organizations]/{parent-name}/roles/{role-name}`.

`gcp.dataproc.JobIAMPolicy` only:
*ë
@
dataprocJobIAMPolicy&gcp:dataproc/jobIAMPolicy:JobIAMPolicyÃThree different resources help you manage IAM policies on dataproc jobs. Each of these resources serves a different use case:

* `gcp.dataproc.JobIAMPolicy`: Authoritative. Sets the IAM policy for the job and replaces any existing policy already attached.
* `gcp.dataproc.JobIAMBinding`: Authoritative for a given role. Updates the IAM policy to grant a role to a list of members. Other roles within the IAM policy for the job are preserved.
* `gcp.dataproc.JobIAMMember`: Non-authoritative. Updates the IAM policy to grant a role to a new member. Other members for the role for the job are preserved.

> **Note:** `gcp.dataproc.JobIAMPolicy` **cannot** be used in conjunction with `gcp.dataproc.JobIAMBinding` and `gcp.dataproc.JobIAMMember` or they will fight over what your policy should be. In addition, be careful not to accidentally unset ownership of the job as `gcp.dataproc.JobIAMPolicy` replaces the entire policy.

> **Note:** `gcp.dataproc.JobIAMBinding` resources **can be** used in conjunction with `gcp.dataproc.JobIAMMember` resources **only if** they do not grant privilege to the same role.

## gcp.dataproc.JobIAMPolicy

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const admin = gcp.organizations.getIAMPolicy({
    bindings: [{
        role: "roles/editor",
        members: ["user:jane@example.com"],
    }],
});
const editor = new gcp.dataproc.JobIAMPolicy("editor", {
    project: "your-project",
    region: "your-region",
    jobId: "your-dataproc-job",
    policyData: admin.then(admin => admin.policyData),
});
```
```python
import pulumi
import pulumi_gcp as gcp

admin = gcp.organizations.get_iam_policy(bindings=[{
    "role": "roles/editor",
    "members": ["user:jane@example.com"],
}])
editor = gcp.dataproc.JobIAMPolicy("editor",
    project="your-project",
    region="your-region",
    job_id="your-dataproc-job",
    policy_data=admin.policy_data)
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var admin = Gcp.Organizations.GetIAMPolicy.Invoke(new()
    {
        Bindings = new[]
        {
            new Gcp.Organizations.Inputs.GetIAMPolicyBindingInputArgs
            {
                Role = "roles/editor",
                Members = new[]
                {
                    "user:jane@example.com",
                },
            },
        },
    });

    var editor = new Gcp.Dataproc.JobIAMPolicy("editor", new()
    {
        Project = "your-project",
        Region = "your-region",
        JobId = "your-dataproc-job",
        PolicyData = admin.Apply(getIAMPolicyResult => getIAMPolicyResult.PolicyData),
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/dataproc"
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/organizations"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		admin, err := organizations.LookupIAMPolicy(ctx, &organizations.LookupIAMPolicyArgs{
			Bindings: []organizations.GetIAMPolicyBinding{
				{
					Role: "roles/editor",
					Members: []string{
						"user:jane@example.com",
					},
				},
			},
		}, nil)
		if err != nil {
			return err
		}
		_, err = dataproc.NewJobIAMPolicy(ctx, "editor", &dataproc.JobIAMPolicyArgs{
			Project:    pulumi.String("your-project"),
			Region:     pulumi.String("your-region"),
			JobId:      pulumi.String("your-dataproc-job"),
			PolicyData: pulumi.String(admin.PolicyData),
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.organizations.OrganizationsFunctions;
import com.pulumi.gcp.organizations.inputs.GetIAMPolicyArgs;
import com.pulumi.gcp.dataproc.JobIAMPolicy;
import com.pulumi.gcp.dataproc.JobIAMPolicyArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        final var admin = OrganizationsFunctions.getIAMPolicy(GetIAMPolicyArgs.builder()
            .bindings(GetIAMPolicyBindingArgs.builder()
                .role("roles/editor")
                .members("user:jane@example.com")
                .build())
            .build());

        var editor = new JobIAMPolicy("editor", JobIAMPolicyArgs.builder()
            .project("your-project")
            .region("your-region")
            .jobId("your-dataproc-job")
            .policyData(admin.applyValue(getIAMPolicyResult -> getIAMPolicyResult.policyData()))
            .build());

    }
}
```
```yaml
resources:
  editor:
    type: gcp:dataproc:JobIAMPolicy
    properties:
      project: your-project
      region: your-region
      jobId: your-dataproc-job
      policyData: ${admin.policyData}
variables:
  admin:
    fn::invoke:
      function: gcp:organizations:getIAMPolicy
      arguments:
        bindings:
          - role: roles/editor
            members:
              - user:jane@example.com
```
<!--End PulumiCodeChooser -->

## gcp.dataproc.JobIAMBinding

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const editor = new gcp.dataproc.JobIAMBinding("editor", {
    jobId: "your-dataproc-job",
    role: "roles/editor",
    members: ["user:jane@example.com"],
});
```
```python
import pulumi
import pulumi_gcp as gcp

editor = gcp.dataproc.JobIAMBinding("editor",
    job_id="your-dataproc-job",
    role="roles/editor",
    members=["user:jane@example.com"])
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var editor = new Gcp.Dataproc.JobIAMBinding("editor", new()
    {
        JobId = "your-dataproc-job",
        Role = "roles/editor",
        Members = new[]
        {
            "user:jane@example.com",
        },
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/dataproc"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		_, err := dataproc.NewJobIAMBinding(ctx, "editor", &dataproc.JobIAMBindingArgs{
			JobId: pulumi.String("your-dataproc-job"),
			Role:  pulumi.String("roles/editor"),
			Members: pulumi.StringArray{
				pulumi.String("user:jane@example.com"),
			},
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.dataproc.JobIAMBinding;
import com.pulumi.gcp.dataproc.JobIAMBindingArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        var editor = new JobIAMBinding("editor", JobIAMBindingArgs.builder()
            .jobId("your-dataproc-job")
            .role("roles/editor")
            .members("user:jane@example.com")
            .build());

    }
}
```
```yaml
resources:
  editor:
    type: gcp:dataproc:JobIAMBinding
    properties:
      jobId: your-dataproc-job
      role: roles/editor
      members:
        - user:jane@example.com
```
<!--End PulumiCodeChooser -->

## gcp.dataproc.JobIAMMember

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const editor = new gcp.dataproc.JobIAMMember("editor", {
    jobId: "your-dataproc-job",
    role: "roles/editor",
    member: "user:jane@example.com",
});
```
```python
import pulumi
import pulumi_gcp as gcp

editor = gcp.dataproc.JobIAMMember("editor",
    job_id="your-dataproc-job",
    role="roles/editor",
    member="user:jane@example.com")
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var editor = new Gcp.Dataproc.JobIAMMember("editor", new()
    {
        JobId = "your-dataproc-job",
        Role = "roles/editor",
        Member = "user:jane@example.com",
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/dataproc"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		_, err := dataproc.NewJobIAMMember(ctx, "editor", &dataproc.JobIAMMemberArgs{
			JobId:  pulumi.String("your-dataproc-job"),
			Role:   pulumi.String("roles/editor"),
			Member: pulumi.String("user:jane@example.com"),
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.dataproc.JobIAMMember;
import com.pulumi.gcp.dataproc.JobIAMMemberArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        var editor = new JobIAMMember("editor", JobIAMMemberArgs.builder()
            .jobId("your-dataproc-job")
            .role("roles/editor")
            .member("user:jane@example.com")
            .build());

    }
}
```
```yaml
resources:
  editor:
    type: gcp:dataproc:JobIAMMember
    properties:
      jobId: your-dataproc-job
      role: roles/editor
      member: user:jane@example.com
```
<!--End PulumiCodeChooser -->

## gcp.dataproc.JobIAMPolicy

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const admin = gcp.organizations.getIAMPolicy({
    bindings: [{
        role: "roles/editor",
        members: ["user:jane@example.com"],
    }],
});
const editor = new gcp.dataproc.JobIAMPolicy("editor", {
    project: "your-project",
    region: "your-region",
    jobId: "your-dataproc-job",
    policyData: admin.then(admin => admin.policyData),
});
```
```python
import pulumi
import pulumi_gcp as gcp

admin = gcp.organizations.get_iam_policy(bindings=[{
    "role": "roles/editor",
    "members": ["user:jane@example.com"],
}])
editor = gcp.dataproc.JobIAMPolicy("editor",
    project="your-project",
    region="your-region",
    job_id="your-dataproc-job",
    policy_data=admin.policy_data)
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var admin = Gcp.Organizations.GetIAMPolicy.Invoke(new()
    {
        Bindings = new[]
        {
            new Gcp.Organizations.Inputs.GetIAMPolicyBindingInputArgs
            {
                Role = "roles/editor",
                Members = new[]
                {
                    "user:jane@example.com",
                },
            },
        },
    });

    var editor = new Gcp.Dataproc.JobIAMPolicy("editor", new()
    {
        Project = "your-project",
        Region = "your-region",
        JobId = "your-dataproc-job",
        PolicyData = admin.Apply(getIAMPolicyResult => getIAMPolicyResult.PolicyData),
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/dataproc"
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/organizations"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		admin, err := organizations.LookupIAMPolicy(ctx, &organizations.LookupIAMPolicyArgs{
			Bindings: []organizations.GetIAMPolicyBinding{
				{
					Role: "roles/editor",
					Members: []string{
						"user:jane@example.com",
					},
				},
			},
		}, nil)
		if err != nil {
			return err
		}
		_, err = dataproc.NewJobIAMPolicy(ctx, "editor", &dataproc.JobIAMPolicyArgs{
			Project:    pulumi.String("your-project"),
			Region:     pulumi.String("your-region"),
			JobId:      pulumi.String("your-dataproc-job"),
			PolicyData: pulumi.String(admin.PolicyData),
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.organizations.OrganizationsFunctions;
import com.pulumi.gcp.organizations.inputs.GetIAMPolicyArgs;
import com.pulumi.gcp.dataproc.JobIAMPolicy;
import com.pulumi.gcp.dataproc.JobIAMPolicyArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        final var admin = OrganizationsFunctions.getIAMPolicy(GetIAMPolicyArgs.builder()
            .bindings(GetIAMPolicyBindingArgs.builder()
                .role("roles/editor")
                .members("user:jane@example.com")
                .build())
            .build());

        var editor = new JobIAMPolicy("editor", JobIAMPolicyArgs.builder()
            .project("your-project")
            .region("your-region")
            .jobId("your-dataproc-job")
            .policyData(admin.applyValue(getIAMPolicyResult -> getIAMPolicyResult.policyData()))
            .build());

    }
}
```
```yaml
resources:
  editor:
    type: gcp:dataproc:JobIAMPolicy
    properties:
      project: your-project
      region: your-region
      jobId: your-dataproc-job
      policyData: ${admin.policyData}
variables:
  admin:
    fn::invoke:
      function: gcp:organizations:getIAMPolicy
      arguments:
        bindings:
          - role: roles/editor
            members:
              - user:jane@example.com
```
<!--End PulumiCodeChooser -->

## gcp.dataproc.JobIAMBinding

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const editor = new gcp.dataproc.JobIAMBinding("editor", {
    jobId: "your-dataproc-job",
    role: "roles/editor",
    members: ["user:jane@example.com"],
});
```
```python
import pulumi
import pulumi_gcp as gcp

editor = gcp.dataproc.JobIAMBinding("editor",
    job_id="your-dataproc-job",
    role="roles/editor",
    members=["user:jane@example.com"])
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var editor = new Gcp.Dataproc.JobIAMBinding("editor", new()
    {
        JobId = "your-dataproc-job",
        Role = "roles/editor",
        Members = new[]
        {
            "user:jane@example.com",
        },
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/dataproc"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		_, err := dataproc.NewJobIAMBinding(ctx, "editor", &dataproc.JobIAMBindingArgs{
			JobId: pulumi.String("your-dataproc-job"),
			Role:  pulumi.String("roles/editor"),
			Members: pulumi.StringArray{
				pulumi.String("user:jane@example.com"),
			},
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.dataproc.JobIAMBinding;
import com.pulumi.gcp.dataproc.JobIAMBindingArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        var editor = new JobIAMBinding("editor", JobIAMBindingArgs.builder()
            .jobId("your-dataproc-job")
            .role("roles/editor")
            .members("user:jane@example.com")
            .build());

    }
}
```
```yaml
resources:
  editor:
    type: gcp:dataproc:JobIAMBinding
    properties:
      jobId: your-dataproc-job
      role: roles/editor
      members:
        - user:jane@example.com
```
<!--End PulumiCodeChooser -->

## gcp.dataproc.JobIAMMember

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const editor = new gcp.dataproc.JobIAMMember("editor", {
    jobId: "your-dataproc-job",
    role: "roles/editor",
    member: "user:jane@example.com",
});
```
```python
import pulumi
import pulumi_gcp as gcp

editor = gcp.dataproc.JobIAMMember("editor",
    job_id="your-dataproc-job",
    role="roles/editor",
    member="user:jane@example.com")
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var editor = new Gcp.Dataproc.JobIAMMember("editor", new()
    {
        JobId = "your-dataproc-job",
        Role = "roles/editor",
        Member = "user:jane@example.com",
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/dataproc"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		_, err := dataproc.NewJobIAMMember(ctx, "editor", &dataproc.JobIAMMemberArgs{
			JobId:  pulumi.String("your-dataproc-job"),
			Role:   pulumi.String("roles/editor"),
			Member: pulumi.String("user:jane@example.com"),
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.dataproc.JobIAMMember;
import com.pulumi.gcp.dataproc.JobIAMMemberArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        var editor = new JobIAMMember("editor", JobIAMMemberArgs.builder()
            .jobId("your-dataproc-job")
            .role("roles/editor")
            .member("user:jane@example.com")
            .build());

    }
}
```
```yaml
resources:
  editor:
    type: gcp:dataproc:JobIAMMember
    properties:
      jobId: your-dataproc-job
      role: roles/editor
      member: user:jane@example.com
```
<!--End PulumiCodeChooser -->

## Import

### Importing IAM policies

IAM policy imports use the `job_id` identifier of the Dataproc Job resource only. For example:

* `projects/{project}/regions/{region}/jobs/{job_id}`

An `import` block (Terraform v1.5.0 and later) can be used to import IAM policies:

tf

import {

  id = "projects/{project}/regions/{region}/jobs/{job_id}"

  to = google_dataproc_job_iam_policy.default

}

The `pulumi import` command can also be used:

```sh
$ pulumi import gcp:dataproc/jobIAMPolicy:JobIAMPolicy default "projects/{project}/regions/{region}/jobs/{job_id}"
```


jobId" f

policyData" TThe policy data generated by a `gcp.organizations.getIAMPolicy` data source.

- - -
o
projectB" ^The project in which the job belongs. If it
is not provided, the provider will use a default.
m
regionB" ]The region in which the job belongs. If it
is not provided, the provider will use a default.
":
etag" .(Computed) The etag of the jobs's IAM policy.
"
jobId" "f

policyData" TThe policy data generated by a `gcp.organizations.getIAMPolicy` data source.

- - -
"m
project" ^The project in which the job belongs. If it
is not provided, the provider will use a default.
"k
region" ]The region in which the job belongs. If it
is not provided, the provider will use a default.
*ö
U
dataprocMetastoreFederation4gcp:dataproc/metastoreFederation:MetastoreFederationÁpA managed metastore federation.



## Example Usage

### Dataproc Metastore Federation Basic


<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const defaultMetastoreService = new gcp.dataproc.MetastoreService("default", {
    serviceId: "metastore-service",
    location: "us-central1",
    tier: "DEVELOPER",
    hiveMetastoreConfig: {
        version: "3.1.2",
        endpointProtocol: "GRPC",
    },
});
const _default = new gcp.dataproc.MetastoreFederation("default", {
    location: "us-central1",
    federationId: "metastore-fed",
    version: "3.1.2",
    backendMetastores: [{
        rank: "1",
        name: defaultMetastoreService.id,
        metastoreType: "DATAPROC_METASTORE",
    }],
});
```
```python
import pulumi
import pulumi_gcp as gcp

default_metastore_service = gcp.dataproc.MetastoreService("default",
    service_id="metastore-service",
    location="us-central1",
    tier="DEVELOPER",
    hive_metastore_config={
        "version": "3.1.2",
        "endpoint_protocol": "GRPC",
    })
default = gcp.dataproc.MetastoreFederation("default",
    location="us-central1",
    federation_id="metastore-fed",
    version="3.1.2",
    backend_metastores=[{
        "rank": "1",
        "name": default_metastore_service.id,
        "metastore_type": "DATAPROC_METASTORE",
    }])
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var defaultMetastoreService = new Gcp.Dataproc.MetastoreService("default", new()
    {
        ServiceId = "metastore-service",
        Location = "us-central1",
        Tier = "DEVELOPER",
        HiveMetastoreConfig = new Gcp.Dataproc.Inputs.MetastoreServiceHiveMetastoreConfigArgs
        {
            Version = "3.1.2",
            EndpointProtocol = "GRPC",
        },
    });

    var @default = new Gcp.Dataproc.MetastoreFederation("default", new()
    {
        Location = "us-central1",
        FederationId = "metastore-fed",
        Version = "3.1.2",
        BackendMetastores = new[]
        {
            new Gcp.Dataproc.Inputs.MetastoreFederationBackendMetastoreArgs
            {
                Rank = "1",
                Name = defaultMetastoreService.Id,
                MetastoreType = "DATAPROC_METASTORE",
            },
        },
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/dataproc"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		defaultMetastoreService, err := dataproc.NewMetastoreService(ctx, "default", &dataproc.MetastoreServiceArgs{
			ServiceId: pulumi.String("metastore-service"),
			Location:  pulumi.String("us-central1"),
			Tier:      pulumi.String("DEVELOPER"),
			HiveMetastoreConfig: &dataproc.MetastoreServiceHiveMetastoreConfigArgs{
				Version:          pulumi.String("3.1.2"),
				EndpointProtocol: pulumi.String("GRPC"),
			},
		})
		if err != nil {
			return err
		}
		_, err = dataproc.NewMetastoreFederation(ctx, "default", &dataproc.MetastoreFederationArgs{
			Location:     pulumi.String("us-central1"),
			FederationId: pulumi.String("metastore-fed"),
			Version:      pulumi.String("3.1.2"),
			BackendMetastores: dataproc.MetastoreFederationBackendMetastoreArray{
				&dataproc.MetastoreFederationBackendMetastoreArgs{
					Rank:          pulumi.String("1"),
					Name:          defaultMetastoreService.ID(),
					MetastoreType: pulumi.String("DATAPROC_METASTORE"),
				},
			},
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.dataproc.MetastoreService;
import com.pulumi.gcp.dataproc.MetastoreServiceArgs;
import com.pulumi.gcp.dataproc.inputs.MetastoreServiceHiveMetastoreConfigArgs;
import com.pulumi.gcp.dataproc.MetastoreFederation;
import com.pulumi.gcp.dataproc.MetastoreFederationArgs;
import com.pulumi.gcp.dataproc.inputs.MetastoreFederationBackendMetastoreArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        var defaultMetastoreService = new MetastoreService("defaultMetastoreService", MetastoreServiceArgs.builder()
            .serviceId("metastore-service")
            .location("us-central1")
            .tier("DEVELOPER")
            .hiveMetastoreConfig(MetastoreServiceHiveMetastoreConfigArgs.builder()
                .version("3.1.2")
                .endpointProtocol("GRPC")
                .build())
            .build());

        var default_ = new MetastoreFederation("default", MetastoreFederationArgs.builder()
            .location("us-central1")
            .federationId("metastore-fed")
            .version("3.1.2")
            .backendMetastores(MetastoreFederationBackendMetastoreArgs.builder()
                .rank("1")
                .name(defaultMetastoreService.id())
                .metastoreType("DATAPROC_METASTORE")
                .build())
            .build());

    }
}
```
```yaml
resources:
  default:
    type: gcp:dataproc:MetastoreFederation
    properties:
      location: us-central1
      federationId: metastore-fed
      version: 3.1.2
      backendMetastores:
        - rank: '1'
          name: ${defaultMetastoreService.id}
          metastoreType: DATAPROC_METASTORE
  defaultMetastoreService:
    type: gcp:dataproc:MetastoreService
    name: default
    properties:
      serviceId: metastore-service
      location: us-central1
      tier: DEVELOPER
      hiveMetastoreConfig:
        version: 3.1.2
        endpointProtocol: GRPC
```
<!--End PulumiCodeChooser -->
### Dataproc Metastore Federation Bigquery


<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const defaultMetastoreService = new gcp.dataproc.MetastoreService("default", {
    serviceId: "metastore-service",
    location: "us-central1",
    tier: "DEVELOPER",
    hiveMetastoreConfig: {
        version: "3.1.2",
        endpointProtocol: "GRPC",
    },
});
const project = gcp.organizations.getProject({});
const _default = new gcp.dataproc.MetastoreFederation("default", {
    location: "us-central1",
    federationId: "metastore-fed",
    version: "3.1.2",
    backendMetastores: [
        {
            rank: "2",
            name: project.then(project => project.id),
            metastoreType: "BIGQUERY",
        },
        {
            rank: "1",
            name: defaultMetastoreService.id,
            metastoreType: "DATAPROC_METASTORE",
        },
    ],
});
```
```python
import pulumi
import pulumi_gcp as gcp

default_metastore_service = gcp.dataproc.MetastoreService("default",
    service_id="metastore-service",
    location="us-central1",
    tier="DEVELOPER",
    hive_metastore_config={
        "version": "3.1.2",
        "endpoint_protocol": "GRPC",
    })
project = gcp.organizations.get_project()
default = gcp.dataproc.MetastoreFederation("default",
    location="us-central1",
    federation_id="metastore-fed",
    version="3.1.2",
    backend_metastores=[
        {
            "rank": "2",
            "name": project.id,
            "metastore_type": "BIGQUERY",
        },
        {
            "rank": "1",
            "name": default_metastore_service.id,
            "metastore_type": "DATAPROC_METASTORE",
        },
    ])
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var defaultMetastoreService = new Gcp.Dataproc.MetastoreService("default", new()
    {
        ServiceId = "metastore-service",
        Location = "us-central1",
        Tier = "DEVELOPER",
        HiveMetastoreConfig = new Gcp.Dataproc.Inputs.MetastoreServiceHiveMetastoreConfigArgs
        {
            Version = "3.1.2",
            EndpointProtocol = "GRPC",
        },
    });

    var project = Gcp.Organizations.GetProject.Invoke();

    var @default = new Gcp.Dataproc.MetastoreFederation("default", new()
    {
        Location = "us-central1",
        FederationId = "metastore-fed",
        Version = "3.1.2",
        BackendMetastores = new[]
        {
            new Gcp.Dataproc.Inputs.MetastoreFederationBackendMetastoreArgs
            {
                Rank = "2",
                Name = project.Apply(getProjectResult => getProjectResult.Id),
                MetastoreType = "BIGQUERY",
            },
            new Gcp.Dataproc.Inputs.MetastoreFederationBackendMetastoreArgs
            {
                Rank = "1",
                Name = defaultMetastoreService.Id,
                MetastoreType = "DATAPROC_METASTORE",
            },
        },
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/dataproc"
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/organizations"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		defaultMetastoreService, err := dataproc.NewMetastoreService(ctx, "default", &dataproc.MetastoreServiceArgs{
			ServiceId: pulumi.String("metastore-service"),
			Location:  pulumi.String("us-central1"),
			Tier:      pulumi.String("DEVELOPER"),
			HiveMetastoreConfig: &dataproc.MetastoreServiceHiveMetastoreConfigArgs{
				Version:          pulumi.String("3.1.2"),
				EndpointProtocol: pulumi.String("GRPC"),
			},
		})
		if err != nil {
			return err
		}
		project, err := organizations.LookupProject(ctx, &organizations.LookupProjectArgs{}, nil)
		if err != nil {
			return err
		}
		_, err = dataproc.NewMetastoreFederation(ctx, "default", &dataproc.MetastoreFederationArgs{
			Location:     pulumi.String("us-central1"),
			FederationId: pulumi.String("metastore-fed"),
			Version:      pulumi.String("3.1.2"),
			BackendMetastores: dataproc.MetastoreFederationBackendMetastoreArray{
				&dataproc.MetastoreFederationBackendMetastoreArgs{
					Rank:          pulumi.String("2"),
					Name:          pulumi.String(project.Id),
					MetastoreType: pulumi.String("BIGQUERY"),
				},
				&dataproc.MetastoreFederationBackendMetastoreArgs{
					Rank:          pulumi.String("1"),
					Name:          defaultMetastoreService.ID(),
					MetastoreType: pulumi.String("DATAPROC_METASTORE"),
				},
			},
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.dataproc.MetastoreService;
import com.pulumi.gcp.dataproc.MetastoreServiceArgs;
import com.pulumi.gcp.dataproc.inputs.MetastoreServiceHiveMetastoreConfigArgs;
import com.pulumi.gcp.organizations.OrganizationsFunctions;
import com.pulumi.gcp.organizations.inputs.GetProjectArgs;
import com.pulumi.gcp.dataproc.MetastoreFederation;
import com.pulumi.gcp.dataproc.MetastoreFederationArgs;
import com.pulumi.gcp.dataproc.inputs.MetastoreFederationBackendMetastoreArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        var defaultMetastoreService = new MetastoreService("defaultMetastoreService", MetastoreServiceArgs.builder()
            .serviceId("metastore-service")
            .location("us-central1")
            .tier("DEVELOPER")
            .hiveMetastoreConfig(MetastoreServiceHiveMetastoreConfigArgs.builder()
                .version("3.1.2")
                .endpointProtocol("GRPC")
                .build())
            .build());

        final var project = OrganizationsFunctions.getProject();

        var default_ = new MetastoreFederation("default", MetastoreFederationArgs.builder()
            .location("us-central1")
            .federationId("metastore-fed")
            .version("3.1.2")
            .backendMetastores(            
                MetastoreFederationBackendMetastoreArgs.builder()
                    .rank("2")
                    .name(project.applyValue(getProjectResult -> getProjectResult.id()))
                    .metastoreType("BIGQUERY")
                    .build(),
                MetastoreFederationBackendMetastoreArgs.builder()
                    .rank("1")
                    .name(defaultMetastoreService.id())
                    .metastoreType("DATAPROC_METASTORE")
                    .build())
            .build());

    }
}
```
```yaml
resources:
  default:
    type: gcp:dataproc:MetastoreFederation
    properties:
      location: us-central1
      federationId: metastore-fed
      version: 3.1.2
      backendMetastores:
        - rank: '2'
          name: ${project.id}
          metastoreType: BIGQUERY
        - rank: '1'
          name: ${defaultMetastoreService.id}
          metastoreType: DATAPROC_METASTORE
  defaultMetastoreService:
    type: gcp:dataproc:MetastoreService
    name: default
    properties:
      serviceId: metastore-service
      location: us-central1
      tier: DEVELOPER
      hiveMetastoreConfig:
        version: 3.1.2
        endpointProtocol: GRPC
variables:
  project:
    fn::invoke:
      function: gcp:organizations:getProject
      arguments: {}
```
<!--End PulumiCodeChooser -->

## Import

Federation can be imported using any of these accepted formats:

* `projects/{{project}}/locations/{{location}}/federations/{{federation_id}}`

* `{{project}}/{{location}}/{{federation_id}}`

* `{{location}}/{{federation_id}}`

When using the `pulumi import` command, Federation can be imported using one of the formats above. For example:

```sh
$ pulumi import gcp:dataproc/metastoreFederation:MetastoreFederation default projects/{{project}}/locations/{{location}}/federations/{{federation_id}}
```

```sh
$ pulumi import gcp:dataproc/metastoreFederation:MetastoreFederation default {{project}}/{{location}}/{{federation_id}}
```

```sh
$ pulumi import gcp:dataproc/metastoreFederation:MetastoreFederation default {{location}}/{{federation_id}}
```

Ë
backendMetastores*:

dataproc#MetastoreFederationBackendMetastoreTgcp:dataproc/MetastoreFederationBackendMetastore:MetastoreFederationBackendMetastore¤A map from BackendMetastore rank to BackendMetastores from which the federation service serves metadata at query time. The map key represents the order in which BackendMetastores should be evaluated to resolve database names at query time and should be greater than or equal to zero. A BackendMetastore with a lower number will be evaluated before a BackendMetastore with a higher number.
Structure is documented below.
ó
federationId" ÞThe ID of the metastore federation. The id must contain only letters (a-z, A-Z), numbers (0-9), underscores (_),
and hyphens (-). Cannot begin or end with underscore or hyphen. Must consist of between
3 and 63 characters.

labelsB2" øUser-defined labels for the metastore federation. **Note**: This field is non-authoritative, and will only manage the
labels present in your configuration. Please refer to the field 'effective_labels' for all of the labels present on the
resource.
M
locationB" ;The location where the metastore federation should reside.

projectB" 
version" The Apache Hive metastore version of the federation. All backend metastore versions must be compatible with the federation version.
"Ë
backendMetastores*:

dataproc#MetastoreFederationBackendMetastoreTgcp:dataproc/MetastoreFederationBackendMetastore:MetastoreFederationBackendMetastore¤A map from BackendMetastore rank to BackendMetastores from which the federation service serves metadata at query time. The map key represents the order in which BackendMetastores should be evaluated to resolve database names at query time and should be greater than or equal to zero. A BackendMetastore with a lower number will be evaluated before a BackendMetastore with a higher number.
Structure is documented below.
"¦
effectiveLabels2" All of labels (key/value pairs) present on the resource in GCP, including the labels configured through Pulumi, other clients and services.
"T
endpointUri" AThe URI of the endpoint used to access the metastore federation.
"ó
federationId" ÞThe ID of the metastore federation. The id must contain only letters (a-z, A-Z), numbers (0-9), underscores (_),
and hyphens (-). Cannot begin or end with underscore or hyphen. Must consist of between
3 and 63 characters.
"
labelsB2" øUser-defined labels for the metastore federation. **Note**: This field is non-authoritative, and will only manage the
labels present in your configuration. Please refer to the field 'effective_labels' for all of the labels present on the
resource.
"M
locationB" ;The location where the metastore federation should reside.
"D
name" 8The relative resource name of the metastore federation.
"
project" "
pulumiLabels2" mThe combination of labels configured directly on the resource
and default labels configured on the provider.
"<
state" /The current state of the metastore federation.
"n
stateMessage" ZAdditional information about the current state of the metastore federation, if available.
"P
uid" EThe globally unique resource identifier of the metastore federation.
"
version" The Apache Hive metastore version of the federation. All backend metastore versions must be compatible with the federation version.
*ïë
s
dataprocMetastoreFederationIamBindingHgcp:dataproc/metastoreFederationIamBinding:MetastoreFederationIamBindingÝÆThree different resources help you manage your IAM policy for Dataproc metastore Federation. Each of these resources serves a different use case:

* `gcp.dataproc.MetastoreFederationIamPolicy`: Authoritative. Sets the IAM policy for the federation and replaces any existing policy already attached.
* `gcp.dataproc.MetastoreFederationIamBinding`: Authoritative for a given role. Updates the IAM policy to grant a role to a list of members. Other roles within the IAM policy for the federation are preserved.
* `gcp.dataproc.MetastoreFederationIamMember`: Non-authoritative. Updates the IAM policy to grant a role to a new member. Other members for the role for the federation are preserved.

A data source can be used to retrieve policy data in advent you do not need creation

* `gcp.dataproc.MetastoreFederationIamPolicy`: Retrieves the IAM policy for the federation

> **Note:** `gcp.dataproc.MetastoreFederationIamPolicy` **cannot** be used in conjunction with `gcp.dataproc.MetastoreFederationIamBinding` and `gcp.dataproc.MetastoreFederationIamMember` or they will fight over what your policy should be.

> **Note:** `gcp.dataproc.MetastoreFederationIamBinding` resources **can be** used in conjunction with `gcp.dataproc.MetastoreFederationIamMember` resources **only if** they do not grant privilege to the same role.



## gcp.dataproc.MetastoreFederationIamPolicy

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const admin = gcp.organizations.getIAMPolicy({
    bindings: [{
        role: "roles/viewer",
        members: ["user:jane@example.com"],
    }],
});
const policy = new gcp.dataproc.MetastoreFederationIamPolicy("policy", {
    project: _default.project,
    location: _default.location,
    federationId: _default.federationId,
    policyData: admin.then(admin => admin.policyData),
});
```
```python
import pulumi
import pulumi_gcp as gcp

admin = gcp.organizations.get_iam_policy(bindings=[{
    "role": "roles/viewer",
    "members": ["user:jane@example.com"],
}])
policy = gcp.dataproc.MetastoreFederationIamPolicy("policy",
    project=default["project"],
    location=default["location"],
    federation_id=default["federationId"],
    policy_data=admin.policy_data)
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var admin = Gcp.Organizations.GetIAMPolicy.Invoke(new()
    {
        Bindings = new[]
        {
            new Gcp.Organizations.Inputs.GetIAMPolicyBindingInputArgs
            {
                Role = "roles/viewer",
                Members = new[]
                {
                    "user:jane@example.com",
                },
            },
        },
    });

    var policy = new Gcp.Dataproc.MetastoreFederationIamPolicy("policy", new()
    {
        Project = @default.Project,
        Location = @default.Location,
        FederationId = @default.FederationId,
        PolicyData = admin.Apply(getIAMPolicyResult => getIAMPolicyResult.PolicyData),
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/dataproc"
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/organizations"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		admin, err := organizations.LookupIAMPolicy(ctx, &organizations.LookupIAMPolicyArgs{
			Bindings: []organizations.GetIAMPolicyBinding{
				{
					Role: "roles/viewer",
					Members: []string{
						"user:jane@example.com",
					},
				},
			},
		}, nil)
		if err != nil {
			return err
		}
		_, err = dataproc.NewMetastoreFederationIamPolicy(ctx, "policy", &dataproc.MetastoreFederationIamPolicyArgs{
			Project:      pulumi.Any(_default.Project),
			Location:     pulumi.Any(_default.Location),
			FederationId: pulumi.Any(_default.FederationId),
			PolicyData:   pulumi.String(admin.PolicyData),
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.organizations.OrganizationsFunctions;
import com.pulumi.gcp.organizations.inputs.GetIAMPolicyArgs;
import com.pulumi.gcp.dataproc.MetastoreFederationIamPolicy;
import com.pulumi.gcp.dataproc.MetastoreFederationIamPolicyArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        final var admin = OrganizationsFunctions.getIAMPolicy(GetIAMPolicyArgs.builder()
            .bindings(GetIAMPolicyBindingArgs.builder()
                .role("roles/viewer")
                .members("user:jane@example.com")
                .build())
            .build());

        var policy = new MetastoreFederationIamPolicy("policy", MetastoreFederationIamPolicyArgs.builder()
            .project(default_.project())
            .location(default_.location())
            .federationId(default_.federationId())
            .policyData(admin.applyValue(getIAMPolicyResult -> getIAMPolicyResult.policyData()))
            .build());

    }
}
```
```yaml
resources:
  policy:
    type: gcp:dataproc:MetastoreFederationIamPolicy
    properties:
      project: ${default.project}
      location: ${default.location}
      federationId: ${default.federationId}
      policyData: ${admin.policyData}
variables:
  admin:
    fn::invoke:
      function: gcp:organizations:getIAMPolicy
      arguments:
        bindings:
          - role: roles/viewer
            members:
              - user:jane@example.com
```
<!--End PulumiCodeChooser -->

## gcp.dataproc.MetastoreFederationIamBinding

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const binding = new gcp.dataproc.MetastoreFederationIamBinding("binding", {
    project: _default.project,
    location: _default.location,
    federationId: _default.federationId,
    role: "roles/viewer",
    members: ["user:jane@example.com"],
});
```
```python
import pulumi
import pulumi_gcp as gcp

binding = gcp.dataproc.MetastoreFederationIamBinding("binding",
    project=default["project"],
    location=default["location"],
    federation_id=default["federationId"],
    role="roles/viewer",
    members=["user:jane@example.com"])
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var binding = new Gcp.Dataproc.MetastoreFederationIamBinding("binding", new()
    {
        Project = @default.Project,
        Location = @default.Location,
        FederationId = @default.FederationId,
        Role = "roles/viewer",
        Members = new[]
        {
            "user:jane@example.com",
        },
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/dataproc"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		_, err := dataproc.NewMetastoreFederationIamBinding(ctx, "binding", &dataproc.MetastoreFederationIamBindingArgs{
			Project:      pulumi.Any(_default.Project),
			Location:     pulumi.Any(_default.Location),
			FederationId: pulumi.Any(_default.FederationId),
			Role:         pulumi.String("roles/viewer"),
			Members: pulumi.StringArray{
				pulumi.String("user:jane@example.com"),
			},
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.dataproc.MetastoreFederationIamBinding;
import com.pulumi.gcp.dataproc.MetastoreFederationIamBindingArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        var binding = new MetastoreFederationIamBinding("binding", MetastoreFederationIamBindingArgs.builder()
            .project(default_.project())
            .location(default_.location())
            .federationId(default_.federationId())
            .role("roles/viewer")
            .members("user:jane@example.com")
            .build());

    }
}
```
```yaml
resources:
  binding:
    type: gcp:dataproc:MetastoreFederationIamBinding
    properties:
      project: ${default.project}
      location: ${default.location}
      federationId: ${default.federationId}
      role: roles/viewer
      members:
        - user:jane@example.com
```
<!--End PulumiCodeChooser -->

## gcp.dataproc.MetastoreFederationIamMember

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const member = new gcp.dataproc.MetastoreFederationIamMember("member", {
    project: _default.project,
    location: _default.location,
    federationId: _default.federationId,
    role: "roles/viewer",
    member: "user:jane@example.com",
});
```
```python
import pulumi
import pulumi_gcp as gcp

member = gcp.dataproc.MetastoreFederationIamMember("member",
    project=default["project"],
    location=default["location"],
    federation_id=default["federationId"],
    role="roles/viewer",
    member="user:jane@example.com")
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var member = new Gcp.Dataproc.MetastoreFederationIamMember("member", new()
    {
        Project = @default.Project,
        Location = @default.Location,
        FederationId = @default.FederationId,
        Role = "roles/viewer",
        Member = "user:jane@example.com",
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/dataproc"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		_, err := dataproc.NewMetastoreFederationIamMember(ctx, "member", &dataproc.MetastoreFederationIamMemberArgs{
			Project:      pulumi.Any(_default.Project),
			Location:     pulumi.Any(_default.Location),
			FederationId: pulumi.Any(_default.FederationId),
			Role:         pulumi.String("roles/viewer"),
			Member:       pulumi.String("user:jane@example.com"),
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.dataproc.MetastoreFederationIamMember;
import com.pulumi.gcp.dataproc.MetastoreFederationIamMemberArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        var member = new MetastoreFederationIamMember("member", MetastoreFederationIamMemberArgs.builder()
            .project(default_.project())
            .location(default_.location())
            .federationId(default_.federationId())
            .role("roles/viewer")
            .member("user:jane@example.com")
            .build());

    }
}
```
```yaml
resources:
  member:
    type: gcp:dataproc:MetastoreFederationIamMember
    properties:
      project: ${default.project}
      location: ${default.location}
      federationId: ${default.federationId}
      role: roles/viewer
      member: user:jane@example.com
```
<!--End PulumiCodeChooser -->


## This resource supports User Project Overrides.

-

# IAM policy for Dataproc metastore Federation
Three different resources help you manage your IAM policy for Dataproc metastore Federation. Each of these resources serves a different use case:

* `gcp.dataproc.MetastoreFederationIamPolicy`: Authoritative. Sets the IAM policy for the federation and replaces any existing policy already attached.
* `gcp.dataproc.MetastoreFederationIamBinding`: Authoritative for a given role. Updates the IAM policy to grant a role to a list of members. Other roles within the IAM policy for the federation are preserved.
* `gcp.dataproc.MetastoreFederationIamMember`: Non-authoritative. Updates the IAM policy to grant a role to a new member. Other members for the role for the federation are preserved.

A data source can be used to retrieve policy data in advent you do not need creation

* `gcp.dataproc.MetastoreFederationIamPolicy`: Retrieves the IAM policy for the federation

> **Note:** `gcp.dataproc.MetastoreFederationIamPolicy` **cannot** be used in conjunction with `gcp.dataproc.MetastoreFederationIamBinding` and `gcp.dataproc.MetastoreFederationIamMember` or they will fight over what your policy should be.

> **Note:** `gcp.dataproc.MetastoreFederationIamBinding` resources **can be** used in conjunction with `gcp.dataproc.MetastoreFederationIamMember` resources **only if** they do not grant privilege to the same role.



## gcp.dataproc.MetastoreFederationIamPolicy

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const admin = gcp.organizations.getIAMPolicy({
    bindings: [{
        role: "roles/viewer",
        members: ["user:jane@example.com"],
    }],
});
const policy = new gcp.dataproc.MetastoreFederationIamPolicy("policy", {
    project: _default.project,
    location: _default.location,
    federationId: _default.federationId,
    policyData: admin.then(admin => admin.policyData),
});
```
```python
import pulumi
import pulumi_gcp as gcp

admin = gcp.organizations.get_iam_policy(bindings=[{
    "role": "roles/viewer",
    "members": ["user:jane@example.com"],
}])
policy = gcp.dataproc.MetastoreFederationIamPolicy("policy",
    project=default["project"],
    location=default["location"],
    federation_id=default["federationId"],
    policy_data=admin.policy_data)
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var admin = Gcp.Organizations.GetIAMPolicy.Invoke(new()
    {
        Bindings = new[]
        {
            new Gcp.Organizations.Inputs.GetIAMPolicyBindingInputArgs
            {
                Role = "roles/viewer",
                Members = new[]
                {
                    "user:jane@example.com",
                },
            },
        },
    });

    var policy = new Gcp.Dataproc.MetastoreFederationIamPolicy("policy", new()
    {
        Project = @default.Project,
        Location = @default.Location,
        FederationId = @default.FederationId,
        PolicyData = admin.Apply(getIAMPolicyResult => getIAMPolicyResult.PolicyData),
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/dataproc"
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/organizations"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		admin, err := organizations.LookupIAMPolicy(ctx, &organizations.LookupIAMPolicyArgs{
			Bindings: []organizations.GetIAMPolicyBinding{
				{
					Role: "roles/viewer",
					Members: []string{
						"user:jane@example.com",
					},
				},
			},
		}, nil)
		if err != nil {
			return err
		}
		_, err = dataproc.NewMetastoreFederationIamPolicy(ctx, "policy", &dataproc.MetastoreFederationIamPolicyArgs{
			Project:      pulumi.Any(_default.Project),
			Location:     pulumi.Any(_default.Location),
			FederationId: pulumi.Any(_default.FederationId),
			PolicyData:   pulumi.String(admin.PolicyData),
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.organizations.OrganizationsFunctions;
import com.pulumi.gcp.organizations.inputs.GetIAMPolicyArgs;
import com.pulumi.gcp.dataproc.MetastoreFederationIamPolicy;
import com.pulumi.gcp.dataproc.MetastoreFederationIamPolicyArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        final var admin = OrganizationsFunctions.getIAMPolicy(GetIAMPolicyArgs.builder()
            .bindings(GetIAMPolicyBindingArgs.builder()
                .role("roles/viewer")
                .members("user:jane@example.com")
                .build())
            .build());

        var policy = new MetastoreFederationIamPolicy("policy", MetastoreFederationIamPolicyArgs.builder()
            .project(default_.project())
            .location(default_.location())
            .federationId(default_.federationId())
            .policyData(admin.applyValue(getIAMPolicyResult -> getIAMPolicyResult.policyData()))
            .build());

    }
}
```
```yaml
resources:
  policy:
    type: gcp:dataproc:MetastoreFederationIamPolicy
    properties:
      project: ${default.project}
      location: ${default.location}
      federationId: ${default.federationId}
      policyData: ${admin.policyData}
variables:
  admin:
    fn::invoke:
      function: gcp:organizations:getIAMPolicy
      arguments:
        bindings:
          - role: roles/viewer
            members:
              - user:jane@example.com
```
<!--End PulumiCodeChooser -->

## gcp.dataproc.MetastoreFederationIamBinding

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const binding = new gcp.dataproc.MetastoreFederationIamBinding("binding", {
    project: _default.project,
    location: _default.location,
    federationId: _default.federationId,
    role: "roles/viewer",
    members: ["user:jane@example.com"],
});
```
```python
import pulumi
import pulumi_gcp as gcp

binding = gcp.dataproc.MetastoreFederationIamBinding("binding",
    project=default["project"],
    location=default["location"],
    federation_id=default["federationId"],
    role="roles/viewer",
    members=["user:jane@example.com"])
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var binding = new Gcp.Dataproc.MetastoreFederationIamBinding("binding", new()
    {
        Project = @default.Project,
        Location = @default.Location,
        FederationId = @default.FederationId,
        Role = "roles/viewer",
        Members = new[]
        {
            "user:jane@example.com",
        },
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/dataproc"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		_, err := dataproc.NewMetastoreFederationIamBinding(ctx, "binding", &dataproc.MetastoreFederationIamBindingArgs{
			Project:      pulumi.Any(_default.Project),
			Location:     pulumi.Any(_default.Location),
			FederationId: pulumi.Any(_default.FederationId),
			Role:         pulumi.String("roles/viewer"),
			Members: pulumi.StringArray{
				pulumi.String("user:jane@example.com"),
			},
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.dataproc.MetastoreFederationIamBinding;
import com.pulumi.gcp.dataproc.MetastoreFederationIamBindingArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        var binding = new MetastoreFederationIamBinding("binding", MetastoreFederationIamBindingArgs.builder()
            .project(default_.project())
            .location(default_.location())
            .federationId(default_.federationId())
            .role("roles/viewer")
            .members("user:jane@example.com")
            .build());

    }
}
```
```yaml
resources:
  binding:
    type: gcp:dataproc:MetastoreFederationIamBinding
    properties:
      project: ${default.project}
      location: ${default.location}
      federationId: ${default.federationId}
      role: roles/viewer
      members:
        - user:jane@example.com
```
<!--End PulumiCodeChooser -->

## gcp.dataproc.MetastoreFederationIamMember

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const member = new gcp.dataproc.MetastoreFederationIamMember("member", {
    project: _default.project,
    location: _default.location,
    federationId: _default.federationId,
    role: "roles/viewer",
    member: "user:jane@example.com",
});
```
```python
import pulumi
import pulumi_gcp as gcp

member = gcp.dataproc.MetastoreFederationIamMember("member",
    project=default["project"],
    location=default["location"],
    federation_id=default["federationId"],
    role="roles/viewer",
    member="user:jane@example.com")
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var member = new Gcp.Dataproc.MetastoreFederationIamMember("member", new()
    {
        Project = @default.Project,
        Location = @default.Location,
        FederationId = @default.FederationId,
        Role = "roles/viewer",
        Member = "user:jane@example.com",
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/dataproc"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		_, err := dataproc.NewMetastoreFederationIamMember(ctx, "member", &dataproc.MetastoreFederationIamMemberArgs{
			Project:      pulumi.Any(_default.Project),
			Location:     pulumi.Any(_default.Location),
			FederationId: pulumi.Any(_default.FederationId),
			Role:         pulumi.String("roles/viewer"),
			Member:       pulumi.String("user:jane@example.com"),
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.dataproc.MetastoreFederationIamMember;
import com.pulumi.gcp.dataproc.MetastoreFederationIamMemberArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        var member = new MetastoreFederationIamMember("member", MetastoreFederationIamMemberArgs.builder()
            .project(default_.project())
            .location(default_.location())
            .federationId(default_.federationId())
            .role("roles/viewer")
            .member("user:jane@example.com")
            .build());

    }
}
```
```yaml
resources:
  member:
    type: gcp:dataproc:MetastoreFederationIamMember
    properties:
      project: ${default.project}
      location: ${default.location}
      federationId: ${default.federationId}
      role: roles/viewer
      member: user:jane@example.com
```
<!--End PulumiCodeChooser -->

## Import

For all import syntaxes, the "resource in question" can take any of the following forms:

* projects/{{project}}/locations/{{location}}/federations/{{federation_id}}

* {{project}}/{{location}}/{{federation_id}}

* {{location}}/{{federation_id}}

* {{federation_id}}

Any variables not passed in the import command will be taken from the provider configuration.

Dataproc metastore federation IAM resources can be imported using the resource identifiers, role, and member.

IAM member imports use space-delimited identifiers: the resource in question, the role, and the member identity, e.g.

```sh
$ pulumi import gcp:dataproc/metastoreFederationIamBinding:MetastoreFederationIamBinding editor "projects/{{project}}/locations/{{location}}/federations/{{federation_id}} roles/viewer user:jane@example.com"
```

IAM binding imports use space-delimited identifiers: the resource in question and the role, e.g.

```sh
$ pulumi import gcp:dataproc/metastoreFederationIamBinding:MetastoreFederationIamBinding editor "projects/{{project}}/locations/{{location}}/federations/{{federation_id}} roles/viewer"
```

IAM policy imports use the identifier of the resource in question, e.g.

```sh
$ pulumi import gcp:dataproc/metastoreFederationIamBinding:MetastoreFederationIamBinding editor projects/{{project}}/locations/{{location}}/federations/{{federation_id}}
```

-> **Custom Roles** If you're importing a IAM resource with a custom role, make sure to use the

 full name of the custom role, e.g. `[projects/my-project|organizations/my-org]/roles/my-custom-role`.

¥
	conditionB:

dataproc&MetastoreFederationIamBindingConditionZgcp:dataproc/MetastoreFederationIamBindingCondition:MetastoreFederationIamBindingCondition
federationId" à
locationB" ÍThe location where the metastore federation should reside.
Used to find the parent resource to bind the IAM policy to. If not specified,
the value will be parsed from the identifier of the parent resource. If no location is provided in the parent identifier and no
location is specified, it is taken from the provider configuration.
Ö	
members*" Ä	Identities that will be granted the privilege in `role`.
Each entry can have one of the following values:
* **allUsers**: A special identifier that represents anyone who is on the internet; with or without a Google account.
* **allAuthenticatedUsers**: A special identifier that represents anyone who is authenticated with a Google account or a service account.
* **user:{emailid}**: An email address that represents a specific Google account. For example, alice@gmail.com or joe@example.com.
* **serviceAccount:{emailid}**: An email address that represents a service account. For example, my-other-app@appspot.gserviceaccount.com.
* **group:{emailid}**: An email address that represents a Google group. For example, admins@example.com.
* **domain:{domain}**: A G Suite domain (primary, instead of alias) name that represents all the users of that domain. For example, google.com or example.com.
* **projectOwner:projectid**: Owners of the given project. For example, "projectOwner:my-example-project"
* **projectEditor:projectid**: Editors of the given project. For example, "projectEditor:my-example-project"
* **projectViewer:projectid**: Viewers of the given project. For example, "projectViewer:my-example-project"

projectB" The ID of the project in which the resource belongs.
If it is not provided, the project will be parsed from the identifier of the parent resource. If no project is provided in the parent identifier and no project is specified, the provider project is used.
ã
role" ÖThe role that should be applied. Only one
`gcp.dataproc.MetastoreFederationIamBinding` can be used per role. Note that custom roles must be of the format
`[projects|organizations]/{parent-name}/roles/{role-name}`.
"¥
	conditionB:

dataproc&MetastoreFederationIamBindingConditionZgcp:dataproc/MetastoreFederationIamBindingCondition:MetastoreFederationIamBindingCondition"3
etag" '(Computed) The etag of the IAM policy.
"
federationId" "Þ
location" ÍThe location where the metastore federation should reside.
Used to find the parent resource to bind the IAM policy to. If not specified,
the value will be parsed from the identifier of the parent resource. If no location is provided in the parent identifier and no
location is specified, it is taken from the provider configuration.
"Ö	
members*" Ä	Identities that will be granted the privilege in `role`.
Each entry can have one of the following values:
* **allUsers**: A special identifier that represents anyone who is on the internet; with or without a Google account.
* **allAuthenticatedUsers**: A special identifier that represents anyone who is authenticated with a Google account or a service account.
* **user:{emailid}**: An email address that represents a specific Google account. For example, alice@gmail.com or joe@example.com.
* **serviceAccount:{emailid}**: An email address that represents a service account. For example, my-other-app@appspot.gserviceaccount.com.
* **group:{emailid}**: An email address that represents a Google group. For example, admins@example.com.
* **domain:{domain}**: A G Suite domain (primary, instead of alias) name that represents all the users of that domain. For example, google.com or example.com.
* **projectOwner:projectid**: Owners of the given project. For example, "projectOwner:my-example-project"
* **projectEditor:projectid**: Editors of the given project. For example, "projectEditor:my-example-project"
* **projectViewer:projectid**: Viewers of the given project. For example, "projectViewer:my-example-project"
"
project" The ID of the project in which the resource belongs.
If it is not provided, the project will be parsed from the identifier of the parent resource. If no project is provided in the parent identifier and no project is specified, the provider project is used.
"ã
role" ÖThe role that should be applied. Only one
`gcp.dataproc.MetastoreFederationIamBinding` can be used per role. Note that custom roles must be of the format
`[projects|organizations]/{parent-name}/roles/{role-name}`.
*Úë
p
dataprocMetastoreFederationIamMemberFgcp:dataproc/metastoreFederationIamMember:MetastoreFederationIamMember×ÆThree different resources help you manage your IAM policy for Dataproc metastore Federation. Each of these resources serves a different use case:

* `gcp.dataproc.MetastoreFederationIamPolicy`: Authoritative. Sets the IAM policy for the federation and replaces any existing policy already attached.
* `gcp.dataproc.MetastoreFederationIamBinding`: Authoritative for a given role. Updates the IAM policy to grant a role to a list of members. Other roles within the IAM policy for the federation are preserved.
* `gcp.dataproc.MetastoreFederationIamMember`: Non-authoritative. Updates the IAM policy to grant a role to a new member. Other members for the role for the federation are preserved.

A data source can be used to retrieve policy data in advent you do not need creation

* `gcp.dataproc.MetastoreFederationIamPolicy`: Retrieves the IAM policy for the federation

> **Note:** `gcp.dataproc.MetastoreFederationIamPolicy` **cannot** be used in conjunction with `gcp.dataproc.MetastoreFederationIamBinding` and `gcp.dataproc.MetastoreFederationIamMember` or they will fight over what your policy should be.

> **Note:** `gcp.dataproc.MetastoreFederationIamBinding` resources **can be** used in conjunction with `gcp.dataproc.MetastoreFederationIamMember` resources **only if** they do not grant privilege to the same role.



## gcp.dataproc.MetastoreFederationIamPolicy

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const admin = gcp.organizations.getIAMPolicy({
    bindings: [{
        role: "roles/viewer",
        members: ["user:jane@example.com"],
    }],
});
const policy = new gcp.dataproc.MetastoreFederationIamPolicy("policy", {
    project: _default.project,
    location: _default.location,
    federationId: _default.federationId,
    policyData: admin.then(admin => admin.policyData),
});
```
```python
import pulumi
import pulumi_gcp as gcp

admin = gcp.organizations.get_iam_policy(bindings=[{
    "role": "roles/viewer",
    "members": ["user:jane@example.com"],
}])
policy = gcp.dataproc.MetastoreFederationIamPolicy("policy",
    project=default["project"],
    location=default["location"],
    federation_id=default["federationId"],
    policy_data=admin.policy_data)
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var admin = Gcp.Organizations.GetIAMPolicy.Invoke(new()
    {
        Bindings = new[]
        {
            new Gcp.Organizations.Inputs.GetIAMPolicyBindingInputArgs
            {
                Role = "roles/viewer",
                Members = new[]
                {
                    "user:jane@example.com",
                },
            },
        },
    });

    var policy = new Gcp.Dataproc.MetastoreFederationIamPolicy("policy", new()
    {
        Project = @default.Project,
        Location = @default.Location,
        FederationId = @default.FederationId,
        PolicyData = admin.Apply(getIAMPolicyResult => getIAMPolicyResult.PolicyData),
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/dataproc"
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/organizations"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		admin, err := organizations.LookupIAMPolicy(ctx, &organizations.LookupIAMPolicyArgs{
			Bindings: []organizations.GetIAMPolicyBinding{
				{
					Role: "roles/viewer",
					Members: []string{
						"user:jane@example.com",
					},
				},
			},
		}, nil)
		if err != nil {
			return err
		}
		_, err = dataproc.NewMetastoreFederationIamPolicy(ctx, "policy", &dataproc.MetastoreFederationIamPolicyArgs{
			Project:      pulumi.Any(_default.Project),
			Location:     pulumi.Any(_default.Location),
			FederationId: pulumi.Any(_default.FederationId),
			PolicyData:   pulumi.String(admin.PolicyData),
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.organizations.OrganizationsFunctions;
import com.pulumi.gcp.organizations.inputs.GetIAMPolicyArgs;
import com.pulumi.gcp.dataproc.MetastoreFederationIamPolicy;
import com.pulumi.gcp.dataproc.MetastoreFederationIamPolicyArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        final var admin = OrganizationsFunctions.getIAMPolicy(GetIAMPolicyArgs.builder()
            .bindings(GetIAMPolicyBindingArgs.builder()
                .role("roles/viewer")
                .members("user:jane@example.com")
                .build())
            .build());

        var policy = new MetastoreFederationIamPolicy("policy", MetastoreFederationIamPolicyArgs.builder()
            .project(default_.project())
            .location(default_.location())
            .federationId(default_.federationId())
            .policyData(admin.applyValue(getIAMPolicyResult -> getIAMPolicyResult.policyData()))
            .build());

    }
}
```
```yaml
resources:
  policy:
    type: gcp:dataproc:MetastoreFederationIamPolicy
    properties:
      project: ${default.project}
      location: ${default.location}
      federationId: ${default.federationId}
      policyData: ${admin.policyData}
variables:
  admin:
    fn::invoke:
      function: gcp:organizations:getIAMPolicy
      arguments:
        bindings:
          - role: roles/viewer
            members:
              - user:jane@example.com
```
<!--End PulumiCodeChooser -->

## gcp.dataproc.MetastoreFederationIamBinding

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const binding = new gcp.dataproc.MetastoreFederationIamBinding("binding", {
    project: _default.project,
    location: _default.location,
    federationId: _default.federationId,
    role: "roles/viewer",
    members: ["user:jane@example.com"],
});
```
```python
import pulumi
import pulumi_gcp as gcp

binding = gcp.dataproc.MetastoreFederationIamBinding("binding",
    project=default["project"],
    location=default["location"],
    federation_id=default["federationId"],
    role="roles/viewer",
    members=["user:jane@example.com"])
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var binding = new Gcp.Dataproc.MetastoreFederationIamBinding("binding", new()
    {
        Project = @default.Project,
        Location = @default.Location,
        FederationId = @default.FederationId,
        Role = "roles/viewer",
        Members = new[]
        {
            "user:jane@example.com",
        },
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/dataproc"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		_, err := dataproc.NewMetastoreFederationIamBinding(ctx, "binding", &dataproc.MetastoreFederationIamBindingArgs{
			Project:      pulumi.Any(_default.Project),
			Location:     pulumi.Any(_default.Location),
			FederationId: pulumi.Any(_default.FederationId),
			Role:         pulumi.String("roles/viewer"),
			Members: pulumi.StringArray{
				pulumi.String("user:jane@example.com"),
			},
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.dataproc.MetastoreFederationIamBinding;
import com.pulumi.gcp.dataproc.MetastoreFederationIamBindingArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        var binding = new MetastoreFederationIamBinding("binding", MetastoreFederationIamBindingArgs.builder()
            .project(default_.project())
            .location(default_.location())
            .federationId(default_.federationId())
            .role("roles/viewer")
            .members("user:jane@example.com")
            .build());

    }
}
```
```yaml
resources:
  binding:
    type: gcp:dataproc:MetastoreFederationIamBinding
    properties:
      project: ${default.project}
      location: ${default.location}
      federationId: ${default.federationId}
      role: roles/viewer
      members:
        - user:jane@example.com
```
<!--End PulumiCodeChooser -->

## gcp.dataproc.MetastoreFederationIamMember

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const member = new gcp.dataproc.MetastoreFederationIamMember("member", {
    project: _default.project,
    location: _default.location,
    federationId: _default.federationId,
    role: "roles/viewer",
    member: "user:jane@example.com",
});
```
```python
import pulumi
import pulumi_gcp as gcp

member = gcp.dataproc.MetastoreFederationIamMember("member",
    project=default["project"],
    location=default["location"],
    federation_id=default["federationId"],
    role="roles/viewer",
    member="user:jane@example.com")
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var member = new Gcp.Dataproc.MetastoreFederationIamMember("member", new()
    {
        Project = @default.Project,
        Location = @default.Location,
        FederationId = @default.FederationId,
        Role = "roles/viewer",
        Member = "user:jane@example.com",
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/dataproc"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		_, err := dataproc.NewMetastoreFederationIamMember(ctx, "member", &dataproc.MetastoreFederationIamMemberArgs{
			Project:      pulumi.Any(_default.Project),
			Location:     pulumi.Any(_default.Location),
			FederationId: pulumi.Any(_default.FederationId),
			Role:         pulumi.String("roles/viewer"),
			Member:       pulumi.String("user:jane@example.com"),
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.dataproc.MetastoreFederationIamMember;
import com.pulumi.gcp.dataproc.MetastoreFederationIamMemberArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        var member = new MetastoreFederationIamMember("member", MetastoreFederationIamMemberArgs.builder()
            .project(default_.project())
            .location(default_.location())
            .federationId(default_.federationId())
            .role("roles/viewer")
            .member("user:jane@example.com")
            .build());

    }
}
```
```yaml
resources:
  member:
    type: gcp:dataproc:MetastoreFederationIamMember
    properties:
      project: ${default.project}
      location: ${default.location}
      federationId: ${default.federationId}
      role: roles/viewer
      member: user:jane@example.com
```
<!--End PulumiCodeChooser -->


## This resource supports User Project Overrides.

-

# IAM policy for Dataproc metastore Federation
Three different resources help you manage your IAM policy for Dataproc metastore Federation. Each of these resources serves a different use case:

* `gcp.dataproc.MetastoreFederationIamPolicy`: Authoritative. Sets the IAM policy for the federation and replaces any existing policy already attached.
* `gcp.dataproc.MetastoreFederationIamBinding`: Authoritative for a given role. Updates the IAM policy to grant a role to a list of members. Other roles within the IAM policy for the federation are preserved.
* `gcp.dataproc.MetastoreFederationIamMember`: Non-authoritative. Updates the IAM policy to grant a role to a new member. Other members for the role for the federation are preserved.

A data source can be used to retrieve policy data in advent you do not need creation

* `gcp.dataproc.MetastoreFederationIamPolicy`: Retrieves the IAM policy for the federation

> **Note:** `gcp.dataproc.MetastoreFederationIamPolicy` **cannot** be used in conjunction with `gcp.dataproc.MetastoreFederationIamBinding` and `gcp.dataproc.MetastoreFederationIamMember` or they will fight over what your policy should be.

> **Note:** `gcp.dataproc.MetastoreFederationIamBinding` resources **can be** used in conjunction with `gcp.dataproc.MetastoreFederationIamMember` resources **only if** they do not grant privilege to the same role.



## gcp.dataproc.MetastoreFederationIamPolicy

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const admin = gcp.organizations.getIAMPolicy({
    bindings: [{
        role: "roles/viewer",
        members: ["user:jane@example.com"],
    }],
});
const policy = new gcp.dataproc.MetastoreFederationIamPolicy("policy", {
    project: _default.project,
    location: _default.location,
    federationId: _default.federationId,
    policyData: admin.then(admin => admin.policyData),
});
```
```python
import pulumi
import pulumi_gcp as gcp

admin = gcp.organizations.get_iam_policy(bindings=[{
    "role": "roles/viewer",
    "members": ["user:jane@example.com"],
}])
policy = gcp.dataproc.MetastoreFederationIamPolicy("policy",
    project=default["project"],
    location=default["location"],
    federation_id=default["federationId"],
    policy_data=admin.policy_data)
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var admin = Gcp.Organizations.GetIAMPolicy.Invoke(new()
    {
        Bindings = new[]
        {
            new Gcp.Organizations.Inputs.GetIAMPolicyBindingInputArgs
            {
                Role = "roles/viewer",
                Members = new[]
                {
                    "user:jane@example.com",
                },
            },
        },
    });

    var policy = new Gcp.Dataproc.MetastoreFederationIamPolicy("policy", new()
    {
        Project = @default.Project,
        Location = @default.Location,
        FederationId = @default.FederationId,
        PolicyData = admin.Apply(getIAMPolicyResult => getIAMPolicyResult.PolicyData),
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/dataproc"
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/organizations"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		admin, err := organizations.LookupIAMPolicy(ctx, &organizations.LookupIAMPolicyArgs{
			Bindings: []organizations.GetIAMPolicyBinding{
				{
					Role: "roles/viewer",
					Members: []string{
						"user:jane@example.com",
					},
				},
			},
		}, nil)
		if err != nil {
			return err
		}
		_, err = dataproc.NewMetastoreFederationIamPolicy(ctx, "policy", &dataproc.MetastoreFederationIamPolicyArgs{
			Project:      pulumi.Any(_default.Project),
			Location:     pulumi.Any(_default.Location),
			FederationId: pulumi.Any(_default.FederationId),
			PolicyData:   pulumi.String(admin.PolicyData),
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.organizations.OrganizationsFunctions;
import com.pulumi.gcp.organizations.inputs.GetIAMPolicyArgs;
import com.pulumi.gcp.dataproc.MetastoreFederationIamPolicy;
import com.pulumi.gcp.dataproc.MetastoreFederationIamPolicyArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        final var admin = OrganizationsFunctions.getIAMPolicy(GetIAMPolicyArgs.builder()
            .bindings(GetIAMPolicyBindingArgs.builder()
                .role("roles/viewer")
                .members("user:jane@example.com")
                .build())
            .build());

        var policy = new MetastoreFederationIamPolicy("policy", MetastoreFederationIamPolicyArgs.builder()
            .project(default_.project())
            .location(default_.location())
            .federationId(default_.federationId())
            .policyData(admin.applyValue(getIAMPolicyResult -> getIAMPolicyResult.policyData()))
            .build());

    }
}
```
```yaml
resources:
  policy:
    type: gcp:dataproc:MetastoreFederationIamPolicy
    properties:
      project: ${default.project}
      location: ${default.location}
      federationId: ${default.federationId}
      policyData: ${admin.policyData}
variables:
  admin:
    fn::invoke:
      function: gcp:organizations:getIAMPolicy
      arguments:
        bindings:
          - role: roles/viewer
            members:
              - user:jane@example.com
```
<!--End PulumiCodeChooser -->

## gcp.dataproc.MetastoreFederationIamBinding

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const binding = new gcp.dataproc.MetastoreFederationIamBinding("binding", {
    project: _default.project,
    location: _default.location,
    federationId: _default.federationId,
    role: "roles/viewer",
    members: ["user:jane@example.com"],
});
```
```python
import pulumi
import pulumi_gcp as gcp

binding = gcp.dataproc.MetastoreFederationIamBinding("binding",
    project=default["project"],
    location=default["location"],
    federation_id=default["federationId"],
    role="roles/viewer",
    members=["user:jane@example.com"])
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var binding = new Gcp.Dataproc.MetastoreFederationIamBinding("binding", new()
    {
        Project = @default.Project,
        Location = @default.Location,
        FederationId = @default.FederationId,
        Role = "roles/viewer",
        Members = new[]
        {
            "user:jane@example.com",
        },
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/dataproc"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		_, err := dataproc.NewMetastoreFederationIamBinding(ctx, "binding", &dataproc.MetastoreFederationIamBindingArgs{
			Project:      pulumi.Any(_default.Project),
			Location:     pulumi.Any(_default.Location),
			FederationId: pulumi.Any(_default.FederationId),
			Role:         pulumi.String("roles/viewer"),
			Members: pulumi.StringArray{
				pulumi.String("user:jane@example.com"),
			},
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.dataproc.MetastoreFederationIamBinding;
import com.pulumi.gcp.dataproc.MetastoreFederationIamBindingArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        var binding = new MetastoreFederationIamBinding("binding", MetastoreFederationIamBindingArgs.builder()
            .project(default_.project())
            .location(default_.location())
            .federationId(default_.federationId())
            .role("roles/viewer")
            .members("user:jane@example.com")
            .build());

    }
}
```
```yaml
resources:
  binding:
    type: gcp:dataproc:MetastoreFederationIamBinding
    properties:
      project: ${default.project}
      location: ${default.location}
      federationId: ${default.federationId}
      role: roles/viewer
      members:
        - user:jane@example.com
```
<!--End PulumiCodeChooser -->

## gcp.dataproc.MetastoreFederationIamMember

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const member = new gcp.dataproc.MetastoreFederationIamMember("member", {
    project: _default.project,
    location: _default.location,
    federationId: _default.federationId,
    role: "roles/viewer",
    member: "user:jane@example.com",
});
```
```python
import pulumi
import pulumi_gcp as gcp

member = gcp.dataproc.MetastoreFederationIamMember("member",
    project=default["project"],
    location=default["location"],
    federation_id=default["federationId"],
    role="roles/viewer",
    member="user:jane@example.com")
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var member = new Gcp.Dataproc.MetastoreFederationIamMember("member", new()
    {
        Project = @default.Project,
        Location = @default.Location,
        FederationId = @default.FederationId,
        Role = "roles/viewer",
        Member = "user:jane@example.com",
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/dataproc"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		_, err := dataproc.NewMetastoreFederationIamMember(ctx, "member", &dataproc.MetastoreFederationIamMemberArgs{
			Project:      pulumi.Any(_default.Project),
			Location:     pulumi.Any(_default.Location),
			FederationId: pulumi.Any(_default.FederationId),
			Role:         pulumi.String("roles/viewer"),
			Member:       pulumi.String("user:jane@example.com"),
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.dataproc.MetastoreFederationIamMember;
import com.pulumi.gcp.dataproc.MetastoreFederationIamMemberArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        var member = new MetastoreFederationIamMember("member", MetastoreFederationIamMemberArgs.builder()
            .project(default_.project())
            .location(default_.location())
            .federationId(default_.federationId())
            .role("roles/viewer")
            .member("user:jane@example.com")
            .build());

    }
}
```
```yaml
resources:
  member:
    type: gcp:dataproc:MetastoreFederationIamMember
    properties:
      project: ${default.project}
      location: ${default.location}
      federationId: ${default.federationId}
      role: roles/viewer
      member: user:jane@example.com
```
<!--End PulumiCodeChooser -->

## Import

For all import syntaxes, the "resource in question" can take any of the following forms:

* projects/{{project}}/locations/{{location}}/federations/{{federation_id}}

* {{project}}/{{location}}/{{federation_id}}

* {{location}}/{{federation_id}}

* {{federation_id}}

Any variables not passed in the import command will be taken from the provider configuration.

Dataproc metastore federation IAM resources can be imported using the resource identifiers, role, and member.

IAM member imports use space-delimited identifiers: the resource in question, the role, and the member identity, e.g.

```sh
$ pulumi import gcp:dataproc/metastoreFederationIamMember:MetastoreFederationIamMember editor "projects/{{project}}/locations/{{location}}/federations/{{federation_id}} roles/viewer user:jane@example.com"
```

IAM binding imports use space-delimited identifiers: the resource in question and the role, e.g.

```sh
$ pulumi import gcp:dataproc/metastoreFederationIamMember:MetastoreFederationIamMember editor "projects/{{project}}/locations/{{location}}/federations/{{federation_id}} roles/viewer"
```

IAM policy imports use the identifier of the resource in question, e.g.

```sh
$ pulumi import gcp:dataproc/metastoreFederationIamMember:MetastoreFederationIamMember editor projects/{{project}}/locations/{{location}}/federations/{{federation_id}}
```

-> **Custom Roles** If you're importing a IAM resource with a custom role, make sure to use the

 full name of the custom role, e.g. `[projects/my-project|organizations/my-org]/roles/my-custom-role`.

¢
	conditionB:

dataproc%MetastoreFederationIamMemberConditionXgcp:dataproc/MetastoreFederationIamMemberCondition:MetastoreFederationIamMemberCondition
federationId" à
locationB" ÍThe location where the metastore federation should reside.
Used to find the parent resource to bind the IAM policy to. If not specified,
the value will be parsed from the identifier of the parent resource. If no location is provided in the parent identifier and no
location is specified, it is taken from the provider configuration.
Ó	
member" Ä	Identities that will be granted the privilege in `role`.
Each entry can have one of the following values:
* **allUsers**: A special identifier that represents anyone who is on the internet; with or without a Google account.
* **allAuthenticatedUsers**: A special identifier that represents anyone who is authenticated with a Google account or a service account.
* **user:{emailid}**: An email address that represents a specific Google account. For example, alice@gmail.com or joe@example.com.
* **serviceAccount:{emailid}**: An email address that represents a service account. For example, my-other-app@appspot.gserviceaccount.com.
* **group:{emailid}**: An email address that represents a Google group. For example, admins@example.com.
* **domain:{domain}**: A G Suite domain (primary, instead of alias) name that represents all the users of that domain. For example, google.com or example.com.
* **projectOwner:projectid**: Owners of the given project. For example, "projectOwner:my-example-project"
* **projectEditor:projectid**: Editors of the given project. For example, "projectEditor:my-example-project"
* **projectViewer:projectid**: Viewers of the given project. For example, "projectViewer:my-example-project"

projectB" The ID of the project in which the resource belongs.
If it is not provided, the project will be parsed from the identifier of the parent resource. If no project is provided in the parent identifier and no project is specified, the provider project is used.
ã
role" ÖThe role that should be applied. Only one
`gcp.dataproc.MetastoreFederationIamBinding` can be used per role. Note that custom roles must be of the format
`[projects|organizations]/{parent-name}/roles/{role-name}`.
"¢
	conditionB:

dataproc%MetastoreFederationIamMemberConditionXgcp:dataproc/MetastoreFederationIamMemberCondition:MetastoreFederationIamMemberCondition"3
etag" '(Computed) The etag of the IAM policy.
"
federationId" "Þ
location" ÍThe location where the metastore federation should reside.
Used to find the parent resource to bind the IAM policy to. If not specified,
the value will be parsed from the identifier of the parent resource. If no location is provided in the parent identifier and no
location is specified, it is taken from the provider configuration.
"Ó	
member" Ä	Identities that will be granted the privilege in `role`.
Each entry can have one of the following values:
* **allUsers**: A special identifier that represents anyone who is on the internet; with or without a Google account.
* **allAuthenticatedUsers**: A special identifier that represents anyone who is authenticated with a Google account or a service account.
* **user:{emailid}**: An email address that represents a specific Google account. For example, alice@gmail.com or joe@example.com.
* **serviceAccount:{emailid}**: An email address that represents a service account. For example, my-other-app@appspot.gserviceaccount.com.
* **group:{emailid}**: An email address that represents a Google group. For example, admins@example.com.
* **domain:{domain}**: A G Suite domain (primary, instead of alias) name that represents all the users of that domain. For example, google.com or example.com.
* **projectOwner:projectid**: Owners of the given project. For example, "projectOwner:my-example-project"
* **projectEditor:projectid**: Editors of the given project. For example, "projectEditor:my-example-project"
* **projectViewer:projectid**: Viewers of the given project. For example, "projectViewer:my-example-project"
"
project" The ID of the project in which the resource belongs.
If it is not provided, the project will be parsed from the identifier of the parent resource. If no project is provided in the parent identifier and no project is specified, the provider project is used.
"ã
role" ÖThe role that should be applied. Only one
`gcp.dataproc.MetastoreFederationIamBinding` can be used per role. Note that custom roles must be of the format
`[projects|organizations]/{parent-name}/roles/{role-name}`.
*ÚÓ
p
dataprocMetastoreFederationIamPolicyFgcp:dataproc/metastoreFederationIamPolicy:MetastoreFederationIamPolicy×ÆThree different resources help you manage your IAM policy for Dataproc metastore Federation. Each of these resources serves a different use case:

* `gcp.dataproc.MetastoreFederationIamPolicy`: Authoritative. Sets the IAM policy for the federation and replaces any existing policy already attached.
* `gcp.dataproc.MetastoreFederationIamBinding`: Authoritative for a given role. Updates the IAM policy to grant a role to a list of members. Other roles within the IAM policy for the federation are preserved.
* `gcp.dataproc.MetastoreFederationIamMember`: Non-authoritative. Updates the IAM policy to grant a role to a new member. Other members for the role for the federation are preserved.

A data source can be used to retrieve policy data in advent you do not need creation

* `gcp.dataproc.MetastoreFederationIamPolicy`: Retrieves the IAM policy for the federation

> **Note:** `gcp.dataproc.MetastoreFederationIamPolicy` **cannot** be used in conjunction with `gcp.dataproc.MetastoreFederationIamBinding` and `gcp.dataproc.MetastoreFederationIamMember` or they will fight over what your policy should be.

> **Note:** `gcp.dataproc.MetastoreFederationIamBinding` resources **can be** used in conjunction with `gcp.dataproc.MetastoreFederationIamMember` resources **only if** they do not grant privilege to the same role.



## gcp.dataproc.MetastoreFederationIamPolicy

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const admin = gcp.organizations.getIAMPolicy({
    bindings: [{
        role: "roles/viewer",
        members: ["user:jane@example.com"],
    }],
});
const policy = new gcp.dataproc.MetastoreFederationIamPolicy("policy", {
    project: _default.project,
    location: _default.location,
    federationId: _default.federationId,
    policyData: admin.then(admin => admin.policyData),
});
```
```python
import pulumi
import pulumi_gcp as gcp

admin = gcp.organizations.get_iam_policy(bindings=[{
    "role": "roles/viewer",
    "members": ["user:jane@example.com"],
}])
policy = gcp.dataproc.MetastoreFederationIamPolicy("policy",
    project=default["project"],
    location=default["location"],
    federation_id=default["federationId"],
    policy_data=admin.policy_data)
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var admin = Gcp.Organizations.GetIAMPolicy.Invoke(new()
    {
        Bindings = new[]
        {
            new Gcp.Organizations.Inputs.GetIAMPolicyBindingInputArgs
            {
                Role = "roles/viewer",
                Members = new[]
                {
                    "user:jane@example.com",
                },
            },
        },
    });

    var policy = new Gcp.Dataproc.MetastoreFederationIamPolicy("policy", new()
    {
        Project = @default.Project,
        Location = @default.Location,
        FederationId = @default.FederationId,
        PolicyData = admin.Apply(getIAMPolicyResult => getIAMPolicyResult.PolicyData),
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/dataproc"
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/organizations"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		admin, err := organizations.LookupIAMPolicy(ctx, &organizations.LookupIAMPolicyArgs{
			Bindings: []organizations.GetIAMPolicyBinding{
				{
					Role: "roles/viewer",
					Members: []string{
						"user:jane@example.com",
					},
				},
			},
		}, nil)
		if err != nil {
			return err
		}
		_, err = dataproc.NewMetastoreFederationIamPolicy(ctx, "policy", &dataproc.MetastoreFederationIamPolicyArgs{
			Project:      pulumi.Any(_default.Project),
			Location:     pulumi.Any(_default.Location),
			FederationId: pulumi.Any(_default.FederationId),
			PolicyData:   pulumi.String(admin.PolicyData),
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.organizations.OrganizationsFunctions;
import com.pulumi.gcp.organizations.inputs.GetIAMPolicyArgs;
import com.pulumi.gcp.dataproc.MetastoreFederationIamPolicy;
import com.pulumi.gcp.dataproc.MetastoreFederationIamPolicyArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        final var admin = OrganizationsFunctions.getIAMPolicy(GetIAMPolicyArgs.builder()
            .bindings(GetIAMPolicyBindingArgs.builder()
                .role("roles/viewer")
                .members("user:jane@example.com")
                .build())
            .build());

        var policy = new MetastoreFederationIamPolicy("policy", MetastoreFederationIamPolicyArgs.builder()
            .project(default_.project())
            .location(default_.location())
            .federationId(default_.federationId())
            .policyData(admin.applyValue(getIAMPolicyResult -> getIAMPolicyResult.policyData()))
            .build());

    }
}
```
```yaml
resources:
  policy:
    type: gcp:dataproc:MetastoreFederationIamPolicy
    properties:
      project: ${default.project}
      location: ${default.location}
      federationId: ${default.federationId}
      policyData: ${admin.policyData}
variables:
  admin:
    fn::invoke:
      function: gcp:organizations:getIAMPolicy
      arguments:
        bindings:
          - role: roles/viewer
            members:
              - user:jane@example.com
```
<!--End PulumiCodeChooser -->

## gcp.dataproc.MetastoreFederationIamBinding

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const binding = new gcp.dataproc.MetastoreFederationIamBinding("binding", {
    project: _default.project,
    location: _default.location,
    federationId: _default.federationId,
    role: "roles/viewer",
    members: ["user:jane@example.com"],
});
```
```python
import pulumi
import pulumi_gcp as gcp

binding = gcp.dataproc.MetastoreFederationIamBinding("binding",
    project=default["project"],
    location=default["location"],
    federation_id=default["federationId"],
    role="roles/viewer",
    members=["user:jane@example.com"])
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var binding = new Gcp.Dataproc.MetastoreFederationIamBinding("binding", new()
    {
        Project = @default.Project,
        Location = @default.Location,
        FederationId = @default.FederationId,
        Role = "roles/viewer",
        Members = new[]
        {
            "user:jane@example.com",
        },
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/dataproc"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		_, err := dataproc.NewMetastoreFederationIamBinding(ctx, "binding", &dataproc.MetastoreFederationIamBindingArgs{
			Project:      pulumi.Any(_default.Project),
			Location:     pulumi.Any(_default.Location),
			FederationId: pulumi.Any(_default.FederationId),
			Role:         pulumi.String("roles/viewer"),
			Members: pulumi.StringArray{
				pulumi.String("user:jane@example.com"),
			},
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.dataproc.MetastoreFederationIamBinding;
import com.pulumi.gcp.dataproc.MetastoreFederationIamBindingArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        var binding = new MetastoreFederationIamBinding("binding", MetastoreFederationIamBindingArgs.builder()
            .project(default_.project())
            .location(default_.location())
            .federationId(default_.federationId())
            .role("roles/viewer")
            .members("user:jane@example.com")
            .build());

    }
}
```
```yaml
resources:
  binding:
    type: gcp:dataproc:MetastoreFederationIamBinding
    properties:
      project: ${default.project}
      location: ${default.location}
      federationId: ${default.federationId}
      role: roles/viewer
      members:
        - user:jane@example.com
```
<!--End PulumiCodeChooser -->

## gcp.dataproc.MetastoreFederationIamMember

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const member = new gcp.dataproc.MetastoreFederationIamMember("member", {
    project: _default.project,
    location: _default.location,
    federationId: _default.federationId,
    role: "roles/viewer",
    member: "user:jane@example.com",
});
```
```python
import pulumi
import pulumi_gcp as gcp

member = gcp.dataproc.MetastoreFederationIamMember("member",
    project=default["project"],
    location=default["location"],
    federation_id=default["federationId"],
    role="roles/viewer",
    member="user:jane@example.com")
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var member = new Gcp.Dataproc.MetastoreFederationIamMember("member", new()
    {
        Project = @default.Project,
        Location = @default.Location,
        FederationId = @default.FederationId,
        Role = "roles/viewer",
        Member = "user:jane@example.com",
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/dataproc"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		_, err := dataproc.NewMetastoreFederationIamMember(ctx, "member", &dataproc.MetastoreFederationIamMemberArgs{
			Project:      pulumi.Any(_default.Project),
			Location:     pulumi.Any(_default.Location),
			FederationId: pulumi.Any(_default.FederationId),
			Role:         pulumi.String("roles/viewer"),
			Member:       pulumi.String("user:jane@example.com"),
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.dataproc.MetastoreFederationIamMember;
import com.pulumi.gcp.dataproc.MetastoreFederationIamMemberArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        var member = new MetastoreFederationIamMember("member", MetastoreFederationIamMemberArgs.builder()
            .project(default_.project())
            .location(default_.location())
            .federationId(default_.federationId())
            .role("roles/viewer")
            .member("user:jane@example.com")
            .build());

    }
}
```
```yaml
resources:
  member:
    type: gcp:dataproc:MetastoreFederationIamMember
    properties:
      project: ${default.project}
      location: ${default.location}
      federationId: ${default.federationId}
      role: roles/viewer
      member: user:jane@example.com
```
<!--End PulumiCodeChooser -->


## This resource supports User Project Overrides.

-

# IAM policy for Dataproc metastore Federation
Three different resources help you manage your IAM policy for Dataproc metastore Federation. Each of these resources serves a different use case:

* `gcp.dataproc.MetastoreFederationIamPolicy`: Authoritative. Sets the IAM policy for the federation and replaces any existing policy already attached.
* `gcp.dataproc.MetastoreFederationIamBinding`: Authoritative for a given role. Updates the IAM policy to grant a role to a list of members. Other roles within the IAM policy for the federation are preserved.
* `gcp.dataproc.MetastoreFederationIamMember`: Non-authoritative. Updates the IAM policy to grant a role to a new member. Other members for the role for the federation are preserved.

A data source can be used to retrieve policy data in advent you do not need creation

* `gcp.dataproc.MetastoreFederationIamPolicy`: Retrieves the IAM policy for the federation

> **Note:** `gcp.dataproc.MetastoreFederationIamPolicy` **cannot** be used in conjunction with `gcp.dataproc.MetastoreFederationIamBinding` and `gcp.dataproc.MetastoreFederationIamMember` or they will fight over what your policy should be.

> **Note:** `gcp.dataproc.MetastoreFederationIamBinding` resources **can be** used in conjunction with `gcp.dataproc.MetastoreFederationIamMember` resources **only if** they do not grant privilege to the same role.



## gcp.dataproc.MetastoreFederationIamPolicy

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const admin = gcp.organizations.getIAMPolicy({
    bindings: [{
        role: "roles/viewer",
        members: ["user:jane@example.com"],
    }],
});
const policy = new gcp.dataproc.MetastoreFederationIamPolicy("policy", {
    project: _default.project,
    location: _default.location,
    federationId: _default.federationId,
    policyData: admin.then(admin => admin.policyData),
});
```
```python
import pulumi
import pulumi_gcp as gcp

admin = gcp.organizations.get_iam_policy(bindings=[{
    "role": "roles/viewer",
    "members": ["user:jane@example.com"],
}])
policy = gcp.dataproc.MetastoreFederationIamPolicy("policy",
    project=default["project"],
    location=default["location"],
    federation_id=default["federationId"],
    policy_data=admin.policy_data)
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var admin = Gcp.Organizations.GetIAMPolicy.Invoke(new()
    {
        Bindings = new[]
        {
            new Gcp.Organizations.Inputs.GetIAMPolicyBindingInputArgs
            {
                Role = "roles/viewer",
                Members = new[]
                {
                    "user:jane@example.com",
                },
            },
        },
    });

    var policy = new Gcp.Dataproc.MetastoreFederationIamPolicy("policy", new()
    {
        Project = @default.Project,
        Location = @default.Location,
        FederationId = @default.FederationId,
        PolicyData = admin.Apply(getIAMPolicyResult => getIAMPolicyResult.PolicyData),
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/dataproc"
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/organizations"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		admin, err := organizations.LookupIAMPolicy(ctx, &organizations.LookupIAMPolicyArgs{
			Bindings: []organizations.GetIAMPolicyBinding{
				{
					Role: "roles/viewer",
					Members: []string{
						"user:jane@example.com",
					},
				},
			},
		}, nil)
		if err != nil {
			return err
		}
		_, err = dataproc.NewMetastoreFederationIamPolicy(ctx, "policy", &dataproc.MetastoreFederationIamPolicyArgs{
			Project:      pulumi.Any(_default.Project),
			Location:     pulumi.Any(_default.Location),
			FederationId: pulumi.Any(_default.FederationId),
			PolicyData:   pulumi.String(admin.PolicyData),
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.organizations.OrganizationsFunctions;
import com.pulumi.gcp.organizations.inputs.GetIAMPolicyArgs;
import com.pulumi.gcp.dataproc.MetastoreFederationIamPolicy;
import com.pulumi.gcp.dataproc.MetastoreFederationIamPolicyArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        final var admin = OrganizationsFunctions.getIAMPolicy(GetIAMPolicyArgs.builder()
            .bindings(GetIAMPolicyBindingArgs.builder()
                .role("roles/viewer")
                .members("user:jane@example.com")
                .build())
            .build());

        var policy = new MetastoreFederationIamPolicy("policy", MetastoreFederationIamPolicyArgs.builder()
            .project(default_.project())
            .location(default_.location())
            .federationId(default_.federationId())
            .policyData(admin.applyValue(getIAMPolicyResult -> getIAMPolicyResult.policyData()))
            .build());

    }
}
```
```yaml
resources:
  policy:
    type: gcp:dataproc:MetastoreFederationIamPolicy
    properties:
      project: ${default.project}
      location: ${default.location}
      federationId: ${default.federationId}
      policyData: ${admin.policyData}
variables:
  admin:
    fn::invoke:
      function: gcp:organizations:getIAMPolicy
      arguments:
        bindings:
          - role: roles/viewer
            members:
              - user:jane@example.com
```
<!--End PulumiCodeChooser -->

## gcp.dataproc.MetastoreFederationIamBinding

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const binding = new gcp.dataproc.MetastoreFederationIamBinding("binding", {
    project: _default.project,
    location: _default.location,
    federationId: _default.federationId,
    role: "roles/viewer",
    members: ["user:jane@example.com"],
});
```
```python
import pulumi
import pulumi_gcp as gcp

binding = gcp.dataproc.MetastoreFederationIamBinding("binding",
    project=default["project"],
    location=default["location"],
    federation_id=default["federationId"],
    role="roles/viewer",
    members=["user:jane@example.com"])
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var binding = new Gcp.Dataproc.MetastoreFederationIamBinding("binding", new()
    {
        Project = @default.Project,
        Location = @default.Location,
        FederationId = @default.FederationId,
        Role = "roles/viewer",
        Members = new[]
        {
            "user:jane@example.com",
        },
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/dataproc"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		_, err := dataproc.NewMetastoreFederationIamBinding(ctx, "binding", &dataproc.MetastoreFederationIamBindingArgs{
			Project:      pulumi.Any(_default.Project),
			Location:     pulumi.Any(_default.Location),
			FederationId: pulumi.Any(_default.FederationId),
			Role:         pulumi.String("roles/viewer"),
			Members: pulumi.StringArray{
				pulumi.String("user:jane@example.com"),
			},
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.dataproc.MetastoreFederationIamBinding;
import com.pulumi.gcp.dataproc.MetastoreFederationIamBindingArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        var binding = new MetastoreFederationIamBinding("binding", MetastoreFederationIamBindingArgs.builder()
            .project(default_.project())
            .location(default_.location())
            .federationId(default_.federationId())
            .role("roles/viewer")
            .members("user:jane@example.com")
            .build());

    }
}
```
```yaml
resources:
  binding:
    type: gcp:dataproc:MetastoreFederationIamBinding
    properties:
      project: ${default.project}
      location: ${default.location}
      federationId: ${default.federationId}
      role: roles/viewer
      members:
        - user:jane@example.com
```
<!--End PulumiCodeChooser -->

## gcp.dataproc.MetastoreFederationIamMember

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const member = new gcp.dataproc.MetastoreFederationIamMember("member", {
    project: _default.project,
    location: _default.location,
    federationId: _default.federationId,
    role: "roles/viewer",
    member: "user:jane@example.com",
});
```
```python
import pulumi
import pulumi_gcp as gcp

member = gcp.dataproc.MetastoreFederationIamMember("member",
    project=default["project"],
    location=default["location"],
    federation_id=default["federationId"],
    role="roles/viewer",
    member="user:jane@example.com")
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var member = new Gcp.Dataproc.MetastoreFederationIamMember("member", new()
    {
        Project = @default.Project,
        Location = @default.Location,
        FederationId = @default.FederationId,
        Role = "roles/viewer",
        Member = "user:jane@example.com",
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/dataproc"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		_, err := dataproc.NewMetastoreFederationIamMember(ctx, "member", &dataproc.MetastoreFederationIamMemberArgs{
			Project:      pulumi.Any(_default.Project),
			Location:     pulumi.Any(_default.Location),
			FederationId: pulumi.Any(_default.FederationId),
			Role:         pulumi.String("roles/viewer"),
			Member:       pulumi.String("user:jane@example.com"),
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.dataproc.MetastoreFederationIamMember;
import com.pulumi.gcp.dataproc.MetastoreFederationIamMemberArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        var member = new MetastoreFederationIamMember("member", MetastoreFederationIamMemberArgs.builder()
            .project(default_.project())
            .location(default_.location())
            .federationId(default_.federationId())
            .role("roles/viewer")
            .member("user:jane@example.com")
            .build());

    }
}
```
```yaml
resources:
  member:
    type: gcp:dataproc:MetastoreFederationIamMember
    properties:
      project: ${default.project}
      location: ${default.location}
      federationId: ${default.federationId}
      role: roles/viewer
      member: user:jane@example.com
```
<!--End PulumiCodeChooser -->

## Import

For all import syntaxes, the "resource in question" can take any of the following forms:

* projects/{{project}}/locations/{{location}}/federations/{{federation_id}}

* {{project}}/{{location}}/{{federation_id}}

* {{location}}/{{federation_id}}

* {{federation_id}}

Any variables not passed in the import command will be taken from the provider configuration.

Dataproc metastore federation IAM resources can be imported using the resource identifiers, role, and member.

IAM member imports use space-delimited identifiers: the resource in question, the role, and the member identity, e.g.

```sh
$ pulumi import gcp:dataproc/metastoreFederationIamPolicy:MetastoreFederationIamPolicy editor "projects/{{project}}/locations/{{location}}/federations/{{federation_id}} roles/viewer user:jane@example.com"
```

IAM binding imports use space-delimited identifiers: the resource in question and the role, e.g.

```sh
$ pulumi import gcp:dataproc/metastoreFederationIamPolicy:MetastoreFederationIamPolicy editor "projects/{{project}}/locations/{{location}}/federations/{{federation_id}} roles/viewer"
```

IAM policy imports use the identifier of the resource in question, e.g.

```sh
$ pulumi import gcp:dataproc/metastoreFederationIamPolicy:MetastoreFederationIamPolicy editor projects/{{project}}/locations/{{location}}/federations/{{federation_id}}
```

-> **Custom Roles** If you're importing a IAM resource with a custom role, make sure to use the

 full name of the custom role, e.g. `[projects/my-project|organizations/my-org]/roles/my-custom-role`.


federationId" à
locationB" ÍThe location where the metastore federation should reside.
Used to find the parent resource to bind the IAM policy to. If not specified,
the value will be parsed from the identifier of the parent resource. If no location is provided in the parent identifier and no
location is specified, it is taken from the provider configuration.
_

policyData" MThe policy data generated by
a `gcp.organizations.getIAMPolicy` data source.

projectB" The ID of the project in which the resource belongs.
If it is not provided, the project will be parsed from the identifier of the parent resource. If no project is provided in the parent identifier and no project is specified, the provider project is used.
"3
etag" '(Computed) The etag of the IAM policy.
"
federationId" "Þ
location" ÍThe location where the metastore federation should reside.
Used to find the parent resource to bind the IAM policy to. If not specified,
the value will be parsed from the identifier of the parent resource. If no location is provided in the parent identifier and no
location is specified, it is taken from the provider configuration.
"_

policyData" MThe policy data generated by
a `gcp.organizations.getIAMPolicy` data source.
"
project" The ID of the project in which the resource belongs.
If it is not provided, the project will be parsed from the identifier of the parent resource. If no project is provided in the parent identifier and no project is specified, the provider project is used.
*Ùª
L
dataprocMetastoreService.gcp:dataproc/metastoreService:MetastoreService®æA managed metastore service that serves metadata queries.


To get more information about Service, see:

* [API documentation](https://cloud.google.com/dataproc-metastore/docs/reference/rest/v1/projects.locations.services)
* How-to Guides
    * [Official Documentation](https://cloud.google.com/dataproc-metastore/docs/overview)

## Example Usage

### Dataproc Metastore Service Basic


<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const _default = new gcp.dataproc.MetastoreService("default", {
    serviceId: "metastore-srv",
    location: "us-central1",
    port: 9080,
    tier: "DEVELOPER",
    maintenanceWindow: {
        hourOfDay: 2,
        dayOfWeek: "SUNDAY",
    },
    hiveMetastoreConfig: {
        version: "2.3.6",
    },
    labels: {
        env: "test",
    },
});
```
```python
import pulumi
import pulumi_gcp as gcp

default = gcp.dataproc.MetastoreService("default",
    service_id="metastore-srv",
    location="us-central1",
    port=9080,
    tier="DEVELOPER",
    maintenance_window={
        "hour_of_day": 2,
        "day_of_week": "SUNDAY",
    },
    hive_metastore_config={
        "version": "2.3.6",
    },
    labels={
        "env": "test",
    })
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var @default = new Gcp.Dataproc.MetastoreService("default", new()
    {
        ServiceId = "metastore-srv",
        Location = "us-central1",
        Port = 9080,
        Tier = "DEVELOPER",
        MaintenanceWindow = new Gcp.Dataproc.Inputs.MetastoreServiceMaintenanceWindowArgs
        {
            HourOfDay = 2,
            DayOfWeek = "SUNDAY",
        },
        HiveMetastoreConfig = new Gcp.Dataproc.Inputs.MetastoreServiceHiveMetastoreConfigArgs
        {
            Version = "2.3.6",
        },
        Labels = 
        {
            { "env", "test" },
        },
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/dataproc"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		_, err := dataproc.NewMetastoreService(ctx, "default", &dataproc.MetastoreServiceArgs{
			ServiceId: pulumi.String("metastore-srv"),
			Location:  pulumi.String("us-central1"),
			Port:      pulumi.Int(9080),
			Tier:      pulumi.String("DEVELOPER"),
			MaintenanceWindow: &dataproc.MetastoreServiceMaintenanceWindowArgs{
				HourOfDay: pulumi.Int(2),
				DayOfWeek: pulumi.String("SUNDAY"),
			},
			HiveMetastoreConfig: &dataproc.MetastoreServiceHiveMetastoreConfigArgs{
				Version: pulumi.String("2.3.6"),
			},
			Labels: pulumi.StringMap{
				"env": pulumi.String("test"),
			},
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.dataproc.MetastoreService;
import com.pulumi.gcp.dataproc.MetastoreServiceArgs;
import com.pulumi.gcp.dataproc.inputs.MetastoreServiceMaintenanceWindowArgs;
import com.pulumi.gcp.dataproc.inputs.MetastoreServiceHiveMetastoreConfigArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        var default_ = new MetastoreService("default", MetastoreServiceArgs.builder()
            .serviceId("metastore-srv")
            .location("us-central1")
            .port(9080)
            .tier("DEVELOPER")
            .maintenanceWindow(MetastoreServiceMaintenanceWindowArgs.builder()
                .hourOfDay(2)
                .dayOfWeek("SUNDAY")
                .build())
            .hiveMetastoreConfig(MetastoreServiceHiveMetastoreConfigArgs.builder()
                .version("2.3.6")
                .build())
            .labels(Map.of("env", "test"))
            .build());

    }
}
```
```yaml
resources:
  default:
    type: gcp:dataproc:MetastoreService
    properties:
      serviceId: metastore-srv
      location: us-central1
      port: 9080
      tier: DEVELOPER
      maintenanceWindow:
        hourOfDay: 2
        dayOfWeek: SUNDAY
      hiveMetastoreConfig:
        version: 2.3.6
      labels:
        env: test
```
<!--End PulumiCodeChooser -->
### Dataproc Metastore Service Deletion Protection


<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const _default = new gcp.dataproc.MetastoreService("default", {
    serviceId: "metastore-srv",
    location: "us-central1",
    port: 9080,
    tier: "DEVELOPER",
    deletionProtection: true,
    maintenanceWindow: {
        hourOfDay: 2,
        dayOfWeek: "SUNDAY",
    },
    hiveMetastoreConfig: {
        version: "2.3.6",
    },
    labels: {
        env: "test",
    },
});
```
```python
import pulumi
import pulumi_gcp as gcp

default = gcp.dataproc.MetastoreService("default",
    service_id="metastore-srv",
    location="us-central1",
    port=9080,
    tier="DEVELOPER",
    deletion_protection=True,
    maintenance_window={
        "hour_of_day": 2,
        "day_of_week": "SUNDAY",
    },
    hive_metastore_config={
        "version": "2.3.6",
    },
    labels={
        "env": "test",
    })
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var @default = new Gcp.Dataproc.MetastoreService("default", new()
    {
        ServiceId = "metastore-srv",
        Location = "us-central1",
        Port = 9080,
        Tier = "DEVELOPER",
        DeletionProtection = true,
        MaintenanceWindow = new Gcp.Dataproc.Inputs.MetastoreServiceMaintenanceWindowArgs
        {
            HourOfDay = 2,
            DayOfWeek = "SUNDAY",
        },
        HiveMetastoreConfig = new Gcp.Dataproc.Inputs.MetastoreServiceHiveMetastoreConfigArgs
        {
            Version = "2.3.6",
        },
        Labels = 
        {
            { "env", "test" },
        },
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/dataproc"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		_, err := dataproc.NewMetastoreService(ctx, "default", &dataproc.MetastoreServiceArgs{
			ServiceId:          pulumi.String("metastore-srv"),
			Location:           pulumi.String("us-central1"),
			Port:               pulumi.Int(9080),
			Tier:               pulumi.String("DEVELOPER"),
			DeletionProtection: pulumi.Bool(true),
			MaintenanceWindow: &dataproc.MetastoreServiceMaintenanceWindowArgs{
				HourOfDay: pulumi.Int(2),
				DayOfWeek: pulumi.String("SUNDAY"),
			},
			HiveMetastoreConfig: &dataproc.MetastoreServiceHiveMetastoreConfigArgs{
				Version: pulumi.String("2.3.6"),
			},
			Labels: pulumi.StringMap{
				"env": pulumi.String("test"),
			},
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.dataproc.MetastoreService;
import com.pulumi.gcp.dataproc.MetastoreServiceArgs;
import com.pulumi.gcp.dataproc.inputs.MetastoreServiceMaintenanceWindowArgs;
import com.pulumi.gcp.dataproc.inputs.MetastoreServiceHiveMetastoreConfigArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        var default_ = new MetastoreService("default", MetastoreServiceArgs.builder()
            .serviceId("metastore-srv")
            .location("us-central1")
            .port(9080)
            .tier("DEVELOPER")
            .deletionProtection(true)
            .maintenanceWindow(MetastoreServiceMaintenanceWindowArgs.builder()
                .hourOfDay(2)
                .dayOfWeek("SUNDAY")
                .build())
            .hiveMetastoreConfig(MetastoreServiceHiveMetastoreConfigArgs.builder()
                .version("2.3.6")
                .build())
            .labels(Map.of("env", "test"))
            .build());

    }
}
```
```yaml
resources:
  default:
    type: gcp:dataproc:MetastoreService
    properties:
      serviceId: metastore-srv
      location: us-central1
      port: 9080
      tier: DEVELOPER
      deletionProtection: true
      maintenanceWindow:
        hourOfDay: 2
        dayOfWeek: SUNDAY
      hiveMetastoreConfig:
        version: 2.3.6
      labels:
        env: test
```
<!--End PulumiCodeChooser -->
### Dataproc Metastore Service Cmek Example


<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const keyRing = new gcp.kms.KeyRing("key_ring", {
    name: "example-keyring",
    location: "us-central1",
});
const cryptoKey = new gcp.kms.CryptoKey("crypto_key", {
    name: "example-key",
    keyRing: keyRing.id,
    purpose: "ENCRYPT_DECRYPT",
});
const _default = new gcp.dataproc.MetastoreService("default", {
    serviceId: "example-service",
    location: "us-central1",
    encryptionConfig: {
        kmsKey: cryptoKey.id,
    },
    hiveMetastoreConfig: {
        version: "3.1.2",
    },
});
```
```python
import pulumi
import pulumi_gcp as gcp

key_ring = gcp.kms.KeyRing("key_ring",
    name="example-keyring",
    location="us-central1")
crypto_key = gcp.kms.CryptoKey("crypto_key",
    name="example-key",
    key_ring=key_ring.id,
    purpose="ENCRYPT_DECRYPT")
default = gcp.dataproc.MetastoreService("default",
    service_id="example-service",
    location="us-central1",
    encryption_config={
        "kms_key": crypto_key.id,
    },
    hive_metastore_config={
        "version": "3.1.2",
    })
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var keyRing = new Gcp.Kms.KeyRing("key_ring", new()
    {
        Name = "example-keyring",
        Location = "us-central1",
    });

    var cryptoKey = new Gcp.Kms.CryptoKey("crypto_key", new()
    {
        Name = "example-key",
        KeyRing = keyRing.Id,
        Purpose = "ENCRYPT_DECRYPT",
    });

    var @default = new Gcp.Dataproc.MetastoreService("default", new()
    {
        ServiceId = "example-service",
        Location = "us-central1",
        EncryptionConfig = new Gcp.Dataproc.Inputs.MetastoreServiceEncryptionConfigArgs
        {
            KmsKey = cryptoKey.Id,
        },
        HiveMetastoreConfig = new Gcp.Dataproc.Inputs.MetastoreServiceHiveMetastoreConfigArgs
        {
            Version = "3.1.2",
        },
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/dataproc"
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/kms"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		keyRing, err := kms.NewKeyRing(ctx, "key_ring", &kms.KeyRingArgs{
			Name:     pulumi.String("example-keyring"),
			Location: pulumi.String("us-central1"),
		})
		if err != nil {
			return err
		}
		cryptoKey, err := kms.NewCryptoKey(ctx, "crypto_key", &kms.CryptoKeyArgs{
			Name:    pulumi.String("example-key"),
			KeyRing: keyRing.ID(),
			Purpose: pulumi.String("ENCRYPT_DECRYPT"),
		})
		if err != nil {
			return err
		}
		_, err = dataproc.NewMetastoreService(ctx, "default", &dataproc.MetastoreServiceArgs{
			ServiceId: pulumi.String("example-service"),
			Location:  pulumi.String("us-central1"),
			EncryptionConfig: &dataproc.MetastoreServiceEncryptionConfigArgs{
				KmsKey: cryptoKey.ID(),
			},
			HiveMetastoreConfig: &dataproc.MetastoreServiceHiveMetastoreConfigArgs{
				Version: pulumi.String("3.1.2"),
			},
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.kms.KeyRing;
import com.pulumi.gcp.kms.KeyRingArgs;
import com.pulumi.gcp.kms.CryptoKey;
import com.pulumi.gcp.kms.CryptoKeyArgs;
import com.pulumi.gcp.dataproc.MetastoreService;
import com.pulumi.gcp.dataproc.MetastoreServiceArgs;
import com.pulumi.gcp.dataproc.inputs.MetastoreServiceEncryptionConfigArgs;
import com.pulumi.gcp.dataproc.inputs.MetastoreServiceHiveMetastoreConfigArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        var keyRing = new KeyRing("keyRing", KeyRingArgs.builder()
            .name("example-keyring")
            .location("us-central1")
            .build());

        var cryptoKey = new CryptoKey("cryptoKey", CryptoKeyArgs.builder()
            .name("example-key")
            .keyRing(keyRing.id())
            .purpose("ENCRYPT_DECRYPT")
            .build());

        var default_ = new MetastoreService("default", MetastoreServiceArgs.builder()
            .serviceId("example-service")
            .location("us-central1")
            .encryptionConfig(MetastoreServiceEncryptionConfigArgs.builder()
                .kmsKey(cryptoKey.id())
                .build())
            .hiveMetastoreConfig(MetastoreServiceHiveMetastoreConfigArgs.builder()
                .version("3.1.2")
                .build())
            .build());

    }
}
```
```yaml
resources:
  default:
    type: gcp:dataproc:MetastoreService
    properties:
      serviceId: example-service
      location: us-central1
      encryptionConfig:
        kmsKey: ${cryptoKey.id}
      hiveMetastoreConfig:
        version: 3.1.2
  cryptoKey:
    type: gcp:kms:CryptoKey
    name: crypto_key
    properties:
      name: example-key
      keyRing: ${keyRing.id}
      purpose: ENCRYPT_DECRYPT
  keyRing:
    type: gcp:kms:KeyRing
    name: key_ring
    properties:
      name: example-keyring
      location: us-central1
```
<!--End PulumiCodeChooser -->
### Dataproc Metastore Service Private Service Connect


<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const net = new gcp.compute.Network("net", {
    name: "my-network",
    autoCreateSubnetworks: false,
});
const subnet = new gcp.compute.Subnetwork("subnet", {
    name: "my-subnetwork",
    region: "us-central1",
    network: net.id,
    ipCidrRange: "10.0.0.0/22",
    privateIpGoogleAccess: true,
});
const _default = new gcp.dataproc.MetastoreService("default", {
    serviceId: "metastore-srv",
    location: "us-central1",
    tier: "DEVELOPER",
    hiveMetastoreConfig: {
        version: "3.1.2",
    },
    networkConfig: {
        consumers: [{
            subnetwork: subnet.id,
        }],
    },
});
```
```python
import pulumi
import pulumi_gcp as gcp

net = gcp.compute.Network("net",
    name="my-network",
    auto_create_subnetworks=False)
subnet = gcp.compute.Subnetwork("subnet",
    name="my-subnetwork",
    region="us-central1",
    network=net.id,
    ip_cidr_range="10.0.0.0/22",
    private_ip_google_access=True)
default = gcp.dataproc.MetastoreService("default",
    service_id="metastore-srv",
    location="us-central1",
    tier="DEVELOPER",
    hive_metastore_config={
        "version": "3.1.2",
    },
    network_config={
        "consumers": [{
            "subnetwork": subnet.id,
        }],
    })
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var net = new Gcp.Compute.Network("net", new()
    {
        Name = "my-network",
        AutoCreateSubnetworks = false,
    });

    var subnet = new Gcp.Compute.Subnetwork("subnet", new()
    {
        Name = "my-subnetwork",
        Region = "us-central1",
        Network = net.Id,
        IpCidrRange = "10.0.0.0/22",
        PrivateIpGoogleAccess = true,
    });

    var @default = new Gcp.Dataproc.MetastoreService("default", new()
    {
        ServiceId = "metastore-srv",
        Location = "us-central1",
        Tier = "DEVELOPER",
        HiveMetastoreConfig = new Gcp.Dataproc.Inputs.MetastoreServiceHiveMetastoreConfigArgs
        {
            Version = "3.1.2",
        },
        NetworkConfig = new Gcp.Dataproc.Inputs.MetastoreServiceNetworkConfigArgs
        {
            Consumers = new[]
            {
                new Gcp.Dataproc.Inputs.MetastoreServiceNetworkConfigConsumerArgs
                {
                    Subnetwork = subnet.Id,
                },
            },
        },
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/compute"
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/dataproc"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		net, err := compute.NewNetwork(ctx, "net", &compute.NetworkArgs{
			Name:                  pulumi.String("my-network"),
			AutoCreateSubnetworks: pulumi.Bool(false),
		})
		if err != nil {
			return err
		}
		subnet, err := compute.NewSubnetwork(ctx, "subnet", &compute.SubnetworkArgs{
			Name:                  pulumi.String("my-subnetwork"),
			Region:                pulumi.String("us-central1"),
			Network:               net.ID(),
			IpCidrRange:           pulumi.String("10.0.0.0/22"),
			PrivateIpGoogleAccess: pulumi.Bool(true),
		})
		if err != nil {
			return err
		}
		_, err = dataproc.NewMetastoreService(ctx, "default", &dataproc.MetastoreServiceArgs{
			ServiceId: pulumi.String("metastore-srv"),
			Location:  pulumi.String("us-central1"),
			Tier:      pulumi.String("DEVELOPER"),
			HiveMetastoreConfig: &dataproc.MetastoreServiceHiveMetastoreConfigArgs{
				Version: pulumi.String("3.1.2"),
			},
			NetworkConfig: &dataproc.MetastoreServiceNetworkConfigArgs{
				Consumers: dataproc.MetastoreServiceNetworkConfigConsumerArray{
					&dataproc.MetastoreServiceNetworkConfigConsumerArgs{
						Subnetwork: subnet.ID(),
					},
				},
			},
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.compute.Network;
import com.pulumi.gcp.compute.NetworkArgs;
import com.pulumi.gcp.compute.Subnetwork;
import com.pulumi.gcp.compute.SubnetworkArgs;
import com.pulumi.gcp.dataproc.MetastoreService;
import com.pulumi.gcp.dataproc.MetastoreServiceArgs;
import com.pulumi.gcp.dataproc.inputs.MetastoreServiceHiveMetastoreConfigArgs;
import com.pulumi.gcp.dataproc.inputs.MetastoreServiceNetworkConfigArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        var net = new Network("net", NetworkArgs.builder()
            .name("my-network")
            .autoCreateSubnetworks(false)
            .build());

        var subnet = new Subnetwork("subnet", SubnetworkArgs.builder()
            .name("my-subnetwork")
            .region("us-central1")
            .network(net.id())
            .ipCidrRange("10.0.0.0/22")
            .privateIpGoogleAccess(true)
            .build());

        var default_ = new MetastoreService("default", MetastoreServiceArgs.builder()
            .serviceId("metastore-srv")
            .location("us-central1")
            .tier("DEVELOPER")
            .hiveMetastoreConfig(MetastoreServiceHiveMetastoreConfigArgs.builder()
                .version("3.1.2")
                .build())
            .networkConfig(MetastoreServiceNetworkConfigArgs.builder()
                .consumers(MetastoreServiceNetworkConfigConsumerArgs.builder()
                    .subnetwork(subnet.id())
                    .build())
                .build())
            .build());

    }
}
```
```yaml
resources:
  net:
    type: gcp:compute:Network
    properties:
      name: my-network
      autoCreateSubnetworks: false
  subnet:
    type: gcp:compute:Subnetwork
    properties:
      name: my-subnetwork
      region: us-central1
      network: ${net.id}
      ipCidrRange: 10.0.0.0/22
      privateIpGoogleAccess: true
  default:
    type: gcp:dataproc:MetastoreService
    properties:
      serviceId: metastore-srv
      location: us-central1
      tier: DEVELOPER
      hiveMetastoreConfig:
        version: 3.1.2
      networkConfig:
        consumers:
          - subnetwork: ${subnet.id}
```
<!--End PulumiCodeChooser -->
### Dataproc Metastore Service Private Service Connect Custom Routes


<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const net = new gcp.compute.Network("net", {
    name: "my-network",
    autoCreateSubnetworks: false,
});
const subnet = new gcp.compute.Subnetwork("subnet", {
    name: "my-subnetwork",
    region: "us-central1",
    network: net.id,
    ipCidrRange: "10.0.0.0/22",
    privateIpGoogleAccess: true,
});
const _default = new gcp.dataproc.MetastoreService("default", {
    serviceId: "metastore-srv",
    location: "us-central1",
    hiveMetastoreConfig: {
        version: "3.1.2",
    },
    networkConfig: {
        consumers: [{
            subnetwork: subnet.id,
        }],
        customRoutesEnabled: true,
    },
});
```
```python
import pulumi
import pulumi_gcp as gcp

net = gcp.compute.Network("net",
    name="my-network",
    auto_create_subnetworks=False)
subnet = gcp.compute.Subnetwork("subnet",
    name="my-subnetwork",
    region="us-central1",
    network=net.id,
    ip_cidr_range="10.0.0.0/22",
    private_ip_google_access=True)
default = gcp.dataproc.MetastoreService("default",
    service_id="metastore-srv",
    location="us-central1",
    hive_metastore_config={
        "version": "3.1.2",
    },
    network_config={
        "consumers": [{
            "subnetwork": subnet.id,
        }],
        "custom_routes_enabled": True,
    })
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var net = new Gcp.Compute.Network("net", new()
    {
        Name = "my-network",
        AutoCreateSubnetworks = false,
    });

    var subnet = new Gcp.Compute.Subnetwork("subnet", new()
    {
        Name = "my-subnetwork",
        Region = "us-central1",
        Network = net.Id,
        IpCidrRange = "10.0.0.0/22",
        PrivateIpGoogleAccess = true,
    });

    var @default = new Gcp.Dataproc.MetastoreService("default", new()
    {
        ServiceId = "metastore-srv",
        Location = "us-central1",
        HiveMetastoreConfig = new Gcp.Dataproc.Inputs.MetastoreServiceHiveMetastoreConfigArgs
        {
            Version = "3.1.2",
        },
        NetworkConfig = new Gcp.Dataproc.Inputs.MetastoreServiceNetworkConfigArgs
        {
            Consumers = new[]
            {
                new Gcp.Dataproc.Inputs.MetastoreServiceNetworkConfigConsumerArgs
                {
                    Subnetwork = subnet.Id,
                },
            },
            CustomRoutesEnabled = true,
        },
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/compute"
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/dataproc"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		net, err := compute.NewNetwork(ctx, "net", &compute.NetworkArgs{
			Name:                  pulumi.String("my-network"),
			AutoCreateSubnetworks: pulumi.Bool(false),
		})
		if err != nil {
			return err
		}
		subnet, err := compute.NewSubnetwork(ctx, "subnet", &compute.SubnetworkArgs{
			Name:                  pulumi.String("my-subnetwork"),
			Region:                pulumi.String("us-central1"),
			Network:               net.ID(),
			IpCidrRange:           pulumi.String("10.0.0.0/22"),
			PrivateIpGoogleAccess: pulumi.Bool(true),
		})
		if err != nil {
			return err
		}
		_, err = dataproc.NewMetastoreService(ctx, "default", &dataproc.MetastoreServiceArgs{
			ServiceId: pulumi.String("metastore-srv"),
			Location:  pulumi.String("us-central1"),
			HiveMetastoreConfig: &dataproc.MetastoreServiceHiveMetastoreConfigArgs{
				Version: pulumi.String("3.1.2"),
			},
			NetworkConfig: &dataproc.MetastoreServiceNetworkConfigArgs{
				Consumers: dataproc.MetastoreServiceNetworkConfigConsumerArray{
					&dataproc.MetastoreServiceNetworkConfigConsumerArgs{
						Subnetwork: subnet.ID(),
					},
				},
				CustomRoutesEnabled: pulumi.Bool(true),
			},
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.compute.Network;
import com.pulumi.gcp.compute.NetworkArgs;
import com.pulumi.gcp.compute.Subnetwork;
import com.pulumi.gcp.compute.SubnetworkArgs;
import com.pulumi.gcp.dataproc.MetastoreService;
import com.pulumi.gcp.dataproc.MetastoreServiceArgs;
import com.pulumi.gcp.dataproc.inputs.MetastoreServiceHiveMetastoreConfigArgs;
import com.pulumi.gcp.dataproc.inputs.MetastoreServiceNetworkConfigArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        var net = new Network("net", NetworkArgs.builder()
            .name("my-network")
            .autoCreateSubnetworks(false)
            .build());

        var subnet = new Subnetwork("subnet", SubnetworkArgs.builder()
            .name("my-subnetwork")
            .region("us-central1")
            .network(net.id())
            .ipCidrRange("10.0.0.0/22")
            .privateIpGoogleAccess(true)
            .build());

        var default_ = new MetastoreService("default", MetastoreServiceArgs.builder()
            .serviceId("metastore-srv")
            .location("us-central1")
            .hiveMetastoreConfig(MetastoreServiceHiveMetastoreConfigArgs.builder()
                .version("3.1.2")
                .build())
            .networkConfig(MetastoreServiceNetworkConfigArgs.builder()
                .consumers(MetastoreServiceNetworkConfigConsumerArgs.builder()
                    .subnetwork(subnet.id())
                    .build())
                .customRoutesEnabled(true)
                .build())
            .build());

    }
}
```
```yaml
resources:
  net:
    type: gcp:compute:Network
    properties:
      name: my-network
      autoCreateSubnetworks: false
  subnet:
    type: gcp:compute:Subnetwork
    properties:
      name: my-subnetwork
      region: us-central1
      network: ${net.id}
      ipCidrRange: 10.0.0.0/22
      privateIpGoogleAccess: true
  default:
    type: gcp:dataproc:MetastoreService
    properties:
      serviceId: metastore-srv
      location: us-central1
      hiveMetastoreConfig:
        version: 3.1.2
      networkConfig:
        consumers:
          - subnetwork: ${subnet.id}
        customRoutesEnabled: true
```
<!--End PulumiCodeChooser -->
### Dataproc Metastore Service Dpms2


<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const dpms2 = new gcp.dataproc.MetastoreService("dpms2", {
    serviceId: "ms-dpms2",
    location: "us-central1",
    databaseType: "SPANNER",
    hiveMetastoreConfig: {
        version: "3.1.2",
    },
    scalingConfig: {
        instanceSize: "EXTRA_SMALL",
    },
});
```
```python
import pulumi
import pulumi_gcp as gcp

dpms2 = gcp.dataproc.MetastoreService("dpms2",
    service_id="ms-dpms2",
    location="us-central1",
    database_type="SPANNER",
    hive_metastore_config={
        "version": "3.1.2",
    },
    scaling_config={
        "instance_size": "EXTRA_SMALL",
    })
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var dpms2 = new Gcp.Dataproc.MetastoreService("dpms2", new()
    {
        ServiceId = "ms-dpms2",
        Location = "us-central1",
        DatabaseType = "SPANNER",
        HiveMetastoreConfig = new Gcp.Dataproc.Inputs.MetastoreServiceHiveMetastoreConfigArgs
        {
            Version = "3.1.2",
        },
        ScalingConfig = new Gcp.Dataproc.Inputs.MetastoreServiceScalingConfigArgs
        {
            InstanceSize = "EXTRA_SMALL",
        },
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/dataproc"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		_, err := dataproc.NewMetastoreService(ctx, "dpms2", &dataproc.MetastoreServiceArgs{
			ServiceId:    pulumi.String("ms-dpms2"),
			Location:     pulumi.String("us-central1"),
			DatabaseType: pulumi.String("SPANNER"),
			HiveMetastoreConfig: &dataproc.MetastoreServiceHiveMetastoreConfigArgs{
				Version: pulumi.String("3.1.2"),
			},
			ScalingConfig: &dataproc.MetastoreServiceScalingConfigArgs{
				InstanceSize: pulumi.String("EXTRA_SMALL"),
			},
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.dataproc.MetastoreService;
import com.pulumi.gcp.dataproc.MetastoreServiceArgs;
import com.pulumi.gcp.dataproc.inputs.MetastoreServiceHiveMetastoreConfigArgs;
import com.pulumi.gcp.dataproc.inputs.MetastoreServiceScalingConfigArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        var dpms2 = new MetastoreService("dpms2", MetastoreServiceArgs.builder()
            .serviceId("ms-dpms2")
            .location("us-central1")
            .databaseType("SPANNER")
            .hiveMetastoreConfig(MetastoreServiceHiveMetastoreConfigArgs.builder()
                .version("3.1.2")
                .build())
            .scalingConfig(MetastoreServiceScalingConfigArgs.builder()
                .instanceSize("EXTRA_SMALL")
                .build())
            .build());

    }
}
```
```yaml
resources:
  dpms2:
    type: gcp:dataproc:MetastoreService
    properties:
      serviceId: ms-dpms2
      location: us-central1
      databaseType: SPANNER
      hiveMetastoreConfig:
        version: 3.1.2
      scalingConfig:
        instanceSize: EXTRA_SMALL
```
<!--End PulumiCodeChooser -->
### Dataproc Metastore Service Dpms2 Scaling Factor


<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const dpms2ScalingFactor = new gcp.dataproc.MetastoreService("dpms2_scaling_factor", {
    serviceId: "ms-dpms2sf",
    location: "us-central1",
    databaseType: "SPANNER",
    hiveMetastoreConfig: {
        version: "3.1.2",
    },
    scalingConfig: {
        scalingFactor: 2,
    },
});
```
```python
import pulumi
import pulumi_gcp as gcp

dpms2_scaling_factor = gcp.dataproc.MetastoreService("dpms2_scaling_factor",
    service_id="ms-dpms2sf",
    location="us-central1",
    database_type="SPANNER",
    hive_metastore_config={
        "version": "3.1.2",
    },
    scaling_config={
        "scaling_factor": 2,
    })
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var dpms2ScalingFactor = new Gcp.Dataproc.MetastoreService("dpms2_scaling_factor", new()
    {
        ServiceId = "ms-dpms2sf",
        Location = "us-central1",
        DatabaseType = "SPANNER",
        HiveMetastoreConfig = new Gcp.Dataproc.Inputs.MetastoreServiceHiveMetastoreConfigArgs
        {
            Version = "3.1.2",
        },
        ScalingConfig = new Gcp.Dataproc.Inputs.MetastoreServiceScalingConfigArgs
        {
            ScalingFactor = 2,
        },
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/dataproc"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		_, err := dataproc.NewMetastoreService(ctx, "dpms2_scaling_factor", &dataproc.MetastoreServiceArgs{
			ServiceId:    pulumi.String("ms-dpms2sf"),
			Location:     pulumi.String("us-central1"),
			DatabaseType: pulumi.String("SPANNER"),
			HiveMetastoreConfig: &dataproc.MetastoreServiceHiveMetastoreConfigArgs{
				Version: pulumi.String("3.1.2"),
			},
			ScalingConfig: &dataproc.MetastoreServiceScalingConfigArgs{
				ScalingFactor: pulumi.Float64(2),
			},
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.dataproc.MetastoreService;
import com.pulumi.gcp.dataproc.MetastoreServiceArgs;
import com.pulumi.gcp.dataproc.inputs.MetastoreServiceHiveMetastoreConfigArgs;
import com.pulumi.gcp.dataproc.inputs.MetastoreServiceScalingConfigArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        var dpms2ScalingFactor = new MetastoreService("dpms2ScalingFactor", MetastoreServiceArgs.builder()
            .serviceId("ms-dpms2sf")
            .location("us-central1")
            .databaseType("SPANNER")
            .hiveMetastoreConfig(MetastoreServiceHiveMetastoreConfigArgs.builder()
                .version("3.1.2")
                .build())
            .scalingConfig(MetastoreServiceScalingConfigArgs.builder()
                .scalingFactor("2")
                .build())
            .build());

    }
}
```
```yaml
resources:
  dpms2ScalingFactor:
    type: gcp:dataproc:MetastoreService
    name: dpms2_scaling_factor
    properties:
      serviceId: ms-dpms2sf
      location: us-central1
      databaseType: SPANNER
      hiveMetastoreConfig:
        version: 3.1.2
      scalingConfig:
        scalingFactor: '2'
```
<!--End PulumiCodeChooser -->
### Dataproc Metastore Service Scheduled Backup


<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const bucket = new gcp.storage.Bucket("bucket", {
    name: "backup",
    location: "us-central1",
});
const backup = new gcp.dataproc.MetastoreService("backup", {
    serviceId: "backup",
    location: "us-central1",
    port: 9080,
    tier: "DEVELOPER",
    maintenanceWindow: {
        hourOfDay: 2,
        dayOfWeek: "SUNDAY",
    },
    hiveMetastoreConfig: {
        version: "2.3.6",
    },
    scheduledBackup: {
        enabled: true,
        cronSchedule: "0 0 * * *",
        timeZone: "UTC",
        backupLocation: pulumi.interpolate`gs://${bucket.name}`,
    },
    labels: {
        env: "test",
    },
});
```
```python
import pulumi
import pulumi_gcp as gcp

bucket = gcp.storage.Bucket("bucket",
    name="backup",
    location="us-central1")
backup = gcp.dataproc.MetastoreService("backup",
    service_id="backup",
    location="us-central1",
    port=9080,
    tier="DEVELOPER",
    maintenance_window={
        "hour_of_day": 2,
        "day_of_week": "SUNDAY",
    },
    hive_metastore_config={
        "version": "2.3.6",
    },
    scheduled_backup={
        "enabled": True,
        "cron_schedule": "0 0 * * *",
        "time_zone": "UTC",
        "backup_location": bucket.name.apply(lambda name: f"gs://{name}"),
    },
    labels={
        "env": "test",
    })
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var bucket = new Gcp.Storage.Bucket("bucket", new()
    {
        Name = "backup",
        Location = "us-central1",
    });

    var backup = new Gcp.Dataproc.MetastoreService("backup", new()
    {
        ServiceId = "backup",
        Location = "us-central1",
        Port = 9080,
        Tier = "DEVELOPER",
        MaintenanceWindow = new Gcp.Dataproc.Inputs.MetastoreServiceMaintenanceWindowArgs
        {
            HourOfDay = 2,
            DayOfWeek = "SUNDAY",
        },
        HiveMetastoreConfig = new Gcp.Dataproc.Inputs.MetastoreServiceHiveMetastoreConfigArgs
        {
            Version = "2.3.6",
        },
        ScheduledBackup = new Gcp.Dataproc.Inputs.MetastoreServiceScheduledBackupArgs
        {
            Enabled = true,
            CronSchedule = "0 0 * * *",
            TimeZone = "UTC",
            BackupLocation = bucket.Name.Apply(name => $"gs://{name}"),
        },
        Labels = 
        {
            { "env", "test" },
        },
    });

});
```
```go
package main

import (
	"fmt"

	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/dataproc"
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/storage"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		bucket, err := storage.NewBucket(ctx, "bucket", &storage.BucketArgs{
			Name:     pulumi.String("backup"),
			Location: pulumi.String("us-central1"),
		})
		if err != nil {
			return err
		}
		_, err = dataproc.NewMetastoreService(ctx, "backup", &dataproc.MetastoreServiceArgs{
			ServiceId: pulumi.String("backup"),
			Location:  pulumi.String("us-central1"),
			Port:      pulumi.Int(9080),
			Tier:      pulumi.String("DEVELOPER"),
			MaintenanceWindow: &dataproc.MetastoreServiceMaintenanceWindowArgs{
				HourOfDay: pulumi.Int(2),
				DayOfWeek: pulumi.String("SUNDAY"),
			},
			HiveMetastoreConfig: &dataproc.MetastoreServiceHiveMetastoreConfigArgs{
				Version: pulumi.String("2.3.6"),
			},
			ScheduledBackup: &dataproc.MetastoreServiceScheduledBackupArgs{
				Enabled:      pulumi.Bool(true),
				CronSchedule: pulumi.String("0 0 * * *"),
				TimeZone:     pulumi.String("UTC"),
				BackupLocation: bucket.Name.ApplyT(func(name string) (string, error) {
					return fmt.Sprintf("gs://%v", name), nil
				}).(pulumi.StringOutput),
			},
			Labels: pulumi.StringMap{
				"env": pulumi.String("test"),
			},
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.storage.Bucket;
import com.pulumi.gcp.storage.BucketArgs;
import com.pulumi.gcp.dataproc.MetastoreService;
import com.pulumi.gcp.dataproc.MetastoreServiceArgs;
import com.pulumi.gcp.dataproc.inputs.MetastoreServiceMaintenanceWindowArgs;
import com.pulumi.gcp.dataproc.inputs.MetastoreServiceHiveMetastoreConfigArgs;
import com.pulumi.gcp.dataproc.inputs.MetastoreServiceScheduledBackupArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        var bucket = new Bucket("bucket", BucketArgs.builder()
            .name("backup")
            .location("us-central1")
            .build());

        var backup = new MetastoreService("backup", MetastoreServiceArgs.builder()
            .serviceId("backup")
            .location("us-central1")
            .port(9080)
            .tier("DEVELOPER")
            .maintenanceWindow(MetastoreServiceMaintenanceWindowArgs.builder()
                .hourOfDay(2)
                .dayOfWeek("SUNDAY")
                .build())
            .hiveMetastoreConfig(MetastoreServiceHiveMetastoreConfigArgs.builder()
                .version("2.3.6")
                .build())
            .scheduledBackup(MetastoreServiceScheduledBackupArgs.builder()
                .enabled(true)
                .cronSchedule("0 0 * * *")
                .timeZone("UTC")
                .backupLocation(bucket.name().applyValue(name -> String.format("gs://%s", name)))
                .build())
            .labels(Map.of("env", "test"))
            .build());

    }
}
```
```yaml
resources:
  backup:
    type: gcp:dataproc:MetastoreService
    properties:
      serviceId: backup
      location: us-central1
      port: 9080
      tier: DEVELOPER
      maintenanceWindow:
        hourOfDay: 2
        dayOfWeek: SUNDAY
      hiveMetastoreConfig:
        version: 2.3.6
      scheduledBackup:
        enabled: true
        cronSchedule: 0 0 * * *
        timeZone: UTC
        backupLocation: gs://${bucket.name}
      labels:
        env: test
  bucket:
    type: gcp:storage:Bucket
    properties:
      name: backup
      location: us-central1
```
<!--End PulumiCodeChooser -->
### Dataproc Metastore Service Autoscaling Max Scaling Factor


<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const testResource = new gcp.dataproc.MetastoreService("test_resource", {
    serviceId: "test-service",
    location: "us-central1",
    databaseType: "SPANNER",
    hiveMetastoreConfig: {
        version: "3.1.2",
    },
    scalingConfig: {
        autoscalingConfig: {
            autoscalingEnabled: true,
            limitConfig: {
                maxScalingFactor: 1,
            },
        },
    },
});
```
```python
import pulumi
import pulumi_gcp as gcp

test_resource = gcp.dataproc.MetastoreService("test_resource",
    service_id="test-service",
    location="us-central1",
    database_type="SPANNER",
    hive_metastore_config={
        "version": "3.1.2",
    },
    scaling_config={
        "autoscaling_config": {
            "autoscaling_enabled": True,
            "limit_config": {
                "max_scaling_factor": 1,
            },
        },
    })
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var testResource = new Gcp.Dataproc.MetastoreService("test_resource", new()
    {
        ServiceId = "test-service",
        Location = "us-central1",
        DatabaseType = "SPANNER",
        HiveMetastoreConfig = new Gcp.Dataproc.Inputs.MetastoreServiceHiveMetastoreConfigArgs
        {
            Version = "3.1.2",
        },
        ScalingConfig = new Gcp.Dataproc.Inputs.MetastoreServiceScalingConfigArgs
        {
            AutoscalingConfig = new Gcp.Dataproc.Inputs.MetastoreServiceScalingConfigAutoscalingConfigArgs
            {
                AutoscalingEnabled = true,
                LimitConfig = new Gcp.Dataproc.Inputs.MetastoreServiceScalingConfigAutoscalingConfigLimitConfigArgs
                {
                    MaxScalingFactor = 1,
                },
            },
        },
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/dataproc"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		_, err := dataproc.NewMetastoreService(ctx, "test_resource", &dataproc.MetastoreServiceArgs{
			ServiceId:    pulumi.String("test-service"),
			Location:     pulumi.String("us-central1"),
			DatabaseType: pulumi.String("SPANNER"),
			HiveMetastoreConfig: &dataproc.MetastoreServiceHiveMetastoreConfigArgs{
				Version: pulumi.String("3.1.2"),
			},
			ScalingConfig: &dataproc.MetastoreServiceScalingConfigArgs{
				AutoscalingConfig: &dataproc.MetastoreServiceScalingConfigAutoscalingConfigArgs{
					AutoscalingEnabled: pulumi.Bool(true),
					LimitConfig: &dataproc.MetastoreServiceScalingConfigAutoscalingConfigLimitConfigArgs{
						MaxScalingFactor: pulumi.Float64(1),
					},
				},
			},
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.dataproc.MetastoreService;
import com.pulumi.gcp.dataproc.MetastoreServiceArgs;
import com.pulumi.gcp.dataproc.inputs.MetastoreServiceHiveMetastoreConfigArgs;
import com.pulumi.gcp.dataproc.inputs.MetastoreServiceScalingConfigArgs;
import com.pulumi.gcp.dataproc.inputs.MetastoreServiceScalingConfigAutoscalingConfigArgs;
import com.pulumi.gcp.dataproc.inputs.MetastoreServiceScalingConfigAutoscalingConfigLimitConfigArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        var testResource = new MetastoreService("testResource", MetastoreServiceArgs.builder()
            .serviceId("test-service")
            .location("us-central1")
            .databaseType("SPANNER")
            .hiveMetastoreConfig(MetastoreServiceHiveMetastoreConfigArgs.builder()
                .version("3.1.2")
                .build())
            .scalingConfig(MetastoreServiceScalingConfigArgs.builder()
                .autoscalingConfig(MetastoreServiceScalingConfigAutoscalingConfigArgs.builder()
                    .autoscalingEnabled(true)
                    .limitConfig(MetastoreServiceScalingConfigAutoscalingConfigLimitConfigArgs.builder()
                        .maxScalingFactor(1)
                        .build())
                    .build())
                .build())
            .build());

    }
}
```
```yaml
resources:
  testResource:
    type: gcp:dataproc:MetastoreService
    name: test_resource
    properties:
      serviceId: test-service
      location: us-central1
      databaseType: SPANNER
      hiveMetastoreConfig:
        version: 3.1.2
      scalingConfig:
        autoscalingConfig:
          autoscalingEnabled: true
          limitConfig:
            maxScalingFactor: 1
```
<!--End PulumiCodeChooser -->
### Dataproc Metastore Service Autoscaling Min And Max Scaling Factor


<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const testResource = new gcp.dataproc.MetastoreService("test_resource", {
    serviceId: "test-service",
    location: "us-central1",
    databaseType: "SPANNER",
    hiveMetastoreConfig: {
        version: "3.1.2",
    },
    scalingConfig: {
        autoscalingConfig: {
            autoscalingEnabled: true,
            limitConfig: {
                minScalingFactor: 0.1,
                maxScalingFactor: 1,
            },
        },
    },
});
```
```python
import pulumi
import pulumi_gcp as gcp

test_resource = gcp.dataproc.MetastoreService("test_resource",
    service_id="test-service",
    location="us-central1",
    database_type="SPANNER",
    hive_metastore_config={
        "version": "3.1.2",
    },
    scaling_config={
        "autoscaling_config": {
            "autoscaling_enabled": True,
            "limit_config": {
                "min_scaling_factor": 0.1,
                "max_scaling_factor": 1,
            },
        },
    })
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var testResource = new Gcp.Dataproc.MetastoreService("test_resource", new()
    {
        ServiceId = "test-service",
        Location = "us-central1",
        DatabaseType = "SPANNER",
        HiveMetastoreConfig = new Gcp.Dataproc.Inputs.MetastoreServiceHiveMetastoreConfigArgs
        {
            Version = "3.1.2",
        },
        ScalingConfig = new Gcp.Dataproc.Inputs.MetastoreServiceScalingConfigArgs
        {
            AutoscalingConfig = new Gcp.Dataproc.Inputs.MetastoreServiceScalingConfigAutoscalingConfigArgs
            {
                AutoscalingEnabled = true,
                LimitConfig = new Gcp.Dataproc.Inputs.MetastoreServiceScalingConfigAutoscalingConfigLimitConfigArgs
                {
                    MinScalingFactor = 0.1,
                    MaxScalingFactor = 1,
                },
            },
        },
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/dataproc"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		_, err := dataproc.NewMetastoreService(ctx, "test_resource", &dataproc.MetastoreServiceArgs{
			ServiceId:    pulumi.String("test-service"),
			Location:     pulumi.String("us-central1"),
			DatabaseType: pulumi.String("SPANNER"),
			HiveMetastoreConfig: &dataproc.MetastoreServiceHiveMetastoreConfigArgs{
				Version: pulumi.String("3.1.2"),
			},
			ScalingConfig: &dataproc.MetastoreServiceScalingConfigArgs{
				AutoscalingConfig: &dataproc.MetastoreServiceScalingConfigAutoscalingConfigArgs{
					AutoscalingEnabled: pulumi.Bool(true),
					LimitConfig: &dataproc.MetastoreServiceScalingConfigAutoscalingConfigLimitConfigArgs{
						MinScalingFactor: pulumi.Float64(0.1),
						MaxScalingFactor: pulumi.Float64(1),
					},
				},
			},
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.dataproc.MetastoreService;
import com.pulumi.gcp.dataproc.MetastoreServiceArgs;
import com.pulumi.gcp.dataproc.inputs.MetastoreServiceHiveMetastoreConfigArgs;
import com.pulumi.gcp.dataproc.inputs.MetastoreServiceScalingConfigArgs;
import com.pulumi.gcp.dataproc.inputs.MetastoreServiceScalingConfigAutoscalingConfigArgs;
import com.pulumi.gcp.dataproc.inputs.MetastoreServiceScalingConfigAutoscalingConfigLimitConfigArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        var testResource = new MetastoreService("testResource", MetastoreServiceArgs.builder()
            .serviceId("test-service")
            .location("us-central1")
            .databaseType("SPANNER")
            .hiveMetastoreConfig(MetastoreServiceHiveMetastoreConfigArgs.builder()
                .version("3.1.2")
                .build())
            .scalingConfig(MetastoreServiceScalingConfigArgs.builder()
                .autoscalingConfig(MetastoreServiceScalingConfigAutoscalingConfigArgs.builder()
                    .autoscalingEnabled(true)
                    .limitConfig(MetastoreServiceScalingConfigAutoscalingConfigLimitConfigArgs.builder()
                        .minScalingFactor(0.1)
                        .maxScalingFactor(1)
                        .build())
                    .build())
                .build())
            .build());

    }
}
```
```yaml
resources:
  testResource:
    type: gcp:dataproc:MetastoreService
    name: test_resource
    properties:
      serviceId: test-service
      location: us-central1
      databaseType: SPANNER
      hiveMetastoreConfig:
        version: 3.1.2
      scalingConfig:
        autoscalingConfig:
          autoscalingEnabled: true
          limitConfig:
            minScalingFactor: 0.1
            maxScalingFactor: 1
```
<!--End PulumiCodeChooser -->
### Dataproc Metastore Service Autoscaling Min Scaling Factor


<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const testResource = new gcp.dataproc.MetastoreService("test_resource", {
    serviceId: "test-service",
    location: "us-central1",
    databaseType: "SPANNER",
    hiveMetastoreConfig: {
        version: "3.1.2",
    },
    scalingConfig: {
        autoscalingConfig: {
            autoscalingEnabled: true,
            limitConfig: {
                minScalingFactor: 0.1,
            },
        },
    },
});
```
```python
import pulumi
import pulumi_gcp as gcp

test_resource = gcp.dataproc.MetastoreService("test_resource",
    service_id="test-service",
    location="us-central1",
    database_type="SPANNER",
    hive_metastore_config={
        "version": "3.1.2",
    },
    scaling_config={
        "autoscaling_config": {
            "autoscaling_enabled": True,
            "limit_config": {
                "min_scaling_factor": 0.1,
            },
        },
    })
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var testResource = new Gcp.Dataproc.MetastoreService("test_resource", new()
    {
        ServiceId = "test-service",
        Location = "us-central1",
        DatabaseType = "SPANNER",
        HiveMetastoreConfig = new Gcp.Dataproc.Inputs.MetastoreServiceHiveMetastoreConfigArgs
        {
            Version = "3.1.2",
        },
        ScalingConfig = new Gcp.Dataproc.Inputs.MetastoreServiceScalingConfigArgs
        {
            AutoscalingConfig = new Gcp.Dataproc.Inputs.MetastoreServiceScalingConfigAutoscalingConfigArgs
            {
                AutoscalingEnabled = true,
                LimitConfig = new Gcp.Dataproc.Inputs.MetastoreServiceScalingConfigAutoscalingConfigLimitConfigArgs
                {
                    MinScalingFactor = 0.1,
                },
            },
        },
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/dataproc"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		_, err := dataproc.NewMetastoreService(ctx, "test_resource", &dataproc.MetastoreServiceArgs{
			ServiceId:    pulumi.String("test-service"),
			Location:     pulumi.String("us-central1"),
			DatabaseType: pulumi.String("SPANNER"),
			HiveMetastoreConfig: &dataproc.MetastoreServiceHiveMetastoreConfigArgs{
				Version: pulumi.String("3.1.2"),
			},
			ScalingConfig: &dataproc.MetastoreServiceScalingConfigArgs{
				AutoscalingConfig: &dataproc.MetastoreServiceScalingConfigAutoscalingConfigArgs{
					AutoscalingEnabled: pulumi.Bool(true),
					LimitConfig: &dataproc.MetastoreServiceScalingConfigAutoscalingConfigLimitConfigArgs{
						MinScalingFactor: pulumi.Float64(0.1),
					},
				},
			},
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.dataproc.MetastoreService;
import com.pulumi.gcp.dataproc.MetastoreServiceArgs;
import com.pulumi.gcp.dataproc.inputs.MetastoreServiceHiveMetastoreConfigArgs;
import com.pulumi.gcp.dataproc.inputs.MetastoreServiceScalingConfigArgs;
import com.pulumi.gcp.dataproc.inputs.MetastoreServiceScalingConfigAutoscalingConfigArgs;
import com.pulumi.gcp.dataproc.inputs.MetastoreServiceScalingConfigAutoscalingConfigLimitConfigArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        var testResource = new MetastoreService("testResource", MetastoreServiceArgs.builder()
            .serviceId("test-service")
            .location("us-central1")
            .databaseType("SPANNER")
            .hiveMetastoreConfig(MetastoreServiceHiveMetastoreConfigArgs.builder()
                .version("3.1.2")
                .build())
            .scalingConfig(MetastoreServiceScalingConfigArgs.builder()
                .autoscalingConfig(MetastoreServiceScalingConfigAutoscalingConfigArgs.builder()
                    .autoscalingEnabled(true)
                    .limitConfig(MetastoreServiceScalingConfigAutoscalingConfigLimitConfigArgs.builder()
                        .minScalingFactor(0.1)
                        .build())
                    .build())
                .build())
            .build());

    }
}
```
```yaml
resources:
  testResource:
    type: gcp:dataproc:MetastoreService
    name: test_resource
    properties:
      serviceId: test-service
      location: us-central1
      databaseType: SPANNER
      hiveMetastoreConfig:
        version: 3.1.2
      scalingConfig:
        autoscalingConfig:
          autoscalingEnabled: true
          limitConfig:
            minScalingFactor: 0.1
```
<!--End PulumiCodeChooser -->
### Dataproc Metastore Service Autoscaling No Limit Config


<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const testResource = new gcp.dataproc.MetastoreService("test_resource", {
    serviceId: "test-service",
    location: "us-central1",
    databaseType: "SPANNER",
    hiveMetastoreConfig: {
        version: "3.1.2",
    },
    scalingConfig: {
        autoscalingConfig: {
            autoscalingEnabled: true,
        },
    },
});
```
```python
import pulumi
import pulumi_gcp as gcp

test_resource = gcp.dataproc.MetastoreService("test_resource",
    service_id="test-service",
    location="us-central1",
    database_type="SPANNER",
    hive_metastore_config={
        "version": "3.1.2",
    },
    scaling_config={
        "autoscaling_config": {
            "autoscaling_enabled": True,
        },
    })
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var testResource = new Gcp.Dataproc.MetastoreService("test_resource", new()
    {
        ServiceId = "test-service",
        Location = "us-central1",
        DatabaseType = "SPANNER",
        HiveMetastoreConfig = new Gcp.Dataproc.Inputs.MetastoreServiceHiveMetastoreConfigArgs
        {
            Version = "3.1.2",
        },
        ScalingConfig = new Gcp.Dataproc.Inputs.MetastoreServiceScalingConfigArgs
        {
            AutoscalingConfig = new Gcp.Dataproc.Inputs.MetastoreServiceScalingConfigAutoscalingConfigArgs
            {
                AutoscalingEnabled = true,
            },
        },
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/dataproc"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		_, err := dataproc.NewMetastoreService(ctx, "test_resource", &dataproc.MetastoreServiceArgs{
			ServiceId:    pulumi.String("test-service"),
			Location:     pulumi.String("us-central1"),
			DatabaseType: pulumi.String("SPANNER"),
			HiveMetastoreConfig: &dataproc.MetastoreServiceHiveMetastoreConfigArgs{
				Version: pulumi.String("3.1.2"),
			},
			ScalingConfig: &dataproc.MetastoreServiceScalingConfigArgs{
				AutoscalingConfig: &dataproc.MetastoreServiceScalingConfigAutoscalingConfigArgs{
					AutoscalingEnabled: pulumi.Bool(true),
				},
			},
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.dataproc.MetastoreService;
import com.pulumi.gcp.dataproc.MetastoreServiceArgs;
import com.pulumi.gcp.dataproc.inputs.MetastoreServiceHiveMetastoreConfigArgs;
import com.pulumi.gcp.dataproc.inputs.MetastoreServiceScalingConfigArgs;
import com.pulumi.gcp.dataproc.inputs.MetastoreServiceScalingConfigAutoscalingConfigArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        var testResource = new MetastoreService("testResource", MetastoreServiceArgs.builder()
            .serviceId("test-service")
            .location("us-central1")
            .databaseType("SPANNER")
            .hiveMetastoreConfig(MetastoreServiceHiveMetastoreConfigArgs.builder()
                .version("3.1.2")
                .build())
            .scalingConfig(MetastoreServiceScalingConfigArgs.builder()
                .autoscalingConfig(MetastoreServiceScalingConfigAutoscalingConfigArgs.builder()
                    .autoscalingEnabled(true)
                    .build())
                .build())
            .build());

    }
}
```
```yaml
resources:
  testResource:
    type: gcp:dataproc:MetastoreService
    name: test_resource
    properties:
      serviceId: test-service
      location: us-central1
      databaseType: SPANNER
      hiveMetastoreConfig:
        version: 3.1.2
      scalingConfig:
        autoscalingConfig:
          autoscalingEnabled: true
```
<!--End PulumiCodeChooser -->

## Import

Service can be imported using any of these accepted formats:

* `projects/{{project}}/locations/{{location}}/services/{{service_id}}`

* `{{project}}/{{location}}/{{service_id}}`

* `{{location}}/{{service_id}}`

When using the `pulumi import` command, Service can be imported using one of the formats above. For example:

```sh
$ pulumi import gcp:dataproc/metastoreService:MetastoreService default projects/{{project}}/locations/{{location}}/services/{{service_id}}
```

```sh
$ pulumi import gcp:dataproc/metastoreService:MetastoreService default {{project}}/{{location}}/{{service_id}}
```

```sh
$ pulumi import gcp:dataproc/metastoreService:MetastoreService default {{location}}/{{service_id}}
```


databaseTypeB" The database type that the Metastore service stores its data.
Default value is `MYSQL`.
Possible values are: `MYSQL`, `SPANNER`.
r
deletionProtectionB
 VIndicates if the dataproc metastore should be protected against accidental deletions.

encryptionConfigB:~
|
dataproc MetastoreServiceEncryptionConfigNgcp:dataproc/MetastoreServiceEncryptionConfig:MetastoreServiceEncryptionConfig~Information used to configure the Dataproc Metastore service to encrypt
customer data at rest.
Structure is documented below.
§
hiveMetastoreConfigB:

dataproc#MetastoreServiceHiveMetastoreConfigTgcp:dataproc/MetastoreServiceHiveMetastoreConfig:MetastoreServiceHiveMetastoreConfigConfiguration information specific to running Hive metastore software as the metastore service.
Structure is documented below.

labelsB2" õUser-defined labels for the metastore service.
**Note**: This field is non-authoritative, and will only manage the labels present in your configuration.
Please refer to the field `effective_labels` for all of the labels present on the resource.
i
locationB" WThe location where the metastore service should reside.
The default value is `global`.
 
maintenanceWindowB:

dataproc!MetastoreServiceMaintenanceWindowPgcp:dataproc/MetastoreServiceMaintenanceWindow:MetastoreServiceMaintenanceWindowThe one hour maintenance window of the metastore service.
This specifies when the service can be restarted for maintenance purposes in UTC time.
Maintenance window is not needed for services with the `SPANNER` database type.
Structure is documented below.
±
metadataIntegrationB:

dataproc#MetastoreServiceMetadataIntegrationTgcp:dataproc/MetastoreServiceMetadataIntegration:MetastoreServiceMetadataIntegrationThe setting that defines how metastore metadata should be integrated with external services and systems.
Structure is documented below.
Ç
networkB" µThe relative resource name of the VPC network on which the instance can be accessed. It is specified in the following form:
"projects/{projectNumber}/global/networks/{network_id}".

networkConfigyBw:u
s
dataprocMetastoreServiceNetworkConfigHgcp:dataproc/MetastoreServiceNetworkConfig:MetastoreServiceNetworkConfiguThe configuration specifying the network settings for the Dataproc Metastore service.
Structure is documented below.
U
portB GThe TCP port at which the metastore service is reached. Default: 9083.
{
projectB" jThe ID of the project in which the resource belongs.
If it is not provided, the provider project is used.
§
releaseChannelB" The release channel of the service. If unspecified, defaults to `STABLE`.
Default value is `STABLE`.
Possible values are: `CANARY`, `STABLE`.
è
scalingConfigyBw:u
s
dataprocMetastoreServiceScalingConfigHgcp:dataproc/MetastoreServiceScalingConfig:MetastoreServiceScalingConfig\Represents the scaling configuration of a metastore service.
Structure is documented below.
ô
scheduledBackupB}:{
y
dataprocMetastoreServiceScheduledBackupLgcp:dataproc/MetastoreServiceScheduledBackup:MetastoreServiceScheduledBackup`The configuration of scheduled backup for the metastore service.
Structure is documented below.
õ
	serviceId" ãThe ID of the metastore service. The id must contain only letters (a-z, A-Z), numbers (0-9), underscores (_),
and hyphens (-). Cannot begin or end with underscore or hyphen. Must consist of between
3 and 63 characters.


- - -
©
telemetryConfigB}:{
y
dataprocMetastoreServiceTelemetryConfigLgcp:dataproc/MetastoreServiceTelemetryConfig:MetastoreServiceTelemetryConfigThe configuration specifying telemetry settings for the Dataproc Metastore service. If unspecified defaults to JSON.
Structure is documented below.
W
tierB" IThe tier of the service.
Possible values are: `DEVELOPER`, `ENTERPRISE`.
"
artifactGcsUri" vA Cloud Storage URI (starting with gs://) that specifies where artifacts related to the metastore service are stored.
"
databaseTypeB" The database type that the Metastore service stores its data.
Default value is `MYSQL`.
Possible values are: `MYSQL`, `SPANNER`.
"r
deletionProtectionB
 VIndicates if the dataproc metastore should be protected against accidental deletions.
"¦
effectiveLabels2" All of labels (key/value pairs) present on the resource in GCP, including the labels configured through Pulumi, other clients and services.
"
encryptionConfigB:~
|
dataproc MetastoreServiceEncryptionConfigNgcp:dataproc/MetastoreServiceEncryptionConfig:MetastoreServiceEncryptionConfig~Information used to configure the Dataproc Metastore service to encrypt
customer data at rest.
Structure is documented below.
"Q
endpointUri" >The URI of the endpoint used to access the metastore service.
"§
hiveMetastoreConfigB:

dataproc#MetastoreServiceHiveMetastoreConfigTgcp:dataproc/MetastoreServiceHiveMetastoreConfig:MetastoreServiceHiveMetastoreConfigConfiguration information specific to running Hive metastore software as the metastore service.
Structure is documented below.
"
labelsB2" õUser-defined labels for the metastore service.
**Note**: This field is non-authoritative, and will only manage the labels present in your configuration.
Please refer to the field `effective_labels` for all of the labels present on the resource.
"i
locationB" WThe location where the metastore service should reside.
The default value is `global`.
" 
maintenanceWindowB:

dataproc!MetastoreServiceMaintenanceWindowPgcp:dataproc/MetastoreServiceMaintenanceWindow:MetastoreServiceMaintenanceWindowThe one hour maintenance window of the metastore service.
This specifies when the service can be restarted for maintenance purposes in UTC time.
Maintenance window is not needed for services with the `SPANNER` database type.
Structure is documented below.
"±
metadataIntegrationB:

dataproc#MetastoreServiceMetadataIntegrationTgcp:dataproc/MetastoreServiceMetadataIntegration:MetastoreServiceMetadataIntegrationThe setting that defines how metastore metadata should be integrated with external services and systems.
Structure is documented below.
"A
name" 5The relative resource name of the metastore service.
"Å
network" µThe relative resource name of the VPC network on which the instance can be accessed. It is specified in the following form:
"projects/{projectNumber}/global/networks/{network_id}".
"
networkConfigyBw:u
s
dataprocMetastoreServiceNetworkConfigHgcp:dataproc/MetastoreServiceNetworkConfig:MetastoreServiceNetworkConfiguThe configuration specifying the network settings for the Dataproc Metastore service.
Structure is documented below.
"S
port GThe TCP port at which the metastore service is reached. Default: 9083.
"y
project" jThe ID of the project in which the resource belongs.
If it is not provided, the provider project is used.
"
pulumiLabels2" mThe combination of labels configured directly on the resource
and default labels configured on the provider.
"§
releaseChannelB" The release channel of the service. If unspecified, defaults to `STABLE`.
Default value is `STABLE`.
Possible values are: `CANARY`, `STABLE`.
"è
scalingConfigyBw:u
s
dataprocMetastoreServiceScalingConfigHgcp:dataproc/MetastoreServiceScalingConfig:MetastoreServiceScalingConfig\Represents the scaling configuration of a metastore service.
Structure is documented below.
"ô
scheduledBackupB}:{
y
dataprocMetastoreServiceScheduledBackupLgcp:dataproc/MetastoreServiceScheduledBackup:MetastoreServiceScheduledBackup`The configuration of scheduled backup for the metastore service.
Structure is documented below.
"õ
	serviceId" ãThe ID of the metastore service. The id must contain only letters (a-z, A-Z), numbers (0-9), underscores (_),
and hyphens (-). Cannot begin or end with underscore or hyphen. Must consist of between
3 and 63 characters.


- - -
"9
state" ,The current state of the metastore service.
"k
stateMessage" WAdditional information about the current state of the metastore service, if available.
"§
telemetryConfig}:{
y
dataprocMetastoreServiceTelemetryConfigLgcp:dataproc/MetastoreServiceTelemetryConfig:MetastoreServiceTelemetryConfigThe configuration specifying telemetry settings for the Dataproc Metastore service. If unspecified defaults to JSON.
Structure is documented below.
"U
tier" IThe tier of the service.
Possible values are: `DEVELOPER`, `ENTERPRISE`.
"M
uid" BThe globally unique resource identifier of the metastore service.
*¡ç
j
dataprocMetastoreServiceIamBindingBgcp:dataproc/metastoreServiceIamBinding:MetastoreServiceIamBindingþÁThree different resources help you manage your IAM policy for Dataproc metastore Service. Each of these resources serves a different use case:

* `gcp.dataproc.MetastoreServiceIamPolicy`: Authoritative. Sets the IAM policy for the service and replaces any existing policy already attached.
* `gcp.dataproc.MetastoreServiceIamBinding`: Authoritative for a given role. Updates the IAM policy to grant a role to a list of members. Other roles within the IAM policy for the service are preserved.
* `gcp.dataproc.MetastoreServiceIamMember`: Non-authoritative. Updates the IAM policy to grant a role to a new member. Other members for the role for the service are preserved.

A data source can be used to retrieve policy data in advent you do not need creation

* `gcp.dataproc.MetastoreServiceIamPolicy`: Retrieves the IAM policy for the service

> **Note:** `gcp.dataproc.MetastoreServiceIamPolicy` **cannot** be used in conjunction with `gcp.dataproc.MetastoreServiceIamBinding` and `gcp.dataproc.MetastoreServiceIamMember` or they will fight over what your policy should be.

> **Note:** `gcp.dataproc.MetastoreServiceIamBinding` resources **can be** used in conjunction with `gcp.dataproc.MetastoreServiceIamMember` resources **only if** they do not grant privilege to the same role.



## gcp.dataproc.MetastoreServiceIamPolicy

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const admin = gcp.organizations.getIAMPolicy({
    bindings: [{
        role: "roles/viewer",
        members: ["user:jane@example.com"],
    }],
});
const policy = new gcp.dataproc.MetastoreServiceIamPolicy("policy", {
    project: _default.project,
    location: _default.location,
    serviceId: _default.serviceId,
    policyData: admin.then(admin => admin.policyData),
});
```
```python
import pulumi
import pulumi_gcp as gcp

admin = gcp.organizations.get_iam_policy(bindings=[{
    "role": "roles/viewer",
    "members": ["user:jane@example.com"],
}])
policy = gcp.dataproc.MetastoreServiceIamPolicy("policy",
    project=default["project"],
    location=default["location"],
    service_id=default["serviceId"],
    policy_data=admin.policy_data)
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var admin = Gcp.Organizations.GetIAMPolicy.Invoke(new()
    {
        Bindings = new[]
        {
            new Gcp.Organizations.Inputs.GetIAMPolicyBindingInputArgs
            {
                Role = "roles/viewer",
                Members = new[]
                {
                    "user:jane@example.com",
                },
            },
        },
    });

    var policy = new Gcp.Dataproc.MetastoreServiceIamPolicy("policy", new()
    {
        Project = @default.Project,
        Location = @default.Location,
        ServiceId = @default.ServiceId,
        PolicyData = admin.Apply(getIAMPolicyResult => getIAMPolicyResult.PolicyData),
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/dataproc"
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/organizations"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		admin, err := organizations.LookupIAMPolicy(ctx, &organizations.LookupIAMPolicyArgs{
			Bindings: []organizations.GetIAMPolicyBinding{
				{
					Role: "roles/viewer",
					Members: []string{
						"user:jane@example.com",
					},
				},
			},
		}, nil)
		if err != nil {
			return err
		}
		_, err = dataproc.NewMetastoreServiceIamPolicy(ctx, "policy", &dataproc.MetastoreServiceIamPolicyArgs{
			Project:    pulumi.Any(_default.Project),
			Location:   pulumi.Any(_default.Location),
			ServiceId:  pulumi.Any(_default.ServiceId),
			PolicyData: pulumi.String(admin.PolicyData),
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.organizations.OrganizationsFunctions;
import com.pulumi.gcp.organizations.inputs.GetIAMPolicyArgs;
import com.pulumi.gcp.dataproc.MetastoreServiceIamPolicy;
import com.pulumi.gcp.dataproc.MetastoreServiceIamPolicyArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        final var admin = OrganizationsFunctions.getIAMPolicy(GetIAMPolicyArgs.builder()
            .bindings(GetIAMPolicyBindingArgs.builder()
                .role("roles/viewer")
                .members("user:jane@example.com")
                .build())
            .build());

        var policy = new MetastoreServiceIamPolicy("policy", MetastoreServiceIamPolicyArgs.builder()
            .project(default_.project())
            .location(default_.location())
            .serviceId(default_.serviceId())
            .policyData(admin.applyValue(getIAMPolicyResult -> getIAMPolicyResult.policyData()))
            .build());

    }
}
```
```yaml
resources:
  policy:
    type: gcp:dataproc:MetastoreServiceIamPolicy
    properties:
      project: ${default.project}
      location: ${default.location}
      serviceId: ${default.serviceId}
      policyData: ${admin.policyData}
variables:
  admin:
    fn::invoke:
      function: gcp:organizations:getIAMPolicy
      arguments:
        bindings:
          - role: roles/viewer
            members:
              - user:jane@example.com
```
<!--End PulumiCodeChooser -->

## gcp.dataproc.MetastoreServiceIamBinding

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const binding = new gcp.dataproc.MetastoreServiceIamBinding("binding", {
    project: _default.project,
    location: _default.location,
    serviceId: _default.serviceId,
    role: "roles/viewer",
    members: ["user:jane@example.com"],
});
```
```python
import pulumi
import pulumi_gcp as gcp

binding = gcp.dataproc.MetastoreServiceIamBinding("binding",
    project=default["project"],
    location=default["location"],
    service_id=default["serviceId"],
    role="roles/viewer",
    members=["user:jane@example.com"])
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var binding = new Gcp.Dataproc.MetastoreServiceIamBinding("binding", new()
    {
        Project = @default.Project,
        Location = @default.Location,
        ServiceId = @default.ServiceId,
        Role = "roles/viewer",
        Members = new[]
        {
            "user:jane@example.com",
        },
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/dataproc"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		_, err := dataproc.NewMetastoreServiceIamBinding(ctx, "binding", &dataproc.MetastoreServiceIamBindingArgs{
			Project:   pulumi.Any(_default.Project),
			Location:  pulumi.Any(_default.Location),
			ServiceId: pulumi.Any(_default.ServiceId),
			Role:      pulumi.String("roles/viewer"),
			Members: pulumi.StringArray{
				pulumi.String("user:jane@example.com"),
			},
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.dataproc.MetastoreServiceIamBinding;
import com.pulumi.gcp.dataproc.MetastoreServiceIamBindingArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        var binding = new MetastoreServiceIamBinding("binding", MetastoreServiceIamBindingArgs.builder()
            .project(default_.project())
            .location(default_.location())
            .serviceId(default_.serviceId())
            .role("roles/viewer")
            .members("user:jane@example.com")
            .build());

    }
}
```
```yaml
resources:
  binding:
    type: gcp:dataproc:MetastoreServiceIamBinding
    properties:
      project: ${default.project}
      location: ${default.location}
      serviceId: ${default.serviceId}
      role: roles/viewer
      members:
        - user:jane@example.com
```
<!--End PulumiCodeChooser -->

## gcp.dataproc.MetastoreServiceIamMember

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const member = new gcp.dataproc.MetastoreServiceIamMember("member", {
    project: _default.project,
    location: _default.location,
    serviceId: _default.serviceId,
    role: "roles/viewer",
    member: "user:jane@example.com",
});
```
```python
import pulumi
import pulumi_gcp as gcp

member = gcp.dataproc.MetastoreServiceIamMember("member",
    project=default["project"],
    location=default["location"],
    service_id=default["serviceId"],
    role="roles/viewer",
    member="user:jane@example.com")
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var member = new Gcp.Dataproc.MetastoreServiceIamMember("member", new()
    {
        Project = @default.Project,
        Location = @default.Location,
        ServiceId = @default.ServiceId,
        Role = "roles/viewer",
        Member = "user:jane@example.com",
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/dataproc"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		_, err := dataproc.NewMetastoreServiceIamMember(ctx, "member", &dataproc.MetastoreServiceIamMemberArgs{
			Project:   pulumi.Any(_default.Project),
			Location:  pulumi.Any(_default.Location),
			ServiceId: pulumi.Any(_default.ServiceId),
			Role:      pulumi.String("roles/viewer"),
			Member:    pulumi.String("user:jane@example.com"),
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.dataproc.MetastoreServiceIamMember;
import com.pulumi.gcp.dataproc.MetastoreServiceIamMemberArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        var member = new MetastoreServiceIamMember("member", MetastoreServiceIamMemberArgs.builder()
            .project(default_.project())
            .location(default_.location())
            .serviceId(default_.serviceId())
            .role("roles/viewer")
            .member("user:jane@example.com")
            .build());

    }
}
```
```yaml
resources:
  member:
    type: gcp:dataproc:MetastoreServiceIamMember
    properties:
      project: ${default.project}
      location: ${default.location}
      serviceId: ${default.serviceId}
      role: roles/viewer
      member: user:jane@example.com
```
<!--End PulumiCodeChooser -->


## This resource supports User Project Overrides.

-

# IAM policy for Dataproc metastore Service
Three different resources help you manage your IAM policy for Dataproc metastore Service. Each of these resources serves a different use case:

* `gcp.dataproc.MetastoreServiceIamPolicy`: Authoritative. Sets the IAM policy for the service and replaces any existing policy already attached.
* `gcp.dataproc.MetastoreServiceIamBinding`: Authoritative for a given role. Updates the IAM policy to grant a role to a list of members. Other roles within the IAM policy for the service are preserved.
* `gcp.dataproc.MetastoreServiceIamMember`: Non-authoritative. Updates the IAM policy to grant a role to a new member. Other members for the role for the service are preserved.

A data source can be used to retrieve policy data in advent you do not need creation

* `gcp.dataproc.MetastoreServiceIamPolicy`: Retrieves the IAM policy for the service

> **Note:** `gcp.dataproc.MetastoreServiceIamPolicy` **cannot** be used in conjunction with `gcp.dataproc.MetastoreServiceIamBinding` and `gcp.dataproc.MetastoreServiceIamMember` or they will fight over what your policy should be.

> **Note:** `gcp.dataproc.MetastoreServiceIamBinding` resources **can be** used in conjunction with `gcp.dataproc.MetastoreServiceIamMember` resources **only if** they do not grant privilege to the same role.



## gcp.dataproc.MetastoreServiceIamPolicy

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const admin = gcp.organizations.getIAMPolicy({
    bindings: [{
        role: "roles/viewer",
        members: ["user:jane@example.com"],
    }],
});
const policy = new gcp.dataproc.MetastoreServiceIamPolicy("policy", {
    project: _default.project,
    location: _default.location,
    serviceId: _default.serviceId,
    policyData: admin.then(admin => admin.policyData),
});
```
```python
import pulumi
import pulumi_gcp as gcp

admin = gcp.organizations.get_iam_policy(bindings=[{
    "role": "roles/viewer",
    "members": ["user:jane@example.com"],
}])
policy = gcp.dataproc.MetastoreServiceIamPolicy("policy",
    project=default["project"],
    location=default["location"],
    service_id=default["serviceId"],
    policy_data=admin.policy_data)
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var admin = Gcp.Organizations.GetIAMPolicy.Invoke(new()
    {
        Bindings = new[]
        {
            new Gcp.Organizations.Inputs.GetIAMPolicyBindingInputArgs
            {
                Role = "roles/viewer",
                Members = new[]
                {
                    "user:jane@example.com",
                },
            },
        },
    });

    var policy = new Gcp.Dataproc.MetastoreServiceIamPolicy("policy", new()
    {
        Project = @default.Project,
        Location = @default.Location,
        ServiceId = @default.ServiceId,
        PolicyData = admin.Apply(getIAMPolicyResult => getIAMPolicyResult.PolicyData),
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/dataproc"
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/organizations"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		admin, err := organizations.LookupIAMPolicy(ctx, &organizations.LookupIAMPolicyArgs{
			Bindings: []organizations.GetIAMPolicyBinding{
				{
					Role: "roles/viewer",
					Members: []string{
						"user:jane@example.com",
					},
				},
			},
		}, nil)
		if err != nil {
			return err
		}
		_, err = dataproc.NewMetastoreServiceIamPolicy(ctx, "policy", &dataproc.MetastoreServiceIamPolicyArgs{
			Project:    pulumi.Any(_default.Project),
			Location:   pulumi.Any(_default.Location),
			ServiceId:  pulumi.Any(_default.ServiceId),
			PolicyData: pulumi.String(admin.PolicyData),
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.organizations.OrganizationsFunctions;
import com.pulumi.gcp.organizations.inputs.GetIAMPolicyArgs;
import com.pulumi.gcp.dataproc.MetastoreServiceIamPolicy;
import com.pulumi.gcp.dataproc.MetastoreServiceIamPolicyArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        final var admin = OrganizationsFunctions.getIAMPolicy(GetIAMPolicyArgs.builder()
            .bindings(GetIAMPolicyBindingArgs.builder()
                .role("roles/viewer")
                .members("user:jane@example.com")
                .build())
            .build());

        var policy = new MetastoreServiceIamPolicy("policy", MetastoreServiceIamPolicyArgs.builder()
            .project(default_.project())
            .location(default_.location())
            .serviceId(default_.serviceId())
            .policyData(admin.applyValue(getIAMPolicyResult -> getIAMPolicyResult.policyData()))
            .build());

    }
}
```
```yaml
resources:
  policy:
    type: gcp:dataproc:MetastoreServiceIamPolicy
    properties:
      project: ${default.project}
      location: ${default.location}
      serviceId: ${default.serviceId}
      policyData: ${admin.policyData}
variables:
  admin:
    fn::invoke:
      function: gcp:organizations:getIAMPolicy
      arguments:
        bindings:
          - role: roles/viewer
            members:
              - user:jane@example.com
```
<!--End PulumiCodeChooser -->

## gcp.dataproc.MetastoreServiceIamBinding

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const binding = new gcp.dataproc.MetastoreServiceIamBinding("binding", {
    project: _default.project,
    location: _default.location,
    serviceId: _default.serviceId,
    role: "roles/viewer",
    members: ["user:jane@example.com"],
});
```
```python
import pulumi
import pulumi_gcp as gcp

binding = gcp.dataproc.MetastoreServiceIamBinding("binding",
    project=default["project"],
    location=default["location"],
    service_id=default["serviceId"],
    role="roles/viewer",
    members=["user:jane@example.com"])
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var binding = new Gcp.Dataproc.MetastoreServiceIamBinding("binding", new()
    {
        Project = @default.Project,
        Location = @default.Location,
        ServiceId = @default.ServiceId,
        Role = "roles/viewer",
        Members = new[]
        {
            "user:jane@example.com",
        },
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/dataproc"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		_, err := dataproc.NewMetastoreServiceIamBinding(ctx, "binding", &dataproc.MetastoreServiceIamBindingArgs{
			Project:   pulumi.Any(_default.Project),
			Location:  pulumi.Any(_default.Location),
			ServiceId: pulumi.Any(_default.ServiceId),
			Role:      pulumi.String("roles/viewer"),
			Members: pulumi.StringArray{
				pulumi.String("user:jane@example.com"),
			},
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.dataproc.MetastoreServiceIamBinding;
import com.pulumi.gcp.dataproc.MetastoreServiceIamBindingArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        var binding = new MetastoreServiceIamBinding("binding", MetastoreServiceIamBindingArgs.builder()
            .project(default_.project())
            .location(default_.location())
            .serviceId(default_.serviceId())
            .role("roles/viewer")
            .members("user:jane@example.com")
            .build());

    }
}
```
```yaml
resources:
  binding:
    type: gcp:dataproc:MetastoreServiceIamBinding
    properties:
      project: ${default.project}
      location: ${default.location}
      serviceId: ${default.serviceId}
      role: roles/viewer
      members:
        - user:jane@example.com
```
<!--End PulumiCodeChooser -->

## gcp.dataproc.MetastoreServiceIamMember

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const member = new gcp.dataproc.MetastoreServiceIamMember("member", {
    project: _default.project,
    location: _default.location,
    serviceId: _default.serviceId,
    role: "roles/viewer",
    member: "user:jane@example.com",
});
```
```python
import pulumi
import pulumi_gcp as gcp

member = gcp.dataproc.MetastoreServiceIamMember("member",
    project=default["project"],
    location=default["location"],
    service_id=default["serviceId"],
    role="roles/viewer",
    member="user:jane@example.com")
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var member = new Gcp.Dataproc.MetastoreServiceIamMember("member", new()
    {
        Project = @default.Project,
        Location = @default.Location,
        ServiceId = @default.ServiceId,
        Role = "roles/viewer",
        Member = "user:jane@example.com",
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/dataproc"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		_, err := dataproc.NewMetastoreServiceIamMember(ctx, "member", &dataproc.MetastoreServiceIamMemberArgs{
			Project:   pulumi.Any(_default.Project),
			Location:  pulumi.Any(_default.Location),
			ServiceId: pulumi.Any(_default.ServiceId),
			Role:      pulumi.String("roles/viewer"),
			Member:    pulumi.String("user:jane@example.com"),
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.dataproc.MetastoreServiceIamMember;
import com.pulumi.gcp.dataproc.MetastoreServiceIamMemberArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        var member = new MetastoreServiceIamMember("member", MetastoreServiceIamMemberArgs.builder()
            .project(default_.project())
            .location(default_.location())
            .serviceId(default_.serviceId())
            .role("roles/viewer")
            .member("user:jane@example.com")
            .build());

    }
}
```
```yaml
resources:
  member:
    type: gcp:dataproc:MetastoreServiceIamMember
    properties:
      project: ${default.project}
      location: ${default.location}
      serviceId: ${default.serviceId}
      role: roles/viewer
      member: user:jane@example.com
```
<!--End PulumiCodeChooser -->

## Import

For all import syntaxes, the "resource in question" can take any of the following forms:

* projects/{{project}}/locations/{{location}}/services/{{service_id}}

* {{project}}/{{location}}/{{service_id}}

* {{location}}/{{service_id}}

* {{service_id}}

Any variables not passed in the import command will be taken from the provider configuration.

Dataproc metastore service IAM resources can be imported using the resource identifiers, role, and member.

IAM member imports use space-delimited identifiers: the resource in question, the role, and the member identity, e.g.

```sh
$ pulumi import gcp:dataproc/metastoreServiceIamBinding:MetastoreServiceIamBinding editor "projects/{{project}}/locations/{{location}}/services/{{service_id}} roles/viewer user:jane@example.com"
```

IAM binding imports use space-delimited identifiers: the resource in question and the role, e.g.

```sh
$ pulumi import gcp:dataproc/metastoreServiceIamBinding:MetastoreServiceIamBinding editor "projects/{{project}}/locations/{{location}}/services/{{service_id}} roles/viewer"
```

IAM policy imports use the identifier of the resource in question, e.g.

```sh
$ pulumi import gcp:dataproc/metastoreServiceIamBinding:MetastoreServiceIamBinding editor projects/{{project}}/locations/{{location}}/services/{{service_id}}
```

-> **Custom Roles** If you're importing a IAM resource with a custom role, make sure to use the

 full name of the custom role, e.g. `[projects/my-project|organizations/my-org]/roles/my-custom-role`.


	conditionB:

dataproc#MetastoreServiceIamBindingConditionTgcp:dataproc/MetastoreServiceIamBindingCondition:MetastoreServiceIamBindingConditionü
locationB" éThe location where the metastore service should reside.
The default value is `global`.
Used to find the parent resource to bind the IAM policy to. If not specified,
the value will be parsed from the identifier of the parent resource. If no location is provided in the parent identifier and no
location is specified, it is taken from the provider configuration.
Ö	
members*" Ä	Identities that will be granted the privilege in `role`.
Each entry can have one of the following values:
* **allUsers**: A special identifier that represents anyone who is on the internet; with or without a Google account.
* **allAuthenticatedUsers**: A special identifier that represents anyone who is authenticated with a Google account or a service account.
* **user:{emailid}**: An email address that represents a specific Google account. For example, alice@gmail.com or joe@example.com.
* **serviceAccount:{emailid}**: An email address that represents a service account. For example, my-other-app@appspot.gserviceaccount.com.
* **group:{emailid}**: An email address that represents a Google group. For example, admins@example.com.
* **domain:{domain}**: A G Suite domain (primary, instead of alias) name that represents all the users of that domain. For example, google.com or example.com.
* **projectOwner:projectid**: Owners of the given project. For example, "projectOwner:my-example-project"
* **projectEditor:projectid**: Editors of the given project. For example, "projectEditor:my-example-project"
* **projectViewer:projectid**: Viewers of the given project. For example, "projectViewer:my-example-project"

projectB" The ID of the project in which the resource belongs.
If it is not provided, the project will be parsed from the identifier of the parent resource. If no project is provided in the parent identifier and no project is specified, the provider project is used.
à
role" ÓThe role that should be applied. Only one
`gcp.dataproc.MetastoreServiceIamBinding` can be used per role. Note that custom roles must be of the format
`[projects|organizations]/{parent-name}/roles/{role-name}`.

	serviceId" "
	conditionB:

dataproc#MetastoreServiceIamBindingConditionTgcp:dataproc/MetastoreServiceIamBindingCondition:MetastoreServiceIamBindingCondition"3
etag" '(Computed) The etag of the IAM policy.
"ú
location" éThe location where the metastore service should reside.
The default value is `global`.
Used to find the parent resource to bind the IAM policy to. If not specified,
the value will be parsed from the identifier of the parent resource. If no location is provided in the parent identifier and no
location is specified, it is taken from the provider configuration.
"Ö	
members*" Ä	Identities that will be granted the privilege in `role`.
Each entry can have one of the following values:
* **allUsers**: A special identifier that represents anyone who is on the internet; with or without a Google account.
* **allAuthenticatedUsers**: A special identifier that represents anyone who is authenticated with a Google account or a service account.
* **user:{emailid}**: An email address that represents a specific Google account. For example, alice@gmail.com or joe@example.com.
* **serviceAccount:{emailid}**: An email address that represents a service account. For example, my-other-app@appspot.gserviceaccount.com.
* **group:{emailid}**: An email address that represents a Google group. For example, admins@example.com.
* **domain:{domain}**: A G Suite domain (primary, instead of alias) name that represents all the users of that domain. For example, google.com or example.com.
* **projectOwner:projectid**: Owners of the given project. For example, "projectOwner:my-example-project"
* **projectEditor:projectid**: Editors of the given project. For example, "projectEditor:my-example-project"
* **projectViewer:projectid**: Viewers of the given project. For example, "projectViewer:my-example-project"
"
project" The ID of the project in which the resource belongs.
If it is not provided, the project will be parsed from the identifier of the parent resource. If no project is provided in the parent identifier and no project is specified, the provider project is used.
"à
role" ÓThe role that should be applied. Only one
`gcp.dataproc.MetastoreServiceIamBinding` can be used per role. Note that custom roles must be of the format
`[projects|organizations]/{parent-name}/roles/{role-name}`.
"
	serviceId" *ç
g
dataprocMetastoreServiceIamMember@gcp:dataproc/metastoreServiceIamMember:MetastoreServiceIamMemberøÁThree different resources help you manage your IAM policy for Dataproc metastore Service. Each of these resources serves a different use case:

* `gcp.dataproc.MetastoreServiceIamPolicy`: Authoritative. Sets the IAM policy for the service and replaces any existing policy already attached.
* `gcp.dataproc.MetastoreServiceIamBinding`: Authoritative for a given role. Updates the IAM policy to grant a role to a list of members. Other roles within the IAM policy for the service are preserved.
* `gcp.dataproc.MetastoreServiceIamMember`: Non-authoritative. Updates the IAM policy to grant a role to a new member. Other members for the role for the service are preserved.

A data source can be used to retrieve policy data in advent you do not need creation

* `gcp.dataproc.MetastoreServiceIamPolicy`: Retrieves the IAM policy for the service

> **Note:** `gcp.dataproc.MetastoreServiceIamPolicy` **cannot** be used in conjunction with `gcp.dataproc.MetastoreServiceIamBinding` and `gcp.dataproc.MetastoreServiceIamMember` or they will fight over what your policy should be.

> **Note:** `gcp.dataproc.MetastoreServiceIamBinding` resources **can be** used in conjunction with `gcp.dataproc.MetastoreServiceIamMember` resources **only if** they do not grant privilege to the same role.



## gcp.dataproc.MetastoreServiceIamPolicy

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const admin = gcp.organizations.getIAMPolicy({
    bindings: [{
        role: "roles/viewer",
        members: ["user:jane@example.com"],
    }],
});
const policy = new gcp.dataproc.MetastoreServiceIamPolicy("policy", {
    project: _default.project,
    location: _default.location,
    serviceId: _default.serviceId,
    policyData: admin.then(admin => admin.policyData),
});
```
```python
import pulumi
import pulumi_gcp as gcp

admin = gcp.organizations.get_iam_policy(bindings=[{
    "role": "roles/viewer",
    "members": ["user:jane@example.com"],
}])
policy = gcp.dataproc.MetastoreServiceIamPolicy("policy",
    project=default["project"],
    location=default["location"],
    service_id=default["serviceId"],
    policy_data=admin.policy_data)
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var admin = Gcp.Organizations.GetIAMPolicy.Invoke(new()
    {
        Bindings = new[]
        {
            new Gcp.Organizations.Inputs.GetIAMPolicyBindingInputArgs
            {
                Role = "roles/viewer",
                Members = new[]
                {
                    "user:jane@example.com",
                },
            },
        },
    });

    var policy = new Gcp.Dataproc.MetastoreServiceIamPolicy("policy", new()
    {
        Project = @default.Project,
        Location = @default.Location,
        ServiceId = @default.ServiceId,
        PolicyData = admin.Apply(getIAMPolicyResult => getIAMPolicyResult.PolicyData),
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/dataproc"
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/organizations"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		admin, err := organizations.LookupIAMPolicy(ctx, &organizations.LookupIAMPolicyArgs{
			Bindings: []organizations.GetIAMPolicyBinding{
				{
					Role: "roles/viewer",
					Members: []string{
						"user:jane@example.com",
					},
				},
			},
		}, nil)
		if err != nil {
			return err
		}
		_, err = dataproc.NewMetastoreServiceIamPolicy(ctx, "policy", &dataproc.MetastoreServiceIamPolicyArgs{
			Project:    pulumi.Any(_default.Project),
			Location:   pulumi.Any(_default.Location),
			ServiceId:  pulumi.Any(_default.ServiceId),
			PolicyData: pulumi.String(admin.PolicyData),
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.organizations.OrganizationsFunctions;
import com.pulumi.gcp.organizations.inputs.GetIAMPolicyArgs;
import com.pulumi.gcp.dataproc.MetastoreServiceIamPolicy;
import com.pulumi.gcp.dataproc.MetastoreServiceIamPolicyArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        final var admin = OrganizationsFunctions.getIAMPolicy(GetIAMPolicyArgs.builder()
            .bindings(GetIAMPolicyBindingArgs.builder()
                .role("roles/viewer")
                .members("user:jane@example.com")
                .build())
            .build());

        var policy = new MetastoreServiceIamPolicy("policy", MetastoreServiceIamPolicyArgs.builder()
            .project(default_.project())
            .location(default_.location())
            .serviceId(default_.serviceId())
            .policyData(admin.applyValue(getIAMPolicyResult -> getIAMPolicyResult.policyData()))
            .build());

    }
}
```
```yaml
resources:
  policy:
    type: gcp:dataproc:MetastoreServiceIamPolicy
    properties:
      project: ${default.project}
      location: ${default.location}
      serviceId: ${default.serviceId}
      policyData: ${admin.policyData}
variables:
  admin:
    fn::invoke:
      function: gcp:organizations:getIAMPolicy
      arguments:
        bindings:
          - role: roles/viewer
            members:
              - user:jane@example.com
```
<!--End PulumiCodeChooser -->

## gcp.dataproc.MetastoreServiceIamBinding

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const binding = new gcp.dataproc.MetastoreServiceIamBinding("binding", {
    project: _default.project,
    location: _default.location,
    serviceId: _default.serviceId,
    role: "roles/viewer",
    members: ["user:jane@example.com"],
});
```
```python
import pulumi
import pulumi_gcp as gcp

binding = gcp.dataproc.MetastoreServiceIamBinding("binding",
    project=default["project"],
    location=default["location"],
    service_id=default["serviceId"],
    role="roles/viewer",
    members=["user:jane@example.com"])
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var binding = new Gcp.Dataproc.MetastoreServiceIamBinding("binding", new()
    {
        Project = @default.Project,
        Location = @default.Location,
        ServiceId = @default.ServiceId,
        Role = "roles/viewer",
        Members = new[]
        {
            "user:jane@example.com",
        },
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/dataproc"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		_, err := dataproc.NewMetastoreServiceIamBinding(ctx, "binding", &dataproc.MetastoreServiceIamBindingArgs{
			Project:   pulumi.Any(_default.Project),
			Location:  pulumi.Any(_default.Location),
			ServiceId: pulumi.Any(_default.ServiceId),
			Role:      pulumi.String("roles/viewer"),
			Members: pulumi.StringArray{
				pulumi.String("user:jane@example.com"),
			},
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.dataproc.MetastoreServiceIamBinding;
import com.pulumi.gcp.dataproc.MetastoreServiceIamBindingArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        var binding = new MetastoreServiceIamBinding("binding", MetastoreServiceIamBindingArgs.builder()
            .project(default_.project())
            .location(default_.location())
            .serviceId(default_.serviceId())
            .role("roles/viewer")
            .members("user:jane@example.com")
            .build());

    }
}
```
```yaml
resources:
  binding:
    type: gcp:dataproc:MetastoreServiceIamBinding
    properties:
      project: ${default.project}
      location: ${default.location}
      serviceId: ${default.serviceId}
      role: roles/viewer
      members:
        - user:jane@example.com
```
<!--End PulumiCodeChooser -->

## gcp.dataproc.MetastoreServiceIamMember

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const member = new gcp.dataproc.MetastoreServiceIamMember("member", {
    project: _default.project,
    location: _default.location,
    serviceId: _default.serviceId,
    role: "roles/viewer",
    member: "user:jane@example.com",
});
```
```python
import pulumi
import pulumi_gcp as gcp

member = gcp.dataproc.MetastoreServiceIamMember("member",
    project=default["project"],
    location=default["location"],
    service_id=default["serviceId"],
    role="roles/viewer",
    member="user:jane@example.com")
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var member = new Gcp.Dataproc.MetastoreServiceIamMember("member", new()
    {
        Project = @default.Project,
        Location = @default.Location,
        ServiceId = @default.ServiceId,
        Role = "roles/viewer",
        Member = "user:jane@example.com",
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/dataproc"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		_, err := dataproc.NewMetastoreServiceIamMember(ctx, "member", &dataproc.MetastoreServiceIamMemberArgs{
			Project:   pulumi.Any(_default.Project),
			Location:  pulumi.Any(_default.Location),
			ServiceId: pulumi.Any(_default.ServiceId),
			Role:      pulumi.String("roles/viewer"),
			Member:    pulumi.String("user:jane@example.com"),
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.dataproc.MetastoreServiceIamMember;
import com.pulumi.gcp.dataproc.MetastoreServiceIamMemberArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        var member = new MetastoreServiceIamMember("member", MetastoreServiceIamMemberArgs.builder()
            .project(default_.project())
            .location(default_.location())
            .serviceId(default_.serviceId())
            .role("roles/viewer")
            .member("user:jane@example.com")
            .build());

    }
}
```
```yaml
resources:
  member:
    type: gcp:dataproc:MetastoreServiceIamMember
    properties:
      project: ${default.project}
      location: ${default.location}
      serviceId: ${default.serviceId}
      role: roles/viewer
      member: user:jane@example.com
```
<!--End PulumiCodeChooser -->


## This resource supports User Project Overrides.

-

# IAM policy for Dataproc metastore Service
Three different resources help you manage your IAM policy for Dataproc metastore Service. Each of these resources serves a different use case:

* `gcp.dataproc.MetastoreServiceIamPolicy`: Authoritative. Sets the IAM policy for the service and replaces any existing policy already attached.
* `gcp.dataproc.MetastoreServiceIamBinding`: Authoritative for a given role. Updates the IAM policy to grant a role to a list of members. Other roles within the IAM policy for the service are preserved.
* `gcp.dataproc.MetastoreServiceIamMember`: Non-authoritative. Updates the IAM policy to grant a role to a new member. Other members for the role for the service are preserved.

A data source can be used to retrieve policy data in advent you do not need creation

* `gcp.dataproc.MetastoreServiceIamPolicy`: Retrieves the IAM policy for the service

> **Note:** `gcp.dataproc.MetastoreServiceIamPolicy` **cannot** be used in conjunction with `gcp.dataproc.MetastoreServiceIamBinding` and `gcp.dataproc.MetastoreServiceIamMember` or they will fight over what your policy should be.

> **Note:** `gcp.dataproc.MetastoreServiceIamBinding` resources **can be** used in conjunction with `gcp.dataproc.MetastoreServiceIamMember` resources **only if** they do not grant privilege to the same role.



## gcp.dataproc.MetastoreServiceIamPolicy

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const admin = gcp.organizations.getIAMPolicy({
    bindings: [{
        role: "roles/viewer",
        members: ["user:jane@example.com"],
    }],
});
const policy = new gcp.dataproc.MetastoreServiceIamPolicy("policy", {
    project: _default.project,
    location: _default.location,
    serviceId: _default.serviceId,
    policyData: admin.then(admin => admin.policyData),
});
```
```python
import pulumi
import pulumi_gcp as gcp

admin = gcp.organizations.get_iam_policy(bindings=[{
    "role": "roles/viewer",
    "members": ["user:jane@example.com"],
}])
policy = gcp.dataproc.MetastoreServiceIamPolicy("policy",
    project=default["project"],
    location=default["location"],
    service_id=default["serviceId"],
    policy_data=admin.policy_data)
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var admin = Gcp.Organizations.GetIAMPolicy.Invoke(new()
    {
        Bindings = new[]
        {
            new Gcp.Organizations.Inputs.GetIAMPolicyBindingInputArgs
            {
                Role = "roles/viewer",
                Members = new[]
                {
                    "user:jane@example.com",
                },
            },
        },
    });

    var policy = new Gcp.Dataproc.MetastoreServiceIamPolicy("policy", new()
    {
        Project = @default.Project,
        Location = @default.Location,
        ServiceId = @default.ServiceId,
        PolicyData = admin.Apply(getIAMPolicyResult => getIAMPolicyResult.PolicyData),
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/dataproc"
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/organizations"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		admin, err := organizations.LookupIAMPolicy(ctx, &organizations.LookupIAMPolicyArgs{
			Bindings: []organizations.GetIAMPolicyBinding{
				{
					Role: "roles/viewer",
					Members: []string{
						"user:jane@example.com",
					},
				},
			},
		}, nil)
		if err != nil {
			return err
		}
		_, err = dataproc.NewMetastoreServiceIamPolicy(ctx, "policy", &dataproc.MetastoreServiceIamPolicyArgs{
			Project:    pulumi.Any(_default.Project),
			Location:   pulumi.Any(_default.Location),
			ServiceId:  pulumi.Any(_default.ServiceId),
			PolicyData: pulumi.String(admin.PolicyData),
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.organizations.OrganizationsFunctions;
import com.pulumi.gcp.organizations.inputs.GetIAMPolicyArgs;
import com.pulumi.gcp.dataproc.MetastoreServiceIamPolicy;
import com.pulumi.gcp.dataproc.MetastoreServiceIamPolicyArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        final var admin = OrganizationsFunctions.getIAMPolicy(GetIAMPolicyArgs.builder()
            .bindings(GetIAMPolicyBindingArgs.builder()
                .role("roles/viewer")
                .members("user:jane@example.com")
                .build())
            .build());

        var policy = new MetastoreServiceIamPolicy("policy", MetastoreServiceIamPolicyArgs.builder()
            .project(default_.project())
            .location(default_.location())
            .serviceId(default_.serviceId())
            .policyData(admin.applyValue(getIAMPolicyResult -> getIAMPolicyResult.policyData()))
            .build());

    }
}
```
```yaml
resources:
  policy:
    type: gcp:dataproc:MetastoreServiceIamPolicy
    properties:
      project: ${default.project}
      location: ${default.location}
      serviceId: ${default.serviceId}
      policyData: ${admin.policyData}
variables:
  admin:
    fn::invoke:
      function: gcp:organizations:getIAMPolicy
      arguments:
        bindings:
          - role: roles/viewer
            members:
              - user:jane@example.com
```
<!--End PulumiCodeChooser -->

## gcp.dataproc.MetastoreServiceIamBinding

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const binding = new gcp.dataproc.MetastoreServiceIamBinding("binding", {
    project: _default.project,
    location: _default.location,
    serviceId: _default.serviceId,
    role: "roles/viewer",
    members: ["user:jane@example.com"],
});
```
```python
import pulumi
import pulumi_gcp as gcp

binding = gcp.dataproc.MetastoreServiceIamBinding("binding",
    project=default["project"],
    location=default["location"],
    service_id=default["serviceId"],
    role="roles/viewer",
    members=["user:jane@example.com"])
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var binding = new Gcp.Dataproc.MetastoreServiceIamBinding("binding", new()
    {
        Project = @default.Project,
        Location = @default.Location,
        ServiceId = @default.ServiceId,
        Role = "roles/viewer",
        Members = new[]
        {
            "user:jane@example.com",
        },
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/dataproc"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		_, err := dataproc.NewMetastoreServiceIamBinding(ctx, "binding", &dataproc.MetastoreServiceIamBindingArgs{
			Project:   pulumi.Any(_default.Project),
			Location:  pulumi.Any(_default.Location),
			ServiceId: pulumi.Any(_default.ServiceId),
			Role:      pulumi.String("roles/viewer"),
			Members: pulumi.StringArray{
				pulumi.String("user:jane@example.com"),
			},
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.dataproc.MetastoreServiceIamBinding;
import com.pulumi.gcp.dataproc.MetastoreServiceIamBindingArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        var binding = new MetastoreServiceIamBinding("binding", MetastoreServiceIamBindingArgs.builder()
            .project(default_.project())
            .location(default_.location())
            .serviceId(default_.serviceId())
            .role("roles/viewer")
            .members("user:jane@example.com")
            .build());

    }
}
```
```yaml
resources:
  binding:
    type: gcp:dataproc:MetastoreServiceIamBinding
    properties:
      project: ${default.project}
      location: ${default.location}
      serviceId: ${default.serviceId}
      role: roles/viewer
      members:
        - user:jane@example.com
```
<!--End PulumiCodeChooser -->

## gcp.dataproc.MetastoreServiceIamMember

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const member = new gcp.dataproc.MetastoreServiceIamMember("member", {
    project: _default.project,
    location: _default.location,
    serviceId: _default.serviceId,
    role: "roles/viewer",
    member: "user:jane@example.com",
});
```
```python
import pulumi
import pulumi_gcp as gcp

member = gcp.dataproc.MetastoreServiceIamMember("member",
    project=default["project"],
    location=default["location"],
    service_id=default["serviceId"],
    role="roles/viewer",
    member="user:jane@example.com")
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var member = new Gcp.Dataproc.MetastoreServiceIamMember("member", new()
    {
        Project = @default.Project,
        Location = @default.Location,
        ServiceId = @default.ServiceId,
        Role = "roles/viewer",
        Member = "user:jane@example.com",
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/dataproc"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		_, err := dataproc.NewMetastoreServiceIamMember(ctx, "member", &dataproc.MetastoreServiceIamMemberArgs{
			Project:   pulumi.Any(_default.Project),
			Location:  pulumi.Any(_default.Location),
			ServiceId: pulumi.Any(_default.ServiceId),
			Role:      pulumi.String("roles/viewer"),
			Member:    pulumi.String("user:jane@example.com"),
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.dataproc.MetastoreServiceIamMember;
import com.pulumi.gcp.dataproc.MetastoreServiceIamMemberArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        var member = new MetastoreServiceIamMember("member", MetastoreServiceIamMemberArgs.builder()
            .project(default_.project())
            .location(default_.location())
            .serviceId(default_.serviceId())
            .role("roles/viewer")
            .member("user:jane@example.com")
            .build());

    }
}
```
```yaml
resources:
  member:
    type: gcp:dataproc:MetastoreServiceIamMember
    properties:
      project: ${default.project}
      location: ${default.location}
      serviceId: ${default.serviceId}
      role: roles/viewer
      member: user:jane@example.com
```
<!--End PulumiCodeChooser -->

## Import

For all import syntaxes, the "resource in question" can take any of the following forms:

* projects/{{project}}/locations/{{location}}/services/{{service_id}}

* {{project}}/{{location}}/{{service_id}}

* {{location}}/{{service_id}}

* {{service_id}}

Any variables not passed in the import command will be taken from the provider configuration.

Dataproc metastore service IAM resources can be imported using the resource identifiers, role, and member.

IAM member imports use space-delimited identifiers: the resource in question, the role, and the member identity, e.g.

```sh
$ pulumi import gcp:dataproc/metastoreServiceIamMember:MetastoreServiceIamMember editor "projects/{{project}}/locations/{{location}}/services/{{service_id}} roles/viewer user:jane@example.com"
```

IAM binding imports use space-delimited identifiers: the resource in question and the role, e.g.

```sh
$ pulumi import gcp:dataproc/metastoreServiceIamMember:MetastoreServiceIamMember editor "projects/{{project}}/locations/{{location}}/services/{{service_id}} roles/viewer"
```

IAM policy imports use the identifier of the resource in question, e.g.

```sh
$ pulumi import gcp:dataproc/metastoreServiceIamMember:MetastoreServiceIamMember editor projects/{{project}}/locations/{{location}}/services/{{service_id}}
```

-> **Custom Roles** If you're importing a IAM resource with a custom role, make sure to use the

 full name of the custom role, e.g. `[projects/my-project|organizations/my-org]/roles/my-custom-role`.


	conditionB:

dataproc"MetastoreServiceIamMemberConditionRgcp:dataproc/MetastoreServiceIamMemberCondition:MetastoreServiceIamMemberConditionü
locationB" éThe location where the metastore service should reside.
The default value is `global`.
Used to find the parent resource to bind the IAM policy to. If not specified,
the value will be parsed from the identifier of the parent resource. If no location is provided in the parent identifier and no
location is specified, it is taken from the provider configuration.
Ó	
member" Ä	Identities that will be granted the privilege in `role`.
Each entry can have one of the following values:
* **allUsers**: A special identifier that represents anyone who is on the internet; with or without a Google account.
* **allAuthenticatedUsers**: A special identifier that represents anyone who is authenticated with a Google account or a service account.
* **user:{emailid}**: An email address that represents a specific Google account. For example, alice@gmail.com or joe@example.com.
* **serviceAccount:{emailid}**: An email address that represents a service account. For example, my-other-app@appspot.gserviceaccount.com.
* **group:{emailid}**: An email address that represents a Google group. For example, admins@example.com.
* **domain:{domain}**: A G Suite domain (primary, instead of alias) name that represents all the users of that domain. For example, google.com or example.com.
* **projectOwner:projectid**: Owners of the given project. For example, "projectOwner:my-example-project"
* **projectEditor:projectid**: Editors of the given project. For example, "projectEditor:my-example-project"
* **projectViewer:projectid**: Viewers of the given project. For example, "projectViewer:my-example-project"

projectB" The ID of the project in which the resource belongs.
If it is not provided, the project will be parsed from the identifier of the parent resource. If no project is provided in the parent identifier and no project is specified, the provider project is used.
à
role" ÓThe role that should be applied. Only one
`gcp.dataproc.MetastoreServiceIamBinding` can be used per role. Note that custom roles must be of the format
`[projects|organizations]/{parent-name}/roles/{role-name}`.

	serviceId" "
	conditionB:

dataproc"MetastoreServiceIamMemberConditionRgcp:dataproc/MetastoreServiceIamMemberCondition:MetastoreServiceIamMemberCondition"3
etag" '(Computed) The etag of the IAM policy.
"ú
location" éThe location where the metastore service should reside.
The default value is `global`.
Used to find the parent resource to bind the IAM policy to. If not specified,
the value will be parsed from the identifier of the parent resource. If no location is provided in the parent identifier and no
location is specified, it is taken from the provider configuration.
"Ó	
member" Ä	Identities that will be granted the privilege in `role`.
Each entry can have one of the following values:
* **allUsers**: A special identifier that represents anyone who is on the internet; with or without a Google account.
* **allAuthenticatedUsers**: A special identifier that represents anyone who is authenticated with a Google account or a service account.
* **user:{emailid}**: An email address that represents a specific Google account. For example, alice@gmail.com or joe@example.com.
* **serviceAccount:{emailid}**: An email address that represents a service account. For example, my-other-app@appspot.gserviceaccount.com.
* **group:{emailid}**: An email address that represents a Google group. For example, admins@example.com.
* **domain:{domain}**: A G Suite domain (primary, instead of alias) name that represents all the users of that domain. For example, google.com or example.com.
* **projectOwner:projectid**: Owners of the given project. For example, "projectOwner:my-example-project"
* **projectEditor:projectid**: Editors of the given project. For example, "projectEditor:my-example-project"
* **projectViewer:projectid**: Viewers of the given project. For example, "projectViewer:my-example-project"
"
project" The ID of the project in which the resource belongs.
If it is not provided, the project will be parsed from the identifier of the parent resource. If no project is provided in the parent identifier and no project is specified, the provider project is used.
"à
role" ÓThe role that should be applied. Only one
`gcp.dataproc.MetastoreServiceIamBinding` can be used per role. Note that custom roles must be of the format
`[projects|organizations]/{parent-name}/roles/{role-name}`.
"
	serviceId" *¤Ï
g
dataprocMetastoreServiceIamPolicy@gcp:dataproc/metastoreServiceIamPolicy:MetastoreServiceIamPolicyøÁThree different resources help you manage your IAM policy for Dataproc metastore Service. Each of these resources serves a different use case:

* `gcp.dataproc.MetastoreServiceIamPolicy`: Authoritative. Sets the IAM policy for the service and replaces any existing policy already attached.
* `gcp.dataproc.MetastoreServiceIamBinding`: Authoritative for a given role. Updates the IAM policy to grant a role to a list of members. Other roles within the IAM policy for the service are preserved.
* `gcp.dataproc.MetastoreServiceIamMember`: Non-authoritative. Updates the IAM policy to grant a role to a new member. Other members for the role for the service are preserved.

A data source can be used to retrieve policy data in advent you do not need creation

* `gcp.dataproc.MetastoreServiceIamPolicy`: Retrieves the IAM policy for the service

> **Note:** `gcp.dataproc.MetastoreServiceIamPolicy` **cannot** be used in conjunction with `gcp.dataproc.MetastoreServiceIamBinding` and `gcp.dataproc.MetastoreServiceIamMember` or they will fight over what your policy should be.

> **Note:** `gcp.dataproc.MetastoreServiceIamBinding` resources **can be** used in conjunction with `gcp.dataproc.MetastoreServiceIamMember` resources **only if** they do not grant privilege to the same role.



## gcp.dataproc.MetastoreServiceIamPolicy

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const admin = gcp.organizations.getIAMPolicy({
    bindings: [{
        role: "roles/viewer",
        members: ["user:jane@example.com"],
    }],
});
const policy = new gcp.dataproc.MetastoreServiceIamPolicy("policy", {
    project: _default.project,
    location: _default.location,
    serviceId: _default.serviceId,
    policyData: admin.then(admin => admin.policyData),
});
```
```python
import pulumi
import pulumi_gcp as gcp

admin = gcp.organizations.get_iam_policy(bindings=[{
    "role": "roles/viewer",
    "members": ["user:jane@example.com"],
}])
policy = gcp.dataproc.MetastoreServiceIamPolicy("policy",
    project=default["project"],
    location=default["location"],
    service_id=default["serviceId"],
    policy_data=admin.policy_data)
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var admin = Gcp.Organizations.GetIAMPolicy.Invoke(new()
    {
        Bindings = new[]
        {
            new Gcp.Organizations.Inputs.GetIAMPolicyBindingInputArgs
            {
                Role = "roles/viewer",
                Members = new[]
                {
                    "user:jane@example.com",
                },
            },
        },
    });

    var policy = new Gcp.Dataproc.MetastoreServiceIamPolicy("policy", new()
    {
        Project = @default.Project,
        Location = @default.Location,
        ServiceId = @default.ServiceId,
        PolicyData = admin.Apply(getIAMPolicyResult => getIAMPolicyResult.PolicyData),
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/dataproc"
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/organizations"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		admin, err := organizations.LookupIAMPolicy(ctx, &organizations.LookupIAMPolicyArgs{
			Bindings: []organizations.GetIAMPolicyBinding{
				{
					Role: "roles/viewer",
					Members: []string{
						"user:jane@example.com",
					},
				},
			},
		}, nil)
		if err != nil {
			return err
		}
		_, err = dataproc.NewMetastoreServiceIamPolicy(ctx, "policy", &dataproc.MetastoreServiceIamPolicyArgs{
			Project:    pulumi.Any(_default.Project),
			Location:   pulumi.Any(_default.Location),
			ServiceId:  pulumi.Any(_default.ServiceId),
			PolicyData: pulumi.String(admin.PolicyData),
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.organizations.OrganizationsFunctions;
import com.pulumi.gcp.organizations.inputs.GetIAMPolicyArgs;
import com.pulumi.gcp.dataproc.MetastoreServiceIamPolicy;
import com.pulumi.gcp.dataproc.MetastoreServiceIamPolicyArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        final var admin = OrganizationsFunctions.getIAMPolicy(GetIAMPolicyArgs.builder()
            .bindings(GetIAMPolicyBindingArgs.builder()
                .role("roles/viewer")
                .members("user:jane@example.com")
                .build())
            .build());

        var policy = new MetastoreServiceIamPolicy("policy", MetastoreServiceIamPolicyArgs.builder()
            .project(default_.project())
            .location(default_.location())
            .serviceId(default_.serviceId())
            .policyData(admin.applyValue(getIAMPolicyResult -> getIAMPolicyResult.policyData()))
            .build());

    }
}
```
```yaml
resources:
  policy:
    type: gcp:dataproc:MetastoreServiceIamPolicy
    properties:
      project: ${default.project}
      location: ${default.location}
      serviceId: ${default.serviceId}
      policyData: ${admin.policyData}
variables:
  admin:
    fn::invoke:
      function: gcp:organizations:getIAMPolicy
      arguments:
        bindings:
          - role: roles/viewer
            members:
              - user:jane@example.com
```
<!--End PulumiCodeChooser -->

## gcp.dataproc.MetastoreServiceIamBinding

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const binding = new gcp.dataproc.MetastoreServiceIamBinding("binding", {
    project: _default.project,
    location: _default.location,
    serviceId: _default.serviceId,
    role: "roles/viewer",
    members: ["user:jane@example.com"],
});
```
```python
import pulumi
import pulumi_gcp as gcp

binding = gcp.dataproc.MetastoreServiceIamBinding("binding",
    project=default["project"],
    location=default["location"],
    service_id=default["serviceId"],
    role="roles/viewer",
    members=["user:jane@example.com"])
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var binding = new Gcp.Dataproc.MetastoreServiceIamBinding("binding", new()
    {
        Project = @default.Project,
        Location = @default.Location,
        ServiceId = @default.ServiceId,
        Role = "roles/viewer",
        Members = new[]
        {
            "user:jane@example.com",
        },
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/dataproc"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		_, err := dataproc.NewMetastoreServiceIamBinding(ctx, "binding", &dataproc.MetastoreServiceIamBindingArgs{
			Project:   pulumi.Any(_default.Project),
			Location:  pulumi.Any(_default.Location),
			ServiceId: pulumi.Any(_default.ServiceId),
			Role:      pulumi.String("roles/viewer"),
			Members: pulumi.StringArray{
				pulumi.String("user:jane@example.com"),
			},
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.dataproc.MetastoreServiceIamBinding;
import com.pulumi.gcp.dataproc.MetastoreServiceIamBindingArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        var binding = new MetastoreServiceIamBinding("binding", MetastoreServiceIamBindingArgs.builder()
            .project(default_.project())
            .location(default_.location())
            .serviceId(default_.serviceId())
            .role("roles/viewer")
            .members("user:jane@example.com")
            .build());

    }
}
```
```yaml
resources:
  binding:
    type: gcp:dataproc:MetastoreServiceIamBinding
    properties:
      project: ${default.project}
      location: ${default.location}
      serviceId: ${default.serviceId}
      role: roles/viewer
      members:
        - user:jane@example.com
```
<!--End PulumiCodeChooser -->

## gcp.dataproc.MetastoreServiceIamMember

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const member = new gcp.dataproc.MetastoreServiceIamMember("member", {
    project: _default.project,
    location: _default.location,
    serviceId: _default.serviceId,
    role: "roles/viewer",
    member: "user:jane@example.com",
});
```
```python
import pulumi
import pulumi_gcp as gcp

member = gcp.dataproc.MetastoreServiceIamMember("member",
    project=default["project"],
    location=default["location"],
    service_id=default["serviceId"],
    role="roles/viewer",
    member="user:jane@example.com")
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var member = new Gcp.Dataproc.MetastoreServiceIamMember("member", new()
    {
        Project = @default.Project,
        Location = @default.Location,
        ServiceId = @default.ServiceId,
        Role = "roles/viewer",
        Member = "user:jane@example.com",
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/dataproc"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		_, err := dataproc.NewMetastoreServiceIamMember(ctx, "member", &dataproc.MetastoreServiceIamMemberArgs{
			Project:   pulumi.Any(_default.Project),
			Location:  pulumi.Any(_default.Location),
			ServiceId: pulumi.Any(_default.ServiceId),
			Role:      pulumi.String("roles/viewer"),
			Member:    pulumi.String("user:jane@example.com"),
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.dataproc.MetastoreServiceIamMember;
import com.pulumi.gcp.dataproc.MetastoreServiceIamMemberArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        var member = new MetastoreServiceIamMember("member", MetastoreServiceIamMemberArgs.builder()
            .project(default_.project())
            .location(default_.location())
            .serviceId(default_.serviceId())
            .role("roles/viewer")
            .member("user:jane@example.com")
            .build());

    }
}
```
```yaml
resources:
  member:
    type: gcp:dataproc:MetastoreServiceIamMember
    properties:
      project: ${default.project}
      location: ${default.location}
      serviceId: ${default.serviceId}
      role: roles/viewer
      member: user:jane@example.com
```
<!--End PulumiCodeChooser -->


## This resource supports User Project Overrides.

-

# IAM policy for Dataproc metastore Service
Three different resources help you manage your IAM policy for Dataproc metastore Service. Each of these resources serves a different use case:

* `gcp.dataproc.MetastoreServiceIamPolicy`: Authoritative. Sets the IAM policy for the service and replaces any existing policy already attached.
* `gcp.dataproc.MetastoreServiceIamBinding`: Authoritative for a given role. Updates the IAM policy to grant a role to a list of members. Other roles within the IAM policy for the service are preserved.
* `gcp.dataproc.MetastoreServiceIamMember`: Non-authoritative. Updates the IAM policy to grant a role to a new member. Other members for the role for the service are preserved.

A data source can be used to retrieve policy data in advent you do not need creation

* `gcp.dataproc.MetastoreServiceIamPolicy`: Retrieves the IAM policy for the service

> **Note:** `gcp.dataproc.MetastoreServiceIamPolicy` **cannot** be used in conjunction with `gcp.dataproc.MetastoreServiceIamBinding` and `gcp.dataproc.MetastoreServiceIamMember` or they will fight over what your policy should be.

> **Note:** `gcp.dataproc.MetastoreServiceIamBinding` resources **can be** used in conjunction with `gcp.dataproc.MetastoreServiceIamMember` resources **only if** they do not grant privilege to the same role.



## gcp.dataproc.MetastoreServiceIamPolicy

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const admin = gcp.organizations.getIAMPolicy({
    bindings: [{
        role: "roles/viewer",
        members: ["user:jane@example.com"],
    }],
});
const policy = new gcp.dataproc.MetastoreServiceIamPolicy("policy", {
    project: _default.project,
    location: _default.location,
    serviceId: _default.serviceId,
    policyData: admin.then(admin => admin.policyData),
});
```
```python
import pulumi
import pulumi_gcp as gcp

admin = gcp.organizations.get_iam_policy(bindings=[{
    "role": "roles/viewer",
    "members": ["user:jane@example.com"],
}])
policy = gcp.dataproc.MetastoreServiceIamPolicy("policy",
    project=default["project"],
    location=default["location"],
    service_id=default["serviceId"],
    policy_data=admin.policy_data)
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var admin = Gcp.Organizations.GetIAMPolicy.Invoke(new()
    {
        Bindings = new[]
        {
            new Gcp.Organizations.Inputs.GetIAMPolicyBindingInputArgs
            {
                Role = "roles/viewer",
                Members = new[]
                {
                    "user:jane@example.com",
                },
            },
        },
    });

    var policy = new Gcp.Dataproc.MetastoreServiceIamPolicy("policy", new()
    {
        Project = @default.Project,
        Location = @default.Location,
        ServiceId = @default.ServiceId,
        PolicyData = admin.Apply(getIAMPolicyResult => getIAMPolicyResult.PolicyData),
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/dataproc"
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/organizations"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		admin, err := organizations.LookupIAMPolicy(ctx, &organizations.LookupIAMPolicyArgs{
			Bindings: []organizations.GetIAMPolicyBinding{
				{
					Role: "roles/viewer",
					Members: []string{
						"user:jane@example.com",
					},
				},
			},
		}, nil)
		if err != nil {
			return err
		}
		_, err = dataproc.NewMetastoreServiceIamPolicy(ctx, "policy", &dataproc.MetastoreServiceIamPolicyArgs{
			Project:    pulumi.Any(_default.Project),
			Location:   pulumi.Any(_default.Location),
			ServiceId:  pulumi.Any(_default.ServiceId),
			PolicyData: pulumi.String(admin.PolicyData),
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.organizations.OrganizationsFunctions;
import com.pulumi.gcp.organizations.inputs.GetIAMPolicyArgs;
import com.pulumi.gcp.dataproc.MetastoreServiceIamPolicy;
import com.pulumi.gcp.dataproc.MetastoreServiceIamPolicyArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        final var admin = OrganizationsFunctions.getIAMPolicy(GetIAMPolicyArgs.builder()
            .bindings(GetIAMPolicyBindingArgs.builder()
                .role("roles/viewer")
                .members("user:jane@example.com")
                .build())
            .build());

        var policy = new MetastoreServiceIamPolicy("policy", MetastoreServiceIamPolicyArgs.builder()
            .project(default_.project())
            .location(default_.location())
            .serviceId(default_.serviceId())
            .policyData(admin.applyValue(getIAMPolicyResult -> getIAMPolicyResult.policyData()))
            .build());

    }
}
```
```yaml
resources:
  policy:
    type: gcp:dataproc:MetastoreServiceIamPolicy
    properties:
      project: ${default.project}
      location: ${default.location}
      serviceId: ${default.serviceId}
      policyData: ${admin.policyData}
variables:
  admin:
    fn::invoke:
      function: gcp:organizations:getIAMPolicy
      arguments:
        bindings:
          - role: roles/viewer
            members:
              - user:jane@example.com
```
<!--End PulumiCodeChooser -->

## gcp.dataproc.MetastoreServiceIamBinding

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const binding = new gcp.dataproc.MetastoreServiceIamBinding("binding", {
    project: _default.project,
    location: _default.location,
    serviceId: _default.serviceId,
    role: "roles/viewer",
    members: ["user:jane@example.com"],
});
```
```python
import pulumi
import pulumi_gcp as gcp

binding = gcp.dataproc.MetastoreServiceIamBinding("binding",
    project=default["project"],
    location=default["location"],
    service_id=default["serviceId"],
    role="roles/viewer",
    members=["user:jane@example.com"])
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var binding = new Gcp.Dataproc.MetastoreServiceIamBinding("binding", new()
    {
        Project = @default.Project,
        Location = @default.Location,
        ServiceId = @default.ServiceId,
        Role = "roles/viewer",
        Members = new[]
        {
            "user:jane@example.com",
        },
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/dataproc"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		_, err := dataproc.NewMetastoreServiceIamBinding(ctx, "binding", &dataproc.MetastoreServiceIamBindingArgs{
			Project:   pulumi.Any(_default.Project),
			Location:  pulumi.Any(_default.Location),
			ServiceId: pulumi.Any(_default.ServiceId),
			Role:      pulumi.String("roles/viewer"),
			Members: pulumi.StringArray{
				pulumi.String("user:jane@example.com"),
			},
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.dataproc.MetastoreServiceIamBinding;
import com.pulumi.gcp.dataproc.MetastoreServiceIamBindingArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        var binding = new MetastoreServiceIamBinding("binding", MetastoreServiceIamBindingArgs.builder()
            .project(default_.project())
            .location(default_.location())
            .serviceId(default_.serviceId())
            .role("roles/viewer")
            .members("user:jane@example.com")
            .build());

    }
}
```
```yaml
resources:
  binding:
    type: gcp:dataproc:MetastoreServiceIamBinding
    properties:
      project: ${default.project}
      location: ${default.location}
      serviceId: ${default.serviceId}
      role: roles/viewer
      members:
        - user:jane@example.com
```
<!--End PulumiCodeChooser -->

## gcp.dataproc.MetastoreServiceIamMember

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const member = new gcp.dataproc.MetastoreServiceIamMember("member", {
    project: _default.project,
    location: _default.location,
    serviceId: _default.serviceId,
    role: "roles/viewer",
    member: "user:jane@example.com",
});
```
```python
import pulumi
import pulumi_gcp as gcp

member = gcp.dataproc.MetastoreServiceIamMember("member",
    project=default["project"],
    location=default["location"],
    service_id=default["serviceId"],
    role="roles/viewer",
    member="user:jane@example.com")
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var member = new Gcp.Dataproc.MetastoreServiceIamMember("member", new()
    {
        Project = @default.Project,
        Location = @default.Location,
        ServiceId = @default.ServiceId,
        Role = "roles/viewer",
        Member = "user:jane@example.com",
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/dataproc"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		_, err := dataproc.NewMetastoreServiceIamMember(ctx, "member", &dataproc.MetastoreServiceIamMemberArgs{
			Project:   pulumi.Any(_default.Project),
			Location:  pulumi.Any(_default.Location),
			ServiceId: pulumi.Any(_default.ServiceId),
			Role:      pulumi.String("roles/viewer"),
			Member:    pulumi.String("user:jane@example.com"),
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.dataproc.MetastoreServiceIamMember;
import com.pulumi.gcp.dataproc.MetastoreServiceIamMemberArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        var member = new MetastoreServiceIamMember("member", MetastoreServiceIamMemberArgs.builder()
            .project(default_.project())
            .location(default_.location())
            .serviceId(default_.serviceId())
            .role("roles/viewer")
            .member("user:jane@example.com")
            .build());

    }
}
```
```yaml
resources:
  member:
    type: gcp:dataproc:MetastoreServiceIamMember
    properties:
      project: ${default.project}
      location: ${default.location}
      serviceId: ${default.serviceId}
      role: roles/viewer
      member: user:jane@example.com
```
<!--End PulumiCodeChooser -->

## Import

For all import syntaxes, the "resource in question" can take any of the following forms:

* projects/{{project}}/locations/{{location}}/services/{{service_id}}

* {{project}}/{{location}}/{{service_id}}

* {{location}}/{{service_id}}

* {{service_id}}

Any variables not passed in the import command will be taken from the provider configuration.

Dataproc metastore service IAM resources can be imported using the resource identifiers, role, and member.

IAM member imports use space-delimited identifiers: the resource in question, the role, and the member identity, e.g.

```sh
$ pulumi import gcp:dataproc/metastoreServiceIamPolicy:MetastoreServiceIamPolicy editor "projects/{{project}}/locations/{{location}}/services/{{service_id}} roles/viewer user:jane@example.com"
```

IAM binding imports use space-delimited identifiers: the resource in question and the role, e.g.

```sh
$ pulumi import gcp:dataproc/metastoreServiceIamPolicy:MetastoreServiceIamPolicy editor "projects/{{project}}/locations/{{location}}/services/{{service_id}} roles/viewer"
```

IAM policy imports use the identifier of the resource in question, e.g.

```sh
$ pulumi import gcp:dataproc/metastoreServiceIamPolicy:MetastoreServiceIamPolicy editor projects/{{project}}/locations/{{location}}/services/{{service_id}}
```

-> **Custom Roles** If you're importing a IAM resource with a custom role, make sure to use the

 full name of the custom role, e.g. `[projects/my-project|organizations/my-org]/roles/my-custom-role`.

ü
locationB" éThe location where the metastore service should reside.
The default value is `global`.
Used to find the parent resource to bind the IAM policy to. If not specified,
the value will be parsed from the identifier of the parent resource. If no location is provided in the parent identifier and no
location is specified, it is taken from the provider configuration.
_

policyData" MThe policy data generated by
a `gcp.organizations.getIAMPolicy` data source.

projectB" The ID of the project in which the resource belongs.
If it is not provided, the project will be parsed from the identifier of the parent resource. If no project is provided in the parent identifier and no project is specified, the provider project is used.

	serviceId" "3
etag" '(Computed) The etag of the IAM policy.
"ú
location" éThe location where the metastore service should reside.
The default value is `global`.
Used to find the parent resource to bind the IAM policy to. If not specified,
the value will be parsed from the identifier of the parent resource. If no location is provided in the parent identifier and no
location is specified, it is taken from the provider configuration.
"_

policyData" MThe policy data generated by
a `gcp.organizations.getIAMPolicy` data source.
"
project" The ID of the project in which the resource belongs.
If it is not provided, the project will be parsed from the identifier of the parent resource. If no project is provided in the parent identifier and no project is specified, the provider project is used.
"
	serviceId" *ã©
L
dataprocWorkflowTemplate.gcp:dataproc/workflowTemplate:WorkflowTemplateò}A Workflow Template is a reusable workflow configuration. It defines a graph of jobs with information on where to run those jobs.

## Example Usage

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const template = new gcp.dataproc.WorkflowTemplate("template", {
    name: "template-example",
    location: "us-central1",
    placement: {
        managedCluster: {
            clusterName: "my-cluster",
            config: {
                gceClusterConfig: {
                    zone: "us-central1-a",
                    tags: [
                        "foo",
                        "bar",
                    ],
                },
                masterConfig: {
                    numInstances: 1,
                    machineType: "n1-standard-1",
                    diskConfig: {
                        bootDiskType: "pd-ssd",
                        bootDiskSizeGb: 15,
                    },
                },
                workerConfig: {
                    numInstances: 3,
                    machineType: "n1-standard-2",
                    diskConfig: {
                        bootDiskSizeGb: 10,
                        numLocalSsds: 2,
                    },
                },
                secondaryWorkerConfig: {
                    numInstances: 2,
                },
                softwareConfig: {
                    imageVersion: "2.0.35-debian10",
                },
            },
        },
    },
    jobs: [
        {
            stepId: "someJob",
            sparkJob: {
                mainClass: "SomeClass",
            },
        },
        {
            stepId: "otherJob",
            prerequisiteStepIds: ["someJob"],
            prestoJob: {
                queryFileUri: "someuri",
            },
        },
    ],
});
```
```python
import pulumi
import pulumi_gcp as gcp

template = gcp.dataproc.WorkflowTemplate("template",
    name="template-example",
    location="us-central1",
    placement={
        "managed_cluster": {
            "cluster_name": "my-cluster",
            "config": {
                "gce_cluster_config": {
                    "zone": "us-central1-a",
                    "tags": [
                        "foo",
                        "bar",
                    ],
                },
                "master_config": {
                    "num_instances": 1,
                    "machine_type": "n1-standard-1",
                    "disk_config": {
                        "boot_disk_type": "pd-ssd",
                        "boot_disk_size_gb": 15,
                    },
                },
                "worker_config": {
                    "num_instances": 3,
                    "machine_type": "n1-standard-2",
                    "disk_config": {
                        "boot_disk_size_gb": 10,
                        "num_local_ssds": 2,
                    },
                },
                "secondary_worker_config": {
                    "num_instances": 2,
                },
                "software_config": {
                    "image_version": "2.0.35-debian10",
                },
            },
        },
    },
    jobs=[
        {
            "step_id": "someJob",
            "spark_job": {
                "main_class": "SomeClass",
            },
        },
        {
            "step_id": "otherJob",
            "prerequisite_step_ids": ["someJob"],
            "presto_job": {
                "query_file_uri": "someuri",
            },
        },
    ])
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var template = new Gcp.Dataproc.WorkflowTemplate("template", new()
    {
        Name = "template-example",
        Location = "us-central1",
        Placement = new Gcp.Dataproc.Inputs.WorkflowTemplatePlacementArgs
        {
            ManagedCluster = new Gcp.Dataproc.Inputs.WorkflowTemplatePlacementManagedClusterArgs
            {
                ClusterName = "my-cluster",
                Config = new Gcp.Dataproc.Inputs.WorkflowTemplatePlacementManagedClusterConfigArgs
                {
                    GceClusterConfig = new Gcp.Dataproc.Inputs.WorkflowTemplatePlacementManagedClusterConfigGceClusterConfigArgs
                    {
                        Zone = "us-central1-a",
                        Tags = new[]
                        {
                            "foo",
                            "bar",
                        },
                    },
                    MasterConfig = new Gcp.Dataproc.Inputs.WorkflowTemplatePlacementManagedClusterConfigMasterConfigArgs
                    {
                        NumInstances = 1,
                        MachineType = "n1-standard-1",
                        DiskConfig = new Gcp.Dataproc.Inputs.WorkflowTemplatePlacementManagedClusterConfigMasterConfigDiskConfigArgs
                        {
                            BootDiskType = "pd-ssd",
                            BootDiskSizeGb = 15,
                        },
                    },
                    WorkerConfig = new Gcp.Dataproc.Inputs.WorkflowTemplatePlacementManagedClusterConfigWorkerConfigArgs
                    {
                        NumInstances = 3,
                        MachineType = "n1-standard-2",
                        DiskConfig = new Gcp.Dataproc.Inputs.WorkflowTemplatePlacementManagedClusterConfigWorkerConfigDiskConfigArgs
                        {
                            BootDiskSizeGb = 10,
                            NumLocalSsds = 2,
                        },
                    },
                    SecondaryWorkerConfig = new Gcp.Dataproc.Inputs.WorkflowTemplatePlacementManagedClusterConfigSecondaryWorkerConfigArgs
                    {
                        NumInstances = 2,
                    },
                    SoftwareConfig = new Gcp.Dataproc.Inputs.WorkflowTemplatePlacementManagedClusterConfigSoftwareConfigArgs
                    {
                        ImageVersion = "2.0.35-debian10",
                    },
                },
            },
        },
        Jobs = new[]
        {
            new Gcp.Dataproc.Inputs.WorkflowTemplateJobArgs
            {
                StepId = "someJob",
                SparkJob = new Gcp.Dataproc.Inputs.WorkflowTemplateJobSparkJobArgs
                {
                    MainClass = "SomeClass",
                },
            },
            new Gcp.Dataproc.Inputs.WorkflowTemplateJobArgs
            {
                StepId = "otherJob",
                PrerequisiteStepIds = new[]
                {
                    "someJob",
                },
                PrestoJob = new Gcp.Dataproc.Inputs.WorkflowTemplateJobPrestoJobArgs
                {
                    QueryFileUri = "someuri",
                },
            },
        },
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/dataproc"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		_, err := dataproc.NewWorkflowTemplate(ctx, "template", &dataproc.WorkflowTemplateArgs{
			Name:     pulumi.String("template-example"),
			Location: pulumi.String("us-central1"),
			Placement: &dataproc.WorkflowTemplatePlacementArgs{
				ManagedCluster: &dataproc.WorkflowTemplatePlacementManagedClusterArgs{
					ClusterName: pulumi.String("my-cluster"),
					Config: &dataproc.WorkflowTemplatePlacementManagedClusterConfigArgs{
						GceClusterConfig: &dataproc.WorkflowTemplatePlacementManagedClusterConfigGceClusterConfigArgs{
							Zone: pulumi.String("us-central1-a"),
							Tags: pulumi.StringArray{
								pulumi.String("foo"),
								pulumi.String("bar"),
							},
						},
						MasterConfig: &dataproc.WorkflowTemplatePlacementManagedClusterConfigMasterConfigArgs{
							NumInstances: pulumi.Int(1),
							MachineType:  pulumi.String("n1-standard-1"),
							DiskConfig: &dataproc.WorkflowTemplatePlacementManagedClusterConfigMasterConfigDiskConfigArgs{
								BootDiskType:   pulumi.String("pd-ssd"),
								BootDiskSizeGb: pulumi.Int(15),
							},
						},
						WorkerConfig: &dataproc.WorkflowTemplatePlacementManagedClusterConfigWorkerConfigArgs{
							NumInstances: pulumi.Int(3),
							MachineType:  pulumi.String("n1-standard-2"),
							DiskConfig: &dataproc.WorkflowTemplatePlacementManagedClusterConfigWorkerConfigDiskConfigArgs{
								BootDiskSizeGb: pulumi.Int(10),
								NumLocalSsds:   pulumi.Int(2),
							},
						},
						SecondaryWorkerConfig: &dataproc.WorkflowTemplatePlacementManagedClusterConfigSecondaryWorkerConfigArgs{
							NumInstances: pulumi.Int(2),
						},
						SoftwareConfig: &dataproc.WorkflowTemplatePlacementManagedClusterConfigSoftwareConfigArgs{
							ImageVersion: pulumi.String("2.0.35-debian10"),
						},
					},
				},
			},
			Jobs: dataproc.WorkflowTemplateJobArray{
				&dataproc.WorkflowTemplateJobArgs{
					StepId: pulumi.String("someJob"),
					SparkJob: &dataproc.WorkflowTemplateJobSparkJobArgs{
						MainClass: pulumi.String("SomeClass"),
					},
				},
				&dataproc.WorkflowTemplateJobArgs{
					StepId: pulumi.String("otherJob"),
					PrerequisiteStepIds: pulumi.StringArray{
						pulumi.String("someJob"),
					},
					PrestoJob: &dataproc.WorkflowTemplateJobPrestoJobArgs{
						QueryFileUri: pulumi.String("someuri"),
					},
				},
			},
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.dataproc.WorkflowTemplate;
import com.pulumi.gcp.dataproc.WorkflowTemplateArgs;
import com.pulumi.gcp.dataproc.inputs.WorkflowTemplatePlacementArgs;
import com.pulumi.gcp.dataproc.inputs.WorkflowTemplatePlacementManagedClusterArgs;
import com.pulumi.gcp.dataproc.inputs.WorkflowTemplatePlacementManagedClusterConfigArgs;
import com.pulumi.gcp.dataproc.inputs.WorkflowTemplatePlacementManagedClusterConfigGceClusterConfigArgs;
import com.pulumi.gcp.dataproc.inputs.WorkflowTemplatePlacementManagedClusterConfigMasterConfigArgs;
import com.pulumi.gcp.dataproc.inputs.WorkflowTemplatePlacementManagedClusterConfigMasterConfigDiskConfigArgs;
import com.pulumi.gcp.dataproc.inputs.WorkflowTemplatePlacementManagedClusterConfigWorkerConfigArgs;
import com.pulumi.gcp.dataproc.inputs.WorkflowTemplatePlacementManagedClusterConfigWorkerConfigDiskConfigArgs;
import com.pulumi.gcp.dataproc.inputs.WorkflowTemplatePlacementManagedClusterConfigSecondaryWorkerConfigArgs;
import com.pulumi.gcp.dataproc.inputs.WorkflowTemplatePlacementManagedClusterConfigSoftwareConfigArgs;
import com.pulumi.gcp.dataproc.inputs.WorkflowTemplateJobArgs;
import com.pulumi.gcp.dataproc.inputs.WorkflowTemplateJobSparkJobArgs;
import com.pulumi.gcp.dataproc.inputs.WorkflowTemplateJobPrestoJobArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        var template = new WorkflowTemplate("template", WorkflowTemplateArgs.builder()
            .name("template-example")
            .location("us-central1")
            .placement(WorkflowTemplatePlacementArgs.builder()
                .managedCluster(WorkflowTemplatePlacementManagedClusterArgs.builder()
                    .clusterName("my-cluster")
                    .config(WorkflowTemplatePlacementManagedClusterConfigArgs.builder()
                        .gceClusterConfig(WorkflowTemplatePlacementManagedClusterConfigGceClusterConfigArgs.builder()
                            .zone("us-central1-a")
                            .tags(                            
                                "foo",
                                "bar")
                            .build())
                        .masterConfig(WorkflowTemplatePlacementManagedClusterConfigMasterConfigArgs.builder()
                            .numInstances(1)
                            .machineType("n1-standard-1")
                            .diskConfig(WorkflowTemplatePlacementManagedClusterConfigMasterConfigDiskConfigArgs.builder()
                                .bootDiskType("pd-ssd")
                                .bootDiskSizeGb(15)
                                .build())
                            .build())
                        .workerConfig(WorkflowTemplatePlacementManagedClusterConfigWorkerConfigArgs.builder()
                            .numInstances(3)
                            .machineType("n1-standard-2")
                            .diskConfig(WorkflowTemplatePlacementManagedClusterConfigWorkerConfigDiskConfigArgs.builder()
                                .bootDiskSizeGb(10)
                                .numLocalSsds(2)
                                .build())
                            .build())
                        .secondaryWorkerConfig(WorkflowTemplatePlacementManagedClusterConfigSecondaryWorkerConfigArgs.builder()
                            .numInstances(2)
                            .build())
                        .softwareConfig(WorkflowTemplatePlacementManagedClusterConfigSoftwareConfigArgs.builder()
                            .imageVersion("2.0.35-debian10")
                            .build())
                        .build())
                    .build())
                .build())
            .jobs(            
                WorkflowTemplateJobArgs.builder()
                    .stepId("someJob")
                    .sparkJob(WorkflowTemplateJobSparkJobArgs.builder()
                        .mainClass("SomeClass")
                        .build())
                    .build(),
                WorkflowTemplateJobArgs.builder()
                    .stepId("otherJob")
                    .prerequisiteStepIds("someJob")
                    .prestoJob(WorkflowTemplateJobPrestoJobArgs.builder()
                        .queryFileUri("someuri")
                        .build())
                    .build())
            .build());

    }
}
```
```yaml
resources:
  template:
    type: gcp:dataproc:WorkflowTemplate
    properties:
      name: template-example
      location: us-central1
      placement:
        managedCluster:
          clusterName: my-cluster
          config:
            gceClusterConfig:
              zone: us-central1-a
              tags:
                - foo
                - bar
            masterConfig:
              numInstances: 1
              machineType: n1-standard-1
              diskConfig:
                bootDiskType: pd-ssd
                bootDiskSizeGb: 15
            workerConfig:
              numInstances: 3
              machineType: n1-standard-2
              diskConfig:
                bootDiskSizeGb: 10
                numLocalSsds: 2
            secondaryWorkerConfig:
              numInstances: 2
            softwareConfig:
              imageVersion: 2.0.35-debian10
      jobs:
        - stepId: someJob
          sparkJob:
            mainClass: SomeClass
        - stepId: otherJob
          prerequisiteStepIds:
            - someJob
          prestoJob:
            queryFileUri: someuri
```
<!--End PulumiCodeChooser -->

## Import

WorkflowTemplate can be imported using any of these accepted formats:

* `projects/{{project}}/locations/{{location}}/workflowTemplates/{{name}}`

* `{{project}}/{{location}}/{{name}}`

* `{{location}}/{{name}}`

When using the `pulumi import` command, WorkflowTemplate can be imported using one of the formats above. For example:

```sh
$ pulumi import gcp:dataproc/workflowTemplate:WorkflowTemplate default projects/{{project}}/locations/{{location}}/workflowTemplates/{{name}}
```

```sh
$ pulumi import gcp:dataproc/workflowTemplate:WorkflowTemplate default {{project}}/{{location}}/{{name}}
```

```sh
$ pulumi import gcp:dataproc/workflowTemplate:WorkflowTemplate default {{location}}/{{name}}
```

ø

dagTimeoutB" ãOptional. Timeout duration for the DAG of jobs, expressed in seconds (see [JSON representation of
duration](https://developers.google.com/protocol-buffers/docs/proto3#json)). The timeout duration must be from 10
minutes ("600s") to 24 hours ("86400s"). The timer begins when the first job is submitted. If the workflow is running at
the end of the timeout period, any remaining jobs are cancelled, the workflow is ended, and if the workflow was running
on a [managed
cluster](https://www.terraform.io/dataproc/docs/concepts/workflows/using-workflows#configuring_or_selecting_a_cluster),
the cluster is deleted.

jobs[*Y:W
U
dataprocWorkflowTemplateJob4gcp:dataproc/WorkflowTemplateJob:WorkflowTemplateJob8Required. The Directed Acyclic Graph of Jobs to submit.
±
labelsB2" Optional. The labels to associate with this template. These labels will be propagated to all jobs and clusters created
by the workflow instance. Label **keys** must contain 1 to 63 characters, and must conform to [RFC
1035](https://www.ietf.org/rfc/rfc1035.txt). Label **values** may be empty, but, if present, must contain 1 to 63
characters, and must conform to [RFC 1035](https://www.ietf.org/rfc/rfc1035.txt). No more than 32 labels can be
associated with a template. **Note**: This field is non-authoritative, and will only manage the labels present in your
configuration. Please refer to the field `effective_labels` for all of the labels present on the resource.
.
location" The location for the resource
õ
nameB" æOutput only. The resource name of the workflow template, as described in https://cloud.google.com/apis/design/resource_names. * For `projects.regions.workflowTemplates`, the resource name of the template has the following format: `projects/{project_id}/regions/{region}/workflowTemplates/{template_id}` * For `projects.locations.workflowTemplates`, the resource name of the template has the following format: `projects/{project_id}/locations/{location}/workflowTemplates/{template_id}`


parametersoBm*k:i
g
dataprocWorkflowTemplateParameter@gcp:dataproc/WorkflowTemplateParameter:WorkflowTemplateParameterOptional. Template parameters whose values are substituted into the template. Values for parameters must be provided
when the template is instantiated.
­
	placementk:i
g
dataprocWorkflowTemplatePlacement@gcp:dataproc/WorkflowTemplatePlacement:WorkflowTemplatePlacement3Required. WorkflowTemplate scheduling information.
.
projectB" The project for the resource
M
versionB <Output only. The current version of this workflow template.
">

createTime" ,Output only. The time template was created.
"ø

dagTimeoutB" ãOptional. Timeout duration for the DAG of jobs, expressed in seconds (see [JSON representation of
duration](https://developers.google.com/protocol-buffers/docs/proto3#json)). The timeout duration must be from 10
minutes ("600s") to 24 hours ("86400s"). The timer begins when the first job is submitted. If the workflow is running at
the end of the timeout period, any remaining jobs are cancelled, the workflow is ended, and if the workflow was running
on a [managed
cluster](https://www.terraform.io/dataproc/docs/concepts/workflows/using-workflows#configuring_or_selecting_a_cluster),
the cluster is deleted.
"
effectiveLabels2" "
jobs[*Y:W
U
dataprocWorkflowTemplateJob4gcp:dataproc/WorkflowTemplateJob:WorkflowTemplateJob8Required. The Directed Acyclic Graph of Jobs to submit.
"±
labelsB2" Optional. The labels to associate with this template. These labels will be propagated to all jobs and clusters created
by the workflow instance. Label **keys** must contain 1 to 63 characters, and must conform to [RFC
1035](https://www.ietf.org/rfc/rfc1035.txt). Label **values** may be empty, but, if present, must contain 1 to 63
characters, and must conform to [RFC 1035](https://www.ietf.org/rfc/rfc1035.txt). No more than 32 labels can be
associated with a template. **Note**: This field is non-authoritative, and will only manage the labels present in your
configuration. Please refer to the field `effective_labels` for all of the labels present on the resource.
".
location" The location for the resource
"ó
name" æOutput only. The resource name of the workflow template, as described in https://cloud.google.com/apis/design/resource_names. * For `projects.regions.workflowTemplates`, the resource name of the template has the following format: `projects/{project_id}/regions/{region}/workflowTemplates/{template_id}` * For `projects.locations.workflowTemplates`, the resource name of the template has the following format: `projects/{project_id}/locations/{location}/workflowTemplates/{template_id}`
"

parametersoBm*k:i
g
dataprocWorkflowTemplateParameter@gcp:dataproc/WorkflowTemplateParameter:WorkflowTemplateParameterOptional. Template parameters whose values are substituted into the template. Values for parameters must be provided
when the template is instantiated.
"­
	placementk:i
g
dataprocWorkflowTemplatePlacement@gcp:dataproc/WorkflowTemplatePlacement:WorkflowTemplatePlacement3Required. WorkflowTemplate scheduling information.
",
project" The project for the resource
"
pulumiLabels2" mThe combination of labels configured directly on the resource and default labels configured on the provider.
"C

updateTime" 1Output only. The time template was last updated.
"K
version <Output only. The current version of this workflow template.
*Ê»
S

datastreamConnectionProfile2gcp:datastream/connectionProfile:ConnectionProfile¡A set of reusable connection configurations to be used as a source or destination for a stream.


To get more information about ConnectionProfile, see:

* [API documentation](https://cloud.google.com/datastream/docs/reference/rest/v1/projects.locations.connectionProfiles)
* How-to Guides
    * [Official Documentation](https://cloud.google.com/datastream/docs/create-connection-profiles)



## Example Usage

### Datastream Connection Profile Basic


<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const _default = new gcp.datastream.ConnectionProfile("default", {
    displayName: "Connection profile",
    location: "us-central1",
    connectionProfileId: "my-profile",
    gcsProfile: {
        bucket: "my-bucket",
        rootPath: "/path",
    },
});
```
```python
import pulumi
import pulumi_gcp as gcp

default = gcp.datastream.ConnectionProfile("default",
    display_name="Connection profile",
    location="us-central1",
    connection_profile_id="my-profile",
    gcs_profile={
        "bucket": "my-bucket",
        "root_path": "/path",
    })
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var @default = new Gcp.Datastream.ConnectionProfile("default", new()
    {
        DisplayName = "Connection profile",
        Location = "us-central1",
        ConnectionProfileId = "my-profile",
        GcsProfile = new Gcp.Datastream.Inputs.ConnectionProfileGcsProfileArgs
        {
            Bucket = "my-bucket",
            RootPath = "/path",
        },
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/datastream"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		_, err := datastream.NewConnectionProfile(ctx, "default", &datastream.ConnectionProfileArgs{
			DisplayName:         pulumi.String("Connection profile"),
			Location:            pulumi.String("us-central1"),
			ConnectionProfileId: pulumi.String("my-profile"),
			GcsProfile: &datastream.ConnectionProfileGcsProfileArgs{
				Bucket:   pulumi.String("my-bucket"),
				RootPath: pulumi.String("/path"),
			},
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.datastream.ConnectionProfile;
import com.pulumi.gcp.datastream.ConnectionProfileArgs;
import com.pulumi.gcp.datastream.inputs.ConnectionProfileGcsProfileArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        var default_ = new ConnectionProfile("default", ConnectionProfileArgs.builder()
            .displayName("Connection profile")
            .location("us-central1")
            .connectionProfileId("my-profile")
            .gcsProfile(ConnectionProfileGcsProfileArgs.builder()
                .bucket("my-bucket")
                .rootPath("/path")
                .build())
            .build());

    }
}
```
```yaml
resources:
  default:
    type: gcp:datastream:ConnectionProfile
    properties:
      displayName: Connection profile
      location: us-central1
      connectionProfileId: my-profile
      gcsProfile:
        bucket: my-bucket
        rootPath: /path
```
<!--End PulumiCodeChooser -->
### Datastream Connection Profile Postgresql Private Connection


<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";
import * as random from "@pulumi/random";

const _default = new gcp.compute.Network("default", {name: "my-network"});
const privateConnection = new gcp.datastream.PrivateConnection("private_connection", {
    displayName: "Connection profile",
    location: "us-central1",
    privateConnectionId: "my-connection",
    labels: {
        key: "value",
    },
    vpcPeeringConfig: {
        vpc: _default.id,
        subnet: "10.0.0.0/29",
    },
});
const instance = new gcp.sql.DatabaseInstance("instance", {
    name: "my-instance",
    databaseVersion: "POSTGRES_14",
    region: "us-central1",
    settings: {
        tier: "db-f1-micro",
        ipConfiguration: {
            authorizedNetworks: [
                {
                    value: "34.71.242.81",
                },
                {
                    value: "34.72.28.29",
                },
                {
                    value: "34.67.6.157",
                },
                {
                    value: "34.67.234.134",
                },
                {
                    value: "34.72.239.218",
                },
            ],
        },
    },
    deletionProtection: true,
});
const db = new gcp.sql.Database("db", {
    instance: instance.name,
    name: "db",
});
const pwd = new random.RandomPassword("pwd", {
    length: 16,
    special: false,
});
const user = new gcp.sql.User("user", {
    name: "user",
    instance: instance.name,
    password: pwd.result,
});
const defaultConnectionProfile = new gcp.datastream.ConnectionProfile("default", {
    displayName: "Connection profile",
    location: "us-central1",
    connectionProfileId: "my-profile",
    postgresqlProfile: {
        hostname: instance.publicIpAddress,
        username: user.name,
        password: user.password,
        database: db.name,
    },
    privateConnectivity: {
        privateConnection: privateConnection.id,
    },
});
```
```python
import pulumi
import pulumi_gcp as gcp
import pulumi_random as random

default = gcp.compute.Network("default", name="my-network")
private_connection = gcp.datastream.PrivateConnection("private_connection",
    display_name="Connection profile",
    location="us-central1",
    private_connection_id="my-connection",
    labels={
        "key": "value",
    },
    vpc_peering_config={
        "vpc": default.id,
        "subnet": "10.0.0.0/29",
    })
instance = gcp.sql.DatabaseInstance("instance",
    name="my-instance",
    database_version="POSTGRES_14",
    region="us-central1",
    settings={
        "tier": "db-f1-micro",
        "ip_configuration": {
            "authorized_networks": [
                {
                    "value": "34.71.242.81",
                },
                {
                    "value": "34.72.28.29",
                },
                {
                    "value": "34.67.6.157",
                },
                {
                    "value": "34.67.234.134",
                },
                {
                    "value": "34.72.239.218",
                },
            ],
        },
    },
    deletion_protection=True)
db = gcp.sql.Database("db",
    instance=instance.name,
    name="db")
pwd = random.RandomPassword("pwd",
    length=16,
    special=False)
user = gcp.sql.User("user",
    name="user",
    instance=instance.name,
    password=pwd.result)
default_connection_profile = gcp.datastream.ConnectionProfile("default",
    display_name="Connection profile",
    location="us-central1",
    connection_profile_id="my-profile",
    postgresql_profile={
        "hostname": instance.public_ip_address,
        "username": user.name,
        "password": user.password,
        "database": db.name,
    },
    private_connectivity={
        "private_connection": private_connection.id,
    })
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;
using Random = Pulumi.Random;

return await Deployment.RunAsync(() => 
{
    var @default = new Gcp.Compute.Network("default", new()
    {
        Name = "my-network",
    });

    var privateConnection = new Gcp.Datastream.PrivateConnection("private_connection", new()
    {
        DisplayName = "Connection profile",
        Location = "us-central1",
        PrivateConnectionId = "my-connection",
        Labels = 
        {
            { "key", "value" },
        },
        VpcPeeringConfig = new Gcp.Datastream.Inputs.PrivateConnectionVpcPeeringConfigArgs
        {
            Vpc = @default.Id,
            Subnet = "10.0.0.0/29",
        },
    });

    var instance = new Gcp.Sql.DatabaseInstance("instance", new()
    {
        Name = "my-instance",
        DatabaseVersion = "POSTGRES_14",
        Region = "us-central1",
        Settings = new Gcp.Sql.Inputs.DatabaseInstanceSettingsArgs
        {
            Tier = "db-f1-micro",
            IpConfiguration = new Gcp.Sql.Inputs.DatabaseInstanceSettingsIpConfigurationArgs
            {
                AuthorizedNetworks = new[]
                {
                    new Gcp.Sql.Inputs.DatabaseInstanceSettingsIpConfigurationAuthorizedNetworkArgs
                    {
                        Value = "34.71.242.81",
                    },
                    new Gcp.Sql.Inputs.DatabaseInstanceSettingsIpConfigurationAuthorizedNetworkArgs
                    {
                        Value = "34.72.28.29",
                    },
                    new Gcp.Sql.Inputs.DatabaseInstanceSettingsIpConfigurationAuthorizedNetworkArgs
                    {
                        Value = "34.67.6.157",
                    },
                    new Gcp.Sql.Inputs.DatabaseInstanceSettingsIpConfigurationAuthorizedNetworkArgs
                    {
                        Value = "34.67.234.134",
                    },
                    new Gcp.Sql.Inputs.DatabaseInstanceSettingsIpConfigurationAuthorizedNetworkArgs
                    {
                        Value = "34.72.239.218",
                    },
                },
            },
        },
        DeletionProtection = true,
    });

    var db = new Gcp.Sql.Database("db", new()
    {
        Instance = instance.Name,
        Name = "db",
    });

    var pwd = new Random.RandomPassword("pwd", new()
    {
        Length = 16,
        Special = false,
    });

    var user = new Gcp.Sql.User("user", new()
    {
        Name = "user",
        Instance = instance.Name,
        Password = pwd.Result,
    });

    var defaultConnectionProfile = new Gcp.Datastream.ConnectionProfile("default", new()
    {
        DisplayName = "Connection profile",
        Location = "us-central1",
        ConnectionProfileId = "my-profile",
        PostgresqlProfile = new Gcp.Datastream.Inputs.ConnectionProfilePostgresqlProfileArgs
        {
            Hostname = instance.PublicIpAddress,
            Username = user.Name,
            Password = user.Password,
            Database = db.Name,
        },
        PrivateConnectivity = new Gcp.Datastream.Inputs.ConnectionProfilePrivateConnectivityArgs
        {
            PrivateConnection = privateConnection.Id,
        },
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/compute"
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/datastream"
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/sql"
	"github.com/pulumi/pulumi-random/sdk/v4/go/random"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		_, err := compute.NewNetwork(ctx, "default", &compute.NetworkArgs{
			Name: pulumi.String("my-network"),
		})
		if err != nil {
			return err
		}
		privateConnection, err := datastream.NewPrivateConnection(ctx, "private_connection", &datastream.PrivateConnectionArgs{
			DisplayName:         pulumi.String("Connection profile"),
			Location:            pulumi.String("us-central1"),
			PrivateConnectionId: pulumi.String("my-connection"),
			Labels: pulumi.StringMap{
				"key": pulumi.String("value"),
			},
			VpcPeeringConfig: &datastream.PrivateConnectionVpcPeeringConfigArgs{
				Vpc:    _default.ID(),
				Subnet: pulumi.String("10.0.0.0/29"),
			},
		})
		if err != nil {
			return err
		}
		instance, err := sql.NewDatabaseInstance(ctx, "instance", &sql.DatabaseInstanceArgs{
			Name:            pulumi.String("my-instance"),
			DatabaseVersion: pulumi.String("POSTGRES_14"),
			Region:          pulumi.String("us-central1"),
			Settings: &sql.DatabaseInstanceSettingsArgs{
				Tier: pulumi.String("db-f1-micro"),
				IpConfiguration: &sql.DatabaseInstanceSettingsIpConfigurationArgs{
					AuthorizedNetworks: sql.DatabaseInstanceSettingsIpConfigurationAuthorizedNetworkArray{
						&sql.DatabaseInstanceSettingsIpConfigurationAuthorizedNetworkArgs{
							Value: pulumi.String("34.71.242.81"),
						},
						&sql.DatabaseInstanceSettingsIpConfigurationAuthorizedNetworkArgs{
							Value: pulumi.String("34.72.28.29"),
						},
						&sql.DatabaseInstanceSettingsIpConfigurationAuthorizedNetworkArgs{
							Value: pulumi.String("34.67.6.157"),
						},
						&sql.DatabaseInstanceSettingsIpConfigurationAuthorizedNetworkArgs{
							Value: pulumi.String("34.67.234.134"),
						},
						&sql.DatabaseInstanceSettingsIpConfigurationAuthorizedNetworkArgs{
							Value: pulumi.String("34.72.239.218"),
						},
					},
				},
			},
			DeletionProtection: pulumi.Bool(true),
		})
		if err != nil {
			return err
		}
		db, err := sql.NewDatabase(ctx, "db", &sql.DatabaseArgs{
			Instance: instance.Name,
			Name:     pulumi.String("db"),
		})
		if err != nil {
			return err
		}
		pwd, err := random.NewRandomPassword(ctx, "pwd", &random.RandomPasswordArgs{
			Length:  pulumi.Int(16),
			Special: pulumi.Bool(false),
		})
		if err != nil {
			return err
		}
		user, err := sql.NewUser(ctx, "user", &sql.UserArgs{
			Name:     pulumi.String("user"),
			Instance: instance.Name,
			Password: pwd.Result,
		})
		if err != nil {
			return err
		}
		_, err = datastream.NewConnectionProfile(ctx, "default", &datastream.ConnectionProfileArgs{
			DisplayName:         pulumi.String("Connection profile"),
			Location:            pulumi.String("us-central1"),
			ConnectionProfileId: pulumi.String("my-profile"),
			PostgresqlProfile: &datastream.ConnectionProfilePostgresqlProfileArgs{
				Hostname: instance.PublicIpAddress,
				Username: user.Name,
				Password: user.Password,
				Database: db.Name,
			},
			PrivateConnectivity: &datastream.ConnectionProfilePrivateConnectivityArgs{
				PrivateConnection: privateConnection.ID(),
			},
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.compute.Network;
import com.pulumi.gcp.compute.NetworkArgs;
import com.pulumi.gcp.datastream.PrivateConnection;
import com.pulumi.gcp.datastream.PrivateConnectionArgs;
import com.pulumi.gcp.datastream.inputs.PrivateConnectionVpcPeeringConfigArgs;
import com.pulumi.gcp.sql.DatabaseInstance;
import com.pulumi.gcp.sql.DatabaseInstanceArgs;
import com.pulumi.gcp.sql.inputs.DatabaseInstanceSettingsArgs;
import com.pulumi.gcp.sql.inputs.DatabaseInstanceSettingsIpConfigurationArgs;
import com.pulumi.gcp.sql.Database;
import com.pulumi.gcp.sql.DatabaseArgs;
import com.pulumi.random.RandomPassword;
import com.pulumi.random.RandomPasswordArgs;
import com.pulumi.gcp.sql.User;
import com.pulumi.gcp.sql.UserArgs;
import com.pulumi.gcp.datastream.ConnectionProfile;
import com.pulumi.gcp.datastream.ConnectionProfileArgs;
import com.pulumi.gcp.datastream.inputs.ConnectionProfilePostgresqlProfileArgs;
import com.pulumi.gcp.datastream.inputs.ConnectionProfilePrivateConnectivityArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        var default_ = new Network("default", NetworkArgs.builder()
            .name("my-network")
            .build());

        var privateConnection = new PrivateConnection("privateConnection", PrivateConnectionArgs.builder()
            .displayName("Connection profile")
            .location("us-central1")
            .privateConnectionId("my-connection")
            .labels(Map.of("key", "value"))
            .vpcPeeringConfig(PrivateConnectionVpcPeeringConfigArgs.builder()
                .vpc(default_.id())
                .subnet("10.0.0.0/29")
                .build())
            .build());

        var instance = new DatabaseInstance("instance", DatabaseInstanceArgs.builder()
            .name("my-instance")
            .databaseVersion("POSTGRES_14")
            .region("us-central1")
            .settings(DatabaseInstanceSettingsArgs.builder()
                .tier("db-f1-micro")
                .ipConfiguration(DatabaseInstanceSettingsIpConfigurationArgs.builder()
                    .authorizedNetworks(                    
                        DatabaseInstanceSettingsIpConfigurationAuthorizedNetworkArgs.builder()
                            .value("34.71.242.81")
                            .build(),
                        DatabaseInstanceSettingsIpConfigurationAuthorizedNetworkArgs.builder()
                            .value("34.72.28.29")
                            .build(),
                        DatabaseInstanceSettingsIpConfigurationAuthorizedNetworkArgs.builder()
                            .value("34.67.6.157")
                            .build(),
                        DatabaseInstanceSettingsIpConfigurationAuthorizedNetworkArgs.builder()
                            .value("34.67.234.134")
                            .build(),
                        DatabaseInstanceSettingsIpConfigurationAuthorizedNetworkArgs.builder()
                            .value("34.72.239.218")
                            .build())
                    .build())
                .build())
            .deletionProtection(true)
            .build());

        var db = new Database("db", DatabaseArgs.builder()
            .instance(instance.name())
            .name("db")
            .build());

        var pwd = new RandomPassword("pwd", RandomPasswordArgs.builder()
            .length(16)
            .special(false)
            .build());

        var user = new User("user", UserArgs.builder()
            .name("user")
            .instance(instance.name())
            .password(pwd.result())
            .build());

        var defaultConnectionProfile = new ConnectionProfile("defaultConnectionProfile", ConnectionProfileArgs.builder()
            .displayName("Connection profile")
            .location("us-central1")
            .connectionProfileId("my-profile")
            .postgresqlProfile(ConnectionProfilePostgresqlProfileArgs.builder()
                .hostname(instance.publicIpAddress())
                .username(user.name())
                .password(user.password())
                .database(db.name())
                .build())
            .privateConnectivity(ConnectionProfilePrivateConnectivityArgs.builder()
                .privateConnection(privateConnection.id())
                .build())
            .build());

    }
}
```
```yaml
resources:
  privateConnection:
    type: gcp:datastream:PrivateConnection
    name: private_connection
    properties:
      displayName: Connection profile
      location: us-central1
      privateConnectionId: my-connection
      labels:
        key: value
      vpcPeeringConfig:
        vpc: ${default.id}
        subnet: 10.0.0.0/29
  default:
    type: gcp:compute:Network
    properties:
      name: my-network
  instance:
    type: gcp:sql:DatabaseInstance
    properties:
      name: my-instance
      databaseVersion: POSTGRES_14
      region: us-central1
      settings:
        tier: db-f1-micro
        ipConfiguration:
          authorizedNetworks:
            - value: 34.71.242.81
            - value: 34.72.28.29
            - value: 34.67.6.157
            - value: 34.67.234.134
            - value: 34.72.239.218
      deletionProtection: true
  db:
    type: gcp:sql:Database
    properties:
      instance: ${instance.name}
      name: db
  pwd:
    type: random:RandomPassword
    properties:
      length: 16
      special: false
  user:
    type: gcp:sql:User
    properties:
      name: user
      instance: ${instance.name}
      password: ${pwd.result}
  defaultConnectionProfile:
    type: gcp:datastream:ConnectionProfile
    name: default
    properties:
      displayName: Connection profile
      location: us-central1
      connectionProfileId: my-profile
      postgresqlProfile:
        hostname: ${instance.publicIpAddress}
        username: ${user.name}
        password: ${user.password}
        database: ${db.name}
      privateConnectivity:
        privateConnection: ${privateConnection.id}
```
<!--End PulumiCodeChooser -->
### Datastream Connection Profile Full


<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const _default = new gcp.datastream.ConnectionProfile("default", {
    displayName: "Connection profile",
    location: "us-central1",
    connectionProfileId: "my-profile",
    gcsProfile: {
        bucket: "my-bucket",
        rootPath: "/path",
    },
    forwardSshConnectivity: {
        hostname: "google.com",
        username: "my-user",
        port: 8022,
        password: "swordfish",
    },
    labels: {
        key: "value",
    },
});
```
```python
import pulumi
import pulumi_gcp as gcp

default = gcp.datastream.ConnectionProfile("default",
    display_name="Connection profile",
    location="us-central1",
    connection_profile_id="my-profile",
    gcs_profile={
        "bucket": "my-bucket",
        "root_path": "/path",
    },
    forward_ssh_connectivity={
        "hostname": "google.com",
        "username": "my-user",
        "port": 8022,
        "password": "swordfish",
    },
    labels={
        "key": "value",
    })
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var @default = new Gcp.Datastream.ConnectionProfile("default", new()
    {
        DisplayName = "Connection profile",
        Location = "us-central1",
        ConnectionProfileId = "my-profile",
        GcsProfile = new Gcp.Datastream.Inputs.ConnectionProfileGcsProfileArgs
        {
            Bucket = "my-bucket",
            RootPath = "/path",
        },
        ForwardSshConnectivity = new Gcp.Datastream.Inputs.ConnectionProfileForwardSshConnectivityArgs
        {
            Hostname = "google.com",
            Username = "my-user",
            Port = 8022,
            Password = "swordfish",
        },
        Labels = 
        {
            { "key", "value" },
        },
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/datastream"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		_, err := datastream.NewConnectionProfile(ctx, "default", &datastream.ConnectionProfileArgs{
			DisplayName:         pulumi.String("Connection profile"),
			Location:            pulumi.String("us-central1"),
			ConnectionProfileId: pulumi.String("my-profile"),
			GcsProfile: &datastream.ConnectionProfileGcsProfileArgs{
				Bucket:   pulumi.String("my-bucket"),
				RootPath: pulumi.String("/path"),
			},
			ForwardSshConnectivity: &datastream.ConnectionProfileForwardSshConnectivityArgs{
				Hostname: pulumi.String("google.com"),
				Username: pulumi.String("my-user"),
				Port:     pulumi.Int(8022),
				Password: pulumi.String("swordfish"),
			},
			Labels: pulumi.StringMap{
				"key": pulumi.String("value"),
			},
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.datastream.ConnectionProfile;
import com.pulumi.gcp.datastream.ConnectionProfileArgs;
import com.pulumi.gcp.datastream.inputs.ConnectionProfileGcsProfileArgs;
import com.pulumi.gcp.datastream.inputs.ConnectionProfileForwardSshConnectivityArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        var default_ = new ConnectionProfile("default", ConnectionProfileArgs.builder()
            .displayName("Connection profile")
            .location("us-central1")
            .connectionProfileId("my-profile")
            .gcsProfile(ConnectionProfileGcsProfileArgs.builder()
                .bucket("my-bucket")
                .rootPath("/path")
                .build())
            .forwardSshConnectivity(ConnectionProfileForwardSshConnectivityArgs.builder()
                .hostname("google.com")
                .username("my-user")
                .port(8022)
                .password("swordfish")
                .build())
            .labels(Map.of("key", "value"))
            .build());

    }
}
```
```yaml
resources:
  default:
    type: gcp:datastream:ConnectionProfile
    properties:
      displayName: Connection profile
      location: us-central1
      connectionProfileId: my-profile
      gcsProfile:
        bucket: my-bucket
        rootPath: /path
      forwardSshConnectivity:
        hostname: google.com
        username: my-user
        port: 8022
        password: swordfish
      labels:
        key: value
```
<!--End PulumiCodeChooser -->
### Datastream Connection Profile Postgres


<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";
import * as random from "@pulumi/random";

const instance = new gcp.sql.DatabaseInstance("instance", {
    name: "my-instance",
    databaseVersion: "POSTGRES_14",
    region: "us-central1",
    settings: {
        tier: "db-f1-micro",
        ipConfiguration: {
            authorizedNetworks: [
                {
                    value: "34.71.242.81",
                },
                {
                    value: "34.72.28.29",
                },
                {
                    value: "34.67.6.157",
                },
                {
                    value: "34.67.234.134",
                },
                {
                    value: "34.72.239.218",
                },
            ],
        },
    },
    deletionProtection: true,
});
const db = new gcp.sql.Database("db", {
    instance: instance.name,
    name: "db",
});
const pwd = new random.RandomPassword("pwd", {
    length: 16,
    special: false,
});
const user = new gcp.sql.User("user", {
    name: "user",
    instance: instance.name,
    password: pwd.result,
});
const _default = new gcp.datastream.ConnectionProfile("default", {
    displayName: "Connection profile",
    location: "us-central1",
    connectionProfileId: "my-profile",
    postgresqlProfile: {
        hostname: instance.publicIpAddress,
        username: user.name,
        password: user.password,
        database: db.name,
    },
});
```
```python
import pulumi
import pulumi_gcp as gcp
import pulumi_random as random

instance = gcp.sql.DatabaseInstance("instance",
    name="my-instance",
    database_version="POSTGRES_14",
    region="us-central1",
    settings={
        "tier": "db-f1-micro",
        "ip_configuration": {
            "authorized_networks": [
                {
                    "value": "34.71.242.81",
                },
                {
                    "value": "34.72.28.29",
                },
                {
                    "value": "34.67.6.157",
                },
                {
                    "value": "34.67.234.134",
                },
                {
                    "value": "34.72.239.218",
                },
            ],
        },
    },
    deletion_protection=True)
db = gcp.sql.Database("db",
    instance=instance.name,
    name="db")
pwd = random.RandomPassword("pwd",
    length=16,
    special=False)
user = gcp.sql.User("user",
    name="user",
    instance=instance.name,
    password=pwd.result)
default = gcp.datastream.ConnectionProfile("default",
    display_name="Connection profile",
    location="us-central1",
    connection_profile_id="my-profile",
    postgresql_profile={
        "hostname": instance.public_ip_address,
        "username": user.name,
        "password": user.password,
        "database": db.name,
    })
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;
using Random = Pulumi.Random;

return await Deployment.RunAsync(() => 
{
    var instance = new Gcp.Sql.DatabaseInstance("instance", new()
    {
        Name = "my-instance",
        DatabaseVersion = "POSTGRES_14",
        Region = "us-central1",
        Settings = new Gcp.Sql.Inputs.DatabaseInstanceSettingsArgs
        {
            Tier = "db-f1-micro",
            IpConfiguration = new Gcp.Sql.Inputs.DatabaseInstanceSettingsIpConfigurationArgs
            {
                AuthorizedNetworks = new[]
                {
                    new Gcp.Sql.Inputs.DatabaseInstanceSettingsIpConfigurationAuthorizedNetworkArgs
                    {
                        Value = "34.71.242.81",
                    },
                    new Gcp.Sql.Inputs.DatabaseInstanceSettingsIpConfigurationAuthorizedNetworkArgs
                    {
                        Value = "34.72.28.29",
                    },
                    new Gcp.Sql.Inputs.DatabaseInstanceSettingsIpConfigurationAuthorizedNetworkArgs
                    {
                        Value = "34.67.6.157",
                    },
                    new Gcp.Sql.Inputs.DatabaseInstanceSettingsIpConfigurationAuthorizedNetworkArgs
                    {
                        Value = "34.67.234.134",
                    },
                    new Gcp.Sql.Inputs.DatabaseInstanceSettingsIpConfigurationAuthorizedNetworkArgs
                    {
                        Value = "34.72.239.218",
                    },
                },
            },
        },
        DeletionProtection = true,
    });

    var db = new Gcp.Sql.Database("db", new()
    {
        Instance = instance.Name,
        Name = "db",
    });

    var pwd = new Random.RandomPassword("pwd", new()
    {
        Length = 16,
        Special = false,
    });

    var user = new Gcp.Sql.User("user", new()
    {
        Name = "user",
        Instance = instance.Name,
        Password = pwd.Result,
    });

    var @default = new Gcp.Datastream.ConnectionProfile("default", new()
    {
        DisplayName = "Connection profile",
        Location = "us-central1",
        ConnectionProfileId = "my-profile",
        PostgresqlProfile = new Gcp.Datastream.Inputs.ConnectionProfilePostgresqlProfileArgs
        {
            Hostname = instance.PublicIpAddress,
            Username = user.Name,
            Password = user.Password,
            Database = db.Name,
        },
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/datastream"
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/sql"
	"github.com/pulumi/pulumi-random/sdk/v4/go/random"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		instance, err := sql.NewDatabaseInstance(ctx, "instance", &sql.DatabaseInstanceArgs{
			Name:            pulumi.String("my-instance"),
			DatabaseVersion: pulumi.String("POSTGRES_14"),
			Region:          pulumi.String("us-central1"),
			Settings: &sql.DatabaseInstanceSettingsArgs{
				Tier: pulumi.String("db-f1-micro"),
				IpConfiguration: &sql.DatabaseInstanceSettingsIpConfigurationArgs{
					AuthorizedNetworks: sql.DatabaseInstanceSettingsIpConfigurationAuthorizedNetworkArray{
						&sql.DatabaseInstanceSettingsIpConfigurationAuthorizedNetworkArgs{
							Value: pulumi.String("34.71.242.81"),
						},
						&sql.DatabaseInstanceSettingsIpConfigurationAuthorizedNetworkArgs{
							Value: pulumi.String("34.72.28.29"),
						},
						&sql.DatabaseInstanceSettingsIpConfigurationAuthorizedNetworkArgs{
							Value: pulumi.String("34.67.6.157"),
						},
						&sql.DatabaseInstanceSettingsIpConfigurationAuthorizedNetworkArgs{
							Value: pulumi.String("34.67.234.134"),
						},
						&sql.DatabaseInstanceSettingsIpConfigurationAuthorizedNetworkArgs{
							Value: pulumi.String("34.72.239.218"),
						},
					},
				},
			},
			DeletionProtection: pulumi.Bool(true),
		})
		if err != nil {
			return err
		}
		db, err := sql.NewDatabase(ctx, "db", &sql.DatabaseArgs{
			Instance: instance.Name,
			Name:     pulumi.String("db"),
		})
		if err != nil {
			return err
		}
		pwd, err := random.NewRandomPassword(ctx, "pwd", &random.RandomPasswordArgs{
			Length:  pulumi.Int(16),
			Special: pulumi.Bool(false),
		})
		if err != nil {
			return err
		}
		user, err := sql.NewUser(ctx, "user", &sql.UserArgs{
			Name:     pulumi.String("user"),
			Instance: instance.Name,
			Password: pwd.Result,
		})
		if err != nil {
			return err
		}
		_, err = datastream.NewConnectionProfile(ctx, "default", &datastream.ConnectionProfileArgs{
			DisplayName:         pulumi.String("Connection profile"),
			Location:            pulumi.String("us-central1"),
			ConnectionProfileId: pulumi.String("my-profile"),
			PostgresqlProfile: &datastream.ConnectionProfilePostgresqlProfileArgs{
				Hostname: instance.PublicIpAddress,
				Username: user.Name,
				Password: user.Password,
				Database: db.Name,
			},
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.sql.DatabaseInstance;
import com.pulumi.gcp.sql.DatabaseInstanceArgs;
import com.pulumi.gcp.sql.inputs.DatabaseInstanceSettingsArgs;
import com.pulumi.gcp.sql.inputs.DatabaseInstanceSettingsIpConfigurationArgs;
import com.pulumi.gcp.sql.Database;
import com.pulumi.gcp.sql.DatabaseArgs;
import com.pulumi.random.RandomPassword;
import com.pulumi.random.RandomPasswordArgs;
import com.pulumi.gcp.sql.User;
import com.pulumi.gcp.sql.UserArgs;
import com.pulumi.gcp.datastream.ConnectionProfile;
import com.pulumi.gcp.datastream.ConnectionProfileArgs;
import com.pulumi.gcp.datastream.inputs.ConnectionProfilePostgresqlProfileArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        var instance = new DatabaseInstance("instance", DatabaseInstanceArgs.builder()
            .name("my-instance")
            .databaseVersion("POSTGRES_14")
            .region("us-central1")
            .settings(DatabaseInstanceSettingsArgs.builder()
                .tier("db-f1-micro")
                .ipConfiguration(DatabaseInstanceSettingsIpConfigurationArgs.builder()
                    .authorizedNetworks(                    
                        DatabaseInstanceSettingsIpConfigurationAuthorizedNetworkArgs.builder()
                            .value("34.71.242.81")
                            .build(),
                        DatabaseInstanceSettingsIpConfigurationAuthorizedNetworkArgs.builder()
                            .value("34.72.28.29")
                            .build(),
                        DatabaseInstanceSettingsIpConfigurationAuthorizedNetworkArgs.builder()
                            .value("34.67.6.157")
                            .build(),
                        DatabaseInstanceSettingsIpConfigurationAuthorizedNetworkArgs.builder()
                            .value("34.67.234.134")
                            .build(),
                        DatabaseInstanceSettingsIpConfigurationAuthorizedNetworkArgs.builder()
                            .value("34.72.239.218")
                            .build())
                    .build())
                .build())
            .deletionProtection(true)
            .build());

        var db = new Database("db", DatabaseArgs.builder()
            .instance(instance.name())
            .name("db")
            .build());

        var pwd = new RandomPassword("pwd", RandomPasswordArgs.builder()
            .length(16)
            .special(false)
            .build());

        var user = new User("user", UserArgs.builder()
            .name("user")
            .instance(instance.name())
            .password(pwd.result())
            .build());

        var default_ = new ConnectionProfile("default", ConnectionProfileArgs.builder()
            .displayName("Connection profile")
            .location("us-central1")
            .connectionProfileId("my-profile")
            .postgresqlProfile(ConnectionProfilePostgresqlProfileArgs.builder()
                .hostname(instance.publicIpAddress())
                .username(user.name())
                .password(user.password())
                .database(db.name())
                .build())
            .build());

    }
}
```
```yaml
resources:
  instance:
    type: gcp:sql:DatabaseInstance
    properties:
      name: my-instance
      databaseVersion: POSTGRES_14
      region: us-central1
      settings:
        tier: db-f1-micro
        ipConfiguration:
          authorizedNetworks:
            - value: 34.71.242.81
            - value: 34.72.28.29
            - value: 34.67.6.157
            - value: 34.67.234.134
            - value: 34.72.239.218
      deletionProtection: true
  db:
    type: gcp:sql:Database
    properties:
      instance: ${instance.name}
      name: db
  pwd:
    type: random:RandomPassword
    properties:
      length: 16
      special: false
  user:
    type: gcp:sql:User
    properties:
      name: user
      instance: ${instance.name}
      password: ${pwd.result}
  default:
    type: gcp:datastream:ConnectionProfile
    properties:
      displayName: Connection profile
      location: us-central1
      connectionProfileId: my-profile
      postgresqlProfile:
        hostname: ${instance.publicIpAddress}
        username: ${user.name}
        password: ${user.password}
        database: ${db.name}
```
<!--End PulumiCodeChooser -->
### Datastream Connection Profile Sql Server


<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const instance = new gcp.sql.DatabaseInstance("instance", {
    name: "sql-server",
    databaseVersion: "SQLSERVER_2019_STANDARD",
    region: "us-central1",
    rootPassword: "root-password",
    deletionProtection: true,
    settings: {
        tier: "db-custom-2-4096",
        ipConfiguration: {
            authorizedNetworks: [
                {
                    value: "34.71.242.81",
                },
                {
                    value: "34.72.28.29",
                },
                {
                    value: "34.67.6.157",
                },
                {
                    value: "34.67.234.134",
                },
                {
                    value: "34.72.239.218",
                },
            ],
        },
    },
});
const db = new gcp.sql.Database("db", {
    name: "db",
    instance: instance.name,
});
const user = new gcp.sql.User("user", {
    name: "user",
    instance: instance.name,
    password: "password",
});
const _default = new gcp.datastream.ConnectionProfile("default", {
    displayName: "SQL Server Source",
    location: "us-central1",
    connectionProfileId: "source-profile",
    sqlServerProfile: {
        hostname: instance.publicIpAddress,
        port: 1433,
        username: user.name,
        password: user.password,
        database: db.name,
    },
});
```
```python
import pulumi
import pulumi_gcp as gcp

instance = gcp.sql.DatabaseInstance("instance",
    name="sql-server",
    database_version="SQLSERVER_2019_STANDARD",
    region="us-central1",
    root_password="root-password",
    deletion_protection=True,
    settings={
        "tier": "db-custom-2-4096",
        "ip_configuration": {
            "authorized_networks": [
                {
                    "value": "34.71.242.81",
                },
                {
                    "value": "34.72.28.29",
                },
                {
                    "value": "34.67.6.157",
                },
                {
                    "value": "34.67.234.134",
                },
                {
                    "value": "34.72.239.218",
                },
            ],
        },
    })
db = gcp.sql.Database("db",
    name="db",
    instance=instance.name)
user = gcp.sql.User("user",
    name="user",
    instance=instance.name,
    password="password")
default = gcp.datastream.ConnectionProfile("default",
    display_name="SQL Server Source",
    location="us-central1",
    connection_profile_id="source-profile",
    sql_server_profile={
        "hostname": instance.public_ip_address,
        "port": 1433,
        "username": user.name,
        "password": user.password,
        "database": db.name,
    })
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var instance = new Gcp.Sql.DatabaseInstance("instance", new()
    {
        Name = "sql-server",
        DatabaseVersion = "SQLSERVER_2019_STANDARD",
        Region = "us-central1",
        RootPassword = "root-password",
        DeletionProtection = true,
        Settings = new Gcp.Sql.Inputs.DatabaseInstanceSettingsArgs
        {
            Tier = "db-custom-2-4096",
            IpConfiguration = new Gcp.Sql.Inputs.DatabaseInstanceSettingsIpConfigurationArgs
            {
                AuthorizedNetworks = new[]
                {
                    new Gcp.Sql.Inputs.DatabaseInstanceSettingsIpConfigurationAuthorizedNetworkArgs
                    {
                        Value = "34.71.242.81",
                    },
                    new Gcp.Sql.Inputs.DatabaseInstanceSettingsIpConfigurationAuthorizedNetworkArgs
                    {
                        Value = "34.72.28.29",
                    },
                    new Gcp.Sql.Inputs.DatabaseInstanceSettingsIpConfigurationAuthorizedNetworkArgs
                    {
                        Value = "34.67.6.157",
                    },
                    new Gcp.Sql.Inputs.DatabaseInstanceSettingsIpConfigurationAuthorizedNetworkArgs
                    {
                        Value = "34.67.234.134",
                    },
                    new Gcp.Sql.Inputs.DatabaseInstanceSettingsIpConfigurationAuthorizedNetworkArgs
                    {
                        Value = "34.72.239.218",
                    },
                },
            },
        },
    });

    var db = new Gcp.Sql.Database("db", new()
    {
        Name = "db",
        Instance = instance.Name,
    });

    var user = new Gcp.Sql.User("user", new()
    {
        Name = "user",
        Instance = instance.Name,
        Password = "password",
    });

    var @default = new Gcp.Datastream.ConnectionProfile("default", new()
    {
        DisplayName = "SQL Server Source",
        Location = "us-central1",
        ConnectionProfileId = "source-profile",
        SqlServerProfile = new Gcp.Datastream.Inputs.ConnectionProfileSqlServerProfileArgs
        {
            Hostname = instance.PublicIpAddress,
            Port = 1433,
            Username = user.Name,
            Password = user.Password,
            Database = db.Name,
        },
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/datastream"
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/sql"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		instance, err := sql.NewDatabaseInstance(ctx, "instance", &sql.DatabaseInstanceArgs{
			Name:               pulumi.String("sql-server"),
			DatabaseVersion:    pulumi.String("SQLSERVER_2019_STANDARD"),
			Region:             pulumi.String("us-central1"),
			RootPassword:       pulumi.String("root-password"),
			DeletionProtection: pulumi.Bool(true),
			Settings: &sql.DatabaseInstanceSettingsArgs{
				Tier: pulumi.String("db-custom-2-4096"),
				IpConfiguration: &sql.DatabaseInstanceSettingsIpConfigurationArgs{
					AuthorizedNetworks: sql.DatabaseInstanceSettingsIpConfigurationAuthorizedNetworkArray{
						&sql.DatabaseInstanceSettingsIpConfigurationAuthorizedNetworkArgs{
							Value: pulumi.String("34.71.242.81"),
						},
						&sql.DatabaseInstanceSettingsIpConfigurationAuthorizedNetworkArgs{
							Value: pulumi.String("34.72.28.29"),
						},
						&sql.DatabaseInstanceSettingsIpConfigurationAuthorizedNetworkArgs{
							Value: pulumi.String("34.67.6.157"),
						},
						&sql.DatabaseInstanceSettingsIpConfigurationAuthorizedNetworkArgs{
							Value: pulumi.String("34.67.234.134"),
						},
						&sql.DatabaseInstanceSettingsIpConfigurationAuthorizedNetworkArgs{
							Value: pulumi.String("34.72.239.218"),
						},
					},
				},
			},
		})
		if err != nil {
			return err
		}
		db, err := sql.NewDatabase(ctx, "db", &sql.DatabaseArgs{
			Name:     pulumi.String("db"),
			Instance: instance.Name,
		})
		if err != nil {
			return err
		}
		user, err := sql.NewUser(ctx, "user", &sql.UserArgs{
			Name:     pulumi.String("user"),
			Instance: instance.Name,
			Password: pulumi.String("password"),
		})
		if err != nil {
			return err
		}
		_, err = datastream.NewConnectionProfile(ctx, "default", &datastream.ConnectionProfileArgs{
			DisplayName:         pulumi.String("SQL Server Source"),
			Location:            pulumi.String("us-central1"),
			ConnectionProfileId: pulumi.String("source-profile"),
			SqlServerProfile: &datastream.ConnectionProfileSqlServerProfileArgs{
				Hostname: instance.PublicIpAddress,
				Port:     pulumi.Int(1433),
				Username: user.Name,
				Password: user.Password,
				Database: db.Name,
			},
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.sql.DatabaseInstance;
import com.pulumi.gcp.sql.DatabaseInstanceArgs;
import com.pulumi.gcp.sql.inputs.DatabaseInstanceSettingsArgs;
import com.pulumi.gcp.sql.inputs.DatabaseInstanceSettingsIpConfigurationArgs;
import com.pulumi.gcp.sql.Database;
import com.pulumi.gcp.sql.DatabaseArgs;
import com.pulumi.gcp.sql.User;
import com.pulumi.gcp.sql.UserArgs;
import com.pulumi.gcp.datastream.ConnectionProfile;
import com.pulumi.gcp.datastream.ConnectionProfileArgs;
import com.pulumi.gcp.datastream.inputs.ConnectionProfileSqlServerProfileArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        var instance = new DatabaseInstance("instance", DatabaseInstanceArgs.builder()
            .name("sql-server")
            .databaseVersion("SQLSERVER_2019_STANDARD")
            .region("us-central1")
            .rootPassword("root-password")
            .deletionProtection(true)
            .settings(DatabaseInstanceSettingsArgs.builder()
                .tier("db-custom-2-4096")
                .ipConfiguration(DatabaseInstanceSettingsIpConfigurationArgs.builder()
                    .authorizedNetworks(                    
                        DatabaseInstanceSettingsIpConfigurationAuthorizedNetworkArgs.builder()
                            .value("34.71.242.81")
                            .build(),
                        DatabaseInstanceSettingsIpConfigurationAuthorizedNetworkArgs.builder()
                            .value("34.72.28.29")
                            .build(),
                        DatabaseInstanceSettingsIpConfigurationAuthorizedNetworkArgs.builder()
                            .value("34.67.6.157")
                            .build(),
                        DatabaseInstanceSettingsIpConfigurationAuthorizedNetworkArgs.builder()
                            .value("34.67.234.134")
                            .build(),
                        DatabaseInstanceSettingsIpConfigurationAuthorizedNetworkArgs.builder()
                            .value("34.72.239.218")
                            .build())
                    .build())
                .build())
            .build());

        var db = new Database("db", DatabaseArgs.builder()
            .name("db")
            .instance(instance.name())
            .build());

        var user = new User("user", UserArgs.builder()
            .name("user")
            .instance(instance.name())
            .password("password")
            .build());

        var default_ = new ConnectionProfile("default", ConnectionProfileArgs.builder()
            .displayName("SQL Server Source")
            .location("us-central1")
            .connectionProfileId("source-profile")
            .sqlServerProfile(ConnectionProfileSqlServerProfileArgs.builder()
                .hostname(instance.publicIpAddress())
                .port(1433)
                .username(user.name())
                .password(user.password())
                .database(db.name())
                .build())
            .build());

    }
}
```
```yaml
resources:
  instance:
    type: gcp:sql:DatabaseInstance
    properties:
      name: sql-server
      databaseVersion: SQLSERVER_2019_STANDARD
      region: us-central1
      rootPassword: root-password
      deletionProtection: true
      settings:
        tier: db-custom-2-4096
        ipConfiguration:
          authorizedNetworks:
            - value: 34.71.242.81
            - value: 34.72.28.29
            - value: 34.67.6.157
            - value: 34.67.234.134
            - value: 34.72.239.218
  db:
    type: gcp:sql:Database
    properties:
      name: db
      instance: ${instance.name}
  user:
    type: gcp:sql:User
    properties:
      name: user
      instance: ${instance.name}
      password: password
  default:
    type: gcp:datastream:ConnectionProfile
    properties:
      displayName: SQL Server Source
      location: us-central1
      connectionProfileId: source-profile
      sqlServerProfile:
        hostname: ${instance.publicIpAddress}
        port: 1433
        username: ${user.name}
        password: ${user.password}
        database: ${db.name}
```
<!--End PulumiCodeChooser -->

## Import

ConnectionProfile can be imported using any of these accepted formats:

* `projects/{{project}}/locations/{{location}}/connectionProfiles/{{connection_profile_id}}`

* `{{project}}/{{location}}/{{connection_profile_id}}`

* `{{location}}/{{connection_profile_id}}`

When using the `pulumi import` command, ConnectionProfile can be imported using one of the formats above. For example:

```sh
$ pulumi import gcp:datastream/connectionProfile:ConnectionProfile default projects/{{project}}/locations/{{location}}/connectionProfiles/{{connection_profile_id}}
```

```sh
$ pulumi import gcp:datastream/connectionProfile:ConnectionProfile default {{project}}/{{location}}/{{connection_profile_id}}
```

```sh
$ pulumi import gcp:datastream/connectionProfile:ConnectionProfile default {{location}}/{{connection_profile_id}}
```

»
bigqueryProfileB:


datastream ConnectionProfileBigqueryProfilePgcp:datastream/ConnectionProfileBigqueryProfile:ConnectionProfileBigqueryProfileBigQuery warehouse profile.
>
connectionProfileId" #The connection profile identifier.
V
createWithoutValidationB
 5Create the connection profile without validating it.
!
displayName" Display name.
û
forwardSshConnectivityB:


datastream'ConnectionProfileForwardSshConnectivity^gcp:datastream/ConnectionProfileForwardSshConnectivity:ConnectionProfileForwardSshConnectivity@Forward SSH tunnel connectivity.
Structure is documented below.
Ä

gcsProfilewBu:s
q

datastreamConnectionProfileGcsProfileFgcp:datastream/ConnectionProfileGcsProfile:ConnectionProfileGcsProfile=Cloud Storage bucket profile.
Structure is documented below.
á
labelsB2" ÎLabels.
**Note**: This field is non-authoritative, and will only manage the labels present in your configuration.
Please refer to the field `effective_labels` for all of the labels present on the resource.
X
location" HThe name of the location this connection profile is located in.


- - -
Æ
mysqlProfile}B{:y
w

datastreamConnectionProfileMysqlProfileJgcp:datastream/ConnectionProfileMysqlProfile:ConnectionProfileMysqlProfile7MySQL database profile.
Structure is documented below.
Ì
oracleProfileB~:|
z

datastreamConnectionProfileOracleProfileLgcp:datastream/ConnectionProfileOracleProfile:ConnectionProfileOracleProfile8Oracle database profile.
Structure is documented below.
ã
postgresqlProfileB:


datastream"ConnectionProfilePostgresqlProfileTgcp:datastream/ConnectionProfilePostgresqlProfile:ConnectionProfilePostgresqlProfile<PostgreSQL database profile.
Structure is documented below.
ä
privateConnectivityB:


datastream$ConnectionProfilePrivateConnectivityXgcp:datastream/ConnectionProfilePrivateConnectivity:ConnectionProfilePrivateConnectivity5Private connectivity.
Structure is documented below.
{
projectB" jThe ID of the project in which the resource belongs.
If it is not provided, the provider project is used.
ß
sqlServerProfileB:


datastream!ConnectionProfileSqlServerProfileRgcp:datastream/ConnectionProfileSqlServerProfile:ConnectionProfileSqlServerProfile<SQL Server database profile.
Structure is documented below.
"»
bigqueryProfileB:


datastream ConnectionProfileBigqueryProfilePgcp:datastream/ConnectionProfileBigqueryProfile:ConnectionProfileBigqueryProfileBigQuery warehouse profile.
">
connectionProfileId" #The connection profile identifier.
"V
createWithoutValidationB
 5Create the connection profile without validating it.
"!
displayName" Display name.
"¦
effectiveLabels2" All of labels (key/value pairs) present on the resource in GCP, including the labels configured through Pulumi, other clients and services.
"û
forwardSshConnectivityB:


datastream'ConnectionProfileForwardSshConnectivity^gcp:datastream/ConnectionProfileForwardSshConnectivity:ConnectionProfileForwardSshConnectivity@Forward SSH tunnel connectivity.
Structure is documented below.
"Ä

gcsProfilewBu:s
q

datastreamConnectionProfileGcsProfileFgcp:datastream/ConnectionProfileGcsProfile:ConnectionProfileGcsProfile=Cloud Storage bucket profile.
Structure is documented below.
"á
labelsB2" ÎLabels.
**Note**: This field is non-authoritative, and will only manage the labels present in your configuration.
Please refer to the field `effective_labels` for all of the labels present on the resource.
"X
location" HThe name of the location this connection profile is located in.


- - -
"Æ
mysqlProfile}B{:y
w

datastreamConnectionProfileMysqlProfileJgcp:datastream/ConnectionProfileMysqlProfile:ConnectionProfileMysqlProfile7MySQL database profile.
Structure is documented below.
"!
name" The resource's name.
"Ì
oracleProfileB~:|
z

datastreamConnectionProfileOracleProfileLgcp:datastream/ConnectionProfileOracleProfile:ConnectionProfileOracleProfile8Oracle database profile.
Structure is documented below.
"ã
postgresqlProfileB:


datastream"ConnectionProfilePostgresqlProfileTgcp:datastream/ConnectionProfilePostgresqlProfile:ConnectionProfilePostgresqlProfile<PostgreSQL database profile.
Structure is documented below.
"ä
privateConnectivityB:


datastream$ConnectionProfilePrivateConnectivityXgcp:datastream/ConnectionProfilePrivateConnectivity:ConnectionProfilePrivateConnectivity5Private connectivity.
Structure is documented below.
"y
project" jThe ID of the project in which the resource belongs.
If it is not provided, the provider project is used.
"
pulumiLabels2" mThe combination of labels configured directly on the resource
and default labels configured on the provider.
"ß
sqlServerProfileB:


datastream!ConnectionProfileSqlServerProfileRgcp:datastream/ConnectionProfileSqlServerProfile:ConnectionProfileSqlServerProfile<SQL Server database profile.
Structure is documented below.
*Ç>
S

datastreamPrivateConnection2gcp:datastream/privateConnection:PrivateConnectionê,The PrivateConnection resource is used to establish private connectivity between Datastream and a customer's network.


To get more information about PrivateConnection, see:

* [API documentation](https://cloud.google.com/datastream/docs/reference/rest/v1/projects.locations.privateConnections)
* How-to Guides
    * [Official Documentation](https://cloud.google.com/datastream/docs/create-a-private-connectivity-configuration)

## Example Usage

### Datastream Private Connection Full


<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const defaultNetwork = new gcp.compute.Network("default", {name: "my-network"});
const _default = new gcp.datastream.PrivateConnection("default", {
    displayName: "Connection profile",
    location: "us-central1",
    privateConnectionId: "my-connection",
    labels: {
        key: "value",
    },
    vpcPeeringConfig: {
        vpc: defaultNetwork.id,
        subnet: "10.0.0.0/29",
    },
});
```
```python
import pulumi
import pulumi_gcp as gcp

default_network = gcp.compute.Network("default", name="my-network")
default = gcp.datastream.PrivateConnection("default",
    display_name="Connection profile",
    location="us-central1",
    private_connection_id="my-connection",
    labels={
        "key": "value",
    },
    vpc_peering_config={
        "vpc": default_network.id,
        "subnet": "10.0.0.0/29",
    })
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var defaultNetwork = new Gcp.Compute.Network("default", new()
    {
        Name = "my-network",
    });

    var @default = new Gcp.Datastream.PrivateConnection("default", new()
    {
        DisplayName = "Connection profile",
        Location = "us-central1",
        PrivateConnectionId = "my-connection",
        Labels = 
        {
            { "key", "value" },
        },
        VpcPeeringConfig = new Gcp.Datastream.Inputs.PrivateConnectionVpcPeeringConfigArgs
        {
            Vpc = defaultNetwork.Id,
            Subnet = "10.0.0.0/29",
        },
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/compute"
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/datastream"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		defaultNetwork, err := compute.NewNetwork(ctx, "default", &compute.NetworkArgs{
			Name: pulumi.String("my-network"),
		})
		if err != nil {
			return err
		}
		_, err = datastream.NewPrivateConnection(ctx, "default", &datastream.PrivateConnectionArgs{
			DisplayName:         pulumi.String("Connection profile"),
			Location:            pulumi.String("us-central1"),
			PrivateConnectionId: pulumi.String("my-connection"),
			Labels: pulumi.StringMap{
				"key": pulumi.String("value"),
			},
			VpcPeeringConfig: &datastream.PrivateConnectionVpcPeeringConfigArgs{
				Vpc:    defaultNetwork.ID(),
				Subnet: pulumi.String("10.0.0.0/29"),
			},
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.compute.Network;
import com.pulumi.gcp.compute.NetworkArgs;
import com.pulumi.gcp.datastream.PrivateConnection;
import com.pulumi.gcp.datastream.PrivateConnectionArgs;
import com.pulumi.gcp.datastream.inputs.PrivateConnectionVpcPeeringConfigArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        var defaultNetwork = new Network("defaultNetwork", NetworkArgs.builder()
            .name("my-network")
            .build());

        var default_ = new PrivateConnection("default", PrivateConnectionArgs.builder()
            .displayName("Connection profile")
            .location("us-central1")
            .privateConnectionId("my-connection")
            .labels(Map.of("key", "value"))
            .vpcPeeringConfig(PrivateConnectionVpcPeeringConfigArgs.builder()
                .vpc(defaultNetwork.id())
                .subnet("10.0.0.0/29")
                .build())
            .build());

    }
}
```
```yaml
resources:
  default:
    type: gcp:datastream:PrivateConnection
    properties:
      displayName: Connection profile
      location: us-central1
      privateConnectionId: my-connection
      labels:
        key: value
      vpcPeeringConfig:
        vpc: ${defaultNetwork.id}
        subnet: 10.0.0.0/29
  defaultNetwork:
    type: gcp:compute:Network
    name: default
    properties:
      name: my-network
```
<!--End PulumiCodeChooser -->

## Import

PrivateConnection can be imported using any of these accepted formats:

* `projects/{{project}}/locations/{{location}}/privateConnections/{{private_connection_id}}`

* `{{project}}/{{location}}/{{private_connection_id}}`

* `{{location}}/{{private_connection_id}}`

When using the `pulumi import` command, PrivateConnection can be imported using one of the formats above. For example:

```sh
$ pulumi import gcp:datastream/privateConnection:PrivateConnection default projects/{{project}}/locations/{{location}}/privateConnections/{{private_connection_id}}
```

```sh
$ pulumi import gcp:datastream/privateConnection:PrivateConnection default {{project}}/{{location}}/{{private_connection_id}}
```

```sh
$ pulumi import gcp:datastream/privateConnection:PrivateConnection default {{location}}/{{private_connection_id}}
```

H
createWithoutValidationB
 'If set to true, will skip validations.
!
displayName" Display name.
á
labelsB2" ÎLabels. **Note**: This field is non-authoritative, and will only manage the labels present in your configuration. Please
refer to the field 'effective_labels' for all of the labels present on the resource.
P
location" @The name of the location this private connection is located in.
@
privateConnectionId" %The private connectivity identifier.

projectB" §
vpcPeeringConfig:


datastream!PrivateConnectionVpcPeeringConfigRgcp:datastream/PrivateConnectionVpcPeeringConfig:PrivateConnectionVpcPeeringConfigThe VPC Peering configuration is used to create VPC peering
between Datastream and the consumer's VPC.
Structure is documented below.
"H
createWithoutValidationB
 'If set to true, will skip validations.
"!
displayName" Display name.
"¦
effectiveLabels2" All of labels (key/value pairs) present on the resource in GCP, including the labels configured through Pulumi, other clients and services.
"Ã
errorsh*f:d
b

datastreamPrivateConnectionError<gcp:datastream/PrivateConnectionError:PrivateConnectionErrorOThe PrivateConnection error in case of failure.
Structure is documented below.
"á
labelsB2" ÎLabels. **Note**: This field is non-authoritative, and will only manage the labels present in your configuration. Please
refer to the field 'effective_labels' for all of the labels present on the resource.
"P
location" @The name of the location this private connection is located in.
"!
name" The resource's name.
"@
privateConnectionId" %The private connectivity identifier.
"
project" "
pulumiLabels2" mThe combination of labels configured directly on the resource
and default labels configured on the provider.
"-
state"  State of the PrivateConnection.
"§
vpcPeeringConfig:


datastream!PrivateConnectionVpcPeeringConfigRgcp:datastream/PrivateConnectionVpcPeeringConfig:PrivateConnectionVpcPeeringConfigThe VPC Peering configuration is used to create VPC peering
between Datastream and the consumer's VPC.
Structure is documented below.
*ÀÎ
2

datastreamStreamgcp:datastream/stream:Stream²¯A resource representing streaming data from a source to a destination.


To get more information about Stream, see:

* [API documentation](https://cloud.google.com/datastream/docs/reference/rest/v1/projects.locations.streams)
* How-to Guides
    * [Official Documentation](https://cloud.google.com/datastream/docs/create-a-stream)

## Example Usage

### Datastream Stream Full


<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";
import * as random from "@pulumi/random";

const project = gcp.organizations.getProject({});
const instance = new gcp.sql.DatabaseInstance("instance", {
    name: "my-instance",
    databaseVersion: "MYSQL_8_0",
    region: "us-central1",
    settings: {
        tier: "db-f1-micro",
        backupConfiguration: {
            enabled: true,
            binaryLogEnabled: true,
        },
        ipConfiguration: {
            authorizedNetworks: [
                {
                    value: "34.71.242.81",
                },
                {
                    value: "34.72.28.29",
                },
                {
                    value: "34.67.6.157",
                },
                {
                    value: "34.67.234.134",
                },
                {
                    value: "34.72.239.218",
                },
            ],
        },
    },
    deletionProtection: true,
});
const db = new gcp.sql.Database("db", {
    instance: instance.name,
    name: "db",
});
const pwd = new random.RandomPassword("pwd", {
    length: 16,
    special: false,
});
const user = new gcp.sql.User("user", {
    name: "user",
    instance: instance.name,
    host: "%",
    password: pwd.result,
});
const sourceConnectionProfile = new gcp.datastream.ConnectionProfile("source_connection_profile", {
    displayName: "Source connection profile",
    location: "us-central1",
    connectionProfileId: "source-profile",
    mysqlProfile: {
        hostname: instance.publicIpAddress,
        username: user.name,
        password: user.password,
    },
});
const bucket = new gcp.storage.Bucket("bucket", {
    name: "my-bucket",
    location: "US",
    uniformBucketLevelAccess: true,
});
const viewer = new gcp.storage.BucketIAMMember("viewer", {
    bucket: bucket.name,
    role: "roles/storage.objectViewer",
    member: project.then(project => `serviceAccount:service-${project.number}@gcp-sa-datastream.iam.gserviceaccount.com`),
});
const creator = new gcp.storage.BucketIAMMember("creator", {
    bucket: bucket.name,
    role: "roles/storage.objectCreator",
    member: project.then(project => `serviceAccount:service-${project.number}@gcp-sa-datastream.iam.gserviceaccount.com`),
});
const reader = new gcp.storage.BucketIAMMember("reader", {
    bucket: bucket.name,
    role: "roles/storage.legacyBucketReader",
    member: project.then(project => `serviceAccount:service-${project.number}@gcp-sa-datastream.iam.gserviceaccount.com`),
});
const keyUser = new gcp.kms.CryptoKeyIAMMember("key_user", {
    cryptoKeyId: "kms-name",
    role: "roles/cloudkms.cryptoKeyEncrypterDecrypter",
    member: project.then(project => `serviceAccount:service-${project.number}@gcp-sa-datastream.iam.gserviceaccount.com`),
});
const destinationConnectionProfile = new gcp.datastream.ConnectionProfile("destination_connection_profile", {
    displayName: "Connection profile",
    location: "us-central1",
    connectionProfileId: "destination-profile",
    gcsProfile: {
        bucket: bucket.name,
        rootPath: "/path",
    },
});
const _default = new gcp.datastream.Stream("default", {
    streamId: "my-stream",
    desiredState: "NOT_STARTED",
    location: "us-central1",
    displayName: "my stream",
    labels: {
        key: "value",
    },
    sourceConfig: {
        sourceConnectionProfile: sourceConnectionProfile.id,
        mysqlSourceConfig: {
            includeObjects: {
                mysqlDatabases: [{
                    database: "my-database",
                    mysqlTables: [
                        {
                            table: "includedTable",
                            mysqlColumns: [{
                                column: "includedColumn",
                                dataType: "VARCHAR",
                                collation: "utf8mb4",
                                primaryKey: false,
                                nullable: false,
                                ordinalPosition: 0,
                            }],
                        },
                        {
                            table: "includedTable_2",
                        },
                    ],
                }],
            },
            excludeObjects: {
                mysqlDatabases: [{
                    database: "my-database",
                    mysqlTables: [{
                        table: "excludedTable",
                        mysqlColumns: [{
                            column: "excludedColumn",
                            dataType: "VARCHAR",
                            collation: "utf8mb4",
                            primaryKey: false,
                            nullable: false,
                            ordinalPosition: 0,
                        }],
                    }],
                }],
            },
            maxConcurrentCdcTasks: 5,
        },
    },
    destinationConfig: {
        destinationConnectionProfile: destinationConnectionProfile.id,
        gcsDestinationConfig: {
            path: "mydata",
            fileRotationMb: 200,
            fileRotationInterval: "60s",
            jsonFileFormat: {
                schemaFileFormat: "NO_SCHEMA_FILE",
                compression: "GZIP",
            },
        },
    },
    backfillAll: {
        mysqlExcludedObjects: {
            mysqlDatabases: [{
                database: "my-database",
                mysqlTables: [{
                    table: "excludedTable",
                    mysqlColumns: [{
                        column: "excludedColumn",
                        dataType: "VARCHAR",
                        collation: "utf8mb4",
                        primaryKey: false,
                        nullable: false,
                        ordinalPosition: 0,
                    }],
                }],
            }],
        },
    },
    customerManagedEncryptionKey: "kms-name",
}, {
    dependsOn: [keyUser],
});
```
```python
import pulumi
import pulumi_gcp as gcp
import pulumi_random as random

project = gcp.organizations.get_project()
instance = gcp.sql.DatabaseInstance("instance",
    name="my-instance",
    database_version="MYSQL_8_0",
    region="us-central1",
    settings={
        "tier": "db-f1-micro",
        "backup_configuration": {
            "enabled": True,
            "binary_log_enabled": True,
        },
        "ip_configuration": {
            "authorized_networks": [
                {
                    "value": "34.71.242.81",
                },
                {
                    "value": "34.72.28.29",
                },
                {
                    "value": "34.67.6.157",
                },
                {
                    "value": "34.67.234.134",
                },
                {
                    "value": "34.72.239.218",
                },
            ],
        },
    },
    deletion_protection=True)
db = gcp.sql.Database("db",
    instance=instance.name,
    name="db")
pwd = random.RandomPassword("pwd",
    length=16,
    special=False)
user = gcp.sql.User("user",
    name="user",
    instance=instance.name,
    host="%",
    password=pwd.result)
source_connection_profile = gcp.datastream.ConnectionProfile("source_connection_profile",
    display_name="Source connection profile",
    location="us-central1",
    connection_profile_id="source-profile",
    mysql_profile={
        "hostname": instance.public_ip_address,
        "username": user.name,
        "password": user.password,
    })
bucket = gcp.storage.Bucket("bucket",
    name="my-bucket",
    location="US",
    uniform_bucket_level_access=True)
viewer = gcp.storage.BucketIAMMember("viewer",
    bucket=bucket.name,
    role="roles/storage.objectViewer",
    member=f"serviceAccount:service-{project.number}@gcp-sa-datastream.iam.gserviceaccount.com")
creator = gcp.storage.BucketIAMMember("creator",
    bucket=bucket.name,
    role="roles/storage.objectCreator",
    member=f"serviceAccount:service-{project.number}@gcp-sa-datastream.iam.gserviceaccount.com")
reader = gcp.storage.BucketIAMMember("reader",
    bucket=bucket.name,
    role="roles/storage.legacyBucketReader",
    member=f"serviceAccount:service-{project.number}@gcp-sa-datastream.iam.gserviceaccount.com")
key_user = gcp.kms.CryptoKeyIAMMember("key_user",
    crypto_key_id="kms-name",
    role="roles/cloudkms.cryptoKeyEncrypterDecrypter",
    member=f"serviceAccount:service-{project.number}@gcp-sa-datastream.iam.gserviceaccount.com")
destination_connection_profile = gcp.datastream.ConnectionProfile("destination_connection_profile",
    display_name="Connection profile",
    location="us-central1",
    connection_profile_id="destination-profile",
    gcs_profile={
        "bucket": bucket.name,
        "root_path": "/path",
    })
default = gcp.datastream.Stream("default",
    stream_id="my-stream",
    desired_state="NOT_STARTED",
    location="us-central1",
    display_name="my stream",
    labels={
        "key": "value",
    },
    source_config={
        "source_connection_profile": source_connection_profile.id,
        "mysql_source_config": {
            "include_objects": {
                "mysql_databases": [{
                    "database": "my-database",
                    "mysql_tables": [
                        {
                            "table": "includedTable",
                            "mysql_columns": [{
                                "column": "includedColumn",
                                "data_type": "VARCHAR",
                                "collation": "utf8mb4",
                                "primary_key": False,
                                "nullable": False,
                                "ordinal_position": 0,
                            }],
                        },
                        {
                            "table": "includedTable_2",
                        },
                    ],
                }],
            },
            "exclude_objects": {
                "mysql_databases": [{
                    "database": "my-database",
                    "mysql_tables": [{
                        "table": "excludedTable",
                        "mysql_columns": [{
                            "column": "excludedColumn",
                            "data_type": "VARCHAR",
                            "collation": "utf8mb4",
                            "primary_key": False,
                            "nullable": False,
                            "ordinal_position": 0,
                        }],
                    }],
                }],
            },
            "max_concurrent_cdc_tasks": 5,
        },
    },
    destination_config={
        "destination_connection_profile": destination_connection_profile.id,
        "gcs_destination_config": {
            "path": "mydata",
            "file_rotation_mb": 200,
            "file_rotation_interval": "60s",
            "json_file_format": {
                "schema_file_format": "NO_SCHEMA_FILE",
                "compression": "GZIP",
            },
        },
    },
    backfill_all={
        "mysql_excluded_objects": {
            "mysql_databases": [{
                "database": "my-database",
                "mysql_tables": [{
                    "table": "excludedTable",
                    "mysql_columns": [{
                        "column": "excludedColumn",
                        "data_type": "VARCHAR",
                        "collation": "utf8mb4",
                        "primary_key": False,
                        "nullable": False,
                        "ordinal_position": 0,
                    }],
                }],
            }],
        },
    },
    customer_managed_encryption_key="kms-name",
    opts = pulumi.ResourceOptions(depends_on=[key_user]))
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;
using Random = Pulumi.Random;

return await Deployment.RunAsync(() => 
{
    var project = Gcp.Organizations.GetProject.Invoke();

    var instance = new Gcp.Sql.DatabaseInstance("instance", new()
    {
        Name = "my-instance",
        DatabaseVersion = "MYSQL_8_0",
        Region = "us-central1",
        Settings = new Gcp.Sql.Inputs.DatabaseInstanceSettingsArgs
        {
            Tier = "db-f1-micro",
            BackupConfiguration = new Gcp.Sql.Inputs.DatabaseInstanceSettingsBackupConfigurationArgs
            {
                Enabled = true,
                BinaryLogEnabled = true,
            },
            IpConfiguration = new Gcp.Sql.Inputs.DatabaseInstanceSettingsIpConfigurationArgs
            {
                AuthorizedNetworks = new[]
                {
                    new Gcp.Sql.Inputs.DatabaseInstanceSettingsIpConfigurationAuthorizedNetworkArgs
                    {
                        Value = "34.71.242.81",
                    },
                    new Gcp.Sql.Inputs.DatabaseInstanceSettingsIpConfigurationAuthorizedNetworkArgs
                    {
                        Value = "34.72.28.29",
                    },
                    new Gcp.Sql.Inputs.DatabaseInstanceSettingsIpConfigurationAuthorizedNetworkArgs
                    {
                        Value = "34.67.6.157",
                    },
                    new Gcp.Sql.Inputs.DatabaseInstanceSettingsIpConfigurationAuthorizedNetworkArgs
                    {
                        Value = "34.67.234.134",
                    },
                    new Gcp.Sql.Inputs.DatabaseInstanceSettingsIpConfigurationAuthorizedNetworkArgs
                    {
                        Value = "34.72.239.218",
                    },
                },
            },
        },
        DeletionProtection = true,
    });

    var db = new Gcp.Sql.Database("db", new()
    {
        Instance = instance.Name,
        Name = "db",
    });

    var pwd = new Random.RandomPassword("pwd", new()
    {
        Length = 16,
        Special = false,
    });

    var user = new Gcp.Sql.User("user", new()
    {
        Name = "user",
        Instance = instance.Name,
        Host = "%",
        Password = pwd.Result,
    });

    var sourceConnectionProfile = new Gcp.Datastream.ConnectionProfile("source_connection_profile", new()
    {
        DisplayName = "Source connection profile",
        Location = "us-central1",
        ConnectionProfileId = "source-profile",
        MysqlProfile = new Gcp.Datastream.Inputs.ConnectionProfileMysqlProfileArgs
        {
            Hostname = instance.PublicIpAddress,
            Username = user.Name,
            Password = user.Password,
        },
    });

    var bucket = new Gcp.Storage.Bucket("bucket", new()
    {
        Name = "my-bucket",
        Location = "US",
        UniformBucketLevelAccess = true,
    });

    var viewer = new Gcp.Storage.BucketIAMMember("viewer", new()
    {
        Bucket = bucket.Name,
        Role = "roles/storage.objectViewer",
        Member = $"serviceAccount:service-{project.Apply(getProjectResult => getProjectResult.Number)}@gcp-sa-datastream.iam.gserviceaccount.com",
    });

    var creator = new Gcp.Storage.BucketIAMMember("creator", new()
    {
        Bucket = bucket.Name,
        Role = "roles/storage.objectCreator",
        Member = $"serviceAccount:service-{project.Apply(getProjectResult => getProjectResult.Number)}@gcp-sa-datastream.iam.gserviceaccount.com",
    });

    var reader = new Gcp.Storage.BucketIAMMember("reader", new()
    {
        Bucket = bucket.Name,
        Role = "roles/storage.legacyBucketReader",
        Member = $"serviceAccount:service-{project.Apply(getProjectResult => getProjectResult.Number)}@gcp-sa-datastream.iam.gserviceaccount.com",
    });

    var keyUser = new Gcp.Kms.CryptoKeyIAMMember("key_user", new()
    {
        CryptoKeyId = "kms-name",
        Role = "roles/cloudkms.cryptoKeyEncrypterDecrypter",
        Member = $"serviceAccount:service-{project.Apply(getProjectResult => getProjectResult.Number)}@gcp-sa-datastream.iam.gserviceaccount.com",
    });

    var destinationConnectionProfile = new Gcp.Datastream.ConnectionProfile("destination_connection_profile", new()
    {
        DisplayName = "Connection profile",
        Location = "us-central1",
        ConnectionProfileId = "destination-profile",
        GcsProfile = new Gcp.Datastream.Inputs.ConnectionProfileGcsProfileArgs
        {
            Bucket = bucket.Name,
            RootPath = "/path",
        },
    });

    var @default = new Gcp.Datastream.Stream("default", new()
    {
        StreamId = "my-stream",
        DesiredState = "NOT_STARTED",
        Location = "us-central1",
        DisplayName = "my stream",
        Labels = 
        {
            { "key", "value" },
        },
        SourceConfig = new Gcp.Datastream.Inputs.StreamSourceConfigArgs
        {
            SourceConnectionProfile = sourceConnectionProfile.Id,
            MysqlSourceConfig = new Gcp.Datastream.Inputs.StreamSourceConfigMysqlSourceConfigArgs
            {
                IncludeObjects = new Gcp.Datastream.Inputs.StreamSourceConfigMysqlSourceConfigIncludeObjectsArgs
                {
                    MysqlDatabases = new[]
                    {
                        new Gcp.Datastream.Inputs.StreamSourceConfigMysqlSourceConfigIncludeObjectsMysqlDatabaseArgs
                        {
                            Database = "my-database",
                            MysqlTables = new[]
                            {
                                new Gcp.Datastream.Inputs.StreamSourceConfigMysqlSourceConfigIncludeObjectsMysqlDatabaseMysqlTableArgs
                                {
                                    Table = "includedTable",
                                    MysqlColumns = new[]
                                    {
                                        new Gcp.Datastream.Inputs.StreamSourceConfigMysqlSourceConfigIncludeObjectsMysqlDatabaseMysqlTableMysqlColumnArgs
                                        {
                                            Column = "includedColumn",
                                            DataType = "VARCHAR",
                                            Collation = "utf8mb4",
                                            PrimaryKey = false,
                                            Nullable = false,
                                            OrdinalPosition = 0,
                                        },
                                    },
                                },
                                new Gcp.Datastream.Inputs.StreamSourceConfigMysqlSourceConfigIncludeObjectsMysqlDatabaseMysqlTableArgs
                                {
                                    Table = "includedTable_2",
                                },
                            },
                        },
                    },
                },
                ExcludeObjects = new Gcp.Datastream.Inputs.StreamSourceConfigMysqlSourceConfigExcludeObjectsArgs
                {
                    MysqlDatabases = new[]
                    {
                        new Gcp.Datastream.Inputs.StreamSourceConfigMysqlSourceConfigExcludeObjectsMysqlDatabaseArgs
                        {
                            Database = "my-database",
                            MysqlTables = new[]
                            {
                                new Gcp.Datastream.Inputs.StreamSourceConfigMysqlSourceConfigExcludeObjectsMysqlDatabaseMysqlTableArgs
                                {
                                    Table = "excludedTable",
                                    MysqlColumns = new[]
                                    {
                                        new Gcp.Datastream.Inputs.StreamSourceConfigMysqlSourceConfigExcludeObjectsMysqlDatabaseMysqlTableMysqlColumnArgs
                                        {
                                            Column = "excludedColumn",
                                            DataType = "VARCHAR",
                                            Collation = "utf8mb4",
                                            PrimaryKey = false,
                                            Nullable = false,
                                            OrdinalPosition = 0,
                                        },
                                    },
                                },
                            },
                        },
                    },
                },
                MaxConcurrentCdcTasks = 5,
            },
        },
        DestinationConfig = new Gcp.Datastream.Inputs.StreamDestinationConfigArgs
        {
            DestinationConnectionProfile = destinationConnectionProfile.Id,
            GcsDestinationConfig = new Gcp.Datastream.Inputs.StreamDestinationConfigGcsDestinationConfigArgs
            {
                Path = "mydata",
                FileRotationMb = 200,
                FileRotationInterval = "60s",
                JsonFileFormat = new Gcp.Datastream.Inputs.StreamDestinationConfigGcsDestinationConfigJsonFileFormatArgs
                {
                    SchemaFileFormat = "NO_SCHEMA_FILE",
                    Compression = "GZIP",
                },
            },
        },
        BackfillAll = new Gcp.Datastream.Inputs.StreamBackfillAllArgs
        {
            MysqlExcludedObjects = new Gcp.Datastream.Inputs.StreamBackfillAllMysqlExcludedObjectsArgs
            {
                MysqlDatabases = new[]
                {
                    new Gcp.Datastream.Inputs.StreamBackfillAllMysqlExcludedObjectsMysqlDatabaseArgs
                    {
                        Database = "my-database",
                        MysqlTables = new[]
                        {
                            new Gcp.Datastream.Inputs.StreamBackfillAllMysqlExcludedObjectsMysqlDatabaseMysqlTableArgs
                            {
                                Table = "excludedTable",
                                MysqlColumns = new[]
                                {
                                    new Gcp.Datastream.Inputs.StreamBackfillAllMysqlExcludedObjectsMysqlDatabaseMysqlTableMysqlColumnArgs
                                    {
                                        Column = "excludedColumn",
                                        DataType = "VARCHAR",
                                        Collation = "utf8mb4",
                                        PrimaryKey = false,
                                        Nullable = false,
                                        OrdinalPosition = 0,
                                    },
                                },
                            },
                        },
                    },
                },
            },
        },
        CustomerManagedEncryptionKey = "kms-name",
    }, new CustomResourceOptions
    {
        DependsOn =
        {
            keyUser,
        },
    });

});
```
```go
package main

import (
	"fmt"

	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/datastream"
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/kms"
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/organizations"
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/sql"
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/storage"
	"github.com/pulumi/pulumi-random/sdk/v4/go/random"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		project, err := organizations.LookupProject(ctx, &organizations.LookupProjectArgs{}, nil)
		if err != nil {
			return err
		}
		instance, err := sql.NewDatabaseInstance(ctx, "instance", &sql.DatabaseInstanceArgs{
			Name:            pulumi.String("my-instance"),
			DatabaseVersion: pulumi.String("MYSQL_8_0"),
			Region:          pulumi.String("us-central1"),
			Settings: &sql.DatabaseInstanceSettingsArgs{
				Tier: pulumi.String("db-f1-micro"),
				BackupConfiguration: &sql.DatabaseInstanceSettingsBackupConfigurationArgs{
					Enabled:          pulumi.Bool(true),
					BinaryLogEnabled: pulumi.Bool(true),
				},
				IpConfiguration: &sql.DatabaseInstanceSettingsIpConfigurationArgs{
					AuthorizedNetworks: sql.DatabaseInstanceSettingsIpConfigurationAuthorizedNetworkArray{
						&sql.DatabaseInstanceSettingsIpConfigurationAuthorizedNetworkArgs{
							Value: pulumi.String("34.71.242.81"),
						},
						&sql.DatabaseInstanceSettingsIpConfigurationAuthorizedNetworkArgs{
							Value: pulumi.String("34.72.28.29"),
						},
						&sql.DatabaseInstanceSettingsIpConfigurationAuthorizedNetworkArgs{
							Value: pulumi.String("34.67.6.157"),
						},
						&sql.DatabaseInstanceSettingsIpConfigurationAuthorizedNetworkArgs{
							Value: pulumi.String("34.67.234.134"),
						},
						&sql.DatabaseInstanceSettingsIpConfigurationAuthorizedNetworkArgs{
							Value: pulumi.String("34.72.239.218"),
						},
					},
				},
			},
			DeletionProtection: pulumi.Bool(true),
		})
		if err != nil {
			return err
		}
		_, err = sql.NewDatabase(ctx, "db", &sql.DatabaseArgs{
			Instance: instance.Name,
			Name:     pulumi.String("db"),
		})
		if err != nil {
			return err
		}
		pwd, err := random.NewRandomPassword(ctx, "pwd", &random.RandomPasswordArgs{
			Length:  pulumi.Int(16),
			Special: pulumi.Bool(false),
		})
		if err != nil {
			return err
		}
		user, err := sql.NewUser(ctx, "user", &sql.UserArgs{
			Name:     pulumi.String("user"),
			Instance: instance.Name,
			Host:     pulumi.String("%"),
			Password: pwd.Result,
		})
		if err != nil {
			return err
		}
		sourceConnectionProfile, err := datastream.NewConnectionProfile(ctx, "source_connection_profile", &datastream.ConnectionProfileArgs{
			DisplayName:         pulumi.String("Source connection profile"),
			Location:            pulumi.String("us-central1"),
			ConnectionProfileId: pulumi.String("source-profile"),
			MysqlProfile: &datastream.ConnectionProfileMysqlProfileArgs{
				Hostname: instance.PublicIpAddress,
				Username: user.Name,
				Password: user.Password,
			},
		})
		if err != nil {
			return err
		}
		bucket, err := storage.NewBucket(ctx, "bucket", &storage.BucketArgs{
			Name:                     pulumi.String("my-bucket"),
			Location:                 pulumi.String("US"),
			UniformBucketLevelAccess: pulumi.Bool(true),
		})
		if err != nil {
			return err
		}
		_, err = storage.NewBucketIAMMember(ctx, "viewer", &storage.BucketIAMMemberArgs{
			Bucket: bucket.Name,
			Role:   pulumi.String("roles/storage.objectViewer"),
			Member: pulumi.Sprintf("serviceAccount:service-%v@gcp-sa-datastream.iam.gserviceaccount.com", project.Number),
		})
		if err != nil {
			return err
		}
		_, err = storage.NewBucketIAMMember(ctx, "creator", &storage.BucketIAMMemberArgs{
			Bucket: bucket.Name,
			Role:   pulumi.String("roles/storage.objectCreator"),
			Member: pulumi.Sprintf("serviceAccount:service-%v@gcp-sa-datastream.iam.gserviceaccount.com", project.Number),
		})
		if err != nil {
			return err
		}
		_, err = storage.NewBucketIAMMember(ctx, "reader", &storage.BucketIAMMemberArgs{
			Bucket: bucket.Name,
			Role:   pulumi.String("roles/storage.legacyBucketReader"),
			Member: pulumi.Sprintf("serviceAccount:service-%v@gcp-sa-datastream.iam.gserviceaccount.com", project.Number),
		})
		if err != nil {
			return err
		}
		keyUser, err := kms.NewCryptoKeyIAMMember(ctx, "key_user", &kms.CryptoKeyIAMMemberArgs{
			CryptoKeyId: pulumi.String("kms-name"),
			Role:        pulumi.String("roles/cloudkms.cryptoKeyEncrypterDecrypter"),
			Member:      pulumi.Sprintf("serviceAccount:service-%v@gcp-sa-datastream.iam.gserviceaccount.com", project.Number),
		})
		if err != nil {
			return err
		}
		destinationConnectionProfile, err := datastream.NewConnectionProfile(ctx, "destination_connection_profile", &datastream.ConnectionProfileArgs{
			DisplayName:         pulumi.String("Connection profile"),
			Location:            pulumi.String("us-central1"),
			ConnectionProfileId: pulumi.String("destination-profile"),
			GcsProfile: &datastream.ConnectionProfileGcsProfileArgs{
				Bucket:   bucket.Name,
				RootPath: pulumi.String("/path"),
			},
		})
		if err != nil {
			return err
		}
		_, err = datastream.NewStream(ctx, "default", &datastream.StreamArgs{
			StreamId:     pulumi.String("my-stream"),
			DesiredState: pulumi.String("NOT_STARTED"),
			Location:     pulumi.String("us-central1"),
			DisplayName:  pulumi.String("my stream"),
			Labels: pulumi.StringMap{
				"key": pulumi.String("value"),
			},
			SourceConfig: &datastream.StreamSourceConfigArgs{
				SourceConnectionProfile: sourceConnectionProfile.ID(),
				MysqlSourceConfig: &datastream.StreamSourceConfigMysqlSourceConfigArgs{
					IncludeObjects: &datastream.StreamSourceConfigMysqlSourceConfigIncludeObjectsArgs{
						MysqlDatabases: datastream.StreamSourceConfigMysqlSourceConfigIncludeObjectsMysqlDatabaseArray{
							&datastream.StreamSourceConfigMysqlSourceConfigIncludeObjectsMysqlDatabaseArgs{
								Database: pulumi.String("my-database"),
								MysqlTables: datastream.StreamSourceConfigMysqlSourceConfigIncludeObjectsMysqlDatabaseMysqlTableArray{
									&datastream.StreamSourceConfigMysqlSourceConfigIncludeObjectsMysqlDatabaseMysqlTableArgs{
										Table: pulumi.String("includedTable"),
										MysqlColumns: datastream.StreamSourceConfigMysqlSourceConfigIncludeObjectsMysqlDatabaseMysqlTableMysqlColumnArray{
											&datastream.StreamSourceConfigMysqlSourceConfigIncludeObjectsMysqlDatabaseMysqlTableMysqlColumnArgs{
												Column:          pulumi.String("includedColumn"),
												DataType:        pulumi.String("VARCHAR"),
												Collation:       pulumi.String("utf8mb4"),
												PrimaryKey:      pulumi.Bool(false),
												Nullable:        pulumi.Bool(false),
												OrdinalPosition: pulumi.Int(0),
											},
										},
									},
									&datastream.StreamSourceConfigMysqlSourceConfigIncludeObjectsMysqlDatabaseMysqlTableArgs{
										Table: pulumi.String("includedTable_2"),
									},
								},
							},
						},
					},
					ExcludeObjects: &datastream.StreamSourceConfigMysqlSourceConfigExcludeObjectsArgs{
						MysqlDatabases: datastream.StreamSourceConfigMysqlSourceConfigExcludeObjectsMysqlDatabaseArray{
							&datastream.StreamSourceConfigMysqlSourceConfigExcludeObjectsMysqlDatabaseArgs{
								Database: pulumi.String("my-database"),
								MysqlTables: datastream.StreamSourceConfigMysqlSourceConfigExcludeObjectsMysqlDatabaseMysqlTableArray{
									&datastream.StreamSourceConfigMysqlSourceConfigExcludeObjectsMysqlDatabaseMysqlTableArgs{
										Table: pulumi.String("excludedTable"),
										MysqlColumns: datastream.StreamSourceConfigMysqlSourceConfigExcludeObjectsMysqlDatabaseMysqlTableMysqlColumnArray{
											&datastream.StreamSourceConfigMysqlSourceConfigExcludeObjectsMysqlDatabaseMysqlTableMysqlColumnArgs{
												Column:          pulumi.String("excludedColumn"),
												DataType:        pulumi.String("VARCHAR"),
												Collation:       pulumi.String("utf8mb4"),
												PrimaryKey:      pulumi.Bool(false),
												Nullable:        pulumi.Bool(false),
												OrdinalPosition: pulumi.Int(0),
											},
										},
									},
								},
							},
						},
					},
					MaxConcurrentCdcTasks: pulumi.Int(5),
				},
			},
			DestinationConfig: &datastream.StreamDestinationConfigArgs{
				DestinationConnectionProfile: destinationConnectionProfile.ID(),
				GcsDestinationConfig: &datastream.StreamDestinationConfigGcsDestinationConfigArgs{
					Path:                 pulumi.String("mydata"),
					FileRotationMb:       pulumi.Int(200),
					FileRotationInterval: pulumi.String("60s"),
					JsonFileFormat: &datastream.StreamDestinationConfigGcsDestinationConfigJsonFileFormatArgs{
						SchemaFileFormat: pulumi.String("NO_SCHEMA_FILE"),
						Compression:      pulumi.String("GZIP"),
					},
				},
			},
			BackfillAll: &datastream.StreamBackfillAllArgs{
				MysqlExcludedObjects: &datastream.StreamBackfillAllMysqlExcludedObjectsArgs{
					MysqlDatabases: datastream.StreamBackfillAllMysqlExcludedObjectsMysqlDatabaseArray{
						&datastream.StreamBackfillAllMysqlExcludedObjectsMysqlDatabaseArgs{
							Database: pulumi.String("my-database"),
							MysqlTables: datastream.StreamBackfillAllMysqlExcludedObjectsMysqlDatabaseMysqlTableArray{
								&datastream.StreamBackfillAllMysqlExcludedObjectsMysqlDatabaseMysqlTableArgs{
									Table: pulumi.String("excludedTable"),
									MysqlColumns: datastream.StreamBackfillAllMysqlExcludedObjectsMysqlDatabaseMysqlTableMysqlColumnArray{
										&datastream.StreamBackfillAllMysqlExcludedObjectsMysqlDatabaseMysqlTableMysqlColumnArgs{
											Column:          pulumi.String("excludedColumn"),
											DataType:        pulumi.String("VARCHAR"),
											Collation:       pulumi.String("utf8mb4"),
											PrimaryKey:      pulumi.Bool(false),
											Nullable:        pulumi.Bool(false),
											OrdinalPosition: pulumi.Int(0),
										},
									},
								},
							},
						},
					},
				},
			},
			CustomerManagedEncryptionKey: pulumi.String("kms-name"),
		}, pulumi.DependsOn([]pulumi.Resource{
			keyUser,
		}))
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.organizations.OrganizationsFunctions;
import com.pulumi.gcp.organizations.inputs.GetProjectArgs;
import com.pulumi.gcp.sql.DatabaseInstance;
import com.pulumi.gcp.sql.DatabaseInstanceArgs;
import com.pulumi.gcp.sql.inputs.DatabaseInstanceSettingsArgs;
import com.pulumi.gcp.sql.inputs.DatabaseInstanceSettingsBackupConfigurationArgs;
import com.pulumi.gcp.sql.inputs.DatabaseInstanceSettingsIpConfigurationArgs;
import com.pulumi.gcp.sql.Database;
import com.pulumi.gcp.sql.DatabaseArgs;
import com.pulumi.random.RandomPassword;
import com.pulumi.random.RandomPasswordArgs;
import com.pulumi.gcp.sql.User;
import com.pulumi.gcp.sql.UserArgs;
import com.pulumi.gcp.datastream.ConnectionProfile;
import com.pulumi.gcp.datastream.ConnectionProfileArgs;
import com.pulumi.gcp.datastream.inputs.ConnectionProfileMysqlProfileArgs;
import com.pulumi.gcp.storage.Bucket;
import com.pulumi.gcp.storage.BucketArgs;
import com.pulumi.gcp.storage.BucketIAMMember;
import com.pulumi.gcp.storage.BucketIAMMemberArgs;
import com.pulumi.gcp.kms.CryptoKeyIAMMember;
import com.pulumi.gcp.kms.CryptoKeyIAMMemberArgs;
import com.pulumi.gcp.datastream.inputs.ConnectionProfileGcsProfileArgs;
import com.pulumi.gcp.datastream.Stream;
import com.pulumi.gcp.datastream.StreamArgs;
import com.pulumi.gcp.datastream.inputs.StreamSourceConfigArgs;
import com.pulumi.gcp.datastream.inputs.StreamSourceConfigMysqlSourceConfigArgs;
import com.pulumi.gcp.datastream.inputs.StreamSourceConfigMysqlSourceConfigIncludeObjectsArgs;
import com.pulumi.gcp.datastream.inputs.StreamSourceConfigMysqlSourceConfigExcludeObjectsArgs;
import com.pulumi.gcp.datastream.inputs.StreamDestinationConfigArgs;
import com.pulumi.gcp.datastream.inputs.StreamDestinationConfigGcsDestinationConfigArgs;
import com.pulumi.gcp.datastream.inputs.StreamDestinationConfigGcsDestinationConfigJsonFileFormatArgs;
import com.pulumi.gcp.datastream.inputs.StreamBackfillAllArgs;
import com.pulumi.gcp.datastream.inputs.StreamBackfillAllMysqlExcludedObjectsArgs;
import com.pulumi.resources.CustomResourceOptions;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        final var project = OrganizationsFunctions.getProject();

        var instance = new DatabaseInstance("instance", DatabaseInstanceArgs.builder()
            .name("my-instance")
            .databaseVersion("MYSQL_8_0")
            .region("us-central1")
            .settings(DatabaseInstanceSettingsArgs.builder()
                .tier("db-f1-micro")
                .backupConfiguration(DatabaseInstanceSettingsBackupConfigurationArgs.builder()
                    .enabled(true)
                    .binaryLogEnabled(true)
                    .build())
                .ipConfiguration(DatabaseInstanceSettingsIpConfigurationArgs.builder()
                    .authorizedNetworks(                    
                        DatabaseInstanceSettingsIpConfigurationAuthorizedNetworkArgs.builder()
                            .value("34.71.242.81")
                            .build(),
                        DatabaseInstanceSettingsIpConfigurationAuthorizedNetworkArgs.builder()
                            .value("34.72.28.29")
                            .build(),
                        DatabaseInstanceSettingsIpConfigurationAuthorizedNetworkArgs.builder()
                            .value("34.67.6.157")
                            .build(),
                        DatabaseInstanceSettingsIpConfigurationAuthorizedNetworkArgs.builder()
                            .value("34.67.234.134")
                            .build(),
                        DatabaseInstanceSettingsIpConfigurationAuthorizedNetworkArgs.builder()
                            .value("34.72.239.218")
                            .build())
                    .build())
                .build())
            .deletionProtection(true)
            .build());

        var db = new Database("db", DatabaseArgs.builder()
            .instance(instance.name())
            .name("db")
            .build());

        var pwd = new RandomPassword("pwd", RandomPasswordArgs.builder()
            .length(16)
            .special(false)
            .build());

        var user = new User("user", UserArgs.builder()
            .name("user")
            .instance(instance.name())
            .host("%")
            .password(pwd.result())
            .build());

        var sourceConnectionProfile = new ConnectionProfile("sourceConnectionProfile", ConnectionProfileArgs.builder()
            .displayName("Source connection profile")
            .location("us-central1")
            .connectionProfileId("source-profile")
            .mysqlProfile(ConnectionProfileMysqlProfileArgs.builder()
                .hostname(instance.publicIpAddress())
                .username(user.name())
                .password(user.password())
                .build())
            .build());

        var bucket = new Bucket("bucket", BucketArgs.builder()
            .name("my-bucket")
            .location("US")
            .uniformBucketLevelAccess(true)
            .build());

        var viewer = new BucketIAMMember("viewer", BucketIAMMemberArgs.builder()
            .bucket(bucket.name())
            .role("roles/storage.objectViewer")
            .member(String.format("serviceAccount:service-%s@gcp-sa-datastream.iam.gserviceaccount.com", project.applyValue(getProjectResult -> getProjectResult.number())))
            .build());

        var creator = new BucketIAMMember("creator", BucketIAMMemberArgs.builder()
            .bucket(bucket.name())
            .role("roles/storage.objectCreator")
            .member(String.format("serviceAccount:service-%s@gcp-sa-datastream.iam.gserviceaccount.com", project.applyValue(getProjectResult -> getProjectResult.number())))
            .build());

        var reader = new BucketIAMMember("reader", BucketIAMMemberArgs.builder()
            .bucket(bucket.name())
            .role("roles/storage.legacyBucketReader")
            .member(String.format("serviceAccount:service-%s@gcp-sa-datastream.iam.gserviceaccount.com", project.applyValue(getProjectResult -> getProjectResult.number())))
            .build());

        var keyUser = new CryptoKeyIAMMember("keyUser", CryptoKeyIAMMemberArgs.builder()
            .cryptoKeyId("kms-name")
            .role("roles/cloudkms.cryptoKeyEncrypterDecrypter")
            .member(String.format("serviceAccount:service-%s@gcp-sa-datastream.iam.gserviceaccount.com", project.applyValue(getProjectResult -> getProjectResult.number())))
            .build());

        var destinationConnectionProfile = new ConnectionProfile("destinationConnectionProfile", ConnectionProfileArgs.builder()
            .displayName("Connection profile")
            .location("us-central1")
            .connectionProfileId("destination-profile")
            .gcsProfile(ConnectionProfileGcsProfileArgs.builder()
                .bucket(bucket.name())
                .rootPath("/path")
                .build())
            .build());

        var default_ = new Stream("default", StreamArgs.builder()
            .streamId("my-stream")
            .desiredState("NOT_STARTED")
            .location("us-central1")
            .displayName("my stream")
            .labels(Map.of("key", "value"))
            .sourceConfig(StreamSourceConfigArgs.builder()
                .sourceConnectionProfile(sourceConnectionProfile.id())
                .mysqlSourceConfig(StreamSourceConfigMysqlSourceConfigArgs.builder()
                    .includeObjects(StreamSourceConfigMysqlSourceConfigIncludeObjectsArgs.builder()
                        .mysqlDatabases(StreamSourceConfigMysqlSourceConfigIncludeObjectsMysqlDatabaseArgs.builder()
                            .database("my-database")
                            .mysqlTables(                            
                                StreamSourceConfigMysqlSourceConfigIncludeObjectsMysqlDatabaseMysqlTableArgs.builder()
                                    .table("includedTable")
                                    .mysqlColumns(StreamSourceConfigMysqlSourceConfigIncludeObjectsMysqlDatabaseMysqlTableMysqlColumnArgs.builder()
                                        .column("includedColumn")
                                        .dataType("VARCHAR")
                                        .collation("utf8mb4")
                                        .primaryKey(false)
                                        .nullable(false)
                                        .ordinalPosition(0)
                                        .build())
                                    .build(),
                                StreamSourceConfigMysqlSourceConfigIncludeObjectsMysqlDatabaseMysqlTableArgs.builder()
                                    .table("includedTable_2")
                                    .build())
                            .build())
                        .build())
                    .excludeObjects(StreamSourceConfigMysqlSourceConfigExcludeObjectsArgs.builder()
                        .mysqlDatabases(StreamSourceConfigMysqlSourceConfigExcludeObjectsMysqlDatabaseArgs.builder()
                            .database("my-database")
                            .mysqlTables(StreamSourceConfigMysqlSourceConfigExcludeObjectsMysqlDatabaseMysqlTableArgs.builder()
                                .table("excludedTable")
                                .mysqlColumns(StreamSourceConfigMysqlSourceConfigExcludeObjectsMysqlDatabaseMysqlTableMysqlColumnArgs.builder()
                                    .column("excludedColumn")
                                    .dataType("VARCHAR")
                                    .collation("utf8mb4")
                                    .primaryKey(false)
                                    .nullable(false)
                                    .ordinalPosition(0)
                                    .build())
                                .build())
                            .build())
                        .build())
                    .maxConcurrentCdcTasks(5)
                    .build())
                .build())
            .destinationConfig(StreamDestinationConfigArgs.builder()
                .destinationConnectionProfile(destinationConnectionProfile.id())
                .gcsDestinationConfig(StreamDestinationConfigGcsDestinationConfigArgs.builder()
                    .path("mydata")
                    .fileRotationMb(200)
                    .fileRotationInterval("60s")
                    .jsonFileFormat(StreamDestinationConfigGcsDestinationConfigJsonFileFormatArgs.builder()
                        .schemaFileFormat("NO_SCHEMA_FILE")
                        .compression("GZIP")
                        .build())
                    .build())
                .build())
            .backfillAll(StreamBackfillAllArgs.builder()
                .mysqlExcludedObjects(StreamBackfillAllMysqlExcludedObjectsArgs.builder()
                    .mysqlDatabases(StreamBackfillAllMysqlExcludedObjectsMysqlDatabaseArgs.builder()
                        .database("my-database")
                        .mysqlTables(StreamBackfillAllMysqlExcludedObjectsMysqlDatabaseMysqlTableArgs.builder()
                            .table("excludedTable")
                            .mysqlColumns(StreamBackfillAllMysqlExcludedObjectsMysqlDatabaseMysqlTableMysqlColumnArgs.builder()
                                .column("excludedColumn")
                                .dataType("VARCHAR")
                                .collation("utf8mb4")
                                .primaryKey(false)
                                .nullable(false)
                                .ordinalPosition(0)
                                .build())
                            .build())
                        .build())
                    .build())
                .build())
            .customerManagedEncryptionKey("kms-name")
            .build(), CustomResourceOptions.builder()
                .dependsOn(keyUser)
                .build());

    }
}
```
```yaml
resources:
  instance:
    type: gcp:sql:DatabaseInstance
    properties:
      name: my-instance
      databaseVersion: MYSQL_8_0
      region: us-central1
      settings:
        tier: db-f1-micro
        backupConfiguration:
          enabled: true
          binaryLogEnabled: true
        ipConfiguration:
          authorizedNetworks:
            - value: 34.71.242.81
            - value: 34.72.28.29
            - value: 34.67.6.157
            - value: 34.67.234.134
            - value: 34.72.239.218
      deletionProtection: true
  db:
    type: gcp:sql:Database
    properties:
      instance: ${instance.name}
      name: db
  pwd:
    type: random:RandomPassword
    properties:
      length: 16
      special: false
  user:
    type: gcp:sql:User
    properties:
      name: user
      instance: ${instance.name}
      host: '%'
      password: ${pwd.result}
  sourceConnectionProfile:
    type: gcp:datastream:ConnectionProfile
    name: source_connection_profile
    properties:
      displayName: Source connection profile
      location: us-central1
      connectionProfileId: source-profile
      mysqlProfile:
        hostname: ${instance.publicIpAddress}
        username: ${user.name}
        password: ${user.password}
  bucket:
    type: gcp:storage:Bucket
    properties:
      name: my-bucket
      location: US
      uniformBucketLevelAccess: true
  viewer:
    type: gcp:storage:BucketIAMMember
    properties:
      bucket: ${bucket.name}
      role: roles/storage.objectViewer
      member: serviceAccount:service-${project.number}@gcp-sa-datastream.iam.gserviceaccount.com
  creator:
    type: gcp:storage:BucketIAMMember
    properties:
      bucket: ${bucket.name}
      role: roles/storage.objectCreator
      member: serviceAccount:service-${project.number}@gcp-sa-datastream.iam.gserviceaccount.com
  reader:
    type: gcp:storage:BucketIAMMember
    properties:
      bucket: ${bucket.name}
      role: roles/storage.legacyBucketReader
      member: serviceAccount:service-${project.number}@gcp-sa-datastream.iam.gserviceaccount.com
  keyUser:
    type: gcp:kms:CryptoKeyIAMMember
    name: key_user
    properties:
      cryptoKeyId: kms-name
      role: roles/cloudkms.cryptoKeyEncrypterDecrypter
      member: serviceAccount:service-${project.number}@gcp-sa-datastream.iam.gserviceaccount.com
  destinationConnectionProfile:
    type: gcp:datastream:ConnectionProfile
    name: destination_connection_profile
    properties:
      displayName: Connection profile
      location: us-central1
      connectionProfileId: destination-profile
      gcsProfile:
        bucket: ${bucket.name}
        rootPath: /path
  default:
    type: gcp:datastream:Stream
    properties:
      streamId: my-stream
      desiredState: NOT_STARTED
      location: us-central1
      displayName: my stream
      labels:
        key: value
      sourceConfig:
        sourceConnectionProfile: ${sourceConnectionProfile.id}
        mysqlSourceConfig:
          includeObjects:
            mysqlDatabases:
              - database: my-database
                mysqlTables:
                  - table: includedTable
                    mysqlColumns:
                      - column: includedColumn
                        dataType: VARCHAR
                        collation: utf8mb4
                        primaryKey: false
                        nullable: false
                        ordinalPosition: 0
                  - table: includedTable_2
          excludeObjects:
            mysqlDatabases:
              - database: my-database
                mysqlTables:
                  - table: excludedTable
                    mysqlColumns:
                      - column: excludedColumn
                        dataType: VARCHAR
                        collation: utf8mb4
                        primaryKey: false
                        nullable: false
                        ordinalPosition: 0
          maxConcurrentCdcTasks: 5
      destinationConfig:
        destinationConnectionProfile: ${destinationConnectionProfile.id}
        gcsDestinationConfig:
          path: mydata
          fileRotationMb: 200
          fileRotationInterval: 60s
          jsonFileFormat:
            schemaFileFormat: NO_SCHEMA_FILE
            compression: GZIP
      backfillAll:
        mysqlExcludedObjects:
          mysqlDatabases:
            - database: my-database
              mysqlTables:
                - table: excludedTable
                  mysqlColumns:
                    - column: excludedColumn
                      dataType: VARCHAR
                      collation: utf8mb4
                      primaryKey: false
                      nullable: false
                      ordinalPosition: 0
      customerManagedEncryptionKey: kms-name
    options:
      dependsOn:
        - ${keyUser}
variables:
  project:
    fn::invoke:
      function: gcp:organizations:getProject
      arguments: {}
```
<!--End PulumiCodeChooser -->
### Datastream Stream Postgresql


<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const source = new gcp.datastream.ConnectionProfile("source", {
    displayName: "Postgresql Source",
    location: "us-central1",
    connectionProfileId: "source-profile",
    postgresqlProfile: {
        hostname: "hostname",
        port: 5432,
        username: "user",
        password: "pass",
        database: "postgres",
    },
});
const destination = new gcp.datastream.ConnectionProfile("destination", {
    displayName: "BigQuery Destination",
    location: "us-central1",
    connectionProfileId: "destination-profile",
    bigqueryProfile: {},
});
const _default = new gcp.datastream.Stream("default", {
    displayName: "Postgres to BigQuery",
    location: "us-central1",
    streamId: "my-stream",
    desiredState: "RUNNING",
    sourceConfig: {
        sourceConnectionProfile: source.id,
        postgresqlSourceConfig: {
            maxConcurrentBackfillTasks: 12,
            publication: "publication",
            replicationSlot: "replication_slot",
            includeObjects: {
                postgresqlSchemas: [{
                    schema: "schema",
                    postgresqlTables: [{
                        table: "table",
                        postgresqlColumns: [{
                            column: "column",
                        }],
                    }],
                }],
            },
            excludeObjects: {
                postgresqlSchemas: [{
                    schema: "schema",
                    postgresqlTables: [{
                        table: "table",
                        postgresqlColumns: [{
                            column: "column",
                        }],
                    }],
                }],
            },
        },
    },
    destinationConfig: {
        destinationConnectionProfile: destination.id,
        bigqueryDestinationConfig: {
            dataFreshness: "900s",
            sourceHierarchyDatasets: {
                datasetTemplate: {
                    location: "us-central1",
                },
            },
        },
    },
    backfillAll: {
        postgresqlExcludedObjects: {
            postgresqlSchemas: [{
                schema: "schema",
                postgresqlTables: [{
                    table: "table",
                    postgresqlColumns: [{
                        column: "column",
                    }],
                }],
            }],
        },
    },
});
```
```python
import pulumi
import pulumi_gcp as gcp

source = gcp.datastream.ConnectionProfile("source",
    display_name="Postgresql Source",
    location="us-central1",
    connection_profile_id="source-profile",
    postgresql_profile={
        "hostname": "hostname",
        "port": 5432,
        "username": "user",
        "password": "pass",
        "database": "postgres",
    })
destination = gcp.datastream.ConnectionProfile("destination",
    display_name="BigQuery Destination",
    location="us-central1",
    connection_profile_id="destination-profile",
    bigquery_profile={})
default = gcp.datastream.Stream("default",
    display_name="Postgres to BigQuery",
    location="us-central1",
    stream_id="my-stream",
    desired_state="RUNNING",
    source_config={
        "source_connection_profile": source.id,
        "postgresql_source_config": {
            "max_concurrent_backfill_tasks": 12,
            "publication": "publication",
            "replication_slot": "replication_slot",
            "include_objects": {
                "postgresql_schemas": [{
                    "schema": "schema",
                    "postgresql_tables": [{
                        "table": "table",
                        "postgresql_columns": [{
                            "column": "column",
                        }],
                    }],
                }],
            },
            "exclude_objects": {
                "postgresql_schemas": [{
                    "schema": "schema",
                    "postgresql_tables": [{
                        "table": "table",
                        "postgresql_columns": [{
                            "column": "column",
                        }],
                    }],
                }],
            },
        },
    },
    destination_config={
        "destination_connection_profile": destination.id,
        "bigquery_destination_config": {
            "data_freshness": "900s",
            "source_hierarchy_datasets": {
                "dataset_template": {
                    "location": "us-central1",
                },
            },
        },
    },
    backfill_all={
        "postgresql_excluded_objects": {
            "postgresql_schemas": [{
                "schema": "schema",
                "postgresql_tables": [{
                    "table": "table",
                    "postgresql_columns": [{
                        "column": "column",
                    }],
                }],
            }],
        },
    })
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var source = new Gcp.Datastream.ConnectionProfile("source", new()
    {
        DisplayName = "Postgresql Source",
        Location = "us-central1",
        ConnectionProfileId = "source-profile",
        PostgresqlProfile = new Gcp.Datastream.Inputs.ConnectionProfilePostgresqlProfileArgs
        {
            Hostname = "hostname",
            Port = 5432,
            Username = "user",
            Password = "pass",
            Database = "postgres",
        },
    });

    var destination = new Gcp.Datastream.ConnectionProfile("destination", new()
    {
        DisplayName = "BigQuery Destination",
        Location = "us-central1",
        ConnectionProfileId = "destination-profile",
        BigqueryProfile = null,
    });

    var @default = new Gcp.Datastream.Stream("default", new()
    {
        DisplayName = "Postgres to BigQuery",
        Location = "us-central1",
        StreamId = "my-stream",
        DesiredState = "RUNNING",
        SourceConfig = new Gcp.Datastream.Inputs.StreamSourceConfigArgs
        {
            SourceConnectionProfile = source.Id,
            PostgresqlSourceConfig = new Gcp.Datastream.Inputs.StreamSourceConfigPostgresqlSourceConfigArgs
            {
                MaxConcurrentBackfillTasks = 12,
                Publication = "publication",
                ReplicationSlot = "replication_slot",
                IncludeObjects = new Gcp.Datastream.Inputs.StreamSourceConfigPostgresqlSourceConfigIncludeObjectsArgs
                {
                    PostgresqlSchemas = new[]
                    {
                        new Gcp.Datastream.Inputs.StreamSourceConfigPostgresqlSourceConfigIncludeObjectsPostgresqlSchemaArgs
                        {
                            Schema = "schema",
                            PostgresqlTables = new[]
                            {
                                new Gcp.Datastream.Inputs.StreamSourceConfigPostgresqlSourceConfigIncludeObjectsPostgresqlSchemaPostgresqlTableArgs
                                {
                                    Table = "table",
                                    PostgresqlColumns = new[]
                                    {
                                        new Gcp.Datastream.Inputs.StreamSourceConfigPostgresqlSourceConfigIncludeObjectsPostgresqlSchemaPostgresqlTablePostgresqlColumnArgs
                                        {
                                            Column = "column",
                                        },
                                    },
                                },
                            },
                        },
                    },
                },
                ExcludeObjects = new Gcp.Datastream.Inputs.StreamSourceConfigPostgresqlSourceConfigExcludeObjectsArgs
                {
                    PostgresqlSchemas = new[]
                    {
                        new Gcp.Datastream.Inputs.StreamSourceConfigPostgresqlSourceConfigExcludeObjectsPostgresqlSchemaArgs
                        {
                            Schema = "schema",
                            PostgresqlTables = new[]
                            {
                                new Gcp.Datastream.Inputs.StreamSourceConfigPostgresqlSourceConfigExcludeObjectsPostgresqlSchemaPostgresqlTableArgs
                                {
                                    Table = "table",
                                    PostgresqlColumns = new[]
                                    {
                                        new Gcp.Datastream.Inputs.StreamSourceConfigPostgresqlSourceConfigExcludeObjectsPostgresqlSchemaPostgresqlTablePostgresqlColumnArgs
                                        {
                                            Column = "column",
                                        },
                                    },
                                },
                            },
                        },
                    },
                },
            },
        },
        DestinationConfig = new Gcp.Datastream.Inputs.StreamDestinationConfigArgs
        {
            DestinationConnectionProfile = destination.Id,
            BigqueryDestinationConfig = new Gcp.Datastream.Inputs.StreamDestinationConfigBigqueryDestinationConfigArgs
            {
                DataFreshness = "900s",
                SourceHierarchyDatasets = new Gcp.Datastream.Inputs.StreamDestinationConfigBigqueryDestinationConfigSourceHierarchyDatasetsArgs
                {
                    DatasetTemplate = new Gcp.Datastream.Inputs.StreamDestinationConfigBigqueryDestinationConfigSourceHierarchyDatasetsDatasetTemplateArgs
                    {
                        Location = "us-central1",
                    },
                },
            },
        },
        BackfillAll = new Gcp.Datastream.Inputs.StreamBackfillAllArgs
        {
            PostgresqlExcludedObjects = new Gcp.Datastream.Inputs.StreamBackfillAllPostgresqlExcludedObjectsArgs
            {
                PostgresqlSchemas = new[]
                {
                    new Gcp.Datastream.Inputs.StreamBackfillAllPostgresqlExcludedObjectsPostgresqlSchemaArgs
                    {
                        Schema = "schema",
                        PostgresqlTables = new[]
                        {
                            new Gcp.Datastream.Inputs.StreamBackfillAllPostgresqlExcludedObjectsPostgresqlSchemaPostgresqlTableArgs
                            {
                                Table = "table",
                                PostgresqlColumns = new[]
                                {
                                    new Gcp.Datastream.Inputs.StreamBackfillAllPostgresqlExcludedObjectsPostgresqlSchemaPostgresqlTablePostgresqlColumnArgs
                                    {
                                        Column = "column",
                                    },
                                },
                            },
                        },
                    },
                },
            },
        },
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/datastream"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		source, err := datastream.NewConnectionProfile(ctx, "source", &datastream.ConnectionProfileArgs{
			DisplayName:         pulumi.String("Postgresql Source"),
			Location:            pulumi.String("us-central1"),
			ConnectionProfileId: pulumi.String("source-profile"),
			PostgresqlProfile: &datastream.ConnectionProfilePostgresqlProfileArgs{
				Hostname: pulumi.String("hostname"),
				Port:     pulumi.Int(5432),
				Username: pulumi.String("user"),
				Password: pulumi.String("pass"),
				Database: pulumi.String("postgres"),
			},
		})
		if err != nil {
			return err
		}
		destination, err := datastream.NewConnectionProfile(ctx, "destination", &datastream.ConnectionProfileArgs{
			DisplayName:         pulumi.String("BigQuery Destination"),
			Location:            pulumi.String("us-central1"),
			ConnectionProfileId: pulumi.String("destination-profile"),
			BigqueryProfile:     &datastream.ConnectionProfileBigqueryProfileArgs{},
		})
		if err != nil {
			return err
		}
		_, err = datastream.NewStream(ctx, "default", &datastream.StreamArgs{
			DisplayName:  pulumi.String("Postgres to BigQuery"),
			Location:     pulumi.String("us-central1"),
			StreamId:     pulumi.String("my-stream"),
			DesiredState: pulumi.String("RUNNING"),
			SourceConfig: &datastream.StreamSourceConfigArgs{
				SourceConnectionProfile: source.ID(),
				PostgresqlSourceConfig: &datastream.StreamSourceConfigPostgresqlSourceConfigArgs{
					MaxConcurrentBackfillTasks: pulumi.Int(12),
					Publication:                pulumi.String("publication"),
					ReplicationSlot:            pulumi.String("replication_slot"),
					IncludeObjects: &datastream.StreamSourceConfigPostgresqlSourceConfigIncludeObjectsArgs{
						PostgresqlSchemas: datastream.StreamSourceConfigPostgresqlSourceConfigIncludeObjectsPostgresqlSchemaArray{
							&datastream.StreamSourceConfigPostgresqlSourceConfigIncludeObjectsPostgresqlSchemaArgs{
								Schema: pulumi.String("schema"),
								PostgresqlTables: datastream.StreamSourceConfigPostgresqlSourceConfigIncludeObjectsPostgresqlSchemaPostgresqlTableArray{
									&datastream.StreamSourceConfigPostgresqlSourceConfigIncludeObjectsPostgresqlSchemaPostgresqlTableArgs{
										Table: pulumi.String("table"),
										PostgresqlColumns: datastream.StreamSourceConfigPostgresqlSourceConfigIncludeObjectsPostgresqlSchemaPostgresqlTablePostgresqlColumnArray{
											&datastream.StreamSourceConfigPostgresqlSourceConfigIncludeObjectsPostgresqlSchemaPostgresqlTablePostgresqlColumnArgs{
												Column: pulumi.String("column"),
											},
										},
									},
								},
							},
						},
					},
					ExcludeObjects: &datastream.StreamSourceConfigPostgresqlSourceConfigExcludeObjectsArgs{
						PostgresqlSchemas: datastream.StreamSourceConfigPostgresqlSourceConfigExcludeObjectsPostgresqlSchemaArray{
							&datastream.StreamSourceConfigPostgresqlSourceConfigExcludeObjectsPostgresqlSchemaArgs{
								Schema: pulumi.String("schema"),
								PostgresqlTables: datastream.StreamSourceConfigPostgresqlSourceConfigExcludeObjectsPostgresqlSchemaPostgresqlTableArray{
									&datastream.StreamSourceConfigPostgresqlSourceConfigExcludeObjectsPostgresqlSchemaPostgresqlTableArgs{
										Table: pulumi.String("table"),
										PostgresqlColumns: datastream.StreamSourceConfigPostgresqlSourceConfigExcludeObjectsPostgresqlSchemaPostgresqlTablePostgresqlColumnArray{
											&datastream.StreamSourceConfigPostgresqlSourceConfigExcludeObjectsPostgresqlSchemaPostgresqlTablePostgresqlColumnArgs{
												Column: pulumi.String("column"),
											},
										},
									},
								},
							},
						},
					},
				},
			},
			DestinationConfig: &datastream.StreamDestinationConfigArgs{
				DestinationConnectionProfile: destination.ID(),
				BigqueryDestinationConfig: &datastream.StreamDestinationConfigBigqueryDestinationConfigArgs{
					DataFreshness: pulumi.String("900s"),
					SourceHierarchyDatasets: &datastream.StreamDestinationConfigBigqueryDestinationConfigSourceHierarchyDatasetsArgs{
						DatasetTemplate: &datastream.StreamDestinationConfigBigqueryDestinationConfigSourceHierarchyDatasetsDatasetTemplateArgs{
							Location: pulumi.String("us-central1"),
						},
					},
				},
			},
			BackfillAll: &datastream.StreamBackfillAllArgs{
				PostgresqlExcludedObjects: &datastream.StreamBackfillAllPostgresqlExcludedObjectsArgs{
					PostgresqlSchemas: datastream.StreamBackfillAllPostgresqlExcludedObjectsPostgresqlSchemaArray{
						&datastream.StreamBackfillAllPostgresqlExcludedObjectsPostgresqlSchemaArgs{
							Schema: pulumi.String("schema"),
							PostgresqlTables: datastream.StreamBackfillAllPostgresqlExcludedObjectsPostgresqlSchemaPostgresqlTableArray{
								&datastream.StreamBackfillAllPostgresqlExcludedObjectsPostgresqlSchemaPostgresqlTableArgs{
									Table: pulumi.String("table"),
									PostgresqlColumns: datastream.StreamBackfillAllPostgresqlExcludedObjectsPostgresqlSchemaPostgresqlTablePostgresqlColumnArray{
										&datastream.StreamBackfillAllPostgresqlExcludedObjectsPostgresqlSchemaPostgresqlTablePostgresqlColumnArgs{
											Column: pulumi.String("column"),
										},
									},
								},
							},
						},
					},
				},
			},
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.datastream.ConnectionProfile;
import com.pulumi.gcp.datastream.ConnectionProfileArgs;
import com.pulumi.gcp.datastream.inputs.ConnectionProfilePostgresqlProfileArgs;
import com.pulumi.gcp.datastream.inputs.ConnectionProfileBigqueryProfileArgs;
import com.pulumi.gcp.datastream.Stream;
import com.pulumi.gcp.datastream.StreamArgs;
import com.pulumi.gcp.datastream.inputs.StreamSourceConfigArgs;
import com.pulumi.gcp.datastream.inputs.StreamSourceConfigPostgresqlSourceConfigArgs;
import com.pulumi.gcp.datastream.inputs.StreamSourceConfigPostgresqlSourceConfigIncludeObjectsArgs;
import com.pulumi.gcp.datastream.inputs.StreamSourceConfigPostgresqlSourceConfigExcludeObjectsArgs;
import com.pulumi.gcp.datastream.inputs.StreamDestinationConfigArgs;
import com.pulumi.gcp.datastream.inputs.StreamDestinationConfigBigqueryDestinationConfigArgs;
import com.pulumi.gcp.datastream.inputs.StreamDestinationConfigBigqueryDestinationConfigSourceHierarchyDatasetsArgs;
import com.pulumi.gcp.datastream.inputs.StreamDestinationConfigBigqueryDestinationConfigSourceHierarchyDatasetsDatasetTemplateArgs;
import com.pulumi.gcp.datastream.inputs.StreamBackfillAllArgs;
import com.pulumi.gcp.datastream.inputs.StreamBackfillAllPostgresqlExcludedObjectsArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        var source = new ConnectionProfile("source", ConnectionProfileArgs.builder()
            .displayName("Postgresql Source")
            .location("us-central1")
            .connectionProfileId("source-profile")
            .postgresqlProfile(ConnectionProfilePostgresqlProfileArgs.builder()
                .hostname("hostname")
                .port(5432)
                .username("user")
                .password("pass")
                .database("postgres")
                .build())
            .build());

        var destination = new ConnectionProfile("destination", ConnectionProfileArgs.builder()
            .displayName("BigQuery Destination")
            .location("us-central1")
            .connectionProfileId("destination-profile")
            .bigqueryProfile()
            .build());

        var default_ = new Stream("default", StreamArgs.builder()
            .displayName("Postgres to BigQuery")
            .location("us-central1")
            .streamId("my-stream")
            .desiredState("RUNNING")
            .sourceConfig(StreamSourceConfigArgs.builder()
                .sourceConnectionProfile(source.id())
                .postgresqlSourceConfig(StreamSourceConfigPostgresqlSourceConfigArgs.builder()
                    .maxConcurrentBackfillTasks(12)
                    .publication("publication")
                    .replicationSlot("replication_slot")
                    .includeObjects(StreamSourceConfigPostgresqlSourceConfigIncludeObjectsArgs.builder()
                        .postgresqlSchemas(StreamSourceConfigPostgresqlSourceConfigIncludeObjectsPostgresqlSchemaArgs.builder()
                            .schema("schema")
                            .postgresqlTables(StreamSourceConfigPostgresqlSourceConfigIncludeObjectsPostgresqlSchemaPostgresqlTableArgs.builder()
                                .table("table")
                                .postgresqlColumns(StreamSourceConfigPostgresqlSourceConfigIncludeObjectsPostgresqlSchemaPostgresqlTablePostgresqlColumnArgs.builder()
                                    .column("column")
                                    .build())
                                .build())
                            .build())
                        .build())
                    .excludeObjects(StreamSourceConfigPostgresqlSourceConfigExcludeObjectsArgs.builder()
                        .postgresqlSchemas(StreamSourceConfigPostgresqlSourceConfigExcludeObjectsPostgresqlSchemaArgs.builder()
                            .schema("schema")
                            .postgresqlTables(StreamSourceConfigPostgresqlSourceConfigExcludeObjectsPostgresqlSchemaPostgresqlTableArgs.builder()
                                .table("table")
                                .postgresqlColumns(StreamSourceConfigPostgresqlSourceConfigExcludeObjectsPostgresqlSchemaPostgresqlTablePostgresqlColumnArgs.builder()
                                    .column("column")
                                    .build())
                                .build())
                            .build())
                        .build())
                    .build())
                .build())
            .destinationConfig(StreamDestinationConfigArgs.builder()
                .destinationConnectionProfile(destination.id())
                .bigqueryDestinationConfig(StreamDestinationConfigBigqueryDestinationConfigArgs.builder()
                    .dataFreshness("900s")
                    .sourceHierarchyDatasets(StreamDestinationConfigBigqueryDestinationConfigSourceHierarchyDatasetsArgs.builder()
                        .datasetTemplate(StreamDestinationConfigBigqueryDestinationConfigSourceHierarchyDatasetsDatasetTemplateArgs.builder()
                            .location("us-central1")
                            .build())
                        .build())
                    .build())
                .build())
            .backfillAll(StreamBackfillAllArgs.builder()
                .postgresqlExcludedObjects(StreamBackfillAllPostgresqlExcludedObjectsArgs.builder()
                    .postgresqlSchemas(StreamBackfillAllPostgresqlExcludedObjectsPostgresqlSchemaArgs.builder()
                        .schema("schema")
                        .postgresqlTables(StreamBackfillAllPostgresqlExcludedObjectsPostgresqlSchemaPostgresqlTableArgs.builder()
                            .table("table")
                            .postgresqlColumns(StreamBackfillAllPostgresqlExcludedObjectsPostgresqlSchemaPostgresqlTablePostgresqlColumnArgs.builder()
                                .column("column")
                                .build())
                            .build())
                        .build())
                    .build())
                .build())
            .build());

    }
}
```
```yaml
resources:
  source:
    type: gcp:datastream:ConnectionProfile
    properties:
      displayName: Postgresql Source
      location: us-central1
      connectionProfileId: source-profile
      postgresqlProfile:
        hostname: hostname
        port: 5432
        username: user
        password: pass
        database: postgres
  destination:
    type: gcp:datastream:ConnectionProfile
    properties:
      displayName: BigQuery Destination
      location: us-central1
      connectionProfileId: destination-profile
      bigqueryProfile: {}
  default:
    type: gcp:datastream:Stream
    properties:
      displayName: Postgres to BigQuery
      location: us-central1
      streamId: my-stream
      desiredState: RUNNING
      sourceConfig:
        sourceConnectionProfile: ${source.id}
        postgresqlSourceConfig:
          maxConcurrentBackfillTasks: 12
          publication: publication
          replicationSlot: replication_slot
          includeObjects:
            postgresqlSchemas:
              - schema: schema
                postgresqlTables:
                  - table: table
                    postgresqlColumns:
                      - column: column
          excludeObjects:
            postgresqlSchemas:
              - schema: schema
                postgresqlTables:
                  - table: table
                    postgresqlColumns:
                      - column: column
      destinationConfig:
        destinationConnectionProfile: ${destination.id}
        bigqueryDestinationConfig:
          dataFreshness: 900s
          sourceHierarchyDatasets:
            datasetTemplate:
              location: us-central1
      backfillAll:
        postgresqlExcludedObjects:
          postgresqlSchemas:
            - schema: schema
              postgresqlTables:
                - table: table
                  postgresqlColumns:
                    - column: column
```
<!--End PulumiCodeChooser -->
### Datastream Stream Oracle


<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const source = new gcp.datastream.ConnectionProfile("source", {
    displayName: "Oracle Source",
    location: "us-central1",
    connectionProfileId: "source-profile",
    oracleProfile: {
        hostname: "hostname",
        port: 1521,
        username: "user",
        password: "pass",
        databaseService: "ORCL",
    },
});
const destination = new gcp.datastream.ConnectionProfile("destination", {
    displayName: "BigQuery Destination",
    location: "us-central1",
    connectionProfileId: "destination-profile",
    bigqueryProfile: {},
});
const stream5 = new gcp.datastream.Stream("stream5", {
    displayName: "Oracle to BigQuery",
    location: "us-central1",
    streamId: "my-stream",
    desiredState: "RUNNING",
    sourceConfig: {
        sourceConnectionProfile: source.id,
        oracleSourceConfig: {
            maxConcurrentCdcTasks: 8,
            maxConcurrentBackfillTasks: 12,
            includeObjects: {
                oracleSchemas: [{
                    schema: "schema",
                    oracleTables: [{
                        table: "table",
                        oracleColumns: [{
                            column: "column",
                        }],
                    }],
                }],
            },
            excludeObjects: {
                oracleSchemas: [{
                    schema: "schema",
                    oracleTables: [{
                        table: "table",
                        oracleColumns: [{
                            column: "column",
                        }],
                    }],
                }],
            },
            dropLargeObjects: {},
        },
    },
    destinationConfig: {
        destinationConnectionProfile: destination.id,
        bigqueryDestinationConfig: {
            dataFreshness: "900s",
            sourceHierarchyDatasets: {
                datasetTemplate: {
                    location: "us-central1",
                },
            },
        },
    },
    backfillAll: {
        oracleExcludedObjects: {
            oracleSchemas: [{
                schema: "schema",
                oracleTables: [{
                    table: "table",
                    oracleColumns: [{
                        column: "column",
                    }],
                }],
            }],
        },
    },
});
```
```python
import pulumi
import pulumi_gcp as gcp

source = gcp.datastream.ConnectionProfile("source",
    display_name="Oracle Source",
    location="us-central1",
    connection_profile_id="source-profile",
    oracle_profile={
        "hostname": "hostname",
        "port": 1521,
        "username": "user",
        "password": "pass",
        "database_service": "ORCL",
    })
destination = gcp.datastream.ConnectionProfile("destination",
    display_name="BigQuery Destination",
    location="us-central1",
    connection_profile_id="destination-profile",
    bigquery_profile={})
stream5 = gcp.datastream.Stream("stream5",
    display_name="Oracle to BigQuery",
    location="us-central1",
    stream_id="my-stream",
    desired_state="RUNNING",
    source_config={
        "source_connection_profile": source.id,
        "oracle_source_config": {
            "max_concurrent_cdc_tasks": 8,
            "max_concurrent_backfill_tasks": 12,
            "include_objects": {
                "oracle_schemas": [{
                    "schema": "schema",
                    "oracle_tables": [{
                        "table": "table",
                        "oracle_columns": [{
                            "column": "column",
                        }],
                    }],
                }],
            },
            "exclude_objects": {
                "oracle_schemas": [{
                    "schema": "schema",
                    "oracle_tables": [{
                        "table": "table",
                        "oracle_columns": [{
                            "column": "column",
                        }],
                    }],
                }],
            },
            "drop_large_objects": {},
        },
    },
    destination_config={
        "destination_connection_profile": destination.id,
        "bigquery_destination_config": {
            "data_freshness": "900s",
            "source_hierarchy_datasets": {
                "dataset_template": {
                    "location": "us-central1",
                },
            },
        },
    },
    backfill_all={
        "oracle_excluded_objects": {
            "oracle_schemas": [{
                "schema": "schema",
                "oracle_tables": [{
                    "table": "table",
                    "oracle_columns": [{
                        "column": "column",
                    }],
                }],
            }],
        },
    })
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var source = new Gcp.Datastream.ConnectionProfile("source", new()
    {
        DisplayName = "Oracle Source",
        Location = "us-central1",
        ConnectionProfileId = "source-profile",
        OracleProfile = new Gcp.Datastream.Inputs.ConnectionProfileOracleProfileArgs
        {
            Hostname = "hostname",
            Port = 1521,
            Username = "user",
            Password = "pass",
            DatabaseService = "ORCL",
        },
    });

    var destination = new Gcp.Datastream.ConnectionProfile("destination", new()
    {
        DisplayName = "BigQuery Destination",
        Location = "us-central1",
        ConnectionProfileId = "destination-profile",
        BigqueryProfile = null,
    });

    var stream5 = new Gcp.Datastream.Stream("stream5", new()
    {
        DisplayName = "Oracle to BigQuery",
        Location = "us-central1",
        StreamId = "my-stream",
        DesiredState = "RUNNING",
        SourceConfig = new Gcp.Datastream.Inputs.StreamSourceConfigArgs
        {
            SourceConnectionProfile = source.Id,
            OracleSourceConfig = new Gcp.Datastream.Inputs.StreamSourceConfigOracleSourceConfigArgs
            {
                MaxConcurrentCdcTasks = 8,
                MaxConcurrentBackfillTasks = 12,
                IncludeObjects = new Gcp.Datastream.Inputs.StreamSourceConfigOracleSourceConfigIncludeObjectsArgs
                {
                    OracleSchemas = new[]
                    {
                        new Gcp.Datastream.Inputs.StreamSourceConfigOracleSourceConfigIncludeObjectsOracleSchemaArgs
                        {
                            Schema = "schema",
                            OracleTables = new[]
                            {
                                new Gcp.Datastream.Inputs.StreamSourceConfigOracleSourceConfigIncludeObjectsOracleSchemaOracleTableArgs
                                {
                                    Table = "table",
                                    OracleColumns = new[]
                                    {
                                        new Gcp.Datastream.Inputs.StreamSourceConfigOracleSourceConfigIncludeObjectsOracleSchemaOracleTableOracleColumnArgs
                                        {
                                            Column = "column",
                                        },
                                    },
                                },
                            },
                        },
                    },
                },
                ExcludeObjects = new Gcp.Datastream.Inputs.StreamSourceConfigOracleSourceConfigExcludeObjectsArgs
                {
                    OracleSchemas = new[]
                    {
                        new Gcp.Datastream.Inputs.StreamSourceConfigOracleSourceConfigExcludeObjectsOracleSchemaArgs
                        {
                            Schema = "schema",
                            OracleTables = new[]
                            {
                                new Gcp.Datastream.Inputs.StreamSourceConfigOracleSourceConfigExcludeObjectsOracleSchemaOracleTableArgs
                                {
                                    Table = "table",
                                    OracleColumns = new[]
                                    {
                                        new Gcp.Datastream.Inputs.StreamSourceConfigOracleSourceConfigExcludeObjectsOracleSchemaOracleTableOracleColumnArgs
                                        {
                                            Column = "column",
                                        },
                                    },
                                },
                            },
                        },
                    },
                },
                DropLargeObjects = null,
            },
        },
        DestinationConfig = new Gcp.Datastream.Inputs.StreamDestinationConfigArgs
        {
            DestinationConnectionProfile = destination.Id,
            BigqueryDestinationConfig = new Gcp.Datastream.Inputs.StreamDestinationConfigBigqueryDestinationConfigArgs
            {
                DataFreshness = "900s",
                SourceHierarchyDatasets = new Gcp.Datastream.Inputs.StreamDestinationConfigBigqueryDestinationConfigSourceHierarchyDatasetsArgs
                {
                    DatasetTemplate = new Gcp.Datastream.Inputs.StreamDestinationConfigBigqueryDestinationConfigSourceHierarchyDatasetsDatasetTemplateArgs
                    {
                        Location = "us-central1",
                    },
                },
            },
        },
        BackfillAll = new Gcp.Datastream.Inputs.StreamBackfillAllArgs
        {
            OracleExcludedObjects = new Gcp.Datastream.Inputs.StreamBackfillAllOracleExcludedObjectsArgs
            {
                OracleSchemas = new[]
                {
                    new Gcp.Datastream.Inputs.StreamBackfillAllOracleExcludedObjectsOracleSchemaArgs
                    {
                        Schema = "schema",
                        OracleTables = new[]
                        {
                            new Gcp.Datastream.Inputs.StreamBackfillAllOracleExcludedObjectsOracleSchemaOracleTableArgs
                            {
                                Table = "table",
                                OracleColumns = new[]
                                {
                                    new Gcp.Datastream.Inputs.StreamBackfillAllOracleExcludedObjectsOracleSchemaOracleTableOracleColumnArgs
                                    {
                                        Column = "column",
                                    },
                                },
                            },
                        },
                    },
                },
            },
        },
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/datastream"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		source, err := datastream.NewConnectionProfile(ctx, "source", &datastream.ConnectionProfileArgs{
			DisplayName:         pulumi.String("Oracle Source"),
			Location:            pulumi.String("us-central1"),
			ConnectionProfileId: pulumi.String("source-profile"),
			OracleProfile: &datastream.ConnectionProfileOracleProfileArgs{
				Hostname:        pulumi.String("hostname"),
				Port:            pulumi.Int(1521),
				Username:        pulumi.String("user"),
				Password:        pulumi.String("pass"),
				DatabaseService: pulumi.String("ORCL"),
			},
		})
		if err != nil {
			return err
		}
		destination, err := datastream.NewConnectionProfile(ctx, "destination", &datastream.ConnectionProfileArgs{
			DisplayName:         pulumi.String("BigQuery Destination"),
			Location:            pulumi.String("us-central1"),
			ConnectionProfileId: pulumi.String("destination-profile"),
			BigqueryProfile:     &datastream.ConnectionProfileBigqueryProfileArgs{},
		})
		if err != nil {
			return err
		}
		_, err = datastream.NewStream(ctx, "stream5", &datastream.StreamArgs{
			DisplayName:  pulumi.String("Oracle to BigQuery"),
			Location:     pulumi.String("us-central1"),
			StreamId:     pulumi.String("my-stream"),
			DesiredState: pulumi.String("RUNNING"),
			SourceConfig: &datastream.StreamSourceConfigArgs{
				SourceConnectionProfile: source.ID(),
				OracleSourceConfig: &datastream.StreamSourceConfigOracleSourceConfigArgs{
					MaxConcurrentCdcTasks:      pulumi.Int(8),
					MaxConcurrentBackfillTasks: pulumi.Int(12),
					IncludeObjects: &datastream.StreamSourceConfigOracleSourceConfigIncludeObjectsArgs{
						OracleSchemas: datastream.StreamSourceConfigOracleSourceConfigIncludeObjectsOracleSchemaArray{
							&datastream.StreamSourceConfigOracleSourceConfigIncludeObjectsOracleSchemaArgs{
								Schema: pulumi.String("schema"),
								OracleTables: datastream.StreamSourceConfigOracleSourceConfigIncludeObjectsOracleSchemaOracleTableArray{
									&datastream.StreamSourceConfigOracleSourceConfigIncludeObjectsOracleSchemaOracleTableArgs{
										Table: pulumi.String("table"),
										OracleColumns: datastream.StreamSourceConfigOracleSourceConfigIncludeObjectsOracleSchemaOracleTableOracleColumnArray{
											&datastream.StreamSourceConfigOracleSourceConfigIncludeObjectsOracleSchemaOracleTableOracleColumnArgs{
												Column: pulumi.String("column"),
											},
										},
									},
								},
							},
						},
					},
					ExcludeObjects: &datastream.StreamSourceConfigOracleSourceConfigExcludeObjectsArgs{
						OracleSchemas: datastream.StreamSourceConfigOracleSourceConfigExcludeObjectsOracleSchemaArray{
							&datastream.StreamSourceConfigOracleSourceConfigExcludeObjectsOracleSchemaArgs{
								Schema: pulumi.String("schema"),
								OracleTables: datastream.StreamSourceConfigOracleSourceConfigExcludeObjectsOracleSchemaOracleTableArray{
									&datastream.StreamSourceConfigOracleSourceConfigExcludeObjectsOracleSchemaOracleTableArgs{
										Table: pulumi.String("table"),
										OracleColumns: datastream.StreamSourceConfigOracleSourceConfigExcludeObjectsOracleSchemaOracleTableOracleColumnArray{
											&datastream.StreamSourceConfigOracleSourceConfigExcludeObjectsOracleSchemaOracleTableOracleColumnArgs{
												Column: pulumi.String("column"),
											},
										},
									},
								},
							},
						},
					},
					DropLargeObjects: &datastream.StreamSourceConfigOracleSourceConfigDropLargeObjectsArgs{},
				},
			},
			DestinationConfig: &datastream.StreamDestinationConfigArgs{
				DestinationConnectionProfile: destination.ID(),
				BigqueryDestinationConfig: &datastream.StreamDestinationConfigBigqueryDestinationConfigArgs{
					DataFreshness: pulumi.String("900s"),
					SourceHierarchyDatasets: &datastream.StreamDestinationConfigBigqueryDestinationConfigSourceHierarchyDatasetsArgs{
						DatasetTemplate: &datastream.StreamDestinationConfigBigqueryDestinationConfigSourceHierarchyDatasetsDatasetTemplateArgs{
							Location: pulumi.String("us-central1"),
						},
					},
				},
			},
			BackfillAll: &datastream.StreamBackfillAllArgs{
				OracleExcludedObjects: &datastream.StreamBackfillAllOracleExcludedObjectsArgs{
					OracleSchemas: datastream.StreamBackfillAllOracleExcludedObjectsOracleSchemaArray{
						&datastream.StreamBackfillAllOracleExcludedObjectsOracleSchemaArgs{
							Schema: pulumi.String("schema"),
							OracleTables: datastream.StreamBackfillAllOracleExcludedObjectsOracleSchemaOracleTableArray{
								&datastream.StreamBackfillAllOracleExcludedObjectsOracleSchemaOracleTableArgs{
									Table: pulumi.String("table"),
									OracleColumns: datastream.StreamBackfillAllOracleExcludedObjectsOracleSchemaOracleTableOracleColumnArray{
										&datastream.StreamBackfillAllOracleExcludedObjectsOracleSchemaOracleTableOracleColumnArgs{
											Column: pulumi.String("column"),
										},
									},
								},
							},
						},
					},
				},
			},
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.datastream.ConnectionProfile;
import com.pulumi.gcp.datastream.ConnectionProfileArgs;
import com.pulumi.gcp.datastream.inputs.ConnectionProfileOracleProfileArgs;
import com.pulumi.gcp.datastream.inputs.ConnectionProfileBigqueryProfileArgs;
import com.pulumi.gcp.datastream.Stream;
import com.pulumi.gcp.datastream.StreamArgs;
import com.pulumi.gcp.datastream.inputs.StreamSourceConfigArgs;
import com.pulumi.gcp.datastream.inputs.StreamSourceConfigOracleSourceConfigArgs;
import com.pulumi.gcp.datastream.inputs.StreamSourceConfigOracleSourceConfigIncludeObjectsArgs;
import com.pulumi.gcp.datastream.inputs.StreamSourceConfigOracleSourceConfigExcludeObjectsArgs;
import com.pulumi.gcp.datastream.inputs.StreamSourceConfigOracleSourceConfigDropLargeObjectsArgs;
import com.pulumi.gcp.datastream.inputs.StreamDestinationConfigArgs;
import com.pulumi.gcp.datastream.inputs.StreamDestinationConfigBigqueryDestinationConfigArgs;
import com.pulumi.gcp.datastream.inputs.StreamDestinationConfigBigqueryDestinationConfigSourceHierarchyDatasetsArgs;
import com.pulumi.gcp.datastream.inputs.StreamDestinationConfigBigqueryDestinationConfigSourceHierarchyDatasetsDatasetTemplateArgs;
import com.pulumi.gcp.datastream.inputs.StreamBackfillAllArgs;
import com.pulumi.gcp.datastream.inputs.StreamBackfillAllOracleExcludedObjectsArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        var source = new ConnectionProfile("source", ConnectionProfileArgs.builder()
            .displayName("Oracle Source")
            .location("us-central1")
            .connectionProfileId("source-profile")
            .oracleProfile(ConnectionProfileOracleProfileArgs.builder()
                .hostname("hostname")
                .port(1521)
                .username("user")
                .password("pass")
                .databaseService("ORCL")
                .build())
            .build());

        var destination = new ConnectionProfile("destination", ConnectionProfileArgs.builder()
            .displayName("BigQuery Destination")
            .location("us-central1")
            .connectionProfileId("destination-profile")
            .bigqueryProfile()
            .build());

        var stream5 = new Stream("stream5", StreamArgs.builder()
            .displayName("Oracle to BigQuery")
            .location("us-central1")
            .streamId("my-stream")
            .desiredState("RUNNING")
            .sourceConfig(StreamSourceConfigArgs.builder()
                .sourceConnectionProfile(source.id())
                .oracleSourceConfig(StreamSourceConfigOracleSourceConfigArgs.builder()
                    .maxConcurrentCdcTasks(8)
                    .maxConcurrentBackfillTasks(12)
                    .includeObjects(StreamSourceConfigOracleSourceConfigIncludeObjectsArgs.builder()
                        .oracleSchemas(StreamSourceConfigOracleSourceConfigIncludeObjectsOracleSchemaArgs.builder()
                            .schema("schema")
                            .oracleTables(StreamSourceConfigOracleSourceConfigIncludeObjectsOracleSchemaOracleTableArgs.builder()
                                .table("table")
                                .oracleColumns(StreamSourceConfigOracleSourceConfigIncludeObjectsOracleSchemaOracleTableOracleColumnArgs.builder()
                                    .column("column")
                                    .build())
                                .build())
                            .build())
                        .build())
                    .excludeObjects(StreamSourceConfigOracleSourceConfigExcludeObjectsArgs.builder()
                        .oracleSchemas(StreamSourceConfigOracleSourceConfigExcludeObjectsOracleSchemaArgs.builder()
                            .schema("schema")
                            .oracleTables(StreamSourceConfigOracleSourceConfigExcludeObjectsOracleSchemaOracleTableArgs.builder()
                                .table("table")
                                .oracleColumns(StreamSourceConfigOracleSourceConfigExcludeObjectsOracleSchemaOracleTableOracleColumnArgs.builder()
                                    .column("column")
                                    .build())
                                .build())
                            .build())
                        .build())
                    .dropLargeObjects()
                    .build())
                .build())
            .destinationConfig(StreamDestinationConfigArgs.builder()
                .destinationConnectionProfile(destination.id())
                .bigqueryDestinationConfig(StreamDestinationConfigBigqueryDestinationConfigArgs.builder()
                    .dataFreshness("900s")
                    .sourceHierarchyDatasets(StreamDestinationConfigBigqueryDestinationConfigSourceHierarchyDatasetsArgs.builder()
                        .datasetTemplate(StreamDestinationConfigBigqueryDestinationConfigSourceHierarchyDatasetsDatasetTemplateArgs.builder()
                            .location("us-central1")
                            .build())
                        .build())
                    .build())
                .build())
            .backfillAll(StreamBackfillAllArgs.builder()
                .oracleExcludedObjects(StreamBackfillAllOracleExcludedObjectsArgs.builder()
                    .oracleSchemas(StreamBackfillAllOracleExcludedObjectsOracleSchemaArgs.builder()
                        .schema("schema")
                        .oracleTables(StreamBackfillAllOracleExcludedObjectsOracleSchemaOracleTableArgs.builder()
                            .table("table")
                            .oracleColumns(StreamBackfillAllOracleExcludedObjectsOracleSchemaOracleTableOracleColumnArgs.builder()
                                .column("column")
                                .build())
                            .build())
                        .build())
                    .build())
                .build())
            .build());

    }
}
```
```yaml
resources:
  source:
    type: gcp:datastream:ConnectionProfile
    properties:
      displayName: Oracle Source
      location: us-central1
      connectionProfileId: source-profile
      oracleProfile:
        hostname: hostname
        port: 1521
        username: user
        password: pass
        databaseService: ORCL
  destination:
    type: gcp:datastream:ConnectionProfile
    properties:
      displayName: BigQuery Destination
      location: us-central1
      connectionProfileId: destination-profile
      bigqueryProfile: {}
  stream5:
    type: gcp:datastream:Stream
    properties:
      displayName: Oracle to BigQuery
      location: us-central1
      streamId: my-stream
      desiredState: RUNNING
      sourceConfig:
        sourceConnectionProfile: ${source.id}
        oracleSourceConfig:
          maxConcurrentCdcTasks: 8
          maxConcurrentBackfillTasks: 12
          includeObjects:
            oracleSchemas:
              - schema: schema
                oracleTables:
                  - table: table
                    oracleColumns:
                      - column: column
          excludeObjects:
            oracleSchemas:
              - schema: schema
                oracleTables:
                  - table: table
                    oracleColumns:
                      - column: column
          dropLargeObjects: {}
      destinationConfig:
        destinationConnectionProfile: ${destination.id}
        bigqueryDestinationConfig:
          dataFreshness: 900s
          sourceHierarchyDatasets:
            datasetTemplate:
              location: us-central1
      backfillAll:
        oracleExcludedObjects:
          oracleSchemas:
            - schema: schema
              oracleTables:
                - table: table
                  oracleColumns:
                    - column: column
```
<!--End PulumiCodeChooser -->
### Datastream Stream Sql Server


<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const instance = new gcp.sql.DatabaseInstance("instance", {
    name: "sql-server",
    databaseVersion: "SQLSERVER_2019_STANDARD",
    region: "us-central1",
    rootPassword: "root-password",
    deletionProtection: true,
    settings: {
        tier: "db-custom-2-4096",
        ipConfiguration: {
            authorizedNetworks: [
                {
                    value: "34.71.242.81",
                },
                {
                    value: "34.72.28.29",
                },
                {
                    value: "34.67.6.157",
                },
                {
                    value: "34.67.234.134",
                },
                {
                    value: "34.72.239.218",
                },
            ],
        },
    },
});
const user = new gcp.sql.User("user", {
    name: "user",
    instance: instance.name,
    password: "password",
});
const db = new gcp.sql.Database("db", {
    name: "db",
    instance: instance.name,
}, {
    dependsOn: [user],
});
const source = new gcp.datastream.ConnectionProfile("source", {
    displayName: "SQL Server Source",
    location: "us-central1",
    connectionProfileId: "source-profile",
    sqlServerProfile: {
        hostname: instance.publicIpAddress,
        port: 1433,
        username: user.name,
        password: user.password,
        database: db.name,
    },
});
const destination = new gcp.datastream.ConnectionProfile("destination", {
    displayName: "BigQuery Destination",
    location: "us-central1",
    connectionProfileId: "destination-profile",
    bigqueryProfile: {},
});
const _default = new gcp.datastream.Stream("default", {
    displayName: "SQL Server to BigQuery",
    location: "us-central1",
    streamId: "stream",
    sourceConfig: {
        sourceConnectionProfile: source.id,
        sqlServerSourceConfig: {
            includeObjects: {
                schemas: [{
                    schema: "schema",
                    tables: [{
                        table: "table",
                    }],
                }],
            },
            transactionLogs: {},
        },
    },
    destinationConfig: {
        destinationConnectionProfile: destination.id,
        bigqueryDestinationConfig: {
            dataFreshness: "900s",
            sourceHierarchyDatasets: {
                datasetTemplate: {
                    location: "us-central1",
                },
            },
        },
    },
    backfillNone: {},
});
```
```python
import pulumi
import pulumi_gcp as gcp

instance = gcp.sql.DatabaseInstance("instance",
    name="sql-server",
    database_version="SQLSERVER_2019_STANDARD",
    region="us-central1",
    root_password="root-password",
    deletion_protection=True,
    settings={
        "tier": "db-custom-2-4096",
        "ip_configuration": {
            "authorized_networks": [
                {
                    "value": "34.71.242.81",
                },
                {
                    "value": "34.72.28.29",
                },
                {
                    "value": "34.67.6.157",
                },
                {
                    "value": "34.67.234.134",
                },
                {
                    "value": "34.72.239.218",
                },
            ],
        },
    })
user = gcp.sql.User("user",
    name="user",
    instance=instance.name,
    password="password")
db = gcp.sql.Database("db",
    name="db",
    instance=instance.name,
    opts = pulumi.ResourceOptions(depends_on=[user]))
source = gcp.datastream.ConnectionProfile("source",
    display_name="SQL Server Source",
    location="us-central1",
    connection_profile_id="source-profile",
    sql_server_profile={
        "hostname": instance.public_ip_address,
        "port": 1433,
        "username": user.name,
        "password": user.password,
        "database": db.name,
    })
destination = gcp.datastream.ConnectionProfile("destination",
    display_name="BigQuery Destination",
    location="us-central1",
    connection_profile_id="destination-profile",
    bigquery_profile={})
default = gcp.datastream.Stream("default",
    display_name="SQL Server to BigQuery",
    location="us-central1",
    stream_id="stream",
    source_config={
        "source_connection_profile": source.id,
        "sql_server_source_config": {
            "include_objects": {
                "schemas": [{
                    "schema": "schema",
                    "tables": [{
                        "table": "table",
                    }],
                }],
            },
            "transaction_logs": {},
        },
    },
    destination_config={
        "destination_connection_profile": destination.id,
        "bigquery_destination_config": {
            "data_freshness": "900s",
            "source_hierarchy_datasets": {
                "dataset_template": {
                    "location": "us-central1",
                },
            },
        },
    },
    backfill_none={})
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var instance = new Gcp.Sql.DatabaseInstance("instance", new()
    {
        Name = "sql-server",
        DatabaseVersion = "SQLSERVER_2019_STANDARD",
        Region = "us-central1",
        RootPassword = "root-password",
        DeletionProtection = true,
        Settings = new Gcp.Sql.Inputs.DatabaseInstanceSettingsArgs
        {
            Tier = "db-custom-2-4096",
            IpConfiguration = new Gcp.Sql.Inputs.DatabaseInstanceSettingsIpConfigurationArgs
            {
                AuthorizedNetworks = new[]
                {
                    new Gcp.Sql.Inputs.DatabaseInstanceSettingsIpConfigurationAuthorizedNetworkArgs
                    {
                        Value = "34.71.242.81",
                    },
                    new Gcp.Sql.Inputs.DatabaseInstanceSettingsIpConfigurationAuthorizedNetworkArgs
                    {
                        Value = "34.72.28.29",
                    },
                    new Gcp.Sql.Inputs.DatabaseInstanceSettingsIpConfigurationAuthorizedNetworkArgs
                    {
                        Value = "34.67.6.157",
                    },
                    new Gcp.Sql.Inputs.DatabaseInstanceSettingsIpConfigurationAuthorizedNetworkArgs
                    {
                        Value = "34.67.234.134",
                    },
                    new Gcp.Sql.Inputs.DatabaseInstanceSettingsIpConfigurationAuthorizedNetworkArgs
                    {
                        Value = "34.72.239.218",
                    },
                },
            },
        },
    });

    var user = new Gcp.Sql.User("user", new()
    {
        Name = "user",
        Instance = instance.Name,
        Password = "password",
    });

    var db = new Gcp.Sql.Database("db", new()
    {
        Name = "db",
        Instance = instance.Name,
    }, new CustomResourceOptions
    {
        DependsOn =
        {
            user,
        },
    });

    var source = new Gcp.Datastream.ConnectionProfile("source", new()
    {
        DisplayName = "SQL Server Source",
        Location = "us-central1",
        ConnectionProfileId = "source-profile",
        SqlServerProfile = new Gcp.Datastream.Inputs.ConnectionProfileSqlServerProfileArgs
        {
            Hostname = instance.PublicIpAddress,
            Port = 1433,
            Username = user.Name,
            Password = user.Password,
            Database = db.Name,
        },
    });

    var destination = new Gcp.Datastream.ConnectionProfile("destination", new()
    {
        DisplayName = "BigQuery Destination",
        Location = "us-central1",
        ConnectionProfileId = "destination-profile",
        BigqueryProfile = null,
    });

    var @default = new Gcp.Datastream.Stream("default", new()
    {
        DisplayName = "SQL Server to BigQuery",
        Location = "us-central1",
        StreamId = "stream",
        SourceConfig = new Gcp.Datastream.Inputs.StreamSourceConfigArgs
        {
            SourceConnectionProfile = source.Id,
            SqlServerSourceConfig = new Gcp.Datastream.Inputs.StreamSourceConfigSqlServerSourceConfigArgs
            {
                IncludeObjects = new Gcp.Datastream.Inputs.StreamSourceConfigSqlServerSourceConfigIncludeObjectsArgs
                {
                    Schemas = new[]
                    {
                        new Gcp.Datastream.Inputs.StreamSourceConfigSqlServerSourceConfigIncludeObjectsSchemaArgs
                        {
                            Schema = "schema",
                            Tables = new[]
                            {
                                new Gcp.Datastream.Inputs.StreamSourceConfigSqlServerSourceConfigIncludeObjectsSchemaTableArgs
                                {
                                    Table = "table",
                                },
                            },
                        },
                    },
                },
                TransactionLogs = null,
            },
        },
        DestinationConfig = new Gcp.Datastream.Inputs.StreamDestinationConfigArgs
        {
            DestinationConnectionProfile = destination.Id,
            BigqueryDestinationConfig = new Gcp.Datastream.Inputs.StreamDestinationConfigBigqueryDestinationConfigArgs
            {
                DataFreshness = "900s",
                SourceHierarchyDatasets = new Gcp.Datastream.Inputs.StreamDestinationConfigBigqueryDestinationConfigSourceHierarchyDatasetsArgs
                {
                    DatasetTemplate = new Gcp.Datastream.Inputs.StreamDestinationConfigBigqueryDestinationConfigSourceHierarchyDatasetsDatasetTemplateArgs
                    {
                        Location = "us-central1",
                    },
                },
            },
        },
        BackfillNone = null,
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/datastream"
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/sql"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		instance, err := sql.NewDatabaseInstance(ctx, "instance", &sql.DatabaseInstanceArgs{
			Name:               pulumi.String("sql-server"),
			DatabaseVersion:    pulumi.String("SQLSERVER_2019_STANDARD"),
			Region:             pulumi.String("us-central1"),
			RootPassword:       pulumi.String("root-password"),
			DeletionProtection: pulumi.Bool(true),
			Settings: &sql.DatabaseInstanceSettingsArgs{
				Tier: pulumi.String("db-custom-2-4096"),
				IpConfiguration: &sql.DatabaseInstanceSettingsIpConfigurationArgs{
					AuthorizedNetworks: sql.DatabaseInstanceSettingsIpConfigurationAuthorizedNetworkArray{
						&sql.DatabaseInstanceSettingsIpConfigurationAuthorizedNetworkArgs{
							Value: pulumi.String("34.71.242.81"),
						},
						&sql.DatabaseInstanceSettingsIpConfigurationAuthorizedNetworkArgs{
							Value: pulumi.String("34.72.28.29"),
						},
						&sql.DatabaseInstanceSettingsIpConfigurationAuthorizedNetworkArgs{
							Value: pulumi.String("34.67.6.157"),
						},
						&sql.DatabaseInstanceSettingsIpConfigurationAuthorizedNetworkArgs{
							Value: pulumi.String("34.67.234.134"),
						},
						&sql.DatabaseInstanceSettingsIpConfigurationAuthorizedNetworkArgs{
							Value: pulumi.String("34.72.239.218"),
						},
					},
				},
			},
		})
		if err != nil {
			return err
		}
		user, err := sql.NewUser(ctx, "user", &sql.UserArgs{
			Name:     pulumi.String("user"),
			Instance: instance.Name,
			Password: pulumi.String("password"),
		})
		if err != nil {
			return err
		}
		db, err := sql.NewDatabase(ctx, "db", &sql.DatabaseArgs{
			Name:     pulumi.String("db"),
			Instance: instance.Name,
		}, pulumi.DependsOn([]pulumi.Resource{
			user,
		}))
		if err != nil {
			return err
		}
		source, err := datastream.NewConnectionProfile(ctx, "source", &datastream.ConnectionProfileArgs{
			DisplayName:         pulumi.String("SQL Server Source"),
			Location:            pulumi.String("us-central1"),
			ConnectionProfileId: pulumi.String("source-profile"),
			SqlServerProfile: &datastream.ConnectionProfileSqlServerProfileArgs{
				Hostname: instance.PublicIpAddress,
				Port:     pulumi.Int(1433),
				Username: user.Name,
				Password: user.Password,
				Database: db.Name,
			},
		})
		if err != nil {
			return err
		}
		destination, err := datastream.NewConnectionProfile(ctx, "destination", &datastream.ConnectionProfileArgs{
			DisplayName:         pulumi.String("BigQuery Destination"),
			Location:            pulumi.String("us-central1"),
			ConnectionProfileId: pulumi.String("destination-profile"),
			BigqueryProfile:     &datastream.ConnectionProfileBigqueryProfileArgs{},
		})
		if err != nil {
			return err
		}
		_, err = datastream.NewStream(ctx, "default", &datastream.StreamArgs{
			DisplayName: pulumi.String("SQL Server to BigQuery"),
			Location:    pulumi.String("us-central1"),
			StreamId:    pulumi.String("stream"),
			SourceConfig: &datastream.StreamSourceConfigArgs{
				SourceConnectionProfile: source.ID(),
				SqlServerSourceConfig: &datastream.StreamSourceConfigSqlServerSourceConfigArgs{
					IncludeObjects: &datastream.StreamSourceConfigSqlServerSourceConfigIncludeObjectsArgs{
						Schemas: datastream.StreamSourceConfigSqlServerSourceConfigIncludeObjectsSchemaArray{
							&datastream.StreamSourceConfigSqlServerSourceConfigIncludeObjectsSchemaArgs{
								Schema: pulumi.String("schema"),
								Tables: datastream.StreamSourceConfigSqlServerSourceConfigIncludeObjectsSchemaTableArray{
									&datastream.StreamSourceConfigSqlServerSourceConfigIncludeObjectsSchemaTableArgs{
										Table: pulumi.String("table"),
									},
								},
							},
						},
					},
					TransactionLogs: &datastream.StreamSourceConfigSqlServerSourceConfigTransactionLogsArgs{},
				},
			},
			DestinationConfig: &datastream.StreamDestinationConfigArgs{
				DestinationConnectionProfile: destination.ID(),
				BigqueryDestinationConfig: &datastream.StreamDestinationConfigBigqueryDestinationConfigArgs{
					DataFreshness: pulumi.String("900s"),
					SourceHierarchyDatasets: &datastream.StreamDestinationConfigBigqueryDestinationConfigSourceHierarchyDatasetsArgs{
						DatasetTemplate: &datastream.StreamDestinationConfigBigqueryDestinationConfigSourceHierarchyDatasetsDatasetTemplateArgs{
							Location: pulumi.String("us-central1"),
						},
					},
				},
			},
			BackfillNone: &datastream.StreamBackfillNoneArgs{},
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.sql.DatabaseInstance;
import com.pulumi.gcp.sql.DatabaseInstanceArgs;
import com.pulumi.gcp.sql.inputs.DatabaseInstanceSettingsArgs;
import com.pulumi.gcp.sql.inputs.DatabaseInstanceSettingsIpConfigurationArgs;
import com.pulumi.gcp.sql.User;
import com.pulumi.gcp.sql.UserArgs;
import com.pulumi.gcp.sql.Database;
import com.pulumi.gcp.sql.DatabaseArgs;
import com.pulumi.gcp.datastream.ConnectionProfile;
import com.pulumi.gcp.datastream.ConnectionProfileArgs;
import com.pulumi.gcp.datastream.inputs.ConnectionProfileSqlServerProfileArgs;
import com.pulumi.gcp.datastream.inputs.ConnectionProfileBigqueryProfileArgs;
import com.pulumi.gcp.datastream.Stream;
import com.pulumi.gcp.datastream.StreamArgs;
import com.pulumi.gcp.datastream.inputs.StreamSourceConfigArgs;
import com.pulumi.gcp.datastream.inputs.StreamSourceConfigSqlServerSourceConfigArgs;
import com.pulumi.gcp.datastream.inputs.StreamSourceConfigSqlServerSourceConfigIncludeObjectsArgs;
import com.pulumi.gcp.datastream.inputs.StreamSourceConfigSqlServerSourceConfigTransactionLogsArgs;
import com.pulumi.gcp.datastream.inputs.StreamDestinationConfigArgs;
import com.pulumi.gcp.datastream.inputs.StreamDestinationConfigBigqueryDestinationConfigArgs;
import com.pulumi.gcp.datastream.inputs.StreamDestinationConfigBigqueryDestinationConfigSourceHierarchyDatasetsArgs;
import com.pulumi.gcp.datastream.inputs.StreamDestinationConfigBigqueryDestinationConfigSourceHierarchyDatasetsDatasetTemplateArgs;
import com.pulumi.gcp.datastream.inputs.StreamBackfillNoneArgs;
import com.pulumi.resources.CustomResourceOptions;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        var instance = new DatabaseInstance("instance", DatabaseInstanceArgs.builder()
            .name("sql-server")
            .databaseVersion("SQLSERVER_2019_STANDARD")
            .region("us-central1")
            .rootPassword("root-password")
            .deletionProtection(true)
            .settings(DatabaseInstanceSettingsArgs.builder()
                .tier("db-custom-2-4096")
                .ipConfiguration(DatabaseInstanceSettingsIpConfigurationArgs.builder()
                    .authorizedNetworks(                    
                        DatabaseInstanceSettingsIpConfigurationAuthorizedNetworkArgs.builder()
                            .value("34.71.242.81")
                            .build(),
                        DatabaseInstanceSettingsIpConfigurationAuthorizedNetworkArgs.builder()
                            .value("34.72.28.29")
                            .build(),
                        DatabaseInstanceSettingsIpConfigurationAuthorizedNetworkArgs.builder()
                            .value("34.67.6.157")
                            .build(),
                        DatabaseInstanceSettingsIpConfigurationAuthorizedNetworkArgs.builder()
                            .value("34.67.234.134")
                            .build(),
                        DatabaseInstanceSettingsIpConfigurationAuthorizedNetworkArgs.builder()
                            .value("34.72.239.218")
                            .build())
                    .build())
                .build())
            .build());

        var user = new User("user", UserArgs.builder()
            .name("user")
            .instance(instance.name())
            .password("password")
            .build());

        var db = new Database("db", DatabaseArgs.builder()
            .name("db")
            .instance(instance.name())
            .build(), CustomResourceOptions.builder()
                .dependsOn(user)
                .build());

        var source = new ConnectionProfile("source", ConnectionProfileArgs.builder()
            .displayName("SQL Server Source")
            .location("us-central1")
            .connectionProfileId("source-profile")
            .sqlServerProfile(ConnectionProfileSqlServerProfileArgs.builder()
                .hostname(instance.publicIpAddress())
                .port(1433)
                .username(user.name())
                .password(user.password())
                .database(db.name())
                .build())
            .build());

        var destination = new ConnectionProfile("destination", ConnectionProfileArgs.builder()
            .displayName("BigQuery Destination")
            .location("us-central1")
            .connectionProfileId("destination-profile")
            .bigqueryProfile()
            .build());

        var default_ = new Stream("default", StreamArgs.builder()
            .displayName("SQL Server to BigQuery")
            .location("us-central1")
            .streamId("stream")
            .sourceConfig(StreamSourceConfigArgs.builder()
                .sourceConnectionProfile(source.id())
                .sqlServerSourceConfig(StreamSourceConfigSqlServerSourceConfigArgs.builder()
                    .includeObjects(StreamSourceConfigSqlServerSourceConfigIncludeObjectsArgs.builder()
                        .schemas(StreamSourceConfigSqlServerSourceConfigIncludeObjectsSchemaArgs.builder()
                            .schema("schema")
                            .tables(StreamSourceConfigSqlServerSourceConfigIncludeObjectsSchemaTableArgs.builder()
                                .table("table")
                                .build())
                            .build())
                        .build())
                    .transactionLogs()
                    .build())
                .build())
            .destinationConfig(StreamDestinationConfigArgs.builder()
                .destinationConnectionProfile(destination.id())
                .bigqueryDestinationConfig(StreamDestinationConfigBigqueryDestinationConfigArgs.builder()
                    .dataFreshness("900s")
                    .sourceHierarchyDatasets(StreamDestinationConfigBigqueryDestinationConfigSourceHierarchyDatasetsArgs.builder()
                        .datasetTemplate(StreamDestinationConfigBigqueryDestinationConfigSourceHierarchyDatasetsDatasetTemplateArgs.builder()
                            .location("us-central1")
                            .build())
                        .build())
                    .build())
                .build())
            .backfillNone()
            .build());

    }
}
```
```yaml
resources:
  instance:
    type: gcp:sql:DatabaseInstance
    properties:
      name: sql-server
      databaseVersion: SQLSERVER_2019_STANDARD
      region: us-central1
      rootPassword: root-password
      deletionProtection: true
      settings:
        tier: db-custom-2-4096
        ipConfiguration:
          authorizedNetworks:
            - value: 34.71.242.81
            - value: 34.72.28.29
            - value: 34.67.6.157
            - value: 34.67.234.134
            - value: 34.72.239.218
  db:
    type: gcp:sql:Database
    properties:
      name: db
      instance: ${instance.name}
    options:
      dependsOn:
        - ${user}
  user:
    type: gcp:sql:User
    properties:
      name: user
      instance: ${instance.name}
      password: password
  source:
    type: gcp:datastream:ConnectionProfile
    properties:
      displayName: SQL Server Source
      location: us-central1
      connectionProfileId: source-profile
      sqlServerProfile:
        hostname: ${instance.publicIpAddress}
        port: 1433
        username: ${user.name}
        password: ${user.password}
        database: ${db.name}
  destination:
    type: gcp:datastream:ConnectionProfile
    properties:
      displayName: BigQuery Destination
      location: us-central1
      connectionProfileId: destination-profile
      bigqueryProfile: {}
  default:
    type: gcp:datastream:Stream
    properties:
      displayName: SQL Server to BigQuery
      location: us-central1
      streamId: stream
      sourceConfig:
        sourceConnectionProfile: ${source.id}
        sqlServerSourceConfig:
          includeObjects:
            schemas:
              - schema: schema
                tables:
                  - table: table
          transactionLogs: {}
      destinationConfig:
        destinationConnectionProfile: ${destination.id}
        bigqueryDestinationConfig:
          dataFreshness: 900s
          sourceHierarchyDatasets:
            datasetTemplate:
              location: us-central1
      backfillNone: {}
```
<!--End PulumiCodeChooser -->
### Datastream Stream Sql Server Change Tables


<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const instance = new gcp.sql.DatabaseInstance("instance", {
    name: "sql-server",
    databaseVersion: "SQLSERVER_2019_STANDARD",
    region: "us-central1",
    rootPassword: "root-password",
    deletionProtection: true,
    settings: {
        tier: "db-custom-2-4096",
        ipConfiguration: {
            authorizedNetworks: [
                {
                    value: "34.71.242.81",
                },
                {
                    value: "34.72.28.29",
                },
                {
                    value: "34.67.6.157",
                },
                {
                    value: "34.67.234.134",
                },
                {
                    value: "34.72.239.218",
                },
            ],
        },
    },
});
const user = new gcp.sql.User("user", {
    name: "user",
    instance: instance.name,
    password: "password",
});
const db = new gcp.sql.Database("db", {
    name: "db",
    instance: instance.name,
}, {
    dependsOn: [user],
});
const source = new gcp.datastream.ConnectionProfile("source", {
    displayName: "SQL Server Source",
    location: "us-central1",
    connectionProfileId: "source-profile",
    sqlServerProfile: {
        hostname: instance.publicIpAddress,
        port: 1433,
        username: user.name,
        password: user.password,
        database: db.name,
    },
});
const destination = new gcp.datastream.ConnectionProfile("destination", {
    displayName: "BigQuery Destination",
    location: "us-central1",
    connectionProfileId: "destination-profile",
    bigqueryProfile: {},
});
const _default = new gcp.datastream.Stream("default", {
    displayName: "SQL Server to BigQuery",
    location: "us-central1",
    streamId: "stream",
    sourceConfig: {
        sourceConnectionProfile: source.id,
        sqlServerSourceConfig: {
            includeObjects: {
                schemas: [{
                    schema: "schema",
                    tables: [{
                        table: "table",
                    }],
                }],
            },
            changeTables: {},
        },
    },
    destinationConfig: {
        destinationConnectionProfile: destination.id,
        bigqueryDestinationConfig: {
            dataFreshness: "900s",
            sourceHierarchyDatasets: {
                datasetTemplate: {
                    location: "us-central1",
                },
            },
        },
    },
    backfillNone: {},
});
```
```python
import pulumi
import pulumi_gcp as gcp

instance = gcp.sql.DatabaseInstance("instance",
    name="sql-server",
    database_version="SQLSERVER_2019_STANDARD",
    region="us-central1",
    root_password="root-password",
    deletion_protection=True,
    settings={
        "tier": "db-custom-2-4096",
        "ip_configuration": {
            "authorized_networks": [
                {
                    "value": "34.71.242.81",
                },
                {
                    "value": "34.72.28.29",
                },
                {
                    "value": "34.67.6.157",
                },
                {
                    "value": "34.67.234.134",
                },
                {
                    "value": "34.72.239.218",
                },
            ],
        },
    })
user = gcp.sql.User("user",
    name="user",
    instance=instance.name,
    password="password")
db = gcp.sql.Database("db",
    name="db",
    instance=instance.name,
    opts = pulumi.ResourceOptions(depends_on=[user]))
source = gcp.datastream.ConnectionProfile("source",
    display_name="SQL Server Source",
    location="us-central1",
    connection_profile_id="source-profile",
    sql_server_profile={
        "hostname": instance.public_ip_address,
        "port": 1433,
        "username": user.name,
        "password": user.password,
        "database": db.name,
    })
destination = gcp.datastream.ConnectionProfile("destination",
    display_name="BigQuery Destination",
    location="us-central1",
    connection_profile_id="destination-profile",
    bigquery_profile={})
default = gcp.datastream.Stream("default",
    display_name="SQL Server to BigQuery",
    location="us-central1",
    stream_id="stream",
    source_config={
        "source_connection_profile": source.id,
        "sql_server_source_config": {
            "include_objects": {
                "schemas": [{
                    "schema": "schema",
                    "tables": [{
                        "table": "table",
                    }],
                }],
            },
            "change_tables": {},
        },
    },
    destination_config={
        "destination_connection_profile": destination.id,
        "bigquery_destination_config": {
            "data_freshness": "900s",
            "source_hierarchy_datasets": {
                "dataset_template": {
                    "location": "us-central1",
                },
            },
        },
    },
    backfill_none={})
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var instance = new Gcp.Sql.DatabaseInstance("instance", new()
    {
        Name = "sql-server",
        DatabaseVersion = "SQLSERVER_2019_STANDARD",
        Region = "us-central1",
        RootPassword = "root-password",
        DeletionProtection = true,
        Settings = new Gcp.Sql.Inputs.DatabaseInstanceSettingsArgs
        {
            Tier = "db-custom-2-4096",
            IpConfiguration = new Gcp.Sql.Inputs.DatabaseInstanceSettingsIpConfigurationArgs
            {
                AuthorizedNetworks = new[]
                {
                    new Gcp.Sql.Inputs.DatabaseInstanceSettingsIpConfigurationAuthorizedNetworkArgs
                    {
                        Value = "34.71.242.81",
                    },
                    new Gcp.Sql.Inputs.DatabaseInstanceSettingsIpConfigurationAuthorizedNetworkArgs
                    {
                        Value = "34.72.28.29",
                    },
                    new Gcp.Sql.Inputs.DatabaseInstanceSettingsIpConfigurationAuthorizedNetworkArgs
                    {
                        Value = "34.67.6.157",
                    },
                    new Gcp.Sql.Inputs.DatabaseInstanceSettingsIpConfigurationAuthorizedNetworkArgs
                    {
                        Value = "34.67.234.134",
                    },
                    new Gcp.Sql.Inputs.DatabaseInstanceSettingsIpConfigurationAuthorizedNetworkArgs
                    {
                        Value = "34.72.239.218",
                    },
                },
            },
        },
    });

    var user = new Gcp.Sql.User("user", new()
    {
        Name = "user",
        Instance = instance.Name,
        Password = "password",
    });

    var db = new Gcp.Sql.Database("db", new()
    {
        Name = "db",
        Instance = instance.Name,
    }, new CustomResourceOptions
    {
        DependsOn =
        {
            user,
        },
    });

    var source = new Gcp.Datastream.ConnectionProfile("source", new()
    {
        DisplayName = "SQL Server Source",
        Location = "us-central1",
        ConnectionProfileId = "source-profile",
        SqlServerProfile = new Gcp.Datastream.Inputs.ConnectionProfileSqlServerProfileArgs
        {
            Hostname = instance.PublicIpAddress,
            Port = 1433,
            Username = user.Name,
            Password = user.Password,
            Database = db.Name,
        },
    });

    var destination = new Gcp.Datastream.ConnectionProfile("destination", new()
    {
        DisplayName = "BigQuery Destination",
        Location = "us-central1",
        ConnectionProfileId = "destination-profile",
        BigqueryProfile = null,
    });

    var @default = new Gcp.Datastream.Stream("default", new()
    {
        DisplayName = "SQL Server to BigQuery",
        Location = "us-central1",
        StreamId = "stream",
        SourceConfig = new Gcp.Datastream.Inputs.StreamSourceConfigArgs
        {
            SourceConnectionProfile = source.Id,
            SqlServerSourceConfig = new Gcp.Datastream.Inputs.StreamSourceConfigSqlServerSourceConfigArgs
            {
                IncludeObjects = new Gcp.Datastream.Inputs.StreamSourceConfigSqlServerSourceConfigIncludeObjectsArgs
                {
                    Schemas = new[]
                    {
                        new Gcp.Datastream.Inputs.StreamSourceConfigSqlServerSourceConfigIncludeObjectsSchemaArgs
                        {
                            Schema = "schema",
                            Tables = new[]
                            {
                                new Gcp.Datastream.Inputs.StreamSourceConfigSqlServerSourceConfigIncludeObjectsSchemaTableArgs
                                {
                                    Table = "table",
                                },
                            },
                        },
                    },
                },
                ChangeTables = null,
            },
        },
        DestinationConfig = new Gcp.Datastream.Inputs.StreamDestinationConfigArgs
        {
            DestinationConnectionProfile = destination.Id,
            BigqueryDestinationConfig = new Gcp.Datastream.Inputs.StreamDestinationConfigBigqueryDestinationConfigArgs
            {
                DataFreshness = "900s",
                SourceHierarchyDatasets = new Gcp.Datastream.Inputs.StreamDestinationConfigBigqueryDestinationConfigSourceHierarchyDatasetsArgs
                {
                    DatasetTemplate = new Gcp.Datastream.Inputs.StreamDestinationConfigBigqueryDestinationConfigSourceHierarchyDatasetsDatasetTemplateArgs
                    {
                        Location = "us-central1",
                    },
                },
            },
        },
        BackfillNone = null,
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/datastream"
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/sql"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		instance, err := sql.NewDatabaseInstance(ctx, "instance", &sql.DatabaseInstanceArgs{
			Name:               pulumi.String("sql-server"),
			DatabaseVersion:    pulumi.String("SQLSERVER_2019_STANDARD"),
			Region:             pulumi.String("us-central1"),
			RootPassword:       pulumi.String("root-password"),
			DeletionProtection: pulumi.Bool(true),
			Settings: &sql.DatabaseInstanceSettingsArgs{
				Tier: pulumi.String("db-custom-2-4096"),
				IpConfiguration: &sql.DatabaseInstanceSettingsIpConfigurationArgs{
					AuthorizedNetworks: sql.DatabaseInstanceSettingsIpConfigurationAuthorizedNetworkArray{
						&sql.DatabaseInstanceSettingsIpConfigurationAuthorizedNetworkArgs{
							Value: pulumi.String("34.71.242.81"),
						},
						&sql.DatabaseInstanceSettingsIpConfigurationAuthorizedNetworkArgs{
							Value: pulumi.String("34.72.28.29"),
						},
						&sql.DatabaseInstanceSettingsIpConfigurationAuthorizedNetworkArgs{
							Value: pulumi.String("34.67.6.157"),
						},
						&sql.DatabaseInstanceSettingsIpConfigurationAuthorizedNetworkArgs{
							Value: pulumi.String("34.67.234.134"),
						},
						&sql.DatabaseInstanceSettingsIpConfigurationAuthorizedNetworkArgs{
							Value: pulumi.String("34.72.239.218"),
						},
					},
				},
			},
		})
		if err != nil {
			return err
		}
		user, err := sql.NewUser(ctx, "user", &sql.UserArgs{
			Name:     pulumi.String("user"),
			Instance: instance.Name,
			Password: pulumi.String("password"),
		})
		if err != nil {
			return err
		}
		db, err := sql.NewDatabase(ctx, "db", &sql.DatabaseArgs{
			Name:     pulumi.String("db"),
			Instance: instance.Name,
		}, pulumi.DependsOn([]pulumi.Resource{
			user,
		}))
		if err != nil {
			return err
		}
		source, err := datastream.NewConnectionProfile(ctx, "source", &datastream.ConnectionProfileArgs{
			DisplayName:         pulumi.String("SQL Server Source"),
			Location:            pulumi.String("us-central1"),
			ConnectionProfileId: pulumi.String("source-profile"),
			SqlServerProfile: &datastream.ConnectionProfileSqlServerProfileArgs{
				Hostname: instance.PublicIpAddress,
				Port:     pulumi.Int(1433),
				Username: user.Name,
				Password: user.Password,
				Database: db.Name,
			},
		})
		if err != nil {
			return err
		}
		destination, err := datastream.NewConnectionProfile(ctx, "destination", &datastream.ConnectionProfileArgs{
			DisplayName:         pulumi.String("BigQuery Destination"),
			Location:            pulumi.String("us-central1"),
			ConnectionProfileId: pulumi.String("destination-profile"),
			BigqueryProfile:     &datastream.ConnectionProfileBigqueryProfileArgs{},
		})
		if err != nil {
			return err
		}
		_, err = datastream.NewStream(ctx, "default", &datastream.StreamArgs{
			DisplayName: pulumi.String("SQL Server to BigQuery"),
			Location:    pulumi.String("us-central1"),
			StreamId:    pulumi.String("stream"),
			SourceConfig: &datastream.StreamSourceConfigArgs{
				SourceConnectionProfile: source.ID(),
				SqlServerSourceConfig: &datastream.StreamSourceConfigSqlServerSourceConfigArgs{
					IncludeObjects: &datastream.StreamSourceConfigSqlServerSourceConfigIncludeObjectsArgs{
						Schemas: datastream.StreamSourceConfigSqlServerSourceConfigIncludeObjectsSchemaArray{
							&datastream.StreamSourceConfigSqlServerSourceConfigIncludeObjectsSchemaArgs{
								Schema: pulumi.String("schema"),
								Tables: datastream.StreamSourceConfigSqlServerSourceConfigIncludeObjectsSchemaTableArray{
									&datastream.StreamSourceConfigSqlServerSourceConfigIncludeObjectsSchemaTableArgs{
										Table: pulumi.String("table"),
									},
								},
							},
						},
					},
					ChangeTables: &datastream.StreamSourceConfigSqlServerSourceConfigChangeTablesArgs{},
				},
			},
			DestinationConfig: &datastream.StreamDestinationConfigArgs{
				DestinationConnectionProfile: destination.ID(),
				BigqueryDestinationConfig: &datastream.StreamDestinationConfigBigqueryDestinationConfigArgs{
					DataFreshness: pulumi.String("900s"),
					SourceHierarchyDatasets: &datastream.StreamDestinationConfigBigqueryDestinationConfigSourceHierarchyDatasetsArgs{
						DatasetTemplate: &datastream.StreamDestinationConfigBigqueryDestinationConfigSourceHierarchyDatasetsDatasetTemplateArgs{
							Location: pulumi.String("us-central1"),
						},
					},
				},
			},
			BackfillNone: &datastream.StreamBackfillNoneArgs{},
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.sql.DatabaseInstance;
import com.pulumi.gcp.sql.DatabaseInstanceArgs;
import com.pulumi.gcp.sql.inputs.DatabaseInstanceSettingsArgs;
import com.pulumi.gcp.sql.inputs.DatabaseInstanceSettingsIpConfigurationArgs;
import com.pulumi.gcp.sql.User;
import com.pulumi.gcp.sql.UserArgs;
import com.pulumi.gcp.sql.Database;
import com.pulumi.gcp.sql.DatabaseArgs;
import com.pulumi.gcp.datastream.ConnectionProfile;
import com.pulumi.gcp.datastream.ConnectionProfileArgs;
import com.pulumi.gcp.datastream.inputs.ConnectionProfileSqlServerProfileArgs;
import com.pulumi.gcp.datastream.inputs.ConnectionProfileBigqueryProfileArgs;
import com.pulumi.gcp.datastream.Stream;
import com.pulumi.gcp.datastream.StreamArgs;
import com.pulumi.gcp.datastream.inputs.StreamSourceConfigArgs;
import com.pulumi.gcp.datastream.inputs.StreamSourceConfigSqlServerSourceConfigArgs;
import com.pulumi.gcp.datastream.inputs.StreamSourceConfigSqlServerSourceConfigIncludeObjectsArgs;
import com.pulumi.gcp.datastream.inputs.StreamSourceConfigSqlServerSourceConfigChangeTablesArgs;
import com.pulumi.gcp.datastream.inputs.StreamDestinationConfigArgs;
import com.pulumi.gcp.datastream.inputs.StreamDestinationConfigBigqueryDestinationConfigArgs;
import com.pulumi.gcp.datastream.inputs.StreamDestinationConfigBigqueryDestinationConfigSourceHierarchyDatasetsArgs;
import com.pulumi.gcp.datastream.inputs.StreamDestinationConfigBigqueryDestinationConfigSourceHierarchyDatasetsDatasetTemplateArgs;
import com.pulumi.gcp.datastream.inputs.StreamBackfillNoneArgs;
import com.pulumi.resources.CustomResourceOptions;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        var instance = new DatabaseInstance("instance", DatabaseInstanceArgs.builder()
            .name("sql-server")
            .databaseVersion("SQLSERVER_2019_STANDARD")
            .region("us-central1")
            .rootPassword("root-password")
            .deletionProtection(true)
            .settings(DatabaseInstanceSettingsArgs.builder()
                .tier("db-custom-2-4096")
                .ipConfiguration(DatabaseInstanceSettingsIpConfigurationArgs.builder()
                    .authorizedNetworks(                    
                        DatabaseInstanceSettingsIpConfigurationAuthorizedNetworkArgs.builder()
                            .value("34.71.242.81")
                            .build(),
                        DatabaseInstanceSettingsIpConfigurationAuthorizedNetworkArgs.builder()
                            .value("34.72.28.29")
                            .build(),
                        DatabaseInstanceSettingsIpConfigurationAuthorizedNetworkArgs.builder()
                            .value("34.67.6.157")
                            .build(),
                        DatabaseInstanceSettingsIpConfigurationAuthorizedNetworkArgs.builder()
                            .value("34.67.234.134")
                            .build(),
                        DatabaseInstanceSettingsIpConfigurationAuthorizedNetworkArgs.builder()
                            .value("34.72.239.218")
                            .build())
                    .build())
                .build())
            .build());

        var user = new User("user", UserArgs.builder()
            .name("user")
            .instance(instance.name())
            .password("password")
            .build());

        var db = new Database("db", DatabaseArgs.builder()
            .name("db")
            .instance(instance.name())
            .build(), CustomResourceOptions.builder()
                .dependsOn(user)
                .build());

        var source = new ConnectionProfile("source", ConnectionProfileArgs.builder()
            .displayName("SQL Server Source")
            .location("us-central1")
            .connectionProfileId("source-profile")
            .sqlServerProfile(ConnectionProfileSqlServerProfileArgs.builder()
                .hostname(instance.publicIpAddress())
                .port(1433)
                .username(user.name())
                .password(user.password())
                .database(db.name())
                .build())
            .build());

        var destination = new ConnectionProfile("destination", ConnectionProfileArgs.builder()
            .displayName("BigQuery Destination")
            .location("us-central1")
            .connectionProfileId("destination-profile")
            .bigqueryProfile()
            .build());

        var default_ = new Stream("default", StreamArgs.builder()
            .displayName("SQL Server to BigQuery")
            .location("us-central1")
            .streamId("stream")
            .sourceConfig(StreamSourceConfigArgs.builder()
                .sourceConnectionProfile(source.id())
                .sqlServerSourceConfig(StreamSourceConfigSqlServerSourceConfigArgs.builder()
                    .includeObjects(StreamSourceConfigSqlServerSourceConfigIncludeObjectsArgs.builder()
                        .schemas(StreamSourceConfigSqlServerSourceConfigIncludeObjectsSchemaArgs.builder()
                            .schema("schema")
                            .tables(StreamSourceConfigSqlServerSourceConfigIncludeObjectsSchemaTableArgs.builder()
                                .table("table")
                                .build())
                            .build())
                        .build())
                    .changeTables()
                    .build())
                .build())
            .destinationConfig(StreamDestinationConfigArgs.builder()
                .destinationConnectionProfile(destination.id())
                .bigqueryDestinationConfig(StreamDestinationConfigBigqueryDestinationConfigArgs.builder()
                    .dataFreshness("900s")
                    .sourceHierarchyDatasets(StreamDestinationConfigBigqueryDestinationConfigSourceHierarchyDatasetsArgs.builder()
                        .datasetTemplate(StreamDestinationConfigBigqueryDestinationConfigSourceHierarchyDatasetsDatasetTemplateArgs.builder()
                            .location("us-central1")
                            .build())
                        .build())
                    .build())
                .build())
            .backfillNone()
            .build());

    }
}
```
```yaml
resources:
  instance:
    type: gcp:sql:DatabaseInstance
    properties:
      name: sql-server
      databaseVersion: SQLSERVER_2019_STANDARD
      region: us-central1
      rootPassword: root-password
      deletionProtection: true
      settings:
        tier: db-custom-2-4096
        ipConfiguration:
          authorizedNetworks:
            - value: 34.71.242.81
            - value: 34.72.28.29
            - value: 34.67.6.157
            - value: 34.67.234.134
            - value: 34.72.239.218
  db:
    type: gcp:sql:Database
    properties:
      name: db
      instance: ${instance.name}
    options:
      dependsOn:
        - ${user}
  user:
    type: gcp:sql:User
    properties:
      name: user
      instance: ${instance.name}
      password: password
  source:
    type: gcp:datastream:ConnectionProfile
    properties:
      displayName: SQL Server Source
      location: us-central1
      connectionProfileId: source-profile
      sqlServerProfile:
        hostname: ${instance.publicIpAddress}
        port: 1433
        username: ${user.name}
        password: ${user.password}
        database: ${db.name}
  destination:
    type: gcp:datastream:ConnectionProfile
    properties:
      displayName: BigQuery Destination
      location: us-central1
      connectionProfileId: destination-profile
      bigqueryProfile: {}
  default:
    type: gcp:datastream:Stream
    properties:
      displayName: SQL Server to BigQuery
      location: us-central1
      streamId: stream
      sourceConfig:
        sourceConnectionProfile: ${source.id}
        sqlServerSourceConfig:
          includeObjects:
            schemas:
              - schema: schema
                tables:
                  - table: table
          changeTables: {}
      destinationConfig:
        destinationConnectionProfile: ${destination.id}
        bigqueryDestinationConfig:
          dataFreshness: 900s
          sourceHierarchyDatasets:
            datasetTemplate:
              location: us-central1
      backfillNone: {}
```
<!--End PulumiCodeChooser -->
### Datastream Stream Postgresql Bigquery Dataset Id


<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";
import * as random from "@pulumi/random";

const postgres = new gcp.bigquery.Dataset("postgres", {
    datasetId: "postgres",
    friendlyName: "postgres",
    description: "Database of postgres",
    location: "us-central1",
});
const destinationConnectionProfile2 = new gcp.datastream.ConnectionProfile("destination_connection_profile2", {
    displayName: "Connection profile",
    location: "us-central1",
    connectionProfileId: "dest-profile",
    bigqueryProfile: {},
});
const instance = new gcp.sql.DatabaseInstance("instance", {
    name: "instance-name",
    databaseVersion: "MYSQL_8_0",
    region: "us-central1",
    settings: {
        tier: "db-f1-micro",
        backupConfiguration: {
            enabled: true,
            binaryLogEnabled: true,
        },
        ipConfiguration: {
            authorizedNetworks: [
                {
                    value: "34.71.242.81",
                },
                {
                    value: "34.72.28.29",
                },
                {
                    value: "34.67.6.157",
                },
                {
                    value: "34.67.234.134",
                },
                {
                    value: "34.72.239.218",
                },
            ],
        },
    },
    deletionProtection: false,
});
const pwd = new random.RandomPassword("pwd", {
    length: 16,
    special: false,
});
const user = new gcp.sql.User("user", {
    name: "my-user",
    instance: instance.name,
    host: "%",
    password: pwd.result,
});
const sourceConnectionProfile = new gcp.datastream.ConnectionProfile("source_connection_profile", {
    displayName: "Source connection profile",
    location: "us-central1",
    connectionProfileId: "source-profile",
    mysqlProfile: {
        hostname: instance.publicIpAddress,
        username: user.name,
        password: user.password,
    },
});
const _default = new gcp.datastream.Stream("default", {
    displayName: "postgres to bigQuery",
    location: "us-central1",
    streamId: "postgres-bigquery",
    sourceConfig: {
        sourceConnectionProfile: sourceConnectionProfile.id,
        mysqlSourceConfig: {},
    },
    destinationConfig: {
        destinationConnectionProfile: destinationConnectionProfile2.id,
        bigqueryDestinationConfig: {
            dataFreshness: "900s",
            singleTargetDataset: {
                datasetId: postgres.id,
            },
        },
    },
    backfillAll: {},
});
const db = new gcp.sql.Database("db", {
    instance: instance.name,
    name: "db",
});
```
```python
import pulumi
import pulumi_gcp as gcp
import pulumi_random as random

postgres = gcp.bigquery.Dataset("postgres",
    dataset_id="postgres",
    friendly_name="postgres",
    description="Database of postgres",
    location="us-central1")
destination_connection_profile2 = gcp.datastream.ConnectionProfile("destination_connection_profile2",
    display_name="Connection profile",
    location="us-central1",
    connection_profile_id="dest-profile",
    bigquery_profile={})
instance = gcp.sql.DatabaseInstance("instance",
    name="instance-name",
    database_version="MYSQL_8_0",
    region="us-central1",
    settings={
        "tier": "db-f1-micro",
        "backup_configuration": {
            "enabled": True,
            "binary_log_enabled": True,
        },
        "ip_configuration": {
            "authorized_networks": [
                {
                    "value": "34.71.242.81",
                },
                {
                    "value": "34.72.28.29",
                },
                {
                    "value": "34.67.6.157",
                },
                {
                    "value": "34.67.234.134",
                },
                {
                    "value": "34.72.239.218",
                },
            ],
        },
    },
    deletion_protection=False)
pwd = random.RandomPassword("pwd",
    length=16,
    special=False)
user = gcp.sql.User("user",
    name="my-user",
    instance=instance.name,
    host="%",
    password=pwd.result)
source_connection_profile = gcp.datastream.ConnectionProfile("source_connection_profile",
    display_name="Source connection profile",
    location="us-central1",
    connection_profile_id="source-profile",
    mysql_profile={
        "hostname": instance.public_ip_address,
        "username": user.name,
        "password": user.password,
    })
default = gcp.datastream.Stream("default",
    display_name="postgres to bigQuery",
    location="us-central1",
    stream_id="postgres-bigquery",
    source_config={
        "source_connection_profile": source_connection_profile.id,
        "mysql_source_config": {},
    },
    destination_config={
        "destination_connection_profile": destination_connection_profile2.id,
        "bigquery_destination_config": {
            "data_freshness": "900s",
            "single_target_dataset": {
                "dataset_id": postgres.id,
            },
        },
    },
    backfill_all={})
db = gcp.sql.Database("db",
    instance=instance.name,
    name="db")
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;
using Random = Pulumi.Random;

return await Deployment.RunAsync(() => 
{
    var postgres = new Gcp.BigQuery.Dataset("postgres", new()
    {
        DatasetId = "postgres",
        FriendlyName = "postgres",
        Description = "Database of postgres",
        Location = "us-central1",
    });

    var destinationConnectionProfile2 = new Gcp.Datastream.ConnectionProfile("destination_connection_profile2", new()
    {
        DisplayName = "Connection profile",
        Location = "us-central1",
        ConnectionProfileId = "dest-profile",
        BigqueryProfile = null,
    });

    var instance = new Gcp.Sql.DatabaseInstance("instance", new()
    {
        Name = "instance-name",
        DatabaseVersion = "MYSQL_8_0",
        Region = "us-central1",
        Settings = new Gcp.Sql.Inputs.DatabaseInstanceSettingsArgs
        {
            Tier = "db-f1-micro",
            BackupConfiguration = new Gcp.Sql.Inputs.DatabaseInstanceSettingsBackupConfigurationArgs
            {
                Enabled = true,
                BinaryLogEnabled = true,
            },
            IpConfiguration = new Gcp.Sql.Inputs.DatabaseInstanceSettingsIpConfigurationArgs
            {
                AuthorizedNetworks = new[]
                {
                    new Gcp.Sql.Inputs.DatabaseInstanceSettingsIpConfigurationAuthorizedNetworkArgs
                    {
                        Value = "34.71.242.81",
                    },
                    new Gcp.Sql.Inputs.DatabaseInstanceSettingsIpConfigurationAuthorizedNetworkArgs
                    {
                        Value = "34.72.28.29",
                    },
                    new Gcp.Sql.Inputs.DatabaseInstanceSettingsIpConfigurationAuthorizedNetworkArgs
                    {
                        Value = "34.67.6.157",
                    },
                    new Gcp.Sql.Inputs.DatabaseInstanceSettingsIpConfigurationAuthorizedNetworkArgs
                    {
                        Value = "34.67.234.134",
                    },
                    new Gcp.Sql.Inputs.DatabaseInstanceSettingsIpConfigurationAuthorizedNetworkArgs
                    {
                        Value = "34.72.239.218",
                    },
                },
            },
        },
        DeletionProtection = false,
    });

    var pwd = new Random.RandomPassword("pwd", new()
    {
        Length = 16,
        Special = false,
    });

    var user = new Gcp.Sql.User("user", new()
    {
        Name = "my-user",
        Instance = instance.Name,
        Host = "%",
        Password = pwd.Result,
    });

    var sourceConnectionProfile = new Gcp.Datastream.ConnectionProfile("source_connection_profile", new()
    {
        DisplayName = "Source connection profile",
        Location = "us-central1",
        ConnectionProfileId = "source-profile",
        MysqlProfile = new Gcp.Datastream.Inputs.ConnectionProfileMysqlProfileArgs
        {
            Hostname = instance.PublicIpAddress,
            Username = user.Name,
            Password = user.Password,
        },
    });

    var @default = new Gcp.Datastream.Stream("default", new()
    {
        DisplayName = "postgres to bigQuery",
        Location = "us-central1",
        StreamId = "postgres-bigquery",
        SourceConfig = new Gcp.Datastream.Inputs.StreamSourceConfigArgs
        {
            SourceConnectionProfile = sourceConnectionProfile.Id,
            MysqlSourceConfig = null,
        },
        DestinationConfig = new Gcp.Datastream.Inputs.StreamDestinationConfigArgs
        {
            DestinationConnectionProfile = destinationConnectionProfile2.Id,
            BigqueryDestinationConfig = new Gcp.Datastream.Inputs.StreamDestinationConfigBigqueryDestinationConfigArgs
            {
                DataFreshness = "900s",
                SingleTargetDataset = new Gcp.Datastream.Inputs.StreamDestinationConfigBigqueryDestinationConfigSingleTargetDatasetArgs
                {
                    DatasetId = postgres.Id,
                },
            },
        },
        BackfillAll = null,
    });

    var db = new Gcp.Sql.Database("db", new()
    {
        Instance = instance.Name,
        Name = "db",
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/bigquery"
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/datastream"
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/sql"
	"github.com/pulumi/pulumi-random/sdk/v4/go/random"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		postgres, err := bigquery.NewDataset(ctx, "postgres", &bigquery.DatasetArgs{
			DatasetId:    pulumi.String("postgres"),
			FriendlyName: pulumi.String("postgres"),
			Description:  pulumi.String("Database of postgres"),
			Location:     pulumi.String("us-central1"),
		})
		if err != nil {
			return err
		}
		destinationConnectionProfile2, err := datastream.NewConnectionProfile(ctx, "destination_connection_profile2", &datastream.ConnectionProfileArgs{
			DisplayName:         pulumi.String("Connection profile"),
			Location:            pulumi.String("us-central1"),
			ConnectionProfileId: pulumi.String("dest-profile"),
			BigqueryProfile:     &datastream.ConnectionProfileBigqueryProfileArgs{},
		})
		if err != nil {
			return err
		}
		instance, err := sql.NewDatabaseInstance(ctx, "instance", &sql.DatabaseInstanceArgs{
			Name:            pulumi.String("instance-name"),
			DatabaseVersion: pulumi.String("MYSQL_8_0"),
			Region:          pulumi.String("us-central1"),
			Settings: &sql.DatabaseInstanceSettingsArgs{
				Tier: pulumi.String("db-f1-micro"),
				BackupConfiguration: &sql.DatabaseInstanceSettingsBackupConfigurationArgs{
					Enabled:          pulumi.Bool(true),
					BinaryLogEnabled: pulumi.Bool(true),
				},
				IpConfiguration: &sql.DatabaseInstanceSettingsIpConfigurationArgs{
					AuthorizedNetworks: sql.DatabaseInstanceSettingsIpConfigurationAuthorizedNetworkArray{
						&sql.DatabaseInstanceSettingsIpConfigurationAuthorizedNetworkArgs{
							Value: pulumi.String("34.71.242.81"),
						},
						&sql.DatabaseInstanceSettingsIpConfigurationAuthorizedNetworkArgs{
							Value: pulumi.String("34.72.28.29"),
						},
						&sql.DatabaseInstanceSettingsIpConfigurationAuthorizedNetworkArgs{
							Value: pulumi.String("34.67.6.157"),
						},
						&sql.DatabaseInstanceSettingsIpConfigurationAuthorizedNetworkArgs{
							Value: pulumi.String("34.67.234.134"),
						},
						&sql.DatabaseInstanceSettingsIpConfigurationAuthorizedNetworkArgs{
							Value: pulumi.String("34.72.239.218"),
						},
					},
				},
			},
			DeletionProtection: pulumi.Bool(false),
		})
		if err != nil {
			return err
		}
		pwd, err := random.NewRandomPassword(ctx, "pwd", &random.RandomPasswordArgs{
			Length:  pulumi.Int(16),
			Special: pulumi.Bool(false),
		})
		if err != nil {
			return err
		}
		user, err := sql.NewUser(ctx, "user", &sql.UserArgs{
			Name:     pulumi.String("my-user"),
			Instance: instance.Name,
			Host:     pulumi.String("%"),
			Password: pwd.Result,
		})
		if err != nil {
			return err
		}
		sourceConnectionProfile, err := datastream.NewConnectionProfile(ctx, "source_connection_profile", &datastream.ConnectionProfileArgs{
			DisplayName:         pulumi.String("Source connection profile"),
			Location:            pulumi.String("us-central1"),
			ConnectionProfileId: pulumi.String("source-profile"),
			MysqlProfile: &datastream.ConnectionProfileMysqlProfileArgs{
				Hostname: instance.PublicIpAddress,
				Username: user.Name,
				Password: user.Password,
			},
		})
		if err != nil {
			return err
		}
		_, err = datastream.NewStream(ctx, "default", &datastream.StreamArgs{
			DisplayName: pulumi.String("postgres to bigQuery"),
			Location:    pulumi.String("us-central1"),
			StreamId:    pulumi.String("postgres-bigquery"),
			SourceConfig: &datastream.StreamSourceConfigArgs{
				SourceConnectionProfile: sourceConnectionProfile.ID(),
				MysqlSourceConfig:       &datastream.StreamSourceConfigMysqlSourceConfigArgs{},
			},
			DestinationConfig: &datastream.StreamDestinationConfigArgs{
				DestinationConnectionProfile: destinationConnectionProfile2.ID(),
				BigqueryDestinationConfig: &datastream.StreamDestinationConfigBigqueryDestinationConfigArgs{
					DataFreshness: pulumi.String("900s"),
					SingleTargetDataset: &datastream.StreamDestinationConfigBigqueryDestinationConfigSingleTargetDatasetArgs{
						DatasetId: postgres.ID(),
					},
				},
			},
			BackfillAll: &datastream.StreamBackfillAllArgs{},
		})
		if err != nil {
			return err
		}
		_, err = sql.NewDatabase(ctx, "db", &sql.DatabaseArgs{
			Instance: instance.Name,
			Name:     pulumi.String("db"),
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.bigquery.Dataset;
import com.pulumi.gcp.bigquery.DatasetArgs;
import com.pulumi.gcp.datastream.ConnectionProfile;
import com.pulumi.gcp.datastream.ConnectionProfileArgs;
import com.pulumi.gcp.datastream.inputs.ConnectionProfileBigqueryProfileArgs;
import com.pulumi.gcp.sql.DatabaseInstance;
import com.pulumi.gcp.sql.DatabaseInstanceArgs;
import com.pulumi.gcp.sql.inputs.DatabaseInstanceSettingsArgs;
import com.pulumi.gcp.sql.inputs.DatabaseInstanceSettingsBackupConfigurationArgs;
import com.pulumi.gcp.sql.inputs.DatabaseInstanceSettingsIpConfigurationArgs;
import com.pulumi.random.RandomPassword;
import com.pulumi.random.RandomPasswordArgs;
import com.pulumi.gcp.sql.User;
import com.pulumi.gcp.sql.UserArgs;
import com.pulumi.gcp.datastream.inputs.ConnectionProfileMysqlProfileArgs;
import com.pulumi.gcp.datastream.Stream;
import com.pulumi.gcp.datastream.StreamArgs;
import com.pulumi.gcp.datastream.inputs.StreamSourceConfigArgs;
import com.pulumi.gcp.datastream.inputs.StreamSourceConfigMysqlSourceConfigArgs;
import com.pulumi.gcp.datastream.inputs.StreamDestinationConfigArgs;
import com.pulumi.gcp.datastream.inputs.StreamDestinationConfigBigqueryDestinationConfigArgs;
import com.pulumi.gcp.datastream.inputs.StreamDestinationConfigBigqueryDestinationConfigSingleTargetDatasetArgs;
import com.pulumi.gcp.datastream.inputs.StreamBackfillAllArgs;
import com.pulumi.gcp.sql.Database;
import com.pulumi.gcp.sql.DatabaseArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        var postgres = new Dataset("postgres", DatasetArgs.builder()
            .datasetId("postgres")
            .friendlyName("postgres")
            .description("Database of postgres")
            .location("us-central1")
            .build());

        var destinationConnectionProfile2 = new ConnectionProfile("destinationConnectionProfile2", ConnectionProfileArgs.builder()
            .displayName("Connection profile")
            .location("us-central1")
            .connectionProfileId("dest-profile")
            .bigqueryProfile()
            .build());

        var instance = new DatabaseInstance("instance", DatabaseInstanceArgs.builder()
            .name("instance-name")
            .databaseVersion("MYSQL_8_0")
            .region("us-central1")
            .settings(DatabaseInstanceSettingsArgs.builder()
                .tier("db-f1-micro")
                .backupConfiguration(DatabaseInstanceSettingsBackupConfigurationArgs.builder()
                    .enabled(true)
                    .binaryLogEnabled(true)
                    .build())
                .ipConfiguration(DatabaseInstanceSettingsIpConfigurationArgs.builder()
                    .authorizedNetworks(                    
                        DatabaseInstanceSettingsIpConfigurationAuthorizedNetworkArgs.builder()
                            .value("34.71.242.81")
                            .build(),
                        DatabaseInstanceSettingsIpConfigurationAuthorizedNetworkArgs.builder()
                            .value("34.72.28.29")
                            .build(),
                        DatabaseInstanceSettingsIpConfigurationAuthorizedNetworkArgs.builder()
                            .value("34.67.6.157")
                            .build(),
                        DatabaseInstanceSettingsIpConfigurationAuthorizedNetworkArgs.builder()
                            .value("34.67.234.134")
                            .build(),
                        DatabaseInstanceSettingsIpConfigurationAuthorizedNetworkArgs.builder()
                            .value("34.72.239.218")
                            .build())
                    .build())
                .build())
            .deletionProtection(false)
            .build());

        var pwd = new RandomPassword("pwd", RandomPasswordArgs.builder()
            .length(16)
            .special(false)
            .build());

        var user = new User("user", UserArgs.builder()
            .name("my-user")
            .instance(instance.name())
            .host("%")
            .password(pwd.result())
            .build());

        var sourceConnectionProfile = new ConnectionProfile("sourceConnectionProfile", ConnectionProfileArgs.builder()
            .displayName("Source connection profile")
            .location("us-central1")
            .connectionProfileId("source-profile")
            .mysqlProfile(ConnectionProfileMysqlProfileArgs.builder()
                .hostname(instance.publicIpAddress())
                .username(user.name())
                .password(user.password())
                .build())
            .build());

        var default_ = new Stream("default", StreamArgs.builder()
            .displayName("postgres to bigQuery")
            .location("us-central1")
            .streamId("postgres-bigquery")
            .sourceConfig(StreamSourceConfigArgs.builder()
                .sourceConnectionProfile(sourceConnectionProfile.id())
                .mysqlSourceConfig()
                .build())
            .destinationConfig(StreamDestinationConfigArgs.builder()
                .destinationConnectionProfile(destinationConnectionProfile2.id())
                .bigqueryDestinationConfig(StreamDestinationConfigBigqueryDestinationConfigArgs.builder()
                    .dataFreshness("900s")
                    .singleTargetDataset(StreamDestinationConfigBigqueryDestinationConfigSingleTargetDatasetArgs.builder()
                        .datasetId(postgres.id())
                        .build())
                    .build())
                .build())
            .backfillAll()
            .build());

        var db = new Database("db", DatabaseArgs.builder()
            .instance(instance.name())
            .name("db")
            .build());

    }
}
```
```yaml
resources:
  postgres:
    type: gcp:bigquery:Dataset
    properties:
      datasetId: postgres
      friendlyName: postgres
      description: Database of postgres
      location: us-central1
  default:
    type: gcp:datastream:Stream
    properties:
      displayName: postgres to bigQuery
      location: us-central1
      streamId: postgres-bigquery
      sourceConfig:
        sourceConnectionProfile: ${sourceConnectionProfile.id}
        mysqlSourceConfig: {}
      destinationConfig:
        destinationConnectionProfile: ${destinationConnectionProfile2.id}
        bigqueryDestinationConfig:
          dataFreshness: 900s
          singleTargetDataset:
            datasetId: ${postgres.id}
      backfillAll: {}
  destinationConnectionProfile2:
    type: gcp:datastream:ConnectionProfile
    name: destination_connection_profile2
    properties:
      displayName: Connection profile
      location: us-central1
      connectionProfileId: dest-profile
      bigqueryProfile: {}
  instance:
    type: gcp:sql:DatabaseInstance
    properties:
      name: instance-name
      databaseVersion: MYSQL_8_0
      region: us-central1
      settings:
        tier: db-f1-micro
        backupConfiguration:
          enabled: true
          binaryLogEnabled: true
        ipConfiguration:
          authorizedNetworks:
            - value: 34.71.242.81
            - value: 34.72.28.29
            - value: 34.67.6.157
            - value: 34.67.234.134
            - value: 34.72.239.218
      deletionProtection: false
  db:
    type: gcp:sql:Database
    properties:
      instance: ${instance.name}
      name: db
  pwd:
    type: random:RandomPassword
    properties:
      length: 16
      special: false
  user:
    type: gcp:sql:User
    properties:
      name: my-user
      instance: ${instance.name}
      host: '%'
      password: ${pwd.result}
  sourceConnectionProfile:
    type: gcp:datastream:ConnectionProfile
    name: source_connection_profile
    properties:
      displayName: Source connection profile
      location: us-central1
      connectionProfileId: source-profile
      mysqlProfile:
        hostname: ${instance.publicIpAddress}
        username: ${user.name}
        password: ${user.password}
```
<!--End PulumiCodeChooser -->
### Datastream Stream Bigquery


<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";
import * as random from "@pulumi/random";

const project = gcp.organizations.getProject({});
const instance = new gcp.sql.DatabaseInstance("instance", {
    name: "my-instance",
    databaseVersion: "MYSQL_8_0",
    region: "us-central1",
    settings: {
        tier: "db-f1-micro",
        backupConfiguration: {
            enabled: true,
            binaryLogEnabled: true,
        },
        ipConfiguration: {
            authorizedNetworks: [
                {
                    value: "34.71.242.81",
                },
                {
                    value: "34.72.28.29",
                },
                {
                    value: "34.67.6.157",
                },
                {
                    value: "34.67.234.134",
                },
                {
                    value: "34.72.239.218",
                },
            ],
        },
    },
    deletionProtection: true,
});
const db = new gcp.sql.Database("db", {
    instance: instance.name,
    name: "db",
});
const pwd = new random.RandomPassword("pwd", {
    length: 16,
    special: false,
});
const user = new gcp.sql.User("user", {
    name: "user",
    instance: instance.name,
    host: "%",
    password: pwd.result,
});
const sourceConnectionProfile = new gcp.datastream.ConnectionProfile("source_connection_profile", {
    displayName: "Source connection profile",
    location: "us-central1",
    connectionProfileId: "source-profile",
    mysqlProfile: {
        hostname: instance.publicIpAddress,
        username: user.name,
        password: user.password,
    },
});
const bqSa = gcp.bigquery.getDefaultServiceAccount({});
const bigqueryKeyUser = new gcp.kms.CryptoKeyIAMMember("bigquery_key_user", {
    cryptoKeyId: "bigquery-kms-name",
    role: "roles/cloudkms.cryptoKeyEncrypterDecrypter",
    member: bqSa.then(bqSa => `serviceAccount:${bqSa.email}`),
});
const destinationConnectionProfile = new gcp.datastream.ConnectionProfile("destination_connection_profile", {
    displayName: "Connection profile",
    location: "us-central1",
    connectionProfileId: "destination-profile",
    bigqueryProfile: {},
});
const _default = new gcp.datastream.Stream("default", {
    streamId: "my-stream",
    location: "us-central1",
    displayName: "my stream",
    sourceConfig: {
        sourceConnectionProfile: sourceConnectionProfile.id,
        mysqlSourceConfig: {},
    },
    destinationConfig: {
        destinationConnectionProfile: destinationConnectionProfile.id,
        bigqueryDestinationConfig: {
            sourceHierarchyDatasets: {
                datasetTemplate: {
                    location: "us-central1",
                    kmsKeyName: "bigquery-kms-name",
                },
            },
        },
    },
    backfillNone: {},
}, {
    dependsOn: [bigqueryKeyUser],
});
```
```python
import pulumi
import pulumi_gcp as gcp
import pulumi_random as random

project = gcp.organizations.get_project()
instance = gcp.sql.DatabaseInstance("instance",
    name="my-instance",
    database_version="MYSQL_8_0",
    region="us-central1",
    settings={
        "tier": "db-f1-micro",
        "backup_configuration": {
            "enabled": True,
            "binary_log_enabled": True,
        },
        "ip_configuration": {
            "authorized_networks": [
                {
                    "value": "34.71.242.81",
                },
                {
                    "value": "34.72.28.29",
                },
                {
                    "value": "34.67.6.157",
                },
                {
                    "value": "34.67.234.134",
                },
                {
                    "value": "34.72.239.218",
                },
            ],
        },
    },
    deletion_protection=True)
db = gcp.sql.Database("db",
    instance=instance.name,
    name="db")
pwd = random.RandomPassword("pwd",
    length=16,
    special=False)
user = gcp.sql.User("user",
    name="user",
    instance=instance.name,
    host="%",
    password=pwd.result)
source_connection_profile = gcp.datastream.ConnectionProfile("source_connection_profile",
    display_name="Source connection profile",
    location="us-central1",
    connection_profile_id="source-profile",
    mysql_profile={
        "hostname": instance.public_ip_address,
        "username": user.name,
        "password": user.password,
    })
bq_sa = gcp.bigquery.get_default_service_account()
bigquery_key_user = gcp.kms.CryptoKeyIAMMember("bigquery_key_user",
    crypto_key_id="bigquery-kms-name",
    role="roles/cloudkms.cryptoKeyEncrypterDecrypter",
    member=f"serviceAccount:{bq_sa.email}")
destination_connection_profile = gcp.datastream.ConnectionProfile("destination_connection_profile",
    display_name="Connection profile",
    location="us-central1",
    connection_profile_id="destination-profile",
    bigquery_profile={})
default = gcp.datastream.Stream("default",
    stream_id="my-stream",
    location="us-central1",
    display_name="my stream",
    source_config={
        "source_connection_profile": source_connection_profile.id,
        "mysql_source_config": {},
    },
    destination_config={
        "destination_connection_profile": destination_connection_profile.id,
        "bigquery_destination_config": {
            "source_hierarchy_datasets": {
                "dataset_template": {
                    "location": "us-central1",
                    "kms_key_name": "bigquery-kms-name",
                },
            },
        },
    },
    backfill_none={},
    opts = pulumi.ResourceOptions(depends_on=[bigquery_key_user]))
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;
using Random = Pulumi.Random;

return await Deployment.RunAsync(() => 
{
    var project = Gcp.Organizations.GetProject.Invoke();

    var instance = new Gcp.Sql.DatabaseInstance("instance", new()
    {
        Name = "my-instance",
        DatabaseVersion = "MYSQL_8_0",
        Region = "us-central1",
        Settings = new Gcp.Sql.Inputs.DatabaseInstanceSettingsArgs
        {
            Tier = "db-f1-micro",
            BackupConfiguration = new Gcp.Sql.Inputs.DatabaseInstanceSettingsBackupConfigurationArgs
            {
                Enabled = true,
                BinaryLogEnabled = true,
            },
            IpConfiguration = new Gcp.Sql.Inputs.DatabaseInstanceSettingsIpConfigurationArgs
            {
                AuthorizedNetworks = new[]
                {
                    new Gcp.Sql.Inputs.DatabaseInstanceSettingsIpConfigurationAuthorizedNetworkArgs
                    {
                        Value = "34.71.242.81",
                    },
                    new Gcp.Sql.Inputs.DatabaseInstanceSettingsIpConfigurationAuthorizedNetworkArgs
                    {
                        Value = "34.72.28.29",
                    },
                    new Gcp.Sql.Inputs.DatabaseInstanceSettingsIpConfigurationAuthorizedNetworkArgs
                    {
                        Value = "34.67.6.157",
                    },
                    new Gcp.Sql.Inputs.DatabaseInstanceSettingsIpConfigurationAuthorizedNetworkArgs
                    {
                        Value = "34.67.234.134",
                    },
                    new Gcp.Sql.Inputs.DatabaseInstanceSettingsIpConfigurationAuthorizedNetworkArgs
                    {
                        Value = "34.72.239.218",
                    },
                },
            },
        },
        DeletionProtection = true,
    });

    var db = new Gcp.Sql.Database("db", new()
    {
        Instance = instance.Name,
        Name = "db",
    });

    var pwd = new Random.RandomPassword("pwd", new()
    {
        Length = 16,
        Special = false,
    });

    var user = new Gcp.Sql.User("user", new()
    {
        Name = "user",
        Instance = instance.Name,
        Host = "%",
        Password = pwd.Result,
    });

    var sourceConnectionProfile = new Gcp.Datastream.ConnectionProfile("source_connection_profile", new()
    {
        DisplayName = "Source connection profile",
        Location = "us-central1",
        ConnectionProfileId = "source-profile",
        MysqlProfile = new Gcp.Datastream.Inputs.ConnectionProfileMysqlProfileArgs
        {
            Hostname = instance.PublicIpAddress,
            Username = user.Name,
            Password = user.Password,
        },
    });

    var bqSa = Gcp.BigQuery.GetDefaultServiceAccount.Invoke();

    var bigqueryKeyUser = new Gcp.Kms.CryptoKeyIAMMember("bigquery_key_user", new()
    {
        CryptoKeyId = "bigquery-kms-name",
        Role = "roles/cloudkms.cryptoKeyEncrypterDecrypter",
        Member = $"serviceAccount:{bqSa.Apply(getDefaultServiceAccountResult => getDefaultServiceAccountResult.Email)}",
    });

    var destinationConnectionProfile = new Gcp.Datastream.ConnectionProfile("destination_connection_profile", new()
    {
        DisplayName = "Connection profile",
        Location = "us-central1",
        ConnectionProfileId = "destination-profile",
        BigqueryProfile = null,
    });

    var @default = new Gcp.Datastream.Stream("default", new()
    {
        StreamId = "my-stream",
        Location = "us-central1",
        DisplayName = "my stream",
        SourceConfig = new Gcp.Datastream.Inputs.StreamSourceConfigArgs
        {
            SourceConnectionProfile = sourceConnectionProfile.Id,
            MysqlSourceConfig = null,
        },
        DestinationConfig = new Gcp.Datastream.Inputs.StreamDestinationConfigArgs
        {
            DestinationConnectionProfile = destinationConnectionProfile.Id,
            BigqueryDestinationConfig = new Gcp.Datastream.Inputs.StreamDestinationConfigBigqueryDestinationConfigArgs
            {
                SourceHierarchyDatasets = new Gcp.Datastream.Inputs.StreamDestinationConfigBigqueryDestinationConfigSourceHierarchyDatasetsArgs
                {
                    DatasetTemplate = new Gcp.Datastream.Inputs.StreamDestinationConfigBigqueryDestinationConfigSourceHierarchyDatasetsDatasetTemplateArgs
                    {
                        Location = "us-central1",
                        KmsKeyName = "bigquery-kms-name",
                    },
                },
            },
        },
        BackfillNone = null,
    }, new CustomResourceOptions
    {
        DependsOn =
        {
            bigqueryKeyUser,
        },
    });

});
```
```go
package main

import (
	"fmt"

	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/bigquery"
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/datastream"
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/kms"
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/organizations"
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/sql"
	"github.com/pulumi/pulumi-random/sdk/v4/go/random"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		_, err := organizations.LookupProject(ctx, &organizations.LookupProjectArgs{}, nil)
		if err != nil {
			return err
		}
		instance, err := sql.NewDatabaseInstance(ctx, "instance", &sql.DatabaseInstanceArgs{
			Name:            pulumi.String("my-instance"),
			DatabaseVersion: pulumi.String("MYSQL_8_0"),
			Region:          pulumi.String("us-central1"),
			Settings: &sql.DatabaseInstanceSettingsArgs{
				Tier: pulumi.String("db-f1-micro"),
				BackupConfiguration: &sql.DatabaseInstanceSettingsBackupConfigurationArgs{
					Enabled:          pulumi.Bool(true),
					BinaryLogEnabled: pulumi.Bool(true),
				},
				IpConfiguration: &sql.DatabaseInstanceSettingsIpConfigurationArgs{
					AuthorizedNetworks: sql.DatabaseInstanceSettingsIpConfigurationAuthorizedNetworkArray{
						&sql.DatabaseInstanceSettingsIpConfigurationAuthorizedNetworkArgs{
							Value: pulumi.String("34.71.242.81"),
						},
						&sql.DatabaseInstanceSettingsIpConfigurationAuthorizedNetworkArgs{
							Value: pulumi.String("34.72.28.29"),
						},
						&sql.DatabaseInstanceSettingsIpConfigurationAuthorizedNetworkArgs{
							Value: pulumi.String("34.67.6.157"),
						},
						&sql.DatabaseInstanceSettingsIpConfigurationAuthorizedNetworkArgs{
							Value: pulumi.String("34.67.234.134"),
						},
						&sql.DatabaseInstanceSettingsIpConfigurationAuthorizedNetworkArgs{
							Value: pulumi.String("34.72.239.218"),
						},
					},
				},
			},
			DeletionProtection: pulumi.Bool(true),
		})
		if err != nil {
			return err
		}
		_, err = sql.NewDatabase(ctx, "db", &sql.DatabaseArgs{
			Instance: instance.Name,
			Name:     pulumi.String("db"),
		})
		if err != nil {
			return err
		}
		pwd, err := random.NewRandomPassword(ctx, "pwd", &random.RandomPasswordArgs{
			Length:  pulumi.Int(16),
			Special: pulumi.Bool(false),
		})
		if err != nil {
			return err
		}
		user, err := sql.NewUser(ctx, "user", &sql.UserArgs{
			Name:     pulumi.String("user"),
			Instance: instance.Name,
			Host:     pulumi.String("%"),
			Password: pwd.Result,
		})
		if err != nil {
			return err
		}
		sourceConnectionProfile, err := datastream.NewConnectionProfile(ctx, "source_connection_profile", &datastream.ConnectionProfileArgs{
			DisplayName:         pulumi.String("Source connection profile"),
			Location:            pulumi.String("us-central1"),
			ConnectionProfileId: pulumi.String("source-profile"),
			MysqlProfile: &datastream.ConnectionProfileMysqlProfileArgs{
				Hostname: instance.PublicIpAddress,
				Username: user.Name,
				Password: user.Password,
			},
		})
		if err != nil {
			return err
		}
		bqSa, err := bigquery.GetDefaultServiceAccount(ctx, &bigquery.GetDefaultServiceAccountArgs{}, nil)
		if err != nil {
			return err
		}
		bigqueryKeyUser, err := kms.NewCryptoKeyIAMMember(ctx, "bigquery_key_user", &kms.CryptoKeyIAMMemberArgs{
			CryptoKeyId: pulumi.String("bigquery-kms-name"),
			Role:        pulumi.String("roles/cloudkms.cryptoKeyEncrypterDecrypter"),
			Member:      pulumi.Sprintf("serviceAccount:%v", bqSa.Email),
		})
		if err != nil {
			return err
		}
		destinationConnectionProfile, err := datastream.NewConnectionProfile(ctx, "destination_connection_profile", &datastream.ConnectionProfileArgs{
			DisplayName:         pulumi.String("Connection profile"),
			Location:            pulumi.String("us-central1"),
			ConnectionProfileId: pulumi.String("destination-profile"),
			BigqueryProfile:     &datastream.ConnectionProfileBigqueryProfileArgs{},
		})
		if err != nil {
			return err
		}
		_, err = datastream.NewStream(ctx, "default", &datastream.StreamArgs{
			StreamId:    pulumi.String("my-stream"),
			Location:    pulumi.String("us-central1"),
			DisplayName: pulumi.String("my stream"),
			SourceConfig: &datastream.StreamSourceConfigArgs{
				SourceConnectionProfile: sourceConnectionProfile.ID(),
				MysqlSourceConfig:       &datastream.StreamSourceConfigMysqlSourceConfigArgs{},
			},
			DestinationConfig: &datastream.StreamDestinationConfigArgs{
				DestinationConnectionProfile: destinationConnectionProfile.ID(),
				BigqueryDestinationConfig: &datastream.StreamDestinationConfigBigqueryDestinationConfigArgs{
					SourceHierarchyDatasets: &datastream.StreamDestinationConfigBigqueryDestinationConfigSourceHierarchyDatasetsArgs{
						DatasetTemplate: &datastream.StreamDestinationConfigBigqueryDestinationConfigSourceHierarchyDatasetsDatasetTemplateArgs{
							Location:   pulumi.String("us-central1"),
							KmsKeyName: pulumi.String("bigquery-kms-name"),
						},
					},
				},
			},
			BackfillNone: &datastream.StreamBackfillNoneArgs{},
		}, pulumi.DependsOn([]pulumi.Resource{
			bigqueryKeyUser,
		}))
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.organizations.OrganizationsFunctions;
import com.pulumi.gcp.organizations.inputs.GetProjectArgs;
import com.pulumi.gcp.sql.DatabaseInstance;
import com.pulumi.gcp.sql.DatabaseInstanceArgs;
import com.pulumi.gcp.sql.inputs.DatabaseInstanceSettingsArgs;
import com.pulumi.gcp.sql.inputs.DatabaseInstanceSettingsBackupConfigurationArgs;
import com.pulumi.gcp.sql.inputs.DatabaseInstanceSettingsIpConfigurationArgs;
import com.pulumi.gcp.sql.Database;
import com.pulumi.gcp.sql.DatabaseArgs;
import com.pulumi.random.RandomPassword;
import com.pulumi.random.RandomPasswordArgs;
import com.pulumi.gcp.sql.User;
import com.pulumi.gcp.sql.UserArgs;
import com.pulumi.gcp.datastream.ConnectionProfile;
import com.pulumi.gcp.datastream.ConnectionProfileArgs;
import com.pulumi.gcp.datastream.inputs.ConnectionProfileMysqlProfileArgs;
import com.pulumi.gcp.bigquery.BigqueryFunctions;
import com.pulumi.gcp.bigquery.inputs.GetDefaultServiceAccountArgs;
import com.pulumi.gcp.kms.CryptoKeyIAMMember;
import com.pulumi.gcp.kms.CryptoKeyIAMMemberArgs;
import com.pulumi.gcp.datastream.inputs.ConnectionProfileBigqueryProfileArgs;
import com.pulumi.gcp.datastream.Stream;
import com.pulumi.gcp.datastream.StreamArgs;
import com.pulumi.gcp.datastream.inputs.StreamSourceConfigArgs;
import com.pulumi.gcp.datastream.inputs.StreamSourceConfigMysqlSourceConfigArgs;
import com.pulumi.gcp.datastream.inputs.StreamDestinationConfigArgs;
import com.pulumi.gcp.datastream.inputs.StreamDestinationConfigBigqueryDestinationConfigArgs;
import com.pulumi.gcp.datastream.inputs.StreamDestinationConfigBigqueryDestinationConfigSourceHierarchyDatasetsArgs;
import com.pulumi.gcp.datastream.inputs.StreamDestinationConfigBigqueryDestinationConfigSourceHierarchyDatasetsDatasetTemplateArgs;
import com.pulumi.gcp.datastream.inputs.StreamBackfillNoneArgs;
import com.pulumi.resources.CustomResourceOptions;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        final var project = OrganizationsFunctions.getProject();

        var instance = new DatabaseInstance("instance", DatabaseInstanceArgs.builder()
            .name("my-instance")
            .databaseVersion("MYSQL_8_0")
            .region("us-central1")
            .settings(DatabaseInstanceSettingsArgs.builder()
                .tier("db-f1-micro")
                .backupConfiguration(DatabaseInstanceSettingsBackupConfigurationArgs.builder()
                    .enabled(true)
                    .binaryLogEnabled(true)
                    .build())
                .ipConfiguration(DatabaseInstanceSettingsIpConfigurationArgs.builder()
                    .authorizedNetworks(                    
                        DatabaseInstanceSettingsIpConfigurationAuthorizedNetworkArgs.builder()
                            .value("34.71.242.81")
                            .build(),
                        DatabaseInstanceSettingsIpConfigurationAuthorizedNetworkArgs.builder()
                            .value("34.72.28.29")
                            .build(),
                        DatabaseInstanceSettingsIpConfigurationAuthorizedNetworkArgs.builder()
                            .value("34.67.6.157")
                            .build(),
                        DatabaseInstanceSettingsIpConfigurationAuthorizedNetworkArgs.builder()
                            .value("34.67.234.134")
                            .build(),
                        DatabaseInstanceSettingsIpConfigurationAuthorizedNetworkArgs.builder()
                            .value("34.72.239.218")
                            .build())
                    .build())
                .build())
            .deletionProtection(true)
            .build());

        var db = new Database("db", DatabaseArgs.builder()
            .instance(instance.name())
            .name("db")
            .build());

        var pwd = new RandomPassword("pwd", RandomPasswordArgs.builder()
            .length(16)
            .special(false)
            .build());

        var user = new User("user", UserArgs.builder()
            .name("user")
            .instance(instance.name())
            .host("%")
            .password(pwd.result())
            .build());

        var sourceConnectionProfile = new ConnectionProfile("sourceConnectionProfile", ConnectionProfileArgs.builder()
            .displayName("Source connection profile")
            .location("us-central1")
            .connectionProfileId("source-profile")
            .mysqlProfile(ConnectionProfileMysqlProfileArgs.builder()
                .hostname(instance.publicIpAddress())
                .username(user.name())
                .password(user.password())
                .build())
            .build());

        final var bqSa = BigqueryFunctions.getDefaultServiceAccount();

        var bigqueryKeyUser = new CryptoKeyIAMMember("bigqueryKeyUser", CryptoKeyIAMMemberArgs.builder()
            .cryptoKeyId("bigquery-kms-name")
            .role("roles/cloudkms.cryptoKeyEncrypterDecrypter")
            .member(String.format("serviceAccount:%s", bqSa.applyValue(getDefaultServiceAccountResult -> getDefaultServiceAccountResult.email())))
            .build());

        var destinationConnectionProfile = new ConnectionProfile("destinationConnectionProfile", ConnectionProfileArgs.builder()
            .displayName("Connection profile")
            .location("us-central1")
            .connectionProfileId("destination-profile")
            .bigqueryProfile()
            .build());

        var default_ = new Stream("default", StreamArgs.builder()
            .streamId("my-stream")
            .location("us-central1")
            .displayName("my stream")
            .sourceConfig(StreamSourceConfigArgs.builder()
                .sourceConnectionProfile(sourceConnectionProfile.id())
                .mysqlSourceConfig()
                .build())
            .destinationConfig(StreamDestinationConfigArgs.builder()
                .destinationConnectionProfile(destinationConnectionProfile.id())
                .bigqueryDestinationConfig(StreamDestinationConfigBigqueryDestinationConfigArgs.builder()
                    .sourceHierarchyDatasets(StreamDestinationConfigBigqueryDestinationConfigSourceHierarchyDatasetsArgs.builder()
                        .datasetTemplate(StreamDestinationConfigBigqueryDestinationConfigSourceHierarchyDatasetsDatasetTemplateArgs.builder()
                            .location("us-central1")
                            .kmsKeyName("bigquery-kms-name")
                            .build())
                        .build())
                    .build())
                .build())
            .backfillNone()
            .build(), CustomResourceOptions.builder()
                .dependsOn(bigqueryKeyUser)
                .build());

    }
}
```
```yaml
resources:
  instance:
    type: gcp:sql:DatabaseInstance
    properties:
      name: my-instance
      databaseVersion: MYSQL_8_0
      region: us-central1
      settings:
        tier: db-f1-micro
        backupConfiguration:
          enabled: true
          binaryLogEnabled: true
        ipConfiguration:
          authorizedNetworks:
            - value: 34.71.242.81
            - value: 34.72.28.29
            - value: 34.67.6.157
            - value: 34.67.234.134
            - value: 34.72.239.218
      deletionProtection: true
  db:
    type: gcp:sql:Database
    properties:
      instance: ${instance.name}
      name: db
  pwd:
    type: random:RandomPassword
    properties:
      length: 16
      special: false
  user:
    type: gcp:sql:User
    properties:
      name: user
      instance: ${instance.name}
      host: '%'
      password: ${pwd.result}
  sourceConnectionProfile:
    type: gcp:datastream:ConnectionProfile
    name: source_connection_profile
    properties:
      displayName: Source connection profile
      location: us-central1
      connectionProfileId: source-profile
      mysqlProfile:
        hostname: ${instance.publicIpAddress}
        username: ${user.name}
        password: ${user.password}
  bigqueryKeyUser:
    type: gcp:kms:CryptoKeyIAMMember
    name: bigquery_key_user
    properties:
      cryptoKeyId: bigquery-kms-name
      role: roles/cloudkms.cryptoKeyEncrypterDecrypter
      member: serviceAccount:${bqSa.email}
  destinationConnectionProfile:
    type: gcp:datastream:ConnectionProfile
    name: destination_connection_profile
    properties:
      displayName: Connection profile
      location: us-central1
      connectionProfileId: destination-profile
      bigqueryProfile: {}
  default:
    type: gcp:datastream:Stream
    properties:
      streamId: my-stream
      location: us-central1
      displayName: my stream
      sourceConfig:
        sourceConnectionProfile: ${sourceConnectionProfile.id}
        mysqlSourceConfig: {}
      destinationConfig:
        destinationConnectionProfile: ${destinationConnectionProfile.id}
        bigqueryDestinationConfig:
          sourceHierarchyDatasets:
            datasetTemplate:
              location: us-central1
              kmsKeyName: bigquery-kms-name
      backfillNone: {}
    options:
      dependsOn:
        - ${bigqueryKeyUser}
variables:
  project:
    fn::invoke:
      function: gcp:organizations:getProject
      arguments: {}
  bqSa:
    fn::invoke:
      function: gcp:bigquery:getDefaultServiceAccount
      arguments: {}
```
<!--End PulumiCodeChooser -->
### Datastream Stream Bigquery Append Only


<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";
import * as random from "@pulumi/random";

const project = gcp.organizations.getProject({});
const instance = new gcp.sql.DatabaseInstance("instance", {
    name: "my-instance",
    databaseVersion: "MYSQL_8_0",
    region: "us-central1",
    settings: {
        tier: "db-f1-micro",
        backupConfiguration: {
            enabled: true,
            binaryLogEnabled: true,
        },
        ipConfiguration: {
            authorizedNetworks: [
                {
                    value: "34.71.242.81",
                },
                {
                    value: "34.72.28.29",
                },
                {
                    value: "34.67.6.157",
                },
                {
                    value: "34.67.234.134",
                },
                {
                    value: "34.72.239.218",
                },
            ],
        },
    },
    deletionProtection: true,
});
const db = new gcp.sql.Database("db", {
    instance: instance.name,
    name: "db",
});
const pwd = new random.RandomPassword("pwd", {
    length: 16,
    special: false,
});
const user = new gcp.sql.User("user", {
    name: "user",
    instance: instance.name,
    host: "%",
    password: pwd.result,
});
const sourceConnectionProfile = new gcp.datastream.ConnectionProfile("source_connection_profile", {
    displayName: "Source connection profile",
    location: "us-central1",
    connectionProfileId: "source-profile",
    mysqlProfile: {
        hostname: instance.publicIpAddress,
        username: user.name,
        password: user.password,
    },
});
const destinationConnectionProfile = new gcp.datastream.ConnectionProfile("destination_connection_profile", {
    displayName: "Connection profile",
    location: "us-central1",
    connectionProfileId: "destination-profile",
    bigqueryProfile: {},
});
const _default = new gcp.datastream.Stream("default", {
    streamId: "my-stream",
    location: "us-central1",
    displayName: "my stream",
    sourceConfig: {
        sourceConnectionProfile: sourceConnectionProfile.id,
        mysqlSourceConfig: {},
    },
    destinationConfig: {
        destinationConnectionProfile: destinationConnectionProfile.id,
        bigqueryDestinationConfig: {
            sourceHierarchyDatasets: {
                datasetTemplate: {
                    location: "us-central1",
                },
            },
            appendOnly: {},
        },
    },
    backfillNone: {},
});
```
```python
import pulumi
import pulumi_gcp as gcp
import pulumi_random as random

project = gcp.organizations.get_project()
instance = gcp.sql.DatabaseInstance("instance",
    name="my-instance",
    database_version="MYSQL_8_0",
    region="us-central1",
    settings={
        "tier": "db-f1-micro",
        "backup_configuration": {
            "enabled": True,
            "binary_log_enabled": True,
        },
        "ip_configuration": {
            "authorized_networks": [
                {
                    "value": "34.71.242.81",
                },
                {
                    "value": "34.72.28.29",
                },
                {
                    "value": "34.67.6.157",
                },
                {
                    "value": "34.67.234.134",
                },
                {
                    "value": "34.72.239.218",
                },
            ],
        },
    },
    deletion_protection=True)
db = gcp.sql.Database("db",
    instance=instance.name,
    name="db")
pwd = random.RandomPassword("pwd",
    length=16,
    special=False)
user = gcp.sql.User("user",
    name="user",
    instance=instance.name,
    host="%",
    password=pwd.result)
source_connection_profile = gcp.datastream.ConnectionProfile("source_connection_profile",
    display_name="Source connection profile",
    location="us-central1",
    connection_profile_id="source-profile",
    mysql_profile={
        "hostname": instance.public_ip_address,
        "username": user.name,
        "password": user.password,
    })
destination_connection_profile = gcp.datastream.ConnectionProfile("destination_connection_profile",
    display_name="Connection profile",
    location="us-central1",
    connection_profile_id="destination-profile",
    bigquery_profile={})
default = gcp.datastream.Stream("default",
    stream_id="my-stream",
    location="us-central1",
    display_name="my stream",
    source_config={
        "source_connection_profile": source_connection_profile.id,
        "mysql_source_config": {},
    },
    destination_config={
        "destination_connection_profile": destination_connection_profile.id,
        "bigquery_destination_config": {
            "source_hierarchy_datasets": {
                "dataset_template": {
                    "location": "us-central1",
                },
            },
            "append_only": {},
        },
    },
    backfill_none={})
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;
using Random = Pulumi.Random;

return await Deployment.RunAsync(() => 
{
    var project = Gcp.Organizations.GetProject.Invoke();

    var instance = new Gcp.Sql.DatabaseInstance("instance", new()
    {
        Name = "my-instance",
        DatabaseVersion = "MYSQL_8_0",
        Region = "us-central1",
        Settings = new Gcp.Sql.Inputs.DatabaseInstanceSettingsArgs
        {
            Tier = "db-f1-micro",
            BackupConfiguration = new Gcp.Sql.Inputs.DatabaseInstanceSettingsBackupConfigurationArgs
            {
                Enabled = true,
                BinaryLogEnabled = true,
            },
            IpConfiguration = new Gcp.Sql.Inputs.DatabaseInstanceSettingsIpConfigurationArgs
            {
                AuthorizedNetworks = new[]
                {
                    new Gcp.Sql.Inputs.DatabaseInstanceSettingsIpConfigurationAuthorizedNetworkArgs
                    {
                        Value = "34.71.242.81",
                    },
                    new Gcp.Sql.Inputs.DatabaseInstanceSettingsIpConfigurationAuthorizedNetworkArgs
                    {
                        Value = "34.72.28.29",
                    },
                    new Gcp.Sql.Inputs.DatabaseInstanceSettingsIpConfigurationAuthorizedNetworkArgs
                    {
                        Value = "34.67.6.157",
                    },
                    new Gcp.Sql.Inputs.DatabaseInstanceSettingsIpConfigurationAuthorizedNetworkArgs
                    {
                        Value = "34.67.234.134",
                    },
                    new Gcp.Sql.Inputs.DatabaseInstanceSettingsIpConfigurationAuthorizedNetworkArgs
                    {
                        Value = "34.72.239.218",
                    },
                },
            },
        },
        DeletionProtection = true,
    });

    var db = new Gcp.Sql.Database("db", new()
    {
        Instance = instance.Name,
        Name = "db",
    });

    var pwd = new Random.RandomPassword("pwd", new()
    {
        Length = 16,
        Special = false,
    });

    var user = new Gcp.Sql.User("user", new()
    {
        Name = "user",
        Instance = instance.Name,
        Host = "%",
        Password = pwd.Result,
    });

    var sourceConnectionProfile = new Gcp.Datastream.ConnectionProfile("source_connection_profile", new()
    {
        DisplayName = "Source connection profile",
        Location = "us-central1",
        ConnectionProfileId = "source-profile",
        MysqlProfile = new Gcp.Datastream.Inputs.ConnectionProfileMysqlProfileArgs
        {
            Hostname = instance.PublicIpAddress,
            Username = user.Name,
            Password = user.Password,
        },
    });

    var destinationConnectionProfile = new Gcp.Datastream.ConnectionProfile("destination_connection_profile", new()
    {
        DisplayName = "Connection profile",
        Location = "us-central1",
        ConnectionProfileId = "destination-profile",
        BigqueryProfile = null,
    });

    var @default = new Gcp.Datastream.Stream("default", new()
    {
        StreamId = "my-stream",
        Location = "us-central1",
        DisplayName = "my stream",
        SourceConfig = new Gcp.Datastream.Inputs.StreamSourceConfigArgs
        {
            SourceConnectionProfile = sourceConnectionProfile.Id,
            MysqlSourceConfig = null,
        },
        DestinationConfig = new Gcp.Datastream.Inputs.StreamDestinationConfigArgs
        {
            DestinationConnectionProfile = destinationConnectionProfile.Id,
            BigqueryDestinationConfig = new Gcp.Datastream.Inputs.StreamDestinationConfigBigqueryDestinationConfigArgs
            {
                SourceHierarchyDatasets = new Gcp.Datastream.Inputs.StreamDestinationConfigBigqueryDestinationConfigSourceHierarchyDatasetsArgs
                {
                    DatasetTemplate = new Gcp.Datastream.Inputs.StreamDestinationConfigBigqueryDestinationConfigSourceHierarchyDatasetsDatasetTemplateArgs
                    {
                        Location = "us-central1",
                    },
                },
                AppendOnly = null,
            },
        },
        BackfillNone = null,
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/datastream"
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/organizations"
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/sql"
	"github.com/pulumi/pulumi-random/sdk/v4/go/random"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		_, err := organizations.LookupProject(ctx, &organizations.LookupProjectArgs{}, nil)
		if err != nil {
			return err
		}
		instance, err := sql.NewDatabaseInstance(ctx, "instance", &sql.DatabaseInstanceArgs{
			Name:            pulumi.String("my-instance"),
			DatabaseVersion: pulumi.String("MYSQL_8_0"),
			Region:          pulumi.String("us-central1"),
			Settings: &sql.DatabaseInstanceSettingsArgs{
				Tier: pulumi.String("db-f1-micro"),
				BackupConfiguration: &sql.DatabaseInstanceSettingsBackupConfigurationArgs{
					Enabled:          pulumi.Bool(true),
					BinaryLogEnabled: pulumi.Bool(true),
				},
				IpConfiguration: &sql.DatabaseInstanceSettingsIpConfigurationArgs{
					AuthorizedNetworks: sql.DatabaseInstanceSettingsIpConfigurationAuthorizedNetworkArray{
						&sql.DatabaseInstanceSettingsIpConfigurationAuthorizedNetworkArgs{
							Value: pulumi.String("34.71.242.81"),
						},
						&sql.DatabaseInstanceSettingsIpConfigurationAuthorizedNetworkArgs{
							Value: pulumi.String("34.72.28.29"),
						},
						&sql.DatabaseInstanceSettingsIpConfigurationAuthorizedNetworkArgs{
							Value: pulumi.String("34.67.6.157"),
						},
						&sql.DatabaseInstanceSettingsIpConfigurationAuthorizedNetworkArgs{
							Value: pulumi.String("34.67.234.134"),
						},
						&sql.DatabaseInstanceSettingsIpConfigurationAuthorizedNetworkArgs{
							Value: pulumi.String("34.72.239.218"),
						},
					},
				},
			},
			DeletionProtection: pulumi.Bool(true),
		})
		if err != nil {
			return err
		}
		_, err = sql.NewDatabase(ctx, "db", &sql.DatabaseArgs{
			Instance: instance.Name,
			Name:     pulumi.String("db"),
		})
		if err != nil {
			return err
		}
		pwd, err := random.NewRandomPassword(ctx, "pwd", &random.RandomPasswordArgs{
			Length:  pulumi.Int(16),
			Special: pulumi.Bool(false),
		})
		if err != nil {
			return err
		}
		user, err := sql.NewUser(ctx, "user", &sql.UserArgs{
			Name:     pulumi.String("user"),
			Instance: instance.Name,
			Host:     pulumi.String("%"),
			Password: pwd.Result,
		})
		if err != nil {
			return err
		}
		sourceConnectionProfile, err := datastream.NewConnectionProfile(ctx, "source_connection_profile", &datastream.ConnectionProfileArgs{
			DisplayName:         pulumi.String("Source connection profile"),
			Location:            pulumi.String("us-central1"),
			ConnectionProfileId: pulumi.String("source-profile"),
			MysqlProfile: &datastream.ConnectionProfileMysqlProfileArgs{
				Hostname: instance.PublicIpAddress,
				Username: user.Name,
				Password: user.Password,
			},
		})
		if err != nil {
			return err
		}
		destinationConnectionProfile, err := datastream.NewConnectionProfile(ctx, "destination_connection_profile", &datastream.ConnectionProfileArgs{
			DisplayName:         pulumi.String("Connection profile"),
			Location:            pulumi.String("us-central1"),
			ConnectionProfileId: pulumi.String("destination-profile"),
			BigqueryProfile:     &datastream.ConnectionProfileBigqueryProfileArgs{},
		})
		if err != nil {
			return err
		}
		_, err = datastream.NewStream(ctx, "default", &datastream.StreamArgs{
			StreamId:    pulumi.String("my-stream"),
			Location:    pulumi.String("us-central1"),
			DisplayName: pulumi.String("my stream"),
			SourceConfig: &datastream.StreamSourceConfigArgs{
				SourceConnectionProfile: sourceConnectionProfile.ID(),
				MysqlSourceConfig:       &datastream.StreamSourceConfigMysqlSourceConfigArgs{},
			},
			DestinationConfig: &datastream.StreamDestinationConfigArgs{
				DestinationConnectionProfile: destinationConnectionProfile.ID(),
				BigqueryDestinationConfig: &datastream.StreamDestinationConfigBigqueryDestinationConfigArgs{
					SourceHierarchyDatasets: &datastream.StreamDestinationConfigBigqueryDestinationConfigSourceHierarchyDatasetsArgs{
						DatasetTemplate: &datastream.StreamDestinationConfigBigqueryDestinationConfigSourceHierarchyDatasetsDatasetTemplateArgs{
							Location: pulumi.String("us-central1"),
						},
					},
					AppendOnly: &datastream.StreamDestinationConfigBigqueryDestinationConfigAppendOnlyArgs{},
				},
			},
			BackfillNone: &datastream.StreamBackfillNoneArgs{},
		})
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.organizations.OrganizationsFunctions;
import com.pulumi.gcp.organizations.inputs.GetProjectArgs;
import com.pulumi.gcp.sql.DatabaseInstance;
import com.pulumi.gcp.sql.DatabaseInstanceArgs;
import com.pulumi.gcp.sql.inputs.DatabaseInstanceSettingsArgs;
import com.pulumi.gcp.sql.inputs.DatabaseInstanceSettingsBackupConfigurationArgs;
import com.pulumi.gcp.sql.inputs.DatabaseInstanceSettingsIpConfigurationArgs;
import com.pulumi.gcp.sql.Database;
import com.pulumi.gcp.sql.DatabaseArgs;
import com.pulumi.random.RandomPassword;
import com.pulumi.random.RandomPasswordArgs;
import com.pulumi.gcp.sql.User;
import com.pulumi.gcp.sql.UserArgs;
import com.pulumi.gcp.datastream.ConnectionProfile;
import com.pulumi.gcp.datastream.ConnectionProfileArgs;
import com.pulumi.gcp.datastream.inputs.ConnectionProfileMysqlProfileArgs;
import com.pulumi.gcp.datastream.inputs.ConnectionProfileBigqueryProfileArgs;
import com.pulumi.gcp.datastream.Stream;
import com.pulumi.gcp.datastream.StreamArgs;
import com.pulumi.gcp.datastream.inputs.StreamSourceConfigArgs;
import com.pulumi.gcp.datastream.inputs.StreamSourceConfigMysqlSourceConfigArgs;
import com.pulumi.gcp.datastream.inputs.StreamDestinationConfigArgs;
import com.pulumi.gcp.datastream.inputs.StreamDestinationConfigBigqueryDestinationConfigArgs;
import com.pulumi.gcp.datastream.inputs.StreamDestinationConfigBigqueryDestinationConfigSourceHierarchyDatasetsArgs;
import com.pulumi.gcp.datastream.inputs.StreamDestinationConfigBigqueryDestinationConfigSourceHierarchyDatasetsDatasetTemplateArgs;
import com.pulumi.gcp.datastream.inputs.StreamDestinationConfigBigqueryDestinationConfigAppendOnlyArgs;
import com.pulumi.gcp.datastream.inputs.StreamBackfillNoneArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        final var project = OrganizationsFunctions.getProject();

        var instance = new DatabaseInstance("instance", DatabaseInstanceArgs.builder()
            .name("my-instance")
            .databaseVersion("MYSQL_8_0")
            .region("us-central1")
            .settings(DatabaseInstanceSettingsArgs.builder()
                .tier("db-f1-micro")
                .backupConfiguration(DatabaseInstanceSettingsBackupConfigurationArgs.builder()
                    .enabled(true)
                    .binaryLogEnabled(true)
                    .build())
                .ipConfiguration(DatabaseInstanceSettingsIpConfigurationArgs.builder()
                    .authorizedNetworks(                    
                        DatabaseInstanceSettingsIpConfigurationAuthorizedNetworkArgs.builder()
                            .value("34.71.242.81")
                            .build(),
                        DatabaseInstanceSettingsIpConfigurationAuthorizedNetworkArgs.builder()
                            .value("34.72.28.29")
                            .build(),
                        DatabaseInstanceSettingsIpConfigurationAuthorizedNetworkArgs.builder()
                            .value("34.67.6.157")
                            .build(),
                        DatabaseInstanceSettingsIpConfigurationAuthorizedNetworkArgs.builder()
                            .value("34.67.234.134")
                            .build(),
                        DatabaseInstanceSettingsIpConfigurationAuthorizedNetworkArgs.builder()
                            .value("34.72.239.218")
                            .build())
                    .build())
                .build())
            .deletionProtection(true)
            .build());

        var db = new Database("db", DatabaseArgs.builder()
            .instance(instance.name())
            .name("db")
            .build());

        var pwd = new RandomPassword("pwd", RandomPasswordArgs.builder()
            .length(16)
            .special(false)
            .build());

        var user = new User("user", UserArgs.builder()
            .name("user")
            .instance(instance.name())
            .host("%")
            .password(pwd.result())
            .build());

        var sourceConnectionProfile = new ConnectionProfile("sourceConnectionProfile", ConnectionProfileArgs.builder()
            .displayName("Source connection profile")
            .location("us-central1")
            .connectionProfileId("source-profile")
            .mysqlProfile(ConnectionProfileMysqlProfileArgs.builder()
                .hostname(instance.publicIpAddress())
                .username(user.name())
                .password(user.password())
                .build())
            .build());

        var destinationConnectionProfile = new ConnectionProfile("destinationConnectionProfile", ConnectionProfileArgs.builder()
            .displayName("Connection profile")
            .location("us-central1")
            .connectionProfileId("destination-profile")
            .bigqueryProfile()
            .build());

        var default_ = new Stream("default", StreamArgs.builder()
            .streamId("my-stream")
            .location("us-central1")
            .displayName("my stream")
            .sourceConfig(StreamSourceConfigArgs.builder()
                .sourceConnectionProfile(sourceConnectionProfile.id())
                .mysqlSourceConfig()
                .build())
            .destinationConfig(StreamDestinationConfigArgs.builder()
                .destinationConnectionProfile(destinationConnectionProfile.id())
                .bigqueryDestinationConfig(StreamDestinationConfigBigqueryDestinationConfigArgs.builder()
                    .sourceHierarchyDatasets(StreamDestinationConfigBigqueryDestinationConfigSourceHierarchyDatasetsArgs.builder()
                        .datasetTemplate(StreamDestinationConfigBigqueryDestinationConfigSourceHierarchyDatasetsDatasetTemplateArgs.builder()
                            .location("us-central1")
                            .build())
                        .build())
                    .appendOnly()
                    .build())
                .build())
            .backfillNone()
            .build());

    }
}
```
```yaml
resources:
  instance:
    type: gcp:sql:DatabaseInstance
    properties:
      name: my-instance
      databaseVersion: MYSQL_8_0
      region: us-central1
      settings:
        tier: db-f1-micro
        backupConfiguration:
          enabled: true
          binaryLogEnabled: true
        ipConfiguration:
          authorizedNetworks:
            - value: 34.71.242.81
            - value: 34.72.28.29
            - value: 34.67.6.157
            - value: 34.67.234.134
            - value: 34.72.239.218
      deletionProtection: true
  db:
    type: gcp:sql:Database
    properties:
      instance: ${instance.name}
      name: db
  pwd:
    type: random:RandomPassword
    properties:
      length: 16
      special: false
  user:
    type: gcp:sql:User
    properties:
      name: user
      instance: ${instance.name}
      host: '%'
      password: ${pwd.result}
  sourceConnectionProfile:
    type: gcp:datastream:ConnectionProfile
    name: source_connection_profile
    properties:
      displayName: Source connection profile
      location: us-central1
      connectionProfileId: source-profile
      mysqlProfile:
        hostname: ${instance.publicIpAddress}
        username: ${user.name}
        password: ${user.password}
  destinationConnectionProfile:
    type: gcp:datastream:ConnectionProfile
    name: destination_connection_profile
    properties:
      displayName: Connection profile
      location: us-central1
      connectionProfileId: destination-profile
      bigqueryProfile: {}
  default:
    type: gcp:datastream:Stream
    properties:
      streamId: my-stream
      location: us-central1
      displayName: my stream
      sourceConfig:
        sourceConnectionProfile: ${sourceConnectionProfile.id}
        mysqlSourceConfig: {}
      destinationConfig:
        destinationConnectionProfile: ${destinationConnectionProfile.id}
        bigqueryDestinationConfig:
          sourceHierarchyDatasets:
            datasetTemplate:
              location: us-central1
          appendOnly: {}
      backfillNone: {}
variables:
  project:
    fn::invoke:
      function: gcp:organizations:getProject
      arguments: {}
```
<!--End PulumiCodeChooser -->

## Import

Stream can be imported using any of these accepted formats:

* `projects/{{project}}/locations/{{location}}/streams/{{stream_id}}`

* `{{project}}/{{location}}/{{stream_id}}`

* `{{location}}/{{stream_id}}`

When using the `pulumi import` command, Stream can be imported using one of the formats above. For example:

```sh
$ pulumi import gcp:datastream/stream:Stream default projects/{{project}}/locations/{{location}}/streams/{{stream_id}}
```

```sh
$ pulumi import gcp:datastream/stream:Stream default {{project}}/{{location}}/{{stream_id}}
```

```sh
$ pulumi import gcp:datastream/stream:Stream default {{location}}/{{stream_id}}
```

Î
backfillAllYBW:U
S

datastreamStreamBackfillAll2gcp:datastream/StreamBackfillAll:StreamBackfillAlldBackfill strategy to automatically backfill the Stream's objects. Specific objects can be excluded.
¸
backfillNone\BZ:X
V

datastreamStreamBackfillNone4gcp:datastream/StreamBackfillNone:StreamBackfillNoneJBackfill strategy to disable automatic backfill for the Stream's objects.
J
createWithoutValidationB
 )Create the stream without validating it.
î
customerManagedEncryptionKeyB" ÇA reference to a KMS encryption key. If provided, it will be used to encrypt the data. If left blank, data will be
encrypted using an internal Stream-specific encryption key provisioned through KMS.

desiredStateB" ÿDesired state of the Stream. Set this field to 'RUNNING' to start the stream, 'NOT_STARTED' to create the stream without
starting and 'PAUSED' to pause the stream from a 'RUNNING' state. Possible values: NOT_STARTED, RUNNING, PAUSED.
Default: NOT_STARTED
Í
destinationConfigi:g
e

datastreamStreamDestinationConfig>gcp:datastream/StreamDestinationConfig:StreamDestinationConfigMDestination connection profile configuration.
Structure is documented below.
!
displayName" Display name.
á
labelsB2" ÎLabels. **Note**: This field is non-authoritative, and will only manage the labels present in your configuration. Please
refer to the field 'effective_labels' for all of the labels present on the resource.
D
location" 4The name of the location this stream is located in.

projectB" ´
sourceConfigZ:X
V

datastreamStreamSourceConfig4gcp:datastream/StreamSourceConfig:StreamSourceConfigHSource connection profile configuration.
Structure is documented below.
'
streamId" The stream identifier.
"Î
backfillAllYBW:U
S

datastreamStreamBackfillAll2gcp:datastream/StreamBackfillAll:StreamBackfillAlldBackfill strategy to automatically backfill the Stream's objects. Specific objects can be excluded.
"¸
backfillNone\BZ:X
V

datastreamStreamBackfillNone4gcp:datastream/StreamBackfillNone:StreamBackfillNoneJBackfill strategy to disable automatic backfill for the Stream's objects.
"J
createWithoutValidationB
 )Create the stream without validating it.
"î
customerManagedEncryptionKeyB" ÇA reference to a KMS encryption key. If provided, it will be used to encrypt the data. If left blank, data will be
encrypted using an internal Stream-specific encryption key provisioned through KMS.
"
desiredStateB" ÿDesired state of the Stream. Set this field to 'RUNNING' to start the stream, 'NOT_STARTED' to create the stream without
starting and 'PAUSED' to pause the stream from a 'RUNNING' state. Possible values: NOT_STARTED, RUNNING, PAUSED.
Default: NOT_STARTED
"Í
destinationConfigi:g
e

datastreamStreamDestinationConfig>gcp:datastream/StreamDestinationConfig:StreamDestinationConfigMDestination connection profile configuration.
Structure is documented below.
"!
displayName" Display name.
"¦
effectiveLabels2" All of labels (key/value pairs) present on the resource in GCP, including the labels configured through Pulumi, other clients and services.
"á
labelsB2" ÎLabels. **Note**: This field is non-authoritative, and will only manage the labels present in your configuration. Please
refer to the field 'effective_labels' for all of the labels present on the resource.
"D
location" 4The name of the location this stream is located in.
"
name" The stream's name.
"
project" "
pulumiLabels2" mThe combination of labels configured directly on the resource
and default labels configured on the provider.
"´
sourceConfigZ:X
V

datastreamStreamSourceConfig4gcp:datastream/StreamSourceConfig:StreamSourceConfigHSource connection profile configuration.
Structure is documented below.
"&
state" The state of the stream.
"'
streamId" The stream identifier.
2Þ
^
containeranalysisgetNoteIamPolicy7gcp:containeranalysis/getNoteIamPolicy:getNoteIamPolicyéRetrieves the current IAM policy data for note


## example

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const policy = gcp.containeranalysis.getNoteIamPolicy({
    project: note.project,
    note: note.name,
});
```
```python
import pulumi
import pulumi_gcp as gcp

policy = gcp.containeranalysis.get_note_iam_policy(project=note["project"],
    note=note["name"])
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var policy = Gcp.ContainerAnalysis.GetNoteIamPolicy.Invoke(new()
    {
        Project = note.Project,
        Note = note.Name,
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/containeranalysis"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		_, err := containeranalysis.LookupNoteIamPolicy(ctx, &containeranalysis.LookupNoteIamPolicyArgs{
			Project: pulumi.StringRef(note.Project),
			Note:    note.Name,
		}, nil)
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.containeranalysis.ContaineranalysisFunctions;
import com.pulumi.gcp.containeranalysis.inputs.GetNoteIamPolicyArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        final var policy = ContaineranalysisFunctions.getNoteIamPolicy(GetNoteIamPolicyArgs.builder()
            .project(note.project())
            .note(note.name())
            .build());

    }
}
```
```yaml
variables:
  policy:
    fn::invoke:
      function: gcp:containeranalysis:getNoteIamPolicy
      arguments:
        project: ${note.project}
        note: ${note.name}
```
<!--End PulumiCodeChooser -->
G
note" ;Used to find the parent resource to bind the IAM policy to

projectB" The ID of the project in which the resource belongs.
If it is not provided, the project will be parsed from the identifier of the parent resource. If no project is provided in the parent identifier and no project is specified, the provider project is used.
"3
etag" '(Computed) The etag of the IAM policy.
"E
id" ;The provider-assigned unique ID for this managed resource.
"

note" "

policyData" (Required only by `gcp.containeranalysis.NoteIamPolicy`) The policy data generated by
a `gcp.organizations.getIAMPolicy` data source.
"
project" 2¥
d
datacataloggetEntryGroupIamPolicy=gcp:datacatalog/getEntryGroupIamPolicy:getEntryGroupIamPolicyRetrieves the current IAM policy data for entrygroup


## example

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const policy = gcp.datacatalog.getEntryGroupIamPolicy({
    entryGroup: basicEntryGroup.name,
});
```
```python
import pulumi
import pulumi_gcp as gcp

policy = gcp.datacatalog.get_entry_group_iam_policy(entry_group=basic_entry_group["name"])
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var policy = Gcp.DataCatalog.GetEntryGroupIamPolicy.Invoke(new()
    {
        EntryGroup = basicEntryGroup.Name,
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/datacatalog"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		_, err := datacatalog.LookupEntryGroupIamPolicy(ctx, &datacatalog.LookupEntryGroupIamPolicyArgs{
			EntryGroup: basicEntryGroup.Name,
		}, nil)
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.datacatalog.DatacatalogFunctions;
import com.pulumi.gcp.datacatalog.inputs.GetEntryGroupIamPolicyArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        final var policy = DatacatalogFunctions.getEntryGroupIamPolicy(GetEntryGroupIamPolicyArgs.builder()
            .entryGroup(basicEntryGroup.name())
            .build());

    }
}
```
```yaml
variables:
  policy:
    fn::invoke:
      function: gcp:datacatalog:getEntryGroupIamPolicy
      arguments:
        entryGroup: ${basicEntryGroup.name}
```
<!--End PulumiCodeChooser -->
M

entryGroup" ;Used to find the parent resource to bind the IAM policy to

projectB" The ID of the project in which the resource belongs.
If it is not provided, the project will be parsed from the identifier of the parent resource. If no project is provided in the parent identifier and no project is specified, the provider project is used.

regionB" "

entryGroup" "3
etag" '(Computed) The etag of the IAM policy.
"E
id" ;The provider-assigned unique ID for this managed resource.
"

policyData" (Required only by `gcp.datacatalog.EntryGroupIamPolicy`) The policy data generated by
a `gcp.organizations.getIAMPolicy` data source.
"
project" "
region" 2Æ
a
datacataloggetPolicyTagIamPolicy;gcp:datacatalog/getPolicyTagIamPolicy:getPolicyTagIamPolicyêRetrieves the current IAM policy data for policytag


## example

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const policy = gcp.datacatalog.getPolicyTagIamPolicy({
    policyTag: basicPolicyTag.name,
});
```
```python
import pulumi
import pulumi_gcp as gcp

policy = gcp.datacatalog.get_policy_tag_iam_policy(policy_tag=basic_policy_tag["name"])
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var policy = Gcp.DataCatalog.GetPolicyTagIamPolicy.Invoke(new()
    {
        PolicyTag = basicPolicyTag.Name,
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/datacatalog"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		_, err := datacatalog.LookupPolicyTagIamPolicy(ctx, &datacatalog.LookupPolicyTagIamPolicyArgs{
			PolicyTag: basicPolicyTag.Name,
		}, nil)
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.datacatalog.DatacatalogFunctions;
import com.pulumi.gcp.datacatalog.inputs.GetPolicyTagIamPolicyArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        final var policy = DatacatalogFunctions.getPolicyTagIamPolicy(GetPolicyTagIamPolicyArgs.builder()
            .policyTag(basicPolicyTag.name())
            .build());

    }
}
```
```yaml
variables:
  policy:
    fn::invoke:
      function: gcp:datacatalog:getPolicyTagIamPolicy
      arguments:
        policyTag: ${basicPolicyTag.name}
```
<!--End PulumiCodeChooser -->
L
	policyTag" ;Used to find the parent resource to bind the IAM policy to
"3
etag" '(Computed) The etag of the IAM policy.
"E
id" ;The provider-assigned unique ID for this managed resource.
"

policyData" (Required only by `gcp.datacatalog.PolicyTagIamPolicy`) The policy data generated by
a `gcp.organizations.getIAMPolicy` data source.
"
	policyTag" 2Á
g
datacataloggetTagTemplateIamPolicy?gcp:datacatalog/getTagTemplateIamPolicy:getTagTemplateIamPolicyRetrieves the current IAM policy data for tagtemplate


## example

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const policy = gcp.datacatalog.getTagTemplateIamPolicy({
    tagTemplate: basicTagTemplate.name,
});
```
```python
import pulumi
import pulumi_gcp as gcp

policy = gcp.datacatalog.get_tag_template_iam_policy(tag_template=basic_tag_template["name"])
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var policy = Gcp.DataCatalog.GetTagTemplateIamPolicy.Invoke(new()
    {
        TagTemplate = basicTagTemplate.Name,
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/datacatalog"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		_, err := datacatalog.LookupTagTemplateIamPolicy(ctx, &datacatalog.LookupTagTemplateIamPolicyArgs{
			TagTemplate: basicTagTemplate.Name,
		}, nil)
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.datacatalog.DatacatalogFunctions;
import com.pulumi.gcp.datacatalog.inputs.GetTagTemplateIamPolicyArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        final var policy = DatacatalogFunctions.getTagTemplateIamPolicy(GetTagTemplateIamPolicyArgs.builder()
            .tagTemplate(basicTagTemplate.name())
            .build());

    }
}
```
```yaml
variables:
  policy:
    fn::invoke:
      function: gcp:datacatalog:getTagTemplateIamPolicy
      arguments:
        tagTemplate: ${basicTagTemplate.name}
```
<!--End PulumiCodeChooser -->

projectB" The ID of the project in which the resource belongs.
If it is not provided, the project will be parsed from the identifier of the parent resource. If no project is provided in the parent identifier and no project is specified, the provider project is used.

regionB" N
tagTemplate" ;Used to find the parent resource to bind the IAM policy to
"3
etag" '(Computed) The etag of the IAM policy.
"E
id" ;The provider-assigned unique ID for this managed resource.
"

policyData" (Required only by `gcp.datacatalog.TagTemplateIamPolicy`) The policy data generated by
a `gcp.organizations.getIAMPolicy` data source.
"
project" "
region" "
tagTemplate" 2ê
^
datacataloggetTaxonomyIamPolicy9gcp:datacatalog/getTaxonomyIamPolicy:getTaxonomyIamPolicyÑRetrieves the current IAM policy data for taxonomy


## example

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const policy = gcp.datacatalog.getTaxonomyIamPolicy({
    taxonomy: basicTaxonomy.name,
});
```
```python
import pulumi
import pulumi_gcp as gcp

policy = gcp.datacatalog.get_taxonomy_iam_policy(taxonomy=basic_taxonomy["name"])
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var policy = Gcp.DataCatalog.GetTaxonomyIamPolicy.Invoke(new()
    {
        Taxonomy = basicTaxonomy.Name,
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/datacatalog"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		_, err := datacatalog.LookupTaxonomyIamPolicy(ctx, &datacatalog.LookupTaxonomyIamPolicyArgs{
			Taxonomy: basicTaxonomy.Name,
		}, nil)
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.datacatalog.DatacatalogFunctions;
import com.pulumi.gcp.datacatalog.inputs.GetTaxonomyIamPolicyArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        final var policy = DatacatalogFunctions.getTaxonomyIamPolicy(GetTaxonomyIamPolicyArgs.builder()
            .taxonomy(basicTaxonomy.name())
            .build());

    }
}
```
```yaml
variables:
  policy:
    fn::invoke:
      function: gcp:datacatalog:getTaxonomyIamPolicy
      arguments:
        taxonomy: ${basicTaxonomy.name}
```
<!--End PulumiCodeChooser -->

projectB" The ID of the project in which the resource belongs.
If it is not provided, the project will be parsed from the identifier of the parent resource. If no project is provided in the parent identifier and no project is specified, the provider project is used.

regionB" K
taxonomy" ;Used to find the parent resource to bind the IAM policy to
"3
etag" '(Computed) The etag of the IAM policy.
"E
id" ;The provider-assigned unique ID for this managed resource.
"

policyData" (Required only by `gcp.datacatalog.TaxonomyIamPolicy`) The policy data generated by
a `gcp.organizations.getIAMPolicy` data source.
"
project" "
region" "
taxonomy" 2Å
^
dataformgetRepositoryIamPolicy:gcp:dataform/getRepositoryIamPolicy:getRepositoryIamPolicy
projectB" The ID of the project in which the resource belongs.
If it is not provided, the project will be parsed from the identifier of the parent resource. If no project is provided in the parent identifier and no project is specified, the provider project is used.
¹
regionB" ¨A reference to the region Used to find the parent resource to bind the IAM policy to. If not specified,
the value will be parsed from the identifier of the parent resource. If no region is provided in the parent identifier and no
region is specified, it is taken from the provider configuration.
M

repository" ;Used to find the parent resource to bind the IAM policy to
"3
etag" '(Computed) The etag of the IAM policy.
"E
id" ;The provider-assigned unique ID for this managed resource.
"

policyData" (Required only by `gcp.dataform.RepositoryIamPolicy`) The policy data generated by
a `gcp.organizations.getIAMPolicy` data source.
"
project" "
region" "

repository" 2î
\

datafusiongetInstanceIamPolicy8gcp:datafusion/getInstanceIamPolicy:getInstanceIamPolicy¢Retrieves the current IAM policy data for instance


## example

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const policy = gcp.datafusion.getInstanceIamPolicy({
    project: basicInstance.project,
    region: basicInstance.region,
    name: basicInstance.name,
});
```
```python
import pulumi
import pulumi_gcp as gcp

policy = gcp.datafusion.get_instance_iam_policy(project=basic_instance["project"],
    region=basic_instance["region"],
    name=basic_instance["name"])
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var policy = Gcp.DataFusion.GetInstanceIamPolicy.Invoke(new()
    {
        Project = basicInstance.Project,
        Region = basicInstance.Region,
        Name = basicInstance.Name,
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/datafusion"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		_, err := datafusion.GetInstanceIamPolicy(ctx, &datafusion.GetInstanceIamPolicyArgs{
			Project: pulumi.StringRef(basicInstance.Project),
			Region:  pulumi.StringRef(basicInstance.Region),
			Name:    basicInstance.Name,
		}, nil)
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.datafusion.DatafusionFunctions;
import com.pulumi.gcp.datafusion.inputs.GetInstanceIamPolicyArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        final var policy = DatafusionFunctions.getInstanceIamPolicy(GetInstanceIamPolicyArgs.builder()
            .project(basicInstance.project())
            .region(basicInstance.region())
            .name(basicInstance.name())
            .build());

    }
}
```
```yaml
variables:
  policy:
    fn::invoke:
      function: gcp:datafusion:getInstanceIamPolicy
      arguments:
        project: ${basicInstance.project}
        region: ${basicInstance.region}
        name: ${basicInstance.name}
```
<!--End PulumiCodeChooser -->
G
name" ;Used to find the parent resource to bind the IAM policy to

projectB" The ID of the project in which the resource belongs.
If it is not provided, the project will be parsed from the identifier of the parent resource. If no project is provided in the parent identifier and no project is specified, the provider project is used.
Ç
regionB" ¶The region of the Data Fusion instance.
Used to find the parent resource to bind the IAM policy to. If not specified,
the value will be parsed from the identifier of the parent resource. If no region is provided in the parent identifier and no
region is specified, it is taken from the provider configuration.
"3
etag" '(Computed) The etag of the IAM policy.
"E
id" ;The provider-assigned unique ID for this managed resource.
"

name" "

policyData" (Required only by `gcp.securitycenter.InstanceIamPolicy`) The policy data generated by
a `gcp.organizations.getIAMPolicy` data source.
"
project" "
region" 2È
^
dataplexgetAspectTypeIamPolicy:gcp:dataplex/getAspectTypeIamPolicy:getAspectTypeIamPolicyRetrieves the current IAM policy data for aspecttype


## example

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const policy = gcp.dataplex.getAspectTypeIamPolicy({
    project: testAspectTypeBasic.project,
    location: testAspectTypeBasic.location,
    aspectTypeId: testAspectTypeBasic.aspectTypeId,
});
```
```python
import pulumi
import pulumi_gcp as gcp

policy = gcp.dataplex.get_aspect_type_iam_policy(project=test_aspect_type_basic["project"],
    location=test_aspect_type_basic["location"],
    aspect_type_id=test_aspect_type_basic["aspectTypeId"])
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var policy = Gcp.DataPlex.GetAspectTypeIamPolicy.Invoke(new()
    {
        Project = testAspectTypeBasic.Project,
        Location = testAspectTypeBasic.Location,
        AspectTypeId = testAspectTypeBasic.AspectTypeId,
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/dataplex"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		_, err := dataplex.LookupAspectTypeIamPolicy(ctx, &dataplex.LookupAspectTypeIamPolicyArgs{
			Project:      pulumi.StringRef(testAspectTypeBasic.Project),
			Location:     pulumi.StringRef(testAspectTypeBasic.Location),
			AspectTypeId: testAspectTypeBasic.AspectTypeId,
		}, nil)
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.dataplex.DataplexFunctions;
import com.pulumi.gcp.dataplex.inputs.GetAspectTypeIamPolicyArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        final var policy = DataplexFunctions.getAspectTypeIamPolicy(GetAspectTypeIamPolicyArgs.builder()
            .project(testAspectTypeBasic.project())
            .location(testAspectTypeBasic.location())
            .aspectTypeId(testAspectTypeBasic.aspectTypeId())
            .build());

    }
}
```
```yaml
variables:
  policy:
    fn::invoke:
      function: gcp:dataplex:getAspectTypeIamPolicy
      arguments:
        project: ${testAspectTypeBasic.project}
        location: ${testAspectTypeBasic.location}
        aspectTypeId: ${testAspectTypeBasic.aspectTypeId}
```
<!--End PulumiCodeChooser -->

aspectTypeId" Ø
locationB" ÅThe location where aspect type will be created in.
Used to find the parent resource to bind the IAM policy to. If not specified,
the value will be parsed from the identifier of the parent resource. If no location is provided in the parent identifier and no
location is specified, it is taken from the provider configuration.

projectB" The ID of the project in which the resource belongs.
If it is not provided, the project will be parsed from the identifier of the parent resource. If no project is provided in the parent identifier and no project is specified, the provider project is used.
"
aspectTypeId" "3
etag" '(Computed) The etag of the IAM policy.
"E
id" ;The provider-assigned unique ID for this managed resource.
"
location" "

policyData" (Required only by `gcp.dataplex.AspectTypeIamPolicy`) The policy data generated by
a `gcp.organizations.getIAMPolicy` data source.
"
project" 2¥
O
dataplexgetAssetIamPolicy0gcp:dataplex/getAssetIamPolicy:getAssetIamPolicyäRetrieves the current IAM policy data for asset


## example

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const policy = gcp.dataplex.getAssetIamPolicy({
    project: example.project,
    location: example.location,
    lake: example.lake,
    dataplexZone: example.dataplexZone,
    asset: example.name,
});
```
```python
import pulumi
import pulumi_gcp as gcp

policy = gcp.dataplex.get_asset_iam_policy(project=example["project"],
    location=example["location"],
    lake=example["lake"],
    dataplex_zone=example["dataplexZone"],
    asset=example["name"])
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var policy = Gcp.DataPlex.GetAssetIamPolicy.Invoke(new()
    {
        Project = example.Project,
        Location = example.Location,
        Lake = example.Lake,
        DataplexZone = example.DataplexZone,
        Asset = example.Name,
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/dataplex"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		_, err := dataplex.LookupAssetIamPolicy(ctx, &dataplex.LookupAssetIamPolicyArgs{
			Project:      pulumi.StringRef(example.Project),
			Location:     pulumi.StringRef(example.Location),
			Lake:         example.Lake,
			DataplexZone: example.DataplexZone,
			Asset:        example.Name,
		}, nil)
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.dataplex.DataplexFunctions;
import com.pulumi.gcp.dataplex.inputs.GetAssetIamPolicyArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        final var policy = DataplexFunctions.getAssetIamPolicy(GetAssetIamPolicyArgs.builder()
            .project(example.project())
            .location(example.location())
            .lake(example.lake())
            .dataplexZone(example.dataplexZone())
            .asset(example.name())
            .build());

    }
}
```
```yaml
variables:
  policy:
    fn::invoke:
      function: gcp:dataplex:getAssetIamPolicy
      arguments:
        project: ${example.project}
        location: ${example.location}
        lake: ${example.lake}
        dataplexZone: ${example.dataplexZone}
        asset: ${example.name}
```
<!--End PulumiCodeChooser -->
H
asset" ;Used to find the parent resource to bind the IAM policy to

dataplexZone" 

lake" 
locationB" 
projectB" The ID of the project in which the resource belongs.
If it is not provided, the project will be parsed from the identifier of the parent resource. If no project is provided in the parent identifier and no project is specified, the provider project is used.
"
asset" "
dataplexZone" "3
etag" '(Computed) The etag of the IAM policy.
"E
id" ;The provider-assigned unique ID for this managed resource.
"

lake" "
location" "

policyData" ~(Required only by `gcp.dataplex.AssetIamPolicy`) The policy data generated by
a `gcp.organizations.getIAMPolicy` data source.
"
project" 2
X
dataplexgetDatascanIamPolicy6gcp:dataplex/getDatascanIamPolicy:getDatascanIamPolicyãRetrieves the current IAM policy data for datascan


## example

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const policy = gcp.dataplex.getDatascanIamPolicy({
    project: basicProfile.project,
    location: basicProfile.location,
    dataScanId: basicProfile.dataScanId,
});
```
```python
import pulumi
import pulumi_gcp as gcp

policy = gcp.dataplex.get_datascan_iam_policy(project=basic_profile["project"],
    location=basic_profile["location"],
    data_scan_id=basic_profile["dataScanId"])
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var policy = Gcp.DataPlex.GetDatascanIamPolicy.Invoke(new()
    {
        Project = basicProfile.Project,
        Location = basicProfile.Location,
        DataScanId = basicProfile.DataScanId,
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/dataplex"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		_, err := dataplex.LookupDatascanIamPolicy(ctx, &dataplex.LookupDatascanIamPolicyArgs{
			Project:    pulumi.StringRef(basicProfile.Project),
			Location:   pulumi.StringRef(basicProfile.Location),
			DataScanId: basicProfile.DataScanId,
		}, nil)
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.dataplex.DataplexFunctions;
import com.pulumi.gcp.dataplex.inputs.GetDatascanIamPolicyArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        final var policy = DataplexFunctions.getDatascanIamPolicy(GetDatascanIamPolicyArgs.builder()
            .project(basicProfile.project())
            .location(basicProfile.location())
            .dataScanId(basicProfile.dataScanId())
            .build());

    }
}
```
```yaml
variables:
  policy:
    fn::invoke:
      function: gcp:dataplex:getDatascanIamPolicy
      arguments:
        project: ${basicProfile.project}
        location: ${basicProfile.location}
        dataScanId: ${basicProfile.dataScanId}
```
<!--End PulumiCodeChooser -->


dataScanId" Õ
locationB" ÂThe location where the data scan should reside.
Used to find the parent resource to bind the IAM policy to. If not specified,
the value will be parsed from the identifier of the parent resource. If no location is provided in the parent identifier and no
location is specified, it is taken from the provider configuration.

projectB" The ID of the project in which the resource belongs.
If it is not provided, the project will be parsed from the identifier of the parent resource. If no project is provided in the parent identifier and no project is specified, the provider project is used.
"

dataScanId" "3
etag" '(Computed) The etag of the IAM policy.
"E
id" ;The provider-assigned unique ID for this managed resource.
"
location" "

policyData" (Required only by `gcp.dataplex.DatascanIamPolicy`) The policy data generated by
a `gcp.organizations.getIAMPolicy` data source.
"
project" 2È
^
dataplexgetEntryGroupIamPolicy:gcp:dataplex/getEntryGroupIamPolicy:getEntryGroupIamPolicyRetrieves the current IAM policy data for entrygroup


## example

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const policy = gcp.dataplex.getEntryGroupIamPolicy({
    project: testEntryGroupBasic.project,
    location: testEntryGroupBasic.location,
    entryGroupId: testEntryGroupBasic.entryGroupId,
});
```
```python
import pulumi
import pulumi_gcp as gcp

policy = gcp.dataplex.get_entry_group_iam_policy(project=test_entry_group_basic["project"],
    location=test_entry_group_basic["location"],
    entry_group_id=test_entry_group_basic["entryGroupId"])
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var policy = Gcp.DataPlex.GetEntryGroupIamPolicy.Invoke(new()
    {
        Project = testEntryGroupBasic.Project,
        Location = testEntryGroupBasic.Location,
        EntryGroupId = testEntryGroupBasic.EntryGroupId,
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/dataplex"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		_, err := dataplex.LookupEntryGroupIamPolicy(ctx, &dataplex.LookupEntryGroupIamPolicyArgs{
			Project:      pulumi.StringRef(testEntryGroupBasic.Project),
			Location:     pulumi.StringRef(testEntryGroupBasic.Location),
			EntryGroupId: testEntryGroupBasic.EntryGroupId,
		}, nil)
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.dataplex.DataplexFunctions;
import com.pulumi.gcp.dataplex.inputs.GetEntryGroupIamPolicyArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        final var policy = DataplexFunctions.getEntryGroupIamPolicy(GetEntryGroupIamPolicyArgs.builder()
            .project(testEntryGroupBasic.project())
            .location(testEntryGroupBasic.location())
            .entryGroupId(testEntryGroupBasic.entryGroupId())
            .build());

    }
}
```
```yaml
variables:
  policy:
    fn::invoke:
      function: gcp:dataplex:getEntryGroupIamPolicy
      arguments:
        project: ${testEntryGroupBasic.project}
        location: ${testEntryGroupBasic.location}
        entryGroupId: ${testEntryGroupBasic.entryGroupId}
```
<!--End PulumiCodeChooser -->

entryGroupId" Ø
locationB" ÅThe location where entry group will be created in.
Used to find the parent resource to bind the IAM policy to. If not specified,
the value will be parsed from the identifier of the parent resource. If no location is provided in the parent identifier and no
location is specified, it is taken from the provider configuration.

projectB" The ID of the project in which the resource belongs.
If it is not provided, the project will be parsed from the identifier of the parent resource. If no project is provided in the parent identifier and no project is specified, the provider project is used.
"
entryGroupId" "3
etag" '(Computed) The etag of the IAM policy.
"E
id" ;The provider-assigned unique ID for this managed resource.
"
location" "

policyData" (Required only by `gcp.dataplex.EntryGroupIamPolicy`) The policy data generated by
a `gcp.organizations.getIAMPolicy` data source.
"
project" 2
[
dataplexgetEntryTypeIamPolicy8gcp:dataplex/getEntryTypeIamPolicy:getEntryTypeIamPolicyîRetrieves the current IAM policy data for entrytype


## example

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const policy = gcp.dataplex.getEntryTypeIamPolicy({
    project: testEntryTypeBasic.project,
    location: testEntryTypeBasic.location,
    entryTypeId: testEntryTypeBasic.entryTypeId,
});
```
```python
import pulumi
import pulumi_gcp as gcp

policy = gcp.dataplex.get_entry_type_iam_policy(project=test_entry_type_basic["project"],
    location=test_entry_type_basic["location"],
    entry_type_id=test_entry_type_basic["entryTypeId"])
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var policy = Gcp.DataPlex.GetEntryTypeIamPolicy.Invoke(new()
    {
        Project = testEntryTypeBasic.Project,
        Location = testEntryTypeBasic.Location,
        EntryTypeId = testEntryTypeBasic.EntryTypeId,
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/dataplex"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		_, err := dataplex.LookupEntryTypeIamPolicy(ctx, &dataplex.LookupEntryTypeIamPolicyArgs{
			Project:     pulumi.StringRef(testEntryTypeBasic.Project),
			Location:    pulumi.StringRef(testEntryTypeBasic.Location),
			EntryTypeId: testEntryTypeBasic.EntryTypeId,
		}, nil)
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.dataplex.DataplexFunctions;
import com.pulumi.gcp.dataplex.inputs.GetEntryTypeIamPolicyArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        final var policy = DataplexFunctions.getEntryTypeIamPolicy(GetEntryTypeIamPolicyArgs.builder()
            .project(testEntryTypeBasic.project())
            .location(testEntryTypeBasic.location())
            .entryTypeId(testEntryTypeBasic.entryTypeId())
            .build());

    }
}
```
```yaml
variables:
  policy:
    fn::invoke:
      function: gcp:dataplex:getEntryTypeIamPolicy
      arguments:
        project: ${testEntryTypeBasic.project}
        location: ${testEntryTypeBasic.location}
        entryTypeId: ${testEntryTypeBasic.entryTypeId}
```
<!--End PulumiCodeChooser -->

entryTypeId" ×
locationB" ÄThe location where entry type will be created in.
Used to find the parent resource to bind the IAM policy to. If not specified,
the value will be parsed from the identifier of the parent resource. If no location is provided in the parent identifier and no
location is specified, it is taken from the provider configuration.

projectB" The ID of the project in which the resource belongs.
If it is not provided, the project will be parsed from the identifier of the parent resource. If no project is provided in the parent identifier and no project is specified, the provider project is used.
"
entryTypeId" "3
etag" '(Computed) The etag of the IAM policy.
"E
id" ;The provider-assigned unique ID for this managed resource.
"
location" "

policyData" (Required only by `gcp.dataplex.EntryTypeIamPolicy`) The policy data generated by
a `gcp.organizations.getIAMPolicy` data source.
"
project" 2
L
dataplexgetLakeIamPolicy.gcp:dataplex/getLakeIamPolicy:getLakeIamPolicyRetrieves the current IAM policy data for lake


## example

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const policy = gcp.dataplex.getLakeIamPolicy({
    project: example.project,
    location: example.location,
    lake: example.name,
});
```
```python
import pulumi
import pulumi_gcp as gcp

policy = gcp.dataplex.get_lake_iam_policy(project=example["project"],
    location=example["location"],
    lake=example["name"])
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var policy = Gcp.DataPlex.GetLakeIamPolicy.Invoke(new()
    {
        Project = example.Project,
        Location = example.Location,
        Lake = example.Name,
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/dataplex"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		_, err := dataplex.LookupLakeIamPolicy(ctx, &dataplex.LookupLakeIamPolicyArgs{
			Project:  pulumi.StringRef(example.Project),
			Location: pulumi.StringRef(example.Location),
			Lake:     example.Name,
		}, nil)
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.dataplex.DataplexFunctions;
import com.pulumi.gcp.dataplex.inputs.GetLakeIamPolicyArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        final var policy = DataplexFunctions.getLakeIamPolicy(GetLakeIamPolicyArgs.builder()
            .project(example.project())
            .location(example.location())
            .lake(example.name())
            .build());

    }
}
```
```yaml
variables:
  policy:
    fn::invoke:
      function: gcp:dataplex:getLakeIamPolicy
      arguments:
        project: ${example.project}
        location: ${example.location}
        lake: ${example.name}
```
<!--End PulumiCodeChooser -->
G
lake" ;Used to find the parent resource to bind the IAM policy to

locationB" 
projectB" The ID of the project in which the resource belongs.
If it is not provided, the project will be parsed from the identifier of the parent resource. If no project is provided in the parent identifier and no project is specified, the provider project is used.
"3
etag" '(Computed) The etag of the IAM policy.
"E
id" ;The provider-assigned unique ID for this managed resource.
"

lake" "
location" "

policyData" }(Required only by `gcp.dataplex.LakeIamPolicy`) The policy data generated by
a `gcp.organizations.getIAMPolicy` data source.
"
project" 2ä
L
dataplexgetTaskIamPolicy.gcp:dataplex/getTaskIamPolicy:getTaskIamPolicyÕRetrieves the current IAM policy data for task


## example

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const policy = gcp.dataplex.getTaskIamPolicy({
    project: example.project,
    location: example.location,
    lake: example.lake,
    taskId: example.taskId,
});
```
```python
import pulumi
import pulumi_gcp as gcp

policy = gcp.dataplex.get_task_iam_policy(project=example["project"],
    location=example["location"],
    lake=example["lake"],
    task_id=example["taskId"])
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var policy = Gcp.DataPlex.GetTaskIamPolicy.Invoke(new()
    {
        Project = example.Project,
        Location = example.Location,
        Lake = example.Lake,
        TaskId = example.TaskId,
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/dataplex"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		_, err := dataplex.LookupTaskIamPolicy(ctx, &dataplex.LookupTaskIamPolicyArgs{
			Project:  pulumi.StringRef(example.Project),
			Location: pulumi.StringRef(example.Location),
			Lake:     example.Lake,
			TaskId:   example.TaskId,
		}, nil)
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.dataplex.DataplexFunctions;
import com.pulumi.gcp.dataplex.inputs.GetTaskIamPolicyArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        final var policy = DataplexFunctions.getTaskIamPolicy(GetTaskIamPolicyArgs.builder()
            .project(example.project())
            .location(example.location())
            .lake(example.lake())
            .taskId(example.taskId())
            .build());

    }
}
```
```yaml
variables:
  policy:
    fn::invoke:
      function: gcp:dataplex:getTaskIamPolicy
      arguments:
        project: ${example.project}
        location: ${example.location}
        lake: ${example.lake}
        taskId: ${example.taskId}
```
<!--End PulumiCodeChooser -->
v
lake" jThe lake in which the task will be created in.
Used to find the parent resource to bind the IAM policy to
Ø
locationB" ÅThe location in which the task will be created in.
Used to find the parent resource to bind the IAM policy to. If not specified,
the value will be parsed from the identifier of the parent resource. If no location is provided in the parent identifier and no
location is specified, it is taken from the provider configuration.

projectB" The ID of the project in which the resource belongs.
If it is not provided, the project will be parsed from the identifier of the parent resource. If no project is provided in the parent identifier and no project is specified, the provider project is used.

taskId" "3
etag" '(Computed) The etag of the IAM policy.
"E
id" ;The provider-assigned unique ID for this managed resource.
"

lake" "
location" "

policyData" }(Required only by `gcp.dataplex.TaskIamPolicy`) The policy data generated by
a `gcp.organizations.getIAMPolicy` data source.
"
project" "
taskId" 2
L
dataplexgetZoneIamPolicy.gcp:dataplex/getZoneIamPolicy:getZoneIamPolicy÷Retrieves the current IAM policy data for zone


## example

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const policy = gcp.dataplex.getZoneIamPolicy({
    project: example.project,
    location: example.location,
    lake: example.lake,
    dataplexZone: example.name,
});
```
```python
import pulumi
import pulumi_gcp as gcp

policy = gcp.dataplex.get_zone_iam_policy(project=example["project"],
    location=example["location"],
    lake=example["lake"],
    dataplex_zone=example["name"])
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var policy = Gcp.DataPlex.GetZoneIamPolicy.Invoke(new()
    {
        Project = example.Project,
        Location = example.Location,
        Lake = example.Lake,
        DataplexZone = example.Name,
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/dataplex"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		_, err := dataplex.LookupZoneIamPolicy(ctx, &dataplex.LookupZoneIamPolicyArgs{
			Project:      pulumi.StringRef(example.Project),
			Location:     pulumi.StringRef(example.Location),
			Lake:         example.Lake,
			DataplexZone: example.Name,
		}, nil)
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.dataplex.DataplexFunctions;
import com.pulumi.gcp.dataplex.inputs.GetZoneIamPolicyArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        final var policy = DataplexFunctions.getZoneIamPolicy(GetZoneIamPolicyArgs.builder()
            .project(example.project())
            .location(example.location())
            .lake(example.lake())
            .dataplexZone(example.name())
            .build());

    }
}
```
```yaml
variables:
  policy:
    fn::invoke:
      function: gcp:dataplex:getZoneIamPolicy
      arguments:
        project: ${example.project}
        location: ${example.location}
        lake: ${example.lake}
        dataplexZone: ${example.name}
```
<!--End PulumiCodeChooser -->
O
dataplexZone" ;Used to find the parent resource to bind the IAM policy to


lake" 
locationB" 
projectB" The ID of the project in which the resource belongs.
If it is not provided, the project will be parsed from the identifier of the parent resource. If no project is provided in the parent identifier and no project is specified, the provider project is used.
"
dataplexZone" "3
etag" '(Computed) The etag of the IAM policy.
"E
id" ;The provider-assigned unique ID for this managed resource.
"

lake" "
location" "

policyData" }(Required only by `gcp.dataplex.ZoneIamPolicy`) The policy data generated by
a `gcp.organizations.getIAMPolicy` data source.
"
project" 2
s
dataprocgetAutoscalingPolicyIamPolicyHgcp:dataproc/getAutoscalingPolicyIamPolicy:getAutoscalingPolicyIamPolicy Retrieves the current IAM policy data for autoscalingpolicy


## example

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const policy = gcp.dataproc.getAutoscalingPolicyIamPolicy({
    project: basic.project,
    location: basic.location,
    policyId: basic.policyId,
});
```
```python
import pulumi
import pulumi_gcp as gcp

policy = gcp.dataproc.get_autoscaling_policy_iam_policy(project=basic["project"],
    location=basic["location"],
    policy_id=basic["policyId"])
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var policy = Gcp.Dataproc.GetAutoscalingPolicyIamPolicy.Invoke(new()
    {
        Project = basic.Project,
        Location = basic.Location,
        PolicyId = basic.PolicyId,
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/dataproc"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		_, err := dataproc.LookupAutoscalingPolicyIamPolicy(ctx, &dataproc.LookupAutoscalingPolicyIamPolicyArgs{
			Project:  pulumi.StringRef(basic.Project),
			Location: pulumi.StringRef(basic.Location),
			PolicyId: basic.PolicyId,
		}, nil)
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.dataproc.DataprocFunctions;
import com.pulumi.gcp.dataproc.inputs.GetAutoscalingPolicyIamPolicyArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        final var policy = DataprocFunctions.getAutoscalingPolicyIamPolicy(GetAutoscalingPolicyIamPolicyArgs.builder()
            .project(basic.project())
            .location(basic.location())
            .policyId(basic.policyId())
            .build());

    }
}
```
```yaml
variables:
  policy:
    fn::invoke:
      function: gcp:dataproc:getAutoscalingPolicyIamPolicy
      arguments:
        project: ${basic.project}
        location: ${basic.location}
        policyId: ${basic.policyId}
```
<!--End PulumiCodeChooser -->
þ
locationB" ëThe  location where the autoscaling policy should reside.
The default value is `global`.
Used to find the parent resource to bind the IAM policy to. If not specified,
the value will be parsed from the identifier of the parent resource. If no location is provided in the parent identifier and no
location is specified, it is taken from the provider configuration.

policyId" The policy id. The id must contain only letters (a-z, A-Z), numbers (0-9), underscores (_),
and hyphens (-). Cannot begin or end with underscore or hyphen. Must consist of between
3 and 50 characters.
Used to find the parent resource to bind the IAM policy to

projectB" The ID of the project in which the resource belongs.
If it is not provided, the project will be parsed from the identifier of the parent resource. If no project is provided in the parent identifier and no project is specified, the provider project is used.
"3
etag" '(Computed) The etag of the IAM policy.
"E
id" ;The provider-assigned unique ID for this managed resource.
"
location" "

policyData" (Required only by `gcp.dataproc.AutoscalingPolicyIamPolicy`) The policy data generated by
a `gcp.organizations.getIAMPolicy` data source.
"
policyId" "
project" 2ð
U
dataprocgetClusterIamPolicy4gcp:dataproc/getClusterIamPolicy:getClusterIamPolicyÁRetrieves the current IAM policy data for a Dataproc cluster.

## example

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const policy = gcp.dataproc.getClusterIamPolicy({
    cluster: cluster.name,
    region: "us-central1",
});
```
```python
import pulumi
import pulumi_gcp as gcp

policy = gcp.dataproc.get_cluster_iam_policy(cluster=cluster["name"],
    region="us-central1")
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var policy = Gcp.Dataproc.GetClusterIamPolicy.Invoke(new()
    {
        Cluster = cluster.Name,
        Region = "us-central1",
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/dataproc"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		_, err := dataproc.GetClusterIamPolicy(ctx, &dataproc.GetClusterIamPolicyArgs{
			Cluster: cluster.Name,
			Region:  pulumi.StringRef("us-central1"),
		}, nil)
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.dataproc.DataprocFunctions;
import com.pulumi.gcp.dataproc.inputs.GetClusterIamPolicyArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        final var policy = DataprocFunctions.getClusterIamPolicy(GetClusterIamPolicyArgs.builder()
            .cluster(cluster.name())
            .region("us-central1")
            .build());

    }
}
```
```yaml
variables:
  policy:
    fn::invoke:
      function: gcp:dataproc:getClusterIamPolicy
      arguments:
        cluster: ${cluster.name}
        region: us-central1
```
<!--End PulumiCodeChooser -->
[
cluster" LThe name or relative resource id of the cluster to manage IAM policies for.

projectB" 
regionB" "
cluster" "3
etag" '(Computed) The etag of the IAM policy.
"E
id" ;The provider-assigned unique ID for this managed resource.
"-

policyData" (Computed) The policy data
"
project" "
region" 2
I
dataprocgetJobIamPolicy,gcp:dataproc/getJobIamPolicy:getJobIamPolicyçRetrieves the current IAM policy data for a Dataproc job.

## example

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const policy = gcp.dataproc.getJobIamPolicy({
    jobId: pyspark.reference[0].jobId,
    region: "us-central1",
});
```
```python
import pulumi
import pulumi_gcp as gcp

policy = gcp.dataproc.get_job_iam_policy(job_id=pyspark["reference"][0]["jobId"],
    region="us-central1")
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var policy = Gcp.Dataproc.GetJobIamPolicy.Invoke(new()
    {
        JobId = pyspark.Reference[0].JobId,
        Region = "us-central1",
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/dataproc"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		_, err := dataproc.GetJobIamPolicy(ctx, &dataproc.GetJobIamPolicyArgs{
			JobId:  pyspark.Reference[0].JobId,
			Region: pulumi.StringRef("us-central1"),
		}, nil)
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.dataproc.DataprocFunctions;
import com.pulumi.gcp.dataproc.inputs.GetJobIamPolicyArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        final var policy = DataprocFunctions.getJobIamPolicy(GetJobIamPolicyArgs.builder()
            .jobId(pyspark.reference()[0].jobId())
            .region("us-central1")
            .build());

    }
}
```
```yaml
variables:
  policy:
    fn::invoke:
      function: gcp:dataproc:getJobIamPolicy
      arguments:
        jobId: ${pyspark.reference[0].jobId}
        region: us-central1
```
<!--End PulumiCodeChooser -->
U
jobId" HThe name or relative resource id of the job to manage IAM policies for.

projectB" 
regionB" "3
etag" '(Computed) The etag of the IAM policy.
"E
id" ;The provider-assigned unique ID for this managed resource.
"
jobId" "-

policyData" (Computed) The policy data
"
project" "
region" 2ï
y
dataprocgetMetastoreFederationIamPolicyLgcp:dataproc/getMetastoreFederationIamPolicy:getMetastoreFederationIamPolicyRetrieves the current IAM policy data for federation


## example

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const policy = gcp.dataproc.getMetastoreFederationIamPolicy({
    project: _default.project,
    location: _default.location,
    federationId: _default.federationId,
});
```
```python
import pulumi
import pulumi_gcp as gcp

policy = gcp.dataproc.get_metastore_federation_iam_policy(project=default["project"],
    location=default["location"],
    federation_id=default["federationId"])
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var policy = Gcp.Dataproc.GetMetastoreFederationIamPolicy.Invoke(new()
    {
        Project = @default.Project,
        Location = @default.Location,
        FederationId = @default.FederationId,
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/dataproc"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		_, err := dataproc.LookupMetastoreFederationIamPolicy(ctx, &dataproc.LookupMetastoreFederationIamPolicyArgs{
			Project:      pulumi.StringRef(_default.Project),
			Location:     pulumi.StringRef(_default.Location),
			FederationId: _default.FederationId,
		}, nil)
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.dataproc.DataprocFunctions;
import com.pulumi.gcp.dataproc.inputs.GetMetastoreFederationIamPolicyArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        final var policy = DataprocFunctions.getMetastoreFederationIamPolicy(GetMetastoreFederationIamPolicyArgs.builder()
            .project(default_.project())
            .location(default_.location())
            .federationId(default_.federationId())
            .build());

    }
}
```
```yaml
variables:
  policy:
    fn::invoke:
      function: gcp:dataproc:getMetastoreFederationIamPolicy
      arguments:
        project: ${default.project}
        location: ${default.location}
        federationId: ${default.federationId}
```
<!--End PulumiCodeChooser -->

federationId" à
locationB" ÍThe location where the metastore federation should reside.
Used to find the parent resource to bind the IAM policy to. If not specified,
the value will be parsed from the identifier of the parent resource. If no location is provided in the parent identifier and no
location is specified, it is taken from the provider configuration.

projectB" The ID of the project in which the resource belongs.
If it is not provided, the project will be parsed from the identifier of the parent resource. If no project is provided in the parent identifier and no project is specified, the provider project is used.
"3
etag" '(Computed) The etag of the IAM policy.
"
federationId" "E
id" ;The provider-assigned unique ID for this managed resource.
"
location" "

policyData" (Required only by `gcp.dataproc.MetastoreFederationIamPolicy`) The policy data generated by
a `gcp.organizations.getIAMPolicy` data source.
"
project" 2 
U
dataprocgetMetastoreService4gcp:dataproc/getMetastoreService:getMetastoreServiceGet a Dataproc Metastore service from Google Cloud by its id and location.

## Example Usage

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const foo = gcp.dataproc.getMetastoreService({
    serviceId: "foo-bar",
    location: "global",
});
```
```python
import pulumi
import pulumi_gcp as gcp

foo = gcp.dataproc.get_metastore_service(service_id="foo-bar",
    location="global")
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var foo = Gcp.Dataproc.GetMetastoreService.Invoke(new()
    {
        ServiceId = "foo-bar",
        Location = "global",
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/dataproc"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		_, err := dataproc.LookupMetastoreService(ctx, &dataproc.LookupMetastoreServiceArgs{
			ServiceId: "foo-bar",
			Location:  "global",
		}, nil)
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.dataproc.DataprocFunctions;
import com.pulumi.gcp.dataproc.inputs.GetMetastoreServiceArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        final var foo = DataprocFunctions.getMetastoreService(GetMetastoreServiceArgs.builder()
            .serviceId("foo-bar")
            .location("global")
            .build());

    }
}
```
```yaml
variables:
  foo:
    fn::invoke:
      function: gcp:dataproc:getMetastoreService
      arguments:
        serviceId: foo-bar
        location: global
```
<!--End PulumiCodeChooser -->
I
location" 9The location where the metastore service resides.

- - -
q
projectB" `The project in which the resource belongs. If it
is not provided, the provider project is used.
2
	serviceId" !The ID of the metastore service.
"
artifactGcsUri" "
databaseType" "
deletionProtection
 "
effectiveLabels2" "¤
encryptionConfigs*:

dataproc#getMetastoreServiceEncryptionConfigTgcp:dataproc/getMetastoreServiceEncryptionConfig:getMetastoreServiceEncryptionConfig"
endpointUri" "°
hiveMetastoreConfigs*:

dataproc&getMetastoreServiceHiveMetastoreConfigZgcp:dataproc/getMetastoreServiceHiveMetastoreConfig:getMetastoreServiceHiveMetastoreConfig"E
id" ;The provider-assigned unique ID for this managed resource.
"
labels2" "
location" "¨
maintenanceWindows*:

dataproc$getMetastoreServiceMaintenanceWindowVgcp:dataproc/getMetastoreServiceMaintenanceWindow:getMetastoreServiceMaintenanceWindow"°
metadataIntegrations*:

dataproc&getMetastoreServiceMetadataIntegrationZgcp:dataproc/getMetastoreServiceMetadataIntegration:getMetastoreServiceMetadataIntegration"

name" "
network" "
networkConfigs*:~
|
dataproc getMetastoreServiceNetworkConfigNgcp:dataproc/getMetastoreServiceNetworkConfig:getMetastoreServiceNetworkConfig"

port "
projectB" "
pulumiLabels2" "
releaseChannel" "
scalingConfigs*:~
|
dataproc getMetastoreServiceScalingConfigNgcp:dataproc/getMetastoreServiceScalingConfig:getMetastoreServiceScalingConfig" 
scheduledBackups*:

dataproc"getMetastoreServiceScheduledBackupRgcp:dataproc/getMetastoreServiceScheduledBackup:getMetastoreServiceScheduledBackup"
	serviceId" "
state" "
stateMessage" " 
telemetryConfigs*:

dataproc"getMetastoreServiceTelemetryConfigRgcp:dataproc/getMetastoreServiceTelemetryConfig:getMetastoreServiceTelemetryConfig"

tier" "	
uid" 2±
p
dataprocgetMetastoreServiceIamPolicyFgcp:dataproc/getMetastoreServiceIamPolicy:getMetastoreServiceIamPolicyËRetrieves the current IAM policy data for service


## example

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const policy = gcp.dataproc.getMetastoreServiceIamPolicy({
    project: _default.project,
    location: _default.location,
    serviceId: _default.serviceId,
});
```
```python
import pulumi
import pulumi_gcp as gcp

policy = gcp.dataproc.get_metastore_service_iam_policy(project=default["project"],
    location=default["location"],
    service_id=default["serviceId"])
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var policy = Gcp.Dataproc.GetMetastoreServiceIamPolicy.Invoke(new()
    {
        Project = @default.Project,
        Location = @default.Location,
        ServiceId = @default.ServiceId,
    });

});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/dataproc"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		_, err := dataproc.LookupMetastoreServiceIamPolicy(ctx, &dataproc.LookupMetastoreServiceIamPolicyArgs{
			Project:   pulumi.StringRef(_default.Project),
			Location:  pulumi.StringRef(_default.Location),
			ServiceId: _default.ServiceId,
		}, nil)
		if err != nil {
			return err
		}
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.dataproc.DataprocFunctions;
import com.pulumi.gcp.dataproc.inputs.GetMetastoreServiceIamPolicyArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        final var policy = DataprocFunctions.getMetastoreServiceIamPolicy(GetMetastoreServiceIamPolicyArgs.builder()
            .project(default_.project())
            .location(default_.location())
            .serviceId(default_.serviceId())
            .build());

    }
}
```
```yaml
variables:
  policy:
    fn::invoke:
      function: gcp:dataproc:getMetastoreServiceIamPolicy
      arguments:
        project: ${default.project}
        location: ${default.location}
        serviceId: ${default.serviceId}
```
<!--End PulumiCodeChooser -->
ü
locationB" éThe location where the metastore service should reside.
The default value is `global`.
Used to find the parent resource to bind the IAM policy to. If not specified,
the value will be parsed from the identifier of the parent resource. If no location is provided in the parent identifier and no
location is specified, it is taken from the provider configuration.

projectB" The ID of the project in which the resource belongs.
If it is not provided, the project will be parsed from the identifier of the parent resource. If no project is provided in the parent identifier and no project is specified, the provider project is used.

	serviceId" "3
etag" '(Computed) The etag of the IAM policy.
"E
id" ;The provider-assigned unique ID for this managed resource.
"
location" "

policyData" (Required only by `gcp.dataproc.MetastoreServiceIamPolicy`) The policy data generated by
a `gcp.organizations.getIAMPolicy` data source.
"
project" "
	serviceId" 2ï
D

datastreamgetStaticIps(gcp:datastream/getStaticIps:getStaticIps£Returns the list of IP addresses that Datastream connects from. For more information see
the [official documentation](https://cloud.google.com/datastream/docs/ip-allowlists-and-regions).

## Example Usage

<!--Start PulumiCodeChooser -->
```typescript
import * as pulumi from "@pulumi/pulumi";
import * as gcp from "@pulumi/gcp";

const datastreamIps = gcp.datastream.getStaticIps({
    location: "us-west1",
    project: "my-project",
});
export const ipList = datastreamIps.then(datastreamIps => datastreamIps.staticIps);
```
```python
import pulumi
import pulumi_gcp as gcp

datastream_ips = gcp.datastream.get_static_ips(location="us-west1",
    project="my-project")
pulumi.export("ipList", datastream_ips.static_ips)
```
```csharp
using System.Collections.Generic;
using System.Linq;
using Pulumi;
using Gcp = Pulumi.Gcp;

return await Deployment.RunAsync(() => 
{
    var datastreamIps = Gcp.Datastream.GetStaticIps.Invoke(new()
    {
        Location = "us-west1",
        Project = "my-project",
    });

    return new Dictionary<string, object?>
    {
        ["ipList"] = datastreamIps.Apply(getStaticIpsResult => getStaticIpsResult.StaticIps),
    };
});
```
```go
package main

import (
	"github.com/pulumi/pulumi-gcp/sdk/v8/go/gcp/datastream"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

func main() {
	pulumi.Run(func(ctx *pulumi.Context) error {
		datastreamIps, err := datastream.GetStaticIps(ctx, &datastream.GetStaticIpsArgs{
			Location: "us-west1",
			Project:  pulumi.StringRef("my-project"),
		}, nil)
		if err != nil {
			return err
		}
		ctx.Export("ipList", datastreamIps.StaticIps)
		return nil
	})
}
```
```java
package generated_program;

import com.pulumi.Context;
import com.pulumi.Pulumi;
import com.pulumi.core.Output;
import com.pulumi.gcp.datastream.DatastreamFunctions;
import com.pulumi.gcp.datastream.inputs.GetStaticIpsArgs;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.io.File;
import java.nio.file.Files;
import java.nio.file.Paths;

public class App {
    public static void main(String[] args) {
        Pulumi.run(App::stack);
    }

    public static void stack(Context ctx) {
        final var datastreamIps = DatastreamFunctions.getStaticIps(GetStaticIpsArgs.builder()
            .location("us-west1")
            .project("my-project")
            .build());

        ctx.export("ipList", datastreamIps.applyValue(getStaticIpsResult -> getStaticIpsResult.staticIps()));
    }
}
```
```yaml
variables:
  datastreamIps:
    fn::invoke:
      function: gcp:datastream:getStaticIps
      arguments:
        location: us-west1
        project: my-project
outputs:
  ipList: ${datastreamIps.staticIps}
```
<!--End PulumiCodeChooser -->
R
location" BThe location to list Datastream IPs for. For example: `us-east1`.
o
projectB" ^Project from which to list static IP addresses. Defaults to project declared in the provider.
"E
id" ;The provider-assigned unique ID for this managed resource.
"
location" "
projectB" "T
	staticIps*" AA list of static IP addresses that Datastream will connect from.
:
v
containeranalysisNoteAttestationAuthorityGgcp:containeranalysis/NoteAttestationAuthority:NoteAttestationAuthority

hint:

containeranalysisNoteAttestationAuthorityHintOgcp:containeranalysis/NoteAttestationAuthorityHint:NoteAttestationAuthorityHintõThis submessage provides human-readable hints about the purpose of
the AttestationAuthority. Because the name of a Note acts as its
resource reference, it is important to disambiguate the canonical
name of the Note (which might be a UUID for security purposes)
from "readable" names more suitable for debug output. Note that
these hints should NOT be used to look up AttestationAuthorities
in security sensitive contexts, such as when looking up
Attestations to verify.
Structure is documented below.
:ô

containeranalysisNoteAttestationAuthorityHintOgcp:containeranalysis/NoteAttestationAuthorityHint:NoteAttestationAuthorityHintm
ki
humanReadableName" PThe human readable name of this Attestation Authority, for
example "qa".

- - -
:­
s
containeranalysisNoteIamBindingConditionEgcp:containeranalysis/NoteIamBindingCondition:NoteIamBindingCondition6
4
descriptionB" 

expression" 
title" :ª
p
containeranalysisNoteIamMemberConditionCgcp:containeranalysis/NoteIamMemberCondition:NoteIamMemberCondition6
4
descriptionB" 

expression" 
title" :Ê
X
containeranalysisNoteRelatedUrl3gcp:containeranalysis/NoteRelatedUrl:NoteRelatedUrln
l2
labelB" #Label to describe usage of the URL
6
url" +Specific URL associated with the resource.
:³
j
containeranalysisOccurenceAttestation?gcp:containeranalysis/OccurenceAttestation:OccurenceAttestationÄ
Áu
serializedPayload" \The serialized payload that is verified by one or
more signatures. A base64-encoded string.
Ç

signatures*:

containeranalysisOccurenceAttestationSignatureQgcp:containeranalysis/OccurenceAttestationSignature:OccurenceAttestationSignature§One or more signatures over serializedPayload.
Verifier implementations should consider this attestation
message verified if at least one signature verifies
serializedPayload. See Signature in common.proto for more
details on signature structure and verification.
Structure is documented below.
:Ç

containeranalysisOccurenceAttestationSignatureQgcp:containeranalysis/OccurenceAttestationSignature:OccurenceAttestationSignature¼
¹Ä
publicKeyId" °The identifier for the public key that verifies this
signature. MUST be an RFC3986 conformant
URI. * When possible, the key id should be an
immutable reference, such as a cryptographic digest.
Examples of valid values:
* OpenPGP V4 public key fingerprint. See https://www.iana.org/assignments/uri-schemes/prov/openpgp4fpr
for more details on this scheme.
* `openpgp4fpr:74FAF3B861BDA0870C7B6DEF607E48D2A663AEEA`
* RFC6920 digest-named SubjectPublicKeyInfo (digest of the DER serialization):
* "ni:///sha-256;cD9o9Cq6LG3jD0iKXqEi_vdjJGecm_iXkbqVoScViaU"

- - -
ï
	signatureB" ÛThe content of the signature, an opaque bytestring.
The payload that this signature verifies MUST be
unambiguously provided with the Signature during
verification. A wrapper message might provide the
payload explicitly. Alternatively, a message might
have a canonical serialization that can always be
unambiguously computed to derive the payload.
:

databasemigrationserviceConnectionProfileAlloydbNgcp:databasemigrationservice/ConnectionProfileAlloydb:ConnectionProfileAlloydb
ÿc
	clusterId" RRequired. The AlloyDB cluster ID that this connection profile is associated with.

settings¥B¢:

databasemigrationservice ConnectionProfileAlloydbSettings^gcp:databasemigrationservice/ConnectionProfileAlloydbSettings:ConnectionProfileAlloydbSettingscImmutable. Metadata used to create the destination AlloyDB cluster.
Structure is documented below.
:Ô	

databasemigrationservice ConnectionProfileAlloydbSettings^gcp:databasemigrationservice/ConnectionProfileAlloydbSettings:ConnectionProfileAlloydbSettings²
¯¹
initialUserÃ:À
½
databasemigrationservice+ConnectionProfileAlloydbSettingsInitialUsertgcp:databasemigrationservice/ConnectionProfileAlloydbSettingsInitialUser:ConnectionProfileAlloydbSettingsInitialUserdRequired. Input only. Initial user to setup during cluster creation.
Structure is documented below.
A
labelsB2" /Labels for the AlloyDB cluster created by DMS.
Ô
primaryInstanceSettingsëBè:å
â
databasemigrationservice7ConnectionProfileAlloydbSettingsPrimaryInstanceSettingsgcp:databasemigrationservice/ConnectionProfileAlloydbSettingsPrimaryInstanceSettings:ConnectionProfileAlloydbSettingsPrimaryInstanceSettingsKSettings for the cluster's primary instance
Structure is documented below.
Ö

vpcNetwork" ÃRequired. The resource link for the VPC network in which cluster resources are created and from which they are accessible via Private IP. The network must belong to the same project as the cluster.
It is specified in the form: 'projects/{project_number}/global/networks/{network_id}'. This is required to create a cluster.
:Ó
½
databasemigrationservice+ConnectionProfileAlloydbSettingsInitialUsertgcp:databasemigrationservice/ConnectionProfileAlloydbSettingsInitialUser:ConnectionProfileAlloydbSettingsInitialUser

password" oThe initial password for the user.
**Note**: This property is sensitive and will not be displayed in the plan.
e
passwordSetB
 P(Output)
Output only. Indicates if the initialUser.password field has been set.
#
user" The database username.
:ª
â
databasemigrationservice7ConnectionProfileAlloydbSettingsPrimaryInstanceSettingsgcp:databasemigrationservice/ConnectionProfileAlloydbSettingsPrimaryInstanceSettings:ConnectionProfileAlloydbSettingsPrimaryInstanceSettingsÂ
¿­
databaseFlagsB2" Database flags to pass to AlloyDB when DMS is creating the AlloyDB cluster and instances. See the AlloyDB documentation for how these can be used.
!
id" The database username.
J
labelsB2" 8Labels for the AlloyDB primary instance created by DMS.

machineConfig:

databasemigrationserviceDConnectionProfileAlloydbSettingsPrimaryInstanceSettingsMachineConfig¦gcp:databasemigrationservice/ConnectionProfileAlloydbSettingsPrimaryInstanceSettingsMachineConfig:ConnectionProfileAlloydbSettingsPrimaryInstanceSettingsMachineConfighConfiguration for the machines that host the underlying database engine.
Structure is documented below.

	privateIpB" |(Output)
Output only. The private IP address for the Instance. This is the connection endpoint for an end-user application.
:Ê

databasemigrationserviceDConnectionProfileAlloydbSettingsPrimaryInstanceSettingsMachineConfig¦gcp:databasemigrationservice/ConnectionProfileAlloydbSettingsPrimaryInstanceSettingsMachineConfig:ConnectionProfileAlloydbSettingsPrimaryInstanceSettingsMachineConfig<
:8
cpuCount (The number of CPU's in the VM instance.
:×

databasemigrationserviceConnectionProfileCloudsqlPgcp:databasemigrationservice/ConnectionProfileCloudsql:ConnectionProfileCloudsqlÊ
Çu

cloudSqlIdB" a(Output)
Output only. The Cloud SQL instance ID that this connection profile is associated with.
W
	privateIpB" D(Output)
Output only. The Cloud SQL database instance's private IP.
U
publicIpB" C(Output)
Output only. The Cloud SQL database instance's public IP.

settings¨B¥:¢

databasemigrationservice!ConnectionProfileCloudsqlSettings`gcp:databasemigrationservice/ConnectionProfileCloudsqlSettings:ConnectionProfileCloudsqlSettingsfImmutable. Metadata used to create the destination Cloud SQL database.
Structure is documented below.
:Ý

databasemigrationservice!ConnectionProfileCloudsqlSettings`gcp:databasemigrationservice/ConnectionProfileCloudsqlSettings:ConnectionProfileCloudsqlSettings¸
µÀ
activationPolicyB" ¥The activation policy specifies when the instance is activated; it is applicable only when the instance state is 'RUNNABLE'.
Possible values are: `ALWAYS`, `NEVER`.
ó
autoStorageIncreaseB
 ÕIf you enable this setting, Cloud SQL checks your available storage every 30 seconds. If the available storage falls below a threshold size, Cloud SQL automatically adds additional storage capacity.
If the available storage repeatedly falls below the threshold size, Cloud SQL continues to add storage until it reaches the maximum of 30 TB.
B
cmekKeyNameB" -The KMS key name used for the csql instance.
C
	collationB" 0The Cloud SQL default instance level collation.
w
dataDiskSizeGbB" _The storage capacity available to the database, in GB. The minimum (and default) size is 10GB.
T
dataDiskTypeB" >The type of storage.
Possible values are: `PD_SSD`, `PD_HDD`.
Y
databaseFlagsB2" @The database flags passed to the Cloud SQL instance at startup.
â
databaseVersionB" ÈThe database engine type and version.
Currently supported values located at https://cloud.google.com/database-migration/docs/reference/rest/v1/projects.locations.connectionProfiles#sqldatabaseversion
t
editionB" cThe edition of the given Cloud SQL instance.
Possible values are: `ENTERPRISE`, `ENTERPRISE_PLUS`.
¥
ipConfigÀB½:º
·
databasemigrationservice)ConnectionProfileCloudsqlSettingsIpConfigpgcp:databasemigrationservice/ConnectionProfileCloudsqlSettingsIpConfig:ConnectionProfileCloudsqlSettingsIpConfigÕThe settings for IP Management. This allows to enable or disable the instance IP and manage which external networks can connect to the instance. The IPv4 address cannot be disabled.
Structure is documented below.

rootPasswordB" oInput only. Initial root password.
**Note**: This property is sensitive and will not be displayed in the plan.
m
rootPasswordSetB
 T(Output)
Output only. Indicates If this connection profile root password is stored.
µ
sourceId" ¤The Database Migration Service source connection profile ID, in the format: projects/my_project_name/locations/us-central1/connectionProfiles/connection_profile_ID
¬
storageAutoResizeLimitB" The maximum size to which storage capacity can be automatically increased. The default value is 0, which specifies that there is no limit.
í
tierB" ÞThe tier (or machine type) for this instance, for example: db-n1-standard-1 (MySQL instances) or db-custom-1-3840 (PostgreSQL instances).
For more information, see https://cloud.google.com/sql/docs/mysql/instance-settings


userLabelsB2" }The resource labels for a Cloud SQL instance to use to annotate any related underlying resources such as Compute Engine VMs.
`
zoneB" RThe Google Cloud Platform zone where your Cloud SQL datdabse instance is located.
:ó
·
databasemigrationservice)ConnectionProfileCloudsqlSettingsIpConfigpgcp:databasemigrationservice/ConnectionProfileCloudsqlSettingsIpConfig:ConnectionProfileCloudsqlSettingsIpConfig¶
³
authorizedNetworks÷Bô*ñ:î
ë
databasemigrationservice:ConnectionProfileCloudsqlSettingsIpConfigAuthorizedNetworkgcp:databasemigrationservice/ConnectionProfileCloudsqlSettingsIpConfigAuthorizedNetwork:ConnectionProfileCloudsqlSettingsIpConfigAuthorizedNetworkwThe list of external networks that are allowed to connect to the instance using the IP.
Structure is documented below.
T

enableIpv4B
 @Whether the instance should be assigned an IPv4 address or not.
ÿ
privateNetworkB" æThe resource link for the VPC network from which the Cloud SQL instance is accessible for private IP. For example, projects/myProject/global/networks/default.
This setting can be updated, but it cannot be removed after it is set.
O

requireSslB
 ;Whether SSL connections over IP should be enforced or not.
:
ë
databasemigrationservice:ConnectionProfileCloudsqlSettingsIpConfigAuthorizedNetworkgcp:databasemigrationservice/ConnectionProfileCloudsqlSettingsIpConfigAuthorizedNetwork:ConnectionProfileCloudsqlSettingsIpConfigAuthorizedNetwork
X

expireTimeB" DThe time when this access control entry expires in RFC 3339 format.
/
labelB"  A label to identify this entry.
I
ttlB" <Input only. The time-to-leave of this access control entry.
@
value" 3The allowlisted value for the access control list.
:
~
databasemigrationserviceConnectionProfileErrorJgcp:databasemigrationservice/ConnectionProfileError:ConnectionProfileError
Z
codeB L(Output)
The status code, which should be an enum value of google.rpc.Code.
O
detailsB*2" :(Output)
A list of messages that carry the error details.
^
messageB" M(Output)
Human readable message indicating details about the current status.
:Ú	
~
databasemigrationserviceConnectionProfileMysqlJgcp:databasemigrationservice/ConnectionProfileMysql:ConnectionProfileMysql×
Ô~

cloudSqlIdB" jIf the source is a Cloud SQL database, use this field to provide the Cloud SQL instance ID of the source.
?
hostB" 1The IP or hostname of the source MySQL database.
¼
passwordB" ©Input only. The password for the user that Database Migration Service will be using to connect to the database.
This field is not returned on request, and the value is encrypted when stored in Database Migration Service.
**Note**: This property is sensitive and will not be displayed in the plan.
d
passwordSetB
 O(Output)
Output only. Indicates If this connection profile password is stored.
=
portB /The network port of the source MySQL database.

sslB:

databasemigrationserviceConnectionProfileMysqlSslPgcp:databasemigrationservice/ConnectionProfileMysqlSsl:ConnectionProfileMysqlSslhSSL configuration for the destination to connect to the source database.
Structure is documented below.
§
usernameB" The username that Database Migration Service will use to connect to the database. The value is encrypted when stored in Database Migration Service.
:À

databasemigrationserviceConnectionProfileMysqlSslPgcp:databasemigrationservice/ConnectionProfileMysqlSsl:ConnectionProfileMysqlSsl³
°¬
caCertificate" Required. Input only. The x509 PEM-encoded certificate of the CA that signed the source database server's certificate.
The replica will use this certificate to verify it's connecting to the right host.
**Note**: This property is sensitive and will not be displayed in the plan.
¨
clientCertificateB" Input only. The x509 PEM-encoded certificate that will be used by the replica to authenticate against the source database server.
If this field is used then the 'clientKey' field is mandatory
**Note**: This property is sensitive and will not be displayed in the plan.

	clientKeyB" Input only. The unencrypted PKCS#1 or PKCS#8 PEM-encoded private key associated with the Client Certificate.
If this field is used then the 'clientCertificate' field is mandatory.
**Note**: This property is sensitive and will not be displayed in the plan.
=
typeB" /(Output)
The current connection profile state.
:Ø

databasemigrationserviceConnectionProfileOracleLgcp:databasemigrationservice/ConnectionProfileOracle:ConnectionProfileOracleÑ
ÎM
databaseService" 6Required. Database service for the Oracle connection.
Ñ
forwardSshConnectivityÌBÉ:Æ
Ã
databasemigrationservice-ConnectionProfileOracleForwardSshConnectivityxgcp:databasemigrationservice/ConnectionProfileOracleForwardSshConnectivity:ConnectionProfileOracleForwardSshConnectivityhSSL configuration for the destination to connect to the source database.
Structure is documented below.
H
host" <Required. The IP or hostname of the source Oracle database.
Ä
password" ³Required. Input only. The password for the user that Database Migration Service will be using to connect to the database.
This field is not returned on request, and the value is encrypted when stored in Database Migration Service.
**Note**: This property is sensitive and will not be displayed in the plan.
d
passwordSetB
 O(Output)
Output only. Indicates If this connection profile password is stored.
F
port :Required. The network port of the source Oracle database.
Î
privateConnectivityÃBÀ:½
º
databasemigrationservice*ConnectionProfileOraclePrivateConnectivityrgcp:databasemigrationservice/ConnectionProfileOraclePrivateConnectivity:ConnectionProfileOraclePrivateConnectivityqConfiguration for using a private network to communicate with the source database
Structure is documented below.

sslB:

databasemigrationserviceConnectionProfileOracleSslRgcp:databasemigrationservice/ConnectionProfileOracleSsl:ConnectionProfileOracleSslhSSL configuration for the destination to connect to the source database.
Structure is documented below.
Þ
staticServiceIpConnectivityÜBÙ:Ö
Ó
databasemigrationservice2ConnectionProfileOracleStaticServiceIpConnectivitygcp:databasemigrationservice/ConnectionProfileOracleStaticServiceIpConnectivity:ConnectionProfileOracleStaticServiceIpConnectivity`This object has no nested fields.
Static IP address connectivity configured on service project.
¯
username" Required. The username that Database Migration Service will use to connect to the database. The value is encrypted when stored in Database Migration Service.
:ï
Ã
databasemigrationservice-ConnectionProfileOracleForwardSshConnectivityxgcp:databasemigrationservice/ConnectionProfileOracleForwardSshConnectivity:ConnectionProfileOracleForwardSshConnectivity¦
£7
hostname" 'Required. Hostname for the SSH tunnel.
µ
passwordB" ¢Input only. SSH password. Only one of `password` and `private_key` can be configured.
**Note**: This property is sensitive and will not be displayed in the plan.
:
port .Port for the SSH tunnel, default value is 22.
º

privateKeyB" ¥Input only. SSH private key. Only one of `password` and `private_key` can be configured.
**Note**: This property is sensitive and will not be displayed in the plan.
7
username" 'Required. Username for the SSH tunnel.
:
º
databasemigrationservice*ConnectionProfileOraclePrivateConnectivityrgcp:databasemigrationservice/ConnectionProfileOraclePrivateConnectivity:ConnectionProfileOraclePrivateConnectivityZ
XV
privateConnection" =Required. The resource name (URI) of the private connection.
:Ã

databasemigrationserviceConnectionProfileOracleSslRgcp:databasemigrationservice/ConnectionProfileOracleSsl:ConnectionProfileOracleSsl³
°¬
caCertificate" Required. Input only. The x509 PEM-encoded certificate of the CA that signed the source database server's certificate.
The replica will use this certificate to verify it's connecting to the right host.
**Note**: This property is sensitive and will not be displayed in the plan.
¨
clientCertificateB" Input only. The x509 PEM-encoded certificate that will be used by the replica to authenticate against the source database server.
If this field is used then the 'clientKey' field is mandatory
**Note**: This property is sensitive and will not be displayed in the plan.

	clientKeyB" Input only. The unencrypted PKCS#1 or PKCS#8 PEM-encoded private key associated with the Client Certificate.
If this field is used then the 'clientCertificate' field is mandatory.
**Note**: This property is sensitive and will not be displayed in the plan.
=
typeB" /(Output)
The current connection profile state.
:Ú
Ó
databasemigrationservice2ConnectionProfileOracleStaticServiceIpConnectivitygcp:databasemigrationservice/ConnectionProfileOracleStaticServiceIpConnectivity:ConnectionProfileOracleStaticServiceIpConnectivity
 :

databasemigrationserviceConnectionProfilePostgresqlTgcp:databasemigrationservice/ConnectionProfilePostgresql:ConnectionProfilePostgresql
~
alloydbClusterIdB" dIf the connected database is an AlloyDB instance, use this field to provide the AlloyDB cluster ID.
~

cloudSqlIdB" jIf the source is a Cloud SQL database, use this field to provide the Cloud SQL instance ID of the source.
?
hostB" 1The IP or hostname of the source MySQL database.

networkArchitectureB" (Output)
Output only. If the source is a Cloud SQL database, this field indicates the network architecture it's associated with.
¼
passwordB" ©Input only. The password for the user that Database Migration Service will be using to connect to the database.
This field is not returned on request, and the value is encrypted when stored in Database Migration Service.
**Note**: This property is sensitive and will not be displayed in the plan.
d
passwordSetB
 O(Output)
Output only. Indicates If this connection profile password is stored.
=
portB /The network port of the source MySQL database.

sslB:

databasemigrationserviceConnectionProfilePostgresqlSslZgcp:databasemigrationservice/ConnectionProfilePostgresqlSsl:ConnectionProfilePostgresqlSslhSSL configuration for the destination to connect to the source database.
Structure is documented below.
§
usernameB" The username that Database Migration Service will use to connect to the database. The value is encrypted when stored in Database Migration Service.
:Ï

databasemigrationserviceConnectionProfilePostgresqlSslZgcp:databasemigrationservice/ConnectionProfilePostgresqlSsl:ConnectionProfilePostgresqlSsl³
°¬
caCertificate" Required. Input only. The x509 PEM-encoded certificate of the CA that signed the source database server's certificate.
The replica will use this certificate to verify it's connecting to the right host.
**Note**: This property is sensitive and will not be displayed in the plan.
¨
clientCertificateB" Input only. The x509 PEM-encoded certificate that will be used by the replica to authenticate against the source database server.
If this field is used then the 'clientKey' field is mandatory
**Note**: This property is sensitive and will not be displayed in the plan.

	clientKeyB" Input only. The unencrypted PKCS#1 or PKCS#8 PEM-encoded private key associated with the Client Certificate.
If this field is used then the 'clientCertificate' field is mandatory.
**Note**: This property is sensitive and will not be displayed in the plan.
=
typeB" /(Output)
The current connection profile state.
:é
{
databasemigrationserviceMigrationJobDumpFlagsHgcp:databasemigrationservice/MigrationJobDumpFlags:MigrationJobDumpFlagsé
æã
	dumpFlagsB*:

databasemigrationserviceMigrationJobDumpFlagsDumpFlagXgcp:databasemigrationservice/MigrationJobDumpFlagsDumpFlag:MigrationJobDumpFlagsDumpFlag4A list of dump flags
Structure is documented below.
:å

databasemigrationserviceMigrationJobDumpFlagsDumpFlagXgcp:databasemigrationservice/MigrationJobDumpFlagsDumpFlag:MigrationJobDumpFlagsDumpFlagM
K#
nameB" The name of the flag
$
valueB" The vale of the flag
:
o
databasemigrationserviceMigrationJobError@gcp:databasemigrationservice/MigrationJobError:MigrationJobError
Z
codeB L(Output)
The status code, which should be an enum value of google.rpc.Code.
O
detailsB*2" :(Output)
A list of messages that carry the error details.
^
messageB" M(Output)
Human readable message indicating details about the current status.
:

databasemigrationserviceMigrationJobPerformanceConfigXgcp:databasemigrationservice/MigrationJobPerformanceConfig:MigrationJobPerformanceConfigm
ki
dumpParallelLevelB" NInitial dump parallelism level.
Possible values are: `MIN`, `OPTIMAL`, `MAX`.
:Ó
¢
databasemigrationservice"MigrationJobReverseSshConnectivitybgcp:databasemigrationservice/MigrationJobReverseSshConnectivity:MigrationJobReverseSshConnectivity«
¨l
vmB" `The name of the virtual machine (Compute Engine) used as the bastion server
for the SSH tunnel.
l
vmIpB" ^The IP of the virtual machine (Compute Engine) used as the bastion server
for the SSH tunnel.
{
vmPortB kThe forwarding port of the virtual machine (Compute Engine) used as the
bastion server for the SSH tunnel.
M
vpcB" @The name of the VPC to peer with the Cloud SQL private network.
:£

databasemigrationservice MigrationJobStaticIpConnectivity^gcp:databasemigrationservice/MigrationJobStaticIpConnectivity:MigrationJobStaticIpConnectivity
 :
¢
databasemigrationservice"MigrationJobVpcPeeringConnectivitybgcp:databasemigrationservice/MigrationJobVpcPeeringConnectivity:MigrationJobVpcPeeringConnectivityY
WU
vpcB" HThe name of the VPC network to peer with the Cloud SQL private network.
:¤
~
databasemigrationservicePrivateConnectionErrorJgcp:databasemigrationservice/PrivateConnectionError:PrivateConnectionError¡
D
detailsB2" 1A list of messages that carry the error details.
V
messageB" EA message containing more information about the error that occurred.
:ý

databasemigrationservice!PrivateConnectionVpcPeeringConfig`gcp:databasemigrationservice/PrivateConnectionVpcPeeringConfig:PrivateConnectionVpcPeeringConfigØ
Õ>
subnet" 0A free subnet for peering. (CIDR of /29)

- - -

vpcName" Fully qualified name of the VPC that Database Migration Service will peer to.
Format: projects/{project}/global/{networks}/{name}
:Ë
v
datacatalogEntryBigqueryDateShardedSpecIgcp:datacatalog/EntryBigqueryDateShardedSpec:EntryBigqueryDateShardedSpecÐ
ÍÒ
datasetB" À(Output)
The Data Catalog resource name of the dataset entry the current table belongs to, for example,
projects/{project_id}/locations/{location}/entrygroups/{entryGroupId}/entries/{entryId}
5

shardCountB !(Output)
Total number of shards.
¾
tablePrefixB" ¨(Output)
The table name prefix of the shards. The name of any given shard is [tablePrefix]YYYYMMDD,
for example, for shard MyTable20180101, the tablePrefix is MyTable.
:÷
d
datacatalogEntryBigqueryTableSpec=gcp:datacatalog/EntryBigqueryTableSpec:EntryBigqueryTableSpec
9
tableSourceTypeB"  (Output)
The table source type.
¨

tableSpecsB*:

datacatalogEntryBigqueryTableSpecTableSpecOgcp:datacatalog/EntryBigqueryTableSpecTableSpec:EntryBigqueryTableSpecTableSpec(Output)
Spec of a BigQuery table. This field should only be populated if tableSourceType is BIGQUERY_TABLE.
Structure is documented below.
¢
	viewSpecsB*:~
|
datacatalogEntryBigqueryTableSpecViewSpecMgcp:datacatalog/EntryBigqueryTableSpecViewSpec:EntryBigqueryTableSpecViewSpec(Output)
Table view specification. This field should only be populated if tableSourceType is BIGQUERY_VIEW.
Structure is documented below.
:Í

datacatalogEntryBigqueryTableSpecTableSpecOgcp:datacatalog/EntryBigqueryTableSpecTableSpec:EntryBigqueryTableSpecTableSpecÉ
ÆÃ
groupedEntryB" ¬(Output)
If the table is a dated shard, i.e., with name pattern [prefix]YYYYMMDD, groupedEntry is the
Data Catalog resource name of the date sharded grouped entry, for example,
projects/{project_id}/locations/{location}/entrygroups/{entryGroupId}/entries/{entryId}.
Otherwise, groupedEntry is empty.
:Ç
|
datacatalogEntryBigqueryTableSpecViewSpecMgcp:datacatalog/EntryBigqueryTableSpecViewSpec:EntryBigqueryTableSpecViewSpecG
EC
	viewQueryB" 0(Output)
The query that defines the table view.
:
[
datacatalogEntryGcsFilesetSpec7gcp:datacatalog/EntryGcsFilesetSpec:EntryGcsFilesetSpec¢
þ
filePatterns*" çPatterns to identify a set of files in Google Cloud Storage.
See [Cloud Storage documentation](https://cloud.google.com/storage/docs/gsutil/addlhelp/WildcardNames)
for more information. Note that bucket wildcards are currently not supported. Examples of valid filePatterns:
* gs://bucket_name/dir/*: matches all files within bucket_name/dir directory.
* gs://bucket_name/dir/**: matches all files in bucket_name/dir spanning all subdirectories.
* gs://bucket_name/file*: matches files prefixed by file in bucket_name
* gs://bucket_name/??.txt: matches files with two characters followed by .txt in bucket_name
* gs://bucket_name/[aeiou].txt: matches files that contain a single vowel character followed by .txt in bucket_name
* gs://bucket_name/[a-m].txt: matches files that contain a, b, ... or m followed by .txt in bucket_name
* gs://bucket_name/a/*/b: matches all files in bucket_name that match a/*/b pattern, such as a/c/b, a/d/b
* gs://another_bucket/a.txt: matches gs://another_bucket/a.txt

sampleGcsFileSpecsB*:

datacatalog$EntryGcsFilesetSpecSampleGcsFileSpecYgcp:datacatalog/EntryGcsFilesetSpecSampleGcsFileSpec:EntryGcsFilesetSpecSampleGcsFileSpecç(Output)
Sample files contained in this fileset, not all files contained in this fileset are represented here.
Structure is documented below.


<a name="nested_sample_gcs_file_specs"></a>The `sample_gcs_file_specs` block contains:
:ñ

datacatalog$EntryGcsFilesetSpecSampleGcsFileSpecYgcp:datacatalog/EntryGcsFilesetSpecSampleGcsFileSpec:EntryGcsFilesetSpecSampleGcsFileSpec^
\%
filePathB" The full file path
3
	sizeBytesB  The size of the file, in bytes.
:³
y
datacatalogEntryGroupIamBindingConditionKgcp:datacatalog/EntryGroupIamBindingCondition:EntryGroupIamBindingCondition6
4
descriptionB" 

expression" 
title" :°
v
datacatalogEntryGroupIamMemberConditionIgcp:datacatalog/EntryGroupIamMemberCondition:EntryGroupIamMemberCondition6
4
descriptionB" 

expression" 
title" :°
v
datacatalogPolicyTagIamBindingConditionIgcp:datacatalog/PolicyTagIamBindingCondition:PolicyTagIamBindingCondition6
4
descriptionB" 

expression" 
title" :­
s
datacatalogPolicyTagIamMemberConditionGgcp:datacatalog/PolicyTagIamMemberCondition:PolicyTagIamMemberCondition6
4
descriptionB" 

expression" 
title" :¯
:
datacatalogTagField!gcp:datacatalog/TagField:TagFieldð
íF
	boolValueB
 3Holds the value for a tag field with boolean type.
=
displayNameB" ((Output)
The display name of this field
G
doubleValueB 2Holds the value for a tag field with double type.

	enumValueB" Holds the value for a tag field with enum type. This value must be one of the allowed values in the definition of this enum.

- - -
I
	fieldName" 8The identifier for this object. Format specified above.

orderB (Output)
The order of this field with respect to other fields in this tag. For example, a higher value can indicate
a more important field. The value can be negative. Multiple fields can have the same order, and field orders
within a tag do not have to be sequential.
G
stringValueB" 2Holds the value for a tag field with string type.
M
timestampValueB" 5Holds the value for a tag field with timestamp type.
:Ü
R
datacatalogTagTemplateField1gcp:datacatalog/TagTemplateField:TagTemplateField
3
descriptionB" A description for this field.
6
displayNameB" !The display name for this field.
G
fieldId" 8The identifier for this object. Format specified above.
I

isRequiredB
 5Whether this is a required field. Defaults to false.
³
nameB" ¤(Output)
The resource name of the tag template field in URL format. Example: projects/{project_id}/locations/{location}/tagTemplates/{tagTemplateId}/fields/{field}

orderB üThe order of this field with respect to other fields in this tag template.
A higher value indicates a more important field. The value can be negative.
Multiple fields can have the same order, and field orders within a tag do not have to be sequential.
¹
typeb:`
^
datacatalogTagTemplateFieldType9gcp:datacatalog/TagTemplateFieldType:TagTemplateFieldTypeMThe type of value this tag field can contain.
Structure is documented below.
:©
^
datacatalogTagTemplateFieldType9gcp:datacatalog/TagTemplateFieldType:TagTemplateFieldTypeÆ
Ãý
enumType|Bz:x
v
datacatalogTagTemplateFieldTypeEnumTypeIgcp:datacatalog/TagTemplateFieldTypeEnumType:TagTemplateFieldTypeEnumTypesRepresents an enum type.
Exactly one of `primitive_type` or `enum_type` must be set
Structure is documented below.
À
primitiveTypeB" ¨Represents primitive types - string, bool etc.
Exactly one of `primitive_type` or `enum_type` must be set
Possible values are: `DOUBLE`, `STRING`, `BOOL`, `TIMESTAMP`.
:÷
v
datacatalogTagTemplateFieldTypeEnumTypeIgcp:datacatalog/TagTemplateFieldTypeEnumType:TagTemplateFieldTypeEnumTypeü
ùö
allowedValues£* :

datacatalog(TagTemplateFieldTypeEnumTypeAllowedValueagcp:datacatalog/TagTemplateFieldTypeEnumTypeAllowedValue:TagTemplateFieldTypeEnumTypeAllowedValue¾The set of allowed values for this enum. The display names of the
values must be case-insensitively unique within this set. Currently,
enum values can only be added to the list of allowed values. Deletion
and renaming of enum values are not supported.
Can have up to 500 allowed values.
Structure is documented below.
:Ú

datacatalog(TagTemplateFieldTypeEnumTypeAllowedValueagcp:datacatalog/TagTemplateFieldTypeEnumTypeAllowedValue:TagTemplateFieldTypeEnumTypeAllowedValue;
97
displayName" $The display name for this template.
:¶
|
datacatalogTagTemplateIamBindingConditionMgcp:datacatalog/TagTemplateIamBindingCondition:TagTemplateIamBindingCondition6
4
descriptionB" 

expression" 
title" :³
y
datacatalogTagTemplateIamMemberConditionKgcp:datacatalog/TagTemplateIamMemberCondition:TagTemplateIamMemberCondition6
4
descriptionB" 

expression" 
title" :­
s
datacatalogTaxonomyIamBindingConditionGgcp:datacatalog/TaxonomyIamBindingCondition:TaxonomyIamBindingCondition6
4
descriptionB" 

expression" 
title" :ª
p
datacatalogTaxonomyIamMemberConditionEgcp:datacatalog/TaxonomyIamMemberCondition:TaxonomyIamMemberCondition6
4
descriptionB" 

expression" 
title" :Ñ
X
dataflowPipelineScheduleInfo6gcp:dataflow/PipelineScheduleInfo:PipelineScheduleInfoô
ñú
nextJobTimeB" ä(Output)
When the next Scheduler job is going to run.
A timestamp in RFC3339 UTC "Zulu" format, with nanosecond resolution and up to nine fractional digits. Examples: "2014-10-02T15:01:23Z" and "2014-10-02T15:01:23.045123456Z".
s
scheduleB" aUnix-cron format of the schedule. This information is retrieved from the linked Cloud Scheduler.
}
timeZoneB" kTimezone ID. This matches the timezone IDs used by the Cloud Scheduler API. If empty, UTC time is assumed.
:
L
dataflowPipelineWorkload.gcp:dataflow/PipelineWorkload:PipelineWorkload³
°Ñ
dataflowFlexTemplateRequest¦B£: 

dataflow+PipelineWorkloadDataflowFlexTemplateRequestdgcp:dataflow/PipelineWorkloadDataflowFlexTemplateRequest:PipelineWorkloadDataflowFlexTemplateRequestTemplate information and additional parameters needed to launch a Dataflow job using the flex launch API.
https://cloud.google.com/dataflow/docs/reference/data-pipelines/rest/v1/projects.locations.pipelines#launchflextemplaterequest
Structure is documented below.
Ù
dataflowLaunchTemplateRequest¬B©:¦
£
dataflow-PipelineWorkloadDataflowLaunchTemplateRequesthgcp:dataflow/PipelineWorkloadDataflowLaunchTemplateRequest:PipelineWorkloadDataflowLaunchTemplateRequestTemplate information and additional parameters needed to launch a Dataflow job using the standard launch API.
https://cloud.google.com/dataflow/docs/reference/data-pipelines/rest/v1/projects.locations.pipelines#launchtemplaterequest
Structure is documented below.
:

dataflow+PipelineWorkloadDataflowFlexTemplateRequestdgcp:dataflow/PipelineWorkloadDataflowFlexTemplateRequest:PipelineWorkloadDataflowFlexTemplateRequestã
à¸
launchParameterÑ:Î
Ë
dataflow:PipelineWorkloadDataflowFlexTemplateRequestLaunchParametergcp:dataflow/PipelineWorkloadDataflowFlexTemplateRequestLaunchParameter:PipelineWorkloadDataflowFlexTemplateRequestLaunchParameterÐParameter to launch a job from a Flex Template.
https://cloud.google.com/dataflow/docs/reference/data-pipelines/rest/v1/projects.locations.pipelines#launchflextemplateparameter
Structure is documented below.
j
location" ZThe regional endpoint to which to direct the request. For example, us-central1, us-west1.
O
	projectId" >The ID of the Cloud Platform project that the job belongs to.
f
validateOnlyB
 PIf true, the request is validated but not actually executed. Defaults to false.
:é
Ë
dataflow:PipelineWorkloadDataflowFlexTemplateRequestLaunchParametergcp:dataflow/PipelineWorkloadDataflowFlexTemplateRequestLaunchParameter:PipelineWorkloadDataflowFlexTemplateRequestLaunchParameter
l
containerSpecGcsPathB" NCloud Storage path to a file with a JSON-serialized ContainerSpec as content.
Þ
environmentõBò:ï
ì
dataflowEPipelineWorkloadDataflowFlexTemplateRequestLaunchParameterEnvironmentgcp:dataflow/PipelineWorkloadDataflowFlexTemplateRequestLaunchParameterEnvironment:PipelineWorkloadDataflowFlexTemplateRequestLaunchParameterEnvironmentÖThe runtime environment for the Flex Template job.
https://cloud.google.com/dataflow/docs/reference/data-pipelines/rest/v1/projects.locations.pipelines#FlexTemplateRuntimeEnvironment
Structure is documented below.

jobName" The job name to use for the created job. For an update job request, the job name should be the same as the existing running job.
¨
launchOptionsB2" Launch options for this Flex Template job. This is a common set of options across languages and templates. This should not be used to pass job parameters.
'An object containing a list of "key": value pairs. Example: { "name": "wrench", "mass": "1.3kg", "count": "3" }.'
Î

parametersB2" ·'The parameters for the Flex Template. Example: {"numWorkers":"5"}'
'An object containing a list of "key": value pairs. Example: { "name": "wrench", "mass": "1.3kg", "count": "3" }.'

transformNameMappingsB2" î'Use this to pass transform name mappings for streaming update jobs. Example: {"oldTransformName":"newTransformName",...}'
'An object containing a list of "key": value pairs. Example: { "name": "wrench", "mass": "1.3kg", "count": "3" }.'
 
updateB
 Set this to true if you are sending a request to update a running streaming job. When set, the job name should be the same as the running job.
:»
ì
dataflowEPipelineWorkloadDataflowFlexTemplateRequestLaunchParameterEnvironmentgcp:dataflow/PipelineWorkloadDataflowFlexTemplateRequestLaunchParameterEnvironment:PipelineWorkloadDataflowFlexTemplateRequestLaunchParameterEnvironmentÉ
ÆJ
additionalExperimentsB*" )Additional experiment flags for the job.

additionalUserLabelsB2" ñAdditional user labels to be specified for the job. Keys and values should follow the restrictions specified in the labeling restrictions page. An object containing a list of key/value pairs.
'Example: { "name": "wrench", "mass": "1kg", "count": "3" }.'
'An object containing a list of "key": value pairs. Example: { "name": "wrench", "mass": "1.3kg", "count": "3" }.'
O
enableStreamingEngineB
 0Whether to enable Streaming Engine for the job.
Å

flexrsGoalB" °Set FlexRS goal for the job. https://cloud.google.com/dataflow/docs/guides/flexrs
https://cloud.google.com/dataflow/docs/reference/data-pipelines/rest/v1/projects.locations.pipelines#FlexResourceSchedulingGoal
Possible values are: `FLEXRS_UNSPECIFIED`, `FLEXRS_SPEED_OPTIMIZED`, `FLEXRS_COST_OPTIMIZED`.

ipConfigurationB" óConfiguration for VM IPs.
https://cloud.google.com/dataflow/docs/reference/data-pipelines/rest/v1/projects.locations.pipelines#WorkerIPAddressConfiguration
Possible values are: `WORKER_IP_UNSPECIFIED`, `WORKER_IP_PUBLIC`, `WORKER_IP_PRIVATE`.
|

kmsKeyNameB" h'Name for the Cloud KMS key for the job. The key format is: projects//locations//keyRings//cryptoKeys/'
t
machineTypeB" _The machine type to use for the job. Defaults to the value from the template if not specified.


maxWorkersB wThe maximum number of Compute Engine instances to be made available to your pipeline during execution, from 1 to 1000.
}
networkB" lNetwork to which VMs will be assigned. If empty or unspecified, the service will use the network "default".
P

numWorkersB <The initial number of Compute Engine instances for the job.
Y
serviceAccountEmailB" <The email address of the service account to run the job as.


subnetworkB" Subnetwork to which VMs will be assigned, if desired. You can specify a subnetwork using either a complete URL or an abbreviated path. Expected to be of the form "https://www.googleapis.com/compute/v1/projects/HOST_PROJECT_ID/regions/REGION/subnetworks/SUBNETWORK" or "regions/REGION/subnetworks/SUBNETWORK". If the subnetwork is located in a Shared VPC network, you must use the complete URL.

tempLocationB" lThe Cloud Storage path to use for temporary files. Must be a valid Cloud Storage URL, beginning with gs://.
¯
workerRegionB" The Compute Engine region (https://cloud.google.com/compute/docs/regions-zones/regions-zones) in which worker processing should occur, e.g. "us-west1". Mutually exclusive with workerZone. If neither workerRegion nor workerZone is specified, default to the control plane's region.


workerZoneB" The Compute Engine zone (https://cloud.google.com/compute/docs/regions-zones/regions-zones) in which worker processing should occur, e.g. "us-west1-a". Mutually exclusive with workerRegion. If neither workerRegion nor workerZone is specified, a zone in the control plane's region is chosen based on available capacity. If both workerZone and zone are set, workerZone takes precedence.

zoneB" The Compute Engine availability zone for launching worker instances to run your pipeline. In the future, workerZone will take precedence.
:ð
£
dataflow-PipelineWorkloadDataflowLaunchTemplateRequesthgcp:dataflow/PipelineWorkloadDataflowLaunchTemplateRequest:PipelineWorkloadDataflowLaunchTemplateRequestÇ
Ä
gcsPathB" ~A Cloud Storage path to the template from which to create the job. Must be a valid Cloud Storage URL, beginning with 'gs://'.
ñ
launchParametersÝBÚ:×
Ô
dataflow=PipelineWorkloadDataflowLaunchTemplateRequestLaunchParametersgcp:dataflow/PipelineWorkloadDataflowLaunchTemplateRequestLaunchParameters:PipelineWorkloadDataflowLaunchTemplateRequestLaunchParametersüThe parameters of the template to launch. This should be part of the body of the POST request.
https://cloud.google.com/dataflow/docs/reference/data-pipelines/rest/v1/projects.locations.pipelines#launchtemplateparameters
Structure is documented below.
H
locationB" 6The regional endpoint to which to direct the request.
O
	projectId" >The ID of the Cloud Platform project that the job belongs to.
!
validateOnlyB
 (Optional)
:Í

Ô
dataflow=PipelineWorkloadDataflowLaunchTemplateRequestLaunchParametersgcp:dataflow/PipelineWorkloadDataflowLaunchTemplateRequestLaunchParameters:PipelineWorkloadDataflowLaunchTemplateRequestLaunchParametersó
ðÍ
environmentþBû:ø
õ
dataflowHPipelineWorkloadDataflowLaunchTemplateRequestLaunchParametersEnvironmentgcp:dataflow/PipelineWorkloadDataflowLaunchTemplateRequestLaunchParametersEnvironment:PipelineWorkloadDataflowLaunchTemplateRequestLaunchParametersEnvironment¼The runtime environment for the job.
https://cloud.google.com/dataflow/docs/reference/data-pipelines/rest/v1/projects.locations.pipelines#RuntimeEnvironment
Structure is documented below.
8
jobName" )The job name to use for the created job.
µ

parametersB2" The runtime parameters to pass to the job.
'An object containing a list of "key": value pairs. Example: { "name": "wrench", "mass": "1.3kg", "count": "3" }.'
ª
transformNameMappingB2" Map of transform name prefixes of the job to be replaced to the corresponding name prefixes of the new job. Only applicable when updating a pipeline.
'An object containing a list of "key": value pairs. Example: { "name": "wrench", "mass": "1.3kg", "count": "3" }.'

updateB
 oIf set, replace the existing pipeline with the name specified by jobName with this pipeline, preserving state.
:ø
õ
dataflowHPipelineWorkloadDataflowLaunchTemplateRequestLaunchParametersEnvironmentgcp:dataflow/PipelineWorkloadDataflowLaunchTemplateRequestLaunchParametersEnvironment:PipelineWorkloadDataflowLaunchTemplateRequestLaunchParametersEnvironmentý
úJ
additionalExperimentsB*" )Additional experiment flags for the job.

additionalUserLabelsB2" ñAdditional user labels to be specified for the job. Keys and values should follow the restrictions specified in the labeling restrictions page. An object containing a list of key/value pairs.
'Example: { "name": "wrench", "mass": "1kg", "count": "3" }.'
'An object containing a list of "key": value pairs. Example: { "name": "wrench", "mass": "1.3kg", "count": "3" }.'
z
bypassTempDirValidationB
 YWhether to bypass the safety checks for the job's temporary directory. Use with caution.
O
enableStreamingEngineB
 0Whether to enable Streaming Engine for the job.

ipConfigurationB" óConfiguration for VM IPs.
https://cloud.google.com/dataflow/docs/reference/data-pipelines/rest/v1/projects.locations.pipelines#WorkerIPAddressConfiguration
Possible values are: `WORKER_IP_UNSPECIFIED`, `WORKER_IP_PUBLIC`, `WORKER_IP_PRIVATE`.
|

kmsKeyNameB" h'Name for the Cloud KMS key for the job. The key format is: projects//locations//keyRings//cryptoKeys/'
t
machineTypeB" _The machine type to use for the job. Defaults to the value from the template if not specified.


maxWorkersB wThe maximum number of Compute Engine instances to be made available to your pipeline during execution, from 1 to 1000.
}
networkB" lNetwork to which VMs will be assigned. If empty or unspecified, the service will use the network "default".
P

numWorkersB <The initial number of Compute Engine instances for the job.
Y
serviceAccountEmailB" <The email address of the service account to run the job as.


subnetworkB" Subnetwork to which VMs will be assigned, if desired. You can specify a subnetwork using either a complete URL or an abbreviated path. Expected to be of the form "https://www.googleapis.com/compute/v1/projects/HOST_PROJECT_ID/regions/REGION/subnetworks/SUBNETWORK" or "regions/REGION/subnetworks/SUBNETWORK". If the subnetwork is located in a Shared VPC network, you must use the complete URL.

tempLocationB" lThe Cloud Storage path to use for temporary files. Must be a valid Cloud Storage URL, beginning with gs://.
¯
workerRegionB" The Compute Engine region (https://cloud.google.com/compute/docs/regions-zones/regions-zones) in which worker processing should occur, e.g. "us-west1". Mutually exclusive with workerZone. If neither workerRegion nor workerZone is specified, default to the control plane's region.


workerZoneB" The Compute Engine zone (https://cloud.google.com/compute/docs/regions-zones/regions-zones) in which worker processing should occur, e.g. "us-west1-a". Mutually exclusive with workerRegion. If neither workerRegion nor workerZone is specified, a zone in the control plane's region is chosen based on available capacity. If both workerZone and zone are set, workerZone takes precedence.

zoneB" The Compute Engine availability zone for launching worker instances to run your pipeline. In the future, workerZone will take precedence.
:ß
m
dataformRepositoryGitRemoteSettingsDgcp:dataform/RepositoryGitRemoteSettings:RepositoryGitRemoteSettingsí
ê
 authenticationTokenSecretVersionB" òThe name of the Secret Manager secret version to use as an authentication token for Git operations. This secret is for assigning with HTTPS only(for SSH use `ssh_authentication_config`). Must be in the format projects/*/secrets/*/versions/*.
;
defaultBranch" &The Git remote's default branch name.
²
sshAuthenticationConfig»B¸:µ
²
dataform2RepositoryGitRemoteSettingsSshAuthenticationConfigrgcp:dataform/RepositoryGitRemoteSettingsSshAuthenticationConfig:RepositoryGitRemoteSettingsSshAuthenticationConfigYAuthentication fields for remote uris using SSH protocol.
Structure is documented below.
²
tokenStatusB" (Output)
Indicates the status of the Git access token. https://cloud.google.com/dataform/reference/rest/v1beta1/projects.locations.repositories#TokenStatus
!
url" The Git remote's URL.
:Ö
²
dataform2RepositoryGitRemoteSettingsSshAuthenticationConfigrgcp:dataform/RepositoryGitRemoteSettingsSshAuthenticationConfig:RepositoryGitRemoteSettingsSshAuthenticationConfig
]
hostPublicKey" HContent of a public SSH key to verify an identity of a remote Git host.
¹
userPrivateKeySecretVersion" The name of the Secret Manager secret version to use as a ssh private key for Git operations. Must be in the format projects/*/secrets/*/versions/*.
:­
s
dataformRepositoryIamBindingConditionHgcp:dataform/RepositoryIamBindingCondition:RepositoryIamBindingCondition6
4
descriptionB" 

expression" 
title" :ª
p
dataformRepositoryIamMemberConditionFgcp:dataform/RepositoryIamMemberCondition:RepositoryIamMemberCondition6
4
descriptionB" 

expression" 
title" :	
 
dataform,RepositoryReleaseConfigCodeCompilationConfigfgcp:dataform/RepositoryReleaseConfigCodeCompilationConfig:RepositoryReleaseConfigCodeCompilationConfigë
è\
assertionSchemaB" COptional. The default schema (BigQuery dataset ID) for assertions.
v
databaseSuffixB" ^Optional. The suffix that should be appended to all database (Google Cloud project ID) names.
S
defaultDatabaseB" :Optional. The default database (Google Cloud project ID).
Â
defaultLocationB" ¨Optional. The default BigQuery location to use. Defaults to "US".
See the BigQuery docs for a full list of locations: https://cloud.google.com/bigquery/docs/locations.
K
defaultSchemaB" 4Optional. The default schema (BigQuery dataset ID).
n
schemaSuffixB" XOptional. The suffix that should be appended to all schema (BigQuery dataset ID) names.
W
tablePrefixB" BOptional. The prefix that should be prepended to all table names.
ß
varsB2" ÎOptional. User-defined variables that are made available to project code during compilation.
An object containing a list of "key": value pairs.
Example: { "name": "wrench", "mass": "1.3kg", "count": "3" }.
:á
µ
dataform3RepositoryReleaseConfigRecentScheduledReleaseRecordtgcp:dataform/RepositoryReleaseConfigRecentScheduledReleaseRecord:RepositoryReleaseConfigRecentScheduledReleaseRecord¦
£Ä
compilationResultB" ¨(Output)
The name of the created compilation result, if one was successfully created. Must be in the format projects/*/locations/*/repositories/*/compilationResults/*.

errorStatusesãBà*Ý:Ú
×
dataform>RepositoryReleaseConfigRecentScheduledReleaseRecordErrorStatusgcp:dataform/RepositoryReleaseConfigRecentScheduledReleaseRecordErrorStatus:RepositoryReleaseConfigRecentScheduledReleaseRecordErrorStatus(Output)
The error status encountered upon this attempt to create the compilation result, if the attempt was unsuccessful.
Structure is documented below.
E
releaseTimeB" 0(Output)
The timestamp of this release attempt.
:
×
dataform>RepositoryReleaseConfigRecentScheduledReleaseRecordErrorStatusgcp:dataform/RepositoryReleaseConfigRecentScheduledReleaseRecordErrorStatus:RepositoryReleaseConfigRecentScheduledReleaseRecordErrorStatusº
·Z
codeB L(Output)
The status code, which should be an enum value of google.rpc.Code.
Ø
messageB" Æ(Output)
A developer-facing error message, which should be in English. Any user-facing error message should be localized and sent in the google.rpc.Status.details field, or localized by the client.
:ï

dataform(RepositoryWorkflowConfigInvocationConfig^gcp:dataform/RepositoryWorkflowConfigInvocationConfig:RepositoryWorkflowConfigInvocationConfigÕ
Òz
$fullyRefreshIncrementalTablesEnabledB
 LOptional. When set to true, any incremental tables will be fully refreshed.
>
includedTagsB*" &Optional. The set of tags to include.
³
includedTargetsÊBÇ*Ä:Á
¾
dataform6RepositoryWorkflowConfigInvocationConfigIncludedTargetzgcp:dataform/RepositoryWorkflowConfigInvocationConfigIncludedTarget:RepositoryWorkflowConfigInvocationConfigIncludedTargetSOptional. The set of action identifiers to include.
Structure is documented below.
Y
serviceAccountB" AOptional. The service account to run workflow invocations under.

transitiveDependenciesIncludedB
 ZOptional. When set to true, transitive dependencies of included actions will be executed.
~
transitiveDependentsIncludedB
 XOptional. When set to true, transitive dependents of included actions will be executed.
:
¾
dataform6RepositoryWorkflowConfigInvocationConfigIncludedTargetzgcp:dataform/RepositoryWorkflowConfigInvocationConfigIncludedTarget:RepositoryWorkflowConfigInvocationConfigIncludedTargetÕ
ÒC
databaseB" 1The action's database (Google Cloud project ID).
=
nameB" /The action's name, within database and schema.
L
schemaB" <The action's schema (BigQuery dataset ID), within database.
:ò
¾
dataform6RepositoryWorkflowConfigRecentScheduledExecutionRecordzgcp:dataform/RepositoryWorkflowConfigRecentScheduledExecutionRecord:RepositoryWorkflowConfigRecentScheduledExecutionRecord®
«
errorStatusesìBé*æ:ã
à
dataformARepositoryWorkflowConfigRecentScheduledExecutionRecordErrorStatusgcp:dataform/RepositoryWorkflowConfigRecentScheduledExecutionRecordErrorStatus:RepositoryWorkflowConfigRecentScheduledExecutionRecordErrorStatus(Output)
The error status encountered upon this attempt to create the workflow invocation, if the attempt was unsuccessful.
Structure is documented below.
H
executionTimeB" 1(Output)
The timestamp of this workflow attempt.
¿
workflowInvocationB" ¢(Output)
The name of the created workflow invocation, if one was successfully created. In the format projects/*/locations/*/repositories/*/workflowInvocations/*.
: 
à
dataformARepositoryWorkflowConfigRecentScheduledExecutionRecordErrorStatusgcp:dataform/RepositoryWorkflowConfigRecentScheduledExecutionRecordErrorStatus:RepositoryWorkflowConfigRecentScheduledExecutionRecordErrorStatusº
·Z
codeB L(Output)
The status code, which should be an enum value of google.rpc.Code.
Ø
messageB" Æ(Output)
A developer-facing error message, which should be in English. Any user-facing error message should be localized and sent in the google.rpc.Status.details field, or localized by the client.
:

dataform'RepositoryWorkspaceCompilationOverrides\gcp:dataform/RepositoryWorkspaceCompilationOverrides:RepositoryWorkspaceCompilationOverrides
I
defaultDatabaseB" 0The default database (Google Cloud project ID).
d
schemaSuffixB" NThe suffix that should be appended to all schema (BigQuery dataset ID) names.
M
tablePrefixB" 8The prefix that should be prepended to all table names.
:Ê
Y

datafusionInstanceAccelerator6gcp:datafusion/InstanceAccelerator:InstanceAcceleratorì
é
acceleratorType" hThe type of an accelator for a CDF instance.
Possible values are: `CDC`, `HEALTHCARE`, `CCAI_INSIGHTS`.
f
state" YThe type of an accelator for a CDF instance.
Possible values are: `ENABLED`, `DISABLED`.
:²
e

datafusionInstanceCryptoKeyConfig>gcp:datafusion/InstanceCryptoKeyConfig:InstanceCryptoKeyConfigÈ
ÅÂ
keyReference" ­The name of the key which is used to encrypt/decrypt customer data. For key in Cloud KMS, the key should be in the format of projects/*/locations/*/keyRings/*/cryptoKeys/*.
:
n

datafusionInstanceEventPublishConfigDgcp:datafusion/InstanceEventPublishConfig:InstanceEventPublishConfig
2
enabled
 #Option to enable Event Publishing.
d
topic" WThe resource name of the Pub/Sub topic. Format: projects/{projectId}/topics/{topic_id}
:Û

_

datafusionInstanceNetworkConfig:gcp:datafusion/InstanceNetworkConfig:InstanceNetworkConfig÷	
ô	û
connectionTypeB" âOptional. Type of connection for establishing private IP connectivity between the Data Fusion customer project VPC and
the corresponding tenant project from a predefined list of available connection modes.
If this field is unspecified for a private instance, VPC peering is used.
Possible values are: `VPC_PEERING`, `PRIVATE_SERVICE_CONNECT_INTERFACES`.
Ä
ipAllocationB" ­The IP range in CIDR notation to use for the managed Data Fusion instance
nodes. This range must not overlap with any other ranges used in the Data Fusion instance network.
¤
networkB" Name of the network in the project with which the tenant project
will be peered for executing pipelines. In case of shared VPC where the network resides in another host
project the network should specified in the form of projects/{host-project-id}/global/networks/{network}

privateServiceConnectConfig¹B¶:³
°

datafusion0InstanceNetworkConfigPrivateServiceConnectConfigpgcp:datafusion/InstanceNetworkConfigPrivateServiceConnectConfig:InstanceNetworkConfigPrivateServiceConnectConfig©Optional. Configuration for Private Service Connect.
This is required only when using connection type PRIVATE_SERVICE_CONNECT_INTERFACES.
Structure is documented below.
:«

°

datafusion0InstanceNetworkConfigPrivateServiceConnectConfigpgcp:datafusion/InstanceNetworkConfigPrivateServiceConnectConfig:InstanceNetworkConfigPrivateServiceConnectConfigõ
òì
effectiveUnreachableCidrBlockB" Ä(Output)
Output only. The CIDR block to which the CDF instance can't route traffic to in the consumer project VPC.
The size of this block is /25. The format of this field is governed by RFC 4632.
µ
networkAttachmentB" Optional. The reference to the network attachment used to establish private connectivity.
It will be of the form projects/{project-id}/regions/{region}/networkAttachments/{network-attachment-id}.
This is required only when using connection type PRIVATE_SERVICE_CONNECT_INTERFACES.
È
unreachableCidrBlockB" ©Optional. Input only. The CIDR block to which the CDF instance can't route traffic to in the consumer project VPC.
The size of this block should be at least /25. This range should not overlap with the primary address range of any subnetwork used by the network attachment.
This range can be used for other purposes in the consumer VPC as long as there is no requirement for CDF to reach destinations using these addresses.
If this value is not provided, the server chooses a non RFC 1918 address range. The format of this field is governed by RFC 4632.
:È

 
dataloss,PreventionDeidentifyTemplateDeidentifyConfigfgcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfig:PreventionDeidentifyTemplateDeidentifyConfig¢	
	Ê
imageTransformationsæBã:à
Ý
dataloss@PreventionDeidentifyTemplateDeidentifyConfigImageTransformationsgcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigImageTransformations:PreventionDeidentifyTemplateDeidentifyConfigImageTransformationsITreat the dataset as an image and redact.
Structure is documented below.

infoTypeTransformationsïBì:é
æ
datalossCPreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsgcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformations:PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationszTreat the dataset as free-form text and apply the same free text transformation everywhere
Structure is documented below.
Å
recordTransformationséBæ:ã
à
datalossAPreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsgcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigRecordTransformations:PreventionDeidentifyTemplateDeidentifyConfigRecordTransformations¿Treat the dataset as structured. Transformations can be applied to specific locations within structured datasets, such as transforming a column within a table.
Structure is documented below.
:Õ
Ý
dataloss@PreventionDeidentifyTemplateDeidentifyConfigImageTransformationsgcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigImageTransformations:PreventionDeidentifyTemplateDeidentifyConfigImageTransformationsò
ïì

transforms*þ:û
ø
datalossIPreventionDeidentifyTemplateDeidentifyConfigImageTransformationsTransform gcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigImageTransformationsTransform:PreventionDeidentifyTemplateDeidentifyConfigImageTransformationsTransformZFor determination of how redaction of images should occur.
Structure is documented below.
:è
ø
datalossIPreventionDeidentifyTemplateDeidentifyConfigImageTransformationsTransform gcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigImageTransformationsTransform:PreventionDeidentifyTemplateDeidentifyConfigImageTransformationsTransformê
ç
allInfoTypes¥B¢:

datalossUPreventionDeidentifyTemplateDeidentifyConfigImageTransformationsTransformAllInfoTypes¸gcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigImageTransformationsTransformAllInfoTypes:PreventionDeidentifyTemplateDeidentifyConfigImageTransformationsTransformAllInfoTypeseApply transformation to all findings not specified in other ImageTransformation's selectedInfoTypes.
å
allTextB:

datalossPPreventionDeidentifyTemplateDeidentifyConfigImageTransformationsTransformAllText®gcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigImageTransformationsTransformAllText:PreventionDeidentifyTemplateDeidentifyConfigImageTransformationsTransformAllTextAApply transformation to all text that doesn't match an infoType.
¾
redactionColor«B¨:¥
¢
datalossWPreventionDeidentifyTemplateDeidentifyConfigImageTransformationsTransformRedactionColor¼gcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigImageTransformationsTransformRedactionColor:PreventionDeidentifyTemplateDeidentifyConfigImageTransformationsTransformRedactionColor~The color to use when redacting content from an image. If not specified, the default is black.
Structure is documented below.

selectedInfoTypes´B±:®
«
datalossZPreventionDeidentifyTemplateDeidentifyConfigImageTransformationsTransformSelectedInfoTypesÂgcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigImageTransformationsTransformSelectedInfoTypes:PreventionDeidentifyTemplateDeidentifyConfigImageTransformationsTransformSelectedInfoTypesOApply transformation to the selected infoTypes.
Structure is documented below.
:£

datalossUPreventionDeidentifyTemplateDeidentifyConfigImageTransformationsTransformAllInfoTypes¸gcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigImageTransformationsTransformAllInfoTypes:PreventionDeidentifyTemplateDeidentifyConfigImageTransformationsTransformAllInfoTypes
 :

datalossPPreventionDeidentifyTemplateDeidentifyConfigImageTransformationsTransformAllText®gcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigImageTransformationsTransformAllText:PreventionDeidentifyTemplateDeidentifyConfigImageTransformationsTransformAllText
 :¤
¢
datalossWPreventionDeidentifyTemplateDeidentifyConfigImageTransformationsTransformRedactionColor¼gcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigImageTransformationsTransformRedactionColor:PreventionDeidentifyTemplateDeidentifyConfigImageTransformationsTransformRedactionColorü
ùQ
blueB CThe amount of blue in the color as a value in the interval [0, 1].
S
greenB DThe amount of green in the color as a value in the interval [0, 1].
O
redB BThe amount of red in the color as a value in the interval [0, 1].
:ê
«
datalossZPreventionDeidentifyTemplateDeidentifyConfigImageTransformationsTransformSelectedInfoTypesÂgcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigImageTransformationsTransformSelectedInfoTypes:PreventionDeidentifyTemplateDeidentifyConfigImageTransformationsTransformSelectedInfoTypes¹
¶³
	infoTypesÌ*É:Æ
Ã
datalossbPreventionDeidentifyTemplateDeidentifyConfigImageTransformationsTransformSelectedInfoTypesInfoTypeÒgcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigImageTransformationsTransformSelectedInfoTypesInfoType:PreventionDeidentifyTemplateDeidentifyConfigImageTransformationsTransformSelectedInfoTypesInfoTypeÖInfoTypes to apply the transformation to. Leaving this empty will apply the transformation to apply to
all findings that correspond to infoTypes that were requested in InspectConfig.
Structure is documented below.
:´
Ã
datalossbPreventionDeidentifyTemplateDeidentifyConfigImageTransformationsTransformSelectedInfoTypesInfoTypeÒgcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigImageTransformationsTransformSelectedInfoTypesInfoType:PreventionDeidentifyTemplateDeidentifyConfigImageTransformationsTransformSelectedInfoTypesInfoTypeë
è*
name" Name of the information type.

sensitivityScoreüBù:ö
ó
datalossrPreventionDeidentifyTemplateDeidentifyConfigImageTransformationsTransformSelectedInfoTypesInfoTypeSensitivityScoreògcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigImageTransformationsTransformSelectedInfoTypesInfoTypeSensitivityScore:PreventionDeidentifyTemplateDeidentifyConfigImageTransformationsTransformSelectedInfoTypesInfoTypeSensitivityScoresOptional custom sensitivity for this InfoType. This only applies to data profiling.
Structure is documented below.
1
versionB"  Version name for this InfoType.
:
ó
datalossrPreventionDeidentifyTemplateDeidentifyConfigImageTransformationsTransformSelectedInfoTypesInfoTypeSensitivityScoreògcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigImageTransformationsTransformSelectedInfoTypesInfoTypeSensitivityScore:PreventionDeidentifyTemplateDeidentifyConfigImageTransformationsTransformSelectedInfoTypesInfoTypeSensitivityScore

score" The sensitivity score applied to the resource.
Possible values are: `SENSITIVITY_LOW`, `SENSITIVITY_MODERATE`, `SENSITIVITY_HIGH`.
:
æ
datalossCPreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsgcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformations:PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformations©
¦£
transformations*:

datalossQPreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformation°gcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformation:PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationtTransformation for each infoType. Cannot specify more than one for a given infoType.
Structure is documented below.
:ó


datalossQPreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformation°gcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformation:PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationÝ
Ú
	infoTypes´B±*®:«
¨
datalossYPreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationInfoTypeÀgcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationInfoType:PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationInfoTypeÖInfoTypes to apply the transformation to. Leaving this empty will apply the transformation to apply to
all findings that correspond to infoTypes that were requested in InspectConfig.
Structure is documented below.
¹
primitiveTransformationÛ:Ø
Õ
datalosshPreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationÞgcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformation:PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformation¿Apply the transformation to the entire field.
The `primitive_transformation` block must only contain one argument, corresponding to the type of transformation.
Structure is documented below.
:þ
¨
datalossYPreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationInfoTypeÀgcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationInfoType:PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationInfoTypeÐ
Í*
name" Name of the information type.
ë
sensitivityScoreáBÞ:Û
Ø
datalossiPreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationInfoTypeSensitivityScoreàgcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationInfoTypeSensitivityScore:PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationInfoTypeSensitivityScoresOptional custom sensitivity for this InfoType. This only applies to data profiling.
Structure is documented below.
1
versionB"  Version name for this InfoType.
:õ
Ø
datalossiPreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationInfoTypeSensitivityScoreàgcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationInfoTypeSensitivityScore:PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationInfoTypeSensitivityScore

score" The sensitivity score applied to the resource.
Possible values are: `SENSITIVITY_LOW`, `SENSITIVITY_MODERATE`, `SENSITIVITY_HIGH`.
:H
Õ
datalosshPreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationÞgcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformation:PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformation¶E
³EÚ
bucketingConfigB:

datalosswPreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationBucketingConfigügcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationBucketingConfig:PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationBucketingConfig¸Generalization function that buckets values based on ranges. The ranges and replacement values are dynamically provided by the user for custom behavior, such as 1-30 > LOW 31-65 > MEDIUM 66-100 > HIGH
This can be used on data of type: number, long, string, timestamp.
If the provided value type differs from the type of data being transformed, we will first attempt converting the type of the data to be transformed to match the type of the bound before comparing.
See https://cloud.google.com/dlp/docs/concepts-bucketing to learn more.
Structure is documented below.
Ñ
characterMaskConfigB:

dataloss{PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationCharacterMaskConfiggcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationCharacterMaskConfig:PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationCharacterMaskConfigPartially mask a string by replacing a given number of characters with a fixed character. Masking can start from the beginning or end of the string. This can be used on data of any type (numbers, longs, and so on) and when de-identifying structured data we'll attempt to preserve the original data's type. (This allows you to take a long like 123 and modify it to a string like **3).
Structure is documented below.
ê
cryptoDeterministicConfigªB§:¤
¡
datalossPreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationCryptoDeterministicConfiggcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationCryptoDeterministicConfig:PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationCryptoDeterministicConfigPseudonymization method that generates deterministic encryption for the given input. Outputs a base64 encoded representation of the encrypted output. Uses AES-SIV based on the RFC [https://tools.ietf.org/html/rfc5297](https://tools.ietf.org/html/rfc5297).
Structure is documented below.
Å
cryptoHashConfigB:

datalossxPreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationCryptoHashConfigþgcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationCryptoHashConfig:PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationCryptoHashConfigPseudonymization method that generates surrogates via cryptographic hashing. Uses SHA-256. The key size must be either 32 or 64 bytes.
Outputs a base64 encoded representation of the hashed output (for example, L7k0BHmF1ha5U3NfGykjro4xWi1MPVQPjhMAZbSV9mM=).
Currently, only string and integer values can be hashed.
See https://cloud.google.com/dlp/docs/pseudonymization to learn more.
Structure is documented below.
¡

cryptoReplaceFfxFpeConfigªB§:¤
¡
datalossPreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationCryptoReplaceFfxFpeConfiggcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationCryptoReplaceFfxFpeConfig:PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationCryptoReplaceFfxFpeConfigÖReplaces an identifier with a surrogate using Format Preserving Encryption (FPE) with the FFX mode of operation; however when used in the `content.reidentify` API method, it serves the opposite function by reversing the surrogate back into the original identifier. The identifier must be encoded as ASCII. For a given crypto key and context, the same identifier will be replaced with the same surrogate. Identifiers must be at least two characters long. In the case that the identifier is the empty string, it will be skipped. See [https://cloud.google.com/dlp/docs/pseudonymization](https://cloud.google.com/dlp/docs/pseudonymization) to learn more.
Note: We recommend using CryptoDeterministicConfig for all use cases which do not require preserving the input alphabet space and size, plus warrant referential integrity.
Structure is documented below.
ç
dateShiftConfigB:

datalosswPreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationDateShiftConfigügcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationDateShiftConfig:PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationDateShiftConfigÅShifts dates by random number of days, with option to be consistent for the same context. See https://cloud.google.com/dlp/docs/concepts-date-shifting to learn more.
Structure is documented below.
Ö	
fixedSizeBucketingConfig§B¤:¡

datalossPreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationFixedSizeBucketingConfiggcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationFixedSizeBucketingConfig:PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationFixedSizeBucketingConfigBuckets values based on fixed size ranges. The Bucketing transformation can provide all of this functionality, but requires more configuration. This message is provided as a convenience to the user for simple bucketing strategies.
The transformed value will be a hyphenated string of {lower_bound}-{upper_bound}. For example, if lower_bound = 10 and upper_bound = 20, all values that are within this bucket will be replaced with "10-20".
This can be used on data of type: double, long.
If the bound Value type differs from the type of data being transformed, we will first attempt converting the type of the data to be transformed to match the type of the bound before comparing.
See https://cloud.google.com/dlp/docs/concepts-bucketing to learn more.
Structure is documented below.
Ó
redactConfigBÿ:ü
ù
datalosstPreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationRedactConfigögcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationRedactConfig:PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationRedactConfig½Redact a given value. For example, if used with an InfoTypeTransformation transforming PHONE_NUMBER, and input 'My phone number is 206-555-0123', the output would be 'My phone number is '.
å
replaceConfigB:ÿ
ü
datalossuPreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationReplaceConfigøgcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationReplaceConfig:PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationReplaceConfigLReplace each input value with a given value.
Structure is documented below.
ª
replaceDictionaryConfig£B :

datalossPreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationReplaceDictionaryConfiggcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationReplaceDictionaryConfig:PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationReplaceDictionaryConfigiReplace with a value randomly drawn (with replacement) from a dictionary.
Structure is documented below.
a
replaceWithInfoTypeConfigB
 >Replace each matching finding with the name of the info type.

timePartConfigB:
ÿ
datalossvPreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationTimePartConfigúgcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationTimePartConfig:PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationTimePartConfigxFor use with Date, Timestamp, and TimeOfDay, extract or preserve a portion of the value.
Structure is documented below.
:Í

datalosswPreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationBucketingConfigügcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationBucketingConfig:PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationBucketingConfigÅ
Â¿
buckets B*:

dataloss}PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationBucketingConfigBucketgcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationBucketingConfigBucket:PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationBucketingConfigBucketSet of buckets. Ranges must be non-overlapping.
Bucket is represented as a range, along with replacement values.
Structure is documented below.
:Î

dataloss}PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationBucketingConfigBucketgcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationBucketingConfigBucket:PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationBucketingConfigBucket´
±
max§B¤:¡

datalossPreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationBucketingConfigBucketMaxgcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationBucketingConfigBucketMax:PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationBucketingConfigBucketMaxçUpper bound of the range, exclusive; type must match min.
The `max` block must only contain one argument. See the `bucketing_config` block description for more information about choosing a data type.
Structure is documented below.
¬
min§B¤:¡

datalossPreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationBucketingConfigBucketMingcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationBucketingConfigBucketMin:PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationBucketingConfigBucketMinúLower bound of the range, inclusive. Type should be the same as max if used.
The `min` block must only contain one argument. See the `bucketing_config` block description for more information about choosing a data type.
Structure is documented below.
ã
replacementValueË:È
Å
datalossPreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationBucketingConfigBucketReplacementValue¨gcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationBucketingConfigBucketReplacementValue:PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationBucketingConfigBucketReplacementValueReplacement value for this bucket.
The `replacement_value` block must only contain one argument.
Structure is documented below.
:Á

datalossPreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationBucketingConfigBucketMaxgcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationBucketingConfigBucketMax:PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationBucketingConfigBucketMax

	dateValueÂB¿:¼
¹
datalossPreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationBucketingConfigBucketMaxDateValue gcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationBucketingConfigBucketMaxDateValue:PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationBucketingConfigBucketMaxDateValueLRepresents a whole or partial calendar date.
Structure is documented below.

dayOfWeekValueB" Represents a day of the week.
Possible values are: `MONDAY`, `TUESDAY`, `WEDNESDAY`, `THURSDAY`, `FRIDAY`, `SATURDAY`, `SUNDAY`.
#

floatValueB A float value.
6
integerValueB"  An integer value (int64 format)
%
stringValueB" A string value.

	timeValueÂB¿:¼
¹
datalossPreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationBucketingConfigBucketMaxTimeValue gcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationBucketingConfigBucketMaxTimeValue:PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationBucketingConfigBucketMaxTimeValue9Represents a time of day.
Structure is documented below.
Ç
timestampValueB" ®A timestamp in RFC3339 UTC "Zulu" format, with nanosecond resolution and up to nine fractional digits. Examples: "2014-10-02T15:01:23Z" and "2014-10-02T15:01:23.045123456Z".
:À
¹
datalossPreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationBucketingConfigBucketMaxDateValue gcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationBucketingConfigBucketMaxDateValue:PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationBucketingConfigBucketMaxDateValue
þ²
dayB ¤Day of a month. Must be from 1 to 31 and valid for the year and month, or 0 to specify a year by itself or a year and month where the day isn't significant.

- - -
f
monthB WMonth of a year. Must be from 1 to 12, or 0 to specify a year without a month and day.
_
yearB QYear of the date. Must be from 1 to 9999, or 0 to specify a date without a year.
:
¹
datalossPreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationBucketingConfigBucketMaxTimeValue gcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationBucketingConfigBucketMaxTimeValue:PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationBucketingConfigBucketMaxTimeValueÊ
Ç¢
hoursB Hours of day in 24 hour format. Should be from 0 to 23. An API may choose to allow the value "24:00:00" for scenarios like business closing time.
?
minutesB .Minutes of hour of day. Must be from 0 to 59.
S
nanosB DFractions of seconds in nanoseconds. Must be from 0 to 999,999,999.

secondsB xSeconds of minutes of the time. Must normally be from 0 to 59. An API may allow the value 60 if it allows leap-seconds.
:Á

datalossPreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationBucketingConfigBucketMingcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationBucketingConfigBucketMin:PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationBucketingConfigBucketMin

	dateValueÂB¿:¼
¹
datalossPreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationBucketingConfigBucketMinDateValue gcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationBucketingConfigBucketMinDateValue:PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationBucketingConfigBucketMinDateValueLRepresents a whole or partial calendar date.
Structure is documented below.

dayOfWeekValueB" Represents a day of the week.
Possible values are: `MONDAY`, `TUESDAY`, `WEDNESDAY`, `THURSDAY`, `FRIDAY`, `SATURDAY`, `SUNDAY`.
#

floatValueB A float value.
6
integerValueB"  An integer value (int64 format)
%
stringValueB" A string value.

	timeValueÂB¿:¼
¹
datalossPreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationBucketingConfigBucketMinTimeValue gcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationBucketingConfigBucketMinTimeValue:PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationBucketingConfigBucketMinTimeValue9Represents a time of day.
Structure is documented below.
Ç
timestampValueB" ®A timestamp in RFC3339 UTC "Zulu" format, with nanosecond resolution and up to nine fractional digits. Examples: "2014-10-02T15:01:23Z" and "2014-10-02T15:01:23.045123456Z".
:À
¹
datalossPreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationBucketingConfigBucketMinDateValue gcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationBucketingConfigBucketMinDateValue:PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationBucketingConfigBucketMinDateValue
þ²
dayB ¤Day of a month. Must be from 1 to 31 and valid for the year and month, or 0 to specify a year by itself or a year and month where the day isn't significant.

- - -
f
monthB WMonth of a year. Must be from 1 to 12, or 0 to specify a year without a month and day.
_
yearB QYear of the date. Must be from 1 to 9999, or 0 to specify a date without a year.
:
¹
datalossPreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationBucketingConfigBucketMinTimeValue gcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationBucketingConfigBucketMinTimeValue:PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationBucketingConfigBucketMinTimeValueÊ
Ç¢
hoursB Hours of day in 24 hour format. Should be from 0 to 23. An API may choose to allow the value "24:00:00" for scenarios like business closing time.
?
minutesB .Minutes of hour of day. Must be from 0 to 59.
S
nanosB DFractions of seconds in nanoseconds. Must be from 0 to 999,999,999.

secondsB xSeconds of minutes of the time. Must normally be from 0 to 59. An API may allow the value 60 if it allows leap-seconds.
:¶
Å
datalossPreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationBucketingConfigBucketReplacementValue¨gcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationBucketingConfigBucketReplacementValue:PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationBucketingConfigBucketReplacementValueë
èÅ
	dateValueéBæ:ã
à
datalossPreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationBucketingConfigBucketReplacementValueDateValueºgcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationBucketingConfigBucketReplacementValueDateValue:PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationBucketingConfigBucketReplacementValueDateValueLRepresents a whole or partial calendar date.
Structure is documented below.

dayOfWeekValueB" Represents a day of the week.
Possible values are: `MONDAY`, `TUESDAY`, `WEDNESDAY`, `THURSDAY`, `FRIDAY`, `SATURDAY`, `SUNDAY`.
#

floatValueB A float value.
6
integerValueB"  An integer value (int64 format)
%
stringValueB" A string value.
²
	timeValueéBæ:ã
à
datalossPreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationBucketingConfigBucketReplacementValueTimeValueºgcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationBucketingConfigBucketReplacementValueTimeValue:PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationBucketingConfigBucketReplacementValueTimeValue9Represents a time of day.
Structure is documented below.
Ç
timestampValueB" ®A timestamp in RFC3339 UTC "Zulu" format, with nanosecond resolution and up to nine fractional digits. Examples: "2014-10-02T15:01:23Z" and "2014-10-02T15:01:23.045123456Z".
:ç
à
datalossPreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationBucketingConfigBucketReplacementValueDateValueºgcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationBucketingConfigBucketReplacementValueDateValue:PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationBucketingConfigBucketReplacementValueDateValue
þ²
dayB ¤Day of a month. Must be from 1 to 31 and valid for the year and month, or 0 to specify a year by itself or a year and month where the day isn't significant.

- - -
f
monthB WMonth of a year. Must be from 1 to 12, or 0 to specify a year without a month and day.
_
yearB QYear of the date. Must be from 1 to 9999, or 0 to specify a date without a year.
:°
à
datalossPreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationBucketingConfigBucketReplacementValueTimeValueºgcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationBucketingConfigBucketReplacementValueTimeValue:PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationBucketingConfigBucketReplacementValueTimeValueÊ
Ç¢
hoursB Hours of day in 24 hour format. Should be from 0 to 23. An API may choose to allow the value "24:00:00" for scenarios like business closing time.
?
minutesB .Minutes of hour of day. Must be from 0 to 59.
S
nanosB DFractions of seconds in nanoseconds. Must be from 0 to 999,999,999.

secondsB xSeconds of minutes of the time. Must normally be from 0 to 59. An API may allow the value 60 if it allows leap-seconds.
:á

dataloss{PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationCharacterMaskConfiggcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationCharacterMaskConfig:PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationCharacterMaskConfigÍ
Êí
charactersToIgnoresÑBÎ*Ë:È
Å
datalossPreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationCharacterMaskConfigCharactersToIgnore¨gcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationCharacterMaskConfigCharactersToIgnore:PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationCharacterMaskConfigCharactersToIgnoreCharacters to skip when doing de-identification of a value. These will be left alone and skipped.
Structure is documented below.
³
maskingCharacterB" Character to use to mask the sensitive valuesâfor example, * for an alphabetic string such as a name, or 0 for a numeric string
such as ZIP code or credit card number. This string must have a length of 1. If not supplied, this value defaults to * for
strings, and 0 for digits.
¹
numberToMaskB ¢Number of characters to mask. If not set, all matching chars will be masked. Skipped characters do not count towards this tally.
If number_to_mask is negative, this denotes inverse masking. Cloud DLP masks all but a number of characters. For example, suppose you have the following values:
å
reverseOrderB
 ÎMask characters in reverse order. For example, if masking_character is 0, number_to_mask is 14, and reverse_order is `false`, then the
input string `1234-5678-9012-3456` is masked as `00000000000000-3456`.
:ø
Å
datalossPreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationCharacterMaskConfigCharactersToIgnore¨gcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationCharacterMaskConfigCharactersToIgnore:PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationCharacterMaskConfigCharactersToIgnore­
ª
charactersToSkipB" oCharacters to not transform when masking. Only one of this or `common_characters_to_ignore` must be specified.

commonCharactersToIgnoreB" øCommon characters to not transform when masking. Useful to avoid removing punctuation. Only one of this or `characters_to_skip` must be specified.
Possible values are: `NUMERIC`, `ALPHA_UPPER_CASE`, `ALPHA_LOWER_CASE`, `PUNCTUATION`, `WHITESPACE`.
:½#
¡
datalossPreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationCryptoDeterministicConfiggcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationCryptoDeterministicConfig:PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationCryptoDeterministicConfig 
  

context¿B¼:¹
¶
datalossPreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationCryptoDeterministicConfigContextgcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationCryptoDeterministicConfigContext:PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationCryptoDeterministicConfigContextÒA context may be used for higher security and maintaining referential integrity such that the same identifier in two different contexts will be given a distinct surrogate. The context is appended to plaintext value being encrypted. On decryption the provided context is validated against the value used during encryption. If a context was provided during encryption, same context must be provided during decryption as well.
If the context is not set, plaintext would be used as is for encryption. If the context is set but:
1. there is no record present when transforming a given value or
2. the field is not present when transforming a given value,
plaintext would be used as is for encryption.
Note that case (1) is expected when an InfoTypeTransformation is applied to both structured and unstructured ContentItems.
Structure is documented below.

	cryptoKeyÅBÂ:¿
¼
datalossPreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationCryptoDeterministicConfigCryptoKey¢gcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationCryptoDeterministicConfigCryptoKey:PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationCryptoDeterministicConfigCryptoKey¶The key used by the encryption function. For deterministic encryption using AES-SIV, the provided key is internally expanded to 64 bytes prior to use.
Structure is documented below.
Þ
surrogateInfoTypeÝBÚ:×
Ô
datalossPreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationCryptoDeterministicConfigSurrogateInfoType²gcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationCryptoDeterministicConfigSurrogateInfoType:PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationCryptoDeterministicConfigSurrogateInfoTypeèThe custom info type to annotate the surrogate with. This annotation will be applied to the surrogate by prefixing it with the name of the custom info type followed by the number of characters comprising the surrogate. The following scheme defines the format: {info type name}({surrogate character count}):{surrogate}
For example, if the name of custom info type is 'MY\_TOKEN\_INFO\_TYPE' and the surrogate is 'abc', the full replacement value will be: 'MY\_TOKEN\_INFO\_TYPE(3):abc'
This annotation identifies the surrogate when inspecting content using the custom info type 'Surrogate'. This facilitates reversal of the surrogate when it occurs in free text.
Note: For record transformations where the entire cell in a table is being transformed, surrogates are not mandatory. Surrogates are used to denote the location of the token and are necessary for re-identification in free form text.
In order for inspection to work properly, the name of this info type must not occur naturally anywhere in your data; otherwise, inspection may either
*   reverse a surrogate that does not correspond to an actual identifier
*   be unable to parse the surrogate and result in an error
Therefore, choose your custom info type name carefully after considering what your data looks like. One way to select a name that has a high chance of yielding reliable detection is to include one or more unicode characters that are highly improbable to exist in your data. For example, assuming your data is entered from a regular ASCII keyboard, the symbol with the hex code point 29DD might be used like so: â§MY\_TOKEN\_TYPE.
Structure is documented below.
:è
¶
datalossPreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationCryptoDeterministicConfigContextgcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationCryptoDeterministicConfigContext:PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationCryptoDeterministicConfigContext-
+)
nameB" Name describing the field.
:Ì
¼
datalossPreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationCryptoDeterministicConfigCryptoKey¢gcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationCryptoDeterministicConfigCryptoKey:PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationCryptoDeterministicConfigCryptoKey
Ñ

kmsWrappedãBà:Ý
Ú
datalossPreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationCryptoDeterministicConfigCryptoKeyKmsWrapped¶gcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationCryptoDeterministicConfigCryptoKeyKmsWrapped:PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationCryptoDeterministicConfigCryptoKeyKmsWrappedÜKMS wrapped key.
Include to use an existing data crypto key wrapped by KMS. The wrapped key must be a 128-, 192-, or 256-bit key. Authorization requires the following IAM permissions when sending a request to perform a crypto transformation using a KMS-wrapped crypto key: dlp.kms.encrypt
For more information, see [Creating a wrapped key](https://cloud.google.com/dlp/docs/create-wrapped-key). Only one of this, `transient` or `unwrapped` must be specified.
Note: When you use Cloud KMS for cryptographic operations, [charges apply](https://cloud.google.com/kms/pricing).
Structure is documented below.
Î
	transientàBÝ:Ú
×
datalossPreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationCryptoDeterministicConfigCryptoKeyTransient´gcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationCryptoDeterministicConfigCryptoKeyTransient:PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationCryptoDeterministicConfigCryptoKeyTransientÝTransient crypto key. Use this to have a random data crypto key generated. It will be discarded after the request finishes. Only one of this, `unwrapped` or `kms_wrapped` must be specified.
Structure is documented below.
ß
	unwrappedàBÝ:Ú
×
datalossPreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationCryptoDeterministicConfigCryptoKeyUnwrapped´gcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationCryptoDeterministicConfigCryptoKeyUnwrapped:PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationCryptoDeterministicConfigCryptoKeyUnwrappedîUnwrapped crypto key. Using raw keys is prone to security risks due to accidentally leaking the key. Choose another type of key if possible. Only one of this, `transient` or `kms_wrapped` must be specified.
Structure is documented below.
:
Ú
datalossPreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationCryptoDeterministicConfigCryptoKeyKmsWrapped¶gcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationCryptoDeterministicConfigCryptoKeyKmsWrapped:PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationCryptoDeterministicConfigCryptoKeyKmsWrapped¢
S
cryptoKeyName" >The resource name of the KMS CryptoKey to use for unwrapping.
H

wrappedKey" 6The wrapped data crypto key.
A base64-encoded string.
:Û
×
datalossPreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationCryptoDeterministicConfigCryptoKeyTransient´gcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationCryptoDeterministicConfigCryptoKeyTransient:PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationCryptoDeterministicConfigCryptoKeyTransientþ
ûø
name" ëName of the key. This is an arbitrary string used to differentiate different keys. A unique key is generated per name: two separate `TransientCryptoKey` protos share the same generated key if their names are the same. When the data crypto key is generated, this name is not used in any way (repeating the api call will result in a different key being generated).
:ê
×
datalossPreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationCryptoDeterministicConfigCryptoKeyUnwrapped´gcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationCryptoDeterministicConfigCryptoKeyUnwrapped:PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationCryptoDeterministicConfigCryptoKeyUnwrapped

key" |A 128/192/256 bit key.
A base64-encoded string.
**Note**: This property is sensitive and will not be displayed in the plan.
:Å
Ô
datalossPreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationCryptoDeterministicConfigSurrogateInfoType²gcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationCryptoDeterministicConfigSurrogateInfoType:PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationCryptoDeterministicConfigSurrogateInfoTypeë
è
nameB" Name of the information type. Either a name of your choosing when creating a CustomInfoType, or one of the names listed at [https://cloud.google.com/dlp/docs/infotypes-reference](https://cloud.google.com/dlp/docs/infotypes-reference) when specifying a built-in type. When sending Cloud DLP results to Data Catalog, infoType names should conform to the pattern `[A-Za-z0-9$-_]{1,64}`.

sensitivityScoreB:

dataloss¢PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationCryptoDeterministicConfigSurrogateInfoTypeSensitivityScoreÒgcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationCryptoDeterministicConfigSurrogateInfoTypeSensitivityScore:PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationCryptoDeterministicConfigSurrogateInfoTypeSensitivityScoresOptional custom sensitivity for this InfoType. This only applies to data profiling.
Structure is documented below.
:
versionB" )Optional version name for this InfoType.
:¡

dataloss¢PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationCryptoDeterministicConfigSurrogateInfoTypeSensitivityScoreÒgcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationCryptoDeterministicConfigSurrogateInfoTypeSensitivityScore:PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationCryptoDeterministicConfigSurrogateInfoTypeSensitivityScore

score" The sensitivity score applied to the resource.
Possible values are: `SENSITIVITY_LOW`, `SENSITIVITY_MODERATE`, `SENSITIVITY_HIGH`.
:

datalossxPreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationCryptoHashConfigþgcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationCryptoHashConfig:PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationCryptoHashConfig

	cryptoKeyªB§:¤
¡
datalossPreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationCryptoHashConfigCryptoKeygcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationCryptoHashConfigCryptoKey:PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationCryptoHashConfigCryptoKeyHThe key used by the encryption function.
Structure is documented below.
:à
¡
datalossPreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationCryptoHashConfigCryptoKeygcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationCryptoHashConfigCryptoKey:PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationCryptoHashConfigCryptoKey¹
¶¶

kmsWrappedÈBÅ:Â
¿
datalossPreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationCryptoHashConfigCryptoKeyKmsWrapped¤gcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationCryptoHashConfigCryptoKeyKmsWrapped:PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationCryptoHashConfigCryptoKeyKmsWrappedÜKMS wrapped key.
Include to use an existing data crypto key wrapped by KMS. The wrapped key must be a 128-, 192-, or 256-bit key. Authorization requires the following IAM permissions when sending a request to perform a crypto transformation using a KMS-wrapped crypto key: dlp.kms.encrypt
For more information, see [Creating a wrapped key](https://cloud.google.com/dlp/docs/create-wrapped-key). Only one of this, `transient` or `unwrapped` must be specified.
Note: When you use Cloud KMS for cryptographic operations, [charges apply](https://cloud.google.com/kms/pricing).
Structure is documented below.
³
	transientÅBÂ:¿
¼
datalossPreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationCryptoHashConfigCryptoKeyTransient¢gcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationCryptoHashConfigCryptoKeyTransient:PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationCryptoHashConfigCryptoKeyTransientÝTransient crypto key. Use this to have a random data crypto key generated. It will be discarded after the request finishes. Only one of this, `unwrapped` or `kms_wrapped` must be specified.
Structure is documented below.
Ä
	unwrappedÅBÂ:¿
¼
datalossPreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationCryptoHashConfigCryptoKeyUnwrapped¢gcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationCryptoHashConfigCryptoKeyUnwrapped:PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationCryptoHashConfigCryptoKeyUnwrappedîUnwrapped crypto key. Using raw keys is prone to security risks due to accidentally leaking the key. Choose another type of key if possible. Only one of this, `transient` or `kms_wrapped` must be specified.
Structure is documented below.
:ç
¿
datalossPreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationCryptoHashConfigCryptoKeyKmsWrapped¤gcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationCryptoHashConfigCryptoKeyKmsWrapped:PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationCryptoHashConfigCryptoKeyKmsWrapped¢
S
cryptoKeyName" >The resource name of the KMS CryptoKey to use for unwrapping.
H

wrappedKey" 6The wrapped data crypto key.
A base64-encoded string.
:À
¼
datalossPreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationCryptoHashConfigCryptoKeyTransient¢gcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationCryptoHashConfigCryptoKeyTransient:PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationCryptoHashConfigCryptoKeyTransientþ
ûø
name" ëName of the key. This is an arbitrary string used to differentiate different keys. A unique key is generated per name: two separate `TransientCryptoKey` protos share the same generated key if their names are the same. When the data crypto key is generated, this name is not used in any way (repeating the api call will result in a different key being generated).
:Ï
¼
datalossPreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationCryptoHashConfigCryptoKeyUnwrapped¢gcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationCryptoHashConfigCryptoKeyUnwrapped:PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationCryptoHashConfigCryptoKeyUnwrapped

key" |A 128/192/256 bit key.
A base64-encoded string.
**Note**: This property is sensitive and will not be displayed in the plan.
:(
¡
datalossPreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationCryptoReplaceFfxFpeConfiggcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationCryptoReplaceFfxFpeConfig:PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationCryptoReplaceFfxFpeConfigÞ$
Û$É
commonAlphabetB" °Common alphabets. Only one of this, `custom_alphabet` or `radix` must be specified.
Possible values are: `NUMERIC`, `HEXADECIMAL`, `UPPER_CASE_ALPHA_NUMERIC`, `ALPHA_NUMERIC`.


context¿B¼:¹
¶
datalossPreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationCryptoReplaceFfxFpeConfigContextgcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationCryptoReplaceFfxFpeConfigContext:PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationCryptoReplaceFfxFpeConfigContextÎThe 'tweak', a context may be used for higher security since the same identifier in two different contexts won't be given the same surrogate. If the context is not set, a default tweak will be used.
If the context is set but:
1.  there is no record present when transforming a given value or
2.  the field is not present when transforming a given value,
a default tweak will be used.
Note that case (1) is expected when an `InfoTypeTransformation` is applied to both structured and non-structured `ContentItem`s. Currently, the referenced field may be of value type integer or string.
The tweak is constructed as a sequence of bytes in big endian byte order such that:
*   a 64 bit integer is encoded followed by a single byte of value 1
*   a string is encoded in UTF-8 format followed by a single byte of value 2
Structure is documented below.

	cryptoKeyÅBÂ:¿
¼
datalossPreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationCryptoReplaceFfxFpeConfigCryptoKey¢gcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationCryptoReplaceFfxFpeConfigCryptoKey:PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationCryptoReplaceFfxFpeConfigCryptoKeyIThe key used by the encryption algorithm.
Structure is documented below.
©
customAlphabetB" This is supported by mapping these to the alphanumeric characters that the FFX mode natively supports. This happens before/after encryption/decryption. Each character listed must appear only once. Number of characters must be in the range \[2, 95\]. This must be encoded as ASCII. The order of characters does not matter. The full list of allowed characters is:
``0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz ~`!@#$%^&*()_-+={[}]|:;"'<,>.?/``. Only one of this, `common_alphabet` or `radix` must be specified.
£
radixB The native way to select the alphabet. Must be in the range \[2, 95\]. Only one of this, `custom_alphabet` or `common_alphabet` must be specified.
ú
surrogateInfoTypeÝBÚ:×
Ô
datalossPreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationCryptoReplaceFfxFpeConfigSurrogateInfoType²gcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationCryptoReplaceFfxFpeConfigSurrogateInfoType:PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationCryptoReplaceFfxFpeConfigSurrogateInfoTypeThe custom infoType to annotate the surrogate with. This annotation will be applied to the surrogate by prefixing it with the name of the custom infoType followed by the number of characters comprising the surrogate. The following scheme defines the format: info\_type\_name(surrogate\_character\_count):surrogate
For example, if the name of custom infoType is 'MY\_TOKEN\_INFO\_TYPE' and the surrogate is 'abc', the full replacement value will be: 'MY\_TOKEN\_INFO\_TYPE(3):abc'
This annotation identifies the surrogate when inspecting content using the custom infoType [`SurrogateType`](https://cloud.google.com/dlp/docs/reference/rest/v2/InspectConfig#surrogatetype). This facilitates reversal of the surrogate when it occurs in free text.
In order for inspection to work properly, the name of this infoType must not occur naturally anywhere in your data; otherwise, inspection may find a surrogate that does not correspond to an actual identifier. Therefore, choose your custom infoType name carefully after considering what your data looks like. One way to select a name that has a high chance of yielding reliable detection is to include one or more unicode characters that are highly improbable to exist in your data. For example, assuming your data is entered from a regular ASCII keyboard, the symbol with the hex code point 29DD might be used like so: â§MY\_TOKEN\_TYPE
Structure is documented below.
:è
¶
datalossPreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationCryptoReplaceFfxFpeConfigContextgcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationCryptoReplaceFfxFpeConfigContext:PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationCryptoReplaceFfxFpeConfigContext-
+)
nameB" Name describing the field.
:Ì
¼
datalossPreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationCryptoReplaceFfxFpeConfigCryptoKey¢gcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationCryptoReplaceFfxFpeConfigCryptoKey:PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationCryptoReplaceFfxFpeConfigCryptoKey
Ñ

kmsWrappedãBà:Ý
Ú
datalossPreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationCryptoReplaceFfxFpeConfigCryptoKeyKmsWrapped¶gcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationCryptoReplaceFfxFpeConfigCryptoKeyKmsWrapped:PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationCryptoReplaceFfxFpeConfigCryptoKeyKmsWrappedÜKMS wrapped key.
Include to use an existing data crypto key wrapped by KMS. The wrapped key must be a 128-, 192-, or 256-bit key. Authorization requires the following IAM permissions when sending a request to perform a crypto transformation using a KMS-wrapped crypto key: dlp.kms.encrypt
For more information, see [Creating a wrapped key](https://cloud.google.com/dlp/docs/create-wrapped-key). Only one of this, `transient` or `unwrapped` must be specified.
Note: When you use Cloud KMS for cryptographic operations, [charges apply](https://cloud.google.com/kms/pricing).
Structure is documented below.
Î
	transientàBÝ:Ú
×
datalossPreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationCryptoReplaceFfxFpeConfigCryptoKeyTransient´gcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationCryptoReplaceFfxFpeConfigCryptoKeyTransient:PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationCryptoReplaceFfxFpeConfigCryptoKeyTransientÝTransient crypto key. Use this to have a random data crypto key generated. It will be discarded after the request finishes. Only one of this, `unwrapped` or `kms_wrapped` must be specified.
Structure is documented below.
ß
	unwrappedàBÝ:Ú
×
datalossPreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationCryptoReplaceFfxFpeConfigCryptoKeyUnwrapped´gcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationCryptoReplaceFfxFpeConfigCryptoKeyUnwrapped:PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationCryptoReplaceFfxFpeConfigCryptoKeyUnwrappedîUnwrapped crypto key. Using raw keys is prone to security risks due to accidentally leaking the key. Choose another type of key if possible. Only one of this, `transient` or `kms_wrapped` must be specified.
Structure is documented below.
:
Ú
datalossPreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationCryptoReplaceFfxFpeConfigCryptoKeyKmsWrapped¶gcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationCryptoReplaceFfxFpeConfigCryptoKeyKmsWrapped:PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationCryptoReplaceFfxFpeConfigCryptoKeyKmsWrapped¢
S
cryptoKeyName" >The resource name of the KMS CryptoKey to use for unwrapping.
H

wrappedKey" 6The wrapped data crypto key.
A base64-encoded string.
:Û
×
datalossPreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationCryptoReplaceFfxFpeConfigCryptoKeyTransient´gcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationCryptoReplaceFfxFpeConfigCryptoKeyTransient:PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationCryptoReplaceFfxFpeConfigCryptoKeyTransientþ
ûø
name" ëName of the key. This is an arbitrary string used to differentiate different keys. A unique key is generated per name: two separate `TransientCryptoKey` protos share the same generated key if their names are the same. When the data crypto key is generated, this name is not used in any way (repeating the api call will result in a different key being generated).
:ê
×
datalossPreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationCryptoReplaceFfxFpeConfigCryptoKeyUnwrapped´gcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationCryptoReplaceFfxFpeConfigCryptoKeyUnwrapped:PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationCryptoReplaceFfxFpeConfigCryptoKeyUnwrapped

key" |A 128/192/256 bit key.
A base64-encoded string.
**Note**: This property is sensitive and will not be displayed in the plan.
:Å
Ô
datalossPreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationCryptoReplaceFfxFpeConfigSurrogateInfoType²gcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationCryptoReplaceFfxFpeConfigSurrogateInfoType:PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationCryptoReplaceFfxFpeConfigSurrogateInfoTypeë
è
nameB" Name of the information type. Either a name of your choosing when creating a CustomInfoType, or one of the names listed at [https://cloud.google.com/dlp/docs/infotypes-reference](https://cloud.google.com/dlp/docs/infotypes-reference) when specifying a built-in type. When sending Cloud DLP results to Data Catalog, infoType names should conform to the pattern `[A-Za-z0-9$-_]{1,64}`.

sensitivityScoreB:

dataloss¢PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationCryptoReplaceFfxFpeConfigSurrogateInfoTypeSensitivityScoreÒgcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationCryptoReplaceFfxFpeConfigSurrogateInfoTypeSensitivityScore:PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationCryptoReplaceFfxFpeConfigSurrogateInfoTypeSensitivityScoresOptional custom sensitivity for this InfoType. This only applies to data profiling.
Structure is documented below.
:
versionB" )Optional version name for this InfoType.
:¡

dataloss¢PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationCryptoReplaceFfxFpeConfigSurrogateInfoTypeSensitivityScoreÒgcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationCryptoReplaceFfxFpeConfigSurrogateInfoTypeSensitivityScore:PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationCryptoReplaceFfxFpeConfigSurrogateInfoTypeSensitivityScore

score" The sensitivity score applied to the resource.
Possible values are: `SENSITIVITY_LOW`, `SENSITIVITY_MODERATE`, `SENSITIVITY_HIGH`.
:¨

datalosswPreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationDateShiftConfigügcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationDateShiftConfig:PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationDateShiftConfig 
ñ
context B:

dataloss~PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationDateShiftConfigContextgcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationDateShiftConfigContext:PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationDateShiftConfigContextÂPoints to the field that contains the context, for example, an entity id.
If set, must also set cryptoKey. If set, shift will be consistent for the given context.
Structure is documented below.
 
	cryptoKey§B¤:¡

datalossPreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationDateShiftConfigCryptoKeygcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationDateShiftConfigCryptoKey:PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationDateShiftConfigCryptoKeyèCauses the shift to be computed based on this key and the context. This results in the same shift for the same context and cryptoKey. If set, must also set context. Can only be applied to table items.
Structure is documented below.
[
lowerBoundDays EFor example, -5 means shift date to at most 5 days back in the past.
¦
upperBoundDays Range of shift in days. Actual shift will be selected at random within this range (inclusive ends). Negative means shift to earlier in time. Must not be more than 365250 days (1000 years) each direction.
For example, 3 means shift date to at most 3 days into the future.
:Ç

dataloss~PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationDateShiftConfigContextgcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationDateShiftConfigContext:PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationDateShiftConfigContext+
)'
name" Name describing the field.
:Ô

datalossPreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationDateShiftConfigCryptoKeygcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationDateShiftConfigCryptoKey:PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationDateShiftConfigCryptoKey°
­³

kmsWrappedÅBÂ:¿
¼
datalossPreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationDateShiftConfigCryptoKeyKmsWrapped¢gcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationDateShiftConfigCryptoKeyKmsWrapped:PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationDateShiftConfigCryptoKeyKmsWrappedÜKMS wrapped key.
Include to use an existing data crypto key wrapped by KMS. The wrapped key must be a 128-, 192-, or 256-bit key. Authorization requires the following IAM permissions when sending a request to perform a crypto transformation using a KMS-wrapped crypto key: dlp.kms.encrypt
For more information, see [Creating a wrapped key](https://cloud.google.com/dlp/docs/create-wrapped-key). Only one of this, `transient` or `unwrapped` must be specified.
Note: When you use Cloud KMS for cryptographic operations, [charges apply](https://cloud.google.com/kms/pricing).
Structure is documented below.
°
	transientÂB¿:¼
¹
datalossPreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationDateShiftConfigCryptoKeyTransient gcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationDateShiftConfigCryptoKeyTransient:PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationDateShiftConfigCryptoKeyTransientÝTransient crypto key. Use this to have a random data crypto key generated. It will be discarded after the request finishes. Only one of this, `unwrapped` or `kms_wrapped` must be specified.
Structure is documented below.
Á
	unwrappedÂB¿:¼
¹
datalossPreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationDateShiftConfigCryptoKeyUnwrapped gcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationDateShiftConfigCryptoKeyUnwrapped:PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationDateShiftConfigCryptoKeyUnwrappedîUnwrapped crypto key. Using raw keys is prone to security risks due to accidentally leaking the key. Choose another type of key if possible. Only one of this, `transient` or `kms_wrapped` must be specified.
Structure is documented below.
:ä
¼
datalossPreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationDateShiftConfigCryptoKeyKmsWrapped¢gcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationDateShiftConfigCryptoKeyKmsWrapped:PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationDateShiftConfigCryptoKeyKmsWrapped¢
S
cryptoKeyName" >The resource name of the KMS CryptoKey to use for unwrapping.
H

wrappedKey" 6The wrapped data crypto key.
A base64-encoded string.
:½
¹
datalossPreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationDateShiftConfigCryptoKeyTransient gcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationDateShiftConfigCryptoKeyTransient:PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationDateShiftConfigCryptoKeyTransientþ
ûø
name" ëName of the key. This is an arbitrary string used to differentiate different keys. A unique key is generated per name: two separate `TransientCryptoKey` protos share the same generated key if their names are the same. When the data crypto key is generated, this name is not used in any way (repeating the api call will result in a different key being generated).
:Ì
¹
datalossPreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationDateShiftConfigCryptoKeyUnwrapped gcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationDateShiftConfigCryptoKeyUnwrapped:PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationDateShiftConfigCryptoKeyUnwrapped

key" |A 128/192/256 bit key.
A base64-encoded string.
**Note**: This property is sensitive and will not be displayed in the plan.
:

datalossPreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationFixedSizeBucketingConfiggcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationFixedSizeBucketingConfig:PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationFixedSizeBucketingConfigî
ë

bucketSize Size of each bucket (except for minimum and maximum buckets).
So if lower_bound = 10, upper_bound = 89, and bucketSize = 10, then the following buckets would be used: -10, 10-20, 20-30, 30-40, 40-50, 50-60, 60-70, 70-80, 80-89, 89+.
Precision up to 2 decimals works.
ß

lowerBoundÂ:¿
¼
datalossPreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationFixedSizeBucketingConfigLowerBound¢gcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationFixedSizeBucketingConfigLowerBound:PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationFixedSizeBucketingConfigLowerBoundLower bound value of buckets.
All values less than lower_bound are grouped together into a single bucket; for example if lower_bound = 10, then all values less than 10 are replaced with the value "-10".
The `lower_bound` block must only contain one argument. See the `fixed_size_bucketing_config` block description for more information about choosing a data type.
Structure is documented below.
å

upperBoundÂ:¿
¼
datalossPreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationFixedSizeBucketingConfigUpperBound¢gcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationFixedSizeBucketingConfigUpperBound:PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationFixedSizeBucketingConfigUpperBoundUpper bound value of buckets.
All values greater than upper_bound are grouped together into a single bucket; for example if upper_bound = 89, then all values greater than 89 are replaced with the value "89+".
The `upper_bound` block must only contain one argument. See the `fixed_size_bucketing_config` block description for more information about choosing a data type.
Structure is documented below.
: 
¼
datalossPreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationFixedSizeBucketingConfigLowerBound¢gcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationFixedSizeBucketingConfigLowerBound:PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationFixedSizeBucketingConfigLowerBound_
]#

floatValueB A float value.
6
integerValueB"  An integer value (int64 format)
: 
¼
datalossPreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationFixedSizeBucketingConfigUpperBound¢gcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationFixedSizeBucketingConfigUpperBound:PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationFixedSizeBucketingConfigUpperBound_
]#

floatValueB A float value.
6
integerValueB"  An integer value (int64 format)
:
ù
datalosstPreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationRedactConfigögcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationRedactConfig:PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationRedactConfig
 :
ü
datalossuPreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationReplaceConfigøgcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationReplaceConfig:PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationReplaceConfig

newValue:

dataloss}PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationReplaceConfigNewValuegcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationReplaceConfigNewValue:PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationReplaceConfigNewValueåReplace each input value with a given value.
The `new_value` block must only contain one argument. For example when replacing the contents of a string-type field, only `string_value` should be set.
Structure is documented below.
:Î

dataloss}PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationReplaceConfigNewValuegcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationReplaceConfigNewValue:PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationReplaceConfigNewValue´
±'
booleanValueB
 A boolean value.

	dateValue¹B¶:³
°
datalossPreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationReplaceConfigNewValueDateValuegcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationReplaceConfigNewValueDateValue:PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationReplaceConfigNewValueDateValueLRepresents a whole or partial calendar date.
Structure is documented below.

dayOfWeekValueB" Represents a day of the week.
Possible values are: `MONDAY`, `TUESDAY`, `WEDNESDAY`, `THURSDAY`, `FRIDAY`, `SATURDAY`, `SUNDAY`.
#

floatValueB A float value.
6
integerValueB  An integer value (int64 format)
%
stringValueB" A string value.

	timeValue¹B¶:³
°
datalossPreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationReplaceConfigNewValueTimeValuegcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationReplaceConfigNewValueTimeValue:PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationReplaceConfigNewValueTimeValue9Represents a time of day.
Structure is documented below.
Ç
timestampValueB" ®A timestamp in RFC3339 UTC "Zulu" format, with nanosecond resolution and up to nine fractional digits.
Examples: "2014-10-02T15:01:23Z" and "2014-10-02T15:01:23.045123456Z".
:·
°
datalossPreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationReplaceConfigNewValueDateValuegcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationReplaceConfigNewValueDateValue:PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationReplaceConfigNewValueDateValue
þ²
dayB ¤Day of a month. Must be from 1 to 31 and valid for the year and month, or 0 to specify a year by itself or a year and month where the day isn't significant.

- - -
f
monthB WMonth of a year. Must be from 1 to 12, or 0 to specify a year without a month and day.
_
yearB QYear of the date. Must be from 1 to 9999, or 0 to specify a date without a year.
:
°
datalossPreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationReplaceConfigNewValueTimeValuegcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationReplaceConfigNewValueTimeValue:PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationReplaceConfigNewValueTimeValueÊ
Ç¢
hoursB Hours of day in 24 hour format. Should be from 0 to 23. An API may choose to allow the value "24:00:00" for scenarios like business closing time.
?
minutesB .Minutes of hour of day. Must be from 0 to 59.
S
nanosB DFractions of seconds in nanoseconds. Must be from 0 to 999,999,999.

secondsB xSeconds of minutes of the time. Must normally be from 0 to 59. An API may allow the value 60 if it allows leap-seconds.
:´

datalossPreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationReplaceDictionaryConfiggcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationReplaceDictionaryConfig:PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationReplaceDictionaryConfig

wordList¹:¶
³
datalossPreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationReplaceDictionaryConfigWordListgcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationReplaceDictionaryConfigWordList:PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationReplaceDictionaryConfigWordListÅA list of words to select from for random replacement. The [limits](https://cloud.google.com/dlp/limits) page contains details about the size limits of dictionaries.
Structure is documented below.
:ù
³
datalossPreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationReplaceDictionaryConfigWordListgcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationReplaceDictionaryConfigWordList:PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationReplaceDictionaryConfigWordListÀ
½º
words*" ªWords or phrases defining the dictionary. The dictionary must contain at least one phrase and every phrase must contain at least 2 characters that are letters or digits.
:¥
ÿ
datalossvPreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationTimePartConfigúgcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationTimePartConfig:PreventionDeidentifyTemplateDeidentifyConfigInfoTypeTransformationsTransformationPrimitiveTransformationTimePartConfig 

partToExtractB" The part of the time to keep.
Possible values are: `YEAR`, `MONTH`, `DAY_OF_MONTH`, `DAY_OF_WEEK`, `WEEK_OF_YEAR`, `HOUR_OF_DAY`.
:é
à
datalossAPreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsgcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigRecordTransformations:PreventionDeidentifyTemplateDeidentifyConfigRecordTransformations

fieldTransformations¥B¢*:

datalossTPreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformation¶gcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformation:PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformation_Transform the record by applying various field transformations.
Structure is documented below.
Û
recordSuppressionsB*:

datalossRPreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsRecordSuppression²gcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsRecordSuppression:PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsRecordSuppression¢Configuration defining which records get suppressed entirely. Records that match any suppression rule are omitted from the output.
Structure is documented below.
:

datalossTPreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformation¶gcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformation:PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationù
ö
	condition½Bº:·
´
dataloss]PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationConditionÈgcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationCondition:PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationCondition³Only apply the transformation if the condition evaluates to true for the given RecordCondition. The conditions are allowed to reference fields that are not used in the actual transformation.
Example Use Cases:
- Apply a different bucket transformation to an age column if the zip code column for the same record is within a specific range.
- Redact a field if the date of birth field is greater than 85.
Structure is documented below.
ã
fields±*®:«
¨
datalossYPreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationFieldÀgcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationField:PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationField¤Input field(s) to apply the transformation to. When you have columns that reference their position within a list, omit the index from the FieldId.
FieldId name matching ignores the index. For example, instead of "contact.nums[0].type", use "contact.nums.type".
Structure is documented below.
è
infoTypeTransformationsçBä:á
Þ
datalosskPreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationInfoTypeTransformationsägcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationInfoTypeTransformations:PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationInfoTypeTransformationsâTreat the contents of the field as free text, and selectively transform content that matches an InfoType.
Only one of `primitive_transformation` or `info_type_transformations` must be specified.
Structure is documented below.

primitiveTransformationçBä:á
Þ
datalosskPreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationPrimitiveTransformationägcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationPrimitiveTransformation:PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationPrimitiveTransformationApply the transformation to the entire field.
The `primitive_transformation` block must only contain one argument, corresponding to the type of transformation.
Only one of `primitive_transformation` or `info_type_transformations` must be specified.
Structure is documented below.
:
´
dataloss]PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationConditionÈgcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationCondition:PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationConditionÎ
ËÈ
expressionsÞBÛ:Ø
Õ
datalosshPreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationConditionExpressionsÞgcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationConditionExpressions:PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationConditionExpressionsXAn expression, consisting of an operator and conditions.
Structure is documented below.
:ë
Õ
datalosshPreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationConditionExpressionsÞgcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationConditionExpressions:PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationConditionExpressions
Ó

conditionsüBù:ö
ó
datalossrPreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationConditionExpressionsConditionsògcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationConditionExpressionsConditions:PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationConditionExpressionsConditionsFConditions to apply to the expression.
Structure is documented below.
´
logicalOperatorB" The operator to apply to the result of conditions. Default and currently only supported value is AND.
Default value is `AND`.
Possible values are: `AND`.
:å
ó
datalossrPreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationConditionExpressionsConditionsògcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationConditionExpressionsConditions:PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationConditionExpressionsConditionsì
éæ

conditionsB*:

dataloss{PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationConditionExpressionsConditionsConditiongcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationConditionExpressionsConditionsCondition:PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationConditionExpressionsConditionsCondition;A collection of conditions.
Structure is documented below.
:

dataloss{PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationConditionExpressionsConditionsConditiongcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationConditionExpressionsConditionsCondition:PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationConditionExpressionsConditionsCondition

þ	
field¤:¡

datalossPreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationConditionExpressionsConditionsConditionFieldgcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationConditionExpressionsConditionsConditionField:PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationConditionExpressionsConditionsConditionField\Field within the record this condition is evaluated against.
Structure is documented below.
×
operator" ÆOperator used to compare the field or infoType to the value.
Possible values are: `EQUAL_TO`, `NOT_EQUAL_TO`, `GREATER_THAN`, `LESS_THAN`, `GREATER_THAN_OR_EQUALS`, `LESS_THAN_OR_EQUALS`, `EXISTS`.

value§B¤:¡

datalossPreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationConditionExpressionsConditionsConditionValuegcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationConditionExpressionsConditionsConditionValue:PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationConditionExpressionsConditionsConditionValue_Value to compare against. [Mandatory, except for EXISTS tests.]
Structure is documented below.
:Ð

datalossPreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationConditionExpressionsConditionsConditionFieldgcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationConditionExpressionsConditionsConditionField:PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationConditionExpressionsConditionsConditionField-
+)
nameB" Name describing the field.
:ê

datalossPreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationConditionExpressionsConditionsConditionValuegcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationConditionExpressionsConditionsConditionValue:PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationConditionExpressionsConditionsConditionValueÆ
Ã'
booleanValueB
 A boolean value.

	dateValueÂB¿:¼
¹
datalossPreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationConditionExpressionsConditionsConditionValueDateValue gcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationConditionExpressionsConditionsConditionValueDateValue:PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationConditionExpressionsConditionsConditionValueDateValueLRepresents a whole or partial calendar date.
Structure is documented below.

dayOfWeekValueB" Represents a day of the week.
Possible values are: `MONDAY`, `TUESDAY`, `WEDNESDAY`, `THURSDAY`, `FRIDAY`, `SATURDAY`, `SUNDAY`.
#

floatValueB A float value.
6
integerValueB"  An integer value (int64 format)
%
stringValueB" A string value.

	timeValueÂB¿:¼
¹
datalossPreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationConditionExpressionsConditionsConditionValueTimeValue gcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationConditionExpressionsConditionsConditionValueTimeValue:PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationConditionExpressionsConditionsConditionValueTimeValue9Represents a time of day.
Structure is documented below.
Ç
timestampValueB" ®A timestamp in RFC3339 UTC "Zulu" format, with nanosecond resolution and up to nine fractional digits. Examples: "2014-10-02T15:01:23Z" and "2014-10-02T15:01:23.045123456Z".
:À
¹
datalossPreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationConditionExpressionsConditionsConditionValueDateValue gcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationConditionExpressionsConditionsConditionValueDateValue:PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationConditionExpressionsConditionsConditionValueDateValue
þ²
dayB ¤Day of a month. Must be from 1 to 31 and valid for the year and month, or 0 to specify a year by itself or a year and month where the day isn't significant.

- - -
f
monthB WMonth of a year. Must be from 1 to 12, or 0 to specify a year without a month and day.
_
yearB QYear of the date. Must be from 1 to 9999, or 0 to specify a date without a year.
:
¹
datalossPreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationConditionExpressionsConditionsConditionValueTimeValue gcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationConditionExpressionsConditionsConditionValueTimeValue:PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationConditionExpressionsConditionsConditionValueTimeValueÊ
Ç¢
hoursB Hours of day in 24 hour format. Should be from 0 to 23. An API may choose to allow the value "24:00:00" for scenarios like business closing time.
?
minutesB .Minutes of hour of day. Must be from 0 to 59.
S
nanosB DFractions of seconds in nanoseconds. Must be from 0 to 999,999,999.

secondsB xSeconds of minutes of the time. Must normally be from 0 to 59. An API may allow the value 60 if it allows leap-seconds.
:Ú
¨
datalossYPreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationFieldÀgcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationField:PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationField-
+)
nameB" Name describing the field.
:
Þ
datalosskPreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationInfoTypeTransformationsägcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationInfoTypeTransformations:PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationInfoTypeTransformations¡

transformations*:

datalossyPreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationInfoTypeTransformationsTransformationgcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationInfoTypeTransformationsTransformation:PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationInfoTypeTransformationsTransformationtTransformation for each infoType. Cannot specify more than one for a given infoType.
Structure is documented below.
:Ý

datalossyPreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationInfoTypeTransformationsTransformationgcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationInfoTypeTransformationsTransformation:PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationInfoTypeTransformationsTransformationÏ

Ì

	infoTypes­Bª*§:¤
¡
datalossPreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationInfoTypeTransformationsTransformationInfoTypegcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationInfoTypeTransformationsTransformationInfoType:PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationInfoTypeTransformationsTransformationInfoTypeÖInfoTypes to apply the transformation to. Leaving this empty will apply the transformation to apply to
all findings that correspond to infoTypes that were requested in InspectConfig.
Structure is documented below.
²
primitiveTransformationÔ:Ñ
Î
datalossPreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationInfoTypeTransformationsTransformationPrimitiveTransformation®gcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationInfoTypeTransformationsTransformationPrimitiveTransformation:PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationInfoTypeTransformationsTransformationPrimitiveTransformation¿Apply the transformation to the entire field.
The `primitive_transformation` block must only contain one argument, corresponding to the type of transformation.
Structure is documented below.
:ð
¡
datalossPreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationInfoTypeTransformationsTransformationInfoTypegcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationInfoTypeTransformationsTransformationInfoType:PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationInfoTypeTransformationsTransformationInfoTypeÉ
Æ*
name" Name of the information type.
ä
sensitivityScoreÚB×:Ô
Ñ
datalossPreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationInfoTypeTransformationsTransformationInfoTypeSensitivityScore°gcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationInfoTypeTransformationsTransformationInfoTypeSensitivityScore:PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationInfoTypeTransformationsTransformationInfoTypeSensitivityScoresOptional custom sensitivity for this InfoType. This only applies to data profiling.
Structure is documented below.
1
versionB"  Version name for this InfoType.
:î
Ñ
datalossPreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationInfoTypeTransformationsTransformationInfoTypeSensitivityScore°gcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationInfoTypeTransformationsTransformationInfoTypeSensitivityScore:PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationInfoTypeTransformationsTransformationInfoTypeSensitivityScore

score" The sensitivity score applied to the resource.
Possible values are: `SENSITIVITY_LOW`, `SENSITIVITY_MODERATE`, `SENSITIVITY_HIGH`.
:ÚW
Î
datalossPreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationInfoTypeTransformationsTransformationPrimitiveTransformation®gcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationInfoTypeTransformationsTransformationPrimitiveTransformation:PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationInfoTypeTransformationsTransformationPrimitiveTransformationT
TÓ
bucketingConfigB:þ
û
datalossPreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationInfoTypeTransformationsTransformationPrimitiveTransformationBucketingConfigÌgcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationInfoTypeTransformationsTransformationPrimitiveTransformationBucketingConfig:PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationInfoTypeTransformationsTransformationPrimitiveTransformationBucketingConfig¸Generalization function that buckets values based on ranges. The ranges and replacement values are dynamically provided by the user for custom behavior, such as 1-30 > LOW 31-65 > MEDIUM 66-100 > HIGH
This can be used on data of type: number, long, string, timestamp.
If the provided value type differs from the type of data being transformed, we will first attempt converting the type of the data to be transformed to match the type of the bound before comparing.
See https://cloud.google.com/dlp/docs/concepts-bucketing to learn more.
Structure is documented below.
Ê
characterMaskConfigB:

dataloss£PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationInfoTypeTransformationsTransformationPrimitiveTransformationCharacterMaskConfigÔgcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationInfoTypeTransformationsTransformationPrimitiveTransformationCharacterMaskConfig:PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationInfoTypeTransformationsTransformationPrimitiveTransformationCharacterMaskConfigPartially mask a string by replacing a given number of characters with a fixed character. Masking can start from the beginning or end of the string. This can be used on data of any type (numbers, longs, and so on) and when de-identifying structured data we'll attempt to preserve the original data's type. (This allows you to take a long like 123 and modify it to a string like **3).
Structure is documented below.
â
cryptoDeterministicConfig¢B:

dataloss©PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationInfoTypeTransformationsTransformationPrimitiveTransformationCryptoDeterministicConfigàgcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationInfoTypeTransformationsTransformationPrimitiveTransformationCryptoDeterministicConfig:PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationInfoTypeTransformationsTransformationPrimitiveTransformationCryptoDeterministicConfigPseudonymization method that generates deterministic encryption for the given input. Outputs a base64 encoded representation of the encrypted output. Uses AES-SIV based on the RFC [https://tools.ietf.org/html/rfc5297](https://tools.ietf.org/html/rfc5297).
Structure is documented below.
¾
cryptoHashConfigB:
þ
dataloss PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationInfoTypeTransformationsTransformationPrimitiveTransformationCryptoHashConfigÎgcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationInfoTypeTransformationsTransformationPrimitiveTransformationCryptoHashConfig:PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationInfoTypeTransformationsTransformationPrimitiveTransformationCryptoHashConfigPseudonymization method that generates surrogates via cryptographic hashing. Uses SHA-256. The key size must be either 32 or 64 bytes.
Outputs a base64 encoded representation of the hashed output (for example, L7k0BHmF1ha5U3NfGykjro4xWi1MPVQPjhMAZbSV9mM=).
Currently, only string and integer values can be hashed.
See https://cloud.google.com/dlp/docs/pseudonymization to learn more.
Structure is documented below.

cryptoReplaceFfxFpeConfig¢B:

dataloss©PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationInfoTypeTransformationsTransformationPrimitiveTransformationCryptoReplaceFfxFpeConfigàgcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationInfoTypeTransformationsTransformationPrimitiveTransformationCryptoReplaceFfxFpeConfig:PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationInfoTypeTransformationsTransformationPrimitiveTransformationCryptoReplaceFfxFpeConfigÖReplaces an identifier with a surrogate using Format Preserving Encryption (FPE) with the FFX mode of operation; however when used in the `content.reidentify` API method, it serves the opposite function by reversing the surrogate back into the original identifier. The identifier must be encoded as ASCII. For a given crypto key and context, the same identifier will be replaced with the same surrogate. Identifiers must be at least two characters long. In the case that the identifier is the empty string, it will be skipped. See [https://cloud.google.com/dlp/docs/pseudonymization](https://cloud.google.com/dlp/docs/pseudonymization) to learn more.
Note: We recommend using CryptoDeterministicConfig for all use cases which do not require preserving the input alphabet space and size, plus warrant referential integrity.
Structure is documented below.
à
dateShiftConfigB:þ
û
datalossPreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationInfoTypeTransformationsTransformationPrimitiveTransformationDateShiftConfigÌgcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationInfoTypeTransformationsTransformationPrimitiveTransformationDateShiftConfig:PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationInfoTypeTransformationsTransformationPrimitiveTransformationDateShiftConfigÅShifts dates by random number of days, with option to be consistent for the same context. See https://cloud.google.com/dlp/docs/concepts-date-shifting to learn more.
Structure is documented below.
Î

fixedSizeBucketingConfigB:

dataloss¨PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationInfoTypeTransformationsTransformationPrimitiveTransformationFixedSizeBucketingConfigÞgcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationInfoTypeTransformationsTransformationPrimitiveTransformationFixedSizeBucketingConfig:PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationInfoTypeTransformationsTransformationPrimitiveTransformationFixedSizeBucketingConfigBuckets values based on fixed size ranges. The Bucketing transformation can provide all of this functionality, but requires more configuration. This message is provided as a convenience to the user for simple bucketing strategies.
The transformed value will be a hyphenated string of {lower_bound}-{upper_bound}. For example, if lower_bound = 10 and upper_bound = 20, all values that are within this bucket will be replaced with "10-20".
This can be used on data of type: double, long.
If the bound Value type differs from the type of data being transformed, we will first attempt converting the type of the data to be transformed to match the type of the bound before comparing.
See https://cloud.google.com/dlp/docs/concepts-bucketing to learn more.
Structure is documented below.
Ì
redactConfigûBø:õ
ò
datalossPreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationInfoTypeTransformationsTransformationPrimitiveTransformationRedactConfigÆgcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationInfoTypeTransformationsTransformationPrimitiveTransformationRedactConfig:PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationInfoTypeTransformationsTransformationPrimitiveTransformationRedactConfig½Redact a given value. For example, if used with an InfoTypeTransformation transforming PHONE_NUMBER, and input 'My phone number is 206-555-0123', the output would be 'My phone number is '.
Þ
replaceConfigþBû:ø
õ
datalossPreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationInfoTypeTransformationsTransformationPrimitiveTransformationReplaceConfigÈgcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationInfoTypeTransformationsTransformationPrimitiveTransformationReplaceConfig:PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationInfoTypeTransformationsTransformationPrimitiveTransformationReplaceConfigLReplace each input value with a given value.
Structure is documented below.
£
replaceDictionaryConfigB:

dataloss§PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationInfoTypeTransformationsTransformationPrimitiveTransformationReplaceDictionaryConfigÜgcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationInfoTypeTransformationsTransformationPrimitiveTransformationReplaceDictionaryConfig:PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationInfoTypeTransformationsTransformationPrimitiveTransformationReplaceDictionaryConfigiReplace with a value randomly drawn (with replacement) from a dictionary.
Structure is documented below.

replaceWithInfoTypeConfig¢B:

dataloss©PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationInfoTypeTransformationsTransformationPrimitiveTransformationReplaceWithInfoTypeConfigàgcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationInfoTypeTransformationsTransformationPrimitiveTransformationReplaceWithInfoTypeConfig:PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationInfoTypeTransformationsTransformationPrimitiveTransformationReplaceWithInfoTypeConfig>Replace each matching finding with the name of the info type.

timePartConfigBþ:û
ø
datalossPreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationInfoTypeTransformationsTransformationPrimitiveTransformationTimePartConfigÊgcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationInfoTypeTransformationsTransformationPrimitiveTransformationTimePartConfig:PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationInfoTypeTransformationsTransformationPrimitiveTransformationTimePartConfigxFor use with Date, Timestamp, and TimeOfDay, extract or preserve a portion of the value.
Structure is documented below.
:¼	
û
datalossPreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationInfoTypeTransformationsTransformationPrimitiveTransformationBucketingConfigÌgcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationInfoTypeTransformationsTransformationPrimitiveTransformationBucketingConfig:PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationInfoTypeTransformationsTransformationPrimitiveTransformationBucketingConfig»
¸µ
buckets*:

dataloss¥PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationInfoTypeTransformationsTransformationPrimitiveTransformationBucketingConfigBucketØgcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationInfoTypeTransformationsTransformationPrimitiveTransformationBucketingConfigBucket:PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationInfoTypeTransformationsTransformationPrimitiveTransformationBucketingConfigBucketSet of buckets. Ranges must be non-overlapping.
Bucket is represented as a range, along with replacement values.
Structure is documented below.
:¯

dataloss¥PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationInfoTypeTransformationsTransformationPrimitiveTransformationBucketingConfigBucketØgcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationInfoTypeTransformationsTransformationPrimitiveTransformationBucketingConfigBucket:PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationInfoTypeTransformationsTransformationPrimitiveTransformationBucketingConfigBucket

maxB:

dataloss¨PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationInfoTypeTransformationsTransformationPrimitiveTransformationBucketingConfigBucketMaxÞgcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationInfoTypeTransformationsTransformationPrimitiveTransformationBucketingConfigBucketMax:PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationInfoTypeTransformationsTransformationPrimitiveTransformationBucketingConfigBucketMaxçUpper bound of the range, exclusive; type must match min.
The `max` block must only contain one argument. See the `bucketing_config` block description for more information about choosing a data type.
Structure is documented below.
¤
minB:

dataloss¨PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationInfoTypeTransformationsTransformationPrimitiveTransformationBucketingConfigBucketMinÞgcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationInfoTypeTransformationsTransformationPrimitiveTransformationBucketingConfigBucketMin:PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationInfoTypeTransformationsTransformationPrimitiveTransformationBucketingConfigBucketMinúLower bound of the range, inclusive. Type should be the same as max if used.
The `min` block must only contain one argument. See the `bucketing_config` block description for more information about choosing a data type.
Structure is documented below.
Û
replacementValueÃ:À
½
datalossµPreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationInfoTypeTransformationsTransformationPrimitiveTransformationBucketingConfigBucketReplacementValueøgcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationInfoTypeTransformationsTransformationPrimitiveTransformationBucketingConfigBucketReplacementValue:PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationInfoTypeTransformationsTransformationPrimitiveTransformationBucketingConfigBucketReplacementValueReplacement value for this bucket.
The `replacement_value` block must only contain one argument.
Structure is documented below.
:©

dataloss¨PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationInfoTypeTransformationsTransformationPrimitiveTransformationBucketingConfigBucketMaxÞgcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationInfoTypeTransformationsTransformationPrimitiveTransformationBucketingConfigBucketMax:PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationInfoTypeTransformationsTransformationPrimitiveTransformationBucketingConfigBucketMax

	dateValueºB·:´
±
dataloss±PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationInfoTypeTransformationsTransformationPrimitiveTransformationBucketingConfigBucketMaxDateValueðgcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationInfoTypeTransformationsTransformationPrimitiveTransformationBucketingConfigBucketMaxDateValue:PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationInfoTypeTransformationsTransformationPrimitiveTransformationBucketingConfigBucketMaxDateValueLRepresents a whole or partial calendar date.
Structure is documented below.

dayOfWeekValueB" Represents a day of the week.
Possible values are: `MONDAY`, `TUESDAY`, `WEDNESDAY`, `THURSDAY`, `FRIDAY`, `SATURDAY`, `SUNDAY`.
#

floatValueB A float value.
6
integerValueB"  An integer value (int64 format)
%
stringValueB" A string value.

	timeValueºB·:´
±
dataloss±PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationInfoTypeTransformationsTransformationPrimitiveTransformationBucketingConfigBucketMaxTimeValueðgcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationInfoTypeTransformationsTransformationPrimitiveTransformationBucketingConfigBucketMaxTimeValue:PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationInfoTypeTransformationsTransformationPrimitiveTransformationBucketingConfigBucketMaxTimeValue9Represents a time of day.
Structure is documented below.
Ç
timestampValueB" ®A timestamp in RFC3339 UTC "Zulu" format, with nanosecond resolution and up to nine fractional digits. Examples: "2014-10-02T15:01:23Z" and "2014-10-02T15:01:23.045123456Z".
:¸
±
dataloss±PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationInfoTypeTransformationsTransformationPrimitiveTransformationBucketingConfigBucketMaxDateValueðgcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationInfoTypeTransformationsTransformationPrimitiveTransformationBucketingConfigBucketMaxDateValue:PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationInfoTypeTransformationsTransformationPrimitiveTransformationBucketingConfigBucketMaxDateValue
þ²
dayB ¤Day of a month. Must be from 1 to 31 and valid for the year and month, or 0 to specify a year by itself or a year and month where the day isn't significant.

- - -
f
monthB WMonth of a year. Must be from 1 to 12, or 0 to specify a year without a month and day.
_
yearB QYear of the date. Must be from 1 to 9999, or 0 to specify a date without a year.
:
±
dataloss±PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationInfoTypeTransformationsTransformationPrimitiveTransformationBucketingConfigBucketMaxTimeValueðgcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationInfoTypeTransformationsTransformationPrimitiveTransformationBucketingConfigBucketMaxTimeValue:PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationInfoTypeTransformationsTransformationPrimitiveTransformationBucketingConfigBucketMaxTimeValueÊ
Ç¢
hoursB Hours of day in 24 hour format. Should be from 0 to 23. An API may choose to allow the value "24:00:00" for scenarios like business closing time.
?
minutesB .Minutes of hour of day. Must be from 0 to 59.
S
nanosB DFractions of seconds in nanoseconds. Must be from 0 to 999,999,999.

secondsB xSeconds of minutes of the time. Must normally be from 0 to 59. An API may allow the value 60 if it allows leap-seconds.
:©

dataloss¨PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationInfoTypeTransformationsTransformationPrimitiveTransformationBucketingConfigBucketMinÞgcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationInfoTypeTransformationsTransformationPrimitiveTransformationBucketingConfigBucketMin:PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationInfoTypeTransformationsTransformationPrimitiveTransformationBucketingConfigBucketMin

	dateValueºB·:´
±
dataloss±PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationInfoTypeTransformationsTransformationPrimitiveTransformationBucketingConfigBucketMinDateValueðgcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationInfoTypeTransformationsTransformationPrimitiveTransformationBucketingConfigBucketMinDateValue:PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationInfoTypeTransformationsTransformationPrimitiveTransformationBucketingConfigBucketMinDateValueLRepresents a whole or partial calendar date.
Structure is documented below.

dayOfWeekValueB" Represents a day of the week.
Possible values are: `MONDAY`, `TUESDAY`, `WEDNESDAY`, `THURSDAY`, `FRIDAY`, `SATURDAY`, `SUNDAY`.
#

floatValueB A float value.
6
integerValueB"  An integer value (int64 format)
%
stringValueB" A string value.

	timeValueºB·:´
±
dataloss±PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationInfoTypeTransformationsTransformationPrimitiveTransformationBucketingConfigBucketMinTimeValueðgcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationInfoTypeTransformationsTransformationPrimitiveTransformationBucketingConfigBucketMinTimeValue:PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationInfoTypeTransformationsTransformationPrimitiveTransformationBucketingConfigBucketMinTimeValue9Represents a time of day.
Structure is documented below.
Ç
timestampValueB" ®A timestamp in RFC3339 UTC "Zulu" format, with nanosecond resolution and up to nine fractional digits. Examples: "2014-10-02T15:01:23Z" and "2014-10-02T15:01:23.045123456Z".
:¸
±
dataloss±PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationInfoTypeTransformationsTransformationPrimitiveTransformationBucketingConfigBucketMinDateValueðgcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationInfoTypeTransformationsTransformationPrimitiveTransformationBucketingConfigBucketMinDateValue:PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationInfoTypeTransformationsTransformationPrimitiveTransformationBucketingConfigBucketMinDateValue
þ²
dayB ¤Day of a month. Must be from 1 to 31 and valid for the year and month, or 0 to specify a year by itself or a year and month where the day isn't significant.

- - -
f
monthB WMonth of a year. Must be from 1 to 12, or 0 to specify a year without a month and day.
_
yearB QYear of the date. Must be from 1 to 9999, or 0 to specify a date without a year.
:
±
dataloss±PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationInfoTypeTransformationsTransformationPrimitiveTransformationBucketingConfigBucketMinTimeValueðgcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationInfoTypeTransformationsTransformationPrimitiveTransformationBucketingConfigBucketMinTimeValue:PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationInfoTypeTransformationsTransformationPrimitiveTransformationBucketingConfigBucketMinTimeValueÊ
Ç¢
hoursB Hours of day in 24 hour format. Should be from 0 to 23. An API may choose to allow the value "24:00:00" for scenarios like business closing time.
?
minutesB .Minutes of hour of day. Must be from 0 to 59.
S
nanosB DFractions of seconds in nanoseconds. Must be from 0 to 999,999,999.

secondsB xSeconds of minutes of the time. Must normally be from 0 to 59. An API may allow the value 60 if it allows leap-seconds.
:
½
datalossµPreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationInfoTypeTransformationsTransformationPrimitiveTransformationBucketingConfigBucketReplacementValueøgcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationInfoTypeTransformationsTransformationPrimitiveTransformationBucketingConfigBucketReplacementValue:PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationInfoTypeTransformationsTransformationPrimitiveTransformationBucketingConfigBucketReplacementValueÛ
Ø½
	dateValueáBÞ:Û
Ø
dataloss¾PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationInfoTypeTransformationsTransformationPrimitiveTransformationBucketingConfigBucketReplacementValueDateValuegcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationInfoTypeTransformationsTransformationPrimitiveTransformationBucketingConfigBucketReplacementValueDateValue:PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationInfoTypeTransformationsTransformationPrimitiveTransformationBucketingConfigBucketReplacementValueDateValueLRepresents a whole or partial calendar date.
Structure is documented below.

dayOfWeekValueB" Represents a day of the week.
Possible values are: `MONDAY`, `TUESDAY`, `WEDNESDAY`, `THURSDAY`, `FRIDAY`, `SATURDAY`, `SUNDAY`.
#

floatValueB A float value.
6
integerValueB"  An integer value (int64 format)
%
stringValueB" A string value.
ª
	timeValueáBÞ:Û
Ø
dataloss¾PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationInfoTypeTransformationsTransformationPrimitiveTransformationBucketingConfigBucketReplacementValueTimeValuegcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationInfoTypeTransformationsTransformationPrimitiveTransformationBucketingConfigBucketReplacementValueTimeValue:PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationInfoTypeTransformationsTransformationPrimitiveTransformationBucketingConfigBucketReplacementValueTimeValue9Represents a time of day.
Structure is documented below.
Ç
timestampValueB" ®A timestamp in RFC3339 UTC "Zulu" format, with nanosecond resolution and up to nine fractional digits. Examples: "2014-10-02T15:01:23Z" and "2014-10-02T15:01:23.045123456Z".
:ß
Ø
dataloss¾PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationInfoTypeTransformationsTransformationPrimitiveTransformationBucketingConfigBucketReplacementValueDateValuegcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationInfoTypeTransformationsTransformationPrimitiveTransformationBucketingConfigBucketReplacementValueDateValue:PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationInfoTypeTransformationsTransformationPrimitiveTransformationBucketingConfigBucketReplacementValueDateValue
þ²
dayB ¤Day of a month. Must be from 1 to 31 and valid for the year and month, or 0 to specify a year by itself or a year and month where the day isn't significant.

- - -
f
monthB WMonth of a year. Must be from 1 to 12, or 0 to specify a year without a month and day.
_
yearB QYear of the date. Must be from 1 to 9999, or 0 to specify a date without a year.
:¨
Ø
dataloss¾PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationInfoTypeTransformationsTransformationPrimitiveTransformationBucketingConfigBucketReplacementValueTimeValuegcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationInfoTypeTransformationsTransformationPrimitiveTransformationBucketingConfigBucketReplacementValueTimeValue:PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationInfoTypeTransformationsTransformationPrimitiveTransformationBucketingConfigBucketReplacementValueTimeValueÊ
Ç¢
hoursB Hours of day in 24 hour format. Should be from 0 to 23. An API may choose to allow the value "24:00:00" for scenarios like business closing time.
?
minutesB .Minutes of hour of day. Must be from 0 to 59.
S
nanosB DFractions of seconds in nanoseconds. Must be from 0 to 999,999,999.

secondsB xSeconds of minutes of the time. Must normally be from 0 to 59. An API may allow the value 60 if it allows leap-seconds.
:Ò

dataloss£PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationInfoTypeTransformationsTransformationPrimitiveTransformationCharacterMaskConfigÔgcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationInfoTypeTransformationsTransformationPrimitiveTransformationCharacterMaskConfig:PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationInfoTypeTransformationsTransformationPrimitiveTransformationCharacterMaskConfigÅ
Âå
charactersToIgnoresÉBÆ*Ã:À
½
datalossµPreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationInfoTypeTransformationsTransformationPrimitiveTransformationCharacterMaskConfigCharactersToIgnoreøgcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationInfoTypeTransformationsTransformationPrimitiveTransformationCharacterMaskConfigCharactersToIgnore:PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationInfoTypeTransformationsTransformationPrimitiveTransformationCharacterMaskConfigCharactersToIgnoreCharacters to skip when doing de-identification of a value. These will be left alone and skipped.
Structure is documented below.
³
maskingCharacterB" Character to use to mask the sensitive valuesâfor example, * for an alphabetic string such as a name, or 0 for a numeric string
such as ZIP code or credit card number. This string must have a length of 1. If not supplied, this value defaults to * for
strings, and 0 for digits.
¹
numberToMaskB ¢Number of characters to mask. If not set, all matching chars will be masked. Skipped characters do not count towards this tally.
If number_to_mask is negative, this denotes inverse masking. Cloud DLP masks all but a number of characters. For example, suppose you have the following values:
å
reverseOrderB
 ÎMask characters in reverse order. For example, if masking_character is 0, number_to_mask is 14, and reverse_order is `false`, then the
input string `1234-5678-9012-3456` is masked as `00000000000000-3456`.
:ð
½
datalossµPreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationInfoTypeTransformationsTransformationPrimitiveTransformationCharacterMaskConfigCharactersToIgnoreøgcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationInfoTypeTransformationsTransformationPrimitiveTransformationCharacterMaskConfigCharactersToIgnore:PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationInfoTypeTransformationsTransformationPrimitiveTransformationCharacterMaskConfigCharactersToIgnore­
ª
charactersToSkipB" oCharacters to not transform when masking. Only one of this or `common_characters_to_ignore` must be specified.

commonCharactersToIgnoreB" øCommon characters to not transform when masking. Useful to avoid removing punctuation. Only one of this or `characters_to_skip` must be specified.
Possible values are: `NUMERIC`, `ALPHA_UPPER_CASE`, `ALPHA_LOWER_CASE`, `PUNCTUATION`, `WHITESPACE`.
:'

dataloss©PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationInfoTypeTransformationsTransformationPrimitiveTransformationCryptoDeterministicConfigàgcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationInfoTypeTransformationsTransformationPrimitiveTransformationCryptoDeterministicConfig:PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationInfoTypeTransformationsTransformationPrimitiveTransformationCryptoDeterministicConfigø"
õ"
context·B´:±
®
dataloss°PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationInfoTypeTransformationsTransformationPrimitiveTransformationCryptoDeterministicConfigContextîgcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationInfoTypeTransformationsTransformationPrimitiveTransformationCryptoDeterministicConfigContext:PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationInfoTypeTransformationsTransformationPrimitiveTransformationCryptoDeterministicConfigContextÒA context may be used for higher security and maintaining referential integrity such that the same identifier in two different contexts will be given a distinct surrogate. The context is appended to plaintext value being encrypted. On decryption the provided context is validated against the value used during encryption. If a context was provided during encryption, same context must be provided during decryption as well.
If the context is not set, plaintext would be used as is for encryption. If the context is set but:
1. there is no record present when transforming a given value or
2. the field is not present when transforming a given value,
plaintext would be used as is for encryption.
Note that case (1) is expected when an InfoTypeTransformation is applied to both structured and unstructured ContentItems.
Structure is documented below.

	cryptoKeyº:·
´
dataloss²PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationInfoTypeTransformationsTransformationPrimitiveTransformationCryptoDeterministicConfigCryptoKeyògcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationInfoTypeTransformationsTransformationPrimitiveTransformationCryptoDeterministicConfigCryptoKey:PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationInfoTypeTransformationsTransformationPrimitiveTransformationCryptoDeterministicConfigCryptoKey¶The key used by the encryption function. For deterministic encryption using AES-SIV, the provided key is internally expanded to 64 bytes prior to use.
Structure is documented below.
Ó
surrogateInfoTypeÒ:Ï
Ì
datalossºPreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationInfoTypeTransformationsTransformationPrimitiveTransformationCryptoDeterministicConfigSurrogateInfoTypegcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationInfoTypeTransformationsTransformationPrimitiveTransformationCryptoDeterministicConfigSurrogateInfoType:PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationInfoTypeTransformationsTransformationPrimitiveTransformationCryptoDeterministicConfigSurrogateInfoTypeèThe custom info type to annotate the surrogate with. This annotation will be applied to the surrogate by prefixing it with the name of the custom info type followed by the number of characters comprising the surrogate. The following scheme defines the format: {info type name}({surrogate character count}):{surrogate}
For example, if the name of custom info type is 'MY\_TOKEN\_INFO\_TYPE' and the surrogate is 'abc', the full replacement value will be: 'MY\_TOKEN\_INFO\_TYPE(3):abc'
This annotation identifies the surrogate when inspecting content using the custom info type 'Surrogate'. This facilitates reversal of the surrogate when it occurs in free text.
Note: For record transformations where the entire cell in a table is being transformed, surrogates are not mandatory. Surrogates are used to denote the location of the token and are necessary for re-identification in free form text.
In order for inspection to work properly, the name of this info type must not occur naturally anywhere in your data; otherwise, inspection may either
*   reverse a surrogate that does not correspond to an actual identifier
*   be unable to parse the surrogate and result in an error
Therefore, choose your custom info type name carefully after considering what your data looks like. One way to select a name that has a high chance of yielding reliable detection is to include one or more unicode characters that are highly improbable to exist in your data. For example, assuming your data is entered from a regular ASCII keyboard, the symbol with the hex code point 29DD might be used like so: â§MY\_TOKEN\_TYPE.
Structure is documented below.
:Þ
®
dataloss°PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationInfoTypeTransformationsTransformationPrimitiveTransformationCryptoDeterministicConfigContextîgcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationInfoTypeTransformationsTransformationPrimitiveTransformationCryptoDeterministicConfigContext:PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationInfoTypeTransformationsTransformationPrimitiveTransformationCryptoDeterministicConfigContext+
)'
name" Name describing the field.
:¬
´
dataloss²PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationInfoTypeTransformationsTransformationPrimitiveTransformationCryptoDeterministicConfigCryptoKeyògcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationInfoTypeTransformationsTransformationPrimitiveTransformationCryptoDeterministicConfigCryptoKey:PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationInfoTypeTransformationsTransformationPrimitiveTransformationCryptoDeterministicConfigCryptoKeyò
ïÉ	

kmsWrappedÛBØ:Õ
Ò
dataloss¼PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationInfoTypeTransformationsTransformationPrimitiveTransformationCryptoDeterministicConfigCryptoKeyKmsWrappedgcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationInfoTypeTransformationsTransformationPrimitiveTransformationCryptoDeterministicConfigCryptoKeyKmsWrapped:PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationInfoTypeTransformationsTransformationPrimitiveTransformationCryptoDeterministicConfigCryptoKeyKmsWrappedÜKMS wrapped key.
Include to use an existing data crypto key wrapped by KMS. The wrapped key must be a 128-, 192-, or 256-bit key. Authorization requires the following IAM permissions when sending a request to perform a crypto transformation using a KMS-wrapped crypto key: dlp.kms.encrypt
For more information, see [Creating a wrapped key](https://cloud.google.com/dlp/docs/create-wrapped-key). Only one of this, `transient` or `unwrapped` must be specified.
Note: When you use Cloud KMS for cryptographic operations, [charges apply](https://cloud.google.com/kms/pricing).
Structure is documented below.
Æ
	transientØBÕ:Ò
Ï
dataloss»PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationInfoTypeTransformationsTransformationPrimitiveTransformationCryptoDeterministicConfigCryptoKeyTransientgcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationInfoTypeTransformationsTransformationPrimitiveTransformationCryptoDeterministicConfigCryptoKeyTransient:PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationInfoTypeTransformationsTransformationPrimitiveTransformationCryptoDeterministicConfigCryptoKeyTransientÝTransient crypto key. Use this to have a random data crypto key generated. It will be discarded after the request finishes. Only one of this, `unwrapped` or `kms_wrapped` must be specified.
Structure is documented below.
×
	unwrappedØBÕ:Ò
Ï
dataloss»PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationInfoTypeTransformationsTransformationPrimitiveTransformationCryptoDeterministicConfigCryptoKeyUnwrappedgcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationInfoTypeTransformationsTransformationPrimitiveTransformationCryptoDeterministicConfigCryptoKeyUnwrapped:PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationInfoTypeTransformationsTransformationPrimitiveTransformationCryptoDeterministicConfigCryptoKeyUnwrappedîUnwrapped crypto key. Using raw keys is prone to security risks due to accidentally leaking the key. Choose another type of key if possible. Only one of this, `transient` or `kms_wrapped` must be specified.
Structure is documented below.
:ú
Ò
dataloss¼PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationInfoTypeTransformationsTransformationPrimitiveTransformationCryptoDeterministicConfigCryptoKeyKmsWrappedgcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationInfoTypeTransformationsTransformationPrimitiveTransformationCryptoDeterministicConfigCryptoKeyKmsWrapped:PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationInfoTypeTransformationsTransformationPrimitiveTransformationCryptoDeterministicConfigCryptoKeyKmsWrapped¢
S
cryptoKeyName" >The resource name of the KMS CryptoKey to use for unwrapping.
H

wrappedKey" 6The wrapped data crypto key.
A base64-encoded string.
:Ó
Ï
dataloss»PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationInfoTypeTransformationsTransformationPrimitiveTransformationCryptoDeterministicConfigCryptoKeyTransientgcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationInfoTypeTransformationsTransformationPrimitiveTransformationCryptoDeterministicConfigCryptoKeyTransient:PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationInfoTypeTransformationsTransformationPrimitiveTransformationCryptoDeterministicConfigCryptoKeyTransientþ
ûø
name" ëName of the key. This is an arbitrary string used to differentiate different keys. A unique key is generated per name: two separate `TransientCryptoKey` protos share the same generated key if their names are the same. When the data crypto key is generated, this name is not used in any way (repeating the api call will result in a different key being generated).
:â
Ï
dataloss»PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationInfoTypeTransformationsTransformationPrimitiveTransformationCryptoDeterministicConfigCryptoKeyUnwrappedgcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationInfoTypeTransformationsTransformationPrimitiveTransformationCryptoDeterministicConfigCryptoKeyUnwrapped:PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationInfoTypeTransformationsTransformationPrimitiveTransformationCryptoDeterministicConfigCryptoKeyUnwrapped

key" |A 128/192/256 bit key.
A base64-encoded string.
**Note**: This property is sensitive and will not be displayed in the plan.
:³
Ì
datalossºPreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationInfoTypeTransformationsTransformationPrimitiveTransformationCryptoDeterministicConfigSurrogateInfoTypegcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationInfoTypeTransformationsTransformationPrimitiveTransformationCryptoDeterministicConfigSurrogateInfoType:PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationInfoTypeTransformationsTransformationPrimitiveTransformationCryptoDeterministicConfigSurrogateInfoTypeá	
Þ	
name" Name of the information type. Either a name of your choosing when creating a CustomInfoType, or one of the names listed at [https://cloud.google.com/dlp/docs/infotypes-reference](https://cloud.google.com/dlp/docs/infotypes-reference) when specifying a built-in type. When sending Cloud DLP results to Data Catalog, infoType names should conform to the pattern `[A-Za-z0-9$-_]{1,64}`.

sensitivityScoreB:ÿ
ü
datalossÊPreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationInfoTypeTransformationsTransformationPrimitiveTransformationCryptoDeterministicConfigSurrogateInfoTypeSensitivityScore¢gcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationInfoTypeTransformationsTransformationPrimitiveTransformationCryptoDeterministicConfigSurrogateInfoTypeSensitivityScore:PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationInfoTypeTransformationsTransformationPrimitiveTransformationCryptoDeterministicConfigSurrogateInfoTypeSensitivityScoresOptional custom sensitivity for this InfoType. This only applies to data profiling.
Structure is documented below.
:
versionB" )Optional version name for this InfoType.
:
ü
datalossÊPreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationInfoTypeTransformationsTransformationPrimitiveTransformationCryptoDeterministicConfigSurrogateInfoTypeSensitivityScore¢gcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationInfoTypeTransformationsTransformationPrimitiveTransformationCryptoDeterministicConfigSurrogateInfoTypeSensitivityScore:PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationInfoTypeTransformationsTransformationPrimitiveTransformationCryptoDeterministicConfigSurrogateInfoTypeSensitivityScore

score" The sensitivity score applied to the resource.
Possible values are: `SENSITIVITY_LOW`, `SENSITIVITY_MODERATE`, `SENSITIVITY_HIGH`.
:	
þ
dataloss PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationInfoTypeTransformationsTransformationPrimitiveTransformationCryptoHashConfigÎgcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationInfoTypeTransformationsTransformationPrimitiveTransformationCryptoHashConfig:PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationInfoTypeTransformationsTransformationPrimitiveTransformationCryptoHashConfigý
ú÷
	cryptoKey:

dataloss©PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationInfoTypeTransformationsTransformationPrimitiveTransformationCryptoHashConfigCryptoKeyàgcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationInfoTypeTransformationsTransformationPrimitiveTransformationCryptoHashConfigCryptoKey:PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationInfoTypeTransformationsTransformationPrimitiveTransformationCryptoHashConfigCryptoKeyHThe key used by the encryption function.
Structure is documented below.
:À

dataloss©PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationInfoTypeTransformationsTransformationPrimitiveTransformationCryptoHashConfigCryptoKeyàgcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationInfoTypeTransformationsTransformationPrimitiveTransformationCryptoHashConfigCryptoKey:PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationInfoTypeTransformationsTransformationPrimitiveTransformationCryptoHashConfigCryptoKey¡
®	

kmsWrappedÀB½:º
·
dataloss³PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationInfoTypeTransformationsTransformationPrimitiveTransformationCryptoHashConfigCryptoKeyKmsWrappedôgcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationInfoTypeTransformationsTransformationPrimitiveTransformationCryptoHashConfigCryptoKeyKmsWrapped:PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationInfoTypeTransformationsTransformationPrimitiveTransformationCryptoHashConfigCryptoKeyKmsWrappedÜKMS wrapped key.
Include to use an existing data crypto key wrapped by KMS. The wrapped key must be a 128-, 192-, or 256-bit key. Authorization requires the following IAM permissions when sending a request to perform a crypto transformation using a KMS-wrapped crypto key: dlp.kms.encrypt
For more information, see [Creating a wrapped key](https://cloud.google.com/dlp/docs/create-wrapped-key). Only one of this, `transient` or `unwrapped` must be specified.
Note: When you use Cloud KMS for cryptographic operations, [charges apply](https://cloud.google.com/kms/pricing).
Structure is documented below.
«
	transient½Bº:·
´
dataloss²PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationInfoTypeTransformationsTransformationPrimitiveTransformationCryptoHashConfigCryptoKeyTransientògcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationInfoTypeTransformationsTransformationPrimitiveTransformationCryptoHashConfigCryptoKeyTransient:PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationInfoTypeTransformationsTransformationPrimitiveTransformationCryptoHashConfigCryptoKeyTransientÝTransient crypto key. Use this to have a random data crypto key generated. It will be discarded after the request finishes. Only one of this, `unwrapped` or `kms_wrapped` must be specified.
Structure is documented below.
¼
	unwrapped½Bº:·
´
dataloss²PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationInfoTypeTransformationsTransformationPrimitiveTransformationCryptoHashConfigCryptoKeyUnwrappedògcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationInfoTypeTransformationsTransformationPrimitiveTransformationCryptoHashConfigCryptoKeyUnwrapped:PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationInfoTypeTransformationsTransformationPrimitiveTransformationCryptoHashConfigCryptoKeyUnwrappedîUnwrapped crypto key. Using raw keys is prone to security risks due to accidentally leaking the key. Choose another type of key if possible. Only one of this, `transient` or `kms_wrapped` must be specified.
Structure is documented below.
:ß
·
dataloss³PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationInfoTypeTransformationsTransformationPrimitiveTransformationCryptoHashConfigCryptoKeyKmsWrappedôgcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationInfoTypeTransformationsTransformationPrimitiveTransformationCryptoHashConfigCryptoKeyKmsWrapped:PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationInfoTypeTransformationsTransformationPrimitiveTransformationCryptoHashConfigCryptoKeyKmsWrapped¢
S
cryptoKeyName" >The resource name of the KMS CryptoKey to use for unwrapping.
H

wrappedKey" 6The wrapped data crypto key.
A base64-encoded string.
:¸
´
dataloss²PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationInfoTypeTransformationsTransformationPrimitiveTransformationCryptoHashConfigCryptoKeyTransientògcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationInfoTypeTransformationsTransformationPrimitiveTransformationCryptoHashConfigCryptoKeyTransient:PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationInfoTypeTransformationsTransformationPrimitiveTransformationCryptoHashConfigCryptoKeyTransientþ
ûø
name" ëName of the key. This is an arbitrary string used to differentiate different keys. A unique key is generated per name: two separate `TransientCryptoKey` protos share the same generated key if their names are the same. When the data crypto key is generated, this name is not used in any way (repeating the api call will result in a different key being generated).
:Ç
´
dataloss²PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationInfoTypeTransformationsTransformationPrimitiveTransformationCryptoHashConfigCryptoKeyUnwrappedògcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationInfoTypeTransformationsTransformationPrimitiveTransformationCryptoHashConfigCryptoKeyUnwrapped:PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationInfoTypeTransformationsTransformationPrimitiveTransformationCryptoHashConfigCryptoKeyUnwrapped

key" |A 128/192/256 bit key.
A base64-encoded string.
**Note**: This property is sensitive and will not be displayed in the plan.
:â+

dataloss©PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationInfoTypeTransformationsTransformationPrimitiveTransformationCryptoReplaceFfxFpeConfigàgcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationInfoTypeTransformationsTransformationPrimitiveTransformationCryptoReplaceFfxFpeConfig:PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationInfoTypeTransformationsTransformationPrimitiveTransformationCryptoReplaceFfxFpeConfigÃ'
À'É
commonAlphabetB" °Common alphabets. Only one of this, `custom_alphabet` or `radix` must be specified.
Possible values are: `NUMERIC`, `HEXADECIMAL`, `UPPER_CASE_ALPHA_NUMERIC`, `ALPHA_NUMERIC`.

context·B´:±
®
dataloss°PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationInfoTypeTransformationsTransformationPrimitiveTransformationCryptoReplaceFfxFpeConfigContextîgcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationInfoTypeTransformationsTransformationPrimitiveTransformationCryptoReplaceFfxFpeConfigContext:PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationInfoTypeTransformationsTransformationPrimitiveTransformationCryptoReplaceFfxFpeConfigContextÎThe 'tweak', a context may be used for higher security since the same identifier in two different contexts won't be given the same surrogate. If the context is not set, a default tweak will be used.
If the context is set but:
1.  there is no record present when transforming a given value or
2.  the field is not present when transforming a given value,
a default tweak will be used.
Note that case (1) is expected when an `InfoTypeTransformation` is applied to both structured and non-structured `ContentItem`s. Currently, the referenced field may be of value type integer or string.
The tweak is constructed as a sequence of bytes in big endian byte order such that:
*   a 64 bit integer is encoded followed by a single byte of value 1
*   a string is encoded in UTF-8 format followed by a single byte of value 2
Structure is documented below.

	cryptoKeyº:·
´
dataloss²PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationInfoTypeTransformationsTransformationPrimitiveTransformationCryptoReplaceFfxFpeConfigCryptoKeyògcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationInfoTypeTransformationsTransformationPrimitiveTransformationCryptoReplaceFfxFpeConfigCryptoKey:PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationInfoTypeTransformationsTransformationPrimitiveTransformationCryptoReplaceFfxFpeConfigCryptoKeyIThe key used by the encryption algorithm.
Structure is documented below.
©
customAlphabetB" This is supported by mapping these to the alphanumeric characters that the FFX mode natively supports. This happens before/after encryption/decryption. Each character listed must appear only once. Number of characters must be in the range \[2, 95\]. This must be encoded as ASCII. The order of characters does not matter. The full list of allowed characters is:
``0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz ~`!@#$%^&*()_-+={[}]|:;"'<,>.?/``. Only one of this, `common_alphabet` or `radix` must be specified.
£
radixB The native way to select the alphabet. Must be in the range \[2, 95\]. Only one of this, `custom_alphabet` or `common_alphabet` must be specified.
ò
surrogateInfoTypeÕBÒ:Ï
Ì
datalossºPreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationInfoTypeTransformationsTransformationPrimitiveTransformationCryptoReplaceFfxFpeConfigSurrogateInfoTypegcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationInfoTypeTransformationsTransformationPrimitiveTransformationCryptoReplaceFfxFpeConfigSurrogateInfoType:PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationInfoTypeTransformationsTransformationPrimitiveTransformationCryptoReplaceFfxFpeConfigSurrogateInfoTypeThe custom infoType to annotate the surrogate with. This annotation will be applied to the surrogate by prefixing it with the name of the custom infoType followed by the number of characters comprising the surrogate. The following scheme defines the format: info\_type\_name(surrogate\_character\_count):surrogate
For example, if the name of custom infoType is 'MY\_TOKEN\_INFO\_TYPE' and the surrogate is 'abc', the full replacement value will be: 'MY\_TOKEN\_INFO\_TYPE(3):abc'
This annotation identifies the surrogate when inspecting content using the custom infoType [`SurrogateType`](https://cloud.google.com/dlp/docs/reference/rest/v2/InspectConfig#surrogatetype). This facilitates reversal of the surrogate when it occurs in free text.
In order for inspection to work properly, the name of this infoType must not occur naturally anywhere in your data; otherwise, inspection may find a surrogate that does not correspond to an actual identifier. Therefore, choose your custom infoType name carefully after considering what your data looks like. One way to select a name that has a high chance of yielding reliable detection is to include one or more unicode characters that are highly improbable to exist in your data. For example, assuming your data is entered from a regular ASCII keyboard, the symbol with the hex code point 29DD might be used like so: â§MY\_TOKEN\_TYPE
Structure is documented below.
:Þ
®
dataloss°PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationInfoTypeTransformationsTransformationPrimitiveTransformationCryptoReplaceFfxFpeConfigContextîgcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationInfoTypeTransformationsTransformationPrimitiveTransformationCryptoReplaceFfxFpeConfigContext:PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationInfoTypeTransformationsTransformationPrimitiveTransformationCryptoReplaceFfxFpeConfigContext+
)'
name" Name describing the field.
:¬
´
dataloss²PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationInfoTypeTransformationsTransformationPrimitiveTransformationCryptoReplaceFfxFpeConfigCryptoKeyògcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationInfoTypeTransformationsTransformationPrimitiveTransformationCryptoReplaceFfxFpeConfigCryptoKey:PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationInfoTypeTransformationsTransformationPrimitiveTransformationCryptoReplaceFfxFpeConfigCryptoKeyò
ïÉ	

kmsWrappedÛBØ:Õ
Ò
dataloss¼PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationInfoTypeTransformationsTransformationPrimitiveTransformationCryptoReplaceFfxFpeConfigCryptoKeyKmsWrappedgcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationInfoTypeTransformationsTransformationPrimitiveTransformationCryptoReplaceFfxFpeConfigCryptoKeyKmsWrapped:PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationInfoTypeTransformationsTransformationPrimitiveTransformationCryptoReplaceFfxFpeConfigCryptoKeyKmsWrappedÜKMS wrapped key.
Include to use an existing data crypto key wrapped by KMS. The wrapped key must be a 128-, 192-, or 256-bit key. Authorization requires the following IAM permissions when sending a request to perform a crypto transformation using a KMS-wrapped crypto key: dlp.kms.encrypt
For more information, see [Creating a wrapped key](https://cloud.google.com/dlp/docs/create-wrapped-key). Only one of this, `transient` or `unwrapped` must be specified.
Note: When you use Cloud KMS for cryptographic operations, [charges apply](https://cloud.google.com/kms/pricing).
Structure is documented below.
Æ
	transientØBÕ:Ò
Ï
dataloss»PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationInfoTypeTransformationsTransformationPrimitiveTransformationCryptoReplaceFfxFpeConfigCryptoKeyTransientgcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationInfoTypeTransformationsTransformationPrimitiveTransformationCryptoReplaceFfxFpeConfigCryptoKeyTransient:PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationInfoTypeTransformationsTransformationPrimitiveTransformationCryptoReplaceFfxFpeConfigCryptoKeyTransientÝTransient crypto key. Use this to have a random data crypto key generated. It will be discarded after the request finishes. Only one of this, `unwrapped` or `kms_wrapped` must be specified.
Structure is documented below.
×
	unwrappedØBÕ:Ò
Ï
dataloss»PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationInfoTypeTransformationsTransformationPrimitiveTransformationCryptoReplaceFfxFpeConfigCryptoKeyUnwrappedgcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationInfoTypeTransformationsTransformationPrimitiveTransformationCryptoReplaceFfxFpeConfigCryptoKeyUnwrapped:PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationInfoTypeTransformationsTransformationPrimitiveTransformationCryptoReplaceFfxFpeConfigCryptoKeyUnwrappedîUnwrapped crypto key. Using raw keys is prone to security risks due to accidentally leaking the key. Choose another type of key if possible. Only one of this, `transient` or `kms_wrapped` must be specified.
Structure is documented below.
:ú
Ò
dataloss¼PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationInfoTypeTransformationsTransformationPrimitiveTransformationCryptoReplaceFfxFpeConfigCryptoKeyKmsWrappedgcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationInfoTypeTransformationsTransformationPrimitiveTransformationCryptoReplaceFfxFpeConfigCryptoKeyKmsWrapped:PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationInfoTypeTransformationsTransformationPrimitiveTransformationCryptoReplaceFfxFpeConfigCryptoKeyKmsWrapped¢
S
cryptoKeyName" >The resource name of the KMS CryptoKey to use for unwrapping.
H

wrappedKey" 6The wrapped data crypto key.
A base64-encoded string.
:Ó
Ï
dataloss»PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationInfoTypeTransformationsTransformationPrimitiveTransformationCryptoReplaceFfxFpeConfigCryptoKeyTransientgcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationInfoTypeTransformationsTransformationPrimitiveTransformationCryptoReplaceFfxFpeConfigCryptoKeyTransient:PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationInfoTypeTransformationsTransformationPrimitiveTransformationCryptoReplaceFfxFpeConfigCryptoKeyTransientþ
ûø
name" ëName of the key. This is an arbitrary string used to differentiate different keys. A unique key is generated per name: two separate `TransientCryptoKey` protos share the same generated key if their names are the same. When the data crypto key is generated, this name is not used in any way (repeating the api call will result in a different key being generated).
:â
Ï
dataloss»PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationInfoTypeTransformationsTransformationPrimitiveTransformationCryptoReplaceFfxFpeConfigCryptoKeyUnwrappedgcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationInfoTypeTransformationsTransformationPrimitiveTransformationCryptoReplaceFfxFpeConfigCryptoKeyUnwrapped:PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationInfoTypeTransformationsTransformationPrimitiveTransformationCryptoReplaceFfxFpeConfigCryptoKeyUnwrapped

key" |A 128/192/256 bit key.
A base64-encoded string.
**Note**: This property is sensitive and will not be displayed in the plan.
:³
Ì
datalossºPreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationInfoTypeTransformationsTransformationPrimitiveTransformationCryptoReplaceFfxFpeConfigSurrogateInfoTypegcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationInfoTypeTransformationsTransformationPrimitiveTransformationCryptoReplaceFfxFpeConfigSurrogateInfoType:PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationInfoTypeTransformationsTransformationPrimitiveTransformationCryptoReplaceFfxFpeConfigSurrogateInfoTypeá	
Þ	
name" Name of the information type. Either a name of your choosing when creating a CustomInfoType, or one of the names listed at [https://cloud.google.com/dlp/docs/infotypes-reference](https://cloud.google.com/dlp/docs/infotypes-reference) when specifying a built-in type. When sending Cloud DLP results to Data Catalog, infoType names should conform to the pattern `[A-Za-z0-9$-_]{1,64}`.

sensitivityScoreB:ÿ
ü
datalossÊPreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationInfoTypeTransformationsTransformationPrimitiveTransformationCryptoReplaceFfxFpeConfigSurrogateInfoTypeSensitivityScore¢gcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationInfoTypeTransformationsTransformationPrimitiveTransformationCryptoReplaceFfxFpeConfigSurrogateInfoTypeSensitivityScore:PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationInfoTypeTransformationsTransformationPrimitiveTransformationCryptoReplaceFfxFpeConfigSurrogateInfoTypeSensitivityScoresOptional custom sensitivity for this InfoType. This only applies to data profiling.
Structure is documented below.
:
versionB" )Optional version name for this InfoType.
:
ü
datalossÊPreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationInfoTypeTransformationsTransformationPrimitiveTransformationCryptoReplaceFfxFpeConfigSurrogateInfoTypeSensitivityScore¢gcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationInfoTypeTransformationsTransformationPrimitiveTransformationCryptoReplaceFfxFpeConfigSurrogateInfoTypeSensitivityScore:PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationInfoTypeTransformationsTransformationPrimitiveTransformationCryptoReplaceFfxFpeConfigSurrogateInfoTypeSensitivityScore

score" The sensitivity score applied to the resource.
Possible values are: `SENSITIVITY_LOW`, `SENSITIVITY_MODERATE`, `SENSITIVITY_HIGH`.
:
û
datalossPreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationInfoTypeTransformationsTransformationPrimitiveTransformationDateShiftConfigÌgcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationInfoTypeTransformationsTransformationPrimitiveTransformationDateShiftConfig:PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationInfoTypeTransformationsTransformationPrimitiveTransformationDateShiftConfig
ê
contextB:

dataloss¦PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationInfoTypeTransformationsTransformationPrimitiveTransformationDateShiftConfigContextÚgcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationInfoTypeTransformationsTransformationPrimitiveTransformationDateShiftConfigContext:PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationInfoTypeTransformationsTransformationPrimitiveTransformationDateShiftConfigContextÂPoints to the field that contains the context, for example, an entity id.
If set, must also set cryptoKey. If set, shift will be consistent for the given context.
Structure is documented below.

	cryptoKeyB:

dataloss¨PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationInfoTypeTransformationsTransformationPrimitiveTransformationDateShiftConfigCryptoKeyÞgcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationInfoTypeTransformationsTransformationPrimitiveTransformationDateShiftConfigCryptoKey:PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationInfoTypeTransformationsTransformationPrimitiveTransformationDateShiftConfigCryptoKeyèCauses the shift to be computed based on this key and the context. This results in the same shift for the same context and cryptoKey. If set, must also set context. Can only be applied to table items.
Structure is documented below.
[
lowerBoundDays EFor example, -5 means shift date to at most 5 days back in the past.
¦
upperBoundDays Range of shift in days. Actual shift will be selected at random within this range (inclusive ends). Negative means shift to earlier in time. Must not be more than 365250 days (1000 years) each direction.
For example, 3 means shift date to at most 3 days into the future.
:À

dataloss¦PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationInfoTypeTransformationsTransformationPrimitiveTransformationDateShiftConfigContextÚgcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationInfoTypeTransformationsTransformationPrimitiveTransformationDateShiftConfigContext:PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationInfoTypeTransformationsTransformationPrimitiveTransformationDateShiftConfigContext+
)'
name" Name describing the field.
:´

dataloss¨PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationInfoTypeTransformationsTransformationPrimitiveTransformationDateShiftConfigCryptoKeyÞgcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationInfoTypeTransformationsTransformationPrimitiveTransformationDateShiftConfigCryptoKey:PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationInfoTypeTransformationsTransformationPrimitiveTransformationDateShiftConfigCryptoKey
«	

kmsWrapped½Bº:·
´
dataloss²PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationInfoTypeTransformationsTransformationPrimitiveTransformationDateShiftConfigCryptoKeyKmsWrappedògcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationInfoTypeTransformationsTransformationPrimitiveTransformationDateShiftConfigCryptoKeyKmsWrapped:PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationInfoTypeTransformationsTransformationPrimitiveTransformationDateShiftConfigCryptoKeyKmsWrappedÜKMS wrapped key.
Include to use an existing data crypto key wrapped by KMS. The wrapped key must be a 128-, 192-, or 256-bit key. Authorization requires the following IAM permissions when sending a request to perform a crypto transformation using a KMS-wrapped crypto key: dlp.kms.encrypt
For more information, see [Creating a wrapped key](https://cloud.google.com/dlp/docs/create-wrapped-key). Only one of this, `transient` or `unwrapped` must be specified.
Note: When you use Cloud KMS for cryptographic operations, [charges apply](https://cloud.google.com/kms/pricing).
Structure is documented below.
¨
	transientºB·:´
±
dataloss±PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationInfoTypeTransformationsTransformationPrimitiveTransformationDateShiftConfigCryptoKeyTransientðgcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationInfoTypeTransformationsTransformationPrimitiveTransformationDateShiftConfigCryptoKeyTransient:PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationInfoTypeTransformationsTransformationPrimitiveTransformationDateShiftConfigCryptoKeyTransientÝTransient crypto key. Use this to have a random data crypto key generated. It will be discarded after the request finishes. Only one of this, `unwrapped` or `kms_wrapped` must be specified.
Structure is documented below.
¹
	unwrappedºB·:´
±
dataloss±PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationInfoTypeTransformationsTransformationPrimitiveTransformationDateShiftConfigCryptoKeyUnwrappedðgcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationInfoTypeTransformationsTransformationPrimitiveTransformationDateShiftConfigCryptoKeyUnwrapped:PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationInfoTypeTransformationsTransformationPrimitiveTransformationDateShiftConfigCryptoKeyUnwrappedîUnwrapped crypto key. Using raw keys is prone to security risks due to accidentally leaking the key. Choose another type of key if possible. Only one of this, `transient` or `kms_wrapped` must be specified.
Structure is documented below.
:Ü
´
dataloss²PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationInfoTypeTransformationsTransformationPrimitiveTransformationDateShiftConfigCryptoKeyKmsWrappedògcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationInfoTypeTransformationsTransformationPrimitiveTransformationDateShiftConfigCryptoKeyKmsWrapped:PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationInfoTypeTransformationsTransformationPrimitiveTransformationDateShiftConfigCryptoKeyKmsWrapped¢
S
cryptoKeyName" >The resource name of the KMS CryptoKey to use for unwrapping.
H

wrappedKey" 6The wrapped data crypto key.
A base64-encoded string.
:µ
±
dataloss±PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationInfoTypeTransformationsTransformationPrimitiveTransformationDateShiftConfigCryptoKeyTransientðgcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationInfoTypeTransformationsTransformationPrimitiveTransformationDateShiftConfigCryptoKeyTransient:PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationInfoTypeTransformationsTransformationPrimitiveTransformationDateShiftConfigCryptoKeyTransientþ
ûø
name" ëName of the key. This is an arbitrary string used to differentiate different keys. A unique key is generated per name: two separate `TransientCryptoKey` protos share the same generated key if their names are the same. When the data crypto key is generated, this name is not used in any way (repeating the api call will result in a different key being generated).
:Ä
±
dataloss±PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationInfoTypeTransformationsTransformationPrimitiveTransformationDateShiftConfigCryptoKeyUnwrappedðgcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationInfoTypeTransformationsTransformationPrimitiveTransformationDateShiftConfigCryptoKeyUnwrapped:PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationInfoTypeTransformationsTransformationPrimitiveTransformationDateShiftConfigCryptoKeyUnwrapped

key" |A 128/192/256 bit key.
A base64-encoded string.
**Note**: This property is sensitive and will not be displayed in the plan.
:ú

dataloss¨PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationInfoTypeTransformationsTransformationPrimitiveTransformationFixedSizeBucketingConfigÞgcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationInfoTypeTransformationsTransformationPrimitiveTransformationFixedSizeBucketingConfig:PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationInfoTypeTransformationsTransformationPrimitiveTransformationFixedSizeBucketingConfigÞ
Û

bucketSize Size of each bucket (except for minimum and maximum buckets).
So if lower_bound = 10, upper_bound = 89, and bucketSize = 10, then the following buckets would be used: -10, 10-20, 20-30, 30-40, 40-50, 50-60, 60-70, 70-80, 80-89, 89+.
Precision up to 2 decimals works.
×

lowerBoundº:·
´
dataloss²PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationInfoTypeTransformationsTransformationPrimitiveTransformationFixedSizeBucketingConfigLowerBoundògcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationInfoTypeTransformationsTransformationPrimitiveTransformationFixedSizeBucketingConfigLowerBound:PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationInfoTypeTransformationsTransformationPrimitiveTransformationFixedSizeBucketingConfigLowerBoundLower bound value of buckets.
All values less than lower_bound are grouped together into a single bucket; for example if lower_bound = 10, then all values less than 10 are replaced with the value "-10".
The `lower_bound` block must only contain one argument. See the `fixed_size_bucketing_config` block description for more information about choosing a data type.
Structure is documented below.
Ý

upperBoundº:·
´
dataloss²PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationInfoTypeTransformationsTransformationPrimitiveTransformationFixedSizeBucketingConfigUpperBoundògcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationInfoTypeTransformationsTransformationPrimitiveTransformationFixedSizeBucketingConfigUpperBound:PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationInfoTypeTransformationsTransformationPrimitiveTransformationFixedSizeBucketingConfigUpperBoundUpper bound value of buckets.
All values greater than upper_bound are grouped together into a single bucket; for example if upper_bound = 89, then all values greater than 89 are replaced with the value "89+".
The `upper_bound` block must only contain one argument. See the `fixed_size_bucketing_config` block description for more information about choosing a data type.
Structure is documented below.
:
´
dataloss²PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationInfoTypeTransformationsTransformationPrimitiveTransformationFixedSizeBucketingConfigLowerBoundògcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationInfoTypeTransformationsTransformationPrimitiveTransformationFixedSizeBucketingConfigLowerBound:PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationInfoTypeTransformationsTransformationPrimitiveTransformationFixedSizeBucketingConfigLowerBound_
]#

floatValueB A float value.
6
integerValueB"  An integer value (int64 format)
:
´
dataloss²PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationInfoTypeTransformationsTransformationPrimitiveTransformationFixedSizeBucketingConfigUpperBoundògcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationInfoTypeTransformationsTransformationPrimitiveTransformationFixedSizeBucketingConfigUpperBound:PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationInfoTypeTransformationsTransformationPrimitiveTransformationFixedSizeBucketingConfigUpperBound_
]#

floatValueB A float value.
6
integerValueB"  An integer value (int64 format)
:ù
ò
datalossPreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationInfoTypeTransformationsTransformationPrimitiveTransformationRedactConfigÆgcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationInfoTypeTransformationsTransformationPrimitiveTransformationRedactConfig:PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationInfoTypeTransformationsTransformationPrimitiveTransformationRedactConfig
 :

õ
datalossPreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationInfoTypeTransformationsTransformationPrimitiveTransformationReplaceConfigÈgcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationInfoTypeTransformationsTransformationPrimitiveTransformationReplaceConfig:PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationInfoTypeTransformationsTransformationPrimitiveTransformationReplaceConfig

newValue:

dataloss¥PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationInfoTypeTransformationsTransformationPrimitiveTransformationReplaceConfigNewValueØgcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationInfoTypeTransformationsTransformationPrimitiveTransformationReplaceConfigNewValue:PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationInfoTypeTransformationsTransformationPrimitiveTransformationReplaceConfigNewValueåReplace each input value with a given value.
The `new_value` block must only contain one argument. For example when replacing the contents of a string-type field, only `string_value` should be set.
Structure is documented below.
:·

dataloss¥PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationInfoTypeTransformationsTransformationPrimitiveTransformationReplaceConfigNewValueØgcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationInfoTypeTransformationsTransformationPrimitiveTransformationReplaceConfigNewValue:PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationInfoTypeTransformationsTransformationPrimitiveTransformationReplaceConfigNewValue¤
¡'
booleanValueB
 A boolean value.

	dateValue±B®:«
¨
dataloss®PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationInfoTypeTransformationsTransformationPrimitiveTransformationReplaceConfigNewValueDateValueêgcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationInfoTypeTransformationsTransformationPrimitiveTransformationReplaceConfigNewValueDateValue:PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationInfoTypeTransformationsTransformationPrimitiveTransformationReplaceConfigNewValueDateValueLRepresents a whole or partial calendar date.
Structure is documented below.

dayOfWeekValueB" Represents a day of the week.
Possible values are: `MONDAY`, `TUESDAY`, `WEDNESDAY`, `THURSDAY`, `FRIDAY`, `SATURDAY`, `SUNDAY`.
#

floatValueB A float value.
6
integerValueB"  An integer value (int64 format)
%
stringValueB" A string value.
ú
	timeValue±B®:«
¨
dataloss®PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationInfoTypeTransformationsTransformationPrimitiveTransformationReplaceConfigNewValueTimeValueêgcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationInfoTypeTransformationsTransformationPrimitiveTransformationReplaceConfigNewValueTimeValue:PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationInfoTypeTransformationsTransformationPrimitiveTransformationReplaceConfigNewValueTimeValue9Represents a time of day.
Structure is documented below.
Ç
timestampValueB" ®A timestamp in RFC3339 UTC "Zulu" format, with nanosecond resolution and up to nine fractional digits.
Examples: "2014-10-02T15:01:23Z" and "2014-10-02T15:01:23.045123456Z".
:¯
¨
dataloss®PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationInfoTypeTransformationsTransformationPrimitiveTransformationReplaceConfigNewValueDateValueêgcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationInfoTypeTransformationsTransformationPrimitiveTransformationReplaceConfigNewValueDateValue:PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationInfoTypeTransformationsTransformationPrimitiveTransformationReplaceConfigNewValueDateValue
þ²
dayB ¤Day of a month. Must be from 1 to 31 and valid for the year and month, or 0 to specify a year by itself or a year and month where the day isn't significant.

- - -
f
monthB WMonth of a year. Must be from 1 to 12, or 0 to specify a year without a month and day.
_
yearB QYear of the date. Must be from 1 to 9999, or 0 to specify a date without a year.
:ø
¨
dataloss®PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationInfoTypeTransformationsTransformationPrimitiveTransformationReplaceConfigNewValueTimeValueêgcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationInfoTypeTransformationsTransformationPrimitiveTransformationReplaceConfigNewValueTimeValue:PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationInfoTypeTransformationsTransformationPrimitiveTransformationReplaceConfigNewValueTimeValueÊ
Ç¢
hoursB Hours of day in 24 hour format. Should be from 0 to 23. An API may choose to allow the value "24:00:00" for scenarios like business closing time.
?
minutesB .Minutes of hour of day. Must be from 0 to 59.
S
nanosB DFractions of seconds in nanoseconds. Must be from 0 to 999,999,999.

secondsB xSeconds of minutes of the time. Must normally be from 0 to 59. An API may allow the value 60 if it allows leap-seconds.
:¥


dataloss§PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationInfoTypeTransformationsTransformationPrimitiveTransformationReplaceDictionaryConfigÜgcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationInfoTypeTransformationsTransformationPrimitiveTransformationReplaceDictionaryConfig:PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationInfoTypeTransformationsTransformationPrimitiveTransformationReplaceDictionaryConfig

wordList±:®
«
dataloss¯PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationInfoTypeTransformationsTransformationPrimitiveTransformationReplaceDictionaryConfigWordListìgcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationInfoTypeTransformationsTransformationPrimitiveTransformationReplaceDictionaryConfigWordList:PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationInfoTypeTransformationsTransformationPrimitiveTransformationReplaceDictionaryConfigWordListÅA list of words to select from for random replacement. The [limits](https://cloud.google.com/dlp/limits) page contains details about the size limits of dictionaries.
Structure is documented below.
:ñ
«
dataloss¯PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationInfoTypeTransformationsTransformationPrimitiveTransformationReplaceDictionaryConfigWordListìgcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationInfoTypeTransformationsTransformationPrimitiveTransformationReplaceDictionaryConfigWordList:PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationInfoTypeTransformationsTransformationPrimitiveTransformationReplaceDictionaryConfigWordListÀ
½º
words*" ªWords or phrases defining the dictionary. The dictionary must contain at least one phrase and every phrase must contain at least 2 characters that are letters or digits.
: 

dataloss©PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationInfoTypeTransformationsTransformationPrimitiveTransformationReplaceWithInfoTypeConfigàgcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationInfoTypeTransformationsTransformationPrimitiveTransformationReplaceWithInfoTypeConfig:PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationInfoTypeTransformationsTransformationPrimitiveTransformationReplaceWithInfoTypeConfig
 :
ø
datalossPreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationInfoTypeTransformationsTransformationPrimitiveTransformationTimePartConfigÊgcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationInfoTypeTransformationsTransformationPrimitiveTransformationTimePartConfig:PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationInfoTypeTransformationsTransformationPrimitiveTransformationTimePartConfig

partToExtract" The part of the time to keep.
Possible values are: `YEAR`, `MONTH`, `DAY_OF_MONTH`, `DAY_OF_WEEK`, `WEEK_OF_YEAR`, `HOUR_OF_DAY`.
:H
Þ
datalosskPreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationPrimitiveTransformationägcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationPrimitiveTransformation:PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationPrimitiveTransformation·E
´Eã
bucketingConfigB:

datalosszPreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationPrimitiveTransformationBucketingConfiggcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationPrimitiveTransformationBucketingConfig:PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationPrimitiveTransformationBucketingConfig¸Generalization function that buckets values based on ranges. The ranges and replacement values are dynamically provided by the user for custom behavior, such as 1-30 > LOW 31-65 > MEDIUM 66-100 > HIGH
This can be used on data of type: number, long, string, timestamp.
If the provided value type differs from the type of data being transformed, we will first attempt converting the type of the data to be transformed to match the type of the bound before comparing.
See https://cloud.google.com/dlp/docs/concepts-bucketing to learn more.
Structure is documented below.
Ú
characterMaskConfig B:

dataloss~PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationPrimitiveTransformationCharacterMaskConfiggcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationPrimitiveTransformationCharacterMaskConfig:PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationPrimitiveTransformationCharacterMaskConfigPartially mask a string by replacing a given number of characters with a fixed character. Masking can start from the beginning or end of the string. This can be used on data of any type (numbers, longs, and so on) and when de-identifying structured data we'll attempt to preserve the original data's type. (This allows you to take a long like 123 and modify it to a string like **3).
Structure is documented below.
ó
cryptoDeterministicConfig³B°:­
ª
datalossPreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationPrimitiveTransformationCryptoDeterministicConfiggcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationPrimitiveTransformationCryptoDeterministicConfig:PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationPrimitiveTransformationCryptoDeterministicConfigPseudonymization method that generates deterministic encryption for the given input. Outputs a base64 encoded representation of the encrypted output. Uses AES-SIV based on the RFC [https://tools.ietf.org/html/rfc5297](https://tools.ietf.org/html/rfc5297).
Structure is documented below.
Î
cryptoHashConfigB:

dataloss{PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationPrimitiveTransformationCryptoHashConfiggcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationPrimitiveTransformationCryptoHashConfig:PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationPrimitiveTransformationCryptoHashConfigPseudonymization method that generates surrogates via cryptographic hashing. Uses SHA-256. The key size must be either 32 or 64 bytes.
Outputs a base64 encoded representation of the hashed output (for example, L7k0BHmF1ha5U3NfGykjro4xWi1MPVQPjhMAZbSV9mM=).
Currently, only string and integer values can be hashed.
See https://cloud.google.com/dlp/docs/pseudonymization to learn more.
Structure is documented below.
ª

cryptoReplaceFfxFpeConfig³B°:­
ª
datalossPreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationPrimitiveTransformationCryptoReplaceFfxFpeConfiggcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationPrimitiveTransformationCryptoReplaceFfxFpeConfig:PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationPrimitiveTransformationCryptoReplaceFfxFpeConfigÖReplaces an identifier with a surrogate using Format Preserving Encryption (FPE) with the FFX mode of operation; however when used in the `content.reidentify` API method, it serves the opposite function by reversing the surrogate back into the original identifier. The identifier must be encoded as ASCII. For a given crypto key and context, the same identifier will be replaced with the same surrogate. Identifiers must be at least two characters long. In the case that the identifier is the empty string, it will be skipped. See [https://cloud.google.com/dlp/docs/pseudonymization](https://cloud.google.com/dlp/docs/pseudonymization) to learn more.
Note: We recommend using CryptoDeterministicConfig for all use cases which do not require preserving the input alphabet space and size, plus warrant referential integrity.
Structure is documented below.
ð
dateShiftConfigB:

datalosszPreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationPrimitiveTransformationDateShiftConfiggcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationPrimitiveTransformationDateShiftConfig:PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationPrimitiveTransformationDateShiftConfigÅShifts dates by random number of days, with option to be consistent for the same context. See https://cloud.google.com/dlp/docs/concepts-date-shifting to learn more.
Structure is documented below.
ß	
fixedSizeBucketingConfig°B­:ª
§
datalossPreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationPrimitiveTransformationFixedSizeBucketingConfiggcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationPrimitiveTransformationFixedSizeBucketingConfig:PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationPrimitiveTransformationFixedSizeBucketingConfigBuckets values based on fixed size ranges. The Bucketing transformation can provide all of this functionality, but requires more configuration. This message is provided as a convenience to the user for simple bucketing strategies.
The transformed value will be a hyphenated string of {lower_bound}-{upper_bound}. For example, if lower_bound = 10 and upper_bound = 20, all values that are within this bucket will be replaced with "10-20".
This can be used on data of type: double, long.
If the bound Value type differs from the type of data being transformed, we will first attempt converting the type of the data to be transformed to match the type of the bound before comparing.
See https://cloud.google.com/dlp/docs/concepts-bucketing to learn more.
Structure is documented below.
Ü
redactConfigB:

datalosswPreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationPrimitiveTransformationRedactConfigügcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationPrimitiveTransformationRedactConfig:PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationPrimitiveTransformationRedactConfig½Redact a given value. For example, if used with an InfoTypeTransformation transforming PHONE_NUMBER, and input 'My phone number is 206-555-0123', the output would be 'My phone number is '.
î
replaceConfigB:

datalossxPreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationPrimitiveTransformationReplaceConfigþgcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationPrimitiveTransformationReplaceConfig:PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationPrimitiveTransformationReplaceConfigLReplace each input value with a given value.
Structure is documented below.
´
replaceDictionaryConfig­Bª:§
¤
datalossPreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationPrimitiveTransformationReplaceDictionaryConfiggcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationPrimitiveTransformationReplaceDictionaryConfig:PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationPrimitiveTransformationReplaceDictionaryConfigiReplace with a value randomly drawn (with replacement) from a dictionary.
Structure is documented below.

timePartConfigB:

datalossyPreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationPrimitiveTransformationTimePartConfiggcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationPrimitiveTransformationTimePartConfig:PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationPrimitiveTransformationTimePartConfigxFor use with Date, Timestamp, and TimeOfDay, extract or preserve a portion of the value.
Structure is documented below.
:à

datalosszPreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationPrimitiveTransformationBucketingConfiggcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationPrimitiveTransformationBucketingConfig:PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationPrimitiveTransformationBucketingConfigÏ
ÌÉ
bucketsªB§*¤:¡

datalossPreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationPrimitiveTransformationBucketingConfigBucketgcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationPrimitiveTransformationBucketingConfigBucket:PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationPrimitiveTransformationBucketingConfigBucketSet of buckets. Ranges must be non-overlapping.
Bucket is represented as a range, along with replacement values.
Structure is documented below.
:ó

datalossPreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationPrimitiveTransformationBucketingConfigBucketgcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationPrimitiveTransformationBucketingConfigBucket:PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationPrimitiveTransformationBucketingConfigBucketÏ
Ì¢
max°B­:ª
§
datalossPreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationPrimitiveTransformationBucketingConfigBucketMaxgcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationPrimitiveTransformationBucketingConfigBucketMax:PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationPrimitiveTransformationBucketingConfigBucketMaxçUpper bound of the range, exclusive; type must match min.
The `max` block must only contain one argument. See the `bucketing_config` block description for more information about choosing a data type.
Structure is documented below.
µ
min°B­:ª
§
datalossPreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationPrimitiveTransformationBucketingConfigBucketMingcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationPrimitiveTransformationBucketingConfigBucketMin:PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationPrimitiveTransformationBucketingConfigBucketMinúLower bound of the range, inclusive. Type should be the same as max if used.
The `min` block must only contain one argument. See the `bucketing_config` block description for more information about choosing a data type.
Structure is documented below.
ì
replacementValueÔ:Ñ
Î
datalossPreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationPrimitiveTransformationBucketingConfigBucketReplacementValue®gcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationPrimitiveTransformationBucketingConfigBucketReplacementValue:PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationPrimitiveTransformationBucketingConfigBucketReplacementValueReplacement value for this bucket.
The `replacement_value` block must only contain one argument.
Structure is documented below.
:
§
datalossPreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationPrimitiveTransformationBucketingConfigBucketMaxgcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationPrimitiveTransformationBucketingConfigBucketMax:PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationPrimitiveTransformationBucketingConfigBucketMaxØ
Õ'
booleanValueB
 A boolean value.
§
	dateValueËBÈ:Å
Â
datalossPreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationPrimitiveTransformationBucketingConfigBucketMaxDateValue¦gcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationPrimitiveTransformationBucketingConfigBucketMaxDateValue:PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationPrimitiveTransformationBucketingConfigBucketMaxDateValueLRepresents a whole or partial calendar date.
Structure is documented below.

dayOfWeekValueB" Represents a day of the week.
Possible values are: `MONDAY`, `TUESDAY`, `WEDNESDAY`, `THURSDAY`, `FRIDAY`, `SATURDAY`, `SUNDAY`.
#

floatValueB A float value.
6
integerValueB"  An integer value (int64 format)
%
stringValueB" A string value.

	timeValueËBÈ:Å
Â
datalossPreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationPrimitiveTransformationBucketingConfigBucketMaxTimeValue¦gcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationPrimitiveTransformationBucketingConfigBucketMaxTimeValue:PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationPrimitiveTransformationBucketingConfigBucketMaxTimeValue9Represents a time of day.
Structure is documented below.
Ç
timestampValueB" ®A timestamp in RFC3339 UTC "Zulu" format, with nanosecond resolution and up to nine fractional digits. Examples: "2014-10-02T15:01:23Z" and "2014-10-02T15:01:23.045123456Z".
:É
Â
datalossPreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationPrimitiveTransformationBucketingConfigBucketMaxDateValue¦gcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationPrimitiveTransformationBucketingConfigBucketMaxDateValue:PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationPrimitiveTransformationBucketingConfigBucketMaxDateValue
þ²
dayB ¤Day of a month. Must be from 1 to 31 and valid for the year and month, or 0 to specify a year by itself or a year and month where the day isn't significant.

- - -
f
monthB WMonth of a year. Must be from 1 to 12, or 0 to specify a year without a month and day.
_
yearB QYear of the date. Must be from 1 to 9999, or 0 to specify a date without a year.
:
Â
datalossPreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationPrimitiveTransformationBucketingConfigBucketMaxTimeValue¦gcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationPrimitiveTransformationBucketingConfigBucketMaxTimeValue:PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationPrimitiveTransformationBucketingConfigBucketMaxTimeValueÊ
Ç¢
hoursB Hours of day in 24 hour format. Should be from 0 to 23. An API may choose to allow the value "24:00:00" for scenarios like business closing time.
?
minutesB .Minutes of hour of day. Must be from 0 to 59.
S
nanosB DFractions of seconds in nanoseconds. Must be from 0 to 999,999,999.

secondsB xSeconds of minutes of the time. Must normally be from 0 to 59. An API may allow the value 60 if it allows leap-seconds.
:
§
datalossPreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationPrimitiveTransformationBucketingConfigBucketMingcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationPrimitiveTransformationBucketingConfigBucketMin:PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationPrimitiveTransformationBucketingConfigBucketMinØ
Õ'
booleanValueB
 A boolean value.
§
	dateValueËBÈ:Å
Â
datalossPreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationPrimitiveTransformationBucketingConfigBucketMinDateValue¦gcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationPrimitiveTransformationBucketingConfigBucketMinDateValue:PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationPrimitiveTransformationBucketingConfigBucketMinDateValueLRepresents a whole or partial calendar date.
Structure is documented below.

dayOfWeekValueB" Represents a day of the week.
Possible values are: `MONDAY`, `TUESDAY`, `WEDNESDAY`, `THURSDAY`, `FRIDAY`, `SATURDAY`, `SUNDAY`.
#

floatValueB A float value.
6
integerValueB"  An integer value (int64 format)
%
stringValueB" A string value.

	timeValueËBÈ:Å
Â
datalossPreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationPrimitiveTransformationBucketingConfigBucketMinTimeValue¦gcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationPrimitiveTransformationBucketingConfigBucketMinTimeValue:PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationPrimitiveTransformationBucketingConfigBucketMinTimeValue9Represents a time of day.
Structure is documented below.
Ç
timestampValueB" ®A timestamp in RFC3339 UTC "Zulu" format, with nanosecond resolution and up to nine fractional digits. Examples: "2014-10-02T15:01:23Z" and "2014-10-02T15:01:23.045123456Z".
:É
Â
datalossPreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationPrimitiveTransformationBucketingConfigBucketMinDateValue¦gcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationPrimitiveTransformationBucketingConfigBucketMinDateValue:PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationPrimitiveTransformationBucketingConfigBucketMinDateValue
þ²
dayB ¤Day of a month. Must be from 1 to 31 and valid for the year and month, or 0 to specify a year by itself or a year and month where the day isn't significant.

- - -
f
monthB WMonth of a year. Must be from 1 to 12, or 0 to specify a year without a month and day.
_
yearB QYear of the date. Must be from 1 to 9999, or 0 to specify a date without a year.
:
Â
datalossPreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationPrimitiveTransformationBucketingConfigBucketMinTimeValue¦gcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationPrimitiveTransformationBucketingConfigBucketMinTimeValue:PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationPrimitiveTransformationBucketingConfigBucketMinTimeValueÊ
Ç¢
hoursB Hours of day in 24 hour format. Should be from 0 to 23. An API may choose to allow the value "24:00:00" for scenarios like business closing time.
?
minutesB .Minutes of hour of day. Must be from 0 to 59.
S
nanosB DFractions of seconds in nanoseconds. Must be from 0 to 999,999,999.

secondsB xSeconds of minutes of the time. Must normally be from 0 to 59. An API may allow the value 60 if it allows leap-seconds.
:ú
Î
datalossPreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationPrimitiveTransformationBucketingConfigBucketReplacementValue®gcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationPrimitiveTransformationBucketingConfigBucketReplacementValue:PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationPrimitiveTransformationBucketingConfigBucketReplacementValue¦
£'
booleanValueB
 A boolean value.
Î
	dateValueòBï:ì
é
datalossPreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationPrimitiveTransformationBucketingConfigBucketReplacementValueDateValueÀgcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationPrimitiveTransformationBucketingConfigBucketReplacementValueDateValue:PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationPrimitiveTransformationBucketingConfigBucketReplacementValueDateValueLRepresents a whole or partial calendar date.
Structure is documented below.

dayOfWeekValueB" Represents a day of the week.
Possible values are: `MONDAY`, `TUESDAY`, `WEDNESDAY`, `THURSDAY`, `FRIDAY`, `SATURDAY`, `SUNDAY`.
#

floatValueB A float value.
6
integerValueB"  An integer value (int64 format)
%
stringValueB" A string value.
»
	timeValueòBï:ì
é
datalossPreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationPrimitiveTransformationBucketingConfigBucketReplacementValueTimeValueÀgcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationPrimitiveTransformationBucketingConfigBucketReplacementValueTimeValue:PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationPrimitiveTransformationBucketingConfigBucketReplacementValueTimeValue9Represents a time of day.
Structure is documented below.
Ç
timestampValueB" ®A timestamp in RFC3339 UTC "Zulu" format, with nanosecond resolution and up to nine fractional digits. Examples: "2014-10-02T15:01:23Z" and "2014-10-02T15:01:23.045123456Z".
:ð
é
datalossPreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationPrimitiveTransformationBucketingConfigBucketReplacementValueDateValueÀgcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationPrimitiveTransformationBucketingConfigBucketReplacementValueDateValue:PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationPrimitiveTransformationBucketingConfigBucketReplacementValueDateValue
þ²
dayB ¤Day of a month. Must be from 1 to 31 and valid for the year and month, or 0 to specify a year by itself or a year and month where the day isn't significant.

- - -
f
monthB WMonth of a year. Must be from 1 to 12, or 0 to specify a year without a month and day.
_
yearB QYear of the date. Must be from 1 to 9999, or 0 to specify a date without a year.
:¹
é
datalossPreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationPrimitiveTransformationBucketingConfigBucketReplacementValueTimeValueÀgcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationPrimitiveTransformationBucketingConfigBucketReplacementValueTimeValue:PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationPrimitiveTransformationBucketingConfigBucketReplacementValueTimeValueÊ
Ç¢
hoursB Hours of day in 24 hour format. Should be from 0 to 23. An API may choose to allow the value "24:00:00" for scenarios like business closing time.
?
minutesB .Minutes of hour of day. Must be from 0 to 59.
S
nanosB DFractions of seconds in nanoseconds. Must be from 0 to 999,999,999.

secondsB xSeconds of minutes of the time. Must normally be from 0 to 59. An API may allow the value 60 if it allows leap-seconds.
:ó

dataloss~PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationPrimitiveTransformationCharacterMaskConfiggcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationPrimitiveTransformationCharacterMaskConfig:PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationPrimitiveTransformationCharacterMaskConfigÖ
Óö
charactersToIgnoresÚB×*Ô:Ñ
Î
datalossPreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationPrimitiveTransformationCharacterMaskConfigCharactersToIgnore®gcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationPrimitiveTransformationCharacterMaskConfigCharactersToIgnore:PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationPrimitiveTransformationCharacterMaskConfigCharactersToIgnoreCharacters to skip when doing de-identification of a value. These will be left alone and skipped.
Structure is documented below.
³
maskingCharacterB" Character to use to mask the sensitive valuesâfor example, * for an alphabetic string such as a name, or 0 for a numeric string
such as ZIP code or credit card number. This string must have a length of 1. If not supplied, this value defaults to * for
strings, and 0 for digits.
¹
numberToMaskB ¢Number of characters to mask. If not set, all matching chars will be masked. Skipped characters do not count towards this tally.
If number_to_mask is negative, this denotes inverse masking. Cloud DLP masks all but a number of characters. For example, suppose you have the following values:
å
reverseOrderB
 ÎMask characters in reverse order. For example, if masking_character is 0, number_to_mask is 14, and reverse_order is `false`, then the
input string `1234-5678-9012-3456` is masked as `00000000000000-3456`.
:
Î
datalossPreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationPrimitiveTransformationCharacterMaskConfigCharactersToIgnore®gcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationPrimitiveTransformationCharacterMaskConfigCharactersToIgnore:PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationPrimitiveTransformationCharacterMaskConfigCharactersToIgnore­
ª
charactersToSkipB" oCharacters to not transform when masking. Only one of this or `common_characters_to_ignore` must be specified.

commonCharactersToIgnoreB" øCommon characters to not transform when masking. Useful to avoid removing punctuation. Only one of this or `characters_to_skip` must be specified.
Possible values are: `NUMERIC`, `ALPHA_UPPER_CASE`, `ALPHA_LOWER_CASE`, `PUNCTUATION`, `WHITESPACE`.
:á#
ª
datalossPreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationPrimitiveTransformationCryptoDeterministicConfiggcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationPrimitiveTransformationCryptoDeterministicConfig:PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationPrimitiveTransformationCryptoDeterministicConfig± 
® ©

contextÈBÅ:Â
¿
datalossPreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationPrimitiveTransformationCryptoDeterministicConfigContext¤gcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationPrimitiveTransformationCryptoDeterministicConfigContext:PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationPrimitiveTransformationCryptoDeterministicConfigContextÒA context may be used for higher security and maintaining referential integrity such that the same identifier in two different contexts will be given a distinct surrogate. The context is appended to plaintext value being encrypted. On decryption the provided context is validated against the value used during encryption. If a context was provided during encryption, same context must be provided during decryption as well.
If the context is not set, plaintext would be used as is for encryption. If the context is set but:
1. there is no record present when transforming a given value or
2. the field is not present when transforming a given value,
plaintext would be used as is for encryption.
Note that case (1) is expected when an InfoTypeTransformation is applied to both structured and unstructured ContentItems.
Structure is documented below.

	cryptoKeyÎBË:È
Å
datalossPreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationPrimitiveTransformationCryptoDeterministicConfigCryptoKey¨gcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationPrimitiveTransformationCryptoDeterministicConfigCryptoKey:PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationPrimitiveTransformationCryptoDeterministicConfigCryptoKey¶The key used by the encryption function. For deterministic encryption using AES-SIV, the provided key is internally expanded to 64 bytes prior to use.
Structure is documented below.
ç
surrogateInfoTypeæBã:à
Ý
datalossPreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationPrimitiveTransformationCryptoDeterministicConfigSurrogateInfoType¸gcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationPrimitiveTransformationCryptoDeterministicConfigSurrogateInfoType:PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationPrimitiveTransformationCryptoDeterministicConfigSurrogateInfoTypeèThe custom info type to annotate the surrogate with. This annotation will be applied to the surrogate by prefixing it with the name of the custom info type followed by the number of characters comprising the surrogate. The following scheme defines the format: {info type name}({surrogate character count}):{surrogate}
For example, if the name of custom info type is 'MY\_TOKEN\_INFO\_TYPE' and the surrogate is 'abc', the full replacement value will be: 'MY\_TOKEN\_INFO\_TYPE(3):abc'
This annotation identifies the surrogate when inspecting content using the custom info type 'Surrogate'. This facilitates reversal of the surrogate when it occurs in free text.
Note: For record transformations where the entire cell in a table is being transformed, surrogates are not mandatory. Surrogates are used to denote the location of the token and are necessary for re-identification in free form text.
In order for inspection to work properly, the name of this info type must not occur naturally anywhere in your data; otherwise, inspection may either
*   reverse a surrogate that does not correspond to an actual identifier
*   be unable to parse the surrogate and result in an error
Therefore, choose your custom info type name carefully after considering what your data looks like. One way to select a name that has a high chance of yielding reliable detection is to include one or more unicode characters that are highly improbable to exist in your data. For example, assuming your data is entered from a regular ASCII keyboard, the symbol with the hex code point 29DD might be used like so: â§MY\_TOKEN\_TYPE.
Structure is documented below.
:ñ
¿
datalossPreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationPrimitiveTransformationCryptoDeterministicConfigContext¤gcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationPrimitiveTransformationCryptoDeterministicConfigContext:PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationPrimitiveTransformationCryptoDeterministicConfigContext-
+)
nameB" Name describing the field.
:ð
Å
datalossPreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationPrimitiveTransformationCryptoDeterministicConfigCryptoKey¨gcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationPrimitiveTransformationCryptoDeterministicConfigCryptoKey:PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationPrimitiveTransformationCryptoDeterministicConfigCryptoKey¥
¢Ú

kmsWrappedìBé:æ
ã
datalossPreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationPrimitiveTransformationCryptoDeterministicConfigCryptoKeyKmsWrapped¼gcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationPrimitiveTransformationCryptoDeterministicConfigCryptoKeyKmsWrapped:PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationPrimitiveTransformationCryptoDeterministicConfigCryptoKeyKmsWrappedÜKMS wrapped key.
Include to use an existing data crypto key wrapped by KMS. The wrapped key must be a 128-, 192-, or 256-bit key. Authorization requires the following IAM permissions when sending a request to perform a crypto transformation using a KMS-wrapped crypto key: dlp.kms.encrypt
For more information, see [Creating a wrapped key](https://cloud.google.com/dlp/docs/create-wrapped-key). Only one of this, `transient` or `unwrapped` must be specified.
Note: When you use Cloud KMS for cryptographic operations, [charges apply](https://cloud.google.com/kms/pricing).
Structure is documented below.
×
	transientéBæ:ã
à
datalossPreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationPrimitiveTransformationCryptoDeterministicConfigCryptoKeyTransientºgcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationPrimitiveTransformationCryptoDeterministicConfigCryptoKeyTransient:PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationPrimitiveTransformationCryptoDeterministicConfigCryptoKeyTransientÝTransient crypto key. Use this to have a random data crypto key generated. It will be discarded after the request finishes. Only one of this, `unwrapped` or `kms_wrapped` must be specified.
Structure is documented below.
è
	unwrappedéBæ:ã
à
datalossPreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationPrimitiveTransformationCryptoDeterministicConfigCryptoKeyUnwrappedºgcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationPrimitiveTransformationCryptoDeterministicConfigCryptoKeyUnwrapped:PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationPrimitiveTransformationCryptoDeterministicConfigCryptoKeyUnwrappedîUnwrapped crypto key. Using raw keys is prone to security risks due to accidentally leaking the key. Choose another type of key if possible. Only one of this, `transient` or `kms_wrapped` must be specified.
Structure is documented below.
:
ã
datalossPreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationPrimitiveTransformationCryptoDeterministicConfigCryptoKeyKmsWrapped¼gcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationPrimitiveTransformationCryptoDeterministicConfigCryptoKeyKmsWrapped:PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationPrimitiveTransformationCryptoDeterministicConfigCryptoKeyKmsWrapped¢
S
cryptoKeyName" >The resource name of the KMS CryptoKey to use for unwrapping.
H

wrappedKey" 6The wrapped data crypto key.
A base64-encoded string.
:ä
à
datalossPreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationPrimitiveTransformationCryptoDeterministicConfigCryptoKeyTransientºgcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationPrimitiveTransformationCryptoDeterministicConfigCryptoKeyTransient:PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationPrimitiveTransformationCryptoDeterministicConfigCryptoKeyTransientþ
ûø
name" ëName of the key. This is an arbitrary string used to differentiate different keys. A unique key is generated per name: two separate `TransientCryptoKey` protos share the same generated key if their names are the same. When the data crypto key is generated, this name is not used in any way (repeating the api call will result in a different key being generated).
:ó
à
datalossPreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationPrimitiveTransformationCryptoDeterministicConfigCryptoKeyUnwrappedºgcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationPrimitiveTransformationCryptoDeterministicConfigCryptoKeyUnwrapped:PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationPrimitiveTransformationCryptoDeterministicConfigCryptoKeyUnwrapped

key" |A 128/192/256 bit key.
A base64-encoded string.
**Note**: This property is sensitive and will not be displayed in the plan.
:×
Ý
datalossPreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationPrimitiveTransformationCryptoDeterministicConfigSurrogateInfoType¸gcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationPrimitiveTransformationCryptoDeterministicConfigSurrogateInfoType:PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationPrimitiveTransformationCryptoDeterministicConfigSurrogateInfoTypeô
ñ
nameB" Name of the information type. Either a name of your choosing when creating a CustomInfoType, or one of the names listed at [https://cloud.google.com/dlp/docs/infotypes-reference](https://cloud.google.com/dlp/docs/infotypes-reference) when specifying a built-in type. When sending Cloud DLP results to Data Catalog, infoType names should conform to the pattern `[A-Za-z0-9$-_]{1,64}`.
 
sensitivityScoreB:

dataloss¥PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationPrimitiveTransformationCryptoDeterministicConfigSurrogateInfoTypeSensitivityScoreØgcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationPrimitiveTransformationCryptoDeterministicConfigSurrogateInfoTypeSensitivityScore:PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationPrimitiveTransformationCryptoDeterministicConfigSurrogateInfoTypeSensitivityScoresOptional custom sensitivity for this InfoType. This only applies to data profiling.
Structure is documented below.
:
versionB" )Optional version name for this InfoType.
:ª

dataloss¥PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationPrimitiveTransformationCryptoDeterministicConfigSurrogateInfoTypeSensitivityScoreØgcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationPrimitiveTransformationCryptoDeterministicConfigSurrogateInfoTypeSensitivityScore:PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationPrimitiveTransformationCryptoDeterministicConfigSurrogateInfoTypeSensitivityScore

score" The sensitivity score applied to the resource.
Possible values are: `SENSITIVITY_LOW`, `SENSITIVITY_MODERATE`, `SENSITIVITY_HIGH`.
:¥

dataloss{PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationPrimitiveTransformationCryptoHashConfiggcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationPrimitiveTransformationCryptoHashConfig:PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationPrimitiveTransformationCryptoHashConfig

	cryptoKey³B°:­
ª
datalossPreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationPrimitiveTransformationCryptoHashConfigCryptoKeygcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationPrimitiveTransformationCryptoHashConfigCryptoKey:PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationPrimitiveTransformationCryptoHashConfigCryptoKeyHThe key used by the encryption function.
Structure is documented below.
:
ª
datalossPreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationPrimitiveTransformationCryptoHashConfigCryptoKeygcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationPrimitiveTransformationCryptoHashConfigCryptoKey:PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationPrimitiveTransformationCryptoHashConfigCryptoKeyÔ
Ñ¿

kmsWrappedÑBÎ:Ë
È
datalossPreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationPrimitiveTransformationCryptoHashConfigCryptoKeyKmsWrappedªgcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationPrimitiveTransformationCryptoHashConfigCryptoKeyKmsWrapped:PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationPrimitiveTransformationCryptoHashConfigCryptoKeyKmsWrappedÜKMS wrapped key.
Include to use an existing data crypto key wrapped by KMS. The wrapped key must be a 128-, 192-, or 256-bit key. Authorization requires the following IAM permissions when sending a request to perform a crypto transformation using a KMS-wrapped crypto key: dlp.kms.encrypt
For more information, see [Creating a wrapped key](https://cloud.google.com/dlp/docs/create-wrapped-key). Only one of this, `transient` or `unwrapped` must be specified.
Note: When you use Cloud KMS for cryptographic operations, [charges apply](https://cloud.google.com/kms/pricing).
Structure is documented below.
¼
	transientÎBË:È
Å
datalossPreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationPrimitiveTransformationCryptoHashConfigCryptoKeyTransient¨gcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationPrimitiveTransformationCryptoHashConfigCryptoKeyTransient:PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationPrimitiveTransformationCryptoHashConfigCryptoKeyTransientÝTransient crypto key. Use this to have a random data crypto key generated. It will be discarded after the request finishes. Only one of this, `unwrapped` or `kms_wrapped` must be specified.
Structure is documented below.
Í
	unwrappedÎBË:È
Å
datalossPreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationPrimitiveTransformationCryptoHashConfigCryptoKeyUnwrapped¨gcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationPrimitiveTransformationCryptoHashConfigCryptoKeyUnwrapped:PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationPrimitiveTransformationCryptoHashConfigCryptoKeyUnwrappedîUnwrapped crypto key. Using raw keys is prone to security risks due to accidentally leaking the key. Choose another type of key if possible. Only one of this, `transient` or `kms_wrapped` must be specified.
Structure is documented below.
:ð
È
datalossPreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationPrimitiveTransformationCryptoHashConfigCryptoKeyKmsWrappedªgcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationPrimitiveTransformationCryptoHashConfigCryptoKeyKmsWrapped:PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationPrimitiveTransformationCryptoHashConfigCryptoKeyKmsWrapped¢
S
cryptoKeyName" >The resource name of the KMS CryptoKey to use for unwrapping.
H

wrappedKey" 6The wrapped data crypto key.
A base64-encoded string.
:É
Å
datalossPreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationPrimitiveTransformationCryptoHashConfigCryptoKeyTransient¨gcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationPrimitiveTransformationCryptoHashConfigCryptoKeyTransient:PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationPrimitiveTransformationCryptoHashConfigCryptoKeyTransientþ
ûø
name" ëName of the key. This is an arbitrary string used to differentiate different keys. A unique key is generated per name: two separate `TransientCryptoKey` protos share the same generated key if their names are the same. When the data crypto key is generated, this name is not used in any way (repeating the api call will result in a different key being generated).
:Ø
Å
datalossPreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationPrimitiveTransformationCryptoHashConfigCryptoKeyUnwrapped¨gcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationPrimitiveTransformationCryptoHashConfigCryptoKeyUnwrapped:PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationPrimitiveTransformationCryptoHashConfigCryptoKeyUnwrapped

key" |A 128/192/256 bit key.
A base64-encoded string.
**Note**: This property is sensitive and will not be displayed in the plan.
:©(
ª
datalossPreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationPrimitiveTransformationCryptoReplaceFfxFpeConfiggcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationPrimitiveTransformationCryptoReplaceFfxFpeConfig:PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationPrimitiveTransformationCryptoReplaceFfxFpeConfigù$
ö$É
commonAlphabetB" °Common alphabets. Only one of this, `custom_alphabet` or `radix` must be specified.
Possible values are: `NUMERIC`, `HEXADECIMAL`, `UPPER_CASE_ALPHA_NUMERIC`, `ALPHA_NUMERIC`.
¥

contextÈBÅ:Â
¿
datalossPreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationPrimitiveTransformationCryptoReplaceFfxFpeConfigContext¤gcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationPrimitiveTransformationCryptoReplaceFfxFpeConfigContext:PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationPrimitiveTransformationCryptoReplaceFfxFpeConfigContextÎThe 'tweak', a context may be used for higher security since the same identifier in two different contexts won't be given the same surrogate. If the context is not set, a default tweak will be used.
If the context is set but:
1.  there is no record present when transforming a given value or
2.  the field is not present when transforming a given value,
a default tweak will be used.
Note that case (1) is expected when an `InfoTypeTransformation` is applied to both structured and non-structured `ContentItem`s. Currently, the referenced field may be of value type integer or string.
The tweak is constructed as a sequence of bytes in big endian byte order such that:
*   a 64 bit integer is encoded followed by a single byte of value 1
*   a string is encoded in UTF-8 format followed by a single byte of value 2
Structure is documented below.
§
	cryptoKeyÎBË:È
Å
datalossPreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationPrimitiveTransformationCryptoReplaceFfxFpeConfigCryptoKey¨gcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationPrimitiveTransformationCryptoReplaceFfxFpeConfigCryptoKey:PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationPrimitiveTransformationCryptoReplaceFfxFpeConfigCryptoKeyIThe key used by the encryption algorithm.
Structure is documented below.
©
customAlphabetB" This is supported by mapping these to the alphanumeric characters that the FFX mode natively supports. This happens before/after encryption/decryption. Each character listed must appear only once. Number of characters must be in the range \[2, 95\]. This must be encoded as ASCII. The order of characters does not matter. The full list of allowed characters is:
``0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz ~`!@#$%^&*()_-+={[}]|:;"'<,>.?/``. Only one of this, `common_alphabet` or `radix` must be specified.
£
radixB The native way to select the alphabet. Must be in the range \[2, 95\]. Only one of this, `custom_alphabet` or `common_alphabet` must be specified.

surrogateInfoTypeæBã:à
Ý
datalossPreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationPrimitiveTransformationCryptoReplaceFfxFpeConfigSurrogateInfoType¸gcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationPrimitiveTransformationCryptoReplaceFfxFpeConfigSurrogateInfoType:PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationPrimitiveTransformationCryptoReplaceFfxFpeConfigSurrogateInfoTypeThe custom infoType to annotate the surrogate with. This annotation will be applied to the surrogate by prefixing it with the name of the custom infoType followed by the number of characters comprising the surrogate. The following scheme defines the format: info\_type\_name(surrogate\_character\_count):surrogate
For example, if the name of custom infoType is 'MY\_TOKEN\_INFO\_TYPE' and the surrogate is 'abc', the full replacement value will be: 'MY\_TOKEN\_INFO\_TYPE(3):abc'
This annotation identifies the surrogate when inspecting content using the custom infoType [`SurrogateType`](https://cloud.google.com/dlp/docs/reference/rest/v2/InspectConfig#surrogatetype). This facilitates reversal of the surrogate when it occurs in free text.
In order for inspection to work properly, the name of this infoType must not occur naturally anywhere in your data; otherwise, inspection may find a surrogate that does not correspond to an actual identifier. Therefore, choose your custom infoType name carefully after considering what your data looks like. One way to select a name that has a high chance of yielding reliable detection is to include one or more unicode characters that are highly improbable to exist in your data. For example, assuming your data is entered from a regular ASCII keyboard, the symbol with the hex code point 29DD might be used like so: â§MY\_TOKEN\_TYPE
Structure is documented below.
:ñ
¿
datalossPreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationPrimitiveTransformationCryptoReplaceFfxFpeConfigContext¤gcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationPrimitiveTransformationCryptoReplaceFfxFpeConfigContext:PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationPrimitiveTransformationCryptoReplaceFfxFpeConfigContext-
+)
nameB" Name describing the field.
:ð
Å
datalossPreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationPrimitiveTransformationCryptoReplaceFfxFpeConfigCryptoKey¨gcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationPrimitiveTransformationCryptoReplaceFfxFpeConfigCryptoKey:PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationPrimitiveTransformationCryptoReplaceFfxFpeConfigCryptoKey¥
¢Ú

kmsWrappedìBé:æ
ã
datalossPreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationPrimitiveTransformationCryptoReplaceFfxFpeConfigCryptoKeyKmsWrapped¼gcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationPrimitiveTransformationCryptoReplaceFfxFpeConfigCryptoKeyKmsWrapped:PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationPrimitiveTransformationCryptoReplaceFfxFpeConfigCryptoKeyKmsWrappedÜKMS wrapped key.
Include to use an existing data crypto key wrapped by KMS. The wrapped key must be a 128-, 192-, or 256-bit key. Authorization requires the following IAM permissions when sending a request to perform a crypto transformation using a KMS-wrapped crypto key: dlp.kms.encrypt
For more information, see [Creating a wrapped key](https://cloud.google.com/dlp/docs/create-wrapped-key). Only one of this, `transient` or `unwrapped` must be specified.
Note: When you use Cloud KMS for cryptographic operations, [charges apply](https://cloud.google.com/kms/pricing).
Structure is documented below.
×
	transientéBæ:ã
à
datalossPreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationPrimitiveTransformationCryptoReplaceFfxFpeConfigCryptoKeyTransientºgcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationPrimitiveTransformationCryptoReplaceFfxFpeConfigCryptoKeyTransient:PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationPrimitiveTransformationCryptoReplaceFfxFpeConfigCryptoKeyTransientÝTransient crypto key. Use this to have a random data crypto key generated. It will be discarded after the request finishes. Only one of this, `unwrapped` or `kms_wrapped` must be specified.
Structure is documented below.
è
	unwrappedéBæ:ã
à
datalossPreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationPrimitiveTransformationCryptoReplaceFfxFpeConfigCryptoKeyUnwrappedºgcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationPrimitiveTransformationCryptoReplaceFfxFpeConfigCryptoKeyUnwrapped:PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationPrimitiveTransformationCryptoReplaceFfxFpeConfigCryptoKeyUnwrappedîUnwrapped crypto key. Using raw keys is prone to security risks due to accidentally leaking the key. Choose another type of key if possible. Only one of this, `transient` or `kms_wrapped` must be specified.
Structure is documented below.
:
ã
datalossPreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationPrimitiveTransformationCryptoReplaceFfxFpeConfigCryptoKeyKmsWrapped¼gcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationPrimitiveTransformationCryptoReplaceFfxFpeConfigCryptoKeyKmsWrapped:PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationPrimitiveTransformationCryptoReplaceFfxFpeConfigCryptoKeyKmsWrapped¢
S
cryptoKeyName" >The resource name of the KMS CryptoKey to use for unwrapping.
H

wrappedKey" 6The wrapped data crypto key.
A base64-encoded string.
:ä
à
datalossPreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationPrimitiveTransformationCryptoReplaceFfxFpeConfigCryptoKeyTransientºgcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationPrimitiveTransformationCryptoReplaceFfxFpeConfigCryptoKeyTransient:PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationPrimitiveTransformationCryptoReplaceFfxFpeConfigCryptoKeyTransientþ
ûø
name" ëName of the key. This is an arbitrary string used to differentiate different keys. A unique key is generated per name: two separate `TransientCryptoKey` protos share the same generated key if their names are the same. When the data crypto key is generated, this name is not used in any way (repeating the api call will result in a different key being generated).
:ó
à
datalossPreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationPrimitiveTransformationCryptoReplaceFfxFpeConfigCryptoKeyUnwrappedºgcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationPrimitiveTransformationCryptoReplaceFfxFpeConfigCryptoKeyUnwrapped:PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationPrimitiveTransformationCryptoReplaceFfxFpeConfigCryptoKeyUnwrapped

key" |A 128/192/256 bit key.
A base64-encoded string.
**Note**: This property is sensitive and will not be displayed in the plan.
:×
Ý
datalossPreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationPrimitiveTransformationCryptoReplaceFfxFpeConfigSurrogateInfoType¸gcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationPrimitiveTransformationCryptoReplaceFfxFpeConfigSurrogateInfoType:PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationPrimitiveTransformationCryptoReplaceFfxFpeConfigSurrogateInfoTypeô
ñ
nameB" Name of the information type. Either a name of your choosing when creating a CustomInfoType, or one of the names listed at [https://cloud.google.com/dlp/docs/infotypes-reference](https://cloud.google.com/dlp/docs/infotypes-reference) when specifying a built-in type. When sending Cloud DLP results to Data Catalog, infoType names should conform to the pattern `[A-Za-z0-9$-_]{1,64}`.
 
sensitivityScoreB:

dataloss¥PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationPrimitiveTransformationCryptoReplaceFfxFpeConfigSurrogateInfoTypeSensitivityScoreØgcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationPrimitiveTransformationCryptoReplaceFfxFpeConfigSurrogateInfoTypeSensitivityScore:PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationPrimitiveTransformationCryptoReplaceFfxFpeConfigSurrogateInfoTypeSensitivityScoresOptional custom sensitivity for this InfoType. This only applies to data profiling.
Structure is documented below.
:
versionB" )Optional version name for this InfoType.
:ª

dataloss¥PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationPrimitiveTransformationCryptoReplaceFfxFpeConfigSurrogateInfoTypeSensitivityScoreØgcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationPrimitiveTransformationCryptoReplaceFfxFpeConfigSurrogateInfoTypeSensitivityScore:PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationPrimitiveTransformationCryptoReplaceFfxFpeConfigSurrogateInfoTypeSensitivityScore

score" The sensitivity score applied to the resource.
Possible values are: `SENSITIVITY_LOW`, `SENSITIVITY_MODERATE`, `SENSITIVITY_HIGH`.
:Ä

datalosszPreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationPrimitiveTransformationDateShiftConfiggcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationPrimitiveTransformationDateShiftConfig:PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationPrimitiveTransformationDateShiftConfig³
°û
contextªB§:¤
¡
datalossPreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationPrimitiveTransformationDateShiftConfigContextgcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationPrimitiveTransformationDateShiftConfigContext:PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationPrimitiveTransformationDateShiftConfigContextÂPoints to the field that contains the context, for example, an entity id.
If set, must also set cryptoKey. If set, shift will be consistent for the given context.
Structure is documented below.
©
	cryptoKey°B­:ª
§
datalossPreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationPrimitiveTransformationDateShiftConfigCryptoKeygcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationPrimitiveTransformationDateShiftConfigCryptoKey:PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationPrimitiveTransformationDateShiftConfigCryptoKeyèCauses the shift to be computed based on this key and the context. This results in the same shift for the same context and cryptoKey. If set, must also set context. Can only be applied to table items.
Structure is documented below.
[
lowerBoundDays EFor example, -5 means shift date to at most 5 days back in the past.
¦
upperBoundDays Range of shift in days. Actual shift will be selected at random within this range (inclusive ends). Negative means shift to earlier in time. Must not be more than 365250 days (1000 years) each direction.
For example, 3 means shift date to at most 3 days into the future.
:Ó
¡
datalossPreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationPrimitiveTransformationDateShiftConfigContextgcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationPrimitiveTransformationDateShiftConfigContext:PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationPrimitiveTransformationDateShiftConfigContext-
+)
nameB" Name describing the field.
:ø
§
datalossPreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationPrimitiveTransformationDateShiftConfigCryptoKeygcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationPrimitiveTransformationDateShiftConfigCryptoKey:PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationPrimitiveTransformationDateShiftConfigCryptoKeyË
È¼

kmsWrappedÎBË:È
Å
datalossPreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationPrimitiveTransformationDateShiftConfigCryptoKeyKmsWrapped¨gcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationPrimitiveTransformationDateShiftConfigCryptoKeyKmsWrapped:PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationPrimitiveTransformationDateShiftConfigCryptoKeyKmsWrappedÜKMS wrapped key.
Include to use an existing data crypto key wrapped by KMS. The wrapped key must be a 128-, 192-, or 256-bit key. Authorization requires the following IAM permissions when sending a request to perform a crypto transformation using a KMS-wrapped crypto key: dlp.kms.encrypt
For more information, see [Creating a wrapped key](https://cloud.google.com/dlp/docs/create-wrapped-key). Only one of this, `transient` or `unwrapped` must be specified.
Note: When you use Cloud KMS for cryptographic operations, [charges apply](https://cloud.google.com/kms/pricing).
Structure is documented below.
¹
	transientËBÈ:Å
Â
datalossPreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationPrimitiveTransformationDateShiftConfigCryptoKeyTransient¦gcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationPrimitiveTransformationDateShiftConfigCryptoKeyTransient:PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationPrimitiveTransformationDateShiftConfigCryptoKeyTransientÝTransient crypto key. Use this to have a random data crypto key generated. It will be discarded after the request finishes. Only one of this, `unwrapped` or `kms_wrapped` must be specified.
Structure is documented below.
Ê
	unwrappedËBÈ:Å
Â
datalossPreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationPrimitiveTransformationDateShiftConfigCryptoKeyUnwrapped¦gcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationPrimitiveTransformationDateShiftConfigCryptoKeyUnwrapped:PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationPrimitiveTransformationDateShiftConfigCryptoKeyUnwrappedîUnwrapped crypto key. Using raw keys is prone to security risks due to accidentally leaking the key. Choose another type of key if possible. Only one of this, `transient` or `kms_wrapped` must be specified.
Structure is documented below.
:í
Å
datalossPreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationPrimitiveTransformationDateShiftConfigCryptoKeyKmsWrapped¨gcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationPrimitiveTransformationDateShiftConfigCryptoKeyKmsWrapped:PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationPrimitiveTransformationDateShiftConfigCryptoKeyKmsWrapped¢
S
cryptoKeyName" >The resource name of the KMS CryptoKey to use for unwrapping.
H

wrappedKey" 6The wrapped data crypto key.
A base64-encoded string.
:Æ
Â
datalossPreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationPrimitiveTransformationDateShiftConfigCryptoKeyTransient¦gcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationPrimitiveTransformationDateShiftConfigCryptoKeyTransient:PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationPrimitiveTransformationDateShiftConfigCryptoKeyTransientþ
ûø
name" ëName of the key. This is an arbitrary string used to differentiate different keys. A unique key is generated per name: two separate `TransientCryptoKey` protos share the same generated key if their names are the same. When the data crypto key is generated, this name is not used in any way (repeating the api call will result in a different key being generated).
:Õ
Â
datalossPreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationPrimitiveTransformationDateShiftConfigCryptoKeyUnwrapped¦gcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationPrimitiveTransformationDateShiftConfigCryptoKeyUnwrapped:PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationPrimitiveTransformationDateShiftConfigCryptoKeyUnwrapped

key" |A 128/192/256 bit key.
A base64-encoded string.
**Note**: This property is sensitive and will not be displayed in the plan.
:­
§
datalossPreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationPrimitiveTransformationFixedSizeBucketingConfiggcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationPrimitiveTransformationFixedSizeBucketingConfig:PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationPrimitiveTransformationFixedSizeBucketingConfig
ý

bucketSize Size of each bucket (except for minimum and maximum buckets).
So if lower_bound = 10, upper_bound = 89, and bucketSize = 10, then the following buckets would be used: -10, 10-20, 20-30, 30-40, 40-50, 50-60, 60-70, 70-80, 80-89, 89+.
Precision up to 2 decimals works.
è

lowerBoundË:È
Å
datalossPreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationPrimitiveTransformationFixedSizeBucketingConfigLowerBound¨gcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationPrimitiveTransformationFixedSizeBucketingConfigLowerBound:PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationPrimitiveTransformationFixedSizeBucketingConfigLowerBoundLower bound value of buckets.
All values less than lower_bound are grouped together into a single bucket; for example if lower_bound = 10, then all values less than 10 are replaced with the value "-10".
The `lower_bound` block must only contain one argument. See the `fixed_size_bucketing_config` block description for more information about choosing a data type.
Structure is documented below.
î

upperBoundË:È
Å
datalossPreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationPrimitiveTransformationFixedSizeBucketingConfigUpperBound¨gcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationPrimitiveTransformationFixedSizeBucketingConfigUpperBound:PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationPrimitiveTransformationFixedSizeBucketingConfigUpperBoundUpper bound value of buckets.
All values greater than upper_bound are grouped together into a single bucket; for example if upper_bound = 89, then all values greater than 89 are replaced with the value "89+".
The `upper_bound` block must only contain one argument. See the `fixed_size_bucketing_config` block description for more information about choosing a data type.
Structure is documented below.
:ß
Å
datalossPreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationPrimitiveTransformationFixedSizeBucketingConfigLowerBound¨gcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationPrimitiveTransformationFixedSizeBucketingConfigLowerBound:PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationPrimitiveTransformationFixedSizeBucketingConfigLowerBound
'
booleanValueB
 A boolean value.
Å
	dateValueéBæ:ã
à
datalossPreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationPrimitiveTransformationFixedSizeBucketingConfigLowerBoundDateValueºgcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationPrimitiveTransformationFixedSizeBucketingConfigLowerBoundDateValue:PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationPrimitiveTransformationFixedSizeBucketingConfigLowerBoundDateValueLRepresents a whole or partial calendar date.
Structure is documented below.

dayOfWeekValueB" Represents a day of the week.
Possible values are: `MONDAY`, `TUESDAY`, `WEDNESDAY`, `THURSDAY`, `FRIDAY`, `SATURDAY`, `SUNDAY`.
#

floatValueB A float value.
6
integerValueB"  An integer value (int64 format)
%
stringValueB" A string value.
²
	timeValueéBæ:ã
à
datalossPreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationPrimitiveTransformationFixedSizeBucketingConfigLowerBoundTimeValueºgcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationPrimitiveTransformationFixedSizeBucketingConfigLowerBoundTimeValue:PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationPrimitiveTransformationFixedSizeBucketingConfigLowerBoundTimeValue9Represents a time of day.
Structure is documented below.
Ç
timestampValueB" ®A timestamp in RFC3339 UTC "Zulu" format, with nanosecond resolution and up to nine fractional digits. Examples: "2014-10-02T15:01:23Z" and "2014-10-02T15:01:23.045123456Z".
:ç
à
datalossPreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationPrimitiveTransformationFixedSizeBucketingConfigLowerBoundDateValueºgcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationPrimitiveTransformationFixedSizeBucketingConfigLowerBoundDateValue:PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationPrimitiveTransformationFixedSizeBucketingConfigLowerBoundDateValue
þ²
dayB ¤Day of a month. Must be from 1 to 31 and valid for the year and month, or 0 to specify a year by itself or a year and month where the day isn't significant.

- - -
f
monthB WMonth of a year. Must be from 1 to 12, or 0 to specify a year without a month and day.
_
yearB QYear of the date. Must be from 1 to 9999, or 0 to specify a date without a year.
:°
à
datalossPreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationPrimitiveTransformationFixedSizeBucketingConfigLowerBoundTimeValueºgcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationPrimitiveTransformationFixedSizeBucketingConfigLowerBoundTimeValue:PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationPrimitiveTransformationFixedSizeBucketingConfigLowerBoundTimeValueÊ
Ç¢
hoursB Hours of day in 24 hour format. Should be from 0 to 23. An API may choose to allow the value "24:00:00" for scenarios like business closing time.
?
minutesB .Minutes of hour of day. Must be from 0 to 59.
S
nanosB DFractions of seconds in nanoseconds. Must be from 0 to 999,999,999.

secondsB xSeconds of minutes of the time. Must normally be from 0 to 59. An API may allow the value 60 if it allows leap-seconds.
:ß
Å
datalossPreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationPrimitiveTransformationFixedSizeBucketingConfigUpperBound¨gcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationPrimitiveTransformationFixedSizeBucketingConfigUpperBound:PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationPrimitiveTransformationFixedSizeBucketingConfigUpperBound
'
booleanValueB
 A boolean value.
Å
	dateValueéBæ:ã
à
datalossPreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationPrimitiveTransformationFixedSizeBucketingConfigUpperBoundDateValueºgcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationPrimitiveTransformationFixedSizeBucketingConfigUpperBoundDateValue:PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationPrimitiveTransformationFixedSizeBucketingConfigUpperBoundDateValueLRepresents a whole or partial calendar date.
Structure is documented below.

dayOfWeekValueB" Represents a day of the week.
Possible values are: `MONDAY`, `TUESDAY`, `WEDNESDAY`, `THURSDAY`, `FRIDAY`, `SATURDAY`, `SUNDAY`.
#

floatValueB A float value.
6
integerValueB"  An integer value (int64 format)
%
stringValueB" A string value.
²
	timeValueéBæ:ã
à
datalossPreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationPrimitiveTransformationFixedSizeBucketingConfigUpperBoundTimeValueºgcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationPrimitiveTransformationFixedSizeBucketingConfigUpperBoundTimeValue:PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationPrimitiveTransformationFixedSizeBucketingConfigUpperBoundTimeValue9Represents a time of day.
Structure is documented below.
Ç
timestampValueB" ®A timestamp in RFC3339 UTC "Zulu" format, with nanosecond resolution and up to nine fractional digits. Examples: "2014-10-02T15:01:23Z" and "2014-10-02T15:01:23.045123456Z".
:ç
à
datalossPreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationPrimitiveTransformationFixedSizeBucketingConfigUpperBoundDateValueºgcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationPrimitiveTransformationFixedSizeBucketingConfigUpperBoundDateValue:PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationPrimitiveTransformationFixedSizeBucketingConfigUpperBoundDateValue
þ²
dayB ¤Day of a month. Must be from 1 to 31 and valid for the year and month, or 0 to specify a year by itself or a year and month where the day isn't significant.

- - -
f
monthB WMonth of a year. Must be from 1 to 12, or 0 to specify a year without a month and day.
_
yearB QYear of the date. Must be from 1 to 9999, or 0 to specify a date without a year.
:°
à
datalossPreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationPrimitiveTransformationFixedSizeBucketingConfigUpperBoundTimeValueºgcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationPrimitiveTransformationFixedSizeBucketingConfigUpperBoundTimeValue:PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationPrimitiveTransformationFixedSizeBucketingConfigUpperBoundTimeValueÊ
Ç¢
hoursB Hours of day in 24 hour format. Should be from 0 to 23. An API may choose to allow the value "24:00:00" for scenarios like business closing time.
?
minutesB .Minutes of hour of day. Must be from 0 to 59.
S
nanosB DFractions of seconds in nanoseconds. Must be from 0 to 999,999,999.

secondsB xSeconds of minutes of the time. Must normally be from 0 to 59. An API may allow the value 60 if it allows leap-seconds.
:

datalosswPreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationPrimitiveTransformationRedactConfigügcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationPrimitiveTransformationRedactConfig:PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationPrimitiveTransformationRedactConfig
 :ª

datalossxPreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationPrimitiveTransformationReplaceConfigþgcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationPrimitiveTransformationReplaceConfig:PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationPrimitiveTransformationReplaceConfig

newValue¤:¡

datalossPreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationPrimitiveTransformationReplaceConfigNewValuegcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationPrimitiveTransformationReplaceConfigNewValue:PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationPrimitiveTransformationReplaceConfigNewValueåReplace each input value with a given value.
The `new_value` block must only contain one argument. For example when replacing the contents of a string-type field, only `string_value` should be set.
Structure is documented below.
:ê

datalossPreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationPrimitiveTransformationReplaceConfigNewValuegcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationPrimitiveTransformationReplaceConfigNewValue:PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationPrimitiveTransformationReplaceConfigNewValueÆ
Ã'
booleanValueB
 A boolean value.

	dateValueÂB¿:¼
¹
datalossPreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationPrimitiveTransformationReplaceConfigNewValueDateValue gcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationPrimitiveTransformationReplaceConfigNewValueDateValue:PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationPrimitiveTransformationReplaceConfigNewValueDateValueLRepresents a whole or partial calendar date.
Structure is documented below.

dayOfWeekValueB" Represents a day of the week.
Possible values are: `MONDAY`, `TUESDAY`, `WEDNESDAY`, `THURSDAY`, `FRIDAY`, `SATURDAY`, `SUNDAY`.
#

floatValueB A float value.
6
integerValueB"  An integer value (int64 format)
%
stringValueB" A string value.

	timeValueÂB¿:¼
¹
datalossPreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationPrimitiveTransformationReplaceConfigNewValueTimeValue gcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationPrimitiveTransformationReplaceConfigNewValueTimeValue:PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationPrimitiveTransformationReplaceConfigNewValueTimeValue9Represents a time of day.
Structure is documented below.
Ç
timestampValueB" ®A timestamp in RFC3339 UTC "Zulu" format, with nanosecond resolution and up to nine fractional digits.
Examples: "2014-10-02T15:01:23Z" and "2014-10-02T15:01:23.045123456Z".
:À
¹
datalossPreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationPrimitiveTransformationReplaceConfigNewValueDateValue gcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationPrimitiveTransformationReplaceConfigNewValueDateValue:PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationPrimitiveTransformationReplaceConfigNewValueDateValue
þ²
dayB ¤Day of a month. Must be from 1 to 31 and valid for the year and month, or 0 to specify a year by itself or a year and month where the day isn't significant.

- - -
f
monthB WMonth of a year. Must be from 1 to 12, or 0 to specify a year without a month and day.
_
yearB QYear of the date. Must be from 1 to 9999, or 0 to specify a date without a year.
:
¹
datalossPreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationPrimitiveTransformationReplaceConfigNewValueTimeValue gcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationPrimitiveTransformationReplaceConfigNewValueTimeValue:PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationPrimitiveTransformationReplaceConfigNewValueTimeValueÊ
Ç¢
hoursB Hours of day in 24 hour format. Should be from 0 to 23. An API may choose to allow the value "24:00:00" for scenarios like business closing time.
?
minutesB .Minutes of hour of day. Must be from 0 to 59.
S
nanosB DFractions of seconds in nanoseconds. Must be from 0 to 999,999,999.

secondsB xSeconds of minutes of the time. Must normally be from 0 to 59. An API may allow the value 60 if it allows leap-seconds.
:Ê
¤
datalossPreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationPrimitiveTransformationReplaceDictionaryConfiggcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationPrimitiveTransformationReplaceDictionaryConfig:PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationPrimitiveTransformationReplaceDictionaryConfig 

wordListÅBÂ:¿
¼
datalossPreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationPrimitiveTransformationReplaceDictionaryConfigWordList¢gcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationPrimitiveTransformationReplaceDictionaryConfigWordList:PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationPrimitiveTransformationReplaceDictionaryConfigWordListÅA list of words to select from for random replacement. The [limits](https://cloud.google.com/dlp/limits) page contains details about the size limits of dictionaries.
Structure is documented below.
:
¼
datalossPreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationPrimitiveTransformationReplaceDictionaryConfigWordList¢gcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationPrimitiveTransformationReplaceDictionaryConfigWordList:PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationPrimitiveTransformationReplaceDictionaryConfigWordListÀ
½º
words*" ªWords or phrases defining the dictionary. The dictionary must contain at least one phrase and every phrase must contain at least 2 characters that are letters or digits.
:®

datalossyPreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationPrimitiveTransformationTimePartConfiggcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationPrimitiveTransformationTimePartConfig:PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsFieldTransformationPrimitiveTransformationTimePartConfig 

partToExtractB" The part of the time to keep.
Possible values are: `YEAR`, `MONTH`, `DAY_OF_MONTH`, `DAY_OF_WEEK`, `WEEK_OF_YEAR`, `HOUR_OF_DAY`.
:

datalossRPreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsRecordSuppression²gcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsRecordSuppression:PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsRecordSuppressionñ
îë
	condition·B´:±
®
dataloss[PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsRecordSuppressionConditionÄgcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsRecordSuppressionCondition:PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsRecordSuppressionCondition£A condition that when it evaluates to true will result in the record being evaluated to be suppressed from the transformed content.
Structure is documented below.
:ü
®
dataloss[PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsRecordSuppressionConditionÄgcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsRecordSuppressionCondition:PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsRecordSuppressionConditionÈ
ÅÂ
expressionsØBÕ:Ò
Ï
datalossfPreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsRecordSuppressionConditionExpressionsÚgcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsRecordSuppressionConditionExpressions:PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsRecordSuppressionConditionExpressionsXAn expression, consisting of an operator and conditions.
Structure is documented below.
:ß
Ï
datalossfPreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsRecordSuppressionConditionExpressionsÚgcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsRecordSuppressionConditionExpressions:PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsRecordSuppressionConditionExpressions
Í

conditionsöBó:ð
í
datalosspPreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsRecordSuppressionConditionExpressionsConditionsîgcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsRecordSuppressionConditionExpressionsConditions:PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsRecordSuppressionConditionExpressionsConditionsFConditions to apply to the expression.
Structure is documented below.
´
logicalOperatorB" The operator to apply to the result of conditions. Default and currently only supported value is AND.
Default value is `AND`.
Possible values are: `AND`.
:Ù
í
datalosspPreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsRecordSuppressionConditionExpressionsConditionsîgcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsRecordSuppressionConditionExpressionsConditions:PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsRecordSuppressionConditionExpressionsConditionsæ
ãà

conditionsB*:

datalossyPreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsRecordSuppressionConditionExpressionsConditionsConditiongcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsRecordSuppressionConditionExpressionsConditionsCondition:PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsRecordSuppressionConditionExpressionsConditionsCondition;A collection of conditions.
Structure is documented below.
:

datalossyPreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsRecordSuppressionConditionExpressionsConditionsConditiongcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsRecordSuppressionConditionExpressionsConditionsCondition:PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsRecordSuppressionConditionExpressionsConditionsConditionó	
ð	
field:

dataloss~PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsRecordSuppressionConditionExpressionsConditionsConditionFieldgcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsRecordSuppressionConditionExpressionsConditionsConditionField:PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsRecordSuppressionConditionExpressionsConditionsConditionField\Field within the record this condition is evaluated against.
Structure is documented below.
×
operator" ÆOperator used to compare the field or infoType to the value.
Possible values are: `EQUAL_TO`, `NOT_EQUAL_TO`, `GREATER_THAN`, `LESS_THAN`, `GREATER_THAN_OR_EQUALS`, `LESS_THAN_OR_EQUALS`, `EXISTS`.

value B:

dataloss~PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsRecordSuppressionConditionExpressionsConditionsConditionValuegcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsRecordSuppressionConditionExpressionsConditionsConditionValue:PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsRecordSuppressionConditionExpressionsConditionsConditionValue_Value to compare against. [Mandatory, except for EXISTS tests.]
Structure is documented below.
:É

dataloss~PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsRecordSuppressionConditionExpressionsConditionsConditionFieldgcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsRecordSuppressionConditionExpressionsConditionsConditionField:PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsRecordSuppressionConditionExpressionsConditionsConditionField-
+)
nameB" Name describing the field.
:×

dataloss~PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsRecordSuppressionConditionExpressionsConditionsConditionValuegcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsRecordSuppressionConditionExpressionsConditionsConditionValue:PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsRecordSuppressionConditionExpressionsConditionsConditionValueº
·'
booleanValueB
 A boolean value.

	dateValue¼B¹:¶
³
datalossPreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsRecordSuppressionConditionExpressionsConditionsConditionValueDateValuegcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsRecordSuppressionConditionExpressionsConditionsConditionValueDateValue:PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsRecordSuppressionConditionExpressionsConditionsConditionValueDateValueLRepresents a whole or partial calendar date.
Structure is documented below.

dayOfWeekValueB" Represents a day of the week.
Possible values are: `MONDAY`, `TUESDAY`, `WEDNESDAY`, `THURSDAY`, `FRIDAY`, `SATURDAY`, `SUNDAY`.
#

floatValueB A float value.
6
integerValueB"  An integer value (int64 format)
%
stringValueB" A string value.

	timeValue¼B¹:¶
³
datalossPreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsRecordSuppressionConditionExpressionsConditionsConditionValueTimeValuegcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsRecordSuppressionConditionExpressionsConditionsConditionValueTimeValue:PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsRecordSuppressionConditionExpressionsConditionsConditionValueTimeValue9Represents a time of day.
Structure is documented below.
Ç
timestampValueB" ®A timestamp in RFC3339 UTC "Zulu" format, with nanosecond resolution and up to nine fractional digits. Examples: "2014-10-02T15:01:23Z" and "2014-10-02T15:01:23.045123456Z".
:º
³
datalossPreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsRecordSuppressionConditionExpressionsConditionsConditionValueDateValuegcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsRecordSuppressionConditionExpressionsConditionsConditionValueDateValue:PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsRecordSuppressionConditionExpressionsConditionsConditionValueDateValue
þ²
dayB ¤Day of a month. Must be from 1 to 31 and valid for the year and month, or 0 to specify a year by itself or a year and month where the day isn't significant.

- - -
f
monthB WMonth of a year. Must be from 1 to 12, or 0 to specify a year without a month and day.
_
yearB QYear of the date. Must be from 1 to 9999, or 0 to specify a date without a year.
:
³
datalossPreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsRecordSuppressionConditionExpressionsConditionsConditionValueTimeValuegcp:dataloss/PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsRecordSuppressionConditionExpressionsConditionsConditionValueTimeValue:PreventionDeidentifyTemplateDeidentifyConfigRecordTransformationsRecordSuppressionConditionExpressionsConditionsConditionValueTimeValueÊ
Ç¢
hoursB Hours of day in 24 hour format. Should be from 0 to 23. An API may choose to allow the value "24:00:00" for scenarios like business closing time.
?
minutesB .Minutes of hour of day. Must be from 0 to 59.
S
nanosB DFractions of seconds in nanoseconds. Must be from 0 to 999,999,999.

secondsB xSeconds of minutes of the time. Must normally be from 0 to 59. An API may allow the value 60 if it allows leap-seconds.
:¤
y
datalossPreventionDiscoveryConfigActionLgcp:dataloss/PreventionDiscoveryConfigAction:PreventionDiscoveryConfigAction¦
£þ

exportData B:

dataloss)PreventionDiscoveryConfigActionExportData`gcp:dataloss/PreventionDiscoveryConfigActionExportData:PreventionDiscoveryConfigActionExportDataMExport data profiles into a provided location
Structure is documented below.

pubSubNotification¸Bµ:²
¯
dataloss1PreventionDiscoveryConfigActionPubSubNotificationpgcp:dataloss/PreventionDiscoveryConfigActionPubSubNotification:PreventionDiscoveryConfigActionPubSubNotificationIPublish a message into the Pub/Sub topic.
Structure is documented below.

tagResources¦B£: 

dataloss+PreventionDiscoveryConfigActionTagResourcesdgcp:dataloss/PreventionDiscoveryConfigActionTagResources:PreventionDiscoveryConfigActionTagResourcesIPublish a message into the Pub/Sub topic.
Structure is documented below.
:²

dataloss)PreventionDiscoveryConfigActionExportData`gcp:dataloss/PreventionDiscoveryConfigActionExportData:PreventionDiscoveryConfigActionExportData

profileTableÄBÁ:¾
»
dataloss5PreventionDiscoveryConfigActionExportDataProfileTablexgcp:dataloss/PreventionDiscoveryConfigActionExportDataProfileTable:PreventionDiscoveryConfigActionExportDataProfileTable·Store all table and column profiles in an existing table or a new table in an existing dataset. Each re-generation will result in a new row in BigQuery
Structure is documented below.
:±
»
dataloss5PreventionDiscoveryConfigActionExportDataProfileTablexgcp:dataloss/PreventionDiscoveryConfigActionExportDataProfileTable:PreventionDiscoveryConfigActionExportDataProfileTableð
í+
	datasetIdB" Dataset Id of the table

	projectIdB" The Google Cloud Platform project ID of the project containing the table. If omitted, the project ID is inferred from the API call.
#
tableIdB" Name of the table
:»
¯
dataloss1PreventionDiscoveryConfigActionPubSubNotificationpgcp:dataloss/PreventionDiscoveryConfigActionPubSubNotification:PreventionDiscoveryConfigActionPubSubNotification

detailOfMessageB" hHow much data to include in the pub/sub message.
Possible values are: `TABLE_PROFILE`, `RESOURCE_NAME`.
Ñ
eventB" ÁThe type of event that triggers a Pub/Sub. At most one PubSubNotification per EventType is permitted.
Possible values are: `NEW_PROFILE`, `CHANGED_PROFILE`, `SCORE_INCREASED`, `ERROR_CHANGED`.
¼
pubsubConditionæBã:à
Ý
dataloss@PreventionDiscoveryConfigActionPubSubNotificationPubsubConditiongcp:dataloss/PreventionDiscoveryConfigActionPubSubNotificationPubsubCondition:PreventionDiscoveryConfigActionPubSubNotificationPubsubCondition@Conditions for triggering pubsub
Structure is documented below.
j
topicB" [Cloud Pub/Sub topic to send notifications to. Format is projects/{project}/topics/{topic}.
:¯
Ý
dataloss@PreventionDiscoveryConfigActionPubSubNotificationPubsubConditiongcp:dataloss/PreventionDiscoveryConfigActionPubSubNotificationPubsubCondition:PreventionDiscoveryConfigActionPubSubNotificationPubsubConditionÌ
ÉÆ
expressionsB:
þ
datalossKPreventionDiscoveryConfigActionPubSubNotificationPubsubConditionExpressions¤gcp:dataloss/PreventionDiscoveryConfigActionPubSubNotificationPubsubConditionExpressions:PreventionDiscoveryConfigActionPubSubNotificationPubsubConditionExpressions-An expression
Structure is documented below.
:ø
þ
datalossKPreventionDiscoveryConfigActionPubSubNotificationPubsubConditionExpressions¤gcp:dataloss/PreventionDiscoveryConfigActionPubSubNotificationPubsubConditionExpressions:PreventionDiscoveryConfigActionPubSubNotificationPubsubConditionExpressionsô
ñû

conditions¥B¢*:

datalossTPreventionDiscoveryConfigActionPubSubNotificationPubsubConditionExpressionsCondition¶gcp:dataloss/PreventionDiscoveryConfigActionPubSubNotificationPubsubConditionExpressionsCondition:PreventionDiscoveryConfigActionPubSubNotificationPubsubConditionExpressionsConditionEConditions to apply to the expression
Structure is documented below.
q
logicalOperatorB" XThe operator to apply to the collection of conditions
Possible values are: `OR`, `AND`.
:µ

datalossTPreventionDiscoveryConfigActionPubSubNotificationPubsubConditionExpressionsCondition¶gcp:dataloss/PreventionDiscoveryConfigActionPubSubNotificationPubsubConditionExpressionsCondition:PreventionDiscoveryConfigActionPubSubNotificationPubsubConditionExpressionsCondition

minimumRiskScoreB" hThe minimum data risk score that triggers the condition.
Possible values are: `HIGH`, `MEDIUM_OR_HIGH`.

minimumSensitivityScoreB" jThe minimum sensitivity level that triggers the condition.
Possible values are: `HIGH`, `MEDIUM_OR_HIGH`.
:

dataloss+PreventionDiscoveryConfigActionTagResourcesdgcp:dataloss/PreventionDiscoveryConfigActionTagResources:PreventionDiscoveryConfigActionTagResourcesô

ñ
¦
lowerDataRiskToLowB
 Whether applying a tag to a resource should lower the risk of the profile for that resource. For example, in conjunction with an [IAM deny policy](https://cloud.google.com/iam/docs/deny-overview), you can deny all principals a permission if a tag value is present, mitigating the risk of the resource. This also lowers the data risk of resources at the lower levels of the resource hierarchy. For example, reducing the data risk of a table data profile also reduces the data risk of the constituent column data profiles.

profileGenerationsToTagsB*" ìThe profile generations for which the tag should be attached to resources. If you attach a tag to only new profiles, then if the sensitivity score of a profile subsequently changes, its tag doesn't change. By default, this field includes only new profiles. To include both new and updated profiles for tagging, this field should explicitly include both `PROFILE_GENERATION_NEW` and `PROFILE_GENERATION_UPDATE`.
Each value may be one of: `PROFILE_GENERATION_NEW`, `PROFILE_GENERATION_UPDATE`.
±
tagConditionsÍBÊ*Ç:Ä
Á
dataloss7PreventionDiscoveryConfigActionTagResourcesTagCondition|gcp:dataloss/PreventionDiscoveryConfigActionTagResourcesTagCondition:PreventionDiscoveryConfigActionTagResourcesTagConditionPThe tags to associate with different conditions.
Structure is documented below.
:ý
Á
dataloss7PreventionDiscoveryConfigActionTagResourcesTagCondition|gcp:dataloss/PreventionDiscoveryConfigActionTagResourcesTagCondition:PreventionDiscoveryConfigActionTagResourcesTagCondition¶
³
sensitivityScoreûBø:õ
ò
datalossGPreventionDiscoveryConfigActionTagResourcesTagConditionSensitivityScoregcp:dataloss/PreventionDiscoveryConfigActionTagResourcesTagConditionSensitivityScore:PreventionDiscoveryConfigActionTagResourcesTagConditionSensitivityScorexConditions attaching the tag to a resource on its profile having this sensitivity score.
Structure is documented below.
£
tagÔBÑ:Î
Ë
dataloss:PreventionDiscoveryConfigActionTagResourcesTagConditionTaggcp:dataloss/PreventionDiscoveryConfigActionTagResourcesTagConditionTag:PreventionDiscoveryConfigActionTagResourcesTagConditionTagEThe tag value to attach to resources.
Structure is documented below.
:
ò
datalossGPreventionDiscoveryConfigActionTagResourcesTagConditionSensitivityScoregcp:dataloss/PreventionDiscoveryConfigActionTagResourcesTagConditionSensitivityScore:PreventionDiscoveryConfigActionTagResourcesTagConditionSensitivityScore

score" The sensitivity score applied to the resource.
Possible values are: `SENSITIVITY_LOW`, `SENSITIVITY_MODERATE`, `SENSITIVITY_HIGH`.
:
Ë
dataloss:PreventionDiscoveryConfigActionTagResourcesTagConditionTaggcp:dataloss/PreventionDiscoveryConfigActionTagResourcesTagConditionTag:PreventionDiscoveryConfigActionTagResourcesTagConditionTagÍ
ÊÇ
namespacedValueB" ­The namespaced name for the tag value to attach to resources. Must be in the format `{parent_id}/{tag_key_short_name}/{short_name}`, for example, "123456/environment/prod".
:Å
v
datalossPreventionDiscoveryConfigErrorJgcp:dataloss/PreventionDiscoveryConfigError:PreventionDiscoveryConfigErrorÊ
ÇÓ
detailsB:

dataloss%PreventionDiscoveryConfigErrorDetailsXgcp:dataloss/PreventionDiscoveryConfigErrorDetails:PreventionDiscoveryConfigErrorDetails1A list of messages that carry the error details.
o
	timestampB" \The times the error occurred. List includes the oldest timestamp and the last 9 timestamps.
:

dataloss%PreventionDiscoveryConfigErrorDetailsXgcp:dataloss/PreventionDiscoveryConfigErrorDetails:PreventionDiscoveryConfigErrorDetailsð
íQ
codeB CThe status code, which should be an enum value of google.rpc.Code.
F
detailsB*2" 1A list of messages that carry the error details.
Ï
messageB" ½A developer-facing error message, which should be in English. Any user-facing error message should be localized and sent in the google.rpc.Status.details field, or localized by the client.
:Õ

dataloss"PreventionDiscoveryConfigOrgConfigRgcp:dataloss/PreventionDiscoveryConfigOrgConfig:PreventionDiscoveryConfigOrgConfigÍ
Êø
location£B :

dataloss*PreventionDiscoveryConfigOrgConfigLocationbgcp:dataloss/PreventionDiscoveryConfigOrgConfigLocation:PreventionDiscoveryConfigOrgConfigLocationFThe data to scan folder org or project
Structure is documented below.
Ì
	projectIdB" ¸The project that will run the scan. The DLP service account that exists within this project must have access to all resources that are profiled, and the cloud DLP API must be enabled.
:¨

dataloss*PreventionDiscoveryConfigOrgConfigLocationbgcp:dataloss/PreventionDiscoveryConfigOrgConfigLocation:PreventionDiscoveryConfigOrgConfigLocation
G
folderIdB" 5The ID for the folder within an organization to scan
:
organizationIdB" "The ID of an organization to scan
:Ó
y
datalossPreventionDiscoveryConfigTargetLgcp:dataloss/PreventionDiscoveryConfigTarget:PreventionDiscoveryConfigTargetÕ

Ò
º
bigQueryTarget¬B©:¦
£
dataloss-PreventionDiscoveryConfigTargetBigQueryTargethgcp:dataloss/PreventionDiscoveryConfigTargetBigQueryTarget:PreventionDiscoveryConfigTargetBigQueryTargetyBigQuery target for Discovery. The first target to match a table will be the one applied.
Structure is documented below.
»
cloudSqlTarget¬B©:¦
£
dataloss-PreventionDiscoveryConfigTargetCloudSqlTargethgcp:dataloss/PreventionDiscoveryConfigTargetCloudSqlTarget:PreventionDiscoveryConfigTargetCloudSqlTargetzCloud SQL target for Discovery. The first target to match a table will be the one applied.
Structure is documented below.
Ð
cloudStorageTarget¸Bµ:²
¯
dataloss1PreventionDiscoveryConfigTargetCloudStorageTargetpgcp:dataloss/PreventionDiscoveryConfigTargetCloudStorageTarget:PreventionDiscoveryConfigTargetCloudStorageTargetCloud Storage target for Discovery. The first target to match a bucket will be the one applied.
Structure is documented below.

secretsTarget©B¦:£
 
dataloss,PreventionDiscoveryConfigTargetSecretsTargetfgcp:dataloss/PreventionDiscoveryConfigTargetSecretsTarget:PreventionDiscoveryConfigTargetSecretsTargetÃDiscovery target that looks for credentials and secrets stored in cloud resource metadata and reports them as vulnerabilities to Security Command Center. Only one target of this type is allowed.
:
£
dataloss-PreventionDiscoveryConfigTargetBigQueryTargethgcp:dataloss/PreventionDiscoveryConfigTargetBigQueryTarget:PreventionDiscoveryConfigTargetBigQueryTargetó

ð

cadenceÁB¾:»
¸
dataloss4PreventionDiscoveryConfigTargetBigQueryTargetCadencevgcp:dataloss/PreventionDiscoveryConfigTargetBigQueryTargetCadence:PreventionDiscoveryConfigTargetBigQueryTargetCadence»How often and when to update profiles. New tables that match both the fiter and conditions are scanned as quickly as possible depending on system capacity.
Structure is documented below.
Ú

conditionsÊBÇ:Ä
Á
dataloss7PreventionDiscoveryConfigTargetBigQueryTargetConditions|gcp:dataloss/PreventionDiscoveryConfigTargetBigQueryTargetConditions:PreventionDiscoveryConfigTargetBigQueryTargetConditionsIn addition to matching the filter, these conditions must be true before a profile is generated
Structure is documented below.

disabledÄBÁ:¾
»
dataloss5PreventionDiscoveryConfigTargetBigQueryTargetDisabledxgcp:dataloss/PreventionDiscoveryConfigTargetBigQueryTargetDisabled:PreventionDiscoveryConfigTargetBigQueryTargetDisabled>Tables that match this filter will not have profiles created.
î
filter¾B»:¸
µ
dataloss3PreventionDiscoveryConfigTargetBigQueryTargetFiltertgcp:dataloss/PreventionDiscoveryConfigTargetBigQueryTargetFilter:PreventionDiscoveryConfigTargetBigQueryTargetFilter¢Required. The tables the discovery cadence applies to. The first target with a matching filter will be the one to apply to a table
Structure is documented below.
:Ê
¸
dataloss4PreventionDiscoveryConfigTargetBigQueryTargetCadencevgcp:dataloss/PreventionDiscoveryConfigTargetBigQueryTargetCadence:PreventionDiscoveryConfigTargetBigQueryTargetCadence



inspectTemplateModifiedCadenceB:

datalossRPreventionDiscoveryConfigTargetBigQueryTargetCadenceInspectTemplateModifiedCadence²gcp:dataloss/PreventionDiscoveryConfigTargetBigQueryTargetCadenceInspectTemplateModifiedCadence:PreventionDiscoveryConfigTargetBigQueryTargetCadenceInspectTemplateModifiedCadenceÒGoverns when to update data profiles when the inspection rules defined by the `InspectTemplate` change. If not set, changing the template will not cause a data profile to update.
Structure is documented below.
û
schemaModifiedCadenceBþ:û
ø
datalossIPreventionDiscoveryConfigTargetBigQueryTargetCadenceSchemaModifiedCadence gcp:dataloss/PreventionDiscoveryConfigTargetBigQueryTargetCadenceSchemaModifiedCadence:PreventionDiscoveryConfigTargetBigQueryTargetCadenceSchemaModifiedCadence^Governs when to update data profiles when a schema is modified
Structure is documented below.
ñ
tableModifiedCadenceþBû:ø
õ
datalossHPreventionDiscoveryConfigTargetBigQueryTargetCadenceTableModifiedCadencegcp:dataloss/PreventionDiscoveryConfigTargetBigQueryTargetCadenceTableModifiedCadence:PreventionDiscoveryConfigTargetBigQueryTargetCadenceTableModifiedCadenceXGoverns when to update profile when a table is modified.
Structure is documented below.
:ö

datalossRPreventionDiscoveryConfigTargetBigQueryTargetCadenceInspectTemplateModifiedCadence²gcp:dataloss/PreventionDiscoveryConfigTargetBigQueryTargetCadenceInspectTemplateModifiedCadence:PreventionDiscoveryConfigTargetBigQueryTargetCadenceInspectTemplateModifiedCadenceÝ
Ú×
	frequencyB" ÃHow frequently data profiles can be updated when the template is modified. Defaults to never.
Possible values are: `UPDATE_FREQUENCY_NEVER`, `UPDATE_FREQUENCY_DAILY`, `UPDATE_FREQUENCY_MONTHLY`.
:î
ø
datalossIPreventionDiscoveryConfigTargetBigQueryTargetCadenceSchemaModifiedCadence gcp:dataloss/PreventionDiscoveryConfigTargetBigQueryTargetCadenceSchemaModifiedCadence:PreventionDiscoveryConfigTargetBigQueryTargetCadenceSchemaModifiedCadenceð
íÑ
	frequencyB" ½Frequency to regenerate data profiles when the schema is modified. Defaults to monthly.
Possible values are: `UPDATE_FREQUENCY_NEVER`, `UPDATE_FREQUENCY_DAILY`, `UPDATE_FREQUENCY_MONTHLY`.

typesB*" The types of schema modifications to consider. Defaults to NEW_COLUMNS.
Each value may be one of: `NEW_COLUMNS`, `REMOVED_COLUMNS`.
:®
õ
datalossHPreventionDiscoveryConfigTargetBigQueryTargetCadenceTableModifiedCadencegcp:dataloss/PreventionDiscoveryConfigTargetBigQueryTargetCadenceTableModifiedCadence:PreventionDiscoveryConfigTargetBigQueryTargetCadenceTableModifiedCadence³
°Ò
	frequencyB" ¾How frequently data profiles can be updated when tables are modified. Defaults to never.
Possible values are: `UPDATE_FREQUENCY_NEVER`, `UPDATE_FREQUENCY_DAILY`, `UPDATE_FREQUENCY_MONTHLY`.
Ø
typesB*" ÆThe type of events to consider when deciding if the table has been modified and should have the profile updated. Defaults to MODIFIED_TIMESTAMP
Each value may be one of: `TABLE_MODIFIED_TIMESTAMP`.
:
Á
dataloss7PreventionDiscoveryConfigTargetBigQueryTargetConditions|gcp:dataloss/PreventionDiscoveryConfigTargetBigQueryTargetConditions:PreventionDiscoveryConfigTargetBigQueryTargetConditionsÃ

À
Ê
createdAfterB" ³File store must have been created after this date. Used to avoid backfilling. A timestamp in RFC3339 UTC "Zulu" format with nanosecond resolution and upto nine fractional digits.
è
orConditionsïBì:é
æ
datalossCPreventionDiscoveryConfigTargetBigQueryTargetConditionsOrConditionsgcp:dataloss/PreventionDiscoveryConfigTargetBigQueryTargetConditionsOrConditions:PreventionDiscoveryConfigTargetBigQueryTargetConditionsOrConditionsfAt least one of the conditions must be true for a table to be scanned.
Structure is documented below.

typeCollectionB" ðRestrict discovery to categories of table types. Currently view, materialized view, snapshot and non-biglake external tables are supported.
Possible values are: `BIG_QUERY_COLLECTION_ALL_TYPES`, `BIG_QUERY_COLLECTION_ONLY_SUPPORTED_TYPES`.
ù
typesÚB×:Ô
Ñ
dataloss<PreventionDiscoveryConfigTargetBigQueryTargetConditionsTypesgcp:dataloss/PreventionDiscoveryConfigTargetBigQueryTargetConditionsTypes:PreventionDiscoveryConfigTargetBigQueryTargetConditionsTypesData profiles will only be generated for the database resource types specified in this field. If not specified, defaults to [DATABASE_RESOURCE_TYPE_ALL_SUPPORTED_TYPES].
Each value may be one of: `DATABASE_RESOURCE_TYPE_ALL_SUPPORTED_TYPES`, `DATABASE_RESOURCE_TYPE_TABLE`.
:Ö
æ
datalossCPreventionDiscoveryConfigTargetBigQueryTargetConditionsOrConditionsgcp:dataloss/PreventionDiscoveryConfigTargetBigQueryTargetConditionsOrConditions:PreventionDiscoveryConfigTargetBigQueryTargetConditionsOrConditionsê
çz
minAgeB" jDuration format. The minimum age a table must have before Cloud DLP can profile it. Value greater than 1.
i
minRowCountB TMinimum number of rows that should be present before Cloud DLP profiles as a table.
:ï
Ñ
dataloss<PreventionDiscoveryConfigTargetBigQueryTargetConditionsTypesgcp:dataloss/PreventionDiscoveryConfigTargetBigQueryTargetConditionsTypes:PreventionDiscoveryConfigTargetBigQueryTargetConditionsTypes

typesB*" A set of BiqQuery table types
Each value may be one of: `BIG_QUERY_TABLE_TYPE_TABLE`, `BIG_QUERY_TABLE_TYPE_EXTERNAL_BIG_LAKE`.
:Â
»
dataloss5PreventionDiscoveryConfigTargetBigQueryTargetDisabledxgcp:dataloss/PreventionDiscoveryConfigTargetBigQueryTargetDisabled:PreventionDiscoveryConfigTargetBigQueryTargetDisabled
 :È

µ
dataloss3PreventionDiscoveryConfigTargetBigQueryTargetFiltertgcp:dataloss/PreventionDiscoveryConfigTargetBigQueryTargetFilter:PreventionDiscoveryConfigTargetBigQueryTargetFilter	
	Û
otherTablesàBÝ:Ú
×
dataloss>PreventionDiscoveryConfigTargetBigQueryTargetFilterOtherTablesgcp:dataloss/PreventionDiscoveryConfigTargetBigQueryTargetFilterOtherTables:PreventionDiscoveryConfigTargetBigQueryTargetFilterOtherTablesiCatch-all. This should always be the last filter in the list because anything above it will apply first.
®
tableReferenceéBæ:ã
à
datalossAPreventionDiscoveryConfigTargetBigQueryTargetFilterTableReferencegcp:dataloss/PreventionDiscoveryConfigTargetBigQueryTargetFilterTableReference:PreventionDiscoveryConfigTargetBigQueryTargetFilterTableReference¯The table to scan. Discovery configurations including this can only include one DiscoveryTarget (the DiscoveryTarget with this TableReference).
Structure is documented below.
ø
tablesÑBÎ:Ë
È
dataloss9PreventionDiscoveryConfigTargetBigQueryTargetFilterTablesgcp:dataloss/PreventionDiscoveryConfigTargetBigQueryTargetFilterTables:PreventionDiscoveryConfigTargetBigQueryTargetFilterTablesA specific set of tables for this filter to apply to. A table collection must be specified in only one filter per config.
Structure is documented below.
:Þ
×
dataloss>PreventionDiscoveryConfigTargetBigQueryTargetFilterOtherTablesgcp:dataloss/PreventionDiscoveryConfigTargetBigQueryTargetFilterOtherTables:PreventionDiscoveryConfigTargetBigQueryTargetFilterOtherTables
 :·
à
datalossAPreventionDiscoveryConfigTargetBigQueryTargetFilterTableReferencegcp:dataloss/PreventionDiscoveryConfigTargetBigQueryTargetFilterTableReference:PreventionDiscoveryConfigTargetBigQueryTargetFilterTableReferenceR
P*
	datasetId" Dataset ID of the table.
"
tableId" Name of the table.
:Ä
È
dataloss9PreventionDiscoveryConfigTargetBigQueryTargetFilterTablesgcp:dataloss/PreventionDiscoveryConfigTargetBigQueryTargetFilterTables:PreventionDiscoveryConfigTargetBigQueryTargetFilterTablesö
óð
includeRegexesûBø:õ
ò
datalossGPreventionDiscoveryConfigTargetBigQueryTargetFilterTablesIncludeRegexesgcp:dataloss/PreventionDiscoveryConfigTargetBigQueryTargetFilterTablesIncludeRegexes:PreventionDiscoveryConfigTargetBigQueryTargetFilterTablesIncludeRegexes`A collection of regular expressions to match a BQ table against.
Structure is documented below.
:î
ò
datalossGPreventionDiscoveryConfigTargetBigQueryTargetFilterTablesIncludeRegexesgcp:dataloss/PreventionDiscoveryConfigTargetBigQueryTargetFilterTablesIncludeRegexes:PreventionDiscoveryConfigTargetBigQueryTargetFilterTablesIncludeRegexesö
óð
patternsB*:

datalossNPreventionDiscoveryConfigTargetBigQueryTargetFilterTablesIncludeRegexesPatternªgcp:dataloss/PreventionDiscoveryConfigTargetBigQueryTargetFilterTablesIncludeRegexesPattern:PreventionDiscoveryConfigTargetBigQueryTargetFilterTablesIncludeRegexesPatternÍThe group of regular expression patterns to match against one or more file stores. Maximum of 100 entries. The sum of all lengths of regular expressions can't exceed 10 KiB.
Structure is documented below.
:³

datalossNPreventionDiscoveryConfigTargetBigQueryTargetFilterTablesIncludeRegexesPatternªgcp:dataloss/PreventionDiscoveryConfigTargetBigQueryTargetFilterTablesIncludeRegexesPattern:PreventionDiscoveryConfigTargetBigQueryTargetFilterTablesIncludeRegexesPattern¦
£E
datasetIdRegexB" -if unset, this property matches all datasets

projectIdRegexB" ~For organizations, if unset, will match all projects. Has no effect for data profile configurations created within a project.
A
tableIdRegexB" +if unset, this property matches all tables
:É
£
dataloss-PreventionDiscoveryConfigTargetCloudSqlTargethgcp:dataloss/PreventionDiscoveryConfigTargetCloudSqlTarget:PreventionDiscoveryConfigTargetCloudSqlTarget 
Ü

conditionsÊBÇ:Ä
Á
dataloss7PreventionDiscoveryConfigTargetCloudSqlTargetConditions|gcp:dataloss/PreventionDiscoveryConfigTargetCloudSqlTargetConditions:PreventionDiscoveryConfigTargetCloudSqlTargetConditionsIn addition to matching the filter, these conditions must be true before a profile is generated.
Structure is documented below.

disabledÄBÁ:¾
»
dataloss5PreventionDiscoveryConfigTargetCloudSqlTargetDisabledxgcp:dataloss/PreventionDiscoveryConfigTargetCloudSqlTargetDisabled:PreventionDiscoveryConfigTargetCloudSqlTargetDisabledADisable profiling for database resources that match this filter.
ì
filter»:¸
µ
dataloss3PreventionDiscoveryConfigTargetCloudSqlTargetFiltertgcp:dataloss/PreventionDiscoveryConfigTargetCloudSqlTargetFilter:PreventionDiscoveryConfigTargetCloudSqlTargetFilter£Required. The tables the discovery cadence applies to. The first target with a matching filter will be the one to apply to a table.
Structure is documented below.
µ
generationCadenceàBÝ:Ú
×
dataloss>PreventionDiscoveryConfigTargetCloudSqlTargetGenerationCadencegcp:dataloss/PreventionDiscoveryConfigTargetCloudSqlTargetGenerationCadence:PreventionDiscoveryConfigTargetCloudSqlTargetGenerationCadence¼How often and when to update profiles. New tables that match both the filter and conditions are scanned as quickly as possible depending on system capacity.
Structure is documented below.
:Ð
Á
dataloss7PreventionDiscoveryConfigTargetCloudSqlTargetConditions|gcp:dataloss/PreventionDiscoveryConfigTargetCloudSqlTargetConditions:PreventionDiscoveryConfigTargetCloudSqlTargetConditions
Ü
databaseEnginesB*" ÀDatabase engines that should be profiled. Optional. Defaults to ALL_SUPPORTED_DATABASE_ENGINES if unspecified.
Each value may be one of: `ALL_SUPPORTED_DATABASE_ENGINES`, `MYSQL`, `POSTGRES`.
¤
typesB*" Data profiles will only be generated for the database resource types specified in this field. If not specified, defaults to [DATABASE_RESOURCE_TYPE_ALL_SUPPORTED_TYPES].
Each value may be one of: `DATABASE_RESOURCE_TYPE_ALL_SUPPORTED_TYPES`, `DATABASE_RESOURCE_TYPE_TABLE`.
:Â
»
dataloss5PreventionDiscoveryConfigTargetCloudSqlTargetDisabledxgcp:dataloss/PreventionDiscoveryConfigTargetCloudSqlTargetDisabled:PreventionDiscoveryConfigTargetCloudSqlTargetDisabled
 :ô	
µ
dataloss3PreventionDiscoveryConfigTargetCloudSqlTargetFiltertgcp:dataloss/PreventionDiscoveryConfigTargetCloudSqlTargetFilter:PreventionDiscoveryConfigTargetCloudSqlTargetFilter¹
¶Ä

collectionÝBÚ:×
Ô
dataloss=PreventionDiscoveryConfigTargetCloudSqlTargetFilterCollectiongcp:dataloss/PreventionDiscoveryConfigTargetCloudSqlTargetFilterCollection:PreventionDiscoveryConfigTargetCloudSqlTargetFilterCollectionVA specific set of buckets for this filter to apply to.
Structure is documented below.
Ð
databaseResourceReferenceB:

datalossLPreventionDiscoveryConfigTargetCloudSqlTargetFilterDatabaseResourceReference¦gcp:dataloss/PreventionDiscoveryConfigTargetCloudSqlTargetFilterDatabaseResourceReference:PreventionDiscoveryConfigTargetCloudSqlTargetFilterDatabaseResourceReference¥The database resource to scan. Targets including this can only include one target (the target with this database resource reference).
Structure is documented below.

othersÑBÎ:Ë
È
dataloss9PreventionDiscoveryConfigTargetCloudSqlTargetFilterOthersgcp:dataloss/PreventionDiscoveryConfigTargetCloudSqlTargetFilterOthers:PreventionDiscoveryConfigTargetCloudSqlTargetFilterOthers;Match discovery resources not covered by any other filter.
:Þ
Ô
dataloss=PreventionDiscoveryConfigTargetCloudSqlTargetFilterCollectiongcp:dataloss/PreventionDiscoveryConfigTargetCloudSqlTargetFilterCollection:PreventionDiscoveryConfigTargetCloudSqlTargetFilterCollection
þ
includeRegexesB:
þ
datalossKPreventionDiscoveryConfigTargetCloudSqlTargetFilterCollectionIncludeRegexes¤gcp:dataloss/PreventionDiscoveryConfigTargetCloudSqlTargetFilterCollectionIncludeRegexes:PreventionDiscoveryConfigTargetCloudSqlTargetFilterCollectionIncludeRegexesbA collection of regular expressions to match a file store against.
Structure is documented below.
:
þ
datalossKPreventionDiscoveryConfigTargetCloudSqlTargetFilterCollectionIncludeRegexes¤gcp:dataloss/PreventionDiscoveryConfigTargetCloudSqlTargetFilterCollectionIncludeRegexes:PreventionDiscoveryConfigTargetCloudSqlTargetFilterCollectionIncludeRegexes
ÿü
patternsB*:

datalossRPreventionDiscoveryConfigTargetCloudSqlTargetFilterCollectionIncludeRegexesPattern²gcp:dataloss/PreventionDiscoveryConfigTargetCloudSqlTargetFilterCollectionIncludeRegexesPattern:PreventionDiscoveryConfigTargetCloudSqlTargetFilterCollectionIncludeRegexesPatternÍThe group of regular expression patterns to match against one or more file stores. Maximum of 100 entries. The sum of all lengths of regular expressions can't exceed 10 KiB.
Structure is documented below.
:

datalossRPreventionDiscoveryConfigTargetCloudSqlTargetFilterCollectionIncludeRegexesPattern²gcp:dataloss/PreventionDiscoveryConfigTargetCloudSqlTargetFilterCollectionIncludeRegexesPattern:PreventionDiscoveryConfigTargetCloudSqlTargetFilterCollectionIncludeRegexesPatternë
è_
databaseRegexB" HRegex to test the database name against. If empty, all databases match.

databaseResourceNameRegexB" æRegex to test the database resource's name against. An example of a database resource name is a table's name. Other database resource names like view names could be included in the future. If empty, all database resources match.'
_
instanceRegexB" HRegex to test the instance name against. If empty, all instances match.

projectIdRegexB" ~For organizations, if unset, will match all projects. Has no effect for data profile configurations created within a project.
:

datalossLPreventionDiscoveryConfigTargetCloudSqlTargetFilterDatabaseResourceReference¦gcp:dataloss/PreventionDiscoveryConfigTargetCloudSqlTargetFilterDatabaseResourceReference:PreventionDiscoveryConfigTargetCloudSqlTargetFilterDatabaseResourceReference
B
database" 2Required. Name of a database within the instance.
i
databaseResource" QRequired. Name of a database resource, for example, a table within the database.
k
instance" [Required. The instance where this resource is located. For example: Cloud SQL instance ID.
k
	projectId" ZRequired. If within a project-level config, then this must match the config's project ID.
:Ï
È
dataloss9PreventionDiscoveryConfigTargetCloudSqlTargetFilterOthersgcp:dataloss/PreventionDiscoveryConfigTargetCloudSqlTargetFilterOthers:PreventionDiscoveryConfigTargetCloudSqlTargetFilterOthers
 :û
×
dataloss>PreventionDiscoveryConfigTargetCloudSqlTargetGenerationCadencegcp:dataloss/PreventionDiscoveryConfigTargetCloudSqlTargetGenerationCadence:PreventionDiscoveryConfigTargetCloudSqlTargetGenerationCadence


²
inspectTemplateModifiedCadenceºB·:´
±
dataloss\PreventionDiscoveryConfigTargetCloudSqlTargetGenerationCadenceInspectTemplateModifiedCadenceÆgcp:dataloss/PreventionDiscoveryConfigTargetCloudSqlTargetGenerationCadenceInspectTemplateModifiedCadence:PreventionDiscoveryConfigTargetCloudSqlTargetGenerationCadenceInspectTemplateModifiedCadenceÒGoverns when to update data profiles when the inspection rules defined by the `InspectTemplate` change. If not set, changing the template will not cause a data profile to update.
Structure is documented below.
Ç
refreshFrequencyB" ¬Data changes in Cloud Storage can't trigger reprofiling. If you set this field, profiles are refreshed at this frequency regardless of whether the underlying buckets have changes. Defaults to never.
Possible values are: `UPDATE_FREQUENCY_NEVER`, `UPDATE_FREQUENCY_DAILY`, `UPDATE_FREQUENCY_MONTHLY`.

schemaModifiedCadenceB:

datalossSPreventionDiscoveryConfigTargetCloudSqlTargetGenerationCadenceSchemaModifiedCadence´gcp:dataloss/PreventionDiscoveryConfigTargetCloudSqlTargetGenerationCadenceSchemaModifiedCadence:PreventionDiscoveryConfigTargetCloudSqlTargetGenerationCadenceSchemaModifiedCadence^Governs when to update data profiles when a schema is modified
Structure is documented below.
:
±
dataloss\PreventionDiscoveryConfigTargetCloudSqlTargetGenerationCadenceInspectTemplateModifiedCadenceÆgcp:dataloss/PreventionDiscoveryConfigTargetCloudSqlTargetGenerationCadenceInspectTemplateModifiedCadence:PreventionDiscoveryConfigTargetCloudSqlTargetGenerationCadenceInspectTemplateModifiedCadenceÛ
ØÕ
	frequency" ÃHow frequently data profiles can be updated when the template is modified. Defaults to never.
Possible values are: `UPDATE_FREQUENCY_NEVER`, `UPDATE_FREQUENCY_DAILY`, `UPDATE_FREQUENCY_MONTHLY`.
:

datalossSPreventionDiscoveryConfigTargetCloudSqlTargetGenerationCadenceSchemaModifiedCadence´gcp:dataloss/PreventionDiscoveryConfigTargetCloudSqlTargetGenerationCadenceSchemaModifiedCadence:PreventionDiscoveryConfigTargetCloudSqlTargetGenerationCadenceSchemaModifiedCadenceð
íÑ
	frequencyB" ½Frequency to regenerate data profiles when the schema is modified. Defaults to monthly.
Possible values are: `UPDATE_FREQUENCY_NEVER`, `UPDATE_FREQUENCY_DAILY`, `UPDATE_FREQUENCY_MONTHLY`.

typesB*" The types of schema modifications to consider. Defaults to NEW_COLUMNS.
Each value may be one of: `NEW_COLUMNS`, `REMOVED_COLUMNS`.
:ö
¯
dataloss1PreventionDiscoveryConfigTargetCloudStorageTargetpgcp:dataloss/PreventionDiscoveryConfigTargetCloudStorageTarget:PreventionDiscoveryConfigTargetCloudStorageTargetÁ
¾é

conditions×BÔ:Ñ
Î
dataloss;PreventionDiscoveryConfigTargetCloudStorageTargetConditionsgcp:dataloss/PreventionDiscoveryConfigTargetCloudStorageTargetConditions:PreventionDiscoveryConfigTargetCloudStorageTargetConditionsIn addition to matching the filter, these conditions must be true before a profile is generated.
Structure is documented below.

disabledÑBÎ:Ë
È
dataloss9PreventionDiscoveryConfigTargetCloudStorageTargetDisabledgcp:dataloss/PreventionDiscoveryConfigTargetCloudStorageTargetDisabled:PreventionDiscoveryConfigTargetCloudStorageTargetDisabled6Disable profiling for buckets that match this filter.
ñ
filterÇ:Ä
Á
dataloss7PreventionDiscoveryConfigTargetCloudStorageTargetFilter|gcp:dataloss/PreventionDiscoveryConfigTargetCloudStorageTargetFilter:PreventionDiscoveryConfigTargetCloudStorageTargetFilterThe buckets the generation_cadence applies to. The first target with a matching filter will be the one to apply to a bucket.
Structure is documented below.
Â
generationCadenceìBé:æ
ã
datalossBPreventionDiscoveryConfigTargetCloudStorageTargetGenerationCadencegcp:dataloss/PreventionDiscoveryConfigTargetCloudStorageTargetGenerationCadence:PreventionDiscoveryConfigTargetCloudStorageTargetGenerationCadence½How often and when to update profiles. New buckets that match both the filter and conditions are scanned as quickly as possible depending on system capacity.
Structure is documented below.
:
Î
dataloss;PreventionDiscoveryConfigTargetCloudStorageTargetConditionsgcp:dataloss/PreventionDiscoveryConfigTargetCloudStorageTargetConditions:PreventionDiscoveryConfigTargetCloudStorageTargetConditions¶
³ï
cloudStorageConditionsB:

datalossQPreventionDiscoveryConfigTargetCloudStorageTargetConditionsCloudStorageConditions°gcp:dataloss/PreventionDiscoveryConfigTargetCloudStorageTargetConditionsCloudStorageConditions:PreventionDiscoveryConfigTargetCloudStorageTargetConditionsCloudStorageConditions9Cloud Storage conditions.
Structure is documented below.
Ê
createdAfterB" ³File store must have been created after this date. Used to avoid backfilling. A timestamp in RFC3339 UTC "Zulu" format with nanosecond resolution and upto nine fractional digits.
r
minAgeB" bDuration format. Minimum age a file store must have. If set, the value must be 1 hour or greater.
:ð

datalossQPreventionDiscoveryConfigTargetCloudStorageTargetConditionsCloudStorageConditions°gcp:dataloss/PreventionDiscoveryConfigTargetCloudStorageTargetConditionsCloudStorageConditions:PreventionDiscoveryConfigTargetCloudStorageTargetConditionsCloudStorageConditionsÚ
×í
includedBucketAttributesB*" ÈOnly objects with the specified attributes will be scanned. Defaults to [ALL_SUPPORTED_BUCKETS] if unset.
Each value may be one of: `ALL_SUPPORTED_BUCKETS`, `AUTOCLASS_DISABLED`, `AUTOCLASS_ENABLED`.
ä
includedObjectAttributesB*" ¿Only objects with the specified attributes will be scanned. If an object has one of the specified attributes but is inside an excluded bucket, it will not be scanned. Defaults to [ALL_SUPPORTED_OBJECTS]. A profile will be created even if no objects match the included_object_attributes.
Each value may be one of: `ALL_SUPPORTED_OBJECTS`, `STANDARD`, `NEARLINE`, `COLDLINE`, `ARCHIVE`, `REGIONAL`, `MULTI_REGIONAL`, `DURABLE_REDUCED_AVAILABILITY`.
:Ï
È
dataloss9PreventionDiscoveryConfigTargetCloudStorageTargetDisabledgcp:dataloss/PreventionDiscoveryConfigTargetCloudStorageTargetDisabled:PreventionDiscoveryConfigTargetCloudStorageTargetDisabled
 :²
Á
dataloss7PreventionDiscoveryConfigTargetCloudStorageTargetFilter|gcp:dataloss/PreventionDiscoveryConfigTargetCloudStorageTargetFilter:PreventionDiscoveryConfigTargetCloudStorageTargetFilterë	
è	ê
cloudStorageResourceReference¢B:

datalossTPreventionDiscoveryConfigTargetCloudStorageTargetFilterCloudStorageResourceReference¶gcp:dataloss/PreventionDiscoveryConfigTargetCloudStorageTargetFilterCloudStorageResourceReference:PreventionDiscoveryConfigTargetCloudStorageTargetFilterCloudStorageResourceReference£The bucket to scan. Targets including this can only include one target (the target with this bucket). This enables profiling the contents of a single bucket, while the other options allow for easy profiling of many buckets within a project or an organization.
Structure is documented below.
Ð

collectionéBæ:ã
à
datalossAPreventionDiscoveryConfigTargetCloudStorageTargetFilterCollectiongcp:dataloss/PreventionDiscoveryConfigTargetCloudStorageTargetFilterCollection:PreventionDiscoveryConfigTargetCloudStorageTargetFilterCollectionVA specific set of buckets for this filter to apply to.
Structure is documented below.
¥
othersÝBÚ:×
Ô
dataloss=PreventionDiscoveryConfigTargetCloudStorageTargetFilterOthersgcp:dataloss/PreventionDiscoveryConfigTargetCloudStorageTargetFilterOthers:PreventionDiscoveryConfigTargetCloudStorageTargetFilterOthers;Match discovery resources not covered by any other filter.
:±

datalossTPreventionDiscoveryConfigTargetCloudStorageTargetFilterCloudStorageResourceReference¶gcp:dataloss/PreventionDiscoveryConfigTargetCloudStorageTargetFilterCloudStorageResourceReference:PreventionDiscoveryConfigTargetCloudStorageTargetFilterCloudStorageResourceReference
(

bucketNameB" The bucket to scan.
c
	projectIdB" PIf within a project-level config, then this must match the config's project id.
:ö
à
datalossAPreventionDiscoveryConfigTargetCloudStorageTargetFilterCollectiongcp:dataloss/PreventionDiscoveryConfigTargetCloudStorageTargetFilterCollection:PreventionDiscoveryConfigTargetCloudStorageTargetFilterCollection

includeRegexesB:

datalossOPreventionDiscoveryConfigTargetCloudStorageTargetFilterCollectionIncludeRegexes¬gcp:dataloss/PreventionDiscoveryConfigTargetCloudStorageTargetFilterCollectionIncludeRegexes:PreventionDiscoveryConfigTargetCloudStorageTargetFilterCollectionIncludeRegexesbA collection of regular expressions to match a file store against.
Structure is documented below.
:

datalossOPreventionDiscoveryConfigTargetCloudStorageTargetFilterCollectionIncludeRegexes¬gcp:dataloss/PreventionDiscoveryConfigTargetCloudStorageTargetFilterCollectionIncludeRegexes:PreventionDiscoveryConfigTargetCloudStorageTargetFilterCollectionIncludeRegexes

patterns«B¨*¥:¢

datalossVPreventionDiscoveryConfigTargetCloudStorageTargetFilterCollectionIncludeRegexesPatternºgcp:dataloss/PreventionDiscoveryConfigTargetCloudStorageTargetFilterCollectionIncludeRegexesPattern:PreventionDiscoveryConfigTargetCloudStorageTargetFilterCollectionIncludeRegexesPatternÍThe group of regular expression patterns to match against one or more file stores. Maximum of 100 entries. The sum of all lengths of regular expressions can't exceed 10 KiB.
Structure is documented below.
:Ö

datalossVPreventionDiscoveryConfigTargetCloudStorageTargetFilterCollectionIncludeRegexesPatternºgcp:dataloss/PreventionDiscoveryConfigTargetCloudStorageTargetFilterCollectionIncludeRegexesPattern:PreventionDiscoveryConfigTargetCloudStorageTargetFilterCollectionIncludeRegexesPattern±
®«
cloudStorageRegexÛBØ:Õ
Ò
datalossgPreventionDiscoveryConfigTargetCloudStorageTargetFilterCollectionIncludeRegexesPatternCloudStorageRegexÜgcp:dataloss/PreventionDiscoveryConfigTargetCloudStorageTargetFilterCollectionIncludeRegexesPatternCloudStorageRegex:PreventionDiscoveryConfigTargetCloudStorageTargetFilterCollectionIncludeRegexesPatternCloudStorageRegex8Regex for Cloud Storage.
Structure is documented below.
:é
Ò
datalossgPreventionDiscoveryConfigTargetCloudStorageTargetFilterCollectionIncludeRegexesPatternCloudStorageRegexÜgcp:dataloss/PreventionDiscoveryConfigTargetCloudStorageTargetFilterCollectionIncludeRegexesPatternCloudStorageRegex:PreventionDiscoveryConfigTargetCloudStorageTargetFilterCollectionIncludeRegexesPatternCloudStorageRegex
»
bucketNameRegexB" ¡Regex to test the bucket name against. If empty, all buckets match. Example: "marketing2021" or "(marketing)\d{4}" will both match the bucket gs://marketing2021
N
projectIdRegexB" 6For organizations, if unset, will match all projects.
:Û
Ô
dataloss=PreventionDiscoveryConfigTargetCloudStorageTargetFilterOthersgcp:dataloss/PreventionDiscoveryConfigTargetCloudStorageTargetFilterOthers:PreventionDiscoveryConfigTargetCloudStorageTargetFilterOthers
 :÷
ã
datalossBPreventionDiscoveryConfigTargetCloudStorageTargetGenerationCadencegcp:dataloss/PreventionDiscoveryConfigTargetCloudStorageTargetGenerationCadence:PreventionDiscoveryConfigTargetCloudStorageTargetGenerationCadence
¾
inspectTemplateModifiedCadenceÆBÃ:À
½
dataloss`PreventionDiscoveryConfigTargetCloudStorageTargetGenerationCadenceInspectTemplateModifiedCadenceÎgcp:dataloss/PreventionDiscoveryConfigTargetCloudStorageTargetGenerationCadenceInspectTemplateModifiedCadence:PreventionDiscoveryConfigTargetCloudStorageTargetGenerationCadenceInspectTemplateModifiedCadenceÒGoverns when to update data profiles when the inspection rules defined by the `InspectTemplate` change. If not set, changing the template will not cause a data profile to update.
Structure is documented below.
Ç
refreshFrequencyB" ¬Data changes in Cloud Storage can't trigger reprofiling. If you set this field, profiles are refreshed at this frequency regardless of whether the underlying buckets have changes. Defaults to never.
Possible values are: `UPDATE_FREQUENCY_NEVER`, `UPDATE_FREQUENCY_DAILY`, `UPDATE_FREQUENCY_MONTHLY`.
: 
½
dataloss`PreventionDiscoveryConfigTargetCloudStorageTargetGenerationCadenceInspectTemplateModifiedCadenceÎgcp:dataloss/PreventionDiscoveryConfigTargetCloudStorageTargetGenerationCadenceInspectTemplateModifiedCadence:PreventionDiscoveryConfigTargetCloudStorageTargetGenerationCadenceInspectTemplateModifiedCadenceÝ
Ú×
	frequencyB" ÃHow frequently data profiles can be updated when the template is modified. Defaults to never.
Possible values are: `UPDATE_FREQUENCY_NEVER`, `UPDATE_FREQUENCY_DAILY`, `UPDATE_FREQUENCY_MONTHLY`.
:§
 
dataloss,PreventionDiscoveryConfigTargetSecretsTargetfgcp:dataloss/PreventionDiscoveryConfigTargetSecretsTarget:PreventionDiscoveryConfigTargetSecretsTarget
 :º

dataloss&PreventionInspectTemplateInspectConfigZgcp:dataloss/PreventionInspectTemplateInspectConfig:PreventionInspectTemplateInspectConfig¦
£Á
contentOptionsB*" ¦List of options defining data content to scan. If empty, text, images, and other content will be included.
Each value may be one of: `CONTENT_TEXT`, `CONTENT_IMAGE`.
ç
customInfoTypesÄBÁ*¾:»
¸
dataloss4PreventionInspectTemplateInspectConfigCustomInfoTypevgcp:dataloss/PreventionInspectTemplateInspectConfigCustomInfoType:PreventionInspectTemplateInspectConfigCustomInfoTypeCustom info types to be used. See https://cloud.google.com/dlp/docs/creating-custom-infotypes to learn more.
Structure is documented below.
P
excludeInfoTypesB
 6When true, excludes type information of the findings.
x
includeQuoteB
 bWhen true, a contextual quote from the data that triggered a finding is included in the response.
æ
	infoTypes²B¯*¬:©
¦
dataloss.PreventionInspectTemplateInspectConfigInfoTypejgcp:dataloss/PreventionInspectTemplateInspectConfigInfoType:PreventionInspectTemplateInspectConfigInfoType£Restricts what infoTypes to look for. The values must correspond to InfoType values returned by infoTypes.list
or listed at https://cloud.google.com/dlp/docs/infotypes-reference.
When no InfoTypes or CustomInfoTypes are specified in a request, the system may automatically choose what detectors to run.
By default this may be all types, but may change over time as detectors are updated.
Structure is documented below.

limits©B¦:£
 
dataloss,PreventionInspectTemplateInspectConfigLimitsfgcp:dataloss/PreventionInspectTemplateInspectConfigLimits:PreventionInspectTemplateInspectConfigLimitsYConfiguration to control the number of findings returned.
Structure is documented below.

minLikelihoodB" èOnly returns findings equal or above this threshold. See https://cloud.google.com/dlp/docs/likelihood for more info
Default value is `POSSIBLE`.
Possible values are: `VERY_UNLIKELY`, `UNLIKELY`, `POSSIBLE`, `LIKELY`, `VERY_LIKELY`.
¨
ruleSets¯B¬*©:¦
£
dataloss-PreventionInspectTemplateInspectConfigRuleSethgcp:dataloss/PreventionInspectTemplateInspectConfigRuleSet:PreventionInspectTemplateInspectConfigRuleSetéSet of rules to apply to the findings for this InspectConfig. Exclusion rules, contained in the set are executed in the end,
other rules are executed in the order they are specified for each info type.
Structure is documented below.
:­
¸
dataloss4PreventionInspectTemplateInspectConfigCustomInfoTypevgcp:dataloss/PreventionInspectTemplateInspectConfigCustomInfoType:PreventionInspectTemplateInspectConfigCustomInfoTypeï
ì³

dictionaryàBÝ:Ú
×
dataloss>PreventionInspectTemplateInspectConfigCustomInfoTypeDictionarygcp:dataloss/PreventionInspectTemplateInspectConfigCustomInfoTypeDictionary:PreventionInspectTemplateInspectConfigCustomInfoTypeDictionaryBDictionary which defines the rule.
Structure is documented below.
È
exclusionTypeB" °If set to EXCLUSION_TYPE_EXCLUDE this infoType will not cause a finding to be returned. It still can be used for rules matching.
Possible values are: `EXCLUSION_TYPE_EXCLUDE`.
ò
infoType×:Ô
Ñ
dataloss<PreventionInspectTemplateInspectConfigCustomInfoTypeInfoTypegcp:dataloss/PreventionInspectTemplateInspectConfigCustomInfoTypeInfoType:PreventionInspectTemplateInspectConfigCustomInfoTypeInfoTypeCustomInfoType can either be a new infoType, or an extension of built-in infoType, when the name matches one of existing
infoTypes and that infoType is specified in `info_types` field. Specifying the latter adds findings to the
one detected by the system. If built-in info type is not specified in `info_types` list then the name is
treated as a custom info type.
Structure is documented below.
¦

likelihoodB" Likelihood to return for this CustomInfoType. This base value can be altered by a detection rule if the finding meets the criteria
specified by the rule.
Default value is `VERY_LIKELY`.
Possible values are: `VERY_UNLIKELY`, `UNLIKELY`, `POSSIBLE`, `LIKELY`, `VERY_LIKELY`.
§
regexÑBÎ:Ë
È
dataloss9PreventionInspectTemplateInspectConfigCustomInfoTypeRegexgcp:dataloss/PreventionInspectTemplateInspectConfigCustomInfoTypeRegex:PreventionInspectTemplateInspectConfigCustomInfoTypeRegexJRegular expression which defines the rule.
Structure is documented below.
ü
sensitivityScoreòBï:ì
é
datalossDPreventionInspectTemplateInspectConfigCustomInfoTypeSensitivityScoregcp:dataloss/PreventionInspectTemplateInspectConfigCustomInfoTypeSensitivityScore:PreventionInspectTemplateInspectConfigCustomInfoTypeSensitivityScoresOptional custom sensitivity for this InfoType. This only applies to data profiling.
Structure is documented below.
Æ

storedTypeàBÝ:Ú
×
dataloss>PreventionInspectTemplateInspectConfigCustomInfoTypeStoredTypegcp:dataloss/PreventionInspectTemplateInspectConfigCustomInfoTypeStoredType:PreventionInspectTemplateInspectConfigCustomInfoTypeStoredTypeUA reference to a StoredInfoType to use with scanning.
Structure is documented below.
Ø
surrogateTypeéBæ:ã
à
datalossAPreventionInspectTemplateInspectConfigCustomInfoTypeSurrogateTypegcp:dataloss/PreventionInspectTemplateInspectConfigCustomInfoTypeSurrogateType:PreventionInspectTemplateInspectConfigCustomInfoTypeSurrogateType[Message for detecting output from deidentification transformations that support reversing.
:Ì
×
dataloss>PreventionInspectTemplateInspectConfigCustomInfoTypeDictionarygcp:dataloss/PreventionInspectTemplateInspectConfigCustomInfoTypeDictionary:PreventionInspectTemplateInspectConfigCustomInfoTypeDictionaryï
ì
cloudStoragePathB:

datalossNPreventionInspectTemplateInspectConfigCustomInfoTypeDictionaryCloudStoragePathªgcp:dataloss/PreventionInspectTemplateInspectConfigCustomInfoTypeDictionaryCloudStoragePath:PreventionInspectTemplateInspectConfigCustomInfoTypeDictionaryCloudStoragePathqNewline-delimited file of words in Cloud Storage. Only a single file is accepted.
Structure is documented below.
Î
wordListøBõ:ò
ï
datalossFPreventionInspectTemplateInspectConfigCustomInfoTypeDictionaryWordListgcp:dataloss/PreventionInspectTemplateInspectConfigCustomInfoTypeDictionaryWordList:PreventionInspectTemplateInspectConfigCustomInfoTypeDictionaryWordListGList of words or phrases to search for.
Structure is documented below.
:

datalossNPreventionInspectTemplateInspectConfigCustomInfoTypeDictionaryCloudStoragePathªgcp:dataloss/PreventionInspectTemplateInspectConfigCustomInfoTypeDictionaryCloudStoragePath:PreventionInspectTemplateInspectConfigCustomInfoTypeDictionaryCloudStoragePath
~|
path" pA url representing a file or path (no wildcards) in Cloud Storage. Example: `gs://[BUCKET_NAME]/dictionary.txt`
:µ
ï
datalossFPreventionInspectTemplateInspectConfigCustomInfoTypeDictionaryWordListgcp:dataloss/PreventionInspectTemplateInspectConfigCustomInfoTypeDictionaryWordList:PreventionInspectTemplateInspectConfigCustomInfoTypeDictionaryWordListÀ
½º
words*" ªWords or phrases defining the dictionary. The dictionary must contain at least one
phrase and every phrase must contain at least 2 characters that are letters or digits.
:
Ñ
dataloss<PreventionInspectTemplateInspectConfigCustomInfoTypeInfoTypegcp:dataloss/PreventionInspectTemplateInspectConfigCustomInfoTypeInfoType:PreventionInspectTemplateInspectConfigCustomInfoTypeInfoType¯
¬ß
name" ÒName of the information type. Either a name of your choosing when creating a CustomInfoType, or one of the names
listed at https://cloud.google.com/dlp/docs/infotypes-reference when specifying a built-in type.

sensitivityScoreB:

datalossLPreventionInspectTemplateInspectConfigCustomInfoTypeInfoTypeSensitivityScore¦gcp:dataloss/PreventionInspectTemplateInspectConfigCustomInfoTypeInfoTypeSensitivityScore:PreventionInspectTemplateInspectConfigCustomInfoTypeInfoTypeSensitivityScoresOptional custom sensitivity for this InfoType. This only applies to data profiling.
Structure is documented below.
1
versionB"  Version name for this InfoType.
:

datalossLPreventionInspectTemplateInspectConfigCustomInfoTypeInfoTypeSensitivityScore¦gcp:dataloss/PreventionInspectTemplateInspectConfigCustomInfoTypeInfoTypeSensitivityScore:PreventionInspectTemplateInspectConfigCustomInfoTypeInfoTypeSensitivityScore

score" The sensitivity score applied to the resource.
Possible values are: `SENSITIVITY_LOW`, `SENSITIVITY_MODERATE`, `SENSITIVITY_HIGH`.
:
È
dataloss9PreventionInspectTemplateInspectConfigCustomInfoTypeRegexgcp:dataloss/PreventionInspectTemplateInspectConfigCustomInfoTypeRegex:PreventionInspectTemplateInspectConfigCustomInfoTypeRegexÎ
Ë
groupIndexesB* The index of the submatch to extract as findings. When not specified, the entire match is returned. No more than 3 may be included.
¨
pattern" Pattern defining the regular expression.
Its syntax (https://github.com/google/re2/wiki/Syntax) can be found under the google/re2 repository on GitHub.
:
é
datalossDPreventionInspectTemplateInspectConfigCustomInfoTypeSensitivityScoregcp:dataloss/PreventionInspectTemplateInspectConfigCustomInfoTypeSensitivityScore:PreventionInspectTemplateInspectConfigCustomInfoTypeSensitivityScore

score" The sensitivity score applied to the resource.
Possible values are: `SENSITIVITY_LOW`, `SENSITIVITY_MODERATE`, `SENSITIVITY_HIGH`.
:
×
dataloss>PreventionInspectTemplateInspectConfigCustomInfoTypeStoredTypegcp:dataloss/PreventionInspectTemplateInspectConfigCustomInfoTypeStoredType:PreventionInspectTemplateInspectConfigCustomInfoTypeStoredType¶
³°
name" £Resource name of the requested StoredInfoType, for example `organizations/433245324/storedInfoTypes/432452342`
or `projects/project-id/storedInfoTypes/432452342`.
:ç
à
datalossAPreventionInspectTemplateInspectConfigCustomInfoTypeSurrogateTypegcp:dataloss/PreventionInspectTemplateInspectConfigCustomInfoTypeSurrogateType:PreventionInspectTemplateInspectConfigCustomInfoTypeSurrogateType
 :±
¦
dataloss.PreventionInspectTemplateInspectConfigInfoTypejgcp:dataloss/PreventionInspectTemplateInspectConfigInfoType:PreventionInspectTemplateInspectConfigInfoType
ß
name" ÒName of the information type. Either a name of your choosing when creating a CustomInfoType, or one of the names listed
at https://cloud.google.com/dlp/docs/infotypes-reference when specifying a built-in type.
ê
sensitivityScoreàBÝ:Ú
×
dataloss>PreventionInspectTemplateInspectConfigInfoTypeSensitivityScoregcp:dataloss/PreventionInspectTemplateInspectConfigInfoTypeSensitivityScore:PreventionInspectTemplateInspectConfigInfoTypeSensitivityScoresOptional custom sensitivity for this InfoType. This only applies to data profiling.
Structure is documented below.
1
versionB"  Version name for this InfoType.
:ô
×
dataloss>PreventionInspectTemplateInspectConfigInfoTypeSensitivityScoregcp:dataloss/PreventionInspectTemplateInspectConfigInfoTypeSensitivityScore:PreventionInspectTemplateInspectConfigInfoTypeSensitivityScore

score" The sensitivity score applied to the resource.
Possible values are: `SENSITIVITY_LOW`, `SENSITIVITY_MODERATE`, `SENSITIVITY_HIGH`.
:
 
dataloss,PreventionInspectTemplateInspectConfigLimitsfgcp:dataloss/PreventionInspectTemplateInspectConfigLimits:PreventionInspectTemplateInspectConfigLimitsê
çë
maxFindingsPerInfoTypesïBì*é:æ
ã
datalossBPreventionInspectTemplateInspectConfigLimitsMaxFindingsPerInfoTypegcp:dataloss/PreventionInspectTemplateInspectConfigLimitsMaxFindingsPerInfoType:PreventionInspectTemplateInspectConfigLimitsMaxFindingsPerInfoType^Configuration of findings limit given for specified infoTypes.
Structure is documented below.
|
maxFindingsPerItem bMax number of findings that will be returned for each item scanned. The maximum returned is 2000.
y
maxFindingsPerRequest \Max number of findings that will be returned per request/job. The maximum returned is 2000.
:à
ã
datalossBPreventionInspectTemplateInspectConfigLimitsMaxFindingsPerInfoTypegcp:dataloss/PreventionInspectTemplateInspectConfigLimitsMaxFindingsPerInfoType:PreventionInspectTemplateInspectConfigLimitsMaxFindingsPerInfoType÷
ô±
infoTypeB:þ
û
datalossJPreventionInspectTemplateInspectConfigLimitsMaxFindingsPerInfoTypeInfoType¢gcp:dataloss/PreventionInspectTemplateInspectConfigLimitsMaxFindingsPerInfoTypeInfoType:PreventionInspectTemplateInspectConfigLimitsMaxFindingsPerInfoTypeInfoTypeType of information the findings limit applies to. Only one limit per infoType should be provided. If InfoTypeLimit does
not have an infoType, the DLP API applies the limit against all infoTypes that are found but not
specified in another InfoTypeLimit.
Structure is documented below.
>
maxFindings +Max findings limit for the given infoType.
:Ú
û
datalossJPreventionInspectTemplateInspectConfigLimitsMaxFindingsPerInfoTypeInfoType¢gcp:dataloss/PreventionInspectTemplateInspectConfigLimitsMaxFindingsPerInfoTypeInfoType:PreventionInspectTemplateInspectConfigLimitsMaxFindingsPerInfoTypeInfoTypeÙ
Öß
name" ÒName of the information type. Either a name of your choosing when creating a CustomInfoType, or one of the names
listed at https://cloud.google.com/dlp/docs/infotypes-reference when specifying a built-in type.
¾
sensitivityScore´B±:®
«
datalossZPreventionInspectTemplateInspectConfigLimitsMaxFindingsPerInfoTypeInfoTypeSensitivityScoreÂgcp:dataloss/PreventionInspectTemplateInspectConfigLimitsMaxFindingsPerInfoTypeInfoTypeSensitivityScore:PreventionInspectTemplateInspectConfigLimitsMaxFindingsPerInfoTypeInfoTypeSensitivityScoresOptional custom sensitivity for this InfoType. This only applies to data profiling.
Structure is documented below.
1
versionB"  Version name for this InfoType.
:È
«
datalossZPreventionInspectTemplateInspectConfigLimitsMaxFindingsPerInfoTypeInfoTypeSensitivityScoreÂgcp:dataloss/PreventionInspectTemplateInspectConfigLimitsMaxFindingsPerInfoTypeInfoTypeSensitivityScore:PreventionInspectTemplateInspectConfigLimitsMaxFindingsPerInfoTypeInfoTypeSensitivityScore

score" The sensitivity score applied to the resource.
Possible values are: `SENSITIVITY_LOW`, `SENSITIVITY_MODERATE`, `SENSITIVITY_HIGH`.
:
£
dataloss-PreventionInspectTemplateInspectConfigRuleSethgcp:dataloss/PreventionInspectTemplateInspectConfigRuleSet:PreventionInspectTemplateInspectConfigRuleSet×
Ô¢
	infoTypesÄ*Á:¾
»
dataloss5PreventionInspectTemplateInspectConfigRuleSetInfoTypexgcp:dataloss/PreventionInspectTemplateInspectConfigRuleSetInfoType:PreventionInspectTemplateInspectConfigRuleSetInfoTypeNList of infoTypes this rule set is applied to.
Structure is documented below.
¬
rules¸*µ:²
¯
dataloss1PreventionInspectTemplateInspectConfigRuleSetRulepgcp:dataloss/PreventionInspectTemplateInspectConfigRuleSetRule:PreventionInspectTemplateInspectConfigRuleSetRulehSet of rules to be applied to infoTypes. The rules are applied in order.
Structure is documented below.
:Û
»
dataloss5PreventionInspectTemplateInspectConfigRuleSetInfoTypexgcp:dataloss/PreventionInspectTemplateInspectConfigRuleSetInfoType:PreventionInspectTemplateInspectConfigRuleSetInfoType
ß
name" ÒName of the information type. Either a name of your choosing when creating a CustomInfoType, or one of the names listed
at https://cloud.google.com/dlp/docs/infotypes-reference when specifying a built-in type.
ÿ
sensitivityScoreõBò:ï
ì
datalossEPreventionInspectTemplateInspectConfigRuleSetInfoTypeSensitivityScoregcp:dataloss/PreventionInspectTemplateInspectConfigRuleSetInfoTypeSensitivityScore:PreventionInspectTemplateInspectConfigRuleSetInfoTypeSensitivityScoresOptional custom sensitivity for this InfoType. This only applies to data profiling.
Structure is documented below.
1
versionB"  Version name for this InfoType.
:
ì
datalossEPreventionInspectTemplateInspectConfigRuleSetInfoTypeSensitivityScoregcp:dataloss/PreventionInspectTemplateInspectConfigRuleSetInfoTypeSensitivityScore:PreventionInspectTemplateInspectConfigRuleSetInfoTypeSensitivityScore

score" The sensitivity score applied to the resource.
Possible values are: `SENSITIVITY_LOW`, `SENSITIVITY_MODERATE`, `SENSITIVITY_HIGH`.
:ò
¯
dataloss1PreventionInspectTemplateInspectConfigRuleSetRulepgcp:dataloss/PreventionInspectTemplateInspectConfigRuleSetRule:PreventionInspectTemplateInspectConfigRuleSetRule½
º
exclusionRuleàBÝ:Ú
×
dataloss>PreventionInspectTemplateInspectConfigRuleSetRuleExclusionRulegcp:dataloss/PreventionInspectTemplateInspectConfigRuleSetRuleExclusionRule:PreventionInspectTemplateInspectConfigRuleSetRuleExclusionRuleThe rule that specifies conditions when findings of infoTypes specified in InspectionRuleSet are removed from results.
Structure is documented below.
©
hotwordRuleÚB×:Ô
Ñ
dataloss<PreventionInspectTemplateInspectConfigRuleSetRuleHotwordRulegcp:dataloss/PreventionInspectTemplateInspectConfigRuleSetRuleHotwordRule:PreventionInspectTemplateInspectConfigRuleSetRuleHotwordRule=Hotword-based detection rule.
Structure is documented below.
:Þ
×
dataloss>PreventionInspectTemplateInspectConfigRuleSetRuleExclusionRulegcp:dataloss/PreventionInspectTemplateInspectConfigRuleSetRuleExclusionRule:PreventionInspectTemplateInspectConfigRuleSetRuleExclusionRule
þÑ

dictionaryþBû:ø
õ
datalossHPreventionInspectTemplateInspectConfigRuleSetRuleExclusionRuleDictionarygcp:dataloss/PreventionInspectTemplateInspectConfigRuleSetRuleExclusionRuleDictionary:PreventionInspectTemplateInspectConfigRuleSetRuleExclusionRuleDictionaryBDictionary which defines the rule.
Structure is documented below.
¿
excludeByHotwordB:

datalossNPreventionInspectTemplateInspectConfigRuleSetRuleExclusionRuleExcludeByHotwordªgcp:dataloss/PreventionInspectTemplateInspectConfigRuleSetRuleExclusionRuleExcludeByHotword:PreventionInspectTemplateInspectConfigRuleSetRuleExclusionRuleExcludeByHotwordDrop if the hotword rule is contained in the proximate context.
For tabular data, the context includes the column name.
Structure is documented below.

excludeInfoTypesB:

datalossNPreventionInspectTemplateInspectConfigRuleSetRuleExclusionRuleExcludeInfoTypesªgcp:dataloss/PreventionInspectTemplateInspectConfigRuleSetRuleExclusionRuleExcludeInfoTypes:PreventionInspectTemplateInspectConfigRuleSetRuleExclusionRuleExcludeInfoTypes[Set of infoTypes for which findings would affect this rule.
Structure is documented below.

matchingType" How the rule is applied. See the documentation for more information: https://cloud.google.com/dlp/docs/reference/rest/v2/InspectConfig#MatchingType
Possible values are: `MATCHING_TYPE_FULL_MATCH`, `MATCHING_TYPE_PARTIAL_MATCH`, `MATCHING_TYPE_INVERSE_MATCH`.
Å
regexïBì:é
æ
datalossCPreventionInspectTemplateInspectConfigRuleSetRuleExclusionRuleRegexgcp:dataloss/PreventionInspectTemplateInspectConfigRuleSetRuleExclusionRuleRegex:PreventionInspectTemplateInspectConfigRuleSetRuleExclusionRuleRegexJRegular expression which defines the rule.
Structure is documented below.
:¦
õ
datalossHPreventionInspectTemplateInspectConfigRuleSetRuleExclusionRuleDictionarygcp:dataloss/PreventionInspectTemplateInspectConfigRuleSetRuleExclusionRuleDictionary:PreventionInspectTemplateInspectConfigRuleSetRuleExclusionRuleDictionary«
¨¶
cloudStoragePath®B«:¨
¥
datalossXPreventionInspectTemplateInspectConfigRuleSetRuleExclusionRuleDictionaryCloudStoragePath¾gcp:dataloss/PreventionInspectTemplateInspectConfigRuleSetRuleExclusionRuleDictionaryCloudStoragePath:PreventionInspectTemplateInspectConfigRuleSetRuleExclusionRuleDictionaryCloudStoragePathqNewline-delimited file of words in Cloud Storage. Only a single file is accepted.
Structure is documented below.
ì
wordListB:

datalossPPreventionInspectTemplateInspectConfigRuleSetRuleExclusionRuleDictionaryWordList®gcp:dataloss/PreventionInspectTemplateInspectConfigRuleSetRuleExclusionRuleDictionaryWordList:PreventionInspectTemplateInspectConfigRuleSetRuleExclusionRuleDictionaryWordListGList of words or phrases to search for.
Structure is documented below.
:«
¥
datalossXPreventionInspectTemplateInspectConfigRuleSetRuleExclusionRuleDictionaryCloudStoragePath¾gcp:dataloss/PreventionInspectTemplateInspectConfigRuleSetRuleExclusionRuleDictionaryCloudStoragePath:PreventionInspectTemplateInspectConfigRuleSetRuleExclusionRuleDictionaryCloudStoragePath
~|
path" pA url representing a file or path (no wildcards) in Cloud Storage. Example: `gs://[BUCKET_NAME]/dictionary.txt`
:Ó

datalossPPreventionInspectTemplateInspectConfigRuleSetRuleExclusionRuleDictionaryWordList®gcp:dataloss/PreventionInspectTemplateInspectConfigRuleSetRuleExclusionRuleDictionaryWordList:PreventionInspectTemplateInspectConfigRuleSetRuleExclusionRuleDictionaryWordListÀ
½º
words*" ªWords or phrases defining the dictionary. The dictionary must contain at least one
phrase and every phrase must contain at least 2 characters that are letters or digits.
:

datalossNPreventionInspectTemplateInspectConfigRuleSetRuleExclusionRuleExcludeByHotwordªgcp:dataloss/PreventionInspectTemplateInspectConfigRuleSetRuleExclusionRuleExcludeByHotword:PreventionInspectTemplateInspectConfigRuleSetRuleExclusionRuleExcludeByHotword


¤
hotwordRegex±:®
«
datalossZPreventionInspectTemplateInspectConfigRuleSetRuleExclusionRuleExcludeByHotwordHotwordRegexÂgcp:dataloss/PreventionInspectTemplateInspectConfigRuleSetRuleExclusionRuleExcludeByHotwordHotwordRegex:PreventionInspectTemplateInspectConfigRuleSetRuleExclusionRuleExcludeByHotwordHotwordRegex`Regular expression pattern defining what qualifies as a hotword.
Structure is documented below.
×
	proximity¨:¥
¢
datalossWPreventionInspectTemplateInspectConfigRuleSetRuleExclusionRuleExcludeByHotwordProximity¼gcp:dataloss/PreventionInspectTemplateInspectConfigRuleSetRuleExclusionRuleExcludeByHotwordProximity:PreventionInspectTemplateInspectConfigRuleSetRuleExclusionRuleExcludeByHotwordProximityProximity of the finding within which the entire hotword must reside. The total length of the window cannot
exceed 1000 characters. Note that the finding itself will be included in the window, so that hotwords may be
used to match substrings of the finding itself. For example, the certainty of a phone number regex
`(\d{3}) \d{3}-\d{4}` could be adjusted upwards if the area code is known to be the local area code of a company
office using the hotword regex `(xxx)`, where `xxx` is the area code in question.
Structure is documented below.
:ÿ
«
datalossZPreventionInspectTemplateInspectConfigRuleSetRuleExclusionRuleExcludeByHotwordHotwordRegexÂgcp:dataloss/PreventionInspectTemplateInspectConfigRuleSetRuleExclusionRuleExcludeByHotwordHotwordRegex:PreventionInspectTemplateInspectConfigRuleSetRuleExclusionRuleExcludeByHotwordHotwordRegexÎ
Ë
groupIndexesB* The index of the submatch to extract as findings. When not specified,
the entire match is returned. No more than 3 may be included.
¨
pattern" Pattern defining the regular expression. Its syntax
(https://github.com/google/re2/wiki/Syntax) can be found under the google/re2 repository on GitHub.
:Ã
¢
datalossWPreventionInspectTemplateInspectConfigRuleSetRuleExclusionRuleExcludeByHotwordProximity¼gcp:dataloss/PreventionInspectTemplateInspectConfigRuleSetRuleExclusionRuleExcludeByHotwordProximity:PreventionInspectTemplateInspectConfigRuleSetRuleExclusionRuleExcludeByHotwordProximity
I
windowAfterB 4Number of characters after the finding to consider.
K
windowBeforeB 5Number of characters before the finding to consider.
:å

datalossNPreventionInspectTemplateInspectConfigRuleSetRuleExclusionRuleExcludeInfoTypesªgcp:dataloss/PreventionInspectTemplateInspectConfigRuleSetRuleExclusionRuleExcludeInfoTypes:PreventionInspectTemplateInspectConfigRuleSetRuleExclusionRuleExcludeInfoTypesØ
ÕÒ
	infoTypes¨*¥:¢

datalossVPreventionInspectTemplateInspectConfigRuleSetRuleExclusionRuleExcludeInfoTypesInfoTypeºgcp:dataloss/PreventionInspectTemplateInspectConfigRuleSetRuleExclusionRuleExcludeInfoTypesInfoType:PreventionInspectTemplateInspectConfigRuleSetRuleExclusionRuleExcludeInfoTypesInfoTypeIf a finding is matched by any of the infoType detectors listed here, the finding will be excluded from the scan results.
Structure is documented below.
:¢

datalossVPreventionInspectTemplateInspectConfigRuleSetRuleExclusionRuleExcludeInfoTypesInfoTypeºgcp:dataloss/PreventionInspectTemplateInspectConfigRuleSetRuleExclusionRuleExcludeInfoTypesInfoType:PreventionInspectTemplateInspectConfigRuleSetRuleExclusionRuleExcludeInfoTypesInfoTypeý
úß
name" ÒName of the information type. Either a name of your choosing when creating a CustomInfoType, or one of the names listed
at https://cloud.google.com/dlp/docs/infotypes-reference when specifying a built-in type.
â
sensitivityScoreØBÕ:Ò
Ï
datalossfPreventionInspectTemplateInspectConfigRuleSetRuleExclusionRuleExcludeInfoTypesInfoTypeSensitivityScoreÚgcp:dataloss/PreventionInspectTemplateInspectConfigRuleSetRuleExclusionRuleExcludeInfoTypesInfoTypeSensitivityScore:PreventionInspectTemplateInspectConfigRuleSetRuleExclusionRuleExcludeInfoTypesInfoTypeSensitivityScoresOptional custom sensitivity for this InfoType. This only applies to data profiling.
Structure is documented below.
1
versionB"  Version name for this InfoType.
:ì
Ï
datalossfPreventionInspectTemplateInspectConfigRuleSetRuleExclusionRuleExcludeInfoTypesInfoTypeSensitivityScoreÚgcp:dataloss/PreventionInspectTemplateInspectConfigRuleSetRuleExclusionRuleExcludeInfoTypesInfoTypeSensitivityScore:PreventionInspectTemplateInspectConfigRuleSetRuleExclusionRuleExcludeInfoTypesInfoTypeSensitivityScore

score" The sensitivity score applied to the resource.
Possible values are: `SENSITIVITY_LOW`, `SENSITIVITY_MODERATE`, `SENSITIVITY_HIGH`.
:º
æ
datalossCPreventionInspectTemplateInspectConfigRuleSetRuleExclusionRuleRegexgcp:dataloss/PreventionInspectTemplateInspectConfigRuleSetRuleExclusionRuleRegex:PreventionInspectTemplateInspectConfigRuleSetRuleExclusionRuleRegexÎ
Ë
groupIndexesB* The index of the submatch to extract as findings. When not specified, the entire match is returned. No more than 3 may be included.
¨
pattern" Pattern defining the regular expression.
Its syntax (https://github.com/google/re2/wiki/Syntax) can be found under the google/re2 repository on GitHub.
:ø
Ñ
dataloss<PreventionInspectTemplateInspectConfigRuleSetRuleHotwordRulegcp:dataloss/PreventionInspectTemplateInspectConfigRuleSetRuleHotwordRule:PreventionInspectTemplateInspectConfigRuleSetRuleHotwordRule¡
î
hotwordRegexû:ø
õ
datalossHPreventionInspectTemplateInspectConfigRuleSetRuleHotwordRuleHotwordRegexgcp:dataloss/PreventionInspectTemplateInspectConfigRuleSetRuleHotwordRuleHotwordRegex:PreventionInspectTemplateInspectConfigRuleSetRuleHotwordRuleHotwordRegex`Regular expression pattern defining what qualifies as a hotword.
Structure is documented below.

likelihoodAdjustment:

datalossPPreventionInspectTemplateInspectConfigRuleSetRuleHotwordRuleLikelihoodAdjustment®gcp:dataloss/PreventionInspectTemplateInspectConfigRuleSetRuleHotwordRuleLikelihoodAdjustment:PreventionInspectTemplateInspectConfigRuleSetRuleHotwordRuleLikelihoodAdjustmentXLikelihood adjustment to apply to all matching findings.
Structure is documented below.
¡
	proximityò:ï
ì
datalossEPreventionInspectTemplateInspectConfigRuleSetRuleHotwordRuleProximitygcp:dataloss/PreventionInspectTemplateInspectConfigRuleSetRuleHotwordRuleProximity:PreventionInspectTemplateInspectConfigRuleSetRuleHotwordRuleProximityProximity of the finding within which the entire hotword must reside. The total length of the window cannot
exceed 1000 characters. Note that the finding itself will be included in the window, so that hotwords may be
used to match substrings of the finding itself. For example, the certainty of a phone number regex
`(\d{3}) \d{3}-\d{4}` could be adjusted upwards if the area code is known to be the local area code of a company
office using the hotword regex `(xxx)`, where `xxx` is the area code in question.
Structure is documented below.
:É
õ
datalossHPreventionInspectTemplateInspectConfigRuleSetRuleHotwordRuleHotwordRegexgcp:dataloss/PreventionInspectTemplateInspectConfigRuleSetRuleHotwordRuleHotwordRegex:PreventionInspectTemplateInspectConfigRuleSetRuleHotwordRuleHotwordRegexÎ
Ë
groupIndexesB* The index of the submatch to extract as findings. When not specified,
the entire match is returned. No more than 3 may be included.
¨
pattern" Pattern defining the regular expression. Its syntax
(https://github.com/google/re2/wiki/Syntax) can be found under the google/re2 repository on GitHub.
:

datalossPPreventionInspectTemplateInspectConfigRuleSetRuleHotwordRuleLikelihoodAdjustment®gcp:dataloss/PreventionInspectTemplateInspectConfigRuleSetRuleHotwordRuleLikelihoodAdjustment:PreventionInspectTemplateInspectConfigRuleSetRuleHotwordRuleLikelihoodAdjustment÷
ôÒ
fixedLikelihoodB" ¸Set the likelihood of a finding to a fixed value. Either this or relative_likelihood can be set.
Possible values are: `VERY_UNLIKELY`, `UNLIKELY`, `POSSIBLE`, `LIKELY`, `VERY_LIKELY`.

relativeLikelihoodB ÿIncrease or decrease the likelihood by the specified number of levels. For example,
if a finding would be POSSIBLE without the detection rule and relativeLikelihood is 1,
then it is upgraded to LIKELY, while a value of -1 would downgrade it to UNLIKELY.
Likelihood may never drop below VERY_UNLIKELY or exceed VERY_LIKELY, so applying an
adjustment of 1 followed by an adjustment of -1 when base likelihood is VERY_LIKELY
will result in a final likelihood of LIKELY. Either this or fixed_likelihood can be set.
:
ì
datalossEPreventionInspectTemplateInspectConfigRuleSetRuleHotwordRuleProximitygcp:dataloss/PreventionInspectTemplateInspectConfigRuleSetRuleHotwordRuleProximity:PreventionInspectTemplateInspectConfigRuleSetRuleHotwordRuleProximity
I
windowAfterB 4Number of characters after the finding to consider.
K
windowBeforeB 5Number of characters before the finding to consider.
:	
v
datalossPreventionJobTriggerInspectJobJgcp:dataloss/PreventionJobTriggerInspectJob:PreventionJobTriggerInspectJob
¶
actionsB*:

dataloss$PreventionJobTriggerInspectJobActionVgcp:dataloss/PreventionJobTriggerInspectJobAction:PreventionJobTriggerInspectJobActionConfiguration block for the actions to execute on the completion of a job. Can be specified multiple times, but only one for each type. Each action block supports fields documented below. This argument is processed in attribute-as-blocks mode.
Structure is documented below.
û
inspectConfig¦B£: 

dataloss+PreventionJobTriggerInspectJobInspectConfigdgcp:dataloss/PreventionJobTriggerInspectJobInspectConfig:PreventionJobTriggerInspectJobInspectConfigAThe core content of the template.
Structure is documented below.
Y
inspectTemplateNameB" <The name of the template to run when this job is triggered.
ö
storageConfig£: 

dataloss+PreventionJobTriggerInspectJobStorageConfigdgcp:dataloss/PreventionJobTriggerInspectJobStorageConfig:PreventionJobTriggerInspectJobStorageConfig?Information on where to inspect
Structure is documented below.
:é

dataloss$PreventionJobTriggerInspectJobActionVgcp:dataloss/PreventionJobTriggerInspectJobAction:PreventionJobTriggerInspectJobActionÛ
Ø

deidentify¯B¬:©
¦
dataloss.PreventionJobTriggerInspectJobActionDeidentifyjgcp:dataloss/PreventionJobTriggerInspectJobActionDeidentify:PreventionJobTriggerInspectJobActionDeidentify\Create a de-identified copy of the requested table or files.
Structure is documented below.
Û
jobNotificationEmailsÑBÎ:Ë
È
dataloss9PreventionJobTriggerInspectJobActionJobNotificationEmailsgcp:dataloss/PreventionJobTriggerInspectJobActionJobNotificationEmails:PreventionJobTriggerInspectJobActionJobNotificationEmailsnSends an email when the job completes. The email goes to IAM project owners and technical Essential Contacts.

pubSub£B :

dataloss*PreventionJobTriggerInspectJobActionPubSubbgcp:dataloss/PreventionJobTriggerInspectJobActionPubSub:PreventionJobTriggerInspectJobActionPubSubdPublish a message into a given Pub/Sub topic when the job completes.
Structure is documented below.
Ë
!publishFindingsToCloudDataCatalogõBò:ï
ì
datalossEPreventionJobTriggerInspectJobActionPublishFindingsToCloudDataCataloggcp:dataloss/PreventionJobTriggerInspectJobActionPublishFindingsToCloudDataCatalog:PreventionJobTriggerInspectJobActionPublishFindingsToCloudDataCatalog.Publish findings of a DlpJob to Data Catalog.
µ
publishSummaryToCsccÍBÊ:Ç
Ä
dataloss8PreventionJobTriggerInspectJobActionPublishSummaryToCscc~gcp:dataloss/PreventionJobTriggerInspectJobActionPublishSummaryToCscc:PreventionJobTriggerInspectJobActionPublishSummaryToCsccMPublish the result summary of a DlpJob to the Cloud Security Command Center.
£
publishToStackdriverÍBÊ:Ç
Ä
dataloss8PreventionJobTriggerInspectJobActionPublishToStackdriver~gcp:dataloss/PreventionJobTriggerInspectJobActionPublishToStackdriver:PreventionJobTriggerInspectJobActionPublishToStackdriver;Enable Stackdriver metric dlp.googleapis.com/findingCount.

saveFindingsµB²:¯
¬
dataloss0PreventionJobTriggerInspectJobActionSaveFindingsngcp:dataloss/PreventionJobTriggerInspectJobActionSaveFindings:PreventionJobTriggerInspectJobActionSaveFindingsÌIf set, the detailed findings will be persisted to the specified OutputStorageConfig. Only a single instance of this action can be specified. Compatible with: Inspect, Risk
Structure is documented below.
:û
¦
dataloss.PreventionJobTriggerInspectJobActionDeidentifyjgcp:dataloss/PreventionJobTriggerInspectJobActionDeidentify:PreventionJobTriggerInspectJobActionDeidentifyÏ
ÌÕ
cloudStorageOutput" ºUser settable Cloud Storage bucket and folders to store de-identified files.
This field must be set for cloud storage deidentification.
The output Cloud Storage bucket must be different from the input bucket.
De-identified files will overwrite files in the output path.
Form of: gs://bucket/folder/ or gs://bucket
Ý
fileTypesToTransformsB*" »List of user-specified file type groups to transform. If specified, only the files with these filetypes will be transformed.
If empty, all supported files will be transformed. Supported types may be automatically added over time.
If a file type is set in this field that isn't supported by the Deidentify action then the job will fail and will not be successfully created/started.
Each value may be one of: `IMAGE`, `TEXT_FILE`, `CSV`, `TSV`.

transformationConfigìBé:æ
ã
datalossBPreventionJobTriggerInspectJobActionDeidentifyTransformationConfiggcp:dataloss/PreventionJobTriggerInspectJobActionDeidentifyTransformationConfig:PreventionJobTriggerInspectJobActionDeidentifyTransformationConfig~User specified deidentify templates and configs for structured, unstructured, and image files.
Structure is documented below.

"transformationDetailsStorageConfigB:

datalossPPreventionJobTriggerInspectJobActionDeidentifyTransformationDetailsStorageConfig®gcp:dataloss/PreventionJobTriggerInspectJobActionDeidentifyTransformationDetailsStorageConfig:PreventionJobTriggerInspectJobActionDeidentifyTransformationDetailsStorageConfigJConfig for storing transformation details.
Structure is documented below.
:þ
ã
datalossBPreventionJobTriggerInspectJobActionDeidentifyTransformationConfiggcp:dataloss/PreventionJobTriggerInspectJobActionDeidentifyTransformationConfig:PreventionJobTriggerInspectJobActionDeidentifyTransformationConfig
n
deidentifyTemplateB" RIf this template is specified, it will serve as the default de-identify template.
r
imageRedactTemplateB" UIf this template is specified, it will serve as the de-identify template for images.
«
structuredDeidentifyTemplateB" If this template is specified, it will serve as the de-identify template for structured content such as delimited files and tables.
:

datalossPPreventionJobTriggerInspectJobActionDeidentifyTransformationDetailsStorageConfig®gcp:dataloss/PreventionJobTriggerInspectJobActionDeidentifyTransformationDetailsStorageConfig:PreventionJobTriggerInspectJobActionDeidentifyTransformationDetailsStorageConfig
þ
table¢:

datalossUPreventionJobTriggerInspectJobActionDeidentifyTransformationDetailsStorageConfigTable¸gcp:dataloss/PreventionJobTriggerInspectJobActionDeidentifyTransformationDetailsStorageConfigTable:PreventionJobTriggerInspectJobActionDeidentifyTransformationDetailsStorageConfigTablePThe BigQuery table in which to store the output.
Structure is documented below.
:Ç

datalossUPreventionJobTriggerInspectJobActionDeidentifyTransformationDetailsStorageConfigTable¸gcp:dataloss/PreventionJobTriggerInspectJobActionDeidentifyTransformationDetailsStorageConfigTable:PreventionJobTriggerInspectJobActionDeidentifyTransformationDetailsStorageConfigTable¥
¢>
	datasetId" -The ID of the dataset containing this table.
>
	projectId" -The ID of the project containing this table.

tableIdB" The ID of the table. The ID must contain only letters (a-z,
A-Z), numbers (0-9), or underscores (_). The maximum length
is 1,024 characters.
:Ï
È
dataloss9PreventionJobTriggerInspectJobActionJobNotificationEmailsgcp:dataloss/PreventionJobTriggerInspectJobActionJobNotificationEmails:PreventionJobTriggerInspectJobActionJobNotificationEmails
 :Þ

dataloss*PreventionJobTriggerInspectJobActionPubSubbgcp:dataloss/PreventionJobTriggerInspectJobActionPubSub:PreventionJobTriggerInspectJobActionPubSub?
=;
topic" .Cloud Pub/Sub topic to send notifications to.
:ó
ì
datalossEPreventionJobTriggerInspectJobActionPublishFindingsToCloudDataCataloggcp:dataloss/PreventionJobTriggerInspectJobActionPublishFindingsToCloudDataCatalog:PreventionJobTriggerInspectJobActionPublishFindingsToCloudDataCatalog
 :Ë
Ä
dataloss8PreventionJobTriggerInspectJobActionPublishSummaryToCscc~gcp:dataloss/PreventionJobTriggerInspectJobActionPublishSummaryToCscc:PreventionJobTriggerInspectJobActionPublishSummaryToCscc
 :Ë
Ä
dataloss8PreventionJobTriggerInspectJobActionPublishToStackdriver~gcp:dataloss/PreventionJobTriggerInspectJobActionPublishToStackdriver:PreventionJobTriggerInspectJobActionPublishToStackdriver
 :æ
¬
dataloss0PreventionJobTriggerInspectJobActionSaveFindingsngcp:dataloss/PreventionJobTriggerInspectJobActionSaveFindings:PreventionJobTriggerInspectJobActionSaveFindings´
±®
outputConfig×:Ô
Ñ
dataloss<PreventionJobTriggerInspectJobActionSaveFindingsOutputConfiggcp:dataloss/PreventionJobTriggerInspectJobActionSaveFindingsOutputConfig:PreventionJobTriggerInspectJobActionSaveFindingsOutputConfigDInformation on where to store output
Structure is documented below.
:Ò	
Ñ
dataloss<PreventionJobTriggerInspectJobActionSaveFindingsOutputConfiggcp:dataloss/PreventionJobTriggerInspectJobActionSaveFindingsOutputConfig:PreventionJobTriggerInspectJobActionSaveFindingsOutputConfigû
ø§
outputSchemaB" Schema used for writing the findings for Inspect jobs. This field is only used for
Inspect and must be unspecified for Risk jobs. Columns are derived from the Finding
object. If appending to an existing table, any columns from the predefined schema
that are missing will be added. No columns in the existing table will be deleted.
If unspecified, then all available columns will be used for a new table or an (existing)
table with no schema, and no changes will be made to an existing table that has a schema.
Only for use with external storage.
Possible values are: `BASIC_COLUMNS`, `GCS_COLUMNS`, `DATASTORE_COLUMNS`, `BIG_QUERY_COLUMNS`, `ALL_COLUMNS`.
Ë
tableæ:ã
à
datalossAPreventionJobTriggerInspectJobActionSaveFindingsOutputConfigTablegcp:dataloss/PreventionJobTriggerInspectJobActionSaveFindingsOutputConfigTable:PreventionJobTriggerInspectJobActionSaveFindingsOutputConfigTableYInformation on the location of the target BigQuery Table.
Structure is documented below.
:
à
datalossAPreventionJobTriggerInspectJobActionSaveFindingsOutputConfigTablegcp:dataloss/PreventionJobTriggerInspectJobActionSaveFindingsOutputConfigTable:PreventionJobTriggerInspectJobActionSaveFindingsOutputConfigTable¥
¢>
	datasetId" -The ID of the dataset containing this table.
>
	projectId" -The ID of the project containing this table.

tableIdB" The ID of the table. The ID must contain only letters (a-z,
A-Z), numbers (0-9), or underscores (_). The maximum length
is 1,024 characters.
:Â

dataloss+PreventionJobTriggerInspectJobInspectConfigdgcp:dataloss/PreventionJobTriggerInspectJobInspectConfig:PreventionJobTriggerInspectJobInspectConfig
÷
customInfoTypesÔBÑ*Î:Ë
È
dataloss9PreventionJobTriggerInspectJobInspectConfigCustomInfoTypegcp:dataloss/PreventionJobTriggerInspectJobInspectConfigCustomInfoType:PreventionJobTriggerInspectJobInspectConfigCustomInfoTypeCustom info types to be used. See https://cloud.google.com/dlp/docs/creating-custom-infotypes to learn more.
Structure is documented below.
P
excludeInfoTypesB
 6When true, excludes type information of the findings.
x
includeQuoteB
 bWhen true, a contextual quote from the data that triggered a finding is included in the response.
õ
	infoTypesÁB¾*»:¸
µ
dataloss3PreventionJobTriggerInspectJobInspectConfigInfoTypetgcp:dataloss/PreventionJobTriggerInspectJobInspectConfigInfoType:PreventionJobTriggerInspectJobInspectConfigInfoType£Restricts what infoTypes to look for. The values must correspond to InfoType values returned by infoTypes.list
or listed at https://cloud.google.com/dlp/docs/infotypes-reference.
When no InfoTypes or CustomInfoTypes are specified in a request, the system may automatically choose what detectors to run.
By default this may be all types, but may change over time as detectors are updated.
Structure is documented below.

limits¸Bµ:²
¯
dataloss1PreventionJobTriggerInspectJobInspectConfigLimitspgcp:dataloss/PreventionJobTriggerInspectJobInspectConfigLimits:PreventionJobTriggerInspectJobInspectConfigLimitsYConfiguration to control the number of findings returned.
Structure is documented below.

minLikelihoodB" èOnly returns findings equal or above this threshold. See https://cloud.google.com/dlp/docs/likelihood for more info
Default value is `POSSIBLE`.
Possible values are: `VERY_UNLIKELY`, `UNLIKELY`, `POSSIBLE`, `LIKELY`, `VERY_LIKELY`.
·
ruleSets¾B»*¸:µ
²
dataloss2PreventionJobTriggerInspectJobInspectConfigRuleSetrgcp:dataloss/PreventionJobTriggerInspectJobInspectConfigRuleSet:PreventionJobTriggerInspectJobInspectConfigRuleSetéSet of rules to apply to the findings for this InspectConfig. Exclusion rules, contained in the set are executed in the end,
other rules are executed in the order they are specified for each info type.
Structure is documented below.
:
È
dataloss9PreventionJobTriggerInspectJobInspectConfigCustomInfoTypegcp:dataloss/PreventionJobTriggerInspectJobInspectConfigCustomInfoType:PreventionJobTriggerInspectJobInspectConfigCustomInfoTypeÉ
ÆÂ

dictionaryïBì:é
æ
datalossCPreventionJobTriggerInspectJobInspectConfigCustomInfoTypeDictionarygcp:dataloss/PreventionJobTriggerInspectJobInspectConfigCustomInfoTypeDictionary:PreventionJobTriggerInspectJobInspectConfigCustomInfoTypeDictionaryBDictionary which defines the rule.
Structure is documented below.
È
exclusionTypeB" °If set to EXCLUSION_TYPE_EXCLUDE this infoType will not cause a finding to be returned. It still can be used for rules matching.
Possible values are: `EXCLUSION_TYPE_EXCLUDE`.

infoTypeæ:ã
à
datalossAPreventionJobTriggerInspectJobInspectConfigCustomInfoTypeInfoTypegcp:dataloss/PreventionJobTriggerInspectJobInspectConfigCustomInfoTypeInfoType:PreventionJobTriggerInspectJobInspectConfigCustomInfoTypeInfoTypeCustomInfoType can either be a new infoType, or an extension of built-in infoType, when the name matches one of existing
infoTypes and that infoType is specified in `info_types` field. Specifying the latter adds findings to the
one detected by the system. If built-in info type is not specified in `info_types` list then the name is
treated as a custom info type.
Structure is documented below.
¦

likelihoodB" Likelihood to return for this CustomInfoType. This base value can be altered by a detection rule if the finding meets the criteria
specified by the rule.
Default value is `VERY_LIKELY`.
Possible values are: `VERY_UNLIKELY`, `UNLIKELY`, `POSSIBLE`, `LIKELY`, `VERY_LIKELY`.
¶
regexàBÝ:Ú
×
dataloss>PreventionJobTriggerInspectJobInspectConfigCustomInfoTypeRegexgcp:dataloss/PreventionJobTriggerInspectJobInspectConfigCustomInfoTypeRegex:PreventionJobTriggerInspectJobInspectConfigCustomInfoTypeRegexJRegular expression which defines the rule.
Structure is documented below.

sensitivityScoreBþ:û
ø
datalossIPreventionJobTriggerInspectJobInspectConfigCustomInfoTypeSensitivityScore gcp:dataloss/PreventionJobTriggerInspectJobInspectConfigCustomInfoTypeSensitivityScore:PreventionJobTriggerInspectJobInspectConfigCustomInfoTypeSensitivityScoresOptional custom sensitivity for this InfoType. This only applies to data profiling.
Structure is documented below.
Õ

storedTypeïBì:é
æ
datalossCPreventionJobTriggerInspectJobInspectConfigCustomInfoTypeStoredTypegcp:dataloss/PreventionJobTriggerInspectJobInspectConfigCustomInfoTypeStoredType:PreventionJobTriggerInspectJobInspectConfigCustomInfoTypeStoredTypeUA reference to a StoredInfoType to use with scanning.
Structure is documented below.
ç
surrogateTypeøBõ:ò
ï
datalossFPreventionJobTriggerInspectJobInspectConfigCustomInfoTypeSurrogateTypegcp:dataloss/PreventionJobTriggerInspectJobInspectConfigCustomInfoTypeSurrogateType:PreventionJobTriggerInspectJobInspectConfigCustomInfoTypeSurrogateType[Message for detecting output from deidentification transformations that support reversing.
:ù
æ
datalossCPreventionJobTriggerInspectJobInspectConfigCustomInfoTypeDictionarygcp:dataloss/PreventionJobTriggerInspectJobInspectConfigCustomInfoTypeDictionary:PreventionJobTriggerInspectJobInspectConfigCustomInfoTypeDictionary
§
cloudStoragePathB:

datalossSPreventionJobTriggerInspectJobInspectConfigCustomInfoTypeDictionaryCloudStoragePath´gcp:dataloss/PreventionJobTriggerInspectJobInspectConfigCustomInfoTypeDictionaryCloudStoragePath:PreventionJobTriggerInspectJobInspectConfigCustomInfoTypeDictionaryCloudStoragePathqNewline-delimited file of words in Cloud Storage. Only a single file is accepted.
Structure is documented below.
Ý
wordListB:
þ
datalossKPreventionJobTriggerInspectJobInspectConfigCustomInfoTypeDictionaryWordList¤gcp:dataloss/PreventionJobTriggerInspectJobInspectConfigCustomInfoTypeDictionaryWordList:PreventionJobTriggerInspectJobInspectConfigCustomInfoTypeDictionaryWordListGList of words or phrases to search for.
Structure is documented below.
:

datalossSPreventionJobTriggerInspectJobInspectConfigCustomInfoTypeDictionaryCloudStoragePath´gcp:dataloss/PreventionJobTriggerInspectJobInspectConfigCustomInfoTypeDictionaryCloudStoragePath:PreventionJobTriggerInspectJobInspectConfigCustomInfoTypeDictionaryCloudStoragePath
~|
path" pA url representing a file or path (no wildcards) in Cloud Storage. Example: `gs://[BUCKET_NAME]/dictionary.txt`
:Ä
þ
datalossKPreventionJobTriggerInspectJobInspectConfigCustomInfoTypeDictionaryWordList¤gcp:dataloss/PreventionJobTriggerInspectJobInspectConfigCustomInfoTypeDictionaryWordList:PreventionJobTriggerInspectJobInspectConfigCustomInfoTypeDictionaryWordListÀ
½º
words*" ªWords or phrases defining the dictionary. The dictionary must contain at least one
phrase and every phrase must contain at least 2 characters that are letters or digits.
:Ö
à
datalossAPreventionJobTriggerInspectJobInspectConfigCustomInfoTypeInfoTypegcp:dataloss/PreventionJobTriggerInspectJobInspectConfigCustomInfoTypeInfoType:PreventionJobTriggerInspectJobInspectConfigCustomInfoTypeInfoTypeð
íß
name" ÒName of the information type. Either a name of your choosing when creating a CustomInfoType, or one of the names
listed at https://cloud.google.com/dlp/docs/infotypes-reference when specifying a built-in type.
£
sensitivityScoreB:

datalossQPreventionJobTriggerInspectJobInspectConfigCustomInfoTypeInfoTypeSensitivityScore°gcp:dataloss/PreventionJobTriggerInspectJobInspectConfigCustomInfoTypeInfoTypeSensitivityScore:PreventionJobTriggerInspectJobInspectConfigCustomInfoTypeInfoTypeSensitivityScoresOptional custom sensitivity for this InfoType. This only applies to data profiling.
Structure is documented below.
c
versionB" RVersion of the information type to use. By default, the version is set to stable.
:­

datalossQPreventionJobTriggerInspectJobInspectConfigCustomInfoTypeInfoTypeSensitivityScore°gcp:dataloss/PreventionJobTriggerInspectJobInspectConfigCustomInfoTypeInfoTypeSensitivityScore:PreventionJobTriggerInspectJobInspectConfigCustomInfoTypeInfoTypeSensitivityScore

score" The sensitivity score applied to the resource.
Possible values are: `SENSITIVITY_LOW`, `SENSITIVITY_MODERATE`, `SENSITIVITY_HIGH`.
:«
×
dataloss>PreventionJobTriggerInspectJobInspectConfigCustomInfoTypeRegexgcp:dataloss/PreventionJobTriggerInspectJobInspectConfigCustomInfoTypeRegex:PreventionJobTriggerInspectJobInspectConfigCustomInfoTypeRegexÎ
Ë
groupIndexesB* The index of the submatch to extract as findings. When not specified, the entire match is returned. No more than 3 may be included.
¨
pattern" Pattern defining the regular expression.
Its syntax (https://github.com/google/re2/wiki/Syntax) can be found under the google/re2 repository on GitHub.
:
ø
datalossIPreventionJobTriggerInspectJobInspectConfigCustomInfoTypeSensitivityScore gcp:dataloss/PreventionJobTriggerInspectJobInspectConfigCustomInfoTypeSensitivityScore:PreventionJobTriggerInspectJobInspectConfigCustomInfoTypeSensitivityScore

score" The sensitivity score applied to the resource.
Possible values are: `SENSITIVITY_LOW`, `SENSITIVITY_MODERATE`, `SENSITIVITY_HIGH`.
:
æ
datalossCPreventionJobTriggerInspectJobInspectConfigCustomInfoTypeStoredTypegcp:dataloss/PreventionJobTriggerInspectJobInspectConfigCustomInfoTypeStoredType:PreventionJobTriggerInspectJobInspectConfigCustomInfoTypeStoredType
^

createTimeB" J(Output)
The creation timestamp of an inspectTemplate. Set by the server.
°
name" £Resource name of the requested StoredInfoType, for example `organizations/433245324/storedInfoTypes/432452342`
or `projects/project-id/storedInfoTypes/432452342`.
:ö
ï
datalossFPreventionJobTriggerInspectJobInspectConfigCustomInfoTypeSurrogateTypegcp:dataloss/PreventionJobTriggerInspectJobInspectConfigCustomInfoTypeSurrogateType:PreventionJobTriggerInspectJobInspectConfigCustomInfoTypeSurrogateType
 :
µ
dataloss3PreventionJobTriggerInspectJobInspectConfigInfoTypetgcp:dataloss/PreventionJobTriggerInspectJobInspectConfigInfoType:PreventionJobTriggerInspectJobInspectConfigInfoTypeÆ
Ãß
name" ÒName of the information type. Either a name of your choosing when creating a CustomInfoType, or one of the names listed
at https://cloud.google.com/dlp/docs/infotypes-reference when specifying a built-in type.
ù
sensitivityScoreïBì:é
æ
datalossCPreventionJobTriggerInspectJobInspectConfigInfoTypeSensitivityScoregcp:dataloss/PreventionJobTriggerInspectJobInspectConfigInfoTypeSensitivityScore:PreventionJobTriggerInspectJobInspectConfigInfoTypeSensitivityScoresOptional custom sensitivity for this InfoType. This only applies to data profiling.
Structure is documented below.
c
versionB" RVersion of the information type to use. By default, the version is set to stable.
:
æ
datalossCPreventionJobTriggerInspectJobInspectConfigInfoTypeSensitivityScoregcp:dataloss/PreventionJobTriggerInspectJobInspectConfigInfoTypeSensitivityScore:PreventionJobTriggerInspectJobInspectConfigInfoTypeSensitivityScore

score" The sensitivity score applied to the resource.
Possible values are: `SENSITIVITY_LOW`, `SENSITIVITY_MODERATE`, `SENSITIVITY_HIGH`.
:²
¯
dataloss1PreventionJobTriggerInspectJobInspectConfigLimitspgcp:dataloss/PreventionJobTriggerInspectJobInspectConfigLimits:PreventionJobTriggerInspectJobInspectConfigLimitsý
úú
maxFindingsPerInfoTypesþBû*ø:õ
ò
datalossGPreventionJobTriggerInspectJobInspectConfigLimitsMaxFindingsPerInfoTypegcp:dataloss/PreventionJobTriggerInspectJobInspectConfigLimitsMaxFindingsPerInfoType:PreventionJobTriggerInspectJobInspectConfigLimitsMaxFindingsPerInfoType^Configuration of findings limit given for specified infoTypes.
Structure is documented below.
~
maxFindingsPerItemB bMax number of findings that will be returned for each item scanned. The maximum returned is 2000.
{
maxFindingsPerRequestB \Max number of findings that will be returned per request/job. The maximum returned is 2000.
:
ò
datalossGPreventionJobTriggerInspectJobInspectConfigLimitsMaxFindingsPerInfoTypegcp:dataloss/PreventionJobTriggerInspectJobInspectConfigLimitsMaxFindingsPerInfoType:PreventionJobTriggerInspectJobInspectConfigLimitsMaxFindingsPerInfoType
À
infoTypeB:

datalossOPreventionJobTriggerInspectJobInspectConfigLimitsMaxFindingsPerInfoTypeInfoType¬gcp:dataloss/PreventionJobTriggerInspectJobInspectConfigLimitsMaxFindingsPerInfoTypeInfoType:PreventionJobTriggerInspectJobInspectConfigLimitsMaxFindingsPerInfoTypeInfoTypeType of information the findings limit applies to. Only one limit per infoType should be provided. If InfoTypeLimit does
not have an infoType, the DLP API applies the limit against all infoTypes that are found but not
specified in another InfoTypeLimit.
Structure is documented below.
@
maxFindingsB +Max findings limit for the given infoType.
:ª

datalossOPreventionJobTriggerInspectJobInspectConfigLimitsMaxFindingsPerInfoTypeInfoType¬gcp:dataloss/PreventionJobTriggerInspectJobInspectConfigLimitsMaxFindingsPerInfoTypeInfoType:PreventionJobTriggerInspectJobInspectConfigLimitsMaxFindingsPerInfoTypeInfoType
ß
name" ÒName of the information type. Either a name of your choosing when creating a CustomInfoType, or one of the names
listed at https://cloud.google.com/dlp/docs/infotypes-reference when specifying a built-in type.
Í
sensitivityScoreÃBÀ:½
º
dataloss_PreventionJobTriggerInspectJobInspectConfigLimitsMaxFindingsPerInfoTypeInfoTypeSensitivityScoreÌgcp:dataloss/PreventionJobTriggerInspectJobInspectConfigLimitsMaxFindingsPerInfoTypeInfoTypeSensitivityScore:PreventionJobTriggerInspectJobInspectConfigLimitsMaxFindingsPerInfoTypeInfoTypeSensitivityScoresOptional custom sensitivity for this InfoType. This only applies to data profiling.
Structure is documented below.
c
versionB" RVersion of the information type to use. By default, the version is set to stable.
:×
º
dataloss_PreventionJobTriggerInspectJobInspectConfigLimitsMaxFindingsPerInfoTypeInfoTypeSensitivityScoreÌgcp:dataloss/PreventionJobTriggerInspectJobInspectConfigLimitsMaxFindingsPerInfoTypeInfoTypeSensitivityScore:PreventionJobTriggerInspectJobInspectConfigLimitsMaxFindingsPerInfoTypeInfoTypeSensitivityScore

score" The sensitivity score applied to the resource.
Possible values are: `SENSITIVITY_LOW`, `SENSITIVITY_MODERATE`, `SENSITIVITY_HIGH`.
:±
²
dataloss2PreventionJobTriggerInspectJobInspectConfigRuleSetrgcp:dataloss/PreventionJobTriggerInspectJobInspectConfigRuleSet:PreventionJobTriggerInspectJobInspectConfigRuleSetù
öµ
	infoTypes×BÔ*Ñ:Î
Ë
dataloss:PreventionJobTriggerInspectJobInspectConfigRuleSetInfoTypegcp:dataloss/PreventionJobTriggerInspectJobInspectConfigRuleSetInfoType:PreventionJobTriggerInspectJobInspectConfigRuleSetInfoTypeNList of infoTypes this rule set is applied to.
Structure is documented below.
»
rulesÇ*Ä:Á
¾
dataloss6PreventionJobTriggerInspectJobInspectConfigRuleSetRulezgcp:dataloss/PreventionJobTriggerInspectJobInspectConfigRuleSetRule:PreventionJobTriggerInspectJobInspectConfigRuleSetRulehSet of rules to be applied to infoTypes. The rules are applied in order.
Structure is documented below.
:¬
Ë
dataloss:PreventionJobTriggerInspectJobInspectConfigRuleSetInfoTypegcp:dataloss/PreventionJobTriggerInspectJobInspectConfigRuleSetInfoType:PreventionJobTriggerInspectJobInspectConfigRuleSetInfoTypeÛ
Øß
name" ÒName of the information type. Either a name of your choosing when creating a CustomInfoType, or one of the names listed
at https://cloud.google.com/dlp/docs/infotypes-reference when specifying a built-in type.

sensitivityScoreB:þ
û
datalossJPreventionJobTriggerInspectJobInspectConfigRuleSetInfoTypeSensitivityScore¢gcp:dataloss/PreventionJobTriggerInspectJobInspectConfigRuleSetInfoTypeSensitivityScore:PreventionJobTriggerInspectJobInspectConfigRuleSetInfoTypeSensitivityScoresOptional custom sensitivity for this InfoType. This only applies to data profiling.
Structure is documented below.
c
versionB" RVersion of the information type to use. By default, the version is set to stable.
:
û
datalossJPreventionJobTriggerInspectJobInspectConfigRuleSetInfoTypeSensitivityScore¢gcp:dataloss/PreventionJobTriggerInspectJobInspectConfigRuleSetInfoTypeSensitivityScore:PreventionJobTriggerInspectJobInspectConfigRuleSetInfoTypeSensitivityScore

score" The sensitivity score applied to the resource.
Possible values are: `SENSITIVITY_LOW`, `SENSITIVITY_MODERATE`, `SENSITIVITY_HIGH`.
:
¾
dataloss6PreventionJobTriggerInspectJobInspectConfigRuleSetRulezgcp:dataloss/PreventionJobTriggerInspectJobInspectConfigRuleSetRule:PreventionJobTriggerInspectJobInspectConfigRuleSetRuleÛ
Ø
exclusionRuleïBì:é
æ
datalossCPreventionJobTriggerInspectJobInspectConfigRuleSetRuleExclusionRulegcp:dataloss/PreventionJobTriggerInspectJobInspectConfigRuleSetRuleExclusionRule:PreventionJobTriggerInspectJobInspectConfigRuleSetRuleExclusionRuleThe rule that specifies conditions when findings of infoTypes specified in InspectionRuleSet are removed from results.
Structure is documented below.
¸
hotwordRuleéBæ:ã
à
datalossAPreventionJobTriggerInspectJobInspectConfigRuleSetRuleHotwordRulegcp:dataloss/PreventionJobTriggerInspectJobInspectConfigRuleSetRuleHotwordRule:PreventionJobTriggerInspectJobInspectConfigRuleSetRuleHotwordRule=Hotword-based detection rule.
Structure is documented below.
:ð
æ
datalossCPreventionJobTriggerInspectJobInspectConfigRuleSetRuleExclusionRulegcp:dataloss/PreventionJobTriggerInspectJobInspectConfigRuleSetRuleExclusionRule:PreventionJobTriggerInspectJobInspectConfigRuleSetRuleExclusionRule
à

dictionaryB:

datalossMPreventionJobTriggerInspectJobInspectConfigRuleSetRuleExclusionRuleDictionary¨gcp:dataloss/PreventionJobTriggerInspectJobInspectConfigRuleSetRuleExclusionRuleDictionary:PreventionJobTriggerInspectJobInspectConfigRuleSetRuleExclusionRuleDictionaryBDictionary which defines the rule.
Structure is documented below.

excludeByHotwordB:

datalossSPreventionJobTriggerInspectJobInspectConfigRuleSetRuleExclusionRuleExcludeByHotword´gcp:dataloss/PreventionJobTriggerInspectJobInspectConfigRuleSetRuleExclusionRuleExcludeByHotword:PreventionJobTriggerInspectJobInspectConfigRuleSetRuleExclusionRuleExcludeByHotword_Drop if the hotword rule is contained in the proximate context.
Structure is documented below.

excludeInfoTypesB:

datalossSPreventionJobTriggerInspectJobInspectConfigRuleSetRuleExclusionRuleExcludeInfoTypes´gcp:dataloss/PreventionJobTriggerInspectJobInspectConfigRuleSetRuleExclusionRuleExcludeInfoTypes:PreventionJobTriggerInspectJobInspectConfigRuleSetRuleExclusionRuleExcludeInfoTypes[Set of infoTypes for which findings would affect this rule.
Structure is documented below.

matchingType" How the rule is applied. See the documentation for more information: https://cloud.google.com/dlp/docs/reference/rest/v2/InspectConfig#MatchingType
Possible values are: `MATCHING_TYPE_FULL_MATCH`, `MATCHING_TYPE_PARTIAL_MATCH`, `MATCHING_TYPE_INVERSE_MATCH`.
Ô
regexþBû:ø
õ
datalossHPreventionJobTriggerInspectJobInspectConfigRuleSetRuleExclusionRuleRegexgcp:dataloss/PreventionJobTriggerInspectJobInspectConfigRuleSetRuleExclusionRuleRegex:PreventionJobTriggerInspectJobInspectConfigRuleSetRuleExclusionRuleRegexJRegular expression which defines the rule.
Structure is documented below.
:Ó

datalossMPreventionJobTriggerInspectJobInspectConfigRuleSetRuleExclusionRuleDictionary¨gcp:dataloss/PreventionJobTriggerInspectJobInspectConfigRuleSetRuleExclusionRuleDictionary:PreventionJobTriggerInspectJobInspectConfigRuleSetRuleExclusionRuleDictionaryÉ
ÆÅ
cloudStoragePath½Bº:·
´
dataloss]PreventionJobTriggerInspectJobInspectConfigRuleSetRuleExclusionRuleDictionaryCloudStoragePathÈgcp:dataloss/PreventionJobTriggerInspectJobInspectConfigRuleSetRuleExclusionRuleDictionaryCloudStoragePath:PreventionJobTriggerInspectJobInspectConfigRuleSetRuleExclusionRuleDictionaryCloudStoragePathqNewline-delimited file of words in Cloud Storage. Only a single file is accepted.
Structure is documented below.
û
wordList¥B¢:

datalossUPreventionJobTriggerInspectJobInspectConfigRuleSetRuleExclusionRuleDictionaryWordList¸gcp:dataloss/PreventionJobTriggerInspectJobInspectConfigRuleSetRuleExclusionRuleDictionaryWordList:PreventionJobTriggerInspectJobInspectConfigRuleSetRuleExclusionRuleDictionaryWordListGList of words or phrases to search for.
Structure is documented below.
:º
´
dataloss]PreventionJobTriggerInspectJobInspectConfigRuleSetRuleExclusionRuleDictionaryCloudStoragePathÈgcp:dataloss/PreventionJobTriggerInspectJobInspectConfigRuleSetRuleExclusionRuleDictionaryCloudStoragePath:PreventionJobTriggerInspectJobInspectConfigRuleSetRuleExclusionRuleDictionaryCloudStoragePath
~|
path" pA url representing a file or path (no wildcards) in Cloud Storage. Example: `gs://[BUCKET_NAME]/dictionary.txt`
:â

datalossUPreventionJobTriggerInspectJobInspectConfigRuleSetRuleExclusionRuleDictionaryWordList¸gcp:dataloss/PreventionJobTriggerInspectJobInspectConfigRuleSetRuleExclusionRuleDictionaryWordList:PreventionJobTriggerInspectJobInspectConfigRuleSetRuleExclusionRuleDictionaryWordListÀ
½º
words*" ªWords or phrases defining the dictionary. The dictionary must contain at least one
phrase and every phrase must contain at least 2 characters that are letters or digits.
:Ä

datalossSPreventionJobTriggerInspectJobInspectConfigRuleSetRuleExclusionRuleExcludeByHotword´gcp:dataloss/PreventionJobTriggerInspectJobInspectConfigRuleSetRuleExclusionRuleExcludeByHotword:PreventionJobTriggerInspectJobInspectConfigRuleSetRuleExclusionRuleExcludeByHotword¨

¥
¶
hotwordRegexÃBÀ:½
º
dataloss_PreventionJobTriggerInspectJobInspectConfigRuleSetRuleExclusionRuleExcludeByHotwordHotwordRegexÌgcp:dataloss/PreventionJobTriggerInspectJobInspectConfigRuleSetRuleExclusionRuleExcludeByHotwordHotwordRegex:PreventionJobTriggerInspectJobInspectConfigRuleSetRuleExclusionRuleExcludeByHotwordHotwordRegex`Regular expression pattern defining what qualifies as a hotword.
Structure is documented below.
é
	proximityºB·:´
±
dataloss\PreventionJobTriggerInspectJobInspectConfigRuleSetRuleExclusionRuleExcludeByHotwordProximityÆgcp:dataloss/PreventionJobTriggerInspectJobInspectConfigRuleSetRuleExclusionRuleExcludeByHotwordProximity:PreventionJobTriggerInspectJobInspectConfigRuleSetRuleExclusionRuleExcludeByHotwordProximityProximity of the finding within which the entire hotword must reside. The total length of the window cannot
exceed 1000 characters. Note that the finding itself will be included in the window, so that hotwords may be
used to match substrings of the finding itself. For example, the certainty of a phone number regex
`(\d{3}) \d{3}-\d{4}` could be adjusted upwards if the area code is known to be the local area code of a company
office using the hotword regex `(xxx)`, where `xxx` is the area code in question.
Structure is documented below.
:
º
dataloss_PreventionJobTriggerInspectJobInspectConfigRuleSetRuleExclusionRuleExcludeByHotwordHotwordRegexÌgcp:dataloss/PreventionJobTriggerInspectJobInspectConfigRuleSetRuleExclusionRuleExcludeByHotwordHotwordRegex:PreventionJobTriggerInspectJobInspectConfigRuleSetRuleExclusionRuleExcludeByHotwordHotwordRegexÐ
Í
groupIndexesB* The index of the submatch to extract as findings. When not specified,
the entire match is returned. No more than 3 may be included.
ª
patternB" Pattern defining the regular expression. Its syntax
(https://github.com/google/re2/wiki/Syntax) can be found under the google/re2 repository on GitHub.
:¯
±
dataloss\PreventionJobTriggerInspectJobInspectConfigRuleSetRuleExclusionRuleExcludeByHotwordProximityÆgcp:dataloss/PreventionJobTriggerInspectJobInspectConfigRuleSetRuleExclusionRuleExcludeByHotwordProximity:PreventionJobTriggerInspectJobInspectConfigRuleSetRuleExclusionRuleExcludeByHotwordProximityø
õx
windowAfterB cNumber of characters after the finding to consider. Either this or window_before must be specified
y
windowBeforeB cNumber of characters before the finding to consider. Either this or window_after must be specified
:

datalossSPreventionJobTriggerInspectJobInspectConfigRuleSetRuleExclusionRuleExcludeInfoTypes´gcp:dataloss/PreventionJobTriggerInspectJobInspectConfigRuleSetRuleExclusionRuleExcludeInfoTypes:PreventionJobTriggerInspectJobInspectConfigRuleSetRuleExclusionRuleExcludeInfoTypesç
äá
	infoTypes·*´:±
®
dataloss[PreventionJobTriggerInspectJobInspectConfigRuleSetRuleExclusionRuleExcludeInfoTypesInfoTypeÄgcp:dataloss/PreventionJobTriggerInspectJobInspectConfigRuleSetRuleExclusionRuleExcludeInfoTypesInfoType:PreventionJobTriggerInspectJobInspectConfigRuleSetRuleExclusionRuleExcludeInfoTypesInfoTypeIf a finding is matched by any of the infoType detectors listed here, the finding will be excluded from the scan results.
Structure is documented below.
:ò
®
dataloss[PreventionJobTriggerInspectJobInspectConfigRuleSetRuleExclusionRuleExcludeInfoTypesInfoTypeÄgcp:dataloss/PreventionJobTriggerInspectJobInspectConfigRuleSetRuleExclusionRuleExcludeInfoTypesInfoType:PreventionJobTriggerInspectJobInspectConfigRuleSetRuleExclusionRuleExcludeInfoTypesInfoType¾
»ß
name" ÒName of the information type. Either a name of your choosing when creating a CustomInfoType, or one of the names listed
at https://cloud.google.com/dlp/docs/infotypes-reference when specifying a built-in type.
ñ
sensitivityScoreçBä:á
Þ
datalosskPreventionJobTriggerInspectJobInspectConfigRuleSetRuleExclusionRuleExcludeInfoTypesInfoTypeSensitivityScoreägcp:dataloss/PreventionJobTriggerInspectJobInspectConfigRuleSetRuleExclusionRuleExcludeInfoTypesInfoTypeSensitivityScore:PreventionJobTriggerInspectJobInspectConfigRuleSetRuleExclusionRuleExcludeInfoTypesInfoTypeSensitivityScoresOptional custom sensitivity for this InfoType. This only applies to data profiling.
Structure is documented below.
c
versionB" RVersion of the information type to use. By default, the version is set to stable.
:û
Þ
datalosskPreventionJobTriggerInspectJobInspectConfigRuleSetRuleExclusionRuleExcludeInfoTypesInfoTypeSensitivityScoreägcp:dataloss/PreventionJobTriggerInspectJobInspectConfigRuleSetRuleExclusionRuleExcludeInfoTypesInfoTypeSensitivityScore:PreventionJobTriggerInspectJobInspectConfigRuleSetRuleExclusionRuleExcludeInfoTypesInfoTypeSensitivityScore

score" The sensitivity score applied to the resource.
Possible values are: `SENSITIVITY_LOW`, `SENSITIVITY_MODERATE`, `SENSITIVITY_HIGH`.
:É
õ
datalossHPreventionJobTriggerInspectJobInspectConfigRuleSetRuleExclusionRuleRegexgcp:dataloss/PreventionJobTriggerInspectJobInspectConfigRuleSetRuleExclusionRuleRegex:PreventionJobTriggerInspectJobInspectConfigRuleSetRuleExclusionRuleRegexÎ
Ë
groupIndexesB* The index of the submatch to extract as findings. When not specified, the entire match is returned. No more than 3 may be included.
¨
pattern" Pattern defining the regular expression.
Its syntax (https://github.com/google/re2/wiki/Syntax) can be found under the google/re2 repository on GitHub.
:½
à
datalossAPreventionJobTriggerInspectJobInspectConfigRuleSetRuleHotwordRulegcp:dataloss/PreventionJobTriggerInspectJobInspectConfigRuleSetRuleHotwordRule:PreventionJobTriggerInspectJobInspectConfigRuleSetRuleHotwordRule×
Ô
hotwordRegexB:

datalossMPreventionJobTriggerInspectJobInspectConfigRuleSetRuleHotwordRuleHotwordRegex¨gcp:dataloss/PreventionJobTriggerInspectJobInspectConfigRuleSetRuleHotwordRuleHotwordRegex:PreventionJobTriggerInspectJobInspectConfigRuleSetRuleHotwordRuleHotwordRegex`Regular expression pattern defining what qualifies as a hotword.
Structure is documented below.

likelihoodAdjustment¥B¢:

datalossUPreventionJobTriggerInspectJobInspectConfigRuleSetRuleHotwordRuleLikelihoodAdjustment¸gcp:dataloss/PreventionJobTriggerInspectJobInspectConfigRuleSetRuleHotwordRuleLikelihoodAdjustment:PreventionJobTriggerInspectJobInspectConfigRuleSetRuleHotwordRuleLikelihoodAdjustmentXLikelihood adjustment to apply to all matching findings.
Structure is documented below.
³
	proximityB:þ
û
datalossJPreventionJobTriggerInspectJobInspectConfigRuleSetRuleHotwordRuleProximity¢gcp:dataloss/PreventionJobTriggerInspectJobInspectConfigRuleSetRuleHotwordRuleProximity:PreventionJobTriggerInspectJobInspectConfigRuleSetRuleHotwordRuleProximityProximity of the finding within which the entire hotword must reside. The total length of the window cannot
exceed 1000 characters. Note that the finding itself will be included in the window, so that hotwords may be
used to match substrings of the finding itself. For example, the certainty of a phone number regex
`(\d{3}) \d{3}-\d{4}` could be adjusted upwards if the area code is known to be the local area code of a company
office using the hotword regex `(xxx)`, where `xxx` is the area code in question.
Structure is documented below.
:Ú

datalossMPreventionJobTriggerInspectJobInspectConfigRuleSetRuleHotwordRuleHotwordRegex¨gcp:dataloss/PreventionJobTriggerInspectJobInspectConfigRuleSetRuleHotwordRuleHotwordRegex:PreventionJobTriggerInspectJobInspectConfigRuleSetRuleHotwordRuleHotwordRegexÐ
Í
groupIndexesB* The index of the submatch to extract as findings. When not specified,
the entire match is returned. No more than 3 may be included.
ª
patternB" Pattern defining the regular expression. Its syntax
(https://github.com/google/re2/wiki/Syntax) can be found under the google/re2 repository on GitHub.
:

datalossUPreventionJobTriggerInspectJobInspectConfigRuleSetRuleHotwordRuleLikelihoodAdjustment¸gcp:dataloss/PreventionJobTriggerInspectJobInspectConfigRuleSetRuleHotwordRuleLikelihoodAdjustment:PreventionJobTriggerInspectJobInspectConfigRuleSetRuleHotwordRuleLikelihoodAdjustment÷
ôÒ
fixedLikelihoodB" ¸Set the likelihood of a finding to a fixed value. Either this or relative_likelihood can be set.
Possible values are: `VERY_UNLIKELY`, `UNLIKELY`, `POSSIBLE`, `LIKELY`, `VERY_LIKELY`.

relativeLikelihoodB ÿIncrease or decrease the likelihood by the specified number of levels. For example,
if a finding would be POSSIBLE without the detection rule and relativeLikelihood is 1,
then it is upgraded to LIKELY, while a value of -1 would downgrade it to UNLIKELY.
Likelihood may never drop below VERY_UNLIKELY or exceed VERY_LIKELY, so applying an
adjustment of 1 followed by an adjustment of -1 when base likelihood is VERY_LIKELY
will result in a final likelihood of LIKELY. Either this or fixed_likelihood can be set.
:ù
û
datalossJPreventionJobTriggerInspectJobInspectConfigRuleSetRuleHotwordRuleProximity¢gcp:dataloss/PreventionJobTriggerInspectJobInspectConfigRuleSetRuleHotwordRuleProximity:PreventionJobTriggerInspectJobInspectConfigRuleSetRuleHotwordRuleProximityø
õx
windowAfterB cNumber of characters after the finding to consider. Either this or window_before must be specified
y
windowBeforeB cNumber of characters before the finding to consider. Either this or window_after must be specified
:Ñ

dataloss+PreventionJobTriggerInspectJobStorageConfigdgcp:dataloss/PreventionJobTriggerInspectJobStorageConfig:PreventionJobTriggerInspectJobStorageConfig®
«¾
bigQueryOptionsÔBÑ:Î
Ë
dataloss:PreventionJobTriggerInspectJobStorageConfigBigQueryOptionsgcp:dataloss/PreventionJobTriggerInspectJobStorageConfigBigQueryOptions:PreventionJobTriggerInspectJobStorageConfigBigQueryOptionsTOptions defining BigQuery table and row identifiers.
Structure is documented below.
é
cloudStorageOptionsàBÝ:Ú
×
dataloss>PreventionJobTriggerInspectJobStorageConfigCloudStorageOptionsgcp:dataloss/PreventionJobTriggerInspectJobStorageConfigCloudStorageOptions:PreventionJobTriggerInspectJobStorageConfigCloudStorageOptionsoOptions defining a file or a set of files within a Google Cloud Storage bucket.
Structure is documented below.
È
datastoreOptions×BÔ:Ñ
Î
dataloss;PreventionJobTriggerInspectJobStorageConfigDatastoreOptionsgcp:dataloss/PreventionJobTriggerInspectJobStorageConfigDatastoreOptions:PreventionJobTriggerInspectJobStorageConfigDatastoreOptionsZOptions defining a data set within Google Cloud Datastore.
Structure is documented below.
æ
hybridOptionsÍBÊ:Ç
Ä
dataloss8PreventionJobTriggerInspectJobStorageConfigHybridOptions~gcp:dataloss/PreventionJobTriggerInspectJobStorageConfigHybridOptions:PreventionJobTriggerInspectJobStorageConfigHybridOptionsConfiguration to control jobs where the content being inspected is outside of Google Cloud Platform.
Structure is documented below.
Ç
timespanConfigÑBÎ:Ë
È
dataloss9PreventionJobTriggerInspectJobStorageConfigTimespanConfiggcp:dataloss/PreventionJobTriggerInspectJobStorageConfigTimespanConfig:PreventionJobTriggerInspectJobStorageConfigTimespanConfigaConfiguration of the timespan of the items to include in scanning
Structure is documented below.
:ç
Ë
dataloss:PreventionJobTriggerInspectJobStorageConfigBigQueryOptionsgcp:dataloss/PreventionJobTriggerInspectJobStorageConfigBigQueryOptions:PreventionJobTriggerInspectJobStorageConfigBigQueryOptions
¶
excludedFieldsþBû*ø:õ
ò
datalossGPreventionJobTriggerInspectJobStorageConfigBigQueryOptionsExcludedFieldgcp:dataloss/PreventionJobTriggerInspectJobStorageConfigBigQueryOptionsExcludedField:PreventionJobTriggerInspectJobStorageConfigBigQueryOptionsExcludedField¢References to fields excluded from scanning.
This allows you to skip inspection of entire columns which you know have no findings.
Structure is documented below.
É
identifyingFieldsB*:þ
û
datalossJPreventionJobTriggerInspectJobStorageConfigBigQueryOptionsIdentifyingField¢gcp:dataloss/PreventionJobTriggerInspectJobStorageConfigBigQueryOptionsIdentifyingField:PreventionJobTriggerInspectJobStorageConfigBigQueryOptionsIdentifyingField©Specifies the BigQuery fields that will be returned with findings.
If not specified, no identifying fields will be returned for findings.
Structure is documented below.
×
includedFieldsþBû*ø:õ
ò
datalossGPreventionJobTriggerInspectJobStorageConfigBigQueryOptionsIncludedFieldgcp:dataloss/PreventionJobTriggerInspectJobStorageConfigBigQueryOptionsIncludedField:PreventionJobTriggerInspectJobStorageConfigBigQueryOptionsIncludedFieldDLimit scanning only to these fields.
Structure is documented below.
¤
	rowsLimitB Max number of rows to scan. If the table has more rows than this value, the rest of the rows are omitted.
If not set, or if set to 0, all rows will be scanned. Only one of rowsLimit and rowsLimitPercent can be
specified. Cannot be used in conjunction with TimespanConfig.
Ã
rowsLimitPercentB ¨Max percentage of rows to scan. The rest are omitted. The number of rows scanned is rounded down.
Must be between 0 and 100, inclusively. Both 0 and 100 means no limit. Defaults to 0. Only one of
rowsLimit and rowsLimitPercent can be specified. Cannot be used in conjunction with TimespanConfig.
ü
sampleMethodB" åHow to sample rows if not all rows are scanned. Meaningful only when used in conjunction with either
rowsLimit or rowsLimitPercent. If not specified, rows are scanned in the order BigQuery reads them.
If TimespanConfig is set, set this to an empty string to avoid using the default value.
Default value is `TOP`.
Possible values are: `TOP`, `RANDOM_START`.
Å
tableReferenceû:ø
õ
datalossHPreventionJobTriggerInspectJobStorageConfigBigQueryOptionsTableReferencegcp:dataloss/PreventionJobTriggerInspectJobStorageConfigBigQueryOptionsTableReference:PreventionJobTriggerInspectJobStorageConfigBigQueryOptionsTableReference5Set of files to scan.
Structure is documented below.
:¹
ò
datalossGPreventionJobTriggerInspectJobStorageConfigBigQueryOptionsExcludedFieldgcp:dataloss/PreventionJobTriggerInspectJobStorageConfigBigQueryOptionsExcludedField:PreventionJobTriggerInspectJobStorageConfigBigQueryOptionsExcludedFieldB
@>
name" 2Name describing the field excluded from scanning.
:«
û
datalossJPreventionJobTriggerInspectJobStorageConfigBigQueryOptionsIdentifyingField¢gcp:dataloss/PreventionJobTriggerInspectJobStorageConfigBigQueryOptionsIdentifyingField:PreventionJobTriggerInspectJobStorageConfigBigQueryOptionsIdentifyingField+
)'
name" Name describing the field.
:¿
ò
datalossGPreventionJobTriggerInspectJobStorageConfigBigQueryOptionsIncludedFieldgcp:dataloss/PreventionJobTriggerInspectJobStorageConfigBigQueryOptionsIncludedField:PreventionJobTriggerInspectJobStorageConfigBigQueryOptionsIncludedFieldH
FD
name" 8Name describing the field to which scanning is limited.
:³
õ
datalossHPreventionJobTriggerInspectJobStorageConfigBigQueryOptionsTableReferencegcp:dataloss/PreventionJobTriggerInspectJobStorageConfigBigQueryOptionsTableReference:PreventionJobTriggerInspectJobStorageConfigBigQueryOptionsTableReference¸
µ.
	datasetId" The dataset ID of the table.
[
	projectId" JThe Google Cloud Platform project ID of the project containing the table.
&
tableId" The name of the table.
:Æ
×
dataloss>PreventionJobTriggerInspectJobStorageConfigCloudStorageOptionsgcp:dataloss/PreventionJobTriggerInspectJobStorageConfigCloudStorageOptions:PreventionJobTriggerInspectJobStorageConfigCloudStorageOptionsé
æ 
bytesLimitPerFileB Max number of bytes to scan from a file. If a scanned file's size is bigger than this value
then the rest of the bytes are omitted.
Ú
bytesLimitPerFilePercentB ·Max percentage of bytes to scan from a file. The rest are omitted. The number of bytes scanned is rounded down.
Must be between 0 and 100, inclusively. Both 0 and 100 means no limit.
µ
fileSetò:ï
ì
datalossEPreventionJobTriggerInspectJobStorageConfigCloudStorageOptionsFileSetgcp:dataloss/PreventionJobTriggerInspectJobStorageConfigCloudStorageOptionsFileSet:PreventionJobTriggerInspectJobStorageConfigCloudStorageOptionsFileSet5Set of files to scan.
Structure is documented below.
â
	fileTypesB*" ÌList of file type groups to include in the scan. If empty, all files are scanned and available data
format processors are applied. In addition, the binary content of the selected files is always scanned as well.
Images are scanned only as binary if the specified region does not support image inspection and no fileTypes were specified.
Each value may be one of: `BINARY_FILE`, `TEXT_FILE`, `IMAGE`, `WORD`, `PDF`, `AVRO`, `CSV`, `TSV`, `POWERPOINT`, `EXCEL`.
Ø
filesLimitPercentB ¼Limits the number of files to scan to this percentage of the input FileSet. Number of files scanned is rounded down.
Must be between 0 and 100, inclusively. Both 0 and 100 means no limit.
ë
sampleMethodB" ÔHow to sample bytes if not all bytes are scanned. Meaningful only when used in conjunction with bytesLimitPerFile.
If not specified, scanning would start from the top.
Possible values are: `TOP`, `RANDOM_START`.
:³
ì
datalossEPreventionJobTriggerInspectJobStorageConfigCloudStorageOptionsFileSetgcp:dataloss/PreventionJobTriggerInspectJobStorageConfigCloudStorageOptionsFileSet:PreventionJobTriggerInspectJobStorageConfigCloudStorageOptionsFileSetÁ
¾ô
regexFileSetB:

datalossQPreventionJobTriggerInspectJobStorageConfigCloudStorageOptionsFileSetRegexFileSet°gcp:dataloss/PreventionJobTriggerInspectJobStorageConfigCloudStorageOptionsFileSetRegexFileSet:PreventionJobTriggerInspectJobStorageConfigCloudStorageOptionsFileSetRegexFileSetHThe regex-filtered set of files to scan.
Structure is documented below.
Ä
urlB" ¶The Cloud Storage url of the file(s) to scan, in the format `gs://<bucket>/<path>`. Trailing wildcard
in the path is allowed.
If the url ends in a trailing slash, the bucket or directory represented by the url will be scanned
non-recursively (content in sub-directories will not be scanned). This means that `gs://mybucket/` is
equivalent to `gs://mybucket/*`, and `gs://mybucket/directory/` is equivalent to `gs://mybucket/directory/*`.
:

datalossQPreventionJobTriggerInspectJobStorageConfigCloudStorageOptionsFileSetRegexFileSet°gcp:dataloss/PreventionJobTriggerInspectJobStorageConfigCloudStorageOptionsFileSetRegexFileSet:PreventionJobTriggerInspectJobStorageConfigCloudStorageOptionsFileSetRegexFileSet÷
ô6

bucketName" $The name of a Cloud Storage bucket.
Æ
excludeRegexesB*" «A list of regular expressions matching file paths to exclude. All files in the bucket that match at
least one of these regular expressions will be excluded from the scan.
ð
includeRegexesB*" ÕA list of regular expressions matching file paths to include. All files in the bucket
that match at least one of these regular expressions will be included in the set of files,
except for those that also match an item in excludeRegex. Leaving this field empty will
match all files by default (this is equivalent to including .* in the list)
:Ö
Î
dataloss;PreventionJobTriggerInspectJobStorageConfigDatastoreOptionsgcp:dataloss/PreventionJobTriggerInspectJobStorageConfigDatastoreOptions:PreventionJobTriggerInspectJobStorageConfigDatastoreOptions
ÿ°
kindà:Ý
Ú
dataloss?PreventionJobTriggerInspectJobStorageConfigDatastoreOptionsKindgcp:dataloss/PreventionJobTriggerInspectJobStorageConfigDatastoreOptionsKind:PreventionJobTriggerInspectJobStorageConfigDatastoreOptionsKindEA representation of a Datastore kind.
Structure is documented below.
É
partitionIdõ:ò
ï
datalossFPreventionJobTriggerInspectJobStorageConfigDatastoreOptionsPartitionIdgcp:dataloss/PreventionJobTriggerInspectJobStorageConfigDatastoreOptionsPartitionId:PreventionJobTriggerInspectJobStorageConfigDatastoreOptionsPartitionIdÁDatastore partition ID. A partition ID identifies a grouping of entities. The grouping
is always by project and namespace, however the namespace ID may be empty.
Structure is documented below.
:
Ú
dataloss?PreventionJobTriggerInspectJobStorageConfigDatastoreOptionsKindgcp:dataloss/PreventionJobTriggerInspectJobStorageConfigDatastoreOptionsKind:PreventionJobTriggerInspectJobStorageConfigDatastoreOptionsKind0
.,
name"  The name of the Datastore kind.
:
ï
datalossFPreventionJobTriggerInspectJobStorageConfigDatastoreOptionsPartitionIdgcp:dataloss/PreventionJobTriggerInspectJobStorageConfigDatastoreOptionsPartitionId:PreventionJobTriggerInspectJobStorageConfigDatastoreOptionsPartitionId¥
¢Y
namespaceIdB" DIf not empty, the ID of the namespace to which the entities belong.
E
	projectId" 4The ID of the project to which the entities belong.
:
Ä
dataloss8PreventionJobTriggerInspectJobStorageConfigHybridOptions~gcp:dataloss/PreventionJobTriggerInspectJobStorageConfigHybridOptions:PreventionJobTriggerInspectJobStorageConfigHybridOptionsÃ

À
{
descriptionB" fA short description of where the data is coming from. Will be stored once in the job. 256 max length.
´
labelsB2" ¡To organize findings, these labels will be added to each finding.
Label keys must be between 1 and 63 characters long and must conform to the following regular expression: `a-z?`.
Label values must be between 0 and 63 characters long and must conform to the regular expression `(a-z?)?`.
No more than 10 labels can be associated with a given finding.
Examples:
* `"environment" : "production"`
* `"pipeline" : "etl"`
æ
requiredFindingLabelKeysB*" ÁThese are labels that each inspection request must include within their 'finding_labels' map. Request
may contain others, but any missing one of these will be rejected.
Label keys must be between 1 and 63 characters long and must conform to the following regular expression: `a-z?`.
No more than 10 keys can be required.
 
tableOptionsòBï:ì
é
datalossDPreventionJobTriggerInspectJobStorageConfigHybridOptionsTableOptionsgcp:dataloss/PreventionJobTriggerInspectJobStorageConfigHybridOptionsTableOptions:PreventionJobTriggerInspectJobStorageConfigHybridOptionsTableOptionsIf the container is a table, additional information to make findings meaningful such as the columns that are primary keys.
Structure is documented below.
:Ð
é
datalossDPreventionJobTriggerInspectJobStorageConfigHybridOptionsTableOptionsgcp:dataloss/PreventionJobTriggerInspectJobStorageConfigHybridOptionsTableOptions:PreventionJobTriggerInspectJobStorageConfigHybridOptionsTableOptionsá
ÞÛ
identifyingFields¥B¢*:

datalossTPreventionJobTriggerInspectJobStorageConfigHybridOptionsTableOptionsIdentifyingField¶gcp:dataloss/PreventionJobTriggerInspectJobStorageConfigHybridOptionsTableOptionsIdentifyingField:PreventionJobTriggerInspectJobStorageConfigHybridOptionsTableOptionsIdentifyingFieldThe columns that are the primary keys for table objects included in ContentItem. A copy of this
cell's value will stored alongside alongside each finding so that the finding can be traced to
the specific row it came from. No more than 3 may be provided.
Structure is documented below.
:É

datalossTPreventionJobTriggerInspectJobStorageConfigHybridOptionsTableOptionsIdentifyingField¶gcp:dataloss/PreventionJobTriggerInspectJobStorageConfigHybridOptionsTableOptionsIdentifyingField:PreventionJobTriggerInspectJobStorageConfigHybridOptionsTableOptionsIdentifyingField+
)'
name" Name describing the field.
:µ	
È
dataloss9PreventionJobTriggerInspectJobStorageConfigTimespanConfiggcp:dataloss/PreventionJobTriggerInspectJobStorageConfigTimespanConfig:PreventionJobTriggerInspectJobStorageConfigTimespanConfigç
äý
$enableAutoPopulationOfTimespanConfigB
 ÎWhen the job is started by a JobTrigger we will automatically figure out a valid startTime to avoid
scanning files that have not been modified since the last time the JobTrigger executed. This will
be based on the time of the execution of the last run of the JobTrigger or the timespan endTime
used in the last run of the JobTrigger.
s
endTimeB" bExclude files, tables, or rows newer than this value. If not set, no upper time limit is applied.
u
	startTimeB" bExclude files, tables, or rows older than this value. If not set, no lower time limit is applied.
õ
timestampFieldûBø:õ
ò
datalossGPreventionJobTriggerInspectJobStorageConfigTimespanConfigTimestampFieldgcp:dataloss/PreventionJobTriggerInspectJobStorageConfigTimespanConfigTimestampField:PreventionJobTriggerInspectJobStorageConfigTimespanConfigTimestampFieldeSpecification of the field containing the timestamp of scanned items.
Structure is documented below.
:æ
ò
datalossGPreventionJobTriggerInspectJobStorageConfigTimespanConfigTimestampFieldgcp:dataloss/PreventionJobTriggerInspectJobStorageConfigTimespanConfigTimestampField:PreventionJobTriggerInspectJobStorageConfigTimespanConfigTimestampFieldî
ëè
name" ÛSpecification of the field containing the timestamp of scanned items. Used for data sources like Datastore and BigQuery.
For BigQuery: Required to filter out rows based on the given start and end times. If not specified and the table was
modified between the given start and end times, the entire table will be scanned. The valid data types of the timestamp
field are: INTEGER, DATE, TIMESTAMP, or DATETIME BigQuery column.
For Datastore. Valid data types of the timestamp field are: TIMESTAMP. Datastore entity will be scanned if the
timestamp property does not exist or its value is empty or invalid.
:­
m
datalossPreventionJobTriggerTriggerDgcp:dataloss/PreventionJobTriggerTrigger:PreventionJobTriggerTrigger»
¸Ú
manualB:

dataloss!PreventionJobTriggerTriggerManualPgcp:dataloss/PreventionJobTriggerTriggerManual:PreventionJobTriggerTriggerManualFFor use with hybrid jobs. Jobs must be manually created and finished.
Ø
scheduleB:

dataloss#PreventionJobTriggerTriggerScheduleTgcp:dataloss/PreventionJobTriggerTriggerSchedule:PreventionJobTriggerTriggerSchedule;Schedule for triggered jobs
Structure is documented below.
:

dataloss!PreventionJobTriggerTriggerManualPgcp:dataloss/PreventionJobTriggerTriggerManual:PreventionJobTriggerTriggerManual
 :×

dataloss#PreventionJobTriggerTriggerScheduleTgcp:dataloss/PreventionJobTriggerTriggerSchedule:PreventionJobTriggerTriggerScheduleÌ
ÉÆ
recurrencePeriodDurationB" £With this option a job is started a regular periodic basis. For example: every day (86400 seconds).
A scheduled start time will be skipped if the previous execution has not ended when its scheduled time occurs.
This value must be set to a time duration greater than or equal to 1 day and can be no longer than 60 days.
A duration in seconds with up to nine fractional digits, terminated by 's'. Example: "3.5s".

- - -
:Í

dataloss"PreventionStoredInfoTypeDictionaryRgcp:dataloss/PreventionStoredInfoTypeDictionary:PreventionStoredInfoTypeDictionaryÅ
ÂÃ
cloudStoragePath»B¸:µ
²
dataloss2PreventionStoredInfoTypeDictionaryCloudStoragePathrgcp:dataloss/PreventionStoredInfoTypeDictionaryCloudStoragePath:PreventionStoredInfoTypeDictionaryCloudStoragePathqNewline-delimited file of words in Cloud Storage. Only a single file is accepted.
Structure is documented below.
ù
wordList£B :

dataloss*PreventionStoredInfoTypeDictionaryWordListbgcp:dataloss/PreventionStoredInfoTypeDictionaryWordList:PreventionStoredInfoTypeDictionaryWordListGList of words or phrases to search for.
Structure is documented below.
:¸
²
dataloss2PreventionStoredInfoTypeDictionaryCloudStoragePathrgcp:dataloss/PreventionStoredInfoTypeDictionaryCloudStoragePath:PreventionStoredInfoTypeDictionaryCloudStoragePath
~|
path" pA url representing a file or path (no wildcards) in Cloud Storage. Example: `gs://[BUCKET_NAME]/dictionary.txt`
:à

dataloss*PreventionStoredInfoTypeDictionaryWordListbgcp:dataloss/PreventionStoredInfoTypeDictionaryWordList:PreventionStoredInfoTypeDictionaryWordListÀ
½º
words*" ªWords or phrases defining the dictionary. The dictionary must contain at least one
phrase and every phrase must contain at least 2 characters that are letters or digits.
:Ó

£
dataloss-PreventionStoredInfoTypeLargeCustomDictionaryhgcp:dataloss/PreventionStoredInfoTypeLargeCustomDictionary:PreventionStoredInfoTypeLargeCustomDictionaryª	
§	Ñ
bigQueryFieldÔBÑ:Î
Ë
dataloss:PreventionStoredInfoTypeLargeCustomDictionaryBigQueryFieldgcp:dataloss/PreventionStoredInfoTypeLargeCustomDictionaryBigQueryField:PreventionStoredInfoTypeLargeCustomDictionaryBigQueryFieldiField in a BigQuery table where each cell represents a dictionary phrase.
Structure is documented below.
æ
cloudStorageFileSetæBã:à
Ý
dataloss@PreventionStoredInfoTypeLargeCustomDictionaryCloudStorageFileSetgcp:dataloss/PreventionStoredInfoTypeLargeCustomDictionaryCloudStorageFileSet:PreventionStoredInfoTypeLargeCustomDictionaryCloudStorageFileSetfSet of files containing newline-delimited lists of dictionary phrases.
Structure is documented below.
ç

outputPathÇ:Ä
Á
dataloss7PreventionStoredInfoTypeLargeCustomDictionaryOutputPath|gcp:dataloss/PreventionStoredInfoTypeLargeCustomDictionaryOutputPath:PreventionStoredInfoTypeLargeCustomDictionaryOutputPathLocation to store dictionary artifacts in Google Cloud Storage. These files will only be accessible by project owners and the DLP API.
If any of these artifacts are modified, the dictionary is considered invalid and can no longer be used.
Structure is documented below.
:â
Ë
dataloss:PreventionStoredInfoTypeLargeCustomDictionaryBigQueryFieldgcp:dataloss/PreventionStoredInfoTypeLargeCustomDictionaryBigQueryField:PreventionStoredInfoTypeLargeCustomDictionaryBigQueryField
³
fieldà:Ý
Ú
dataloss?PreventionStoredInfoTypeLargeCustomDictionaryBigQueryFieldFieldgcp:dataloss/PreventionStoredInfoTypeLargeCustomDictionaryBigQueryFieldField:PreventionStoredInfoTypeLargeCustomDictionaryBigQueryFieldFieldGDesignated field in the BigQuery table.
Structure is documented below.
Õ
tableà:Ý
Ú
dataloss?PreventionStoredInfoTypeLargeCustomDictionaryBigQueryFieldTablegcp:dataloss/PreventionStoredInfoTypeLargeCustomDictionaryBigQueryFieldTable:PreventionStoredInfoTypeLargeCustomDictionaryBigQueryFieldTableiField in a BigQuery table where each cell represents a dictionary phrase.
Structure is documented below.
:
Ú
dataloss?PreventionStoredInfoTypeLargeCustomDictionaryBigQueryFieldFieldgcp:dataloss/PreventionStoredInfoTypeLargeCustomDictionaryBigQueryFieldField:PreventionStoredInfoTypeLargeCustomDictionaryBigQueryFieldField+
)'
name" Name describing the field.
:
Ú
dataloss?PreventionStoredInfoTypeLargeCustomDictionaryBigQueryFieldTablegcp:dataloss/PreventionStoredInfoTypeLargeCustomDictionaryBigQueryFieldTable:PreventionStoredInfoTypeLargeCustomDictionaryBigQueryFieldTable¸
µ.
	datasetId" The dataset ID of the table.
[
	projectId" JThe Google Cloud Platform project ID of the project containing the table.
&
tableId" The name of the table.
:Ê
Ý
dataloss@PreventionStoredInfoTypeLargeCustomDictionaryCloudStorageFileSetgcp:dataloss/PreventionStoredInfoTypeLargeCustomDictionaryCloudStorageFileSet:PreventionStoredInfoTypeLargeCustomDictionaryCloudStorageFileSeth
fd
url" YThe url, in the format `gs://<bucket>/<path>`. Trailing wildcard in the path is allowed.
:Ç
Á
dataloss7PreventionStoredInfoTypeLargeCustomDictionaryOutputPath|gcp:dataloss/PreventionStoredInfoTypeLargeCustomDictionaryOutputPath:PreventionStoredInfoTypeLargeCustomDictionaryOutputPath
~|
path" pA url representing a file or path (no wildcards) in Cloud Storage. Example: `gs://[BUCKET_NAME]/dictionary.txt`
:Æ
s
datalossPreventionStoredInfoTypeRegexHgcp:dataloss/PreventionStoredInfoTypeRegex:PreventionStoredInfoTypeRegexÎ
Ë
groupIndexesB* The index of the submatch to extract as findings. When not specified, the entire match is returned. No more than 3 may be included.
¨
pattern" Pattern defining the regular expression.
Its syntax (https://github.com/google/re2/wiki/Syntax) can be found under the google/re2 repository on GitHub.
:­
s
dataplexAspectTypeIamBindingConditionHgcp:dataplex/AspectTypeIamBindingCondition:AspectTypeIamBindingCondition6
4
descriptionB" 

expression" 
title" :ª
p
dataplexAspectTypeIamMemberConditionFgcp:dataplex/AspectTypeIamMemberCondition:AspectTypeIamMemberCondition6
4
descriptionB" 

expression" 
title" :¥
R
dataplexAssetDiscoverySpec2gcp:dataplex/AssetDiscoverySpec:AssetDiscoverySpecÎ
Ë¬

csvOptionsvBt:r
p
dataplexAssetDiscoverySpecCsvOptionsFgcp:dataplex/AssetDiscoverySpecCsvOptions:AssetDiscoverySpecCsvOptions&Optional. Configuration for CSV data.
7
enabled
 (Required. Whether discovery is enabled.
­
excludePatternsB*" Optional. The list of patterns to apply for selecting data to exclude during discovery. For Cloud Storage bucket assets, these are interpreted as glob patterns used to match object names. For BigQuery dataset assets, these are interpreted as patterns to match table names.
Ü
includePatternsB*" ÀOptional. The list of patterns to apply for selecting data to include during discovery if only a subset of the data should considered. For Cloud Storage bucket assets, these are interpreted as glob patterns used to match object names. For BigQuery dataset assets, these are interpreted as patterns to match table names.
±
jsonOptionsyBw:u
s
dataplexAssetDiscoverySpecJsonOptionsHgcp:dataplex/AssetDiscoverySpecJsonOptions:AssetDiscoverySpecJsonOptions'Optional. Configuration for Json data.

scheduleB" Optional. Cron schedule (https://en.wikipedia.org/wiki/Cron) for running discovery periodically. Successive discovery runs must be scheduled at least 60 minutes apart. The default value is to run discovery every 60 minutes. To explicitly set a timezone to the cron tab, apply a prefix in the cron tab: "CRON_TZ=${IANA_TIME_ZONE}" or TZ=${IANA_TIME_ZONE}". The ${IANA_TIME_ZONE} may only be a valid string from IANA time zone database. For example, "CRON_TZ=America/New_York 1 * * * *", or "TZ=America/New_York 1 * * * *".
:Ë
p
dataplexAssetDiscoverySpecCsvOptionsFgcp:dataplex/AssetDiscoverySpecCsvOptions:AssetDiscoverySpecCsvOptionsÖ
Ó`
	delimiterB" MOptional. The delimiter being used to separate values. This defaults to ','.

disableTypeInferenceB
 zOptional. Whether to disable the inference of data type for CSV data. If true, all columns will be registered as strings.
V
encodingB" DOptional. The character encoding of the data. The default is UTF-8.
|

headerRowsB hOptional. The number of rows to interpret as header rows that should be skipped when reading data rows.
:
s
dataplexAssetDiscoverySpecJsonOptionsHgcp:dataplex/AssetDiscoverySpecJsonOptions:AssetDiscoverySpecJsonOptions£
 Å
disableTypeInferenceB
 ¦Optional. Whether to disable the inference of data type for Json data. If true, all columns will be registered as their primitive types (strings, number or boolean).
V
encodingB" DOptional. The character encoding of the data. The default is UTF-8.
:¨
X
dataplexAssetDiscoveryStatus6gcp:dataplex/AssetDiscoveryStatus:AssetDiscoveryStatusË
ÈA
lastRunDurationB" (The duration of the last discovery run.
?
lastRunTimeB" *The start time of the last discovery run.
A
messageB" 0Additional information about the current state.

stateB" yOutput only. Current state of the asset. Possible values: STATE_UNSPECIFIED, ACTIVE, CREATING, DELETING, ACTION_REQUIRED
¦
statslBj*h:f
d
dataplexAssetDiscoveryStatusStat>gcp:dataplex/AssetDiscoveryStatusStat:AssetDiscoveryStatusStat/Data Stats of the asset reported by discovery.
K

updateTimeB" 7Output only. The time when the asset was last updated.
:­
d
dataplexAssetDiscoveryStatusStat>gcp:dataplex/AssetDiscoveryStatusStat:AssetDiscoveryStatusStatÄ
ÁK
	dataItemsB 8The count of data items within the referenced resource.
R
dataSizeB @The number of stored data bytes within the referenced resource.
P
filesetsB >The count of fileset entities within the referenced resource.
L
tablesB <The count of table entities within the referenced resource.
:
d
dataplexAssetIamBindingCondition>gcp:dataplex/AssetIamBindingCondition:AssetIamBindingCondition6
4
descriptionB" 

expression" 
title" :
a
dataplexAssetIamMemberCondition<gcp:dataplex/AssetIamMemberCondition:AssetIamMemberCondition6
4
descriptionB" 

expression" 
title" :ú
O
dataplexAssetResourceSpec0gcp:dataplex/AssetResourceSpec:AssetResourceSpec¦
£é
nameB" ÚImmutable. Relative name of the cloud resource that contains the data that is being managed within a lake. For example: `projects/{project_number}/buckets/{bucket_id}` `projects/{project_number}/datasets/{dataset_id}`
Æ
readAccessModeB" ­Optional. Determines how read permissions are handled for each asset and their associated tables. Only available to storage buckets assets. Possible values: DIRECT, MANAGED
l
type" `Required. Immutable. Type of resource. Possible values: STORAGE_BUCKET, BIGQUERY_DATASET

- - -
:ø
U
dataplexAssetResourceStatus4gcp:dataplex/AssetResourceStatus:AssetResourceStatus
A
messageB" 0Additional information about the current state.

stateB" yOutput only. Current state of the asset. Possible values: STATE_UNSPECIFIED, ACTIVE, CREATING, DELETING, ACTION_REQUIRED
K

updateTimeB" 7Output only. The time when the asset was last updated.
:ø
U
dataplexAssetSecurityStatus4gcp:dataplex/AssetSecurityStatus:AssetSecurityStatus
A
messageB" 0Additional information about the current state.

stateB" yOutput only. Current state of the asset. Possible values: STATE_UNSPECIFIED, ACTIVE, CREATING, DELETING, ACTION_REQUIRED
K

updateTimeB" 7Output only. The time when the asset was last updated.
:®
@
dataplexDatascanData&gcp:dataplex/DatascanData:DatascanDataé
æg
entityB" WThe Dataplex entity that represents the data source(e.g. BigQuery table) for Datascan.
ú
resourceB" çThe service-qualified full resource name of the cloud resource for a DataScan job to scan against. The field could be:
(Cloud Storage bucket for DataDiscoveryScan)BigQuery table of type "TABLE" for DataProfileScan/DataQualityScan.
:ô
a
dataplexDatascanDataProfileSpec<gcp:dataplex/DatascanDataProfileSpec:DatascanDataProfileSpec
Ñ
excludeFieldsB:

dataplex$DatascanDataProfileSpecExcludeFieldsVgcp:dataplex/DatascanDataProfileSpecExcludeFields:DatascanDataProfileSpecExcludeFields«The fields to exclude from data profile.
If specified, the fields will be excluded from data profile, regardless of `include_fields` value.
Structure is documented below.
í
includeFieldsB:

dataplex$DatascanDataProfileSpecIncludeFieldsVgcp:dataplex/DatascanDataProfileSpecIncludeFields:DatascanDataProfileSpecIncludeFieldsÇThe fields to include in data profile.
If not specified, all fields at the time of profile scan job execution are included, except for ones listed in `exclude_fields`.
Structure is documented below.
ñ
postScanActionsB:

dataplex&DatascanDataProfileSpecPostScanActionsZgcp:dataplex/DatascanDataProfileSpecPostScanActions:DatascanDataProfileSpecPostScanActionsDActions to take upon job completion.
Structure is documented below.
Î
	rowFilterB" ºA filter applied to all rows in a single DataScan job. The filter needs to be a valid SQL expression for a WHERE clause in BigQuery standard SQL syntax. Example: col1 >= 0 AND col2 < 10
ÿ
samplingPercentB åThe percentage of the records to be selected from the dataset for DataScan.
Value can range between 0.0 and 100.0 with up to 3 significant decimal digits.
Sampling is not applied if `sampling_percent` is not specified, 0 or 100.
:Ç

dataplex$DatascanDataProfileSpecExcludeFieldsVgcp:dataplex/DatascanDataProfileSpecExcludeFields:DatascanDataProfileSpecExcludeFields¹
¶³

fieldNamesB*" Expected input is a list of fully qualified names of fields as in the schema.
Only top-level field names for nested fields are supported.
For instance, if 'x' is of nested field type, listing 'x' is supported but 'x.y.z' is not supported. Here 'y' and 'y.z' are nested fields of 'x'.
:Ç

dataplex$DatascanDataProfileSpecIncludeFieldsVgcp:dataplex/DatascanDataProfileSpecIncludeFields:DatascanDataProfileSpecIncludeFields¹
¶³

fieldNamesB*" Expected input is a list of fully qualified names of fields as in the schema.
Only top-level field names for nested fields are supported.
For instance, if 'x' is of nested field type, listing 'x' is supported but 'x.y.z' is not supported. Here 'y' and 'y.z' are nested fields of 'x'.
:Ð

dataplex&DatascanDataProfileSpecPostScanActionsZgcp:dataplex/DatascanDataProfileSpecPostScanActions:DatascanDataProfileSpecPostScanActions¼
¹¶
bigqueryExportÁB¾:»
¸
dataplex4DatascanDataProfileSpecPostScanActionsBigqueryExportvgcp:dataplex/DatascanDataProfileSpecPostScanActionsBigqueryExport:DatascanDataProfileSpecPostScanActionsBigqueryExport`If set, results will be exported to the provided BigQuery table.
Structure is documented below.
:í
¸
dataplex4DatascanDataProfileSpecPostScanActionsBigqueryExportvgcp:dataplex/DatascanDataProfileSpecPostScanActionsBigqueryExport:DatascanDataProfileSpecPostScanActionsBigqueryExport¯
¬©
resultsTableB" The BigQuery table to export DataProfileScan results to.
Format://bigquery.googleapis.com/projects/PROJECT_ID/datasets/DATASET_ID/tables/TABLE_ID
:¦
a
dataplexDatascanDataQualitySpec<gcp:dataplex/DatascanDataQualitySpec:DatascanDataQualitySpecÀ
½ñ
postScanActionsB:

dataplex&DatascanDataQualitySpecPostScanActionsZgcp:dataplex/DatascanDataQualitySpecPostScanActions:DatascanDataQualitySpecPostScanActionsDActions to take upon job completion.
Structure is documented below.
Î
	rowFilterB" ºA filter applied to all rows in a single DataScan job. The filter needs to be a valid SQL expression for a WHERE clause in BigQuery standard SQL syntax. Example: col1 >= 0 AND col2 < 10
ó
rulesuBs*q:o
m
dataplexDatascanDataQualitySpecRuleDgcp:dataplex/DatascanDataQualitySpecRule:DatascanDataQualitySpecRulesThe list of rules to evaluate against a data source. At least one rule is required.
Structure is documented below.
ÿ
samplingPercentB åThe percentage of the records to be selected from the dataset for DataScan.
Value can range between 0.0 and 100.0 with up to 3 significant decimal digits.
Sampling is not applied if `sampling_percent` is not specified, 0 or 100.
:Ð

dataplex&DatascanDataQualitySpecPostScanActionsZgcp:dataplex/DatascanDataQualitySpecPostScanActions:DatascanDataQualitySpecPostScanActions¼
¹¶
bigqueryExportÁB¾:»
¸
dataplex4DatascanDataQualitySpecPostScanActionsBigqueryExportvgcp:dataplex/DatascanDataQualitySpecPostScanActionsBigqueryExport:DatascanDataQualitySpecPostScanActionsBigqueryExport`If set, results will be exported to the provided BigQuery table.
Structure is documented below.
:í
¸
dataplex4DatascanDataQualitySpecPostScanActionsBigqueryExportvgcp:dataplex/DatascanDataQualitySpecPostScanActionsBigqueryExport:DatascanDataQualitySpecPostScanActionsBigqueryExport¯
¬©
resultsTableB" The BigQuery table to export DataProfileScan results to.
Format://bigquery.googleapis.com/projects/PROJECT_ID/datasets/DATASET_ID/tables/TABLE_ID
:
m
dataplexDatascanDataQualitySpecRuleDgcp:dataplex/DatascanDataQualitySpecRule:DatascanDataQualitySpecRule
J
columnB" :The unnested column which this rule is evaluated against.
V
descriptionB" ADescription of the rule.
The maximum length is 1,024 characters.
Ó
	dimension" ÁThe dimension a rule belongs to. Results are also aggregated at the dimension level. Supported dimensions are ["COMPLETENESS", "ACCURACY", "CONSISTENCY", "VALIDITY", "UNIQUENESS", "INTEGRITY"]
É

ignoreNullB
 ´Rows with null values will automatically fail a rule, unless ignoreNull is true. In that case, such null rows are trivially considered passing. Only applicable to ColumnMap rules.
Ý
nameB" ÎA mutable name for the rule.
The name must contain only letters (a-z, A-Z), numbers (0-9), or hyphens (-).
The maximum length is 63 characters.
Must start with a letter.
Must end with a number or a letter.

nonNullExpectation¬B©:¦
£
dataplex-DatascanDataQualitySpecRuleNonNullExpectationhgcp:dataplex/DatascanDataQualitySpecRuleNonNullExpectation:DatascanDataQualitySpecRuleNonNullExpectationBColumnMap rule which evaluates whether each column value is null.
µ
rangeExpectation¦B£: 

dataplex+DatascanDataQualitySpecRuleRangeExpectationdgcp:dataplex/DatascanDataQualitySpecRuleRangeExpectation:DatascanDataQualitySpecRuleRangeExpectationxColumnMap rule which evaluates whether each column value lies between a specified range.
Structure is documented below.
°
regexExpectation¦B£: 

dataplex+DatascanDataQualitySpecRuleRegexExpectationdgcp:dataplex/DatascanDataQualitySpecRuleRegexExpectation:DatascanDataQualitySpecRuleRegexExpectationsColumnMap rule which evaluates whether each column value matches a specified regex.
Structure is documented below.
Ä
rowConditionExpectation»B¸:µ
²
dataplex2DatascanDataQualitySpecRuleRowConditionExpectationrgcp:dataplex/DatascanDataQualitySpecRuleRowConditionExpectation:DatascanDataQualitySpecRuleRowConditionExpectationkTable rule which evaluates whether each row passes the specified condition.
Structure is documented below.
®
setExpectation B:

dataplex)DatascanDataQualitySpecRuleSetExpectation`gcp:dataplex/DatascanDataQualitySpecRuleSetExpectation:DatascanDataQualitySpecRuleSetExpectationyColumnMap rule which evaluates whether each column value is contained by a specified set.
Structure is documented below.

sqlAssertionB:

dataplex'DatascanDataQualitySpecRuleSqlAssertion\gcp:dataplex/DatascanDataQualitySpecRuleSqlAssertion:DatascanDataQualitySpecRuleSqlAssertionaTable rule which evaluates whether any row matches invalid state.
Structure is documented below.
í
statisticRangeExpectationÁB¾:»
¸
dataplex4DatascanDataQualitySpecRuleStatisticRangeExpectationvgcp:dataplex/DatascanDataQualitySpecRuleStatisticRangeExpectation:DatascanDataQualitySpecRuleStatisticRangeExpectationColumnAggregate rule which evaluates whether the column aggregate statistic lies between a specified range.
Structure is documented below.
Ä
tableConditionExpectationÁB¾:»
¸
dataplex4DatascanDataQualitySpecRuleTableConditionExpectationvgcp:dataplex/DatascanDataQualitySpecRuleTableConditionExpectation:DatascanDataQualitySpecRuleTableConditionExpectationcTable rule which evaluates whether the provided expression is true.
Structure is documented below.
¡
	thresholdB The minimum ratio of passing_rows / total_rows required to pass this rule, with a range of [0.0, 1.0]. 0 indicates default value (i.e. 1.0).

uniquenessExpectationµB²:¯
¬
dataplex0DatascanDataQualitySpecRuleUniquenessExpectationngcp:dataplex/DatascanDataQualitySpecRuleUniquenessExpectation:DatascanDataQualitySpecRuleUniquenessExpectationDRow-level rule which evaluates whether each column value is unique.
:ª
£
dataplex-DatascanDataQualitySpecRuleNonNullExpectationhgcp:dataplex/DatascanDataQualitySpecRuleNonNullExpectation:DatascanDataQualitySpecRuleNonNullExpectation
 :Í

dataplex+DatascanDataQualitySpecRuleRangeExpectationdgcp:dataplex/DatascanDataQualitySpecRuleRangeExpectation:DatascanDataQualitySpecRuleRangeExpectationª
§
maxValueB" The maximum column value allowed for a row to pass this validation. At least one of minValue and maxValue need to be provided.

minValueB" The minimum column value allowed for a row to pass this validation. At least one of minValue and maxValue need to be provided.
¼
strictMaxEnabledB
 ¡Whether each value needs to be strictly lesser than ('<') the maximum, or if equality is allowed.
Only relevant if a maxValue has been defined. Default = false.
½
strictMinEnabledB
 ¢Whether each value needs to be strictly greater than ('>') the minimum, or if equality is allowed.
Only relevant if a minValue has been defined. Default = false.
:ï

dataplex+DatascanDataQualitySpecRuleRegexExpectationdgcp:dataplex/DatascanDataQualitySpecRuleRegexExpectation:DatascanDataQualitySpecRuleRegexExpectationM
KI
regex" <A regular expression the column value is expected to match.
:ä
²
dataplex2DatascanDataQualitySpecRuleRowConditionExpectationrgcp:dataplex/DatascanDataQualitySpecRuleRowConditionExpectation:DatascanDataQualitySpecRuleRowConditionExpectation-
+)
sqlExpression" The SQL expression.
:Ö

dataplex)DatascanDataQualitySpecRuleSetExpectation`gcp:dataplex/DatascanDataQualitySpecRuleSetExpectation:DatascanDataQualitySpecRuleSetExpectation:
86
values*" &Expected values for the column value.
:Á

dataplex'DatascanDataQualitySpecRuleSqlAssertion\gcp:dataplex/DatascanDataQualitySpecRuleSqlAssertion:DatascanDataQualitySpecRuleSqlAssertion+
)'
sqlStatement" The SQL statement.
:ò
¸
dataplex4DatascanDataQualitySpecRuleStatisticRangeExpectationvgcp:dataplex/DatascanDataQualitySpecRuleStatisticRangeExpectation:DatascanDataQualitySpecRuleStatisticRangeExpectation´
±
maxValueB" The maximum column statistic value allowed for a row to pass this validation.
At least one of minValue and maxValue need to be provided.

minValueB" The minimum column statistic value allowed for a row to pass this validation.
At least one of minValue and maxValue need to be provided.
f
	statistic" Ucolumn statistics.
Possible values are: `STATISTIC_UNDEFINED`, `MEAN`, `MIN`, `MAX`.
Â
strictMaxEnabledB
 §Whether column statistic needs to be strictly lesser than ('<') the maximum, or if equality is allowed.
Only relevant if a maxValue has been defined. Default = false.
Ã
strictMinEnabledB
 ¨Whether column statistic needs to be strictly greater than ('>') the minimum, or if equality is allowed.
Only relevant if a minValue has been defined. Default = false.
:ê
¸
dataplex4DatascanDataQualitySpecRuleTableConditionExpectationvgcp:dataplex/DatascanDataQualitySpecRuleTableConditionExpectation:DatascanDataQualitySpecRuleTableConditionExpectation-
+)
sqlExpression" The SQL expression.
:³
¬
dataplex0DatascanDataQualitySpecRuleUniquenessExpectationngcp:dataplex/DatascanDataQualitySpecRuleUniquenessExpectation:DatascanDataQualitySpecRuleUniquenessExpectation
 :
[
dataplexDatascanExecutionSpec8gcp:dataplex/DatascanExecutionSpec:DatascanExecutionSpec¦
£¾
fieldB" ®The unnested field (of type Date or Timestamp) that contains values which monotonically increase over time. If not specified, a data scan will run for all data in the table.
ß
triggert:r
p
dataplexDatascanExecutionSpecTriggerFgcp:dataplex/DatascanExecutionSpecTrigger:DatascanExecutionSpecTrigger^Spec related to how often and when a scan should be triggered.
Structure is documented below.
:²
p
dataplexDatascanExecutionSpecTriggerFgcp:dataplex/DatascanExecutionSpecTrigger:DatascanExecutionSpecTrigger½
ºÊ
onDemandB:

dataplex$DatascanExecutionSpecTriggerOnDemandVgcp:dataplex/DatascanExecutionSpecTriggerOnDemand:DatascanExecutionSpecTriggerOnDemand*The scan runs once via dataScans.run API.
ê
scheduleB:

dataplex$DatascanExecutionSpecTriggerScheduleVgcp:dataplex/DatascanExecutionSpecTriggerSchedule:DatascanExecutionSpecTriggerScheduleJThe scan is scheduled to run periodically.
Structure is documented below.
:

dataplex$DatascanExecutionSpecTriggerOnDemandVgcp:dataplex/DatascanExecutionSpecTriggerOnDemand:DatascanExecutionSpecTriggerOnDemand
 :ý

dataplex$DatascanExecutionSpecTriggerScheduleVgcp:dataplex/DatascanExecutionSpecTriggerSchedule:DatascanExecutionSpecTriggerSchedulep
nl
cron" `Cron schedule for running scans periodically. This field is required for Schedule scans.

- - -
:
a
dataplexDatascanExecutionStatus<gcp:dataplex/DatascanExecutionStatus:DatascanExecutionStatus©
¦Q
latestJobEndTimeB" 7(Output)
The time when the latest DataScanJob started.
Q
latestJobStartTimeB" 5(Output)
The time when the latest DataScanJob ended.
:§
m
dataplexDatascanIamBindingConditionDgcp:dataplex/DatascanIamBindingCondition:DatascanIamBindingCondition6
4
descriptionB" 

expression" 
title" :¤
j
dataplexDatascanIamMemberConditionBgcp:dataplex/DatascanIamMemberCondition:DatascanIamMemberCondition6
4
descriptionB" 

expression" 
title" :­
s
dataplexEntryGroupIamBindingConditionHgcp:dataplex/EntryGroupIamBindingCondition:EntryGroupIamBindingCondition6
4
descriptionB" 

expression" 
title" :ª
p
dataplexEntryGroupIamMemberConditionFgcp:dataplex/EntryGroupIamMemberCondition:EntryGroupIamMemberCondition6
4
descriptionB" 

expression" 
title" :ª
p
dataplexEntryTypeIamBindingConditionFgcp:dataplex/EntryTypeIamBindingCondition:EntryTypeIamBindingCondition6
4
descriptionB" 

expression" 
title" :§
m
dataplexEntryTypeIamMemberConditionDgcp:dataplex/EntryTypeIamMemberCondition:EntryTypeIamMemberCondition6
4
descriptionB" 

expression" 
title" : 
a
dataplexEntryTypeRequiredAspect<gcp:dataplex/EntryTypeRequiredAspect:EntryTypeRequiredAspect;
97
typeB" )Required aspect type for the entry type.
:Ó
I
dataplexLakeAssetStatus,gcp:dataplex/LakeAssetStatus:LakeAssetStatus
/
activeAssetsB Number of active assets.

securityPolicyApplyingAssetsB \Number of assets that are in process of updating the security policy on attached resources.
J

updateTimeB" 6Output only. The time when the lake was last updated.
:
a
dataplexLakeIamBindingCondition<gcp:dataplex/LakeIamBindingCondition:LakeIamBindingCondition6
4
descriptionB" 

expression" 
title" :
^
dataplexLakeIamMemberCondition:gcp:dataplex/LakeIamMemberCondition:LakeIamMemberCondition6
4
descriptionB" 

expression" 
title" :´
C
dataplexLakeMetastore(gcp:dataplex/LakeMetastore:LakeMetastoreì
éæ
serviceB" ÔOptional. A relative reference to the Dataproc Metastore (https://cloud.google.com/dataproc-metastore/docs) service associated with the lake: `projects/{project_id}/locations/{location_id}/services/{service_id}`
:É
U
dataplexLakeMetastoreStatus4gcp:dataplex/LakeMetastoreStatus:LakeMetastoreStatusï
ìP
endpointB" >The URI of the endpoint used to access the Metastore service.
B
messageB" 1Additional information about the current status.

stateB" xOutput only. Current state of the lake. Possible values: STATE_UNSPECIFIED, ACTIVE, CREATING, DELETING, ACTION_REQUIRED
J

updateTimeB" 6Output only. The time when the lake was last updated.
:¦
O
dataplexTaskExecutionSpec0gcp:dataplex/TaskExecutionSpec:TaskExecutionSpecÒ

Ï
Í
argsB2" ¼The arguments to pass to the task. The args can use placeholders of the format ${placeholder} as part of key/value string. These will be interpolated before passing the args to the driver. Currently supported placeholders: - ${taskId} - ${job_time} To pass positional args, set the key as TASK_ARGS. The value should be a comma-separated string of all the positional arguments. To use a delimiter other than comma, refer to https://cloud.google.com/sdk/gcloud/reference/topic/escaping. In case of other keys being present in the args, then TASK_ARGS will be passed as the last argument. An object containing a list of 'key': value pairs. Example: { 'name': 'wrench', 'mass': '1.3kg', 'count': '3' }.
¯
kmsKeyB" The Cloud KMS key to use for encryption, of the form: projects/{project_number}/locations/{locationId}/keyRings/{key-ring-name}/cryptoKeys/{key-name}.

- - -
¼
maxJobExecutionLifetimeB" The maximum duration after which the job execution is expired. A duration in seconds with up to nine fractional digits, ending with 's'. Example: '3.5s'.
{
projectB" jThe ID of the project in which the resource belongs.
If it is not provided, the provider project is used.

serviceAccount" xService account to use to execute a task. If not provided, the default Compute service account for the project is used.
:å
U
dataplexTaskExecutionStatus4gcp:dataplex/TaskExecutionStatus:TaskExecutionStatus
Æ

latestJobsxBv*t:r
p
dataplexTaskExecutionStatusLatestJobFgcp:dataplex/TaskExecutionStatusLatestJob:TaskExecutionStatusLatestJob>(Output)
latest job execution.
Structure is documented below.
=

updateTimeB" )(Output)
Last update time of the status.
:û
p
dataplexTaskExecutionStatusLatestJobFgcp:dataplex/TaskExecutionStatusLatestJob:TaskExecutionStatusLatestJob
7
endTimeB" &(Output)
The time when the job ended.
J
messageB" 9(Output)
Additional information about the current state.
©
nameB" (Output)
The relative resource name of the job, of the form: projects/{project_number}/locations/{locationId}/lakes/{lakeId}/tasks/{taskId}/jobs/{jobId}.
k

retryCountB W(Output)
The number of times the job has been retried (excluding the initial attempt).
@
serviceB" /(Output)
The underlying service running a job.
`

serviceJobB" L(Output)
The full resource name for the job run under a particular service.
?
	startTimeB" ,(Output)
The time when the job was started.
5
stateB" &(Output)
Execution state for the job.
G
uidB" :(Output)
System generated globally unique ID for the job.
:
a
dataplexTaskIamBindingCondition<gcp:dataplex/TaskIamBindingCondition:TaskIamBindingCondition6
4
descriptionB" 

expression" 
title" :
^
dataplexTaskIamMemberCondition:gcp:dataplex/TaskIamMemberCondition:TaskIamMemberCondition6
4
descriptionB" 

expression" 
title" :
@
dataplexTaskNotebook&gcp:dataplex/TaskNotebook:TaskNotebookØ
Õ¯
archiveUrisB*" Cloud Storage URIs of archives to be extracted into the working directory of each executor. Supported file types: .jar, .tar, .tar.gz, .tgz, and .zip.
h
fileUrisB*" TCloud Storage URIs of files to be placed in the working directory of each executor.
ã
infrastructureSpec|Bz:x
v
dataplexTaskNotebookInfrastructureSpecJgcp:dataplex/TaskNotebookInfrastructureSpec:TaskNotebookInfrastructureSpecOInfrastructure specification for the execution.
Structure is documented below.
Ð
notebook" ¿Path to input notebook. This can be the Cloud Storage URI of the notebook file or the path to a Notebook Content. The execution args are accessible as environment variables (TASK_key=value).
:â
v
dataplexTaskNotebookInfrastructureSpecJgcp:dataplex/TaskNotebookInfrastructureSpec:TaskNotebookInfrastructureSpecç
äý
batchB:

dataplex#TaskNotebookInfrastructureSpecBatchTgcp:dataplex/TaskNotebookInfrastructureSpecBatch:TaskNotebookInfrastructureSpecBatchcCompute resources needed for a Task when using Dataproc Serverless.
Structure is documented below.

containerImage©B¦:£
 
dataplex,TaskNotebookInfrastructureSpecContainerImagefgcp:dataplex/TaskNotebookInfrastructureSpecContainerImage:TaskNotebookInfrastructureSpecContainerImageFContainer Image Runtime Configuration.
Structure is documented below.
Ú

vpcNetworkB:

dataplex(TaskNotebookInfrastructureSpecVpcNetwork^gcp:dataplex/TaskNotebookInfrastructureSpecVpcNetwork:TaskNotebookInfrastructureSpecVpcNetwork,Vpc network.
Structure is documented below.
:¿

dataplex#TaskNotebookInfrastructureSpecBatchTgcp:dataplex/TaskNotebookInfrastructureSpecBatch:TaskNotebookInfrastructureSpecBatch´
±o
executorsCountB WTotal number of job executors. Executor Count should be between 2 and 100. [Default=2]
½
maxExecutorsCountB ¡Max configurable executors. If maxExecutorsCount > executorsCount, then auto-scaling is enabled. Max Executor Count should be between 2 and 1000. [Default=1000]
:ñ
 
dataplex,TaskNotebookInfrastructureSpecContainerImagefgcp:dataplex/TaskNotebookInfrastructureSpecContainerImage:TaskNotebookInfrastructureSpecContainerImageË
È'
imageB" Container image to use.
­
javaJarsB*" A list of Java JARS to add to the classpath. Valid input includes Cloud Storage URIs to Jar binaries. For example, gs://bucket-name/my/path/to/file.jar
©

propertiesB2" Override to common configuration of open source components installed on the Dataproc cluster. The properties to set on daemon config files. Property keys are specified in prefix:property format, for example core:hadoop.tmp.dir. For more information, see Cluster properties.
À
pythonPackagesB*" ¥A list of python packages to be installed. Valid formats include Cloud Storage URI to a PIP installable library. For example, gs://bucket-name/my/path/to/lib.tar.gz
:¸

dataplex(TaskNotebookInfrastructureSpecVpcNetwork^gcp:dataplex/TaskNotebookInfrastructureSpecVpcNetwork:TaskNotebookInfrastructureSpecVpcNetwork

networkB" {The Cloud VPC network in which the job is run. By default, the Cloud VPC network named Default within the project is used.
A
networkTagsB*" *List of network tags to apply to the job.
G

subNetworkB" 3The Cloud VPC sub-network in which the job is run.
:¡
7
dataplex	TaskSpark gcp:dataplex/TaskSpark:TaskSparkå
â¯
archiveUrisB*" Cloud Storage URIs of archives to be extracted into the working directory of each executor. Supported file types: .jar, .tar, .tar.gz, .tgz, and .zip.
h
fileUrisB*" TCloud Storage URIs of files to be placed in the working directory of each executor.
Ú
infrastructureSpecsBq:o
m
dataplexTaskSparkInfrastructureSpecDgcp:dataplex/TaskSparkInfrastructureSpec:TaskSparkInfrastructureSpecOInfrastructure specification for the execution.
Structure is documented below.
÷
	mainClassB" ãThe name of the driver's main class. The jar file that contains the class must be in the default CLASSPATH or specified in jar_file_uris. The execution args are passed in as a sequence of named process arguments (--key=value).
¶
mainJarFileUriB" The Cloud Storage URI of the jar file that contains the main class. The execution args are passed in as a sequence of named process arguments (--key=value).
Í
pythonScriptFileB" ²The Gcloud Storage URI of the main Python file to use as the driver. Must be a .py file. The execution args are passed in as a sequence of named process arguments (--key=value).
x
	sqlScriptB" eThe query text. The execution args are used to declare a set of script variables (set key='value';).
é
sqlScriptFileB" ÑA reference to a query file. This can be the Cloud Storage URI of the query file or it can the path to a SqlScript Content. The execution args are used to declare a set of script variables (set key='value';).
:¼
m
dataplexTaskSparkInfrastructureSpecDgcp:dataplex/TaskSparkInfrastructureSpec:TaskSparkInfrastructureSpecÊ
Çò
batchB:~
|
dataplex TaskSparkInfrastructureSpecBatchNgcp:dataplex/TaskSparkInfrastructureSpecBatch:TaskSparkInfrastructureSpecBatchcCompute resources needed for a Task when using Dataproc Serverless.
Structure is documented below.
û
containerImage B:

dataplex)TaskSparkInfrastructureSpecContainerImage`gcp:dataplex/TaskSparkInfrastructureSpecContainerImage:TaskSparkInfrastructureSpecContainerImageFContainer Image Runtime Configuration.
Structure is documented below.
Ñ

vpcNetworkB:

dataplex%TaskSparkInfrastructureSpecVpcNetworkXgcp:dataplex/TaskSparkInfrastructureSpecVpcNetwork:TaskSparkInfrastructureSpecVpcNetwork,Vpc network.
Structure is documented below.
:µ
|
dataplex TaskSparkInfrastructureSpecBatchNgcp:dataplex/TaskSparkInfrastructureSpecBatch:TaskSparkInfrastructureSpecBatch´
±o
executorsCountB WTotal number of job executors. Executor Count should be between 2 and 100. [Default=2]
½
maxExecutorsCountB ¡Max configurable executors. If maxExecutorsCount > executorsCount, then auto-scaling is enabled. Max Executor Count should be between 2 and 1000. [Default=1000]
:è

dataplex)TaskSparkInfrastructureSpecContainerImage`gcp:dataplex/TaskSparkInfrastructureSpecContainerImage:TaskSparkInfrastructureSpecContainerImageË
È'
imageB" Container image to use.
­
javaJarsB*" A list of Java JARS to add to the classpath. Valid input includes Cloud Storage URIs to Jar binaries. For example, gs://bucket-name/my/path/to/file.jar
©

propertiesB2" Override to common configuration of open source components installed on the Dataproc cluster. The properties to set on daemon config files. Property keys are specified in prefix:property format, for example core:hadoop.tmp.dir. For more information, see Cluster properties.
À
pythonPackagesB*" ¥A list of python packages to be installed. Valid formats include Cloud Storage URI to a PIP installable library. For example, gs://bucket-name/my/path/to/lib.tar.gz
:¯

dataplex%TaskSparkInfrastructureSpecVpcNetworkXgcp:dataplex/TaskSparkInfrastructureSpecVpcNetwork:TaskSparkInfrastructureSpecVpcNetwork

networkB" {The Cloud VPC network in which the job is run. By default, the Cloud VPC network named Default within the project is used.
A
networkTagsB*" *List of network tags to apply to the job.
G

subNetworkB" 3The Cloud VPC sub-network in which the job is run.
:Â
I
dataplexTaskTriggerSpec,gcp:dataplex/TaskTriggerSpec:TaskTriggerSpecô
ñ
disabledB
 Prevent the task from executing. This does not cancel already running tasks. It is intended to temporarily disable RECURRING tasks.
s

maxRetriesB _Number of retry attempts before aborting. Set to zero to never attempt to retry a failed task.
¹
scheduleB" ¦Cron schedule (https://en.wikipedia.org/wiki/Cron) for running tasks periodically. To explicitly set a timezone to the cron tab, apply a prefix in the cron tab: 'CRON_TZ=${IANA_TIME_ZONE}' or 'TZ=${IANA_TIME_ZONE}'. The ${IANA_TIME_ZONE} may only be a valid string from IANA time zone database. For example, CRON_TZ=America/New_York 1 * * * *, or TZ=America/New_York 1 * * * *. This field is required for RECURRING tasks.
¾
	startTimeB" ªThe first run of the task will be after this time. If not specified, the task will run shortly after being submitted if ON_DEMAND and based on the schedule if RECURRING.
c
type" WTrigger type of the user-specified Task
Possible values are: `ON_DEMAND`, `RECURRING`.
:Ó
I
dataplexZoneAssetStatus,gcp:dataplex/ZoneAssetStatus:ZoneAssetStatus
/
activeAssetsB Number of active assets.

securityPolicyApplyingAssetsB \Number of assets that are in process of updating the security policy on attached resources.
J

updateTimeB" 6Output only. The time when the zone was last updated.
:
O
dataplexZoneDiscoverySpec0gcp:dataplex/ZoneDiscoverySpec:ZoneDiscoverySpecÈ
Å©

csvOptionssBq:o
m
dataplexZoneDiscoverySpecCsvOptionsDgcp:dataplex/ZoneDiscoverySpecCsvOptions:ZoneDiscoverySpecCsvOptions&Optional. Configuration for CSV data.
7
enabled
 (Required. Whether discovery is enabled.
­
excludePatternsB*" Optional. The list of patterns to apply for selecting data to exclude during discovery. For Cloud Storage bucket assets, these are interpreted as glob patterns used to match object names. For BigQuery dataset assets, these are interpreted as patterns to match table names.
Ü
includePatternsB*" ÀOptional. The list of patterns to apply for selecting data to include during discovery if only a subset of the data should considered. For Cloud Storage bucket assets, these are interpreted as glob patterns used to match object names. For BigQuery dataset assets, these are interpreted as patterns to match table names.
®
jsonOptionsvBt:r
p
dataplexZoneDiscoverySpecJsonOptionsFgcp:dataplex/ZoneDiscoverySpecJsonOptions:ZoneDiscoverySpecJsonOptions'Optional. Configuration for Json data.

scheduleB" Optional. Cron schedule (https://en.wikipedia.org/wiki/Cron) for running discovery periodically. Successive discovery runs must be scheduled at least 60 minutes apart. The default value is to run discovery every 60 minutes. To explicitly set a timezone to the cron tab, apply a prefix in the cron tab: "CRON_TZ=${IANA_TIME_ZONE}" or TZ=${IANA_TIME_ZONE}". The ${IANA_TIME_ZONE} may only be a valid string from IANA time zone database. For example, "CRON_TZ=America/New_York 1 * * * *", or "TZ=America/New_York 1 * * * *".
:È
m
dataplexZoneDiscoverySpecCsvOptionsDgcp:dataplex/ZoneDiscoverySpecCsvOptions:ZoneDiscoverySpecCsvOptionsÖ
Ó`
	delimiterB" MOptional. The delimiter being used to separate values. This defaults to ','.

disableTypeInferenceB
 zOptional. Whether to disable the inference of data type for CSV data. If true, all columns will be registered as strings.
V
encodingB" DOptional. The character encoding of the data. The default is UTF-8.
|

headerRowsB hOptional. The number of rows to interpret as header rows that should be skipped when reading data rows.
:
p
dataplexZoneDiscoverySpecJsonOptionsFgcp:dataplex/ZoneDiscoverySpecJsonOptions:ZoneDiscoverySpecJsonOptions£
 Å
disableTypeInferenceB
 ¦Optional. Whether to disable the inference of data type for Json data. If true, all columns will be registered as their primitive types (strings, number or boolean).
V
encodingB" DOptional. The character encoding of the data. The default is UTF-8.
:
a
dataplexZoneIamBindingCondition<gcp:dataplex/ZoneIamBindingCondition:ZoneIamBindingCondition6
4
descriptionB" 

expression" 
title" :
^
dataplexZoneIamMemberCondition:gcp:dataplex/ZoneIamMemberCondition:ZoneIamMemberCondition6
4
descriptionB" 

expression" 
title" :³
L
dataplexZoneResourceSpec.gcp:dataplex/ZoneResourceSpec:ZoneResourceSpecâ
ßÜ
locationType" ÇRequired. Immutable. The location type of the resources that are allowed to be attached to the assets within this zone. Possible values: LOCATION_TYPE_UNSPECIFIED, SINGLE_REGION, MULTI_REGION

- - -
:§
y
dataprocAutoscalingPolicyBasicAlgorithmLgcp:dataproc/AutoscalingPolicyBasicAlgorithm:AutoscalingPolicyBasicAlgorithm©
¦³
cooldownPeriodB" Duration between scaling events. A scaling period starts after the
update operation from the previous event has completed.
Bounds: [2m, 1d]. Default: 2m.
í

yarnConfig:

dataproc)AutoscalingPolicyBasicAlgorithmYarnConfig`gcp:dataproc/AutoscalingPolicyBasicAlgorithmYarnConfig:AutoscalingPolicyBasicAlgorithmYarnConfig?YARN autoscaling configuration.
Structure is documented below.
:Å

dataproc)AutoscalingPolicyBasicAlgorithmYarnConfig`gcp:dataproc/AutoscalingPolicyBasicAlgorithmYarnConfig:AutoscalingPolicyBasicAlgorithmYarnConfig¨
¥
gracefulDecommissionTimeout" õTimeout for YARN graceful decommissioning of Node Managers. Specifies the
duration to wait for jobs to complete before forcefully removing workers
(and potentially interrupting jobs). Only applicable to downscaling operations.
Bounds: [0s, 1d].

scaleDownFactor êFraction of average pending memory in the last cooldown period for which to
remove workers. A scale-down factor of 1 will result in scaling down so that there
is no available memory remaining after the update (more aggressive scaling).
A scale-down factor of 0 disables removing workers, which can be beneficial for
autoscaling a single job.
Bounds: [0.0, 1.0].

scaleDownMinWorkerFractionB àMinimum scale-down threshold as a fraction of total cluster size before scaling occurs.
For example, in a 20-worker cluster, a threshold of 0.1 means the autoscaler must
recommend at least a 2 worker scale-down for the cluster to scale. A threshold of 0
means the autoscaler will scale down on any recommended change.
Bounds: [0.0, 1.0]. Default: 0.0.
ù
scaleUpFactor ãFraction of average pending memory in the last cooldown period for which to
add workers. A scale-up factor of 1.0 will result in scaling up so that there
is no pending memory remaining after the update (more aggressive scaling).
A scale-up factor closer to 0 will result in a smaller magnitude of scaling up
(less aggressive scaling).
Bounds: [0.0, 1.0].
ý
scaleUpMinWorkerFractionB ÚMinimum scale-up threshold as a fraction of total cluster size before scaling
occurs. For example, in a 20-worker cluster, a threshold of 0.1 means the autoscaler
must recommend at least a 2-worker scale-up for the cluster to scale. A threshold of
0 means the autoscaler will scale up on any recommended change.
Bounds: [0.0, 1.0]. Default: 0.0.
:Ã

dataproc$AutoscalingPolicyIamBindingConditionVgcp:dataproc/AutoscalingPolicyIamBindingCondition:AutoscalingPolicyIamBindingCondition6
4
descriptionB" 

expression" 
title" :À

dataproc#AutoscalingPolicyIamMemberConditionTgcp:dataproc/AutoscalingPolicyIamMemberCondition:AutoscalingPolicyIamMemberCondition6
4
descriptionB" 

expression" 
title" :þ

dataproc&AutoscalingPolicySecondaryWorkerConfigZgcp:dataproc/AutoscalingPolicySecondaryWorkerConfig:AutoscalingPolicySecondaryWorkerConfigê

ç
õ
maxInstancesB ÞMaximum number of instances for this group. Note that by default, clusters will not use
secondary workers. Required for secondary workers if the minimum secondary instances is set.
Bounds: [minInstances, ). Defaults to 0.
l
minInstancesB VMinimum number of instances for this group. Bounds: [0, maxInstances]. Defaults to 0.
þ
weightB íWeight for the instance group, which is used to determine the fraction of total workers
in the cluster from this instance group. For example, if primary workers have weight 2,
and secondary workers have weight 1, the cluster will have approximately 2 primary workers
for each secondary worker.
The cluster may not reach the specified balance if constrained by min/max bounds or other
autoscaling settings. For example, if maxInstances for secondary workers is 0, then only
primary workers will be added. The cluster can also be out of balance when created.
If weight is not set on any instance group, the cluster will default to equal weight for
all groups: the cluster will attempt to maintain an equal number of workers in each group
within the configured size bounds for each group. If weight is set for one group only,
the cluster will default to zero weight on the unset group. For example if weight is set
only on primary workers, the cluster will use primary workers only and no secondary workers.
:¬

s
dataprocAutoscalingPolicyWorkerConfigHgcp:dataproc/AutoscalingPolicyWorkerConfig:AutoscalingPolicyWorkerConfig´	
±	@
maxInstances ,Maximum number of instances for this group.
l
minInstancesB VMinimum number of instances for this group. Bounds: [2, maxInstances]. Defaults to 2.
þ
weightB íWeight for the instance group, which is used to determine the fraction of total workers
in the cluster from this instance group. For example, if primary workers have weight 2,
and secondary workers have weight 1, the cluster will have approximately 2 primary workers
for each secondary worker.
The cluster may not reach the specified balance if constrained by min/max bounds or other
autoscaling settings. For example, if maxInstances for secondary workers is 0, then only
primary workers will be added. The cluster can also be out of balance when created.
If weight is not set on any instance group, the cluster will default to equal weight for
all groups: the cluster will attempt to maintain an equal number of workers in each group
within the configured size bounds for each group. If weight is set for one group only,
the cluster will default to zero weight on the unset group. For example if weight is set
only on primary workers, the cluster will use primary workers only and no secondary workers.
:å
^
dataprocBatchEnvironmentConfig:gcp:dataproc/BatchEnvironmentConfig:BatchEnvironmentConfig
ÿñ
executionConfigB:

dataproc%BatchEnvironmentConfigExecutionConfigXgcp:dataproc/BatchEnvironmentConfigExecutionConfig:BatchEnvironmentConfigExecutionConfigGExecution configuration for a workload.
Structure is documented below.

peripheralsConfigB:

dataproc'BatchEnvironmentConfigPeripheralsConfig\gcp:dataproc/BatchEnvironmentConfigPeripheralsConfig:BatchEnvironmentConfigPeripheralsConfigVPeripherals configuration that workload has access to.
Structure is documented below.
:

dataproc%BatchEnvironmentConfigExecutionConfigXgcp:dataproc/BatchEnvironmentConfigExecutionConfig:BatchEnvironmentConfigExecutionConfigô
ñ9
kmsKeyB" )The Cloud KMS key to use for encryption.
>
networkTagsB*" 'Tags used for network traffic control.
B

networkUriB" .Network configuration for workload execution.
G
serviceAccountB" /Service account that used to execute workload.
ÿ
stagingBucketB" çA Cloud Storage bucket used to stage workload dependencies, config files, and store
workload output and other ephemeral data, such as Spark history files. If you do not specify a staging bucket,
Cloud Dataproc will determine a Cloud Storage location according to the region where your workload is running,
and then create and manage project-level, per-location staging and temporary buckets.
This field requires a Cloud Storage bucket name, not a gs://... URI to a Cloud Storage bucket.
H
subnetworkUriB" 1Subnetwork configuration for workload execution.

ttlB" The duration after which the workload will be terminated.
When the workload exceeds this duration, it will be unconditionally terminated without waiting for ongoing
work to finish. If ttl is not specified for a batch workload, the workload will be allowed to run until it
exits naturally (or run forever without exiting). If ttl is not specified for an interactive session,
it defaults to 24 hours. If ttl is not specified for a batch that uses 2.1+ runtime version, it defaults to 4 hours.
Minimum value is 10 minutes; maximum value is 14 days. If both ttl and idleTtl are specified (for an interactive session),
the conditions are treated as OR conditions: the workload will be terminated when it has been idle for idleTtl or
when ttl has been exceeded, whichever occurs first.
:Ì

dataproc'BatchEnvironmentConfigPeripheralsConfig\gcp:dataproc/BatchEnvironmentConfigPeripheralsConfig:BatchEnvironmentConfigPeripheralsConfigµ
²S
metastoreServiceB" 9Resource name of an existing Dataproc Metastore service.
Ú
sparkHistoryServerConfigãBà:Ý
Ú
dataproc?BatchEnvironmentConfigPeripheralsConfigSparkHistoryServerConfiggcp:dataproc/BatchEnvironmentConfigPeripheralsConfigSparkHistoryServerConfig:BatchEnvironmentConfigPeripheralsConfigSparkHistoryServerConfigXThe Spark History Server configuration for the workload.
Structure is documented below.
:Ý
Ú
dataproc?BatchEnvironmentConfigPeripheralsConfigSparkHistoryServerConfiggcp:dataproc/BatchEnvironmentConfigPeripheralsConfigSparkHistoryServerConfig:BatchEnvironmentConfigPeripheralsConfigSparkHistoryServerConfig~
|z
dataprocClusterB" aResource name of an existing Dataproc Cluster to act as a Spark History Server for the workload.
:
O
dataprocBatchPysparkBatch0gcp:dataproc/BatchPysparkBatch:BatchPysparkBatch½
º¦
archiveUrisB*" HCFS URIs of archives to be extracted into the working directory of each executor.
Supported file types: .jar, .tar, .tar.gz, .tgz, and .zip.
Ë
argsB*" ºThe arguments to pass to the driver. Do not include arguments that can be set as batch
properties, such as --conf, since a collision can occur that causes an incorrect batch submission.
_
fileUrisB*" KHCFS URIs of files to be placed in the working directory of each executor.
e
jarFileUrisB*" NHCFS URIs of jar files to add to the classpath of the Spark driver and tasks.
p
mainPythonFileUriB" UThe HCFS URI of the main Python file to use as the Spark driver. Must be a .py file.

pythonFileUrisB*" lHCFS file URIs of Python files to pass to the PySpark framework.
Supported file types: .py, .egg, and .zip.
:
R
dataprocBatchRuntimeConfig2gcp:dataproc/BatchRuntimeConfig:BatchRuntimeConfig²
¯õ
autotuningConfigB:

dataproc"BatchRuntimeConfigAutotuningConfigRgcp:dataproc/BatchRuntimeConfigAutotuningConfig:BatchRuntimeConfigAutotuningConfigSOptional. Autotuning configuration of the workload.
Structure is documented below.
~
cohortB" nOptional. Cohort identifier. Identifies families of the workloads having the same shape, e.g. daily ETL jobs.

containerImageB" {Optional custom container image for the job runtime environment. If not specified, a default container image will be used.

effectivePropertiesB2" `(Output)
A mapping of property names to values, which are used to configure workload execution.
m

propertiesB2" WA mapping of property names to values, which are used to configure workload execution.
/
versionB" Version of the batch runtime.
:

dataproc"BatchRuntimeConfigAutotuningConfigRgcp:dataproc/BatchRuntimeConfigAutotuningConfig:BatchRuntimeConfigAutotuningConfig

	scenariosB*" yOptional. Scenarios for which tunings are applied.
Each value may be one of: `SCALING`, `BROADCAST_HASH_JOIN`, `MEMORY`.
:¹
L
dataprocBatchRuntimeInfo.gcp:dataproc/BatchRuntimeInfo:BatchRuntimeInfoè
åì
approximateUsagesB*:~
|
dataproc BatchRuntimeInfoApproximateUsageNgcp:dataproc/BatchRuntimeInfoApproximateUsage:BatchRuntimeInfoApproximateUsageÍ(Output)
Approximate workload resource usage, calculated when the workload completes(see [Dataproc Serverless pricing](https://cloud.google.com/dataproc-serverless/pricing))
Structure is documented below.
¹
currentUsagesxBv*t:r
p
dataprocBatchRuntimeInfoCurrentUsageFgcp:dataproc/BatchRuntimeInfoCurrentUsage:BatchRuntimeInfoCurrentUsage­(Output)
Snapshot of current workload resource usage(see [Dataproc Serverless pricing](https://cloud.google.com/dataproc-serverless/pricing))
Structure is documented below.
a
diagnosticOutputUriB" D(Output)
A URI pointing to the location of the diagnostics tarball.
n
	endpointsB2" Y(Output)
Map of remote access endpoints (such as web interfaces and APIs) to their URIs.
e
	outputUriB" R(Output)
A URI pointing to the location of the stdout and stderr of the workload.
:Þ
|
dataproc BatchRuntimeInfoApproximateUsageNgcp:dataproc/BatchRuntimeInfoApproximateUsage:BatchRuntimeInfoApproximateUsageÝ
ÚG
acceleratorTypeB" .(Output)
Accelerator type being used, if any.
\
milliAcceleratorSecondsB" ;(Output)
Accelerator usage in (milliAccelerator x seconds)
]
milliDcuSecondsB" D(Output)
DCU (Dataproc Compute Units) usage in (milliDCU x seconds)
R
shuffleStorageGbSecondsB" 1(Output)
Shuffle storage usage in (GB x seconds)
:Å
p
dataprocBatchRuntimeInfoCurrentUsageFgcp:dataproc/BatchRuntimeInfoCurrentUsage:BatchRuntimeInfoCurrentUsageÐ
ÍG
acceleratorTypeB" .(Output)
Accelerator type being used, if any.
H
milliAcceleratorB" .(Output)
Milli (one-thousandth) accelerator..
Q
milliDcuB" ?(Output)
Milli (one-thousandth) Dataproc Compute Units (DCUs).
p
milliDcuPremiumB" W(Output)
Milli (one-thousandth) Dataproc Compute Units (DCUs) charged at premium tier.
F
shuffleStorageGbB" ,(Output)
Shuffle Storage in gigabytes (GB).
e
shuffleStorageGbPremiumB" D(Output)
Shuffle Storage in gigabytes (GB) charged at premium tier.
D
snapshotTimeB" .(Output)
The timestamp of the usage snapshot.
:ù
I
dataprocBatchSparkBatch,gcp:dataproc/BatchSparkBatch:BatchSparkBatch«
¨¦
archiveUrisB*" HCFS URIs of archives to be extracted into the working directory of each executor.
Supported file types: .jar, .tar, .tar.gz, .tgz, and .zip.
Ë
argsB*" ºThe arguments to pass to the driver. Do not include arguments that can be set as batch
properties, such as --conf, since a collision can occur that causes an incorrect batch submission.
_
fileUrisB*" KHCFS URIs of files to be placed in the working directory of each executor.
e
jarFileUrisB*" NHCFS URIs of jar files to add to the classpath of the Spark driver and tasks.

	mainClassB" ~The name of the driver main class. The jar file that contains the class must be in the
classpath or specified in jarFileUris.
S
mainJarFileUriB" ;The HCFS URI of the jar file that contains the main class.
:
L
dataprocBatchSparkRBatch.gcp:dataproc/BatchSparkRBatch:BatchSparkRBatchÂ
¿¦
archiveUrisB*" HCFS URIs of archives to be extracted into the working directory of each executor.
Supported file types: .jar, .tar, .tar.gz, .tgz, and .zip.
Ë
argsB*" ºThe arguments to pass to the driver. Do not include arguments that can be set as batch
properties, such as --conf, since a collision can occur that causes an incorrect batch submission.
_
fileUrisB*" KHCFS URIs of files to be placed in the working directory of each executor.
e
mainRFileUriB" OThe HCFS URI of the main R file to use as the driver. Must be a .R or .r file.
:
R
dataprocBatchSparkSqlBatch2gcp:dataproc/BatchSparkSqlBatch:BatchSparkSqlBatch¶
³R
jarFileUrisB*" ;HCFS URIs of jar files to be added to the Spark CLASSPATH.
]
queryFileUriB" GThe HCFS URI of the script that contains Spark SQL queries to execute.
~
queryVariablesB2" dMapping of query variable names to values (equivalent to the Spark SQL command: SET name="value";).
:è
O
dataprocBatchStateHistory0gcp:dataproc/BatchStateHistory:BatchStateHistory
â
stateB" Ò(Output)
The state of the batch at this point in history. For possible values, see the [API documentation](https://cloud.google.com/dataproc-serverless/docs/reference/rest/v1/projects.locations.batches#State).
Q
stateMessageB" ;(Output)
Details about the state at this point in history.
W
stateStartTimeB" ?(Output)
The time when the batch entered the historical state.
:»)
X
dataprocClusterClusterConfig6gcp:dataproc/ClusterClusterConfig:ClusterClusterConfigÞ(
Û(³
autoscalingConfigB:

dataproc%ClusterClusterConfigAutoscalingConfigXgcp:dataproc/ClusterClusterConfigAutoscalingConfig:ClusterClusterConfigAutoscalingConfigThe autoscaling policy config associated with the cluster.
Note that once set, if `autoscaling_config` is the only field set in `cluster_config`, it can
only be removed by setting `policy_uri = ""`, rather than removing the whole block.
Structure defined below.
°
auxiliaryNodeGroupsB*:

dataproc&ClusterClusterConfigAuxiliaryNodeGroupZgcp:dataproc/ClusterClusterConfigAuxiliaryNodeGroup:ClusterClusterConfigAuxiliaryNodeGroup|A Dataproc NodeGroup resource is a group of Dataproc cluster nodes that execute an assigned role. 
Structure defined below.
Ý
bucketB" ÌThe name of the cloud storage bucket ultimately used to house the staging data
for the cluster. If `staging_bucket` is specified, it will contain this value, otherwise
it will be the auto generated name.
»
dataprocMetricConfigB:

dataproc(ClusterClusterConfigDataprocMetricConfig^gcp:dataproc/ClusterClusterConfigDataprocMetricConfig:ClusterClusterConfigDataprocMetricConfigThe Compute Engine accelerator (GPU) configuration for these instances. Can be specified multiple times.
Structure defined below.

encryptionConfigB:

dataproc$ClusterClusterConfigEncryptionConfigVgcp:dataproc/ClusterClusterConfigEncryptionConfig:ClusterClusterConfigEncryptionConfigXThe Customer managed encryption keys settings for the cluster.
Structure defined below.
í
endpointConfigB:

dataproc"ClusterClusterConfigEndpointConfigRgcp:dataproc/ClusterClusterConfigEndpointConfig:ClusterClusterConfigEndpointConfigMThe config settings for port access on the cluster.
Structure defined below.
¿
gceClusterConfigB:

dataproc$ClusterClusterConfigGceClusterConfigVgcp:dataproc/ClusterClusterConfigGceClusterConfig:ClusterClusterConfigGceClusterConfigCommon config settings for resources of Google Compute Engine cluster
instances, applicable to all instances in the cluster. Structure defined below.
¾
initializationActions B*:

dataproc(ClusterClusterConfigInitializationAction^gcp:dataproc/ClusterClusterConfigInitializationAction:ClusterClusterConfigInitializationActionCommands to execute on each node after config is completed.
You can specify multiple versions of these. Structure defined below.
î
lifecycleConfigB:

dataproc#ClusterClusterConfigLifecycleConfigTgcp:dataproc/ClusterClusterConfigLifecycleConfig:ClusterClusterConfigLifecycleConfigJThe settings for auto deletion cluster schedule.
Structure defined below.

masterConfigB:~
|
dataproc ClusterClusterConfigMasterConfigNgcp:dataproc/ClusterClusterConfigMasterConfig:ClusterClusterConfigMasterConfigjThe Google Compute Engine config settings for the master instances
in a cluster. Structure defined below.
þ
metastoreConfigB:

dataproc#ClusterClusterConfigMetastoreConfigTgcp:dataproc/ClusterClusterConfigMetastoreConfig:ClusterClusterConfigMetastoreConfigZThe config setting for metastore service with the cluster.
Structure defined below.
- - -
Ö
preemptibleWorkerConfig¦B£: 

dataproc+ClusterClusterConfigPreemptibleWorkerConfigdgcp:dataproc/ClusterClusterConfigPreemptibleWorkerConfig:ClusterClusterConfigPreemptibleWorkerConfigThe Google Compute Engine config settings for the additional
instances in a cluster. Structure defined below.
* **NOTE** : `preemptible_worker_config` is
an alias for the api's [secondaryWorkerConfig](https://cloud.google.com/dataproc/docs/reference/rest/v1/ClusterConfig#InstanceGroupConfig). The name doesn't necessarily mean it is preemptible and is named as
such for legacy/compatibility reasons.
Ù
securityConfigB:

dataproc"ClusterClusterConfigSecurityConfigRgcp:dataproc/ClusterClusterConfigSecurityConfig:ClusterClusterConfigSecurityConfig9Security related configuration. Structure defined below.
î
softwareConfigB:

dataproc"ClusterClusterConfigSoftwareConfigRgcp:dataproc/ClusterClusterConfigSoftwareConfig:ClusterClusterConfigSoftwareConfigNThe config settings for software inside the cluster.
Structure defined below.
Ç
stagingBucketB" ¯The Cloud Storage staging bucket used to stage files,
such as Hadoop jars, between client machines and the cluster.
Note: If you don't explicitly specify a `staging_bucket`
then GCP will auto create / assign one for you. However, you are not guaranteed
an auto generated bucket which is solely dedicated to your cluster; it may be shared
with other clusters in the same region/zone also choosing to use the auto generation
option.
ó

tempBucketB" ÞThe Cloud Storage temp bucket used to store ephemeral cluster
and jobs data, such as Spark and MapReduce history files.
Note: If you don't explicitly specify a `temp_bucket` then GCP will auto create / assign one for you.

workerConfigB:~
|
dataproc ClusterClusterConfigWorkerConfigNgcp:dataproc/ClusterClusterConfigWorkerConfig:ClusterClusterConfigWorkerConfigjThe Google Compute Engine config settings for the worker instances
in a cluster. Structure defined below.
:É

dataproc%ClusterClusterConfigAutoscalingConfigXgcp:dataproc/ClusterClusterConfigAutoscalingConfig:ClusterClusterConfigAutoscalingConfig¸
µ²
	policyUri"  The autoscaling policy used by the cluster.

Only resource names including projectid and location (region) are valid. Examples:

`https://www.googleapis.com/compute/v1/projects/[projectId]/locations/[dataproc_region]/autoscalingPolicies/[policy_id]`
`projects/[projectId]/locations/[dataproc_region]/autoscalingPolicies/[policy_id]`
Note that the policy must be in the same project and Cloud Dataproc region.

- - -
:ó

dataproc&ClusterClusterConfigAuxiliaryNodeGroupZgcp:dataproc/ClusterClusterConfigAuxiliaryNodeGroup:ClusterClusterConfigAuxiliaryNodeGroupß
Üù
nodeGroupIdB" ãA node group ID. Generated if not specified. The ID must contain only letters (a-z, A-Z), numbers (0-9), underscores (_), and hyphens (-). Cannot begin or end with underscore or hyphen. Must consist of from 3 to 33 characters.
Ý

nodeGroups²*¯:¬
©
dataproc/ClusterClusterConfigAuxiliaryNodeGroupNodeGrouplgcp:dataproc/ClusterClusterConfigAuxiliaryNodeGroupNodeGroup:ClusterClusterConfigAuxiliaryNodeGroupNodeGroupNode group configuration.
:½
©
dataproc/ClusterClusterConfigAuxiliaryNodeGroupNodeGrouplgcp:dataproc/ClusterClusterConfigAuxiliaryNodeGroupNodeGroup:ClusterClusterConfigAuxiliaryNodeGroupNodeGroup
,
nameB" The Node group resource name.
£
nodeGroupConfigàBÝ:Ú
×
dataproc>ClusterClusterConfigAuxiliaryNodeGroupNodeGroupNodeGroupConfiggcp:dataproc/ClusterClusterConfigAuxiliaryNodeGroupNodeGroupNodeGroupConfig:ClusterClusterConfigAuxiliaryNodeGroupNodeGroupNodeGroupConfig-The node group instance group configuration.
5
roles*" &Node group roles. 
One of `"DRIVER"`.
:²
×
dataproc>ClusterClusterConfigAuxiliaryNodeGroupNodeGroupNodeGroupConfiggcp:dataproc/ClusterClusterConfigAuxiliaryNodeGroupNodeGroupNodeGroupConfig:ClusterClusterConfigAuxiliaryNodeGroupNodeGroupNodeGroupConfigÕ
Ò
acceleratorsB*þ:û
ø
dataprocIClusterClusterConfigAuxiliaryNodeGroupNodeGroupNodeGroupConfigAccelerator gcp:dataproc/ClusterClusterConfigAuxiliaryNodeGroupNodeGroupNodeGroupConfigAccelerator:ClusterClusterConfigAuxiliaryNodeGroupNodeGroupNodeGroupConfigAcceleratorjThe Compute Engine accelerator (GPU) configuration for these instances. Can be specified 
multiple times.


diskConfigþBû:ø
õ
dataprocHClusterClusterConfigAuxiliaryNodeGroupNodeGroupNodeGroupConfigDiskConfiggcp:dataproc/ClusterClusterConfigAuxiliaryNodeGroupNodeGroupNodeGroupConfigDiskConfig:ClusterClusterConfigAuxiliaryNodeGroupNodeGroupNodeGroupConfigDiskConfigDisk Config
n
instanceNamesB*" UList of auxiliary node group instance names which have been assigned to the cluster.
Ç
machineTypeB" ±The name of a Google Compute Engine machine type
to create for the node group. If not specified, GCP will default to a predetermined
computed value (currently `n1-standard-4`).
Ü
minCpuPlatformB" ÃThe name of a minimum generation of CPU family
for the node group. If not specified, GCP will default to a predetermined computed value
for each zone. See [the guide](https://cloud.google.com/compute/docs/instances/specify-min-cpu-platform)
for details about which CPU families are available (and defaulted) for each zone.

numInstancesB ~Specifies the number of master nodes to create.
Please set a number greater than 0. Node Group must have at least 1 instance.
:
ø
dataprocIClusterClusterConfigAuxiliaryNodeGroupNodeGroupNodeGroupConfigAccelerator gcp:dataproc/ClusterClusterConfigAuxiliaryNodeGroupNodeGroupNodeGroupConfigAccelerator:ClusterClusterConfigAuxiliaryNodeGroupNodeGroupNodeGroupConfigAccelerator¡

acceleratorCount The number of the accelerator cards of this type exposed to this instance. Often restricted to one of `1`, `2`, `4`, or `8`.


- - -
{
acceleratorType" dThe short name of the accelerator type to expose to this instance. For example, `nvidia-tesla-k80`.
:»
õ
dataprocHClusterClusterConfigAuxiliaryNodeGroupNodeGroupNodeGroupConfigDiskConfiggcp:dataproc/ClusterClusterConfigAuxiliaryNodeGroupNodeGroupNodeGroupConfigDiskConfig:ClusterClusterConfigAuxiliaryNodeGroupNodeGroupNodeGroupConfigDiskConfigÀ
½ý
bootDiskSizeGbB äSize of the primary disk attached to each node, specified
in GB. The primary disk contains the boot volume and system libraries, and the
smallest allowed disk size is 10GB. GCP will default to a predetermined
computed value if not set (currently 500GB). Note: If SSDs are not
attached, it also contains the HDFS data blocks and Hadoop working directories.

bootDiskTypeB" |The disk type of the primary disk attached to each node.
One of `"pd-ssd"` or `"pd-standard"`. Defaults to `"pd-standard"`.
¬
localSsdInterfaceB" Interface type of local SSDs (default is "scsi"). Valid values: "scsi" (Small Computer System Interface), "nvme" (Non-Volatile Memory Express).
w
numLocalSsdsB aThe amount of local SSD disks that will be attached to each master cluster node. 
Defaults to 0.
:ø

dataproc(ClusterClusterConfigDataprocMetricConfig^gcp:dataproc/ClusterClusterConfigDataprocMetricConfig:ClusterClusterConfigDataprocMetricConfigÞ
ÛØ
metrics¯*¬:©
¦
dataproc.ClusterClusterConfigDataprocMetricConfigMetricjgcp:dataproc/ClusterClusterConfigDataprocMetricConfigMetric:ClusterClusterConfigDataprocMetricConfigMetricMetrics sources to enable.
:¨
¦
dataproc.ClusterClusterConfigDataprocMetricConfigMetricjgcp:dataproc/ClusterClusterConfigDataprocMetricConfigMetric:ClusterClusterConfigDataprocMetricConfigMetricü
ùº
metricOverridesB*" One or more [available OSS metrics] (https://cloud.google.com/dataproc/docs/guides/monitoring#available_oss_metrics) to collect for the metric course.

- - -
¹
metricSource" ¤A source for the collection of Dataproc OSS metrics (see [available OSS metrics](https://cloud.google.com//dataproc/docs/guides/monitoring#available_oss_metrics)).
:

dataproc$ClusterClusterConfigEncryptionConfigVgcp:dataproc/ClusterClusterConfigEncryptionConfig:ClusterClusterConfigEncryptionConfigt
rp

kmsKeyName" ^The Cloud KMS key name to use for PD disk encryption for
all instances in the cluster.

- - -
:§

dataproc"ClusterClusterConfigEndpointConfigRgcp:dataproc/ClusterClusterConfigEndpointConfig:ClusterClusterConfigEndpointConfig

enableHttpPortAccess
 The flag to enable http access to specific ports
on the cluster from external sources (aka Component Gateway). Defaults to false.
x
	httpPortsB2" cThe map of port descriptions to URLs. Will only be populated if
`enable_http_port_access` is true.
:£

dataproc$ClusterClusterConfigGceClusterConfigVgcp:dataproc/ClusterClusterConfigGceClusterConfig:ClusterClusterConfigGceClusterConfig
 
confidentialInstanceConfigàBÝ:Ú
×
dataproc>ClusterClusterConfigGceClusterConfigConfidentialInstanceConfiggcp:dataproc/ClusterClusterConfigGceClusterConfigConfidentialInstanceConfig:ClusterClusterConfigGceClusterConfigConfidentialInstanceConfigConfidential Instance Config for clusters using [Confidential VMs](https://cloud.google.com/dataproc/docs/concepts/configuring-clusters/confidential-compute)

internalIpOnlyB
 êBy default, clusters are not restricted to internal IP addresses,
and will have ephemeral external IP addresses assigned to each instance. If set to true, all
instances in the cluster will only have internal IP addresses. Note: Private Google Access
(also known as `privateIpGoogleAccess`) must be enabled on the subnetwork that the cluster
will be launched in.
â
metadataB2" ÍA map of the Compute Engine metadata entries to add to all instances
(see [Project and instance metadata](https://cloud.google.com/compute/docs/storing-retrieving-metadata#project_and_instance_metadata)).
Ë
networkB" ¹The name or self_link of the Google Compute Engine
network to the cluster will be part of. Conflicts with `subnetwork`.
If neither is specified, this defaults to the "default" network.

nodeGroupAffinityÄBÁ:¾
»
dataproc5ClusterClusterConfigGceClusterConfigNodeGroupAffinityxgcp:dataproc/ClusterClusterConfigGceClusterConfigNodeGroupAffinity:ClusterClusterConfigGceClusterConfigNodeGroupAffinity.Node Group Affinity for sole-tenant clusters.

reservationAffinityÊBÇ:Ä
Á
dataproc7ClusterClusterConfigGceClusterConfigReservationAffinity|gcp:dataproc/ClusterClusterConfigGceClusterConfigReservationAffinity:ClusterClusterConfigGceClusterConfigReservationAffinity6Reservation Affinity for consuming zonal reservation.

serviceAccountB" iThe service account to be used by the Node VMs.
If not specified, the "default" service account is used.

serviceAccountScopesB*" ðThe set of Google API scopes
to be made available on all of the node VMs under the `service_account`
specified. Both OAuth2 URLs and gcloud
short names are supported. To allow full access to all Cloud APIs, use the
`cloud-platform` scope. See a complete list of scopes [here](https://cloud.google.com/sdk/gcloud/reference/alpha/compute/instances/set-scopes#--scopes).

shieldedInstanceConfigÔBÑ:Î
Ë
dataproc:ClusterClusterConfigGceClusterConfigShieldedInstanceConfiggcp:dataproc/ClusterClusterConfigGceClusterConfigShieldedInstanceConfig:ClusterClusterConfigGceClusterConfigShieldedInstanceConfigShielded Instance Config for clusters using [Compute Engine Shielded VMs](https://cloud.google.com/security/shielded-cloud/shielded-vm).

- - -


subnetworkB" uThe name or self_link of the Google Compute Engine
subnetwork the cluster will be part of. Conflicts with `network`.

tagsB*" The list of instance tags applied to instances in the cluster.
Tags are used to identify valid sources or targets for network firewalls.
Ã
zoneB" ´The GCP zone where your data is stored and used (i.e. where
the master and the worker nodes will be created in). If `region` is set to 'global' (default)
then `zone` is mandatory, otherwise GCP is able to make use of [Auto Zone Placement](https://cloud.google.com/dataproc/docs/concepts/auto-zone)
to determine this automatically for you.
Note: This setting additionally determines and restricts
which computing resources are available for use with other configs such as
`cluster_config.master_config.machine_type` and `cluster_config.worker_config.machine_type`.
:Ê
×
dataproc>ClusterClusterConfigGceClusterConfigConfidentialInstanceConfiggcp:dataproc/ClusterClusterConfigGceClusterConfigConfidentialInstanceConfig:ClusterClusterConfigGceClusterConfigConfidentialInstanceConfign
lj
enableConfidentialComputeB
 GDefines whether the instance should have confidential compute enabled.
:ª
»
dataproc5ClusterClusterConfigGceClusterConfigNodeGroupAffinityxgcp:dataproc/ClusterClusterConfigGceClusterConfigNodeGroupAffinity:ClusterClusterConfigGceClusterConfigNodeGroupAffinityj
hf
nodeGroupUri" RThe URI of a sole-tenant node group resource that the cluster will be created on.
:²
Á
dataproc7ClusterClusterConfigGceClusterConfigReservationAffinity|gcp:dataproc/ClusterClusterConfigGceClusterConfigReservationAffinity:ClusterClusterConfigGceClusterConfigReservationAffinityë
èT
consumeReservationTypeB" 4Corresponds to the type of reservation consumption.
C
keyB" 6Corresponds to the label key of reservation resource.
K
valuesB*" 9Corresponds to the label values of reservation resource.
:
Ë
dataproc:ClusterClusterConfigGceClusterConfigShieldedInstanceConfiggcp:dataproc/ClusterClusterConfigGceClusterConfigShieldedInstanceConfig:ClusterClusterConfigGceClusterConfigShieldedInstanceConfigÉ
Æg
enableIntegrityMonitoringB
 DDefines whether instances have integrity monitoring enabled.

- - -
N
enableSecureBootB
 4Defines whether instances have Secure Boot enabled.


enableVtpmB
 vDefines whether instances have the [vTPM](https://cloud.google.com/security/shielded-cloud/shielded-vm#vtpm) enabled.
:ê

dataproc(ClusterClusterConfigInitializationAction^gcp:dataproc/ClusterClusterConfigInitializationAction:ClusterClusterConfigInitializationActionÐ
Í
script" sThe script to be executed during initialization of the cluster.
The script must be a GCS file with a gs:// prefix.
Æ

timeoutSecB ±The maximum duration (in seconds) which `script` is
allowed to take to execute its action. GCP will default to a predetermined
computed value if not set (currently 300).

- - -
:ü

dataproc#ClusterClusterConfigLifecycleConfigTgcp:dataproc/ClusterClusterConfigLifecycleConfig:ClusterClusterConfigLifecycleConfigñ
îº
autoDeleteTimeB" ¡The time when cluster will be auto-deleted.
A timestamp in RFC3339 UTC "Zulu" format, accurate to nanoseconds.
Example: "2014-10-02T15:01:23.045123456Z".

- - -
¥
idleDeleteTtlB" The duration to keep the cluster alive while idling
(no jobs running). After this TTL, the cluster will be deleted. Valid range: [10m, 14d].

idleStartTimeB" oTime when the cluster became idle
(most recent job finished) and became eligible for deletion due to idleness.
:º
|
dataproc ClusterClusterConfigMasterConfigNgcp:dataproc/ClusterClusterConfigMasterConfig:ClusterClusterConfigMasterConfig¹
¶¥
accelerators©B¦*£: 

dataproc+ClusterClusterConfigMasterConfigAcceleratordgcp:dataproc/ClusterClusterConfigMasterConfigAccelerator:ClusterClusterConfigMasterConfigAcceleratoriThe Compute Engine accelerator (GPU) configuration for these instances. Can be specified multiple times.
À

diskConfig£B :

dataproc*ClusterClusterConfigMasterConfigDiskConfigbgcp:dataproc/ClusterClusterConfigMasterConfigDiskConfig:ClusterClusterConfigMasterConfigDiskConfigDisk Config
§
imageUriB" The URI for the image to use for this worker.  See [the guide](https://cloud.google.com/dataproc/docs/guides/dataproc-images)
for more information.
`
instanceNamesB*" GList of master instance names which
have been assigned to the cluster.
Ã
machineTypeB" ­The name of a Google Compute Engine machine type
to create for the master. If not specified, GCP will default to a predetermined
computed value (currently `n1-standard-4`).
Ø
minCpuPlatformB" ¿The name of a minimum generation of CPU family
for the master. If not specified, GCP will default to a predetermined computed value
for each zone. See [the guide](https://cloud.google.com/compute/docs/instances/specify-min-cpu-platform)
for details about which CPU families are available (and defaulted) for each zone.

numInstancesB Specifies the number of master nodes to create.
If not specified, GCP will default to a predetermined computed value (currently 1).
:´

dataproc+ClusterClusterConfigMasterConfigAcceleratordgcp:dataproc/ClusterClusterConfigMasterConfigAccelerator:ClusterClusterConfigMasterConfigAccelerator

acceleratorCount õThe number of the accelerator cards of this type exposed to this instance. Often restricted to one of `1`, `2`, `4`, or `8`.

> The Cloud Dataproc API can return unintuitive error messages when using accelerators; even when you have defined an accelerator, Auto Zone Placement does not exclusively select
zones that have that accelerator available. If you get a 400 error that the accelerator can't be found, this is a likely cause. Make sure you check [accelerator availability by zone](https://cloud.google.com/compute/docs/reference/rest/v1/acceleratorTypes/list)
if you are trying to use accelerators in a given zone.

- - -
{
acceleratorType" dThe short name of the accelerator type to expose to this instance. For example, `nvidia-tesla-k80`.
:É

dataproc*ClusterClusterConfigMasterConfigDiskConfigbgcp:dataproc/ClusterClusterConfigMasterConfigDiskConfig:ClusterClusterConfigMasterConfigDiskConfig©
¦ý
bootDiskSizeGbB äSize of the primary disk attached to each node, specified
in GB. The primary disk contains the boot volume and system libraries, and the
smallest allowed disk size is 10GB. GCP will default to a predetermined
computed value if not set (currently 500GB). Note: If SSDs are not
attached, it also contains the HDFS data blocks and Hadoop working directories.

bootDiskTypeB" |The disk type of the primary disk attached to each node.
One of `"pd-ssd"` or `"pd-standard"`. Defaults to `"pd-standard"`.

localSsdInterfaceB" úOptional. Interface type of local SSDs (default is "scsi").
Valid values: "scsi" (Small Computer System Interface), "nvme" (Non-Volatile
Memory Express). See
[local SSD performance](https://cloud.google.com/compute/docs/disks/local-ssd#performance).
v
numLocalSsdsB `The amount of local SSD disks that will be
attached to each master cluster node. Defaults to 0.
:

dataproc#ClusterClusterConfigMetastoreConfigTgcp:dataproc/ClusterClusterConfigMetastoreConfig:ClusterClusterConfigMetastoreConfig
ýú
dataprocMetastoreService" ÙResource name of an existing Dataproc Metastore service.

Only resource names including projectid and location (region) are valid. Examples:

`projects/[projectId]/locations/[dataproc_region]/services/[service-name]`
:ÿ

dataproc+ClusterClusterConfigPreemptibleWorkerConfigdgcp:dataproc/ClusterClusterConfigPreemptibleWorkerConfig:ClusterClusterConfigPreemptibleWorkerConfigÜ
Ùá

diskConfigÄBÁ:¾
»
dataproc5ClusterClusterConfigPreemptibleWorkerConfigDiskConfigxgcp:dataproc/ClusterClusterConfigPreemptibleWorkerConfigDiskConfig:ClusterClusterConfigPreemptibleWorkerConfigDiskConfigDisk Config
ç
instanceFlexibilityPolicyòBï:ì
é
dataprocDClusterClusterConfigPreemptibleWorkerConfigInstanceFlexibilityPolicygcp:dataproc/ClusterClusterConfigPreemptibleWorkerConfigInstanceFlexibilityPolicy:ClusterClusterConfigPreemptibleWorkerConfigInstanceFlexibilityPolicyUInstance flexibility Policy allowing a mixture of VM shapes and provisioning models.
e
instanceNamesB*" LList of preemptible instance names which have been assigned
to the cluster.
Z
numInstancesB DSpecifies the number of preemptible nodes to create.
Defaults to 0.
Å
preemptibilityB" ¬Specifies the preemptibility of the secondary workers. The default value is `PREEMPTIBLE`
Accepted values are:
* PREEMPTIBILITY_UNSPECIFIED
* NON_PREEMPTIBLE
* PREEMPTIBLE
:ç
»
dataproc5ClusterClusterConfigPreemptibleWorkerConfigDiskConfigxgcp:dataproc/ClusterClusterConfigPreemptibleWorkerConfigDiskConfig:ClusterClusterConfigPreemptibleWorkerConfigDiskConfig¦
£Ì
bootDiskSizeGbB ³Size of the primary disk attached to each preemptible worker node, specified
in GB. The smallest allowed disk size is 10GB. GCP will default to a predetermined
computed value if not set (currently 500GB). Note: If SSDs are not
attached, it also contains the HDFS data blocks and Hadoop working directories.
¦
bootDiskTypeB" The disk type of the primary disk attached to each preemptible worker node.
One of `"pd-ssd"` or `"pd-standard"`. Defaults to `"pd-standard"`.
¬
localSsdInterfaceB" Interface type of local SSDs (default is "scsi"). Valid values: "scsi" (Small Computer System Interface), "nvme" (Non-Volatile Memory Express).
z
numLocalSsdsB dThe amount of local SSD disks that will be
attached to each preemptible worker node. Defaults to 0.
:Á
é
dataprocDClusterClusterConfigPreemptibleWorkerConfigInstanceFlexibilityPolicygcp:dataproc/ClusterClusterConfigPreemptibleWorkerConfigInstanceFlexibilityPolicy:ClusterClusterConfigPreemptibleWorkerConfigInstanceFlexibilityPolicyÒ	
Ï	£
instanceSelectionLists´B±*®:«
¨
dataprocYClusterClusterConfigPreemptibleWorkerConfigInstanceFlexibilityPolicyInstanceSelectionListÀgcp:dataproc/ClusterClusterConfigPreemptibleWorkerConfigInstanceFlexibilityPolicyInstanceSelectionList:ClusterClusterConfigPreemptibleWorkerConfigInstanceFlexibilityPolicyInstanceSelectionListRList of instance selection options that the group will use when creating new VMs.

instanceSelectionResultsºB·*´:±
®
dataproc[ClusterClusterConfigPreemptibleWorkerConfigInstanceFlexibilityPolicyInstanceSelectionResultÄgcp:dataproc/ClusterClusterConfigPreemptibleWorkerConfigInstanceFlexibilityPolicyInstanceSelectionResult:ClusterClusterConfigPreemptibleWorkerConfigInstanceFlexibilityPolicyInstanceSelectionResult3A list of instance selection results in the group.

provisioningModelMix®B«:¨
¥
dataprocXClusterClusterConfigPreemptibleWorkerConfigInstanceFlexibilityPolicyProvisioningModelMix¾gcp:dataproc/ClusterClusterConfigPreemptibleWorkerConfigInstanceFlexibilityPolicyProvisioningModelMix:ClusterClusterConfigPreemptibleWorkerConfigInstanceFlexibilityPolicyProvisioningModelMixNDefines how Dataproc should create VMs with a mixture of provisioning models.
:Á
¨
dataprocYClusterClusterConfigPreemptibleWorkerConfigInstanceFlexibilityPolicyInstanceSelectionListÀgcp:dataproc/ClusterClusterConfigPreemptibleWorkerConfigInstanceFlexibilityPolicyInstanceSelectionList:ClusterClusterConfigPreemptibleWorkerConfigInstanceFlexibilityPolicyInstanceSelectionList
J
machineTypesB*" 2Full machine-type names, e.g. `"n1-standard-16"`.
Á
rankB ²Preference of this instance selection. A lower number means higher preference. Dataproc will first try to create a VM based on the machine-type with priority rank and fallback to next rank based on availability. Machine types and instance selections with the same priority have the same preference.

- - -
:Á
®
dataproc[ClusterClusterConfigPreemptibleWorkerConfigInstanceFlexibilityPolicyInstanceSelectionResultÄgcp:dataproc/ClusterClusterConfigPreemptibleWorkerConfigInstanceFlexibilityPolicyInstanceSelectionResult:ClusterClusterConfigPreemptibleWorkerConfigInstanceFlexibilityPolicyInstanceSelectionResult
E
machineTypeB" 0Full machine-type names, e.g. "n1-standard-16".
A
vmCountB 0Number of VM provisioned with the machine_type.
:à
¥
dataprocXClusterClusterConfigPreemptibleWorkerConfigInstanceFlexibilityPolicyProvisioningModelMix¾gcp:dataproc/ClusterClusterConfigPreemptibleWorkerConfigInstanceFlexibilityPolicyProvisioningModelMix:ClusterClusterConfigPreemptibleWorkerConfigInstanceFlexibilityPolicyProvisioningModelMixµ
²
standardCapacityBaseB yThe base capacity that will always use Standard VMs to avoid risk of more preemption than the minimum capacity you need.

 standardCapacityPercentAboveBaseB kThe percentage of target capacity that should use Standard VM. The remaining percentage will use Spot VMs.
:ì

dataproc"ClusterClusterConfigSecurityConfigRgcp:dataproc/ClusterClusterConfigSecurityConfig:ClusterClusterConfigSecurityConfigä
áÞ
kerberosConfig²:¯
¬
dataproc0ClusterClusterConfigSecurityConfigKerberosConfigngcp:dataproc/ClusterClusterConfigSecurityConfigKerberosConfig:ClusterClusterConfigSecurityConfigKerberosConfigKerberos Configuration
:´
¬
dataproc0ClusterClusterConfigSecurityConfigKerberosConfigngcp:dataproc/ClusterClusterConfigSecurityConfigKerberosConfig:ClusterClusterConfigSecurityConfigKerberosConfig
ÿ
crossRealmTrustAdminServerB" dThe admin server (IP or hostname) for the
remote trusted realm in a cross realm trust relationship.
w
crossRealmTrustKdcB" [The KDC (IP or hostname) for the
remote trusted realm in a cross realm trust relationship.

crossRealmTrustRealmB" cThe remote realm the Dataproc on-cluster KDC will
trust, should the user enable cross realm trust.
á
 crossRealmTrustSharedPasswordUriB" ¶The Cloud Storage URI of a KMS
encrypted file containing the shared password between the on-cluster Kerberos realm
and the remote trusted realm, in a cross realm trust relationship.
K
enableKerberosB
 3Flag to indicate whether to Kerberize the cluster.
r
kdcDbKeyUriB" ]The Cloud Storage URI of a KMS encrypted file containing
the master key of the KDC database.
Â
keyPasswordUriB" ©The Cloud Storage URI of a KMS encrypted file containing
the password to the user provided key. For the self-signed certificate, this password
is generated by Dataproc.
Ì
keystorePasswordUriB" ®The Cloud Storage URI of a KMS encrypted file containing
the password to the user provided keystore. For the self-signed certificated, the password
is generated by Dataproc.

keystoreUriB" The Cloud Storage URI of the keystore file used for SSL encryption.
If not provided, Dataproc will provide a self-signed certificate.
Q
	kmsKeyUri" @The URI of the KMS key used to encrypt various sensitive files.

realmB" sThe name of the on-cluster Kerberos realm. If not specified, the
uppercased domain of hostnames will be the realm.
v
rootPrincipalPasswordUri" VThe Cloud Storage URI of a KMS encrypted file
containing the root principal password.
P
tgtLifetimeHoursB 6The lifetime of the ticket granting ticket, in hours.
Ð
truststorePasswordUriB" °The Cloud Storage URI of a KMS encrypted file
containing the password to the user provided truststore. For the self-signed
certificate, this password is generated by Dataproc.
§
truststoreUriB" The Cloud Storage URI of the truststore file used for
SSL encryption. If not provided, Dataproc will provide a self-signed certificate.

- - -
:à	

dataproc"ClusterClusterConfigSoftwareConfigRgcp:dataproc/ClusterClusterConfigSoftwareConfig:ClusterClusterConfigSoftwareConfigØ
Õà
imageVersionB" ÉThe Cloud Dataproc image version to use
for the cluster - this controls the sets of software versions
installed onto the nodes when you create clusters. If not specified, defaults to the
latest version. For a list of valid versions see
[Cloud Dataproc versions](https://cloud.google.com/dataproc/docs/concepts/dataproc-versions)
é
optionalComponentsB*" ÊThe set of optional components to activate on the cluster. See [Available Optional Components](https://cloud.google.com/dataproc/docs/concepts/components/overview#available_optional_components).

- - -
À
overridePropertiesB2" ¡A list of override and additional properties (key/value pairs)
used to modify various aspects of the common configuration files used when creating
a cluster. For a list of valid properties please see
[Cluster properties](https://cloud.google.com/dataproc/docs/concepts/cluster-properties)
À

propertiesB2" ©A list of the properties used to set the daemon config files.
This will include any values supplied by the user via `cluster_config.software_config.override_properties`
:Ú
|
dataproc ClusterClusterConfigWorkerConfigNgcp:dataproc/ClusterClusterConfigWorkerConfig:ClusterClusterConfigWorkerConfigÙ
Ö
accelerators©B¦*£: 

dataproc+ClusterClusterConfigWorkerConfigAcceleratordgcp:dataproc/ClusterClusterConfigWorkerConfigAccelerator:ClusterClusterConfigWorkerConfigAcceleratorcThe Compute Engine accelerator configuration for these instances. Can be specified multiple times.
À

diskConfig£B :

dataproc*ClusterClusterConfigWorkerConfigDiskConfigbgcp:dataproc/ClusterClusterConfigWorkerConfigDiskConfig:ClusterClusterConfigWorkerConfigDiskConfigDisk Config
§
imageUriB" The URI for the image to use for this worker.  See [the guide](https://cloud.google.com/dataproc/docs/guides/dataproc-images)
for more information.
`
instanceNamesB*" GList of worker instance names which have been assigned
to the cluster.
É
machineTypeB" ³The name of a Google Compute Engine machine type
to create for the worker nodes. If not specified, GCP will default to a predetermined
computed value (currently `n1-standard-4`).
Ø
minCpuPlatformB" ¿The name of a minimum generation of CPU family
for the master. If not specified, GCP will default to a predetermined computed value
for each zone. See [the guide](https://cloud.google.com/compute/docs/instances/specify-min-cpu-platform)
for details about which CPU families are available (and defaulted) for each zone.
ð
minNumInstancesB ÖThe minimum number of primary worker instances to create.  If `min_num_instances` is set, cluster creation will succeed if the number of primary workers created is at least equal to the `min_num_instances` number.
È
numInstancesB ±Specifies the number of worker nodes to create.
If not specified, GCP will default to a predetermined computed value (currently 2).
There is currently a beta feature which allows you to run a
[Single Node Cluster](https://cloud.google.com/dataproc/docs/concepts/single-node-clusters).
In order to take advantage of this you need to set
`"dataproc:dataproc.allow.zero.workers" = "true"` in
`cluster_config.software_config.properties`
:´

dataproc+ClusterClusterConfigWorkerConfigAcceleratordgcp:dataproc/ClusterClusterConfigWorkerConfigAccelerator:ClusterClusterConfigWorkerConfigAccelerator

acceleratorCount õThe number of the accelerator cards of this type exposed to this instance. Often restricted to one of `1`, `2`, `4`, or `8`.

> The Cloud Dataproc API can return unintuitive error messages when using accelerators; even when you have defined an accelerator, Auto Zone Placement does not exclusively select
zones that have that accelerator available. If you get a 400 error that the accelerator can't be found, this is a likely cause. Make sure you check [accelerator availability by zone](https://cloud.google.com/compute/docs/reference/rest/v1/acceleratorTypes/list)
if you are trying to use accelerators in a given zone.

- - -
{
acceleratorType" dThe short name of the accelerator type to expose to this instance. For example, `nvidia-tesla-k80`.
:¢

dataproc*ClusterClusterConfigWorkerConfigDiskConfigbgcp:dataproc/ClusterClusterConfigWorkerConfigDiskConfig:ClusterClusterConfigWorkerConfigDiskConfig
ÿÀ
bootDiskSizeGbB §Size of the primary disk attached to each worker node, specified
in GB. The smallest allowed disk size is 10GB. GCP will default to a predetermined
computed value if not set (currently 500GB). Note: If SSDs are not
attached, it also contains the HDFS data blocks and Hadoop working directories.

bootDiskTypeB" |The disk type of the primary disk attached to each node.
One of `"pd-ssd"` or `"pd-standard"`. Defaults to `"pd-standard"`.
¬
localSsdInterfaceB" Interface type of local SSDs (default is "scsi"). Valid values: "scsi" (Small Computer System Interface), "nvme" (Non-Volatile Memory Express).
v
numLocalSsdsB `The amount of local SSD disks that will be
attached to each worker cluster node. Defaults to 0.
:¤
j
dataprocClusterIAMBindingConditionBgcp:dataproc/ClusterIAMBindingCondition:ClusterIAMBindingCondition6
4
descriptionB" 

expression" 
title" :¡
g
dataprocClusterIAMMemberCondition@gcp:dataproc/ClusterIAMMemberCondition:ClusterIAMMemberCondition6
4
descriptionB" 

expression" 
title" :¬	
m
dataprocClusterVirtualClusterConfigDgcp:dataproc/ClusterVirtualClusterConfig:ClusterVirtualClusterConfigº
·­
auxiliaryServicesConfig»B¸:µ
²
dataproc2ClusterVirtualClusterConfigAuxiliaryServicesConfigrgcp:dataproc/ClusterVirtualClusterConfigAuxiliaryServicesConfig:ClusterVirtualClusterConfigAuxiliaryServicesConfigTConfiguration of auxiliary services used by this cluster. 
Structure defined below.
º
kubernetesClusterConfig»B¸:µ
²
dataproc2ClusterVirtualClusterConfigKubernetesClusterConfigrgcp:dataproc/ClusterVirtualClusterConfigKubernetesClusterConfig:ClusterVirtualClusterConfigKubernetesClusterConfigaThe configuration for running the Dataproc cluster on Kubernetes.
Structure defined below.
- - -
Ç
stagingBucketB" ¯The Cloud Storage staging bucket used to stage files,
such as Hadoop jars, between client machines and the cluster.
Note: If you don't explicitly specify a `staging_bucket`
then GCP will auto create / assign one for you. However, you are not guaranteed
an auto generated bucket which is solely dedicated to your cluster; it may be shared
with other clusters in the same region/zone also choosing to use the auto generation
option.
:Ð
²
dataproc2ClusterVirtualClusterConfigAuxiliaryServicesConfigrgcp:dataproc/ClusterVirtualClusterConfigAuxiliaryServicesConfig:ClusterVirtualClusterConfigAuxiliaryServicesConfig
³
metastoreConfigéBæ:ã
à
dataprocAClusterVirtualClusterConfigAuxiliaryServicesConfigMetastoreConfiggcp:dataproc/ClusterVirtualClusterConfigAuxiliaryServicesConfigMetastoreConfig:ClusterVirtualClusterConfigAuxiliaryServicesConfigMetastoreConfig4The Hive Metastore configuration for this workload.
Ü
sparkHistoryServerConfigB:þ
û
dataprocJClusterVirtualClusterConfigAuxiliaryServicesConfigSparkHistoryServerConfig¢gcp:dataproc/ClusterVirtualClusterConfigAuxiliaryServicesConfigSparkHistoryServerConfig:ClusterVirtualClusterConfigAuxiliaryServicesConfigSparkHistoryServerConfig9The Spark History Server configuration for the workload.
:Ä
à
dataprocAClusterVirtualClusterConfigAuxiliaryServicesConfigMetastoreConfiggcp:dataproc/ClusterVirtualClusterConfigAuxiliaryServicesConfigMetastoreConfig:ClusterVirtualClusterConfigAuxiliaryServicesConfigMetastoreConfig_
][
dataprocMetastoreServiceB" 9Resource name of an existing Dataproc Metastore service.
:
û
dataprocJClusterVirtualClusterConfigAuxiliaryServicesConfigSparkHistoryServerConfig¢gcp:dataproc/ClusterVirtualClusterConfigAuxiliaryServicesConfigSparkHistoryServerConfig:ClusterVirtualClusterConfigAuxiliaryServicesConfigSparkHistoryServerConfig

dataprocClusterB" gResource name of an existing Dataproc Cluster to act as a Spark History Server for the workload.
- - -
:	
²
dataproc2ClusterVirtualClusterConfigKubernetesClusterConfigrgcp:dataproc/ClusterVirtualClusterConfigKubernetesClusterConfig:ClusterVirtualClusterConfigKubernetesClusterConfigÙ
Ö»
gkeClusterConfigé:æ
ã
dataprocBClusterVirtualClusterConfigKubernetesClusterConfigGkeClusterConfiggcp:dataproc/ClusterVirtualClusterConfigKubernetesClusterConfigGkeClusterConfig:ClusterVirtualClusterConfigKubernetesClusterConfigGkeClusterConfig;The configuration for running the Dataproc cluster on GKE.
¦
kubernetesNamespaceB" A namespace within the Kubernetes cluster to deploy into. 
If this namespace does not exist, it is created.
If it  exists, Dataproc verifies that another Dataproc VirtualCluster is not installed into it.
If not specified, the name of the Dataproc Cluster is used.
ì
kubernetesSoftwareConfig:þ
û
dataprocJClusterVirtualClusterConfigKubernetesClusterConfigKubernetesSoftwareConfig¢gcp:dataproc/ClusterVirtualClusterConfigKubernetesClusterConfigKubernetesSoftwareConfig:ClusterVirtualClusterConfigKubernetesClusterConfigKubernetesSoftwareConfigLThe software configuration for this Dataproc cluster running on Kubernetes.
:
ã
dataprocBClusterVirtualClusterConfigKubernetesClusterConfigGkeClusterConfiggcp:dataproc/ClusterVirtualClusterConfigKubernetesClusterConfigGkeClusterConfig:ClusterVirtualClusterConfigKubernetesClusterConfigGkeClusterConfig­
ª¬
gkeClusterTargetB" A target GKE cluster to deploy to. It must be in the same project and region as the Dataproc cluster 
(the GKE cluster can be zonal or regional)
ø
nodePoolTargetsB*:

dataprocPClusterVirtualClusterConfigKubernetesClusterConfigGkeClusterConfigNodePoolTarget®gcp:dataproc/ClusterVirtualClusterConfigKubernetesClusterConfigGkeClusterConfigNodePoolTarget:ClusterVirtualClusterConfigKubernetesClusterConfigGkeClusterConfigNodePoolTargetÈGKE node pools where workloads will be scheduled. At least one node pool must be assigned the `DEFAULT` 
GkeNodePoolTarget.Role. If a GkeNodePoolTarget is not specified, Dataproc constructs a `DEFAULT` GkeNodePoolTarget.
Each role can be given to only one GkeNodePoolTarget. All node pools must have the same location settings.
:´

dataprocPClusterVirtualClusterConfigKubernetesClusterConfigGkeClusterConfigNodePoolTarget®gcp:dataproc/ClusterVirtualClusterConfigKubernetesClusterConfigGkeClusterConfigNodePoolTarget:ClusterVirtualClusterConfigKubernetesClusterConfigGkeClusterConfigNodePoolTarget¡
*
nodePool" The target GKE node pool.
ã
nodePoolConfigÀB½:º
·
dataproc^ClusterVirtualClusterConfigKubernetesClusterConfigGkeClusterConfigNodePoolTargetNodePoolConfigÊgcp:dataproc/ClusterVirtualClusterConfigKubernetesClusterConfigGkeClusterConfigNodePoolTargetNodePoolConfig:ClusterVirtualClusterConfigKubernetesClusterConfigGkeClusterConfigNodePoolTargetNodePoolConfigThe configuration for the GKE node pool. 
If specified, Dataproc attempts to create a node pool with the specified shape.
If one with the same name already exists, it is verified against all specified fields.
If a field differs, the virtual cluster creation will fail.

roles*" zThe roles associated with the GKE node pool. 
One of `"DEFAULT"`, `"CONTROLLER"`, `"SPARK_DRIVER"` or `"SPARK_EXECUTOR"`.
:Å

·
dataproc^ClusterVirtualClusterConfigKubernetesClusterConfigGkeClusterConfigNodePoolTargetNodePoolConfigÊgcp:dataproc/ClusterVirtualClusterConfigKubernetesClusterConfigGkeClusterConfigNodePoolTargetNodePoolConfig:ClusterVirtualClusterConfigKubernetesClusterConfigGkeClusterConfigNodePoolTargetNodePoolConfig
ë
autoscalingáBÞ:Û
Ø
dataprociClusterVirtualClusterConfigKubernetesClusterConfigGkeClusterConfigNodePoolTargetNodePoolConfigAutoscalingàgcp:dataproc/ClusterVirtualClusterConfigKubernetesClusterConfigGkeClusterConfigNodePoolTargetNodePoolConfigAutoscaling:ClusterVirtualClusterConfigKubernetesClusterConfigGkeClusterConfigNodePoolTargetNodePoolConfigAutoscalingxThe autoscaler configuration for this node pool. 
The autoscaler is enabled only when a valid configuration is present.
ü
configÒBÏ:Ì
É
dataprocdClusterVirtualClusterConfigKubernetesClusterConfigGkeClusterConfigNodePoolTargetNodePoolConfigConfigÖgcp:dataproc/ClusterVirtualClusterConfigKubernetesClusterConfigGkeClusterConfigNodePoolTargetNodePoolConfigConfig:ClusterVirtualClusterConfigKubernetesClusterConfigGkeClusterConfigNodePoolTargetNodePoolConfigConfigThe node pool configuration.

	locations*" The list of Compute Engine zones where node pool nodes associated 
with a Dataproc on GKE virtual cluster will be located.
- - -
:¹
Ø
dataprociClusterVirtualClusterConfigKubernetesClusterConfigGkeClusterConfigNodePoolTargetNodePoolConfigAutoscalingàgcp:dataproc/ClusterVirtualClusterConfigKubernetesClusterConfigGkeClusterConfigNodePoolTargetNodePoolConfigAutoscaling:ClusterVirtualClusterConfigKubernetesClusterConfigGkeClusterConfigNodePoolTargetNodePoolConfigAutoscalingÛ
Øn
maxNodeCountB XThe maximum number of nodes in the node pool. Must be >= minNodeCount, and must be > 0.
f
minNodeCountB PThe minimum number of nodes in the node pool. Must be >= 0 and <= maxNodeCount.
:	
É
dataprocdClusterVirtualClusterConfigKubernetesClusterConfigGkeClusterConfigNodePoolTargetNodePoolConfigConfigÖgcp:dataproc/ClusterVirtualClusterConfigKubernetesClusterConfigGkeClusterConfigNodePoolTargetNodePoolConfigConfig:ClusterVirtualClusterConfigKubernetesClusterConfigGkeClusterConfigNodePoolTargetNodePoolConfigConfigÍ
Ê
localSsdCountB zThe number of local SSD disks to attach to the node, 
which is limited by the maximum number of disks allowable per zone.
@
machineTypeB" +The name of a Compute Engine machine type.
ò
minCpuPlatformB" ÙMinimum CPU platform to be used by this instance. 
The instance may be scheduled on the specified or a newer CPU platform.
Specify the friendly names of CPU platforms, such as "Intel Haswell" or "Intel Sandy Bridge".

preemptibleB
 Whether the nodes are created as preemptible VM instances. 
Preemptible nodes cannot be used in a node pool with the CONTROLLER role or in the DEFAULT node pool if the
CONTROLLER role is not assigned (the DEFAULT node pool will assume the CONTROLLER role).
c
spotB
 USpot flag for enabling Spot VM, which is a rebrand of the existing preemptible flag.
:¥
û
dataprocJClusterVirtualClusterConfigKubernetesClusterConfigKubernetesSoftwareConfig¢gcp:dataproc/ClusterVirtualClusterConfigKubernetesClusterConfigKubernetesSoftwareConfig:ClusterVirtualClusterConfigKubernetesClusterConfigKubernetesSoftwareConfig¤
¡ê
componentVersion2" ÏThe components that should be installed in this Dataproc cluster. The key must be a string from the   
KubernetesComponent enumeration. The value is the version of the software to be installed. At least one entry must be specified.
* **NOTE** : `component_version[SPARK]` is mandatory to set, or the creation of the cluster will fail.
±

propertiesB2" The properties to set on daemon config files. Property keys are specified in prefix:property format, 
for example spark:spark.kubernetes.container.image.
:
Ë
dataproc:GdcApplicationEnvironmentSparkApplicationEnvironmentConfiggcp:dataproc/GdcApplicationEnvironmentSparkApplicationEnvironmentConfig:GdcApplicationEnvironmentSparkApplicationEnvironmentConfig¶
³·
defaultPropertiesB2" A map of default Spark properties to apply to workloads in this application environment. These defaults may be overridden by per-application properties.
w
defaultVersionB" _The default Dataproc version to use for applications submitted to this application environment
:¨
s
dataprocGdcServiceInstanceGdceClusterHgcp:dataproc/GdcServiceInstanceGdceCluster:GdcServiceInstanceGdceCluster1
/-
gdceCluster" Gdce cluster resource id.
:§
 
dataproc,GdcServiceInstanceSparkServiceInstanceConfigfgcp:dataproc/GdcServiceInstanceSparkServiceInstanceConfig:GdcServiceInstanceSparkServiceInstanceConfig
 :þ

dataproc+GdcSparkApplicationPysparkApplicationConfigdgcp:dataproc/GdcSparkApplicationPysparkApplicationConfig:GdcSparkApplicationPysparkApplicationConfigÛ
Ø¦
archiveUrisB*" HCFS URIs of archives to be extracted into the working directory of each executor. Supported file types: .jar, .tar, .tar.gz, .tgz, and .zip.
Ë
argsB*" ºThe arguments to pass to the driver.  Do not include arguments, such as `--conf`, that can be set as job properties, since a collision may occur that causes an incorrect job submission.

fileUrisB*" nHCFS URIs of files to be placed in the working directory of each executor. Useful for naively parallel tasks.
g
jarFileUrisB*" PHCFS URIs of jar files to add to the CLASSPATHs of the Python driver and tasks.
h
mainPythonFileUri" OThe HCFS URI of the main Python file to use as the driver. Must be a .py file.

pythonFileUrisB*" lHCFS file URIs of Python files to pass to the PySpark framework. Supported file types: .py, .egg, and .zip.
:å

dataproc)GdcSparkApplicationSparkApplicationConfig`gcp:dataproc/GdcSparkApplicationSparkApplicationConfig:GdcSparkApplicationSparkApplicationConfigÈ
Å°
archiveUrisB*" HCFS URIs of archives to be extracted into the working directory of each executor. Supported file types: `.jar`, `.tar`, `.tar.gz`, `.tgz`, and `.zip`.
Ù
argsB*" ÈThe arguments to pass to the driver. Do not include arguments that can be set as application properties, such as `--conf`, since a collision can occur that causes an incorrect application submission.
_
fileUrisB*" KHCFS URIs of files to be placed in the working directory of each executor.
e
jarFileUrisB*" NHCFS URIs of jar files to add to the classpath of the Spark driver and tasks.

	mainClassB" The name of the driver main class. The jar file that contains the class must be in the classpath or specified in `jar_file_uris`.
S
mainJarFileUriB" ;The HCFS URI of the jar file that contains the main class.
:þ

dataproc*GdcSparkApplicationSparkRApplicationConfigbgcp:dataproc/GdcSparkApplicationSparkRApplicationConfig:GdcSparkApplicationSparkRApplicationConfigÞ
Û¦
archiveUrisB*" HCFS URIs of archives to be extracted into the working directory of each executor. Supported file types: .jar, .tar, .tar.gz, .tgz, and .zip.
Ë
argsB*" ºThe arguments to pass to the driver.  Do not include arguments, such as `--conf`, that can be set as job properties, since a collision may occur that causes an incorrect job submission.

fileUrisB*" nHCFS URIs of files to be placed in the working directory of each executor. Useful for naively parallel tasks.
]
mainRFileUri" IThe HCFS URI of the main R file to use as the driver. Must be a .R file.
:ã
 
dataproc,GdcSparkApplicationSparkSqlApplicationConfigfgcp:dataproc/GdcSparkApplicationSparkSqlApplicationConfig:GdcSparkApplicationSparkSqlApplicationConfig½
ºR
jarFileUrisB*" ;HCFS URIs of jar files to be added to the Spark CLASSPATH.
L
queryFileUriB" 6The HCFS URI of the script that contains SQL queries.

	queryListÄBÁ:¾
»
dataproc5GdcSparkApplicationSparkSqlApplicationConfigQueryListxgcp:dataproc/GdcSparkApplicationSparkSqlApplicationConfigQueryList:GdcSparkApplicationSparkSqlApplicationConfigQueryList=Represents a list of queries.
Structure is documented below.

scriptVariablesB2" fMapping of query variable names to values (equivalent to the Spark SQL command: SET `name="value";`).
:é
»
dataproc5GdcSparkApplicationSparkSqlApplicationConfigQueryListxgcp:dataproc/GdcSparkApplicationSparkSqlApplicationConfigQueryList:GdcSparkApplicationSparkSqlApplicationConfigQueryList)
'%
queries*" The queries to run.
:»
I
dataprocJobHadoopConfig,gcp:dataproc/JobHadoopConfig:JobHadoopConfigí
ê~
archiveUrisB*" gHCFS URIs of archives to be extracted in the working directory of .jar, .tar, .tar.gz, .tgz, and .zip.
×
argsB*" ÆThe arguments to pass to the driver. Do not include arguments, such as -libjars or -Dfoo=bar, that can be set as job properties, since a collision may occur that causes an incorrect job submission.

fileUrisB*" HCFS URIs of files to be copied to the working directory of Hadoop drivers and distributed tasks. Useful for naively parallel tasks.
f
jarFileUrisB*" OHCFS URIs of jar files to add to the CLASSPATHs of the Spark driver and tasks.
¯
loggingConfigvBt:r
p
dataprocJobHadoopConfigLoggingConfigFgcp:dataproc/JobHadoopConfigLoggingConfig:JobHadoopConfigLoggingConfig&The runtime logging config of the job
À
	mainClassB" ¬The name of the driver's main class. The jar file containing the class must be in the default CLASSPATH or specified in `jar_file_uris`. Conflicts with `main_jar_file_uri`
¯
mainJarFileUriB" The HCFS URI of the jar file containing the main class. Examples: 'gs://foo-bucket/analytics-binaries/extract-useful-metrics-mr.jar' 'hdfs:/tmp/test-samples/custom-wordcount.jar' 'file:///home/usr/lib/hadoop-mapreduce/hadoop-mapreduce-examples.jar'. Conflicts with `main_class`
á

propertiesB2" ÊA mapping of property names to values, used to configure Hadoop. Properties that conflict with values set by the Cloud Dataproc API may be overwritten. Can include properties set in `/etc/hadoop/conf/*-site` and classes in user code..

* `logging_config.driver_log_levels`- (Required) The per-package log levels for the driver. This may include 'root' package name to configure rootLogger. Examples: 'com.google = FATAL', 'root = INFO', 'org.apache = DEBUG'
:Í
p
dataprocJobHadoopConfigLoggingConfigFgcp:dataproc/JobHadoopConfigLoggingConfig:JobHadoopConfigLoggingConfigØ
ÕÒ
driverLogLevels2" ¸Optional. The per-package log levels for the driver. This may include 'root' package name to configure rootLogger. Examples: 'com.google = FATAL', 'root = INFO', 'org.apache = DEBUG'.
:Ô
C
dataprocJobHiveConfig(gcp:dataproc/JobHiveConfig:JobHiveConfig
Î
continueOnFailureB
 ²Whether to continue executing queries if a query fails. The default value is false. Setting to true can be useful when executing independent parallel queries. Defaults to false.

jarFileUrisB*" HCFS URIs of jar files to add to the CLASSPATH of the Hive server and Hadoop MapReduce (MR) tasks. Can contain Hive SerDes and UDFs.
¦

propertiesB2" A mapping of property names and values, used to configure Hive. Properties that conflict with values set by the Cloud Dataproc API may be overwritten. Can include properties set in `/etc/hadoop/conf/*-site.xml`, `/etc/hive/conf/hive-site.xml`, and classes in user code..
q
queryFileUriB" [HCFS URI of file containing Hive script to execute as the job.
Conflicts with `query_list`
|

queryListsB*" fThe list of Hive queries or statements to execute as part of the job.
Conflicts with `query_file_uri`
|
scriptVariablesB2" aMapping of query variable names to values (equivalent to the Hive command: `SET name="value";`).
:
^
dataprocJobIAMBindingCondition:gcp:dataproc/JobIAMBindingCondition:JobIAMBindingCondition6
4
descriptionB" 

expression" 
title" :
[
dataprocJobIAMMemberCondition8gcp:dataproc/JobIAMMemberCondition:JobIAMMemberCondition6
4
descriptionB" 

expression" 
title" :Ã
@
dataprocJobPigConfig&gcp:dataproc/JobPigConfig:JobPigConfigþ

û
Î
continueOnFailureB
 ²Whether to continue executing queries if a query fails. The default value is false. Setting to true can be useful when executing independent parallel queries. Defaults to false.
ï
jarFileUrisB*" ×HCFS URIs of jar files to add to the CLASSPATH of the Pig Client and Hadoop MapReduce (MR) tasks. Can contain Pig UDFs.

* `logging_config.driver_log_levels`- (Required) The per-package log levels for the driver. This may include 'root' package name to configure rootLogger. Examples: 'com.google = FATAL', 'root = INFO', 'org.apache = DEBUG'
¦
loggingConfigmBk:i
g
dataprocJobPigConfigLoggingConfig@gcp:dataproc/JobPigConfigLoggingConfig:JobPigConfigLoggingConfig&The runtime logging config of the job
£

propertiesB2" A mapping of property names to values, used to configure Pig. Properties that conflict with values set by the Cloud Dataproc API may be overwritten. Can include properties set in `/etc/hadoop/conf/*-site.xml`, `/etc/pig/conf/pig.properties`, and classes in user code.
q
queryFileUriB" [HCFS URI of file containing Hive script to execute as the job.
Conflicts with `query_list`
|

queryListsB*" fThe list of Hive queries or statements to execute as part of the job.
Conflicts with `query_file_uri`
v
scriptVariablesB2" [Mapping of query variable names to values (equivalent to the Pig command: `name=[value]`).
:Ä
g
dataprocJobPigConfigLoggingConfig@gcp:dataproc/JobPigConfigLoggingConfig:JobPigConfigLoggingConfigØ
ÕÒ
driverLogLevels2" ¸Optional. The per-package log levels for the driver. This may include 'root' package name to configure rootLogger. Examples: 'com.google = FATAL', 'root = INFO', 'org.apache = DEBUG'.
:
@
dataprocJobPlacement&gcp:dataproc/JobPlacement:JobPlacementÅ
ÂK
clusterName" 8The name of the cluster where the job will be submitted
s
clusterUuidB" ^Output-only. A cluster UUID generated by the Cloud Dataproc service when the job is submitted
:ì	
I
dataprocJobPrestoConfig,gcp:dataproc/JobPrestoConfig:JobPrestoConfig	
	B

clientTagsB*" ,Presto client tags to attach to this query.
²
continueOnFailureB
 Whether to continue executing queries if a query fails. Setting to true can be useful when executing independent parallel queries. Defaults to false.
¯
loggingConfigvBt:r
p
dataprocJobPrestoConfigLoggingConfigFgcp:dataproc/JobPrestoConfigLoggingConfig:JobPrestoConfigLoggingConfig&The runtime logging config of the job
å
outputFormatB" ÎThe format in which query output will be displayed. See the Presto documentation for supported output formats.

* `logging_config.driver_log_levels`- (Required) The per-package log levels for the driver. This may include 'root' package name to configure rootLogger. Examples: 'com.google = FATAL', 'root = INFO', 'org.apache = DEBUG'


propertiesB2" A mapping of property names to values. Used to set Presto session properties Equivalent to using the --session flag in the Presto CLI.
h
queryFileUriB" RThe HCFS URI of the script that contains SQL queries.
Conflicts with `query_list`
{

queryListsB*" eThe list of SQL queries or statements to execute as part of the job.
Conflicts with `query_file_uri`
:Í
p
dataprocJobPrestoConfigLoggingConfigFgcp:dataproc/JobPrestoConfigLoggingConfig:JobPrestoConfigLoggingConfigØ
ÕÒ
driverLogLevels2" ¸Optional. The per-package log levels for the driver. This may include 'root' package name to configure rootLogger. Examples: 'com.google = FATAL', 'root = INFO', 'org.apache = DEBUG'.
:©
L
dataprocJobPysparkConfig.gcp:dataproc/JobPysparkConfig:JobPysparkConfigØ

Õ
~
archiveUrisB*" gHCFS URIs of archives to be extracted in the working directory of .jar, .tar, .tar.gz, .tgz, and .zip.
5
argsB*" %The arguments to pass to the driver.

fileUrisB*" HCFS URIs of files to be copied to the working directory of Python drivers and distributed tasks. Useful for naively parallel tasks.
g
jarFileUrisB*" PHCFS URIs of jar files to add to the CLASSPATHs of the Python driver and tasks.
²
loggingConfigyBw:u
s
dataprocJobPysparkConfigLoggingConfigHgcp:dataproc/JobPysparkConfigLoggingConfig:JobPysparkConfigLoggingConfig&The runtime logging config of the job
h
mainPythonFileUri" OThe HCFS URI of the main Python file to use as the driver. Must be a .py file.
í

propertiesB2" ÖA mapping of property names to values, used to configure PySpark. Properties that conflict with values set by the Cloud Dataproc API may be overwritten. Can include properties set in `/etc/spark/conf/spark-defaults.conf` and classes in user code.

* `logging_config.driver_log_levels`- (Required) The per-package log levels for the driver. This may include 'root' package name to configure rootLogger. Examples: 'com.google = FATAL', 'root = INFO', 'org.apache = DEBUG'

pythonFileUrisB*" lHCFS file URIs of Python files to pass to the PySpark framework. Supported file types: .py, .egg, and .zip.
:Ð
s
dataprocJobPysparkConfigLoggingConfigHgcp:dataproc/JobPysparkConfigLoggingConfig:JobPysparkConfigLoggingConfigØ
ÕÒ
driverLogLevels2" ¸Optional. The per-package log levels for the driver. This may include 'root' package name to configure rootLogger. Examples: 'com.google = FATAL', 'root = INFO', 'org.apache = DEBUG'.
: 
@
dataprocJobReference&gcp:dataproc/JobReference:JobReferenceÛ
ØÕ
jobIdB" ÅThe job ID, which must be unique within the project. The job ID is generated by the server upon job submission or provided by the user as a means to perform retries without creating duplicate jobs
:
C
dataprocJobScheduling(gcp:dataproc/JobScheduling:JobSchedulingÓ
Ð¦
maxFailuresPerHour Maximum number of times per hour a driver may be restarted as a result of driver exiting with non-zero code before job is reported failed.
¤
maxFailuresTotal Maximum number of times in total a driver may be restarted as a result of driver exiting with non-zero code before job is reported failed.
:Á
F
dataprocJobSparkConfig*gcp:dataproc/JobSparkConfig:JobSparkConfigö

ó
~
archiveUrisB*" gHCFS URIs of archives to be extracted in the working directory of .jar, .tar, .tar.gz, .tgz, and .zip.
5
argsB*" %The arguments to pass to the driver.

fileUrisB*" HCFS URIs of files to be copied to the working directory of Spark drivers and distributed tasks. Useful for naively parallel tasks.
f
jarFileUrisB*" OHCFS URIs of jar files to add to the CLASSPATHs of the Spark driver and tasks.
¬
loggingConfigsBq:o
m
dataprocJobSparkConfigLoggingConfigDgcp:dataproc/JobSparkConfigLoggingConfig:JobSparkConfigLoggingConfig&The runtime logging config of the job
®
	mainClassB" The class containing the main method of the driver. Must be in a
provided jar or jar that is already on the classpath. Conflicts with `main_jar_file_uri`
h
mainJarFileUriB" PThe HCFS URI of jar file containing
the driver jar. Conflicts with `main_class`
ë

propertiesB2" ÔA mapping of property names to values, used to configure Spark. Properties that conflict with values set by the Cloud Dataproc API may be overwritten. Can include properties set in `/etc/spark/conf/spark-defaults.conf` and classes in user code.

* `logging_config.driver_log_levels`- (Required) The per-package log levels for the driver. This may include 'root' package name to configure rootLogger. Examples: 'com.google = FATAL', 'root = INFO', 'org.apache = DEBUG'
:Ê
m
dataprocJobSparkConfigLoggingConfigDgcp:dataproc/JobSparkConfigLoggingConfig:JobSparkConfigLoggingConfigØ
ÕÒ
driverLogLevels2" ¸Optional. The per-package log levels for the driver. This may include 'root' package name to configure rootLogger. Examples: 'com.google = FATAL', 'root = INFO', 'org.apache = DEBUG'.
:ð
O
dataprocJobSparksqlConfig0gcp:dataproc/JobSparksqlConfig:JobSparksqlConfig
²
jarFileUrisB*" HCFS URIs of jar files to be added to the Spark CLASSPATH.

* `logging_config.driver_log_levels`- (Required) The per-package log levels for the driver. This may include 'root' package name to configure rootLogger. Examples: 'com.google = FATAL', 'root = INFO', 'org.apache = DEBUG'
µ
loggingConfig|Bz:x
v
dataprocJobSparksqlConfigLoggingConfigJgcp:dataproc/JobSparksqlConfigLoggingConfig:JobSparksqlConfigLoggingConfig&The runtime logging config of the job
¾

propertiesB2" §A mapping of property names to values, used to configure Spark SQL's SparkConf. Properties that conflict with values set by the Cloud Dataproc API may be overwritten.
h
queryFileUriB" RThe HCFS URI of the script that contains SQL queries.
Conflicts with `query_list`
{

queryListsB*" eThe list of SQL queries or statements to execute as part of the job.
Conflicts with `query_file_uri`

scriptVariablesB2" fMapping of query variable names to values (equivalent to the Spark SQL command: `SET name="value";`).
:Ó
v
dataprocJobSparksqlConfigLoggingConfigJgcp:dataproc/JobSparksqlConfigLoggingConfig:JobSparksqlConfigLoggingConfigØ
ÕÒ
driverLogLevels2" ¸Optional. The per-package log levels for the driver. This may include 'root' package name to configure rootLogger. Examples: 'com.google = FATAL', 'root = INFO', 'org.apache = DEBUG'.
:
7
dataproc	JobStatus gcp:dataproc/JobStatus:JobStatusÈ
Åa
detailsB" POptional job state details, such as an error description if the state is ERROR.
A
stateB" 2A state message specifying the overall job state.
>
stateStartTimeB" &The time when this state was entered.
]
substateB" KAdditional state information, which includes status reported by the agent.
:Ú

dataproc#MetastoreFederationBackendMetastoreTgcp:dataproc/MetastoreFederationBackendMetastore:MetastoreFederationBackendMetastoreÏ
Ì
metastoreType" The type of the backend metastore.
Possible values are: `METASTORE_TYPE_UNSPECIFIED`, `DATAPROC_METASTORE`, `BIGQUERY`.

- - -
ì
name" ßThe relative resource name of the metastore that is being federated. The formats of the relative resource names for the currently supported metastores are listed below: Dataplex: projects/{projectId}/locations/{location}/lakes/{lake_id} BigQuery: projects/{projectId} Dataproc Metastore: projects/{projectId}/locations/{location}/services/{serviceId}
D
rank" 8The identifier for this object. Format specified above.
:É

dataproc&MetastoreFederationIamBindingConditionZgcp:dataproc/MetastoreFederationIamBindingCondition:MetastoreFederationIamBindingCondition6
4
descriptionB" 

expression" 
title" :Æ

dataproc%MetastoreFederationIamMemberConditionXgcp:dataproc/MetastoreFederationIamMemberCondition:MetastoreFederationIamMemberCondition6
4
descriptionB" 

expression" 
title" :×
|
dataproc MetastoreServiceEncryptionConfigNgcp:dataproc/MetastoreServiceEncryptionConfig:MetastoreServiceEncryptionConfigÖ
ÓÐ
kmsKey" ÁThe fully qualified customer provided Cloud KMS key name to use for customer data encryption.
Use the following format: `projects/([^/]+)/locations/([^/]+)/keyRings/([^/]+)/cryptoKeys/([^/]+)`
:»

dataproc#MetastoreServiceHiveMetastoreConfigTgcp:dataproc/MetastoreServiceHiveMetastoreConfig:MetastoreServiceHiveMetastoreConfig°
­
auxiliaryVersionsÁB¾*»:¸
µ
dataproc3MetastoreServiceHiveMetastoreConfigAuxiliaryVersiontgcp:dataproc/MetastoreServiceHiveMetastoreConfigAuxiliaryVersion:MetastoreServiceHiveMetastoreConfigAuxiliaryVersion«A mapping of Hive metastore version to the auxiliary version configuration.
When specified, a secondary Hive metastore service is created along with the primary service.
All auxiliary versions must be less than the service's primary version.
The key is the auxiliary service name and it must match the regular expression a-z?.
This means that the first character must be a lowercase letter, and all the following characters must be hyphens, lowercase letters, or digits, except the last character, which cannot be a hyphen.
Structure is documented below.
Û
configOverridesB2" ¿A mapping of Hive metastore configuration key-value pairs to apply to the Hive metastore (configured in hive-site.xml).
The mappings override system defaults (some keys cannot be overridden)
»
endpointProtocolB"  The protocol to use for the metastore service endpoint. If unspecified, defaults to `THRIFT`.
Default value is `THRIFT`.
Possible values are: `THRIFT`, `GRPC`.
Ò
kerberosConfig¸Bµ:²
¯
dataproc1MetastoreServiceHiveMetastoreConfigKerberosConfigpgcp:dataproc/MetastoreServiceHiveMetastoreConfigKerberosConfig:MetastoreServiceHiveMetastoreConfigKerberosConfigInformation used to configure the Hive metastore service as a service principal in a Kerberos realm.
Structure is documented below.
2
version" #The Hive metastore schema version.
:
µ
dataproc3MetastoreServiceHiveMetastoreConfigAuxiliaryVersiontgcp:dataproc/MetastoreServiceHiveMetastoreConfigAuxiliaryVersion:MetastoreServiceHiveMetastoreConfigAuxiliaryVersionÈ
Åó
configOverridesB2" ×A mapping of Hive metastore configuration key-value pairs to apply to the auxiliary Hive metastore (configured in hive-site.xml) in addition to the primary version's overrides.
If keys are present in both the auxiliary version's overrides and the primary version's overrides, the value from the auxiliary version's overrides takes precedence.
C
key" 8The identifier for this object. Format specified above.

version" xThe Hive metastore version of the auxiliary service. It must be less than the primary Hive metastore service's version.
:Å
¯
dataproc1MetastoreServiceHiveMetastoreConfigKerberosConfigpgcp:dataproc/MetastoreServiceHiveMetastoreConfigKerberosConfig:MetastoreServiceHiveMetastoreConfigKerberosConfig
ï
keytabÇ:Ä
Á
dataproc7MetastoreServiceHiveMetastoreConfigKerberosConfigKeytab|gcp:dataproc/MetastoreServiceHiveMetastoreConfigKerberosConfigKeytab:MetastoreServiceHiveMetastoreConfigKerberosConfigKeytabA Kerberos keytab file that can be used to authenticate a service principal with a Kerberos Key Distribution Center (KDC).
Structure is documented below.
Ô
krb5ConfigGcsUri" »A Cloud Storage URI that specifies the path to a krb5.conf file. It is of the form gs://{bucket_name}/path/to/krb5.conf, although the file does not need to be named krb5.conf explicitly.
Á
	principal" ¯A Kerberos principal that exists in the both the keytab the KDC to authenticate as. A typical principal is of the form "primary/instance@REALM", but there is no exact format.
:ý
Á
dataproc7MetastoreServiceHiveMetastoreConfigKerberosConfigKeytab|gcp:dataproc/MetastoreServiceHiveMetastoreConfigKerberosConfigKeytab:MetastoreServiceHiveMetastoreConfigKerberosConfigKeytab¶
³°
cloudSecret" The relative resource name of a Secret Manager secret version, in the following form:
"projects/{projectNumber}/secrets/{secret_id}/versions/{version_id}".
:À

dataproc#MetastoreServiceIamBindingConditionTgcp:dataproc/MetastoreServiceIamBindingCondition:MetastoreServiceIamBindingCondition6
4
descriptionB" 

expression" 
title" :½

dataproc"MetastoreServiceIamMemberConditionRgcp:dataproc/MetastoreServiceIamMemberCondition:MetastoreServiceIamMemberCondition6
4
descriptionB" 

expression" 
title" :ê

dataproc!MetastoreServiceMaintenanceWindowPgcp:dataproc/MetastoreServiceMaintenanceWindow:MetastoreServiceMaintenanceWindowæ
ã
	dayOfWeek" The day of week, when the window starts.
Possible values are: `MONDAY`, `TUESDAY`, `WEDNESDAY`, `THURSDAY`, `FRIDAY`, `SATURDAY`, `SUNDAY`.
@
	hourOfDay /The hour of day (0-23) when the window starts.
:»

dataproc#MetastoreServiceMetadataIntegrationTgcp:dataproc/MetastoreServiceMetadataIntegration:MetastoreServiceMetadataIntegration°
­ª
dataCatalogConfig¾:»
¸
dataproc4MetastoreServiceMetadataIntegrationDataCatalogConfigvgcp:dataproc/MetastoreServiceMetadataIntegrationDataCatalogConfig:MetastoreServiceMetadataIntegrationDataCatalogConfigTThe integration config for the Data Catalog service.
Structure is documented below.
:é
¸
dataproc4MetastoreServiceMetadataIntegrationDataCatalogConfigvgcp:dataproc/MetastoreServiceMetadataIntegrationDataCatalogConfig:MetastoreServiceMetadataIntegrationDataCatalogConfig«
¨¥
enabled
 Defines whether the metastore metadata should be synced to Data Catalog. The default value is to disable syncing metastore metadata to Data Catalog.
:
s
dataprocMetastoreServiceNetworkConfigHgcp:dataproc/MetastoreServiceNetworkConfig:MetastoreServiceNetworkConfig¡

	consumers*:

dataproc%MetastoreServiceNetworkConfigConsumerXgcp:dataproc/MetastoreServiceNetworkConfigConsumer:MetastoreServiceNetworkConfigConsumerlThe consumer-side network configuration for the Dataproc Metastore instance.
Structure is documented below.

customRoutesEnabledB
 kEnables custom routes to be imported and exported for the Dataproc Metastore service's peered VPC network.
:½

dataproc%MetastoreServiceNetworkConfigConsumerXgcp:dataproc/MetastoreServiceNetworkConfigConsumer:MetastoreServiceNetworkConfigConsumer¬
©\
endpointUriB" G(Output)
The URI of the endpoint used to access the metastore service.
È

subnetwork" µThe subnetwork of the customer project from which an IP address is reserved and used as the Dataproc Metastore service's endpoint.
It is accessible to hosts in the subnet and to all hosts in a subnet in the same region and same network.
There must be at least one IP address available in the subnet's primary range. The subnet is specified in the following form:
`projects/{projectNumber}/regions/{region_id}/subnetworks/{subnetwork_id}
:²
s
dataprocMetastoreServiceScalingConfigHgcp:dataproc/MetastoreServiceScalingConfig:MetastoreServiceScalingConfigº
·§
autoscalingConfig¯B¬:©
¦
dataproc.MetastoreServiceScalingConfigAutoscalingConfigjgcp:dataproc/MetastoreServiceScalingConfigAutoscalingConfig:MetastoreServiceScalingConfigAutoscalingConfig`Represents the autoscaling configuration of a metastore service.
Structure is documented below.

instanceSizeB" iMetastore instance sizes.
Possible values are: `EXTRA_SMALL`, `SMALL`, `MEDIUM`, `LARGE`, `EXTRA_LARGE`.

scalingFactorB rScaling factor, in increments of 0.1 for values less than 1.0, and increments of 1.0 for values greater than 1.0.
:Ñ
¦
dataproc.MetastoreServiceScalingConfigAutoscalingConfigjgcp:dataproc/MetastoreServiceScalingConfigAutoscalingConfig:MetastoreServiceScalingConfigAutoscalingConfig¥
¢`
autoscalingEnabledB
 DDefines whether autoscaling is enabled. The default value is false.
½
limitConfigÑBÎ:Ë
È
dataproc9MetastoreServiceScalingConfigAutoscalingConfigLimitConfiggcp:dataproc/MetastoreServiceScalingConfigAutoscalingConfigLimitConfig:MetastoreServiceScalingConfigAutoscalingConfigLimitConfigZRepresents the limit configuration of a metastore service.
Structure is documented below.
:»
È
dataproc9MetastoreServiceScalingConfigAutoscalingConfigLimitConfiggcp:dataproc/MetastoreServiceScalingConfigAutoscalingConfigLimitConfig:MetastoreServiceScalingConfigAutoscalingConfigLimitConfigí
ês
maxScalingFactorB YThe maximum scaling factor that the service will autoscale to. The default value is 6.0.
s
minScalingFactorB YThe minimum scaling factor that the service will autoscale to. The default value is 0.1.
:
y
dataprocMetastoreServiceScheduledBackupLgcp:dataproc/MetastoreServiceScheduledBackup:MetastoreServiceScheduledBackup
½
backupLocation" ¦A Cloud Storage URI of a folder, in the format gs://<bucket_name>/<path_inside_bucket>. A sub-folder <backup_folder> containing backup files will be stored below it.
Ë
cronScheduleB" ´The scheduled interval in Cron format, see https://en.wikipedia.org/wiki/Cron The default is empty: scheduled backup is not enabled. Must be specified to enable scheduled backups.
^
enabledB
 MDefines whether the scheduled backup is enabled. The default value is false.
 
timeZoneB" Specifies the time zone to be used when interpreting cronSchedule. Must be a time zone name from the time zone database (https://en.wikipedia.org/wiki/List_of_tz_database_time_zones), e.g. America/Los_Angeles or Africa/Abidjan. If left unspecified, the default is UTC.
:
y
dataprocMetastoreServiceTelemetryConfigLgcp:dataproc/MetastoreServiceTelemetryConfig:MetastoreServiceTelemetryConfig

	logFormatB" |The output format of the Dataproc Metastore service's logs.
Default value is `JSON`.
Possible values are: `LEGACY`, `JSON`.
:ô
U
dataprocWorkflowTemplateJob4gcp:dataproc/WorkflowTemplateJob:WorkflowTemplateJob

	hadoopJobvBt:r
p
dataprocWorkflowTemplateJobHadoopJobFgcp:dataproc/WorkflowTemplateJobHadoopJob:WorkflowTemplateJobHadoopJobJob is a Hadoop job.

hiveJobpBn:l
j
dataprocWorkflowTemplateJobHiveJobBgcp:dataproc/WorkflowTemplateJobHiveJob:WorkflowTemplateJobHiveJobJob is a Hive job.
ç
labelsB2" ÔThe labels to associate with this job. Label keys must be between 1 and 63 characters long, and must conform to the following regular expression: {0,63} No more than 32 labels can be associated with a given job.

pigJobmBk:i
g
dataprocWorkflowTemplateJobPigJob@gcp:dataproc/WorkflowTemplateJobPigJob:WorkflowTemplateJobPigJobJob is a Pig job.

prerequisiteStepIdsB*" sThe optional list of prerequisite job step_ids. If not specified, the job will start at the beginning of workflow.

	prestoJobvBt:r
p
dataprocWorkflowTemplateJobPrestoJobFgcp:dataproc/WorkflowTemplateJobPrestoJob:WorkflowTemplateJobPrestoJobJob is a Presto job.


pysparkJobyBw:u
s
dataprocWorkflowTemplateJobPysparkJobHgcp:dataproc/WorkflowTemplateJobPysparkJob:WorkflowTemplateJobPysparkJobJob is a PySpark job.
§

schedulingyBw:u
s
dataprocWorkflowTemplateJobSchedulingHgcp:dataproc/WorkflowTemplateJobScheduling:WorkflowTemplateJobSchedulingJob scheduling configuration.

sparkJobsBq:o
m
dataprocWorkflowTemplateJobSparkJobDgcp:dataproc/WorkflowTemplateJobSparkJob:WorkflowTemplateJobSparkJobJob is a Spark job.

	sparkRJobvBt:r
p
dataprocWorkflowTemplateJobSparkRJobFgcp:dataproc/WorkflowTemplateJobSparkRJob:WorkflowTemplateJobSparkRJobJob is a SparkR job.
¤
sparkSqlJob|Bz:x
v
dataprocWorkflowTemplateJobSparkSqlJobJgcp:dataproc/WorkflowTemplateJobSparkSqlJob:WorkflowTemplateJobSparkSqlJobJob is a SparkSql job.

stepId" Required. The step id. The id must be unique among all jobs within the template. The step id is used as prefix for job id, as job `goog-dataproc-workflow-step-id` label, and in field from other steps. The id must contain only letters (a-z, A-Z), numbers (0-9), underscores (_), and hyphens (-). Cannot begin or end with underscore or hyphen. Must consist of between 3 and 50 characters.
:µ
p
dataprocWorkflowTemplateJobHadoopJobFgcp:dataproc/WorkflowTemplateJobHadoopJob:WorkflowTemplateJobHadoopJobÀ
½®
archiveUrisB*" HCFS URIs of archives to be extracted in the working directory of Hadoop drivers and tasks. Supported file types: .jar, .tar, .tar.gz, .tgz, or .zip.
Û
argsB*" ÊThe arguments to pass to the driver. Do not include arguments, such as `-libjars` or `-Dfoo=bar`, that can be set as job properties, since a collision may occur that causes an incorrect job submission.
¹
fileUrisB*" ¤HCFS (Hadoop Compatible Filesystem) URIs of files to be copied to the working directory of Hadoop drivers and distributed tasks. Useful for naively parallel tasks.
^
jarFileUrisB*" GJar file URIs to add to the CLASSPATHs of the Hadoop driver and tasks.
Þ
loggingConfig B:

dataproc)WorkflowTemplateJobHadoopJobLoggingConfig`gcp:dataproc/WorkflowTemplateJobHadoopJobLoggingConfig:WorkflowTemplateJobHadoopJobLoggingConfig*The runtime log config for job execution.

	mainClassB" The name of the driver's main class. The jar file containing the class must be in the default CLASSPATH or specified in `jar_file_uris`.

mainJarFileUriB" ùThe HCFS URI of the jar file containing the main class. Examples: 'gs://foo-bucket/analytics-binaries/extract-useful-metrics-mr.jar' 'hdfs:/tmp/test-samples/custom-wordcount.jar' 'file:///home/usr/lib/hadoop-mapreduce/hadoop-mapreduce-examples.jar'
ù

propertiesB2" âA mapping of property names to values, used to configure Hadoop. Properties that conflict with values set by the Dataproc API may be overwritten. Can include properties set in /etc/hadoop/conf/*-site and classes in user code.
:ì

dataproc)WorkflowTemplateJobHadoopJobLoggingConfig`gcp:dataproc/WorkflowTemplateJobHadoopJobLoggingConfig:WorkflowTemplateJobHadoopJobLoggingConfigÏ
ÌÉ
driverLogLevelsB2" ­The per-package log levels for the driver. This may include "root" package name to configure rootLogger. Examples: 'com.google = FATAL', 'root = INFO', 'org.apache = DEBUG'
:ó
j
dataprocWorkflowTemplateJobHiveJobBgcp:dataproc/WorkflowTemplateJobHiveJob:WorkflowTemplateJobHiveJob
¿
continueOnFailureB
 £Whether to continue executing queries if a query fails. The default value is `false`. Setting to `true` can be useful when executing independent parallel queries.

jarFileUrisB*" HCFS URIs of jar files to add to the CLASSPATH of the Hive server and Hadoop MapReduce (MR) tasks. Can contain Hive SerDes and UDFs.


propertiesB2" A mapping of property names and values, used to configure Hive. Properties that conflict with values set by the Dataproc API may be overwritten. Can include properties set in /etc/hadoop/conf/*-site.xml, /etc/hive/conf/hive-site.xml, and classes in user code.
M
queryFileUriB" 7The HCFS URI of the script that contains Hive queries.
±
	queryListB:

dataproc#WorkflowTemplateJobHiveJobQueryListTgcp:dataproc/WorkflowTemplateJobHiveJobQueryList:WorkflowTemplateJobHiveJobQueryListA list of queries.
|
scriptVariablesB2" aMapping of query variable names to values (equivalent to the Hive command: `SET name="value";`).
:Ú

dataproc#WorkflowTemplateJobHiveJobQueryListTgcp:dataproc/WorkflowTemplateJobHiveJobQueryList:WorkflowTemplateJobHiveJobQueryListÏ
ÌÉ
queries*" ·Required. The queries to execute. You do not need to end a query expression with a semicolon. Multiple queries can be specified in one string by separating each with a semicolon. Here is an example of a Dataproc API snippet that uses a QueryList to specify a HiveJob: "hiveJob": { "queryList": { "queries": } }
:«

g
dataprocWorkflowTemplateJobPigJob@gcp:dataproc/WorkflowTemplateJobPigJob:WorkflowTemplateJobPigJob¿	
¼	¿
continueOnFailureB
 £Whether to continue executing queries if a query fails. The default value is `false`. Setting to `true` can be useful when executing independent parallel queries.

jarFileUrisB*" xHCFS URIs of jar files to add to the CLASSPATH of the Pig Client and Hadoop MapReduce (MR) tasks. Can contain Pig UDFs.
Õ
loggingConfigB:

dataproc&WorkflowTemplateJobPigJobLoggingConfigZgcp:dataproc/WorkflowTemplateJobPigJobLoggingConfig:WorkflowTemplateJobPigJobLoggingConfig*The runtime log config for job execution.


propertiesB2" A mapping of property names to values, used to configure Pig. Properties that conflict with values set by the Dataproc API may be overwritten. Can include properties set in /etc/hadoop/conf/*-site.xml, /etc/pig/conf/pig.properties, and classes in user code.
P
queryFileUriB" :The HCFS URI of the script that contains the Pig queries.
®
	queryListB:

dataproc"WorkflowTemplateJobPigJobQueryListRgcp:dataproc/WorkflowTemplateJobPigJobQueryList:WorkflowTemplateJobPigJobQueryListA list of queries.
o
scriptVariablesB2" TMapping of query variable names to values (equivalent to the Pig command: `name=`).
:ã

dataproc&WorkflowTemplateJobPigJobLoggingConfigZgcp:dataproc/WorkflowTemplateJobPigJobLoggingConfig:WorkflowTemplateJobPigJobLoggingConfigÏ
ÌÉ
driverLogLevelsB2" ­The per-package log levels for the driver. This may include "root" package name to configure rootLogger. Examples: 'com.google = FATAL', 'root = INFO', 'org.apache = DEBUG'
:×

dataproc"WorkflowTemplateJobPigJobQueryListRgcp:dataproc/WorkflowTemplateJobPigJobQueryList:WorkflowTemplateJobPigJobQueryListÏ
ÌÉ
queries*" ·Required. The queries to execute. You do not need to end a query expression with a semicolon. Multiple queries can be specified in one string by separating each with a semicolon. Here is an example of a Dataproc API snippet that uses a QueryList to specify a HiveJob: "hiveJob": { "queryList": { "queries": } }
:²	
p
dataprocWorkflowTemplateJobPrestoJobFgcp:dataproc/WorkflowTemplateJobPrestoJob:WorkflowTemplateJobPrestoJob½
ºA

clientTagsB*" +Presto client tags to attach to this query
¿
continueOnFailureB
 £Whether to continue executing queries if a query fails. The default value is `false`. Setting to `true` can be useful when executing independent parallel queries.
Þ
loggingConfig B:

dataproc)WorkflowTemplateJobPrestoJobLoggingConfig`gcp:dataproc/WorkflowTemplateJobPrestoJobLoggingConfig:WorkflowTemplateJobPrestoJobLoggingConfig*The runtime log config for job execution.

outputFormatB" nThe format in which query output will be displayed. See the Presto documentation for supported output formats
Â

propertiesB2" «A mapping of property names to values. Used to set Presto (https://prestodb.io/docs/current/sql/set-session.html) Equivalent to using the --session flag in the Presto CLI
L
queryFileUriB" 6The HCFS URI of the script that contains SQL queries.
·
	queryListB:

dataproc%WorkflowTemplateJobPrestoJobQueryListXgcp:dataproc/WorkflowTemplateJobPrestoJobQueryList:WorkflowTemplateJobPrestoJobQueryListA list of queries.
:ì

dataproc)WorkflowTemplateJobPrestoJobLoggingConfig`gcp:dataproc/WorkflowTemplateJobPrestoJobLoggingConfig:WorkflowTemplateJobPrestoJobLoggingConfigÏ
ÌÉ
driverLogLevelsB2" ­The per-package log levels for the driver. This may include "root" package name to configure rootLogger. Examples: 'com.google = FATAL', 'root = INFO', 'org.apache = DEBUG'
:à

dataproc%WorkflowTemplateJobPrestoJobQueryListXgcp:dataproc/WorkflowTemplateJobPrestoJobQueryList:WorkflowTemplateJobPrestoJobQueryListÏ
ÌÉ
queries*" ·Required. The queries to execute. You do not need to end a query expression with a semicolon. Multiple queries can be specified in one string by separating each with a semicolon. Here is an example of a Dataproc API snippet that uses a QueryList to specify a HiveJob: "hiveJob": { "queryList": { "queries": } }
:É
s
dataprocWorkflowTemplateJobPysparkJobHgcp:dataproc/WorkflowTemplateJobPysparkJob:WorkflowTemplateJobPysparkJobÑ

Î
¦
archiveUrisB*" HCFS URIs of archives to be extracted into the working directory of each executor. Supported file types: .jar, .tar, .tar.gz, .tgz, and .zip.
Ê
argsB*" ¹The arguments to pass to the driver. Do not include arguments, such as `--conf`, that can be set as job properties, since a collision may occur that causes an incorrect job submission.

fileUrisB*" nHCFS URIs of files to be placed in the working directory of each executor. Useful for naively parallel tasks.
g
jarFileUrisB*" PHCFS URIs of jar files to add to the CLASSPATHs of the Python driver and tasks.
á
loggingConfig£B :

dataproc*WorkflowTemplateJobPysparkJobLoggingConfigbgcp:dataproc/WorkflowTemplateJobPysparkJobLoggingConfig:WorkflowTemplateJobPysparkJobLoggingConfig*The runtime log config for job execution.
r
mainPythonFileUri" YRequired. The HCFS URI of the main Python file to use as the driver. Must be a .py file.


propertiesB2" ïA mapping of property names to values, used to configure PySpark. Properties that conflict with values set by the Dataproc API may be overwritten. Can include properties set in /etc/spark/conf/spark-defaults.conf and classes in user code.

pythonFileUrisB*" lHCFS file URIs of Python files to pass to the PySpark framework. Supported file types: .py, .egg, and .zip.
:ï

dataproc*WorkflowTemplateJobPysparkJobLoggingConfigbgcp:dataproc/WorkflowTemplateJobPysparkJobLoggingConfig:WorkflowTemplateJobPysparkJobLoggingConfigÏ
ÌÉ
driverLogLevelsB2" ­The per-package log levels for the driver. This may include "root" package name to configure rootLogger. Examples: 'com.google = FATAL', 'root = INFO', 'org.apache = DEBUG'
:à
s
dataprocWorkflowTemplateJobSchedulingHgcp:dataproc/WorkflowTemplateJobScheduling:WorkflowTemplateJobSchedulingè
å¤
maxFailuresPerHourB Maximum number of times per hour a driver may be restarted as a result of driver exiting with non-zero code before job is reported failed. A job may be reported as thrashing if driver exits with non-zero code 4 times within 10 minute window. Maximum value is 10.
»
maxFailuresTotalB  Maximum number of times in total a driver may be restarted as a result of driver exiting with non-zero code before job is reported failed. Maximum value is 240
:µ
m
dataprocWorkflowTemplateJobSparkJobDgcp:dataproc/WorkflowTemplateJobSparkJob:WorkflowTemplateJobSparkJobÃ

À
¦
archiveUrisB*" HCFS URIs of archives to be extracted into the working directory of each executor. Supported file types: .jar, .tar, .tar.gz, .tgz, and .zip.
Ê
argsB*" ¹The arguments to pass to the driver. Do not include arguments, such as `--conf`, that can be set as job properties, since a collision may occur that causes an incorrect job submission.

fileUrisB*" nHCFS URIs of files to be placed in the working directory of each executor. Useful for naively parallel tasks.
f
jarFileUrisB*" OHCFS URIs of jar files to add to the CLASSPATHs of the Spark driver and tasks.
Û
loggingConfigB:

dataproc(WorkflowTemplateJobSparkJobLoggingConfig^gcp:dataproc/WorkflowTemplateJobSparkJobLoggingConfig:WorkflowTemplateJobSparkJobLoggingConfig*The runtime log config for job execution.
 
	mainClassB" The name of the driver's main class. The jar file that contains the class must be in the default CLASSPATH or specified in `jar_file_uris`.
S
mainJarFileUriB" ;The HCFS URI of the jar file that contains the main class.


propertiesB2" íA mapping of property names to values, used to configure Spark. Properties that conflict with values set by the Dataproc API may be overwritten. Can include properties set in /etc/spark/conf/spark-defaults.conf and classes in user code.
:é

dataproc(WorkflowTemplateJobSparkJobLoggingConfig^gcp:dataproc/WorkflowTemplateJobSparkJobLoggingConfig:WorkflowTemplateJobSparkJobLoggingConfigÏ
ÌÉ
driverLogLevelsB2" ­The per-package log levels for the driver. This may include "root" package name to configure rootLogger. Examples: 'com.google = FATAL', 'root = INFO', 'org.apache = DEBUG'
:Å	
p
dataprocWorkflowTemplateJobSparkRJobFgcp:dataproc/WorkflowTemplateJobSparkRJob:WorkflowTemplateJobSparkRJobÐ
Í¦
archiveUrisB*" HCFS URIs of archives to be extracted into the working directory of each executor. Supported file types: .jar, .tar, .tar.gz, .tgz, and .zip.
Ê
argsB*" ¹The arguments to pass to the driver. Do not include arguments, such as `--conf`, that can be set as job properties, since a collision may occur that causes an incorrect job submission.

fileUrisB*" nHCFS URIs of files to be placed in the working directory of each executor. Useful for naively parallel tasks.
Þ
loggingConfig B:

dataproc)WorkflowTemplateJobSparkRJobLoggingConfig`gcp:dataproc/WorkflowTemplateJobSparkRJobLoggingConfig:WorkflowTemplateJobSparkRJobLoggingConfig*The runtime log config for job execution.
g
mainRFileUri" SRequired. The HCFS URI of the main R file to use as the driver. Must be a .R file.


propertiesB2" îA mapping of property names to values, used to configure SparkR. Properties that conflict with values set by the Dataproc API may be overwritten. Can include properties set in /etc/spark/conf/spark-defaults.conf and classes in user code.
:ì

dataproc)WorkflowTemplateJobSparkRJobLoggingConfig`gcp:dataproc/WorkflowTemplateJobSparkRJobLoggingConfig:WorkflowTemplateJobSparkRJobLoggingConfigÏ
ÌÉ
driverLogLevelsB2" ­The per-package log levels for the driver. This may include "root" package name to configure rootLogger. Examples: 'com.google = FATAL', 'root = INFO', 'org.apache = DEBUG'
:
v
dataprocWorkflowTemplateJobSparkSqlJobJgcp:dataproc/WorkflowTemplateJobSparkSqlJob:WorkflowTemplateJobSparkSqlJob
R
jarFileUrisB*" ;HCFS URIs of jar files to be added to the Spark CLASSPATH.
ä
loggingConfig¦B£: 

dataproc+WorkflowTemplateJobSparkSqlJobLoggingConfigdgcp:dataproc/WorkflowTemplateJobSparkSqlJobLoggingConfig:WorkflowTemplateJobSparkSqlJobLoggingConfig*The runtime log config for job execution.
¸

propertiesB2" ¡A mapping of property names to values, used to configure Spark SQL's SparkConf. Properties that conflict with values set by the Dataproc API may be overwritten.
L
queryFileUriB" 6The HCFS URI of the script that contains SQL queries.
½
	queryListB:

dataproc'WorkflowTemplateJobSparkSqlJobQueryList\gcp:dataproc/WorkflowTemplateJobSparkSqlJobQueryList:WorkflowTemplateJobSparkSqlJobQueryListA list of queries.

scriptVariablesB2" fMapping of query variable names to values (equivalent to the Spark SQL command: SET `name="value";`).
:ò

dataproc+WorkflowTemplateJobSparkSqlJobLoggingConfigdgcp:dataproc/WorkflowTemplateJobSparkSqlJobLoggingConfig:WorkflowTemplateJobSparkSqlJobLoggingConfigÏ
ÌÉ
driverLogLevelsB2" ­The per-package log levels for the driver. This may include "root" package name to configure rootLogger. Examples: 'com.google = FATAL', 'root = INFO', 'org.apache = DEBUG'
:æ

dataproc'WorkflowTemplateJobSparkSqlJobQueryList\gcp:dataproc/WorkflowTemplateJobSparkSqlJobQueryList:WorkflowTemplateJobSparkSqlJobQueryListÏ
ÌÉ
queries*" ·Required. The queries to execute. You do not need to end a query expression with a semicolon. Multiple queries can be specified in one string by separating each with a semicolon. Here is an example of a Dataproc API snippet that uses a QueryList to specify a HiveJob: "hiveJob": { "queryList": { "queries": } }
:Ð
g
dataprocWorkflowTemplateParameter@gcp:dataproc/WorkflowTemplateParameter:WorkflowTemplateParameterä
áZ
descriptionB" EBrief description of the parameter. Must not exceed 1024 characters.
Ï
fields*" ¾Required. Paths to all fields that the parameter replaces. A field is allowed to appear in at most one parameter's list of field paths. A field path is similar in syntax to a .sparkJob.args
Ô
name" ÇRequired. Parameter name. The parameter name is used as the key, and paired with the parameter value, which are passed to the template when the template is instantiated. The name must contain only capital letters (A-Z), numbers (0-9), and underscores (_), and must not start with a number. The maximum length is 40 characters.
Ù

validationB:

dataproc#WorkflowTemplateParameterValidationTgcp:dataproc/WorkflowTemplateParameterValidation:WorkflowTemplateParameterValidation:Validation rules to be applied to this parameter's value.
:Á

dataproc#WorkflowTemplateParameterValidationTgcp:dataproc/WorkflowTemplateParameterValidation:WorkflowTemplateParameterValidation¶
³Ò
regexB:

dataproc(WorkflowTemplateParameterValidationRegex^gcp:dataproc/WorkflowTemplateParameterValidationRegex:WorkflowTemplateParameterValidationRegex)Validation based on regular expressions.
Û
values B:

dataproc)WorkflowTemplateParameterValidationValues`gcp:dataproc/WorkflowTemplateParameterValidationValues:WorkflowTemplateParameterValidationValues.Validation based on a list of allowed values.
:Ó

dataproc(WorkflowTemplateParameterValidationRegex^gcp:dataproc/WorkflowTemplateParameterValidationRegex:WorkflowTemplateParameterValidationRegex¹
¶³
regexes*" ¡Required. RE2 regular expressions used to validate the parameter's value. The value must match the regex in its entirety (substring matches are not sufficient).
:ä

dataproc)WorkflowTemplateParameterValidationValues`gcp:dataproc/WorkflowTemplateParameterValidationValues:WorkflowTemplateParameterValidationValuesH
FD
values*" 4Required. List of allowed values for the parameter.
:
g
dataprocWorkflowTemplatePlacement@gcp:dataproc/WorkflowTemplatePlacement:WorkflowTemplatePlacement
´
clusterSelectorB:

dataproc(WorkflowTemplatePlacementClusterSelector^gcp:dataproc/WorkflowTemplatePlacementClusterSelector:WorkflowTemplatePlacementClusterSelectorA selector that chooses target cluster for jobs based on metadata. The selector is evaluated at the time each job is submitted.
Ú
managedClusterB:

dataproc'WorkflowTemplatePlacementManagedCluster\gcp:dataproc/WorkflowTemplatePlacementManagedCluster:WorkflowTemplatePlacementManagedCluster+A cluster that is managed by the workflow.
:Á

dataproc(WorkflowTemplatePlacementClusterSelector^gcp:dataproc/WorkflowTemplatePlacementClusterSelector:WorkflowTemplatePlacementClusterSelector§
¤\
clusterLabels2" ERequired. The cluster labels. Cluster must have all labels to match.
Ã
zoneB" ´The zone where workflow process executes. This parameter does not affect the selection of the cluster. If unspecified, the zone of the first cluster matching the selector is used.
:©

dataproc'WorkflowTemplatePlacementManagedCluster\gcp:dataproc/WorkflowTemplatePlacementManagedCluster:WorkflowTemplatePlacementManagedCluster
·
clusterName" £Required. The cluster name prefix. A unique cluster name will be formed by appending a random suffix. The name must contain only lower-case letters (a-z), numbers (0-9), and hyphens (-). Must begin with a letter. Cannot begin or end with hyphen. Must consist of between 2 and 35 characters.
Û
config©:¦
£
dataproc-WorkflowTemplatePlacementManagedClusterConfighgcp:dataproc/WorkflowTemplatePlacementManagedClusterConfig:WorkflowTemplatePlacementManagedClusterConfig%Required. The cluster configuration.
ô
labelsB2" áThe labels to associate with this cluster. Label keys must be between 1 and 63 characters long, and must conform to the following PCRE regular expression: {0,63} No more than 32 labels can be associated with a given cluster.
:°-
£
dataproc-WorkflowTemplatePlacementManagedClusterConfighgcp:dataproc/WorkflowTemplatePlacementManagedClusterConfig:WorkflowTemplatePlacementManagedClusterConfig,
,ê
autoscalingConfigàBÝ:Ú
×
dataproc>WorkflowTemplatePlacementManagedClusterConfigAutoscalingConfiggcp:dataproc/WorkflowTemplatePlacementManagedClusterConfigAutoscalingConfig:WorkflowTemplatePlacementManagedClusterConfigAutoscalingConfigrAutoscaling config for the policy associated with the cluster. Cluster does not autoscale if this field is unset.

encryptionConfigÝBÚ:×
Ô
dataproc=WorkflowTemplatePlacementManagedClusterConfigEncryptionConfiggcp:dataproc/WorkflowTemplatePlacementManagedClusterConfigEncryptionConfig:WorkflowTemplatePlacementManagedClusterConfigEncryptionConfig%Encryption settings for the cluster.

endpointConfig×BÔ:Ñ
Î
dataproc;WorkflowTemplatePlacementManagedClusterConfigEndpointConfiggcp:dataproc/WorkflowTemplatePlacementManagedClusterConfigEndpointConfig:WorkflowTemplatePlacementManagedClusterConfigEndpointConfig-Port/endpoint configuration for this cluster
¾
gceClusterConfigÝBÚ:×
Ô
dataproc=WorkflowTemplatePlacementManagedClusterConfigGceClusterConfiggcp:dataproc/WorkflowTemplatePlacementManagedClusterConfigGceClusterConfig:WorkflowTemplatePlacementManagedClusterConfigGceClusterConfigJThe shared Compute Engine config settings for all instances in a cluster.

gkeClusterConfigÝBÚ:×
Ô
dataproc=WorkflowTemplatePlacementManagedClusterConfigGkeClusterConfiggcp:dataproc/WorkflowTemplatePlacementManagedClusterConfigGkeClusterConfig:WorkflowTemplatePlacementManagedClusterConfigGkeClusterConfigThe Kubernetes Engine config for Dataproc clusters deployed to Kubernetes. Setting this is considered mutually exclusive with Compute Engine-based options such as `gce_cluster_config`, `master_config`, `worker_config`, `secondary_worker_config`, and `autoscaling_config`.
Ñ
initializationActionsìBé*æ:ã
à
dataprocAWorkflowTemplatePlacementManagedClusterConfigInitializationActiongcp:dataproc/WorkflowTemplatePlacementManagedClusterConfigInitializationAction:WorkflowTemplatePlacementManagedClusterConfigInitializationActionÈCommands to execute on each node after config is completed. By default, executables are run on master and all worker nodes. You can test a node's `role` metadata to run an executable on a master or worker node, as shown below using `curl` (you can also use `wget`): ROLE=$(curl -H Metadata-Flavor:Google http://metadata/computeMetadata/v1/instance/attributes/dataproc-role) if ; then ... master specific actions ... else ... worker specific actions ... fi

lifecycleConfigÚB×:Ô
Ñ
dataproc<WorkflowTemplatePlacementManagedClusterConfigLifecycleConfiggcp:dataproc/WorkflowTemplatePlacementManagedClusterConfigLifecycleConfig:WorkflowTemplatePlacementManagedClusterConfigLifecycleConfig#Lifecycle setting for the cluster.
µ
masterConfigÑBÎ:Ë
È
dataproc9WorkflowTemplatePlacementManagedClusterConfigMasterConfiggcp:dataproc/WorkflowTemplatePlacementManagedClusterConfigMasterConfig:WorkflowTemplatePlacementManagedClusterConfigMasterConfigQThe Compute Engine config settings for additional worker instances in a cluster.

metastoreConfigÚB×:Ô
Ñ
dataproc<WorkflowTemplatePlacementManagedClusterConfigMetastoreConfiggcp:dataproc/WorkflowTemplatePlacementManagedClusterConfigMetastoreConfig:WorkflowTemplatePlacementManagedClusterConfigMetastoreConfigMetastore configuration.
Ù
secondaryWorkerConfigìBé:æ
ã
dataprocBWorkflowTemplatePlacementManagedClusterConfigSecondaryWorkerConfiggcp:dataproc/WorkflowTemplatePlacementManagedClusterConfigSecondaryWorkerConfig:WorkflowTemplatePlacementManagedClusterConfigSecondaryWorkerConfigQThe Compute Engine config settings for additional worker instances in a cluster.

securityConfig×BÔ:Ñ
Î
dataproc;WorkflowTemplatePlacementManagedClusterConfigSecurityConfiggcp:dataproc/WorkflowTemplatePlacementManagedClusterConfigSecurityConfig:WorkflowTemplatePlacementManagedClusterConfigSecurityConfig#Security settings for the cluster.
¡
softwareConfig×BÔ:Ñ
Î
dataproc;WorkflowTemplatePlacementManagedClusterConfigSoftwareConfiggcp:dataproc/WorkflowTemplatePlacementManagedClusterConfigSoftwareConfig:WorkflowTemplatePlacementManagedClusterConfigSoftwareConfig5The config settings for software inside the cluster.

stagingBucketB" ÿA Cloud Storage bucket used to stage job dependencies, config files, and job driver console output. If you do not specify a staging bucket, Cloud Dataproc will determine a Cloud Storage location (US, ASIA, or EU) for your cluster's staging bucket according to the Compute Engine zone where your cluster is deployed, and then create and manage this project-level, per-location bucket (see [Dataproc staging and temp buckets](https://cloud.google.com/dataproc/docs/concepts/configuring-clusters/staging-bucket)).
ú

tempBucketB" åA Cloud Storage bucket used to store ephemeral cluster and jobs data, such as Spark and MapReduce history files. If you do not specify a temp bucket, Dataproc will determine a Cloud Storage location (US, ASIA, or EU) for your cluster's temp bucket according to the Compute Engine zone where your cluster is deployed, and then create and manage this project-level, per-location bucket. The default bucket has a TTL of 90 days, but you can use any TTL (or none) if you specify a bucket.
¼
workerConfigÑBÎ:Ë
È
dataproc9WorkflowTemplatePlacementManagedClusterConfigWorkerConfiggcp:dataproc/WorkflowTemplatePlacementManagedClusterConfigWorkerConfig:WorkflowTemplatePlacementManagedClusterConfigWorkerConfigXThe Compute Engine config settings for additional worker instances in a cluster.

- - -
:í
×
dataproc>WorkflowTemplatePlacementManagedClusterConfigAutoscalingConfiggcp:dataproc/WorkflowTemplatePlacementManagedClusterConfigAutoscalingConfig:WorkflowTemplatePlacementManagedClusterConfigAutoscalingConfig

policyB" ùThe autoscaling policy used by the cluster. Only resource names including projectid and location (region) are valid. Examples: * `https://www.googleapis.com/compute/v1/projects/` Note that the policy must be in the same project and Dataproc region.
:Í
Ô
dataproc=WorkflowTemplatePlacementManagedClusterConfigEncryptionConfiggcp:dataproc/WorkflowTemplatePlacementManagedClusterConfigEncryptionConfig:WorkflowTemplatePlacementManagedClusterConfigEncryptionConfigt
rp
gcePdKmsKeyNameB" WThe Cloud KMS key name to use for PD disk encryption for all instances in the cluster.
:å
Î
dataproc;WorkflowTemplatePlacementManagedClusterConfigEndpointConfiggcp:dataproc/WorkflowTemplatePlacementManagedClusterConfigEndpointConfig:WorkflowTemplatePlacementManagedClusterConfigEndpointConfig

enableHttpPortAccessB
 gIf true, enable http access to specific ports on the cluster from external sources. Defaults to false.

	httpPortsB2" nOutput only. The map of port descriptions to URLs. Will only be populated if enable_http_port_access is true.
: 
Ô
dataproc=WorkflowTemplatePlacementManagedClusterConfigGceClusterConfiggcp:dataproc/WorkflowTemplatePlacementManagedClusterConfigGceClusterConfig:WorkflowTemplatePlacementManagedClusterConfigGceClusterConfigÃ
À­
internalIpOnlyB
 If true, all instances in the cluster will only have internal IP addresses. By default, clusters are not restricted to internal IP addresses, and will have ephemeral external IP addresses assigned to each instance. This `internal_ip_only` restriction can only be enabled for subnetwork enabled networks, and all off-cluster dependencies must be configured to be accessible without external IP addresses.
¥
metadataB2" The Compute Engine metadata entries to add to all instances (see [About VM metadata](https://cloud.google.com/compute/docs/metadata/overview)).
Ã
networkB" ±The Compute Engine network to be used for machine communications. Cannot be specified with subnetwork_uri. If neither `network_uri` nor `subnetwork_uri` is specified, the "default" network of the project is used, if it exists. Cannot be a "Custom Subnet Network" (see /regions/global/default` * `default`
Ö
nodeGroupAffinityB:

dataprocNWorkflowTemplatePlacementManagedClusterConfigGceClusterConfigNodeGroupAffinityªgcp:dataproc/WorkflowTemplatePlacementManagedClusterConfigGceClusterConfigNodeGroupAffinity:WorkflowTemplatePlacementManagedClusterConfigGceClusterConfigNodeGroupAffinity.Node Group Affinity for sole-tenant clusters.
³
privateIpv6GoogleAccessB" The type of IPv6 access for a cluster. Possible values: PRIVATE_IPV6_GOOGLE_ACCESS_UNSPECIFIED, INHERIT_FROM_SUBNETWORK, OUTBOUND, BIDIRECTIONAL
æ
reservationAffinityB:

dataprocPWorkflowTemplatePlacementManagedClusterConfigGceClusterConfigReservationAffinity®gcp:dataproc/WorkflowTemplatePlacementManagedClusterConfigGceClusterConfigReservationAffinity:WorkflowTemplatePlacementManagedClusterConfigGceClusterConfigReservationAffinity6Reservation Affinity for consuming Zonal reservation.
}
serviceAccountB" eThe (https://cloud.google.com/compute/docs/access/service-accounts#default_service_account) is used.
Ý
serviceAccountScopesB*" ¼The URIs of service account scopes to be included in Compute Engine instances. The following base set of scopes is always included: * https://www.googleapis.com/auth/cloud.useraccounts.readonly * https://www.googleapis.com/auth/devstorage.read_write * https://www.googleapis.com/auth/logging.write If no scopes are specified, the following defaults are also provided: * https://www.googleapis.com/auth/bigquery * https://www.googleapis.com/auth/bigtable.admin.table * https://www.googleapis.com/auth/bigtable.data * https://www.googleapis.com/auth/devstorage.full_control
ß
shieldedInstanceConfigB:

dataprocSWorkflowTemplatePlacementManagedClusterConfigGceClusterConfigShieldedInstanceConfig´gcp:dataproc/WorkflowTemplatePlacementManagedClusterConfigGceClusterConfigShieldedInstanceConfig:WorkflowTemplatePlacementManagedClusterConfigGceClusterConfigShieldedInstanceConfig¢Shielded Instance Config for clusters using [Compute Engine Shielded VMs](https://cloud.google.com/security/shielded-cloud/shielded-vm). Structure defined below.


subnetworkB" The Compute Engine subnetwork to be used for machine communications. Cannot be specified with network_uri. A full URL, partial URI, or short name are valid. Examples: * `https://www.googleapis.com/compute/v1/projects//regions/us-east1/subnetworks/sub0` * `sub0`

tagsB*" The Compute Engine tags to add to all instances (see [Manage tags for resources](https://cloud.google.com/compute/docs/tag-resources)).
¬
zoneB" The zone where the Compute Engine cluster will be located. On a create request, it is required in the "global" region. If omitted in a non-global Dataproc region, the service will pick a zone in the corresponding Compute Engine region. On a get request, zone will always be present. A full URL, partial URI, or short name are valid. Examples: * `https://www.googleapis.com/compute/v1/projects/` * `us-central1-f`
:

dataprocNWorkflowTemplatePlacementManagedClusterConfigGceClusterConfigNodeGroupAffinityªgcp:dataproc/WorkflowTemplatePlacementManagedClusterConfigGceClusterConfigNodeGroupAffinity:WorkflowTemplatePlacementManagedClusterConfigGceClusterConfigNodeGroupAffinityw
us
	nodeGroup" bRequired. The URI of a sole-tenant /zones/us-central1-a/nodeGroups/node-group-1` * `node-group-1`
:Ã

dataprocPWorkflowTemplatePlacementManagedClusterConfigGceClusterConfigReservationAffinity®gcp:dataproc/WorkflowTemplatePlacementManagedClusterConfigGceClusterConfigReservationAffinity:WorkflowTemplatePlacementManagedClusterConfigGceClusterConfigReservationAffinity°
­
consumeReservationTypeB" xType of reservation to consume Possible values: TYPE_UNSPECIFIED, NO_RESERVATION, ANY_RESERVATION, SPECIFIC_RESERVATION
C
keyB" 6Corresponds to the label key of reservation resource.
K
valuesB*" 9Corresponds to the label values of reservation resource.
:

dataprocSWorkflowTemplatePlacementManagedClusterConfigGceClusterConfigShieldedInstanceConfig´gcp:dataproc/WorkflowTemplatePlacementManagedClusterConfigGceClusterConfigShieldedInstanceConfig:WorkflowTemplatePlacementManagedClusterConfigGceClusterConfigShieldedInstanceConfigê
ç·
enableIntegrityMonitoringB
 Defines whether instances have [Integrity Monitoring](https://cloud.google.com/compute/shielded-vm/docs/shielded-vm#integrity-monitoring) enabled.

enableSecureBootB
 Defines whether instances have [Secure Boot](https://cloud.google.com/compute/shielded-vm/docs/shielded-vm#secure-boot) enabled.


enableVtpmB
 wDefines whether instances have the [vTPM](https://cloud.google.com/compute/shielded-vm/docs/shielded-vm#vtpm) enabled.
:Õ
Ô
dataproc=WorkflowTemplatePlacementManagedClusterConfigGkeClusterConfiggcp:dataproc/WorkflowTemplatePlacementManagedClusterConfigGkeClusterConfig:WorkflowTemplatePlacementManagedClusterConfigGkeClusterConfigû
øõ
namespacedGkeDeploymentTarget´B±:®
«
dataprocZWorkflowTemplatePlacementManagedClusterConfigGkeClusterConfigNamespacedGkeDeploymentTargetÂgcp:dataproc/WorkflowTemplatePlacementManagedClusterConfigGkeClusterConfigNamespacedGkeDeploymentTarget:WorkflowTemplatePlacementManagedClusterConfigGkeClusterConfigNamespacedGkeDeploymentTargetA target for the deployment.
:
«
dataprocZWorkflowTemplatePlacementManagedClusterConfigGkeClusterConfigNamespacedGkeDeploymentTargetÂgcp:dataproc/WorkflowTemplatePlacementManagedClusterConfigGkeClusterConfigNamespacedGkeDeploymentTarget:WorkflowTemplatePlacementManagedClusterConfigGkeClusterConfigNamespacedGkeDeploymentTargetÜ
ÙM
clusterNamespaceB" 3A namespace within the GKE cluster to deploy into.

targetGkeClusterB" mThe target GKE cluster to deploy to. Format: 'projects/{project}/locations/{location}/clusters/{cluster_id}'
:è
à
dataprocAWorkflowTemplatePlacementManagedClusterConfigInitializationActiongcp:dataproc/WorkflowTemplatePlacementManagedClusterConfigInitializationAction:WorkflowTemplatePlacementManagedClusterConfigInitializationAction
ÿH
executableFileB" 0Required. Cloud Storage URI of executable file.
²
executionTimeoutB" Amount of time executable has to complete. Default is 10 minutes (see JSON representation of [JSON Mapping - Language Guide (proto 3)](https://developers.google.com/protocol-buffers/docs/proto3#json)). Cluster creation fails with an explanatory error message (the name of the executable that caused the error and the exceeded timeout period) if the executable is not completed at end of the timeout period.
:æ

Ñ
dataproc<WorkflowTemplatePlacementManagedClusterConfigLifecycleConfiggcp:dataproc/WorkflowTemplatePlacementManagedClusterConfigLifecycleConfig:WorkflowTemplatePlacementManagedClusterConfigLifecycleConfig	
	Í
autoDeleteTimeB" ´The time when cluster will be auto-deleted (see JSON representation of [JSON Mapping - Language Guide (proto 3)](https://developers.google.com/protocol-buffers/docs/proto3#json)).
µ
autoDeleteTtlB" The lifetime duration of cluster. The cluster will be auto-deleted at the end of this period. Minimum value is 10 minutes; maximum value is 14 days (see JSON representation of [JSON Mapping - Language Guide (proto 3)](https://developers.google.com/protocol-buffers/docs/proto3#json)).
â
idleDeleteTtlB" ÊThe duration to keep the cluster alive while idling (when no jobs are running). Passing this threshold will cause the cluster to be deleted. Minimum value is 5 minutes; maximum value is 14 days (see JSON representation of [JSON Mapping - Language Guide (proto 3)](https://developers.google.com/protocol-buffers/docs/proto3#json).

idleStartTimeB" Output only. The time when cluster became idle (most recent job finished) and became eligible for deletion due to idleness (see JSON representation of [JSON Mapping - Language Guide (proto 3)](https://developers.google.com/protocol-buffers/docs/proto3#json)).
:¬
È
dataproc9WorkflowTemplatePlacementManagedClusterConfigMasterConfiggcp:dataproc/WorkflowTemplatePlacementManagedClusterConfigMasterConfig:WorkflowTemplatePlacementManagedClusterConfigMasterConfigÞ
ÛÊ
acceleratorsõBò*ï:ì
é
dataprocDWorkflowTemplatePlacementManagedClusterConfigMasterConfigAcceleratorgcp:dataproc/WorkflowTemplatePlacementManagedClusterConfigMasterConfigAccelerator:WorkflowTemplatePlacementManagedClusterConfigMasterConfigAcceleratorBThe Compute Engine accelerator configuration for these instances.


diskConfigïBì:é
æ
dataprocCWorkflowTemplatePlacementManagedClusterConfigMasterConfigDiskConfiggcp:dataproc/WorkflowTemplatePlacementManagedClusterConfigMasterConfigDiskConfig:WorkflowTemplatePlacementManagedClusterConfigMasterConfigDiskConfigDisk option config settings.
®
imageB" The Compute Engine image resource used for cluster instances. The URI can represent an image or image family. Image examples: * `https://www.googleapis.com/compute/beta/projects/` If the URI is unspecified, it will be inferred from `SoftwareConfig.image_version` or the system default.

instanceNamesB*" Output only. The list of instance names. Dataproc derives the names from `cluster_name`, `num_instances`, and the instance group.
g
isPreemptibleB
 POutput only. Specifies that this instance group contains preemptible instances.

machineTypeB" öThe Compute Engine machine type used for cluster instances. A full URL, partial URI, or short name are valid. Examples: * `https://www.googleapis.com/compute/v1/projects/(https://cloud.google.com/dataproc/docs/concepts/configuring-clusters/auto-zone#using_auto_zone_placement) feature, you must use the short name of the machine type resource, for example, `n1-standard-2`.
³
managedGroupConfigsB*:
þ
dataprocKWorkflowTemplatePlacementManagedClusterConfigMasterConfigManagedGroupConfig¤gcp:dataproc/WorkflowTemplatePlacementManagedClusterConfigMasterConfigManagedGroupConfig:WorkflowTemplatePlacementManagedClusterConfigMasterConfigManagedGroupConfigOutput only. The config for Compute Engine Instance Group Manager that manages this group. This is only used for preemptible instance groups.
º
minCpuPlatformB" ¡Specifies the minimum cpu platform for the Instance Group. See [Minimum CPU platform](https://cloud.google.com/dataproc/docs/concepts/compute/dataproc-min-cpu).
v
numInstancesB `The number of VM instances in the instance group. For master instance groups, must be set to 1.
¸
preemptibilityB" Specifies the preemptibility of the instance group. The default value for master and worker groups is `NON_PREEMPTIBLE`. This default cannot be changed. The default value for secondary instances is `PREEMPTIBLE`. Possible values: PREEMPTIBILITY_UNSPECIFIED, NON_PREEMPTIBLE, PREEMPTIBLE
:¯
é
dataprocDWorkflowTemplatePlacementManagedClusterConfigMasterConfigAcceleratorgcp:dataproc/WorkflowTemplatePlacementManagedClusterConfigMasterConfigAccelerator:WorkflowTemplatePlacementManagedClusterConfigMasterConfigAcceleratorÀ
½e
acceleratorCountB KThe number of the accelerator cards of this type exposed to this instance.
Ó
acceleratorTypeB" ¹Full URL, partial URI, or short name of the accelerator type resource to expose to this instance. See (https://cloud.google.com/dataproc/docs/concepts/configuring-clusters/auto-zone#using_auto_zone_placement) feature, you must use the short name of the accelerator type resource, for example, `nvidia-tesla-k80`.
:å
æ
dataprocCWorkflowTemplatePlacementManagedClusterConfigMasterConfigDiskConfiggcp:dataproc/WorkflowTemplatePlacementManagedClusterConfigMasterConfigDiskConfig:WorkflowTemplatePlacementManagedClusterConfigMasterConfigDiskConfigù
öH
bootDiskSizeGbB 0Size in GB of the boot disk (default is 500GB).
¸
bootDiskTypeB" ¡Type of the boot disk (default is "pd-standard"). Valid values: "pd-ssd" (Persistent Disk Solid State Drive) or "pd-standard" (Persistent Disk Hard Disk Drive).
î
numLocalSsdsB ×Number of attached SSDs, from 0 to 4 (default is 0). If SSDs are not attached, the boot disk is used to store runtime logs and (https://hadoop.apache.org/docs/r1.2.1/hdfs_user_guide.html) data. If one or more SSDs are attached, this runtime bulk data is spread across them, and the boot disk contains only basic config and installed binaries.
:ã
þ
dataprocKWorkflowTemplatePlacementManagedClusterConfigMasterConfigManagedGroupConfig¤gcp:dataproc/WorkflowTemplatePlacementManagedClusterConfigMasterConfigManagedGroupConfig:WorkflowTemplatePlacementManagedClusterConfigMasterConfigManagedGroupConfigß
Üf
instanceGroupManagerNameB" DOutput only. The name of the Instance Group Manager for this group.
r
instanceTemplateNameB" TOutput only. The name of the Instance Template used for the Managed Instance Group.
:Ô
Ñ
dataproc<WorkflowTemplatePlacementManagedClusterConfigMetastoreConfiggcp:dataproc/WorkflowTemplatePlacementManagedClusterConfigMetastoreConfig:WorkflowTemplatePlacementManagedClusterConfigMetastoreConfig~
|z
dataprocMetastoreService" ZRequired. Resource name of an existing Dataproc Metastore service. Example: * `projects/`
:â
ã
dataprocBWorkflowTemplatePlacementManagedClusterConfigSecondaryWorkerConfiggcp:dataproc/WorkflowTemplatePlacementManagedClusterConfigSecondaryWorkerConfig:WorkflowTemplatePlacementManagedClusterConfigSecondaryWorkerConfigù
öï
acceleratorsB*:

dataprocMWorkflowTemplatePlacementManagedClusterConfigSecondaryWorkerConfigAccelerator¨gcp:dataproc/WorkflowTemplatePlacementManagedClusterConfigSecondaryWorkerConfigAccelerator:WorkflowTemplatePlacementManagedClusterConfigSecondaryWorkerConfigAcceleratorLOptional. The Compute Engine accelerator configuration for these instances.
Â

diskConfigB:

dataprocLWorkflowTemplatePlacementManagedClusterConfigSecondaryWorkerConfigDiskConfig¦gcp:dataproc/WorkflowTemplatePlacementManagedClusterConfigSecondaryWorkerConfigDiskConfig:WorkflowTemplatePlacementManagedClusterConfigSecondaryWorkerConfigDiskConfig'Optional. Disk option config settings.
©
imageB" Optional. The Compute Engine image resource used for cluster instances. The URI can represent an image or image family. Image examples: * `https://www.googleapis.com/compute/beta/projects/[project_id]/global/images/[image-id]` * `projects/[project_id]/global/images/[image-id]` * `image-id` Image family examples. Dataproc will use the most recent image from the family: * `https://www.googleapis.com/compute/beta/projects/[project_id]/global/images/family/[custom-image-family-name]` * `projects/[project_id]/global/images/family/[custom-image-family-name]` If the URI is unspecified, it will be inferred from `SoftwareConfig.image_version` or the system default.

instanceNamesB*" Output only. The list of instance names. Dataproc derives the names from `cluster_name`, `num_instances`, and the instance group.
g
isPreemptibleB
 POutput only. Specifies that this instance group contains preemptible instances.
ô
machineTypeB" ÞOptional. The Compute Engine machine type used for cluster instances. A full URL, partial URI, or short name are valid. Examples: * `https://www.googleapis.com/compute/v1/projects/[project_id]/zones/us-east1-a/machineTypes/n1-standard-2` * `projects/[project_id]/zones/us-east1-a/machineTypes/n1-standard-2` * `n1-standard-2` **Auto Zone Exception**: If you are using the Dataproc [Auto Zone Placement](https://cloud.google.com/dataproc/docs/concepts/configuring-clusters/auto-zone#using_auto_zone_placement) feature, you must use the short name of the machine type resource, for example, `n1-standard-2`.
Î
managedGroupConfigs¥B¢*:

dataprocTWorkflowTemplatePlacementManagedClusterConfigSecondaryWorkerConfigManagedGroupConfig¶gcp:dataproc/WorkflowTemplatePlacementManagedClusterConfigSecondaryWorkerConfigManagedGroupConfig:WorkflowTemplatePlacementManagedClusterConfigSecondaryWorkerConfigManagedGroupConfigOutput only. The config for Compute Engine Instance Group Manager that manages this group. This is only used for preemptible instance groups.
Ï
minCpuPlatformB" ¶Optional. Specifies the minimum cpu platform for the Instance Group. See [Dataproc > Minimum CPU Platform](https://cloud.google.com/dataproc/docs/concepts/compute/dataproc-min-cpu).
©
numInstancesB Optional. The number of VM instances in the instance group. For [HA cluster](https://www.terraform.io/dataproc/docs/concepts/configuring-clusters/high-availability) master_config groups, **must be set to 3**. For standard cluster master_config groups, **must be set to 1**.
Â
preemptibilityB" ©Optional. Specifies the preemptibility of the instance group. The default value for master and worker groups is `NON_PREEMPTIBLE`. This default cannot be changed. The default value for secondary instances is `PREEMPTIBLE`. Possible values: PREEMPTIBILITY_UNSPECIFIED, NON_PREEMPTIBLE, PREEMPTIBLE
:Ê

dataprocMWorkflowTemplatePlacementManagedClusterConfigSecondaryWorkerConfigAccelerator¨gcp:dataproc/WorkflowTemplatePlacementManagedClusterConfigSecondaryWorkerConfigAccelerator:WorkflowTemplatePlacementManagedClusterConfigSecondaryWorkerConfigAcceleratorÀ
½e
acceleratorCountB KThe number of the accelerator cards of this type exposed to this instance.
Ó
acceleratorTypeB" ¹Full URL, partial URI, or short name of the accelerator type resource to expose to this instance. See (https://cloud.google.com/dataproc/docs/concepts/configuring-clusters/auto-zone#using_auto_zone_placement) feature, you must use the short name of the accelerator type resource, for example, `nvidia-tesla-k80`.
:

dataprocLWorkflowTemplatePlacementManagedClusterConfigSecondaryWorkerConfigDiskConfig¦gcp:dataproc/WorkflowTemplatePlacementManagedClusterConfigSecondaryWorkerConfigDiskConfig:WorkflowTemplatePlacementManagedClusterConfigSecondaryWorkerConfigDiskConfigù
öH
bootDiskSizeGbB 0Size in GB of the boot disk (default is 500GB).
¸
bootDiskTypeB" ¡Type of the boot disk (default is "pd-standard"). Valid values: "pd-ssd" (Persistent Disk Solid State Drive) or "pd-standard" (Persistent Disk Hard Disk Drive).
î
numLocalSsdsB ×Number of attached SSDs, from 0 to 4 (default is 0). If SSDs are not attached, the boot disk is used to store runtime logs and (https://hadoop.apache.org/docs/r1.2.1/hdfs_user_guide.html) data. If one or more SSDs are attached, this runtime bulk data is spread across them, and the boot disk contains only basic config and installed binaries.
:þ

dataprocTWorkflowTemplatePlacementManagedClusterConfigSecondaryWorkerConfigManagedGroupConfig¶gcp:dataproc/WorkflowTemplatePlacementManagedClusterConfigSecondaryWorkerConfigManagedGroupConfig:WorkflowTemplatePlacementManagedClusterConfigSecondaryWorkerConfigManagedGroupConfigß
Üf
instanceGroupManagerNameB" DOutput only. The name of the Instance Group Manager for this group.
r
instanceTemplateNameB" TOutput only. The name of the Instance Template used for the Managed Instance Group.
:
Î
dataproc;WorkflowTemplatePlacementManagedClusterConfigSecurityConfiggcp:dataproc/WorkflowTemplatePlacementManagedClusterConfigSecurityConfig:WorkflowTemplatePlacementManagedClusterConfigSecurityConfig¼
¹¶
kerberosConfigBþ:û
ø
dataprocIWorkflowTemplatePlacementManagedClusterConfigSecurityConfigKerberosConfig gcp:dataproc/WorkflowTemplatePlacementManagedClusterConfigSecurityConfigKerberosConfig:WorkflowTemplatePlacementManagedClusterConfigSecurityConfigKerberosConfig Kerberos related configuration.
:ù
ø
dataprocIWorkflowTemplatePlacementManagedClusterConfigSecurityConfigKerberosConfig gcp:dataproc/WorkflowTemplatePlacementManagedClusterConfigSecurityConfigKerberosConfig:WorkflowTemplatePlacementManagedClusterConfigSecurityConfigKerberosConfigû
ø
crossRealmTrustAdminServerB" dThe admin server (IP or hostname) for the remote trusted realm in a cross realm trust relationship.
w
crossRealmTrustKdcB" [The KDC (IP or hostname) for the remote trusted realm in a cross realm trust relationship.

crossRealmTrustRealmB" cThe remote realm the Dataproc on-cluster KDC will trust, should the user enable cross realm trust.
Þ
crossRealmTrustSharedPasswordB" ¶The Cloud Storage URI of a KMS encrypted file containing the shared password between the on-cluster Kerberos realm and the remote trusted realm, in a cross realm trust relationship.

enableKerberosB
 |Flag to indicate whether to Kerberize the cluster (default: false). Set this field to true to enable Kerberos on a cluster.
o
kdcDbKeyB" ]The Cloud Storage URI of a KMS encrypted file containing the master key of the KDC database.
¿
keyPasswordB" ©The Cloud Storage URI of a KMS encrypted file containing the password to the user provided key. For the self-signed certificate, this password is generated by Dataproc.

keystoreB" The Cloud Storage URI of the keystore file used for SSL encryption. If not provided, Dataproc will provide a self-signed certificate.
É
keystorePasswordB" ®The Cloud Storage URI of a KMS encrypted file containing the password to the user provided keystore. For the self-signed certificate, this password is generated by Dataproc.
P
kmsKeyB" @The uri of the KMS key used to encrypt various sensitive files.

realmB" sThe name of the on-cluster Kerberos realm. If not specified, the uppercased domain of hostnames will be the realm.
u
rootPrincipalPasswordB" VThe Cloud Storage URI of a KMS encrypted file containing the root principal password.

tgtLifetimeHoursB The lifetime of the ticket granting ticket, in hours. If not specified, or user specifies 0, then default value 10 will be used.


truststoreB" The Cloud Storage URI of the truststore file used for SSL encryption. If not provided, Dataproc will provide a self-signed certificate.
Í
truststorePasswordB" °The Cloud Storage URI of a KMS encrypted file containing the password to the user provided truststore. For the self-signed certificate, this password is generated by Dataproc.
:×

Î
dataproc;WorkflowTemplatePlacementManagedClusterConfigSoftwareConfiggcp:dataproc/WorkflowTemplatePlacementManagedClusterConfigSoftwareConfig:WorkflowTemplatePlacementManagedClusterConfigSoftwareConfig	
	Õ
imageVersionB" ¾The version of software inside the cluster. It must be one of the supported [Dataproc Versions](https://cloud.google.com/dataproc/docs/concepts/versioning/dataproc-versions#supported_dataproc_versions), such as "1.2" (including a subminor version, such as "1.2.29"), or the ["preview" version](https://cloud.google.com/dataproc/docs/concepts/versioning/dataproc-versions#other_versions). If unspecified, it defaults to the latest Debian version.
P
optionalComponentsB*" 2The set of components to activate on the cluster.
Ó

propertiesB2" ¼The properties to set on daemon config files.

Property keys are specified in `prefix:property` format, for example `core:hadoop.tmp.dir`. The following are supported prefixes and their mappings:

* capacity-scheduler: `capacity-scheduler.xml`
* core: `core-site.xml`
* distcp: `distcp-default.xml`
* hdfs: `hdfs-site.xml`
* hive: `hive-site.xml`
* mapred: `mapred-site.xml`
* pig: `pig.properties`
* spark: `spark-defaults.conf`
* yarn: `yarn-site.xml`


For more information, see [Cluster properties](https://cloud.google.com/dataproc/docs/concepts/cluster-properties).
:ö
È
dataproc9WorkflowTemplatePlacementManagedClusterConfigWorkerConfiggcp:dataproc/WorkflowTemplatePlacementManagedClusterConfigWorkerConfig:WorkflowTemplatePlacementManagedClusterConfigWorkerConfig¨
¥Ô
acceleratorsõBò*ï:ì
é
dataprocDWorkflowTemplatePlacementManagedClusterConfigWorkerConfigAcceleratorgcp:dataproc/WorkflowTemplatePlacementManagedClusterConfigWorkerConfigAccelerator:WorkflowTemplatePlacementManagedClusterConfigWorkerConfigAcceleratorLOptional. The Compute Engine accelerator configuration for these instances.
§

diskConfigïBì:é
æ
dataprocCWorkflowTemplatePlacementManagedClusterConfigWorkerConfigDiskConfiggcp:dataproc/WorkflowTemplatePlacementManagedClusterConfigWorkerConfigDiskConfig:WorkflowTemplatePlacementManagedClusterConfigWorkerConfigDiskConfig'Optional. Disk option config settings.
©
imageB" Optional. The Compute Engine image resource used for cluster instances. The URI can represent an image or image family. Image examples: * `https://www.googleapis.com/compute/beta/projects/[project_id]/global/images/[image-id]` * `projects/[project_id]/global/images/[image-id]` * `image-id` Image family examples. Dataproc will use the most recent image from the family: * `https://www.googleapis.com/compute/beta/projects/[project_id]/global/images/family/[custom-image-family-name]` * `projects/[project_id]/global/images/family/[custom-image-family-name]` If the URI is unspecified, it will be inferred from `SoftwareConfig.image_version` or the system default.

instanceNamesB*" Output only. The list of instance names. Dataproc derives the names from `cluster_name`, `num_instances`, and the instance group.
g
isPreemptibleB
 POutput only. Specifies that this instance group contains preemptible instances.
ô
machineTypeB" ÞOptional. The Compute Engine machine type used for cluster instances. A full URL, partial URI, or short name are valid. Examples: * `https://www.googleapis.com/compute/v1/projects/[project_id]/zones/us-east1-a/machineTypes/n1-standard-2` * `projects/[project_id]/zones/us-east1-a/machineTypes/n1-standard-2` * `n1-standard-2` **Auto Zone Exception**: If you are using the Dataproc [Auto Zone Placement](https://cloud.google.com/dataproc/docs/concepts/configuring-clusters/auto-zone#using_auto_zone_placement) feature, you must use the short name of the machine type resource, for example, `n1-standard-2`.
³
managedGroupConfigsB*:
þ
dataprocKWorkflowTemplatePlacementManagedClusterConfigWorkerConfigManagedGroupConfig¤gcp:dataproc/WorkflowTemplatePlacementManagedClusterConfigWorkerConfigManagedGroupConfig:WorkflowTemplatePlacementManagedClusterConfigWorkerConfigManagedGroupConfigOutput only. The config for Compute Engine Instance Group Manager that manages this group. This is only used for preemptible instance groups.
Ï
minCpuPlatformB" ¶Optional. Specifies the minimum cpu platform for the Instance Group. See [Dataproc > Minimum CPU Platform](https://cloud.google.com/dataproc/docs/concepts/compute/dataproc-min-cpu).
©
numInstancesB Optional. The number of VM instances in the instance group. For [HA cluster](https://www.terraform.io/dataproc/docs/concepts/configuring-clusters/high-availability) master_config groups, **must be set to 3**. For standard cluster master_config groups, **must be set to 1**.
Â
preemptibilityB" ©Optional. Specifies the preemptibility of the instance group. The default value for master and worker groups is `NON_PREEMPTIBLE`. This default cannot be changed. The default value for secondary instances is `PREEMPTIBLE`. Possible values: PREEMPTIBILITY_UNSPECIFIED, NON_PREEMPTIBLE, PREEMPTIBLE
:¯
é
dataprocDWorkflowTemplatePlacementManagedClusterConfigWorkerConfigAcceleratorgcp:dataproc/WorkflowTemplatePlacementManagedClusterConfigWorkerConfigAccelerator:WorkflowTemplatePlacementManagedClusterConfigWorkerConfigAcceleratorÀ
½e
acceleratorCountB KThe number of the accelerator cards of this type exposed to this instance.
Ó
acceleratorTypeB" ¹Full URL, partial URI, or short name of the accelerator type resource to expose to this instance. See (https://cloud.google.com/dataproc/docs/concepts/configuring-clusters/auto-zone#using_auto_zone_placement) feature, you must use the short name of the accelerator type resource, for example, `nvidia-tesla-k80`.
:å
æ
dataprocCWorkflowTemplatePlacementManagedClusterConfigWorkerConfigDiskConfiggcp:dataproc/WorkflowTemplatePlacementManagedClusterConfigWorkerConfigDiskConfig:WorkflowTemplatePlacementManagedClusterConfigWorkerConfigDiskConfigù
öH
bootDiskSizeGbB 0Size in GB of the boot disk (default is 500GB).
¸
bootDiskTypeB" ¡Type of the boot disk (default is "pd-standard"). Valid values: "pd-ssd" (Persistent Disk Solid State Drive) or "pd-standard" (Persistent Disk Hard Disk Drive).
î
numLocalSsdsB ×Number of attached SSDs, from 0 to 4 (default is 0). If SSDs are not attached, the boot disk is used to store runtime logs and (https://hadoop.apache.org/docs/r1.2.1/hdfs_user_guide.html) data. If one or more SSDs are attached, this runtime bulk data is spread across them, and the boot disk contains only basic config and installed binaries.
:ã
þ
dataprocKWorkflowTemplatePlacementManagedClusterConfigWorkerConfigManagedGroupConfig¤gcp:dataproc/WorkflowTemplatePlacementManagedClusterConfigWorkerConfigManagedGroupConfig:WorkflowTemplatePlacementManagedClusterConfigWorkerConfigManagedGroupConfigß
Üf
instanceGroupManagerNameB" DOutput only. The name of the Instance Group Manager for this group.
r
instanceTemplateNameB" TOutput only. The name of the Instance Template used for the Managed Instance Group.
:á

dataproc#getMetastoreServiceEncryptionConfigTgcp:dataproc/getMetastoreServiceEncryptionConfig:getMetastoreServiceEncryptionConfigÖ
ÓÐ
kmsKey" ÁThe fully qualified customer provided Cloud KMS key name to use for customer data encryption.
Use the following format: 'projects/([^/]+)/locations/([^/]+)/keyRings/([^/]+)/cryptoKeys/([^/]+)'
:

dataproc&getMetastoreServiceHiveMetastoreConfigZgcp:dataproc/getMetastoreServiceHiveMetastoreConfig:getMetastoreServiceHiveMetastoreConfig÷
ôì
auxiliaryVersionsÇ*Ä:Á
¾
dataproc6getMetastoreServiceHiveMetastoreConfigAuxiliaryVersionzgcp:dataproc/getMetastoreServiceHiveMetastoreConfigAuxiliaryVersion:getMetastoreServiceHiveMetastoreConfigAuxiliaryVersionA mapping of Hive metastore version to the auxiliary version configuration.
When specified, a secondary Hive metastore service is created along with the primary service.
All auxiliary versions must be less than the service's primary version.
The key is the auxiliary service name and it must match the regular expression a-z?.
This means that the first character must be a lowercase letter, and all the following characters must be hyphens, lowercase letters, or digits, except the last character, which cannot be a hyphen.
Ù
configOverrides2" ¿A mapping of Hive metastore configuration key-value pairs to apply to the Hive metastore (configured in hive-site.xml).
The mappings override system defaults (some keys cannot be overridden)
³
endpointProtocol" The protocol to use for the metastore service endpoint. If unspecified, defaults to 'THRIFT'. Default value: "THRIFT" Possible values: ["THRIFT", "GRPC"]
¼
kerberosConfigsÁ*¾:»
¸
dataproc4getMetastoreServiceHiveMetastoreConfigKerberosConfigvgcp:dataproc/getMetastoreServiceHiveMetastoreConfigKerberosConfig:getMetastoreServiceHiveMetastoreConfigKerberosConfigeInformation used to configure the Hive metastore service as a service principal in a Kerberos realm.
2
version" #The Hive metastore schema version.
:Ð
¾
dataproc6getMetastoreServiceHiveMetastoreConfigAuxiliaryVersionzgcp:dataproc/getMetastoreServiceHiveMetastoreConfigAuxiliaryVersion:getMetastoreServiceHiveMetastoreConfigAuxiliaryVersion
ñ
configOverrides2" ×A mapping of Hive metastore configuration key-value pairs to apply to the auxiliary Hive metastore (configured in hive-site.xml) in addition to the primary version's overrides.
If keys are present in both the auxiliary version's overrides and the primary version's overrides, the value from the auxiliary version's overrides takes precedence.
	
key" 
version" xThe Hive metastore version of the auxiliary service. It must be less than the primary Hive metastore service's version.
:¼
¸
dataproc4getMetastoreServiceHiveMetastoreConfigKerberosConfigvgcp:dataproc/getMetastoreServiceHiveMetastoreConfigKerberosConfig:getMetastoreServiceHiveMetastoreConfigKerberosConfigþ
ûÝ
keytabsÔ*Ñ:Î
Ë
dataproc:getMetastoreServiceHiveMetastoreConfigKerberosConfigKeytabgcp:dataproc/getMetastoreServiceHiveMetastoreConfigKerberosConfigKeytab:getMetastoreServiceHiveMetastoreConfigKerberosConfigKeytab{A Kerberos keytab file that can be used to authenticate a service principal with a Kerberos Key Distribution Center (KDC).
Ô
krb5ConfigGcsUri" »A Cloud Storage URI that specifies the path to a krb5.conf file. It is of the form gs://{bucket_name}/path/to/krb5.conf, although the file does not need to be named krb5.conf explicitly.
Á
	principal" ¯A Kerberos principal that exists in the both the keytab the KDC to authenticate as. A typical principal is of the form "primary/instance@REALM", but there is no exact format.
:
Ë
dataproc:getMetastoreServiceHiveMetastoreConfigKerberosConfigKeytabgcp:dataproc/getMetastoreServiceHiveMetastoreConfigKerberosConfigKeytab:getMetastoreServiceHiveMetastoreConfigKerberosConfigKeytab·
´±
cloudSecret" The relative resource name of a Secret Manager secret version, in the following form:

"projects/{projectNumber}/secrets/{secret_id}/versions/{version_id}".
:ñ

dataproc$getMetastoreServiceMaintenanceWindowVgcp:dataproc/getMetastoreServiceMaintenanceWindow:getMetastoreServiceMaintenanceWindowã
à
	dayOfWeek" The day of week, when the window starts. Possible values: ["MONDAY", "TUESDAY", "WEDNESDAY", "THURSDAY", "FRIDAY", "SATURDAY", "SUNDAY"]
@
	hourOfDay /The hour of day (0-23) when the window starts.
:²

dataproc&getMetastoreServiceMetadataIntegrationZgcp:dataproc/getMetastoreServiceMetadataIntegration:getMetastoreServiceMetadataIntegration

dataCatalogConfigsÊ*Ç:Ä
Á
dataproc7getMetastoreServiceMetadataIntegrationDataCatalogConfig|gcp:dataproc/getMetastoreServiceMetadataIntegrationDataCatalogConfig:getMetastoreServiceMetadataIntegrationDataCatalogConfig5The integration config for the Data Catalog service.
:ò
Á
dataproc7getMetastoreServiceMetadataIntegrationDataCatalogConfig|gcp:dataproc/getMetastoreServiceMetadataIntegrationDataCatalogConfig:getMetastoreServiceMetadataIntegrationDataCatalogConfig«
¨¥
enabled
 Defines whether the metastore metadata should be synced to Data Catalog. The default value is to disable syncing metastore metadata to Data Catalog.
:
|
dataproc getMetastoreServiceNetworkConfigNgcp:dataproc/getMetastoreServiceNetworkConfig:getMetastoreServiceNetworkConfig
ú
	consumers*:

dataproc(getMetastoreServiceNetworkConfigConsumer^gcp:dataproc/getMetastoreServiceNetworkConfigConsumer:getMetastoreServiceNetworkConfigConsumerMThe consumer-side network configuration for the Dataproc Metastore instance.

customRoutesEnabled
 kEnables custom routes to be imported and exported for the Dataproc Metastore service's peered VPC network.
:»

dataproc(getMetastoreServiceNetworkConfigConsumer^gcp:dataproc/getMetastoreServiceNetworkConfigConsumer:getMetastoreServiceNetworkConfigConsumer¡
Q
endpointUri" >The URI of the endpoint used to access the metastore service.
È

subnetwork" µThe subnetwork of the customer project from which an IP address is reserved and used as the Dataproc Metastore service's endpoint.
It is accessible to hosts in the subnet and to all hosts in a subnet in the same region and same network.
There must be at least one IP address available in the subnet's primary range. The subnet is specified in the following form:
'projects/{projectNumber}/regions/{region_id}/subnetworks/{subnetwork_id}
:
|
dataproc getMetastoreServiceScalingConfigNgcp:dataproc/getMetastoreServiceScalingConfig:getMetastoreServiceScalingConfig

autoscalingConfigs¸*µ:²
¯
dataproc1getMetastoreServiceScalingConfigAutoscalingConfigpgcp:dataproc/getMetastoreServiceScalingConfigAutoscalingConfig:getMetastoreServiceScalingConfigAutoscalingConfigARepresents the autoscaling configuration of a metastore service.
z
instanceSize" fMetastore instance sizes. Possible values: ["EXTRA_SMALL", "SMALL", "MEDIUM", "LARGE", "EXTRA_LARGE"]

scalingFactor rScaling factor, in increments of 0.1 for values less than 1.0, and increments of 1.0 for values greater than 1.0.
:Ã
¯
dataproc1getMetastoreServiceScalingConfigAutoscalingConfigpgcp:dataproc/getMetastoreServiceScalingConfigAutoscalingConfig:getMetastoreServiceScalingConfigAutoscalingConfig
^
autoscalingEnabled
 DDefines whether autoscaling is enabled. The default value is false.
¨
limitConfigsÚ*×:Ô
Ñ
dataproc<getMetastoreServiceScalingConfigAutoscalingConfigLimitConfiggcp:dataproc/getMetastoreServiceScalingConfigAutoscalingConfigLimitConfig:getMetastoreServiceScalingConfigAutoscalingConfigLimitConfig;Represents the limit configuration of a metastore service.
:À
Ñ
dataproc<getMetastoreServiceScalingConfigAutoscalingConfigLimitConfiggcp:dataproc/getMetastoreServiceScalingConfigAutoscalingConfigLimitConfig:getMetastoreServiceScalingConfigAutoscalingConfigLimitConfigé
æq
maxScalingFactor YThe maximum scaling factor that the service will autoscale to. The default value is 6.0.
q
minScalingFactor YThe minimum scaling factor that the service will autoscale to. The default value is 0.1.
:

dataproc"getMetastoreServiceScheduledBackupRgcp:dataproc/getMetastoreServiceScheduledBackup:getMetastoreServiceScheduledBackup
½
backupLocation" ¦A Cloud Storage URI of a folder, in the format gs://<bucket_name>/<path_inside_bucket>. A sub-folder <backup_folder> containing backup files will be stored below it.
É
cronSchedule" ´The scheduled interval in Cron format, see https://en.wikipedia.org/wiki/Cron The default is empty: scheduled backup is not enabled. Must be specified to enable scheduled backups.
\
enabled
 MDefines whether the scheduled backup is enabled. The default value is false.

timeZone" Specifies the time zone to be used when interpreting cronSchedule. Must be a time zone name from the time zone database (https://en.wikipedia.org/wiki/List_of_tz_database_time_zones), e.g. America/Los_Angeles or Africa/Abidjan. If left unspecified, the default is UTC.
:

dataproc"getMetastoreServiceTelemetryConfigRgcp:dataproc/getMetastoreServiceTelemetryConfig:getMetastoreServiceTelemetryConfig

	logFormat" vThe output format of the Dataproc Metastore service's logs. Default value: "JSON" Possible values: ["LEGACY", "JSON"]
:


datastream ConnectionProfileBigqueryProfilePgcp:datastream/ConnectionProfileBigqueryProfile:ConnectionProfileBigqueryProfile
 :


datastream'ConnectionProfileForwardSshConnectivity^gcp:datastream/ConnectionProfileForwardSshConnectivity:ConnectionProfileForwardSshConnectivityë
è-
hostname" Hostname for the SSH tunnel.
l
passwordB" ZSSH password.
**Note**: This property is sensitive and will not be displayed in the plan.
'
portB Port for the SSH tunnel.
q

privateKeyB" ]SSH private key.
**Note**: This property is sensitive and will not be displayed in the plan.
-
username" Username for the SSH tunnel.
:é
q

datastreamConnectionProfileGcsProfileFgcp:datastream/ConnectionProfileGcsProfile:ConnectionProfileGcsProfilet
r-
bucket" The Cloud Storage bucket name.
A
rootPathB" /The root path inside the Cloud Storage bucket.
:
w

datastreamConnectionProfileMysqlProfileJgcp:datastream/ConnectionProfileMysqlProfile:ConnectionProfileMysqlProfile
3
hostname" #Hostname for the MySQL connection.

password" oPassword for the MySQL connection.
**Note**: This property is sensitive and will not be displayed in the plan.
-
portB Port for the MySQL connection.
ö
	sslConfigB:


datastream&ConnectionProfileMysqlProfileSslConfig\gcp:datastream/ConnectionProfileMysqlProfileSslConfig:ConnectionProfileMysqlProfileSslConfigKSSL configuration for the MySQL connection.
Structure is documented below.
3
username" #Username for the MySQL connection.
:	


datastream&ConnectionProfileMysqlProfileSslConfig\gcp:datastream/ConnectionProfileMysqlProfileSslConfig:ConnectionProfileMysqlProfileSslConfigú
÷¼
caCertificateB" ¤PEM-encoded certificate of the CA that signed the source database
server's certificate.
**Note**: This property is sensitive and will not be displayed in the plan.
Q
caCertificateSetB
 7(Output)
Indicates whether the clientKey field is set.
®
clientCertificateB" PEM-encoded certificate that will be used by the replica to
authenticate against the source database server. If this field
is used then the 'clientKey' and the 'caCertificate' fields are
mandatory.
**Note**: This property is sensitive and will not be displayed in the plan.
]
clientCertificateSetB
 ?(Output)
Indicates whether the clientCertificate field is set.

	clientKeyB" ïPEM-encoded private key associated with the Client Certificate.
If this field is used then the 'client_certificate' and the
'ca_certificate' fields are mandatory.
**Note**: This property is sensitive and will not be displayed in the plan.
M
clientKeySetB
 7(Output)
Indicates whether the clientKey field is set.
:
z

datastreamConnectionProfileOracleProfileLgcp:datastream/ConnectionProfileOracleProfile:ConnectionProfileOracleProfile
=
connectionAttributesB2" Connection string attributes
;
databaseService" $Database for the Oracle connection.
4
hostname" $Hostname for the Oracle connection.

password" pPassword for the Oracle connection.
**Note**: This property is sensitive and will not be displayed in the plan.
.
portB  Port for the Oracle connection.
4
username" $Username for the Oracle connection.
:ø


datastream"ConnectionProfilePostgresqlProfileTgcp:datastream/ConnectionProfilePostgresqlProfile:ConnectionProfilePostgresqlProfileì
é8
database" (Database for the PostgreSQL connection.
8
hostname" (Hostname for the PostgreSQL connection.

password" tPassword for the PostgreSQL connection.
**Note**: This property is sensitive and will not be displayed in the plan.
2
portB $Port for the PostgreSQL connection.
8
username" (Username for the PostgreSQL connection.
:«


datastream$ConnectionProfilePrivateConnectivityXgcp:datastream/ConnectionProfilePrivateConnectivity:ConnectionProfilePrivateConnectivity

privateConnection" zA reference to a private connection resource. Format: `projects/{project}/locations/{location}/privateConnections/{name}`
:õ


datastream!ConnectionProfileSqlServerProfileRgcp:datastream/ConnectionProfileSqlServerProfile:ConnectionProfileSqlServerProfileì
é8
database" (Database for the SQL Server connection.
8
hostname" (Hostname for the SQL Server connection.

password" tPassword for the SQL Server connection.
**Note**: This property is sensitive and will not be displayed in the plan.
2
portB $Port for the SQL Server connection.
8
username" (Username for the SQL Server connection.
:
b

datastreamPrivateConnectionError<gcp:datastream/PrivateConnectionError:PrivateConnectionError¡
D
detailsB2" 1A list of messages that carry the error details.
V
messageB" EA message containing more information about the error that occurred.
:Ë


datastream!PrivateConnectionVpcPeeringConfigRgcp:datastream/PrivateConnectionVpcPeeringConfig:PrivateConnectionVpcPeeringConfigÂ
¿>
subnet" 0A free subnet for peering. (CIDR of /29)

- - -
}
vpc" rFully qualified name of the VPC that Datastream will peer to.
Format: projects/{project}/global/{networks}/{name}
:¦	
S

datastreamStreamBackfillAll2gcp:datastream/StreamBackfillAll:StreamBackfillAllÎ
Ë
mysqlExcludedObjectsB:


datastream%StreamBackfillAllMysqlExcludedObjectsZgcp:datastream/StreamBackfillAllMysqlExcludedObjects:StreamBackfillAllMysqlExcludedObjectsOMySQL data source objects to avoid backfilling.
Structure is documented below.

oracleExcludedObjectsB:


datastream&StreamBackfillAllOracleExcludedObjects\gcp:datastream/StreamBackfillAllOracleExcludedObjects:StreamBackfillAllOracleExcludedObjectsTPostgreSQL data source objects to avoid backfilling.
Structure is documented below.

postgresqlExcludedObjects§B¤:¡


datastream*StreamBackfillAllPostgresqlExcludedObjectsdgcp:datastream/StreamBackfillAllPostgresqlExcludedObjects:StreamBackfillAllPostgresqlExcludedObjectsTPostgreSQL data source objects to avoid backfilling.
Structure is documented below.

sqlServerExcludedObjects¤B¡:


datastream)StreamBackfillAllSqlServerExcludedObjectsbgcp:datastream/StreamBackfillAllSqlServerExcludedObjects:StreamBackfillAllSqlServerExcludedObjectsTSQL Server data source objects to avoid backfilling.
Structure is documented below.
:¬


datastream%StreamBackfillAllMysqlExcludedObjectsZgcp:datastream/StreamBackfillAllMysqlExcludedObjects:StreamBackfillAllMysqlExcludedObjects

mysqlDatabases¿*¼:¹
¶

datastream2StreamBackfillAllMysqlExcludedObjectsMysqlDatabasetgcp:datastream/StreamBackfillAllMysqlExcludedObjectsMysqlDatabase:StreamBackfillAllMysqlExcludedObjectsMysqlDatabase=MySQL databases on the server
Structure is documented below.
:
¶

datastream2StreamBackfillAllMysqlExcludedObjectsMysqlDatabasetgcp:datastream/StreamBackfillAllMysqlExcludedObjectsMysqlDatabase:StreamBackfillAllMysqlExcludedObjectsMysqlDatabaseÑ
Î
database" Database name.
ª
mysqlTablesáBÞ*Û:Ø
Õ

datastream<StreamBackfillAllMysqlExcludedObjectsMysqlDatabaseMysqlTablegcp:datastream/StreamBackfillAllMysqlExcludedObjectsMysqlDatabaseMysqlTable:StreamBackfillAllMysqlExcludedObjectsMysqlDatabaseMysqlTable7Tables in the database.
Structure is documented below.
:¡
Õ

datastream<StreamBackfillAllMysqlExcludedObjectsMysqlDatabaseMysqlTablegcp:datastream/StreamBackfillAllMysqlExcludedObjectsMysqlDatabaseMysqlTable:StreamBackfillAllMysqlExcludedObjectsMysqlDatabaseMysqlTableÆ
Ã¥
mysqlColumnsBÿ*ü:ù
ö

datastreamGStreamBackfillAllMysqlExcludedObjectsMysqlDatabaseMysqlTableMysqlColumngcp:datastream/StreamBackfillAllMysqlExcludedObjectsMysqlDatabaseMysqlTableMysqlColumn:StreamBackfillAllMysqlExcludedObjectsMysqlDatabaseMysqlTableMysqlColumnMySQL columns in the schema. When unspecified as part of include/exclude objects, includes/excludes everything.
Structure is documented below.

table" Table name.
:Ö
ö

datastreamGStreamBackfillAllMysqlExcludedObjectsMysqlDatabaseMysqlTableMysqlColumngcp:datastream/StreamBackfillAllMysqlExcludedObjectsMysqlDatabaseMysqlTableMysqlColumn:StreamBackfillAllMysqlExcludedObjectsMysqlDatabaseMysqlTableMysqlColumnÚ
×%
	collationB" Column collation.

columnB" Column name.

dataTypeB" uThe MySQL data type. Full data types list can be found here:
https://dev.mysql.com/doc/refman/8.0/en/data-types.html
(
lengthB (Output)
Column length.
E
nullableB
 3Whether or not the column can accept a null value.
J
ordinalPositionB 1The ordinal position of the column in the table.
H

primaryKeyB
 4Whether or not the column represents a primary key.
:À


datastream&StreamBackfillAllOracleExcludedObjects\gcp:datastream/StreamBackfillAllOracleExcludedObjects:StreamBackfillAllOracleExcludedObjects¨
¥¢
oracleSchemas¿*¼:¹
¶

datastream2StreamBackfillAllOracleExcludedObjectsOracleSchematgcp:datastream/StreamBackfillAllOracleExcludedObjectsOracleSchema:StreamBackfillAllOracleExcludedObjectsOracleSchemaOOracle schemas/databases in the database server
Structure is documented below.
:
¶

datastream2StreamBackfillAllOracleExcludedObjectsOracleSchematgcp:datastream/StreamBackfillAllOracleExcludedObjectsOracleSchema:StreamBackfillAllOracleExcludedObjectsOracleSchemaÑ
Î®
oracleTablesäBá*Þ:Û
Ø

datastream=StreamBackfillAllOracleExcludedObjectsOracleSchemaOracleTablegcp:datastream/StreamBackfillAllOracleExcludedObjectsOracleSchemaOracleTable:StreamBackfillAllOracleExcludedObjectsOracleSchemaOracleTable7Tables in the database.
Structure is documented below.

schema" Schema name.
:¬
Ø

datastream=StreamBackfillAllOracleExcludedObjectsOracleSchemaOracleTablegcp:datastream/StreamBackfillAllOracleExcludedObjectsOracleSchemaOracleTable:StreamBackfillAllOracleExcludedObjectsOracleSchemaOracleTableÎ
Ë­
oracleColumnsB*:ÿ
ü

datastreamIStreamBackfillAllOracleExcludedObjectsOracleSchemaOracleTableOracleColumn¢gcp:datastream/StreamBackfillAllOracleExcludedObjectsOracleSchemaOracleTableOracleColumn:StreamBackfillAllOracleExcludedObjectsOracleSchemaOracleTableOracleColumnOracle columns in the schema. When unspecified as part of include/exclude objects, includes/excludes everything.
Structure is documented below.

table" Table name.
:ô
ü

datastreamIStreamBackfillAllOracleExcludedObjectsOracleSchemaOracleTableOracleColumn¢gcp:datastream/StreamBackfillAllOracleExcludedObjectsOracleSchemaOracleTableOracleColumn:StreamBackfillAllOracleExcludedObjectsOracleSchemaOracleTableOracleColumnò
ï
columnB" Column name.
¥
dataTypeB" The Oracle data type. Full data types list can be found here:
https://docs.oracle.com/en/database/oracle/oracle-database/21/sqlrf/Data-Types.html
,
encodingB" (Output)
Column encoding.
(
lengthB (Output)
Column length.
N
nullableB
 <(Output)
Whether or not the column can accept a null value.
S
ordinalPositionB :(Output)
The ordinal position of the column in the table.
.
	precisionB (Output)
Column precision.
Q

primaryKeyB
 =(Output)
Whether or not the column represents a primary key.
&
scaleB (Output)
Column scale.
:Ú


datastream*StreamBackfillAllPostgresqlExcludedObjectsdgcp:datastream/StreamBackfillAllPostgresqlExcludedObjects:StreamBackfillAllPostgresqlExcludedObjects¶
³°
postgresqlSchemasØ*Õ:Ò
Ï

datastream:StreamBackfillAllPostgresqlExcludedObjectsPostgresqlSchemagcp:datastream/StreamBackfillAllPostgresqlExcludedObjectsPostgresqlSchema:StreamBackfillAllPostgresqlExcludedObjectsPostgresqlSchema@PostgreSQL schemas on the server
Structure is documented below.
:Î
Ï

datastream:StreamBackfillAllPostgresqlExcludedObjectsPostgresqlSchemagcp:datastream/StreamBackfillAllPostgresqlExcludedObjectsPostgresqlSchema:StreamBackfillAllPostgresqlExcludedObjectsPostgresqlSchemaù
öÔ
postgresqlTablesB*:ÿ
ü

datastreamIStreamBackfillAllPostgresqlExcludedObjectsPostgresqlSchemaPostgresqlTable¢gcp:datastream/StreamBackfillAllPostgresqlExcludedObjectsPostgresqlSchemaPostgresqlTable:StreamBackfillAllPostgresqlExcludedObjectsPostgresqlSchemaPostgresqlTable5Tables in the schema.
Structure is documented below.

schema" Database name.
:
ü

datastreamIStreamBackfillAllPostgresqlExcludedObjectsPostgresqlSchemaPostgresqlTable¢gcp:datastream/StreamBackfillAllPostgresqlExcludedObjectsPostgresqlSchemaPostgresqlTable:StreamBackfillAllPostgresqlExcludedObjectsPostgresqlSchemaPostgresqlTable
å
postgresqlColumns¸Bµ*²:¯
¬

datastreamYStreamBackfillAllPostgresqlExcludedObjectsPostgresqlSchemaPostgresqlTablePostgresqlColumnÂgcp:datastream/StreamBackfillAllPostgresqlExcludedObjectsPostgresqlSchemaPostgresqlTablePostgresqlColumn:StreamBackfillAllPostgresqlExcludedObjectsPostgresqlSchemaPostgresqlTablePostgresqlColumnPostgreSQL columns in the schema. When unspecified as part of include/exclude objects, includes/excludes everything.
Structure is documented below.

table" Table name.
:À
¬

datastreamYStreamBackfillAllPostgresqlExcludedObjectsPostgresqlSchemaPostgresqlTablePostgresqlColumnÂgcp:datastream/StreamBackfillAllPostgresqlExcludedObjectsPostgresqlSchemaPostgresqlTablePostgresqlColumn:StreamBackfillAllPostgresqlExcludedObjectsPostgresqlSchemaPostgresqlTablePostgresqlColumn

columnB" Column name.

dataTypeB" xThe PostgreSQL data type. Full data types list can be found here:
https://www.postgresql.org/docs/current/datatype.html
(
lengthB (Output)
Column length.
E
nullableB
 3Whether or not the column can accept a null value.
J
ordinalPositionB 1The ordinal position of the column in the table.
.
	precisionB (Output)
Column precision.
H

primaryKeyB
 4Whether or not the column represents a primary key.
&
scaleB (Output)
Column scale.
:¾


datastream)StreamBackfillAllSqlServerExcludedObjectsbgcp:datastream/StreamBackfillAllSqlServerExcludedObjects:StreamBackfillAllSqlServerExcludedObjects

schemas¶*³:°
­

datastream/StreamBackfillAllSqlServerExcludedObjectsSchemangcp:datastream/StreamBackfillAllSqlServerExcludedObjectsSchema:StreamBackfillAllSqlServerExcludedObjectsSchemaSSQL Server schemas/databases in the database server
Structure is documented below.
:â
­

datastream/StreamBackfillAllSqlServerExcludedObjectsSchemangcp:datastream/StreamBackfillAllSqlServerExcludedObjectsSchema:StreamBackfillAllSqlServerExcludedObjectsSchema¯
¬
schema" Schema name.

tablesÈBÅ*Â:¿
¼

datastream4StreamBackfillAllSqlServerExcludedObjectsSchemaTablexgcp:datastream/StreamBackfillAllSqlServerExcludedObjectsSchemaTable:StreamBackfillAllSqlServerExcludedObjectsSchemaTable7Tables in the database.
Structure is documented below.
:á
¼

datastream4StreamBackfillAllSqlServerExcludedObjectsSchemaTablexgcp:datastream/StreamBackfillAllSqlServerExcludedObjectsSchemaTable:StreamBackfillAllSqlServerExcludedObjectsSchemaTable
þ
columnsÛBØ*Õ:Ò
Ï

datastream:StreamBackfillAllSqlServerExcludedObjectsSchemaTableColumngcp:datastream/StreamBackfillAllSqlServerExcludedObjectsSchemaTableColumn:StreamBackfillAllSqlServerExcludedObjectsSchemaTableColumnSQL Server columns in the schema. When unspecified as part of include/exclude objects, includes/excludes everything.
Structure is documented below.

table" Table name.
:®
Ï

datastream:StreamBackfillAllSqlServerExcludedObjectsSchemaTableColumngcp:datastream/StreamBackfillAllSqlServerExcludedObjectsSchemaTableColumn:StreamBackfillAllSqlServerExcludedObjectsSchemaTableColumnÙ
Ö
columnB" Column name.
º
dataTypeB" §The SQL Server data type. Full data types list can be found here:
https://learn.microsoft.com/en-us/sql/t-sql/data-types/data-types-transact-sql?view=sql-server-ver16
(
lengthB (Output)
Column length.
N
nullableB
 <(Output)
Whether or not the column can accept a null value.
S
ordinalPositionB :(Output)
The ordinal position of the column in the table.
.
	precisionB (Output)
Column precision.
Q

primaryKeyB
 =(Output)
Whether or not the column represents a primary key.
&
scaleB (Output)
Column scale.
:\
V

datastreamStreamBackfillNone4gcp:datastream/StreamBackfillNone:StreamBackfillNone
 :ë
e

datastreamStreamDestinationConfig>gcp:datastream/StreamDestinationConfig:StreamDestinationConfig
þº
bigqueryDestinationConfig¹B¶:³
°

datastream0StreamDestinationConfigBigqueryDestinationConfigpgcp:datastream/StreamDestinationConfigBigqueryDestinationConfig:StreamDestinationConfigBigqueryDestinationConfigaA configuration for how data should be loaded to Google BigQuery.
Structure is documented below.

destinationConnectionProfile" sDestination connection profile resource. Format: projects/{project}/locations/{location}/connectionProfiles/{name}
¤
gcsDestinationConfigªB§:¤
¡

datastream+StreamDestinationConfigGcsDestinationConfigfgcp:datastream/StreamDestinationConfigGcsDestinationConfig:StreamDestinationConfigGcsDestinationConfig_A configuration for how data should be loaded to Cloud Storage.
Structure is documented below.
:Ç
°

datastream0StreamDestinationConfigBigqueryDestinationConfigpgcp:datastream/StreamDestinationConfigBigqueryDestinationConfig:StreamDestinationConfigBigqueryDestinationConfig
Î

appendOnlyØBÕ:Ò
Ï

datastream:StreamDestinationConfigBigqueryDestinationConfigAppendOnlygcp:datastream/StreamDestinationConfigBigqueryDestinationConfigAppendOnly:StreamDestinationConfigBigqueryDestinationConfigAppendOnlyäAppendOnly mode defines that the stream of changes (INSERT, UPDATE-INSERT, UPDATE-DELETE and DELETE
events) to a source table will be written to the destination Google BigQuery table, retaining the
historical state of the data.
¦
dataFreshnessB" The guaranteed data freshness (in seconds) when querying tables created by the stream.
Editing this field will only affect new tables created in the future, but existing tables
will not be impacted. Lower values mean that queries will return fresher data, but may result in higher cost.
A duration in seconds with up to nine fractional digits, terminated by 's'. Example: "3.5s". Defaults to 900s.
õ
mergeÈBÅ:Â
¿

datastream5StreamDestinationConfigBigqueryDestinationConfigMergezgcp:datastream/StreamDestinationConfigBigqueryDestinationConfigMerge:StreamDestinationConfigBigqueryDestinationConfigMerge Merge mode defines that all changes to a table will be merged at the destination Google BigQuery
table. This is the default write mode. When selected, BigQuery reflects the way the data is stored
in the source database. With Merge mode, no historical record of the change events is kept.
è
singleTargetDatasetóBð:í
ê

datastreamCStreamDestinationConfigBigqueryDestinationConfigSingleTargetDatasetgcp:datastream/StreamDestinationConfigBigqueryDestinationConfigSingleTargetDataset:StreamDestinationConfigBigqueryDestinationConfigSingleTargetDataset[A single target dataset to which all data will be streamed.
Structure is documented below.
®
sourceHierarchyDatasetsÿBü:ù
ö

datastreamGStreamDestinationConfigBigqueryDestinationConfigSourceHierarchyDatasetsgcp:datastream/StreamDestinationConfigBigqueryDestinationConfigSourceHierarchyDatasets:StreamDestinationConfigBigqueryDestinationConfigSourceHierarchyDatasetsDestination datasets are created so that hierarchy of the destination data objects matches the source hierarchy.
Structure is documented below.
:Ö
Ï

datastream:StreamDestinationConfigBigqueryDestinationConfigAppendOnlygcp:datastream/StreamDestinationConfigBigqueryDestinationConfigAppendOnly:StreamDestinationConfigBigqueryDestinationConfigAppendOnly
 :Æ
¿

datastream5StreamDestinationConfigBigqueryDestinationConfigMergezgcp:datastream/StreamDestinationConfigBigqueryDestinationConfigMerge:StreamDestinationConfigBigqueryDestinationConfigMerge
 :à
ê

datastreamCStreamDestinationConfigBigqueryDestinationConfigSingleTargetDatasetgcp:datastream/StreamDestinationConfigBigqueryDestinationConfigSingleTargetDataset:StreamDestinationConfigBigqueryDestinationConfigSingleTargetDatasetq
om
	datasetId" \Dataset ID in the format projects/{project}/datasets/{dataset_id} or
{project}:{dataset_id}
:
ö

datastreamGStreamDestinationConfigBigqueryDestinationConfigSourceHierarchyDatasetsgcp:datastream/StreamDestinationConfigBigqueryDestinationConfigSourceHierarchyDatasets:StreamDestinationConfigBigqueryDestinationConfigSourceHierarchyDatasets

datasetTemplate©:¦
£

datastreamVStreamDestinationConfigBigqueryDestinationConfigSourceHierarchyDatasetsDatasetTemplate¼gcp:datastream/StreamDestinationConfigBigqueryDestinationConfigSourceHierarchyDatasetsDatasetTemplate:StreamDestinationConfigBigqueryDestinationConfigSourceHierarchyDatasetsDatasetTemplateSDataset template used for dynamic dataset creation.
Structure is documented below.
:
£

datastreamVStreamDestinationConfigBigqueryDestinationConfigSourceHierarchyDatasetsDatasetTemplate¼gcp:datastream/StreamDestinationConfigBigqueryDestinationConfigSourceHierarchyDatasetsDatasetTemplate:StreamDestinationConfigBigqueryDestinationConfigSourceHierarchyDatasetsDatasetTemplateè
å°
datasetIdPrefixB" If supplied, every created dataset will have its name prefixed by the provided value.
The prefix and name will be separated by an underscore. i.e. _.


kmsKeyNameB" ÿDescribes the Cloud KMS encryption key that will be used to protect destination BigQuery
table. The BigQuery Service Account associated with your project requires access to this
encryption key. i.e. projects/{project}/locations/{location}/keyRings/{key_ring}/cryptoKeys/{cryptoKey}.
See https://cloud.google.com/bigquery/docs/customer-managed-encryption for more information.

- - -

location" The geographic location where the dataset should reside.
See https://cloud.google.com/bigquery/docs/locations for supported locations.
:í
¡

datastream+StreamDestinationConfigGcsDestinationConfigfgcp:datastream/StreamDestinationConfigGcsDestinationConfig:StreamDestinationConfigGcsDestinationConfigÆ
Ã
avroFileFormatÕBÒ:Ï
Ì

datastream9StreamDestinationConfigGcsDestinationConfigAvroFileFormatgcp:datastream/StreamDestinationConfigGcsDestinationConfigAvroFileFormat:StreamDestinationConfigGcsDestinationConfigAvroFileFormat AVRO file format configuration.
õ
fileRotationIntervalB" ÖThe maximum duration for which new events are added before a file is closed and a new file is created.
A duration in seconds with up to nine fractional digits, terminated by 's'. Example: "3.5s". Defaults to 900s.
I
fileRotationMbB 1The maximum file size to be saved in the bucket.
©
jsonFileFormatÕBÒ:Ï
Ì

datastream9StreamDestinationConfigGcsDestinationConfigJsonFileFormatgcp:datastream/StreamDestinationConfigGcsDestinationConfigJsonFileFormat:StreamDestinationConfigGcsDestinationConfigJsonFileFormat?JSON file format configuration.
Structure is documented below.
E
pathB" 7Path inside the Cloud Storage bucket to write data to.
:Ó
Ì

datastream9StreamDestinationConfigGcsDestinationConfigAvroFileFormatgcp:datastream/StreamDestinationConfigGcsDestinationConfigAvroFileFormat:StreamDestinationConfigGcsDestinationConfigAvroFileFormat
 :Æ
Ì

datastream9StreamDestinationConfigGcsDestinationConfigJsonFileFormatgcp:datastream/StreamDestinationConfigGcsDestinationConfigJsonFileFormat:StreamDestinationConfigGcsDestinationConfigJsonFileFormatô
ñi
compressionB" TCompression of the loaded JSON file.
Possible values are: `NO_COMPRESSION`, `GZIP`.

schemaFileFormatB" iThe schema file format along JSON data files.
Possible values are: `NO_SCHEMA_FILE`, `AVRO_SCHEMA_FILE`.
:Ô	
V

datastreamStreamSourceConfig4gcp:datastream/StreamSourceConfig:StreamSourceConfigù
öê
mysqlSourceConfigB:


datastream#StreamSourceConfigMysqlSourceConfigVgcp:datastream/StreamSourceConfigMysqlSourceConfig:StreamSourceConfigMysqlSourceConfig@MySQL data source configuration.
Structure is documented below.
î
oracleSourceConfigB:


datastream$StreamSourceConfigOracleSourceConfigXgcp:datastream/StreamSourceConfigOracleSourceConfig:StreamSourceConfigOracleSourceConfig@MySQL data source configuration.
Structure is documented below.

postgresqlSourceConfig¡B:


datastream(StreamSourceConfigPostgresqlSourceConfig`gcp:datastream/StreamSourceConfigPostgresqlSourceConfig:StreamSourceConfigPostgresqlSourceConfigEPostgreSQL data source configuration.
Structure is documented below.

sourceConnectionProfile" nSource connection profile resource. Format: projects/{project}/locations/{location}/connectionProfiles/{name}
ÿ
sqlServerSourceConfigB:


datastream'StreamSourceConfigSqlServerSourceConfig^gcp:datastream/StreamSourceConfigSqlServerSourceConfig:StreamSourceConfigSqlServerSourceConfigESQL Server data source configuration.
Structure is documented below.
:¹


datastream#StreamSourceConfigMysqlSourceConfigVgcp:datastream/StreamSourceConfigMysqlSourceConfig:StreamSourceConfigMysqlSourceConfigª
§
excludeObjects¼B¹:¶
³

datastream1StreamSourceConfigMysqlSourceConfigExcludeObjectsrgcp:datastream/StreamSourceConfigMysqlSourceConfigExcludeObjects:StreamSourceConfigMysqlSourceConfigExcludeObjectsIMySQL objects to exclude from the stream.
Structure is documented below.

includeObjects¼B¹:¶
³

datastream1StreamSourceConfigMysqlSourceConfigIncludeObjectsrgcp:datastream/StreamSourceConfigMysqlSourceConfigIncludeObjects:StreamSourceConfigMysqlSourceConfigIncludeObjectsJMySQL objects to retrieve from the source.
Structure is documented below.
¸
maxConcurrentBackfillTasksB Maximum number of concurrent backfill tasks. The number should be non negative.
If not set (or set to 0), the system's default value will be used.
®
maxConcurrentCdcTasksB Maximum number of concurrent CDC tasks. The number should be non negative.
If not set (or set to 0), the system's default value will be used.
:õ
³

datastream1StreamSourceConfigMysqlSourceConfigExcludeObjectsrgcp:datastream/StreamSourceConfigMysqlSourceConfigExcludeObjects:StreamSourceConfigMysqlSourceConfigExcludeObjects¼
¹¶
mysqlDatabasesä*á:Þ
Û

datastream>StreamSourceConfigMysqlSourceConfigExcludeObjectsMysqlDatabasegcp:datastream/StreamSourceConfigMysqlSourceConfigExcludeObjectsMysqlDatabase:StreamSourceConfigMysqlSourceConfigExcludeObjectsMysqlDatabase=MySQL databases on the server
Structure is documented below.
:Ö
Û

datastream>StreamSourceConfigMysqlSourceConfigExcludeObjectsMysqlDatabasegcp:datastream/StreamSourceConfigMysqlSourceConfigExcludeObjectsMysqlDatabase:StreamSourceConfigMysqlSourceConfigExcludeObjectsMysqlDatabaseõ
ò
database" Database name.
Î
mysqlTablesB*ÿ:ü
ù

datastreamHStreamSourceConfigMysqlSourceConfigExcludeObjectsMysqlDatabaseMysqlTable gcp:datastream/StreamSourceConfigMysqlSourceConfigExcludeObjectsMysqlDatabaseMysqlTable:StreamSourceConfigMysqlSourceConfigExcludeObjectsMysqlDatabaseMysqlTable7Tables in the database.
Structure is documented below.
:é
ù

datastreamHStreamSourceConfigMysqlSourceConfigExcludeObjectsMysqlDatabaseMysqlTable gcp:datastream/StreamSourceConfigMysqlSourceConfigExcludeObjectsMysqlDatabaseMysqlTable:StreamSourceConfigMysqlSourceConfigExcludeObjectsMysqlDatabaseMysqlTableê
çÉ
mysqlColumns¦B£* :


datastreamSStreamSourceConfigMysqlSourceConfigExcludeObjectsMysqlDatabaseMysqlTableMysqlColumn¶gcp:datastream/StreamSourceConfigMysqlSourceConfigExcludeObjectsMysqlDatabaseMysqlTableMysqlColumn:StreamSourceConfigMysqlSourceConfigExcludeObjectsMysqlDatabaseMysqlTableMysqlColumnMySQL columns in the schema. When unspecified as part of include/exclude objects, includes/excludes everything.
Structure is documented below.

table" Table name.
:ú


datastreamSStreamSourceConfigMysqlSourceConfigExcludeObjectsMysqlDatabaseMysqlTableMysqlColumn¶gcp:datastream/StreamSourceConfigMysqlSourceConfigExcludeObjectsMysqlDatabaseMysqlTableMysqlColumn:StreamSourceConfigMysqlSourceConfigExcludeObjectsMysqlDatabaseMysqlTableMysqlColumnÚ
×%
	collationB" Column collation.

columnB" Column name.

dataTypeB" uThe MySQL data type. Full data types list can be found here:
https://dev.mysql.com/doc/refman/8.0/en/data-types.html
(
lengthB (Output)
Column length.
E
nullableB
 3Whether or not the column can accept a null value.
J
ordinalPositionB 1The ordinal position of the column in the table.
H

primaryKeyB
 4Whether or not the column represents a primary key.
:õ
³

datastream1StreamSourceConfigMysqlSourceConfigIncludeObjectsrgcp:datastream/StreamSourceConfigMysqlSourceConfigIncludeObjects:StreamSourceConfigMysqlSourceConfigIncludeObjects¼
¹¶
mysqlDatabasesä*á:Þ
Û

datastream>StreamSourceConfigMysqlSourceConfigIncludeObjectsMysqlDatabasegcp:datastream/StreamSourceConfigMysqlSourceConfigIncludeObjectsMysqlDatabase:StreamSourceConfigMysqlSourceConfigIncludeObjectsMysqlDatabase=MySQL databases on the server
Structure is documented below.
:Ö
Û

datastream>StreamSourceConfigMysqlSourceConfigIncludeObjectsMysqlDatabasegcp:datastream/StreamSourceConfigMysqlSourceConfigIncludeObjectsMysqlDatabase:StreamSourceConfigMysqlSourceConfigIncludeObjectsMysqlDatabaseõ
ò
database" Database name.
Î
mysqlTablesB*ÿ:ü
ù

datastreamHStreamSourceConfigMysqlSourceConfigIncludeObjectsMysqlDatabaseMysqlTable gcp:datastream/StreamSourceConfigMysqlSourceConfigIncludeObjectsMysqlDatabaseMysqlTable:StreamSourceConfigMysqlSourceConfigIncludeObjectsMysqlDatabaseMysqlTable7Tables in the database.
Structure is documented below.
:é
ù

datastreamHStreamSourceConfigMysqlSourceConfigIncludeObjectsMysqlDatabaseMysqlTable gcp:datastream/StreamSourceConfigMysqlSourceConfigIncludeObjectsMysqlDatabaseMysqlTable:StreamSourceConfigMysqlSourceConfigIncludeObjectsMysqlDatabaseMysqlTableê
çÉ
mysqlColumns¦B£* :


datastreamSStreamSourceConfigMysqlSourceConfigIncludeObjectsMysqlDatabaseMysqlTableMysqlColumn¶gcp:datastream/StreamSourceConfigMysqlSourceConfigIncludeObjectsMysqlDatabaseMysqlTableMysqlColumn:StreamSourceConfigMysqlSourceConfigIncludeObjectsMysqlDatabaseMysqlTableMysqlColumnMySQL columns in the schema. When unspecified as part of include/exclude objects, includes/excludes everything.
Structure is documented below.

table" Table name.
:ú


datastreamSStreamSourceConfigMysqlSourceConfigIncludeObjectsMysqlDatabaseMysqlTableMysqlColumn¶gcp:datastream/StreamSourceConfigMysqlSourceConfigIncludeObjectsMysqlDatabaseMysqlTableMysqlColumn:StreamSourceConfigMysqlSourceConfigIncludeObjectsMysqlDatabaseMysqlTableMysqlColumnÚ
×%
	collationB" Column collation.

columnB" Column name.

dataTypeB" uThe MySQL data type. Full data types list can be found here:
https://dev.mysql.com/doc/refman/8.0/en/data-types.html
(
lengthB (Output)
Column length.
E
nullableB
 3Whether or not the column can accept a null value.
J
ordinalPositionB 1The ordinal position of the column in the table.
H

primaryKeyB
 4Whether or not the column represents a primary key.
:à


datastream$StreamSourceConfigOracleSourceConfigXgcp:datastream/StreamSourceConfigOracleSourceConfig:StreamSourceConfigOracleSourceConfigÎ
Ë
dropLargeObjectsÅBÂ:¿
¼

datastream4StreamSourceConfigOracleSourceConfigDropLargeObjectsxgcp:datastream/StreamSourceConfigOracleSourceConfigDropLargeObjects:StreamSourceConfigOracleSourceConfigDropLargeObjects+Configuration to drop large object values.

excludeObjects¿B¼:¹
¶

datastream2StreamSourceConfigOracleSourceConfigExcludeObjectstgcp:datastream/StreamSourceConfigOracleSourceConfigExcludeObjects:StreamSourceConfigOracleSourceConfigExcludeObjectsJOracle objects to exclude from the stream.
Structure is documented below.

includeObjects¿B¼:¹
¶

datastream2StreamSourceConfigOracleSourceConfigIncludeObjectstgcp:datastream/StreamSourceConfigOracleSourceConfigIncludeObjects:StreamSourceConfigOracleSourceConfigIncludeObjectsKOracle objects to retrieve from the source.
Structure is documented below.
¸
maxConcurrentBackfillTasksB Maximum number of concurrent backfill tasks. The number should be non negative.
If not set (or set to 0), the system's default value will be used.
®
maxConcurrentCdcTasksB Maximum number of concurrent CDC tasks. The number should be non negative.
If not set (or set to 0), the system's default value will be used.

streamLargeObjectsËBÈ:Å
Â

datastream6StreamSourceConfigOracleSourceConfigStreamLargeObjects|gcp:datastream/StreamSourceConfigOracleSourceConfigStreamLargeObjects:StreamSourceConfigOracleSourceConfigStreamLargeObjects+Configuration to drop large object values.
:Ã
¼

datastream4StreamSourceConfigOracleSourceConfigDropLargeObjectsxgcp:datastream/StreamSourceConfigOracleSourceConfigDropLargeObjects:StreamSourceConfigOracleSourceConfigDropLargeObjects
 :
¶

datastream2StreamSourceConfigOracleSourceConfigExcludeObjectstgcp:datastream/StreamSourceConfigOracleSourceConfigExcludeObjects:StreamSourceConfigOracleSourceConfigExcludeObjectsÍ
ÊÇ
oracleSchemasä*á:Þ
Û

datastream>StreamSourceConfigOracleSourceConfigExcludeObjectsOracleSchemagcp:datastream/StreamSourceConfigOracleSourceConfigExcludeObjectsOracleSchema:StreamSourceConfigOracleSourceConfigExcludeObjectsOracleSchemaOOracle schemas/databases in the database server
Structure is documented below.
:Ö
Û

datastream>StreamSourceConfigOracleSourceConfigExcludeObjectsOracleSchemagcp:datastream/StreamSourceConfigOracleSourceConfigExcludeObjectsOracleSchema:StreamSourceConfigOracleSourceConfigExcludeObjectsOracleSchemaõ
òÒ
oracleTablesB*:ÿ
ü

datastreamIStreamSourceConfigOracleSourceConfigExcludeObjectsOracleSchemaOracleTable¢gcp:datastream/StreamSourceConfigOracleSourceConfigExcludeObjectsOracleSchemaOracleTable:StreamSourceConfigOracleSourceConfigExcludeObjectsOracleSchemaOracleTable7Tables in the database.
Structure is documented below.

schema" Schema name.
:ô
ü

datastreamIStreamSourceConfigOracleSourceConfigExcludeObjectsOracleSchemaOracleTable¢gcp:datastream/StreamSourceConfigOracleSourceConfigExcludeObjectsOracleSchemaOracleTable:StreamSourceConfigOracleSourceConfigExcludeObjectsOracleSchemaOracleTableò
ïÑ
oracleColumns¬B©*¦:£
 

datastreamUStreamSourceConfigOracleSourceConfigExcludeObjectsOracleSchemaOracleTableOracleColumnºgcp:datastream/StreamSourceConfigOracleSourceConfigExcludeObjectsOracleSchemaOracleTableOracleColumn:StreamSourceConfigOracleSourceConfigExcludeObjectsOracleSchemaOracleTableOracleColumnOracle columns in the schema. When unspecified as part of include/exclude objects, includes/excludes everything.
Structure is documented below.

table" Table name.
:
 

datastreamUStreamSourceConfigOracleSourceConfigExcludeObjectsOracleSchemaOracleTableOracleColumnºgcp:datastream/StreamSourceConfigOracleSourceConfigExcludeObjectsOracleSchemaOracleTableOracleColumn:StreamSourceConfigOracleSourceConfigExcludeObjectsOracleSchemaOracleTableOracleColumnò
ï
columnB" Column name.
¥
dataTypeB" The Oracle data type. Full data types list can be found here:
https://docs.oracle.com/en/database/oracle/oracle-database/21/sqlrf/Data-Types.html
,
encodingB" (Output)
Column encoding.
(
lengthB (Output)
Column length.
N
nullableB
 <(Output)
Whether or not the column can accept a null value.
S
ordinalPositionB :(Output)
The ordinal position of the column in the table.
.
	precisionB (Output)
Column precision.
Q

primaryKeyB
 =(Output)
Whether or not the column represents a primary key.
&
scaleB (Output)
Column scale.
:
¶

datastream2StreamSourceConfigOracleSourceConfigIncludeObjectstgcp:datastream/StreamSourceConfigOracleSourceConfigIncludeObjects:StreamSourceConfigOracleSourceConfigIncludeObjectsÍ
ÊÇ
oracleSchemasä*á:Þ
Û

datastream>StreamSourceConfigOracleSourceConfigIncludeObjectsOracleSchemagcp:datastream/StreamSourceConfigOracleSourceConfigIncludeObjectsOracleSchema:StreamSourceConfigOracleSourceConfigIncludeObjectsOracleSchemaOOracle schemas/databases in the database server
Structure is documented below.
:Ö
Û

datastream>StreamSourceConfigOracleSourceConfigIncludeObjectsOracleSchemagcp:datastream/StreamSourceConfigOracleSourceConfigIncludeObjectsOracleSchema:StreamSourceConfigOracleSourceConfigIncludeObjectsOracleSchemaõ
òÒ
oracleTablesB*:ÿ
ü

datastreamIStreamSourceConfigOracleSourceConfigIncludeObjectsOracleSchemaOracleTable¢gcp:datastream/StreamSourceConfigOracleSourceConfigIncludeObjectsOracleSchemaOracleTable:StreamSourceConfigOracleSourceConfigIncludeObjectsOracleSchemaOracleTable7Tables in the database.
Structure is documented below.

schema" Schema name.
:ô
ü

datastreamIStreamSourceConfigOracleSourceConfigIncludeObjectsOracleSchemaOracleTable¢gcp:datastream/StreamSourceConfigOracleSourceConfigIncludeObjectsOracleSchemaOracleTable:StreamSourceConfigOracleSourceConfigIncludeObjectsOracleSchemaOracleTableò
ïÑ
oracleColumns¬B©*¦:£
 

datastreamUStreamSourceConfigOracleSourceConfigIncludeObjectsOracleSchemaOracleTableOracleColumnºgcp:datastream/StreamSourceConfigOracleSourceConfigIncludeObjectsOracleSchemaOracleTableOracleColumn:StreamSourceConfigOracleSourceConfigIncludeObjectsOracleSchemaOracleTableOracleColumnOracle columns in the schema. When unspecified as part of include/exclude objects, includes/excludes everything.
Structure is documented below.

table" Table name.
:
 

datastreamUStreamSourceConfigOracleSourceConfigIncludeObjectsOracleSchemaOracleTableOracleColumnºgcp:datastream/StreamSourceConfigOracleSourceConfigIncludeObjectsOracleSchemaOracleTableOracleColumn:StreamSourceConfigOracleSourceConfigIncludeObjectsOracleSchemaOracleTableOracleColumnò
ï
columnB" Column name.
¥
dataTypeB" The Oracle data type. Full data types list can be found here:
https://docs.oracle.com/en/database/oracle/oracle-database/21/sqlrf/Data-Types.html
,
encodingB" (Output)
Column encoding.
(
lengthB (Output)
Column length.
N
nullableB
 <(Output)
Whether or not the column can accept a null value.
S
ordinalPositionB :(Output)
The ordinal position of the column in the table.
.
	precisionB (Output)
Column precision.
Q

primaryKeyB
 =(Output)
Whether or not the column represents a primary key.
&
scaleB (Output)
Column scale.
:É
Â

datastream6StreamSourceConfigOracleSourceConfigStreamLargeObjects|gcp:datastream/StreamSourceConfigOracleSourceConfigStreamLargeObjects:StreamSourceConfigOracleSourceConfigStreamLargeObjects
 :µ	


datastream(StreamSourceConfigPostgresqlSourceConfig`gcp:datastream/StreamSourceConfigPostgresqlSourceConfig:StreamSourceConfigPostgresqlSourceConfig
®
excludeObjectsËBÈ:Å
Â

datastream6StreamSourceConfigPostgresqlSourceConfigExcludeObjects|gcp:datastream/StreamSourceConfigPostgresqlSourceConfigExcludeObjects:StreamSourceConfigPostgresqlSourceConfigExcludeObjectsNPostgreSQL objects to exclude from the stream.
Structure is documented below.
¯
includeObjectsËBÈ:Å
Â

datastream6StreamSourceConfigPostgresqlSourceConfigIncludeObjects|gcp:datastream/StreamSourceConfigPostgresqlSourceConfigIncludeObjects:StreamSourceConfigPostgresqlSourceConfigIncludeObjectsOPostgreSQL objects to retrieve from the source.
Structure is documented below.
¸
maxConcurrentBackfillTasksB Maximum number of concurrent backfill tasks. The number should be non
negative. If not set (or set to 0), the system's default value will be used.

publication" rThe name of the publication that includes the set of all tables
that are defined in the stream's include_objects.
l
replicationSlot" UThe name of the logical replication slot that's configured with
the pgoutput plugin.
:¢
Â

datastream6StreamSourceConfigPostgresqlSourceConfigExcludeObjects|gcp:datastream/StreamSourceConfigPostgresqlSourceConfigExcludeObjects:StreamSourceConfigPostgresqlSourceConfigExcludeObjectsÚ
×Ô
postgresqlSchemasü*ù:ö
ó

datastreamFStreamSourceConfigPostgresqlSourceConfigExcludeObjectsPostgresqlSchemagcp:datastream/StreamSourceConfigPostgresqlSourceConfigExcludeObjectsPostgresqlSchema:StreamSourceConfigPostgresqlSourceConfigExcludeObjectsPostgresqlSchema@PostgreSQL schemas on the server
Structure is documented below.
:
ó

datastreamFStreamSourceConfigPostgresqlSourceConfigExcludeObjectsPostgresqlSchemagcp:datastream/StreamSourceConfigPostgresqlSourceConfigExcludeObjectsPostgresqlSchema:StreamSourceConfigPostgresqlSourceConfigExcludeObjectsPostgresqlSchema
ø
postgresqlTables¬B©*¦:£
 

datastreamUStreamSourceConfigPostgresqlSourceConfigExcludeObjectsPostgresqlSchemaPostgresqlTableºgcp:datastream/StreamSourceConfigPostgresqlSourceConfigExcludeObjectsPostgresqlSchemaPostgresqlTable:StreamSourceConfigPostgresqlSourceConfigExcludeObjectsPostgresqlSchemaPostgresqlTable5Tables in the schema.
Structure is documented below.

schema" Database name.
:Ð
 

datastreamUStreamSourceConfigPostgresqlSourceConfigExcludeObjectsPostgresqlSchemaPostgresqlTableºgcp:datastream/StreamSourceConfigPostgresqlSourceConfigExcludeObjectsPostgresqlSchemaPostgresqlTable:StreamSourceConfigPostgresqlSourceConfigExcludeObjectsPostgresqlSchemaPostgresqlTableª
§
postgresqlColumnsÜBÙ*Ö:Ó
Ð

datastreameStreamSourceConfigPostgresqlSourceConfigExcludeObjectsPostgresqlSchemaPostgresqlTablePostgresqlColumnÚgcp:datastream/StreamSourceConfigPostgresqlSourceConfigExcludeObjectsPostgresqlSchemaPostgresqlTablePostgresqlColumn:StreamSourceConfigPostgresqlSourceConfigExcludeObjectsPostgresqlSchemaPostgresqlTablePostgresqlColumnPostgreSQL columns in the schema. When unspecified as part of include/exclude objects, includes/excludes everything.
Structure is documented below.

table" Table name.
:ä
Ð

datastreameStreamSourceConfigPostgresqlSourceConfigExcludeObjectsPostgresqlSchemaPostgresqlTablePostgresqlColumnÚgcp:datastream/StreamSourceConfigPostgresqlSourceConfigExcludeObjectsPostgresqlSchemaPostgresqlTablePostgresqlColumn:StreamSourceConfigPostgresqlSourceConfigExcludeObjectsPostgresqlSchemaPostgresqlTablePostgresqlColumn

columnB" Column name.

dataTypeB" xThe PostgreSQL data type. Full data types list can be found here:
https://www.postgresql.org/docs/current/datatype.html
(
lengthB (Output)
Column length.
E
nullableB
 3Whether or not the column can accept a null value.
J
ordinalPositionB 1The ordinal position of the column in the table.
.
	precisionB (Output)
Column precision.
H

primaryKeyB
 4Whether or not the column represents a primary key.
&
scaleB (Output)
Column scale.
:¢
Â

datastream6StreamSourceConfigPostgresqlSourceConfigIncludeObjects|gcp:datastream/StreamSourceConfigPostgresqlSourceConfigIncludeObjects:StreamSourceConfigPostgresqlSourceConfigIncludeObjectsÚ
×Ô
postgresqlSchemasü*ù:ö
ó

datastreamFStreamSourceConfigPostgresqlSourceConfigIncludeObjectsPostgresqlSchemagcp:datastream/StreamSourceConfigPostgresqlSourceConfigIncludeObjectsPostgresqlSchema:StreamSourceConfigPostgresqlSourceConfigIncludeObjectsPostgresqlSchema@PostgreSQL schemas on the server
Structure is documented below.
:
ó

datastreamFStreamSourceConfigPostgresqlSourceConfigIncludeObjectsPostgresqlSchemagcp:datastream/StreamSourceConfigPostgresqlSourceConfigIncludeObjectsPostgresqlSchema:StreamSourceConfigPostgresqlSourceConfigIncludeObjectsPostgresqlSchema
ø
postgresqlTables¬B©*¦:£
 

datastreamUStreamSourceConfigPostgresqlSourceConfigIncludeObjectsPostgresqlSchemaPostgresqlTableºgcp:datastream/StreamSourceConfigPostgresqlSourceConfigIncludeObjectsPostgresqlSchemaPostgresqlTable:StreamSourceConfigPostgresqlSourceConfigIncludeObjectsPostgresqlSchemaPostgresqlTable5Tables in the schema.
Structure is documented below.

schema" Database name.
:Ð
 

datastreamUStreamSourceConfigPostgresqlSourceConfigIncludeObjectsPostgresqlSchemaPostgresqlTableºgcp:datastream/StreamSourceConfigPostgresqlSourceConfigIncludeObjectsPostgresqlSchemaPostgresqlTable:StreamSourceConfigPostgresqlSourceConfigIncludeObjectsPostgresqlSchemaPostgresqlTableª
§
postgresqlColumnsÜBÙ*Ö:Ó
Ð

datastreameStreamSourceConfigPostgresqlSourceConfigIncludeObjectsPostgresqlSchemaPostgresqlTablePostgresqlColumnÚgcp:datastream/StreamSourceConfigPostgresqlSourceConfigIncludeObjectsPostgresqlSchemaPostgresqlTablePostgresqlColumn:StreamSourceConfigPostgresqlSourceConfigIncludeObjectsPostgresqlSchemaPostgresqlTablePostgresqlColumnPostgreSQL columns in the schema. When unspecified as part of include/exclude objects, includes/excludes everything.
Structure is documented below.

table" Table name.
:ä
Ð

datastreameStreamSourceConfigPostgresqlSourceConfigIncludeObjectsPostgresqlSchemaPostgresqlTablePostgresqlColumnÚgcp:datastream/StreamSourceConfigPostgresqlSourceConfigIncludeObjectsPostgresqlSchemaPostgresqlTablePostgresqlColumn:StreamSourceConfigPostgresqlSourceConfigIncludeObjectsPostgresqlSchemaPostgresqlTablePostgresqlColumn

columnB" Column name.

dataTypeB" xThe PostgreSQL data type. Full data types list can be found here:
https://www.postgresql.org/docs/current/datatype.html
(
lengthB (Output)
Column length.
E
nullableB
 3Whether or not the column can accept a null value.
J
ordinalPositionB 1The ordinal position of the column in the table.
.
	precisionB (Output)
Column precision.
H

primaryKeyB
 4Whether or not the column represents a primary key.
&
scaleB (Output)
Column scale.
:


datastream'StreamSourceConfigSqlServerSourceConfig^gcp:datastream/StreamSourceConfigSqlServerSourceConfig:StreamSourceConfigSqlServerSourceConfigé	
æ	ú
changeTablesÂB¿:¼
¹

datastream3StreamSourceConfigSqlServerSourceConfigChangeTablesvgcp:datastream/StreamSourceConfigSqlServerSourceConfigChangeTables:StreamSourceConfigSqlServerSourceConfigChangeTables%CDC reader reads from change tables.
«
excludeObjectsÈBÅ:Â
¿

datastream5StreamSourceConfigSqlServerSourceConfigExcludeObjectszgcp:datastream/StreamSourceConfigSqlServerSourceConfigExcludeObjects:StreamSourceConfigSqlServerSourceConfigExcludeObjectsNSQL Server objects to exclude from the stream.
Structure is documented below.
¬
includeObjectsÈBÅ:Â
¿

datastream5StreamSourceConfigSqlServerSourceConfigIncludeObjectszgcp:datastream/StreamSourceConfigSqlServerSourceConfigIncludeObjects:StreamSourceConfigSqlServerSourceConfigIncludeObjectsOSQL Server objects to retrieve from the source.
Structure is documented below.
C
maxConcurrentBackfillTasksB Max concurrent backfill tasks.
9
maxConcurrentCdcTasksB Max concurrent CDC tasks.

transactionLogsËBÈ:Å
Â

datastream6StreamSourceConfigSqlServerSourceConfigTransactionLogs|gcp:datastream/StreamSourceConfigSqlServerSourceConfigTransactionLogs:StreamSourceConfigSqlServerSourceConfigTransactionLogs(CDC reader reads from transaction logs.
:À
¹

datastream3StreamSourceConfigSqlServerSourceConfigChangeTablesvgcp:datastream/StreamSourceConfigSqlServerSourceConfigChangeTables:StreamSourceConfigSqlServerSourceConfigChangeTables
 :
¿

datastream5StreamSourceConfigSqlServerSourceConfigExcludeObjectszgcp:datastream/StreamSourceConfigSqlServerSourceConfigExcludeObjects:StreamSourceConfigSqlServerSourceConfigExcludeObjectsÂ
¿¼
schemasÛ*Ø:Õ
Ò

datastream;StreamSourceConfigSqlServerSourceConfigExcludeObjectsSchemagcp:datastream/StreamSourceConfigSqlServerSourceConfigExcludeObjectsSchema:StreamSourceConfigSqlServerSourceConfigExcludeObjectsSchemaSSQL Server schemas/databases in the database server
Structure is documented below.
:¬
Ò

datastream;StreamSourceConfigSqlServerSourceConfigExcludeObjectsSchemagcp:datastream/StreamSourceConfigSqlServerSourceConfigExcludeObjectsSchema:StreamSourceConfigSqlServerSourceConfigExcludeObjectsSchemaÔ
Ñ
schema" Schema name.
±
tablesíBê*ç:ä
á

datastream@StreamSourceConfigSqlServerSourceConfigExcludeObjectsSchemaTablegcp:datastream/StreamSourceConfigSqlServerSourceConfigExcludeObjectsSchemaTable:StreamSourceConfigSqlServerSourceConfigExcludeObjectsSchemaTable7Tables in the database.
Structure is documented below.
:ª
á

datastream@StreamSourceConfigSqlServerSourceConfigExcludeObjectsSchemaTablegcp:datastream/StreamSourceConfigSqlServerSourceConfigExcludeObjectsSchemaTable:StreamSourceConfigSqlServerSourceConfigExcludeObjectsSchemaTableÃ
À¢
columnsÿBü*ù:ö
ó

datastreamFStreamSourceConfigSqlServerSourceConfigExcludeObjectsSchemaTableColumngcp:datastream/StreamSourceConfigSqlServerSourceConfigExcludeObjectsSchemaTableColumn:StreamSourceConfigSqlServerSourceConfigExcludeObjectsSchemaTableColumnSQL Server columns in the schema. When unspecified as part of include/exclude objects, includes/excludes everything.
Structure is documented below.

table" Table name.
:Ò
ó

datastreamFStreamSourceConfigSqlServerSourceConfigExcludeObjectsSchemaTableColumngcp:datastream/StreamSourceConfigSqlServerSourceConfigExcludeObjectsSchemaTableColumn:StreamSourceConfigSqlServerSourceConfigExcludeObjectsSchemaTableColumnÙ
Ö
columnB" Column name.
º
dataTypeB" §The SQL Server data type. Full data types list can be found here:
https://learn.microsoft.com/en-us/sql/t-sql/data-types/data-types-transact-sql?view=sql-server-ver16
(
lengthB (Output)
Column length.
N
nullableB
 <(Output)
Whether or not the column can accept a null value.
S
ordinalPositionB :(Output)
The ordinal position of the column in the table.
.
	precisionB (Output)
Column precision.
Q

primaryKeyB
 =(Output)
Whether or not the column represents a primary key.
&
scaleB (Output)
Column scale.
:
¿

datastream5StreamSourceConfigSqlServerSourceConfigIncludeObjectszgcp:datastream/StreamSourceConfigSqlServerSourceConfigIncludeObjects:StreamSourceConfigSqlServerSourceConfigIncludeObjectsÂ
¿¼
schemasÛ*Ø:Õ
Ò

datastream;StreamSourceConfigSqlServerSourceConfigIncludeObjectsSchemagcp:datastream/StreamSourceConfigSqlServerSourceConfigIncludeObjectsSchema:StreamSourceConfigSqlServerSourceConfigIncludeObjectsSchemaSSQL Server schemas/databases in the database server
Structure is documented below.
:¬
Ò

datastream;StreamSourceConfigSqlServerSourceConfigIncludeObjectsSchemagcp:datastream/StreamSourceConfigSqlServerSourceConfigIncludeObjectsSchema:StreamSourceConfigSqlServerSourceConfigIncludeObjectsSchemaÔ
Ñ
schema" Schema name.
±
tablesíBê*ç:ä
á

datastream@StreamSourceConfigSqlServerSourceConfigIncludeObjectsSchemaTablegcp:datastream/StreamSourceConfigSqlServerSourceConfigIncludeObjectsSchemaTable:StreamSourceConfigSqlServerSourceConfigIncludeObjectsSchemaTable7Tables in the database.
Structure is documented below.
:ª
á

datastream@StreamSourceConfigSqlServerSourceConfigIncludeObjectsSchemaTablegcp:datastream/StreamSourceConfigSqlServerSourceConfigIncludeObjectsSchemaTable:StreamSourceConfigSqlServerSourceConfigIncludeObjectsSchemaTableÃ
À¢
columnsÿBü*ù:ö
ó

datastreamFStreamSourceConfigSqlServerSourceConfigIncludeObjectsSchemaTableColumngcp:datastream/StreamSourceConfigSqlServerSourceConfigIncludeObjectsSchemaTableColumn:StreamSourceConfigSqlServerSourceConfigIncludeObjectsSchemaTableColumnSQL Server columns in the schema. When unspecified as part of include/exclude objects, includes/excludes everything.
Structure is documented below.

table" Table name.
:Ò
ó

datastreamFStreamSourceConfigSqlServerSourceConfigIncludeObjectsSchemaTableColumngcp:datastream/StreamSourceConfigSqlServerSourceConfigIncludeObjectsSchemaTableColumn:StreamSourceConfigSqlServerSourceConfigIncludeObjectsSchemaTableColumnÙ
Ö
columnB" Column name.
º
dataTypeB" §The SQL Server data type. Full data types list can be found here:
https://learn.microsoft.com/en-us/sql/t-sql/data-types/data-types-transact-sql?view=sql-server-ver16
(
lengthB (Output)
Column length.
N
nullableB
 <(Output)
Whether or not the column can accept a null value.
S
ordinalPositionB :(Output)
The ordinal position of the column in the table.
.
	precisionB (Output)
Column precision.
Q

primaryKeyB
 =(Output)
Whether or not the column represents a primary key.
&
scaleB (Output)
Column scale.
:É
Â

datastream6StreamSourceConfigSqlServerSourceConfigTransactionLogs|gcp:datastream/StreamSourceConfigSqlServerSourceConfigTransactionLogs:StreamSourceConfigSqlServerSourceConfigTransactionLogs
 